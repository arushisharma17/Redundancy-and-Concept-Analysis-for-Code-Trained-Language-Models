Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_CodeBERT
Loading json activations from ./activations/codebert_activations_train.json...
54291 13.0
Skipping line:  2668
A: 2, S: 3, T: 3
Deleting line 2668: 2 activations, 3 source, 3 target
Number of tokens:  507518
length of source dictionary:  28818
length of target dictionary:  49
507518
Total instances: 507518
['criterion_str', 'is_point_fmt_compatible_with_version', '_client', "'imageDetails'", 'expression_y', 'socket', 'CANCELLED', 'shard_no', 'widgets', 'tv', "'gene_name'", "'drive'", 'sig_next_f', 'compute_bleu', 'from_iterable', 'plasmid_length', 'FloatTensor', 'wrapped_skills', 'from_records', 'createSOAPMessage']
Number of samples:  507518
Stats: Labels with their frequencies in the final set
NAME 175779
KEYWORD 38836
LPAR 37541
RPAR 36846
DOT 35570
COMMA 33435
EQUAL 30541
COLON 19840
STRING 17115
DEDENT 16600
LSQB 14740
RSQB 14613
INDENT 11963
NUMBER 10471
PLUS 1939
EQEQUAL 1830
STAR 1500
MINUS 1458
LBRACE 1070
RBRACE 845
DOUBLESTAR 844
SLASH 630
PERCENT 577
PLUSEQUAL 501
GREATER 456
NOTEQUAL 429
LESS 332
RARROW 330
GREATEREQUAL 175
LESSEQUAL 133
AMPER 94
DOUBLESLASH 94
MINEQUAL 58
ELLIPSIS 55
COMMENT 37
VBAR 35
AT 29
STAREQUAL 27
RIGHTSHIFT 25
LEFTSHIFT 25
SLASHEQUAL 24
VBAREQUAL 23
TILDE 23
CIRCUMFLEX 22
AMPEREQUAL 2
DOUBLESLASHEQUAL 2
RIGHTSHIFTEQUAL 2
ENCODING 1
DOUBLESTAREQUAL 1
pretrained_CodeBERT distribution after trauncating:
{0: 0.7257567062068282, 3: 0.16034615876895636, 1: 0.07066444812366587, 2: 0.043232686900549544}
{0: 175779, 3: 38836, 1: 17115, 2: 10471}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codebert_activations_valid.json...
33619 13.0
Number of tokens:  308882
length of source dictionary:  19446
length of target dictionary:  46
308882
Total instances: 308882
['forgot_password', 'kernel_name', '_client', '_imports', 'socket', 'accepted', "'connected'", '"Disease"', 'nid', 'widgets', 'from_string', 'group_key', "'azlength'", "'-l'", 'run_branch', 'CONF', 'DatetimeIndex', "'#3b5b92'", 'plot_gain_offsets', 'disease']
Number of samples:  308882
Stats: Labels with their frequencies in the final set
NAME 106508
DOT 23234
KEYWORD 22857
LPAR 22119
RPAR 21487
COMMA 21037
EQUAL 18195
STRING 12883
COLON 12504
DEDENT 10176
LSQB 8421
RSQB 8348
INDENT 7080
NUMBER 5227
EQEQUAL 1207
PLUS 1136
LBRACE 1077
STAR 963
RBRACE 913
MINUS 741
DOUBLESTAR 555
SLASH 393
PLUSEQUAL 323
GREATER 292
NOTEQUAL 240
PERCENT 222
RARROW 214
LESS 200
GREATEREQUAL 82
LESSEQUAL 47
AT 33
AMPER 29
DOUBLESLASH 27
MINEQUAL 27
VBAR 23
COMMENT 13
ELLIPSIS 13
STAREQUAL 10
LEFTSHIFT 7
TILDE 7
RIGHTSHIFT 4
SLASHEQUAL 3
CIRCUMFLEX 2
ENCODING 1
DOUBLESLASHEQUAL 1
AMPEREQUAL 1
pretrained_CodeBERT distribution after trauncating:
{0: 0.7222105441600272, 3: 0.1549889811832514, 1: 0.08735717918291236, 2: 0.035443295473809124}
{0: 106508, 3: 22857, 1: 12883, 2: 5227}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codebert_activations_test.json...
32570 13.0
Number of tokens:  302448
length of source dictionary:  18380
length of target dictionary:  49
302448
Total instances: 302448
['Box', 'demonstration', 'socket', 'nL1SimpleSequences', 'queries_map', 'tv', 'ClientResponse', '">H"', 'sparseThreshold', "'whitespace/indent'", '_minLikelihoodThreshold', '_indentLines', 'nditer', "'bolts'", 'CUSTOM', 'out', 'parents', 'cast_type', '_bias_scale', 'name2count']
Number of samples:  302448
Stats: Labels with their frequencies in the final set
NAME 106943
DOT 23125
LPAR 23019
RPAR 22645
KEYWORD 21773
COMMA 19472
EQUAL 18096
COLON 11225
DEDENT 9778
STRING 8156
LSQB 7717
RSQB 7682
NUMBER 7295
INDENT 6823
EQEQUAL 1344
MINUS 1259
PLUS 1013
STAR 863
LBRACE 527
PLUSEQUAL 448
RBRACE 436
GREATER 417
PERCENT 341
NOTEQUAL 341
SLASH 323
DOUBLESTAR 284
LESS 247
GREATEREQUAL 216
LESSEQUAL 107
AMPER 100
RIGHTSHIFT 61
LEFTSHIFT 53
MINEQUAL 48
DOUBLESLASH 48
RARROW 41
VBAR 38
ELLIPSIS 28
COMMENT 19
AT 17
CIRCUMFLEX 17
STAREQUAL 15
SLASHEQUAL 15
VBAREQUAL 12
TILDE 7
SEMI 6
PERCENTEQUAL 5
ENCODING 1
DOUBLESTAREQUAL 1
AMPEREQUAL 1
pretrained_CodeBERT distribution after trauncating:
{0: 0.7417994409261481, 3: 0.1510262404017563, 1: 0.05657327959935353, 2: 0.05060103907274203}
{0: 106943, 3: 21773, 1: 8156, 2: 7295}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
label:3, the number of unique tokens:33
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:21572
label:1, the number of unique tokens:6803
label:2, the number of unique tokens:331
The unique labels are:['.00001', '.01', '.05', '.1', '.2', '.3', '.5', '.9', '.95', '0', '0.', '0.0', '0.00002', '0.0001', '0.001', '0.002', '0.005', '0.01', '0.01683697', '0.02', '0.025', '0.03', '0.05', '0.07', '0.1', '0.15', '0.2', '0.20', '0.22', '0.25', '0.3', '0.33', '0.4', '0.400', '0.5', '0.50922', '0.53', '0.7', '0.75', '0.8', '0.80', '0.85', '0.9', '0.95', '0.98', '0.99', '0j', '0o600', '0o644', '0o777', '0x00', '0x08', '0x0B', '0x1', '0x147A', '0x1F', '0x7F', '0x80', '0x8000', '0x84', '0x86', '0x88', '0x89', '0x9F', '0xAC00', '0xFF', '0xFFFF', '0xff', '1', '1.', '1.0', '1.05', '1.08', '1.0e-7', '1.1', '1.10', '1.2', '1.25', '1.3', '1.4', '1.406211e-6', '1.5', '1.J', '1.j', '10', '10.0', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '10000000', '1000000000.0', '100000000000', '101', '101677777', '1023', '1024', '1024.0', '107.7', '109', '10e10', '11', '11025', '11025.0', '111', '113', '12', '12.', '12.0', '120', '120.0', '120000', '12200', '127', '128', '13', '131', '14', '140', '144', '15', '150', '150.0', '152.0', '16', '160', '17', '175', '18', '180', '19', '19.4712', '192', '192.85', '192.85948', '1E-12', '1E-9', '1E3', '1e-09', '1e-10', '1e-12', '1e-2', '1e-3', '1e-4', '1e-5', '1e-6', '1e-9', '1e6', '1j', '2', '2.', '2.0', '2.13', '2.371512e-11', '2.5', '20', '20.0', '20.6', '200', '200.0', '2000', '20000', '200000', '20051', '20060', '20061', '201', '202', '204', '2048', '207', '21', '2147483647', '22', '22.5', '22050', '224', '225', '23', '24', '240', '242854337', '246', '25', '25.0', '250', '25000', '255', '255.', '255.0', '256', '257', '258', '259', '2595.0', '26', '260', '262', '264', '27', '27.12', '27.12825', '270', '27017', '28', '29', '3', '3.', '3.0', '30', '300', '301', '302', '306674912', '307', '31', '314', '32', '32.0', '32.93192', '320.0', '32768', '33', '34', '34736', '34737', '35', '35163', '36', '360', '3600', '365', '37', '38', '384', '39', '4', '4.', '4.0', '4.2', '4.74057', '40', '40.0', '40.11453', '400', '4000.0', '40000', '401', '403', '404', '4096', '41', '410', '42', '420', '4200000', '429', '43', '440.0', '4410', '443', '45', '48', '480', '493', '5', '5.0', '5.5', '50', '50.', '500', '5000', '50000', '502', '503', '504', '512', '52', '55', '550', '55296', '56', '57344', '59', '5e4', '6', '6.', '6.0', '6.5', '60', '60.0', '600', '6000000', '63', '6367', '6379', '64', '650', '65535.0', '65536', '67', '7', '7.', '70', '700.0', '720', '737.9', '75', '77', '8', '8.0', '80', '80.0', '800', '8080', '84', '85', '86400', '882', '8E3', '9', '90', '96', '98', '99', '99.73', '993', '999999.0']
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:13665
label:2, the number of unique tokens:610
The unique labels are:['.02', '.025', '.05', '.8', '.95', '0', '0.', '0.0', '0.000', '0.001', '0.009', '0.01', '0.012', '0.02', '0.025', '0.027', '0.03', '0.032', '0.0349', '0.04', '0.0471', '0.05', '0.075', '0.08', '0.082', '0.0975', '0.1', '0.1125', '0.115', '0.125', '0.15', '0.167', '0.2', '0.206', '0.22', '0.232', '0.25', '0.250', '0.298', '0.3', '0.33', '0.333', '0.35', '0.4', '0.404', '0.435', '0.45', '0.5', '0.500', '0.509', '0.598', '0.6', '0.627', '0.667', '0.685', '0.7', '0.700', '0.73', '0.75', '0.772', '0.794', '0.8', '0.855', '0.9', '0.912', '0.93', '0.948', '0.968', '0.983', '0.997', '0x0000', '0x0140', '0x0280', '0x03c0', '0x0440', '0x0500', '0x06c0', '0x0780', '0x0880', '0x09c0', '0x0F0F', '0x0a00', '0x0b40', '0x0cc0', '0x0d80', '0x0e40', '0x0f00', '0x1040', '0x1100', '0x12c0', '0x1380', '0x1400', '0x1540', '0x1680', '0x17c0', '0x18c0', '0x1980', '0x1a40', '0x1b00', '0x1c80', '0x1dc0', '0x1e00', '0x1f40', '0x2080', '0x21c0', '0x2200', '0x2340', '0x24c0', '0x2580', '0x2640', '0x2700', '0x2800', '0x2940', '0x2a80', '0x2bc0', '0x2c40', '0x2d00', '0x2ec0', '0x2f80', '0x3030303', '0x30c0', '0x3180', '0x3240', '0x3300', '0x3480', '0x35c0', '0x3600', '0x3740', '0x3840', '0x3900', '0x3ac0', '0x3b80', '0x3c00', '0x3d40', '0x3e80', '0x3fc0', '0x4040', '0x4100', '0x42c0', '0x4380', '0x4400', '0x4540', '0x4680', '0x47c0', '0x48c0', '0x4980', '0x4a40', '0x4b00', '0x4c80', '0x4dc0', '0x4e00', '0x4f40', '0x5000', '0x5140', '0x5280', '0x53c0', '0x5440', '0x5500', '0x56c0', '0x5780', '0x5880', '0x59c0', '0x5a00', '0x5b40', '0x5cc0', '0x5d80', '0x5e40', '0x5f00', '0x60c0', '0x6180', '0x6240', '0x6300', '0x6480', '0x65c0', '0x6600', '0x6740', '0x6840', '0x6900', '0x6ac0', '0x6b80', '0x6c00', '0x6d40', '0x6e80', '0x6fc0', '0x7080', '0x71c0', '0x7200', '0x7340', '0x74c0', '0x7580', '0x7640', '0x7700', '0x7800', '0x7940', '0x7F', '0x7F7F', '0x7a80', '0x7bc0', '0x7c40', '0x7d00', '0x7ec0', '0x7f80', '0x8081', '0x81c1', '0x8201', '0x8341', '0x84c1', '0x8581', '0x8641', '0x8701', '0x8801', '0x8941', '0x8a81', '0x8bc1', '0x8c41', '0x8d01', '0x8ec1', '0x8f81', '0x90c1', '0x9181', '0x9241', '0x9301', '0x9481', '0x95c1', '0x9601', '0x9741', '0x9841', '0x9901', '0x9ac1', '0x9b81', '0x9c01', '0x9d41', '0x9e81', '0x9fc1', '0xF000F', '0xFF', '0xFFFF', '0xa001', '0xa141', '0xa281', '0xa3c1', '0xa441', '0xa501', '0xa6c1', '0xa781', '0xa881', '0xa9c1', '0xaa01', '0xab41', '0xacc1', '0xad81', '0xae41', '0xaf01', '0xb041', '0xb101', '0xb2c1', '0xb381', '0xb401', '0xb541', '0xb681', '0xb7c1', '0xb8c1', '0xb981', '0xba41', '0xbb01', '0xbc81', '0xbdc1', '0xbe01', '0xbf41', '0xc0c1', '0xc181', '0xc241', '0xc301', '0xc481', '0xc5c1', '0xc601', '0xc741', '0xc841', '0xc901', '0xcac1', '0xcb81', '0xcc01', '0xcd41', '0xce81', '0xcfc1', '0xd081', '0xd1c1', '0xd201', '0xd341', '0xd4c1', '0xd581', '0xd641', '0xd701', '0xd801', '0xd941', '0xda81', '0xdbc1', '0xdc41', '0xdd01', '0xdec1', '0xdf81', '0xe041', '0xe101', '0xe2c1', '0xe381', '0xe401', '0xe541', '0xe681', '0xe7c1', '0xe8c1', '0xe981', '0xea41', '0xeb01', '0xec81', '0xedc1', '0xee01', '0xef41', '0xf001', '0xf141', '0xf281', '0xf3c1', '0xf441', '0xf501', '0xf6c1', '0xf781', '0xf881', '0xf9c1', '0xfa01', '0xfb41', '0xfcc1', '0xfd81', '0xfe41', '0xff', '0xff01', '0xffff', '1', '1.', '1.0', '1.01', '1.03', '1.033', '1.056', '1.064', '1.088', '1.107', '1.109', '1.121', '1.152', '1.154', '1.167', '1.17', '1.193', '1.208', '1.235', '1.241', '1.3', '1.302', '1.311', '1.32', '1.337', '1.342', '1.389', '1.4', '1.444', '1.446', '1.5', '1.55', '1.56', '1.584', '1.71', '1.86', '1.87', '1.e-9', '10', '10.0', '10.04', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '1024', '103.939', '10e10', '11', '11.11', '110', '116.779', '119.', '12', '12.30', '120', '123.68', '13', '13.86', '138', '14', '14.0', '14.29', '147', '149.597870e6', '15', '15.95', '150', '1500', '15000', '16', '163', '17', '177.', '178.', '18', '180', '184', '187.', '187.5', '188.', '19', '19.34', '194.', '1_000_000_000', '1e-2', '1e-3', '1e-5', '1e3', '1e6', '1e7', '2', '2.', '2.0', '2.10', '2.26', '2.33', '2.4', '2.49', '2.5', '2.64', '2.72', '2.87', '2.9296875', '20', '20.00', '20.08', '200', '2000', '2000.0', '201', '204', '2097151', '21', '21.17', '21000', '211', '212', '22', '22.42', '22.50', '22.51', '22000', '23', '24', '24.', '25.08', '25.10', '254.', '255', '255.', '256', '27', '27.47', '27.58', '27.69', '270', '27017', '28.0', '28.00', '280', '281', '3', '3.', '3.0', '3.11', '3.27', '3.34', '3.35', '3.74', '3.81', '30', '30.0', '30.00', '30.08', '30.11', '300', '304', '31', '32', '32.45', '32.50', '32.58', '34.92', '35.00', '35.04', '35000', '360', '3600', '3600.0', '365.', '37', '37.50', '37.67', '37.83', '37.88', '38', '4', '4.43', '4.44', '4.82', '40', '40.00', '40.14', '40.17', '400', '401', '403', '404', '406', '409', '412', '42', '42.0', '42.42', '42.65', '42.67', '422', '424.2', '45', '45.00', '45.07', '46', '465', '47.00', '47.17', '47.33', '47.50', '4729418', '49.75', '5', '5.0', '5.14', '5.20', '5.28', '5.37', '5.7', '50', '50.', '50.00', '50.08', '50.4', '500', '5000', '50000', '51', '512', '53', '5500', '55000', '58', '587', '59', '6', '6.07', '6.14', '6.29', '60', '60.', '60.0', '63', '64', '65', '7', '7.16', '7.38', '7.46', '7.5', '70', '70.6', '700', '7000', '75', '78', '79', '8', '8.0', '8.33', '80', '8000', '9', '9.01', '9.24', '9.8', '90', '900', '9600', '9800', '99.0', '9999', '999999', '99999999']
label:1, the number of unique tokens:5085
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:14163
label:1, the number of unique tokens:3813
label:2, the number of unique tokens:310
The unique labels are:['.2', '.4', '.5', '0', '0.', '0.0', '0.000001', '0.00001', '0.0001', '0.0003', '0.001', '0.005', '0.01', '0.02', '0.03', '0.032', '0.04', '0.05', '0.1', '0.10', '0.125', '0.2', '0.22', '0.25', '0.258', '0.3', '0.35', '0.352', '0.4', '0.486', '0.5', '0.50', '0.6', '0.65', '0.66', '0.7', '0.75', '0.8', '0.843', '0.9', '0.911', '0.94', '0.95', '0.99', '0.999', '0.99999', '0b001', '0b010', '0b100', '0o070', '0o7', '0o700', '0o755', '0x0', '0x00', '0x00000000', '0x00000001', '0x00000002', '0x00000003', '0x00000004', '0x00000005', '0x00000006', '0x0000000d', '0x00000010', '0x0000003f', '0x00000040', '0x00000080', '0x00000100', '0x000001ff', '0x00000201', '0x00000400', '0x00000800', '0x00000fff', '0x0000800000000000', '0x000306c3', '0x00c10000', '0x00f0b5ff', '0x01c0003f', '0x02', '0x03c0003f', '0x05100800', '0x0F', '0x0f', '0x1', '0x10', '0x1000', '0x1c004121', '0x1c004122', '0x1c004143', '0x1c03c163', '0x1f', '0x2', '0x3', '0x3f', '0x4', '0x49656e69', '0x60', '0x6c65746e', '0x7', '0x756e6547', '0x76035a01', '0x7ffafbff', '0x8', '0x80', '0x90', '0x99', '0xD5', '0xb', '0xbfebfbff', '0xd', '0xf0', '0xf8000000', '0xff', '0xffff', '0xffffffff', '0xffffffffffffffffffffffffffffffff00000000000000000000000000000000', '1', '1.', '1.0', '1.01', '1.1', '1.15', '1.2', '1.279', '1.4142', '1.42', '1.5', '1.5e-5', '1.8', '10', '10.0', '10.6', '100', '100.0', '1000', '10000', '10000.0', '100000', '100000.0', '1000000.0', '101', '1024', '109', '10e-7', '11', '111', '113', '12', '12.', '120', '127.5', '128', '12836', '13', '14', '144', '15', '15.', '150', '1500', '16', '17', '18', '180', '180.0', '19', '19.9', '195', '1e-10', '1e-2', '1e-3', '1e-5', '1e-6', '1e-7', '1e-8', '1e-9', '1e6', '1e9', '2', '2.', '2.0', '20', '20.0', '20.4', '200', '2000', '201', '2012', '2048', '21', '21.0', '21.3', '2147483647', '22', '22.2', '22.4', '22.7', '224', '23', '2396512', '24', '24.0', '24.4', '25', '250', '255', '255.', '255.0', '256', '27.2', '270', '273.15', '28', '282', '3', '3.92', '3.95', '30', '300', '30000', '31', '3119362', '31344016', '32', '32.', '35', '360.0', '3600', '368', '376', '39', '3e-4', '4', '4.0', '4.03', '4.29', '40', '40.0', '400', '4000', '403', '404', '4096', '41', '42', '42.0', '422', '430', '4326', '443', '48', '48.2', '5', '5.0', '5.25', '50', '500', '5000', '5000.0', '50000', '500000', '51', '512', '52', '52.5', '54', '55', '56', '58', '5e-4', '6', '6.0', '6.26', '60', '60.0', '600', '6006', '62', '63', '6379', '64', '650', '7', '7.0', '7.2', '7.8', '7.9', '784', '7e-4', '8', '8.0', '8.03', '8.2', '8.31', '8.4', '8.5', '80', '800', '8000', '80e6', '86400', '888', '9', '9.5', '9.8', '90', '92', '96', '9862', '999999']
Write tokens in the training set to files:
Write tokens in the validation set to files:
Write tokens in the testing set to files:

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 5000, 3: 5000, 1: 5000, 2: 5000})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in valid:
Counter({3: 540, 0: 540, 1: 540, 2: 540})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({3: 365, 0: 365, 1: 365, 2: 365})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
All-layer probing
Stops at epoch 10,Best training score:0.99825,validation score:0.9990740740740741,test score:0.9931506849315068
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Independent-layerwise probing
Stops at epoch 6,Best training score:0.99655,validation score:0.9314814814814815,test score:0.8876712328767123
Stops at epoch 7,Best training score:0.99745,validation score:0.9916666666666667,test score:0.9719178082191781
Stops at epoch 15,Best training score:0.99845,validation score:0.9916666666666667,test score:0.9904109589041096
Stops at epoch 56,Best training score:0.999,validation score:0.9458333333333333,test score:0.9691780821917808
Stops at epoch 34,Best training score:0.99855,validation score:0.9708333333333333,test score:0.9863013698630136
Stops at epoch 7,Best training score:0.99585,validation score:0.9787037037037037,test score:0.9773972602739726
Stops at epoch 29,Best training score:0.9988,validation score:0.9879629629629629,test score:0.9808219178082191
Stops at epoch 20,Best training score:0.99865,validation score:0.9958333333333333,test score:0.9863013698630136
Stops at epoch 35,Best training score:0.9985,validation score:0.9986111111111111,test score:0.9876712328767123
Stops at epoch 37,Best training score:0.99745,validation score:0.9949074074074075,test score:0.989041095890411
Stops at epoch 20,Best training score:0.99885,validation score:0.9930555555555556,test score:0.9856164383561644
Stops at epoch 15,Best training score:0.99835,validation score:0.9828703703703704,test score:0.9780821917808219
Stops at epoch 21,Best training score:0.9982,validation score:0.9949074074074075,test score:0.9780821917808219
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Incremental-layerwise probing
Stops at epoch 8,Best training score:0.99765,validation score:0.9523148148148148,test score:0.897945205479452
Stops at epoch 5,Best training score:0.99915,validation score:0.9907407407407407,test score:0.9609589041095891
Stops at epoch 5,Best training score:0.99915,validation score:0.9907407407407407,test score:0.9794520547945206
Stops at epoch 17,Best training score:0.9997,validation score:0.9925925925925926,test score:0.9863013698630136
Stops at epoch 16,Best training score:0.9996,validation score:0.9958333333333333,test score:0.9917808219178083
Stops at epoch 11,Best training score:0.99965,validation score:0.9953703703703703,test score:0.9904109589041096
Stops at epoch 15,Best training score:0.9997,validation score:0.9967592592592592,test score:0.9917808219178083
Stops at epoch 13,Best training score:0.9996,validation score:0.9990740740740741,test score:0.9938356164383562
Stops at epoch 15,Best training score:0.99955,validation score:0.9990740740740741,test score:0.9924657534246575
Stops at epoch 14,Best training score:0.99935,validation score:0.999537037037037,test score:0.9931506849315068
Stops at epoch 10,Best training score:0.9991,validation score:0.9990740740740741,test score:0.9938356164383562
Stops at epoch 11,Best training score:0.99845,validation score:0.9990740740740741,test score:0.9938356164383562
Stops at epoch 12,Best training score:0.9985,validation score:0.9990740740740741,test score:0.9931506849315068
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select minimum layers (LS+CC+LCA)
Stops at epoch 16,Best training score:0.99965,validation score:0.9944444444444445,test score:0.9842465753424657
Stops at epoch 21,Best training score:0.89755,validation score:0.912962962962963,test score:0.8602739726027397
Stops at epoch 21,Best training score:0.94175,validation score:0.9574074074074074,test score:0.9123287671232877
Stops at epoch 16,Best training score:0.95655,validation score:0.975462962962963,test score:0.9452054794520548
Stops at epoch 13,Best training score:0.95445,validation score:0.9703703703703703,test score:0.9445205479452055
Stops at epoch 11,Best training score:0.9743,validation score:0.975,test score:0.9541095890410959
Stops at epoch 10,Best training score:0.97835,validation score:0.9861111111111112,test score:0.9547945205479452
Stops at epoch 12,Best training score:0.99255,validation score:0.9912037037037037,test score:0.9650684931506849
Stops at epoch 10,Best training score:0.9958,validation score:0.9962962962962963,test score:0.9726027397260274
Stops at epoch 7,Best training score:0.99535,validation score:0.9958333333333333,test score:0.9863013698630136
Correlation matrix size (#neurons x #neurons): (2304, 2304)
Number of clusters detected: 1456
Stops at epoch 5,Best training score:0.9979,validation score:0.9879629629629629,test score:0.9753424657534246
Stops at epoch 19,Best training score:0.8956,validation score:0.8634259259259259,test score:0.7815068493150685
Stops at epoch 17,Best training score:0.9391,validation score:0.9481481481481482,test score:0.8972602739726028
Stops at epoch 17,Best training score:0.957,validation score:0.9675925925925926,test score:0.9027397260273973
Stops at epoch 23,Best training score:0.97325,validation score:0.9611111111111111,test score:0.9273972602739726
Stops at epoch 13,Best training score:0.97105,validation score:0.9736111111111111,test score:0.9541095890410959
Stops at epoch 12,Best training score:0.99,validation score:0.9837962962962963,test score:0.9664383561643836
Stops at epoch 10,Best training score:0.9996,validation score:0.9925925925925926,test score:0.9856164383561644
Stops at epoch 20,Best training score:0.86715,validation score:0.8583333333333333,test score:0.7965753424657535
Stops at epoch 27,Best training score:0.94665,validation score:0.9055555555555556,test score:0.873972602739726
Stops at epoch 18,Best training score:0.96495,validation score:0.9495370370370371,test score:0.8965753424657534
Stops at epoch 12,Best training score:0.97085,validation score:0.9629629629629629,test score:0.9321917808219178
Stops at epoch 18,Best training score:0.9788,validation score:0.975462962962963,test score:0.9445205479452055
Stops at epoch 11,Best training score:0.9896,validation score:0.9810185185185185,test score:0.9609589041095891
Stops at epoch 18,Best training score:0.9967,validation score:0.9847222222222223,test score:0.9780821917808219
Correlation matrix size (#neurons x #neurons): (2304, 2304)
Number of clusters detected: 1456
Stops at epoch 21,Best training score:0.99885,validation score:0.9879629629629629,test score:0.9684931506849315
Stops at epoch 10,Best training score:0.85265,validation score:0.7138888888888889,test score:0.6986301369863014
Stops at epoch 14,Best training score:0.9305,validation score:0.8828703703703704,test score:0.8287671232876712
Stops at epoch 11,Best training score:0.95365,validation score:0.9263888888888889,test score:0.8801369863013698
Stops at epoch 7,Best training score:0.95215,validation score:0.9550925925925926,test score:0.9260273972602739
Stops at epoch 23,Best training score:0.98035,validation score:0.9532407407407407,test score:0.9417808219178082
Stops at epoch 11,Best training score:0.97635,validation score:0.9773148148148149,test score:0.9554794520547946
Stops at epoch 12,Best training score:0.99595,validation score:0.9888888888888889,test score:0.9726027397260274
Stops at epoch 5,Best training score:0.99975,validation score:0.9939814814814815,test score:0.9849315068493151
Stops at epoch 14,Best training score:0.85885,validation score:0.8675925925925926,test score:0.797945205479452
Stops at epoch 15,Best training score:0.9394,validation score:0.9175925925925926,test score:0.9013698630136986
Stops at epoch 16,Best training score:0.95025,validation score:0.9467592592592593,test score:0.9034246575342466
Stops at epoch 15,Best training score:0.96615,validation score:0.9236111111111112,test score:0.8623287671232877
Stops at epoch 8,Best training score:0.96475,validation score:0.9606481481481481,test score:0.923972602739726
Stops at epoch 11,Best training score:0.98965,validation score:0.9703703703703703,test score:0.9636986301369863
Stops at epoch 9,Best training score:0.99105,validation score:0.9851851851851852,test score:0.9678082191780822
Stops at epoch 13,Best training score:0.9965,validation score:0.9875,test score:0.9801369863013699
Correlation matrix size (#neurons x #neurons): (3072, 3072)
Number of clusters detected: 1927
Stops at epoch 6,Best training score:0.9995,validation score:0.9884259259259259,test score:0.9897260273972602
Stops at epoch 13,Best training score:0.82365,validation score:0.8180555555555555,test score:0.763013698630137
Stops at epoch 16,Best training score:0.919,validation score:0.8439814814814814,test score:0.8041095890410959
Stops at epoch 15,Best training score:0.9544,validation score:0.850925925925926,test score:0.8184931506849316
Stops at epoch 11,Best training score:0.944,validation score:0.8731481481481481,test score:0.839041095890411
Stops at epoch 7,Best training score:0.93425,validation score:0.9069444444444444,test score:0.873972602739726
Stops at epoch 13,Best training score:0.98935,validation score:0.9527777777777777,test score:0.9410958904109589
Stops at epoch 6,Best training score:0.99435,validation score:0.975,test score:0.9547945205479452
Stops at epoch 7,Best training score:0.98245,validation score:0.9777777777777777,test score:0.976027397260274
Stops at epoch 10,Best training score:0.9979,validation score:0.9717592592592592,test score:0.9554794520547946
Stops at epoch 9,Best training score:0.99705,validation score:0.9851851851851852,test score:0.9684931506849315
Stops at epoch 6,Best training score:0.99875,validation score:0.9791666666666666,test score:0.9794520547945206
Stops at epoch 5,Best training score:0.9972,validation score:0.9837962962962963,test score:0.9664383561643836
Stops at epoch 7,Best training score:0.999,validation score:0.9898148148148148,test score:0.9924657534246575
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers (run_cc_all.py)
Stops at epoch 14,Best training score:0.99895,validation score:0.9990740740740741,test score:0.9938356164383562
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 8556
Stops at epoch 15,Best training score:0.99955,validation score:0.9990740740740741,test score:0.9938356164383562
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 7204
Stops at epoch 11,Best training score:0.99955,validation score:0.9935185185185185,test score:0.9842465753424657
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 5809
Stops at epoch 10,Best training score:0.99955,validation score:0.9935185185185185,test score:0.986986301369863
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 4439
Stops at epoch 16,Best training score:0.9997,validation score:0.9898148148148148,test score:0.9828767123287672
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 3244
Stops at epoch 18,Best training score:0.99965,validation score:0.9884259259259259,test score:0.9815068493150685
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 2277
Stops at epoch 5,Best training score:0.9991,validation score:0.9791666666666666,test score:0.9746575342465753
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 1463
Stops at epoch 22,Best training score:0.9994,validation score:0.9680555555555556,test score:0.9691780821917808
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 716
Stops at epoch 5,Best training score:0.99235,validation score:0.9254629629629629,test score:0.8897260273972603
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 107
Stops at epoch 41,Best training score:0.94825,validation score:0.8226851851851852,test score:0.8643835616438356
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers with finer percentage (run_max_features.py)
Stops at epoch 14,Best training score:0.99915,validation score:0.999537037037037,test score:0.9931506849315068
Stops at epoch 19,Best training score:0.8922,validation score:0.9231481481481482,test score:0.8890410958904109
Stops at epoch 16,Best training score:0.96295,validation score:0.9657407407407408,test score:0.9472602739726027
Stops at epoch 15,Best training score:0.98225,validation score:0.9912037037037037,test score:0.9650684931506849
Stops at epoch 10,Best training score:0.98455,validation score:0.9939814814814815,test score:0.9643835616438357
Stops at epoch 15,Best training score:0.9933,validation score:0.9962962962962963,test score:0.986986301369863
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Stops at epoch 12,Best training score:0.99835,validation score:0.9990740740740741,test score:0.9931506849315068
Stops at epoch 25,Best training score:0.831,validation score:0.8597222222222223,test score:0.8315068493150685
Stops at epoch 9,Best training score:0.902,validation score:0.8726851851851852,test score:0.8856164383561644
Stops at epoch 7,Best training score:0.90315,validation score:0.8472222222222222,test score:0.7760273972602739
Stops at epoch 15,Best training score:0.935,validation score:0.875462962962963,test score:0.8801369863013698
Stops at epoch 9,Best training score:0.94595,validation score:0.8875,test score:0.8753424657534247
Stops at epoch 16,Best training score:0.9576,validation score:0.9300925925925926,test score:0.9054794520547945
Stops at epoch 8,Best training score:0.96285,validation score:0.9481481481481482,test score:0.9027397260273973
Stops at epoch 14,Best training score:0.97165,validation score:0.9560185185185185,test score:0.9410958904109589
Stops at epoch 21,Best training score:0.98325,validation score:0.9606481481481481,test score:0.9534246575342465
Stops at epoch 22,Best training score:0.98605,validation score:0.9745370370370371,test score:0.9513698630136986
Stops at epoch 18,Best training score:0.98545,validation score:0.9694444444444444,test score:0.9417808219178082
Stops at epoch 24,Best training score:0.98845,validation score:0.975462962962963,test score:0.952054794520548
Stops at epoch 21,Best training score:0.9909,validation score:0.9791666666666666,test score:0.9671232876712329
Stops at epoch 14,Best training score:0.9894,validation score:0.9773148148148149,test score:0.9650684931506849
Stops at epoch 24,Best training score:0.9924,validation score:0.9800925925925926,test score:0.9678082191780822
Stops at epoch 16,Best training score:0.99115,validation score:0.9833333333333333,test score:0.9780821917808219
Stops at epoch 19,Best training score:0.9932,validation score:0.9814814814814815,test score:0.9636986301369863
Stops at epoch 16,Best training score:0.9931,validation score:0.9842592592592593,test score:0.9732876712328767
Stops at epoch 16,Best training score:0.99305,validation score:0.9842592592592593,test score:0.9787671232876712
Stops at epoch 13,Best training score:0.9932,validation score:0.9842592592592593,test score:0.9753424657534246
Stops at epoch 19,Best training score:0.9943,validation score:0.9810185185185185,test score:0.9808219178082191
Stops at epoch 19,Best training score:0.9941,validation score:0.9847222222222223,test score:0.9815068493150685
Stops at epoch 21,Best training score:0.99515,validation score:0.9819444444444444,test score:0.9691780821917808
Stops at epoch 15,Best training score:0.99425,validation score:0.9842592592592593,test score:0.9691780821917808
Stops at epoch 21,Best training score:0.9958,validation score:0.9944444444444445,test score:0.9815068493150685
Stops at epoch 14,Best training score:0.9948,validation score:0.9847222222222223,test score:0.9808219178082191
Stops at epoch 18,Best training score:0.99545,validation score:0.9907407407407407,test score:0.976027397260274
Stops at epoch 20,Best training score:0.9958,validation score:0.987037037037037,test score:0.9746575342465753
Stops at epoch 12,Best training score:0.995,validation score:0.987037037037037,test score:0.9780821917808219
Stops at epoch 18,Best training score:0.9959,validation score:0.9898148148148148,test score:0.9712328767123287
Stops at epoch 16,Best training score:0.9961,validation score:0.9916666666666667,test score:0.9863013698630136
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

pretrained_CodeBERT top neurons
array([3460, 8198, 3590,  776, 7559, 5392, 3856, 7696, 3088, 6037, 1022,
       1047, 1560, 1305, 9626, 4251,  412,   29, 7962,  538, 1440, 5025,
       5280, 3744, 5630, 6695, 3881,  682, 3113, 3246, 6714, 6202, 1597,
       8509, 3133, 5437, 9277, 4287,  835, 4669,  709, 4422, 3525, 1600,
       1865,  586, 6475, 7243, 1869, 2765, 8656, 2002, 2644,  213, 4571,
       9947, 9179, 8411, 2273, 1891, 9833, 2284,  367, 3991,  629, 3317,
       5621, 4088, 4862])
pretrained_CodeBERT top neurons per class
{'NAME': array([3133, 5437, 9277, 4422,  682, 8198, 8509,  776, 1597, 1305,  412,
        367, 4251, 1869, 3590, 2284]), 'STRING': array([5392, 4287, 3856, 5025, 7696, 6475, 3246, 2765,  586, 4088, 2273,
       2644, 2002, 6037, 6714, 7559, 8656, 9626, 7243, 3088]), 'NUMBER': array([4862, 3881, 3113, 1560, 1047,  629, 3317, 5621, 1440, 3460,  213,
       6202,   29, 5280, 1022,  709,  835, 5630, 3744]), 'KEYWORD': array([4571, 5437, 3525, 4669, 1891, 1600, 6695, 9947, 9179, 7962, 3133,
        538, 9833, 1865, 8411, 3991])}
pretrained_CodeBERT top words
Top words for pretrained_CodeBERT neuron indx 3460 [('now', 3.0943931341171265), ('fcntl', 2.9681901931762695), ('dry_run', 2.6510086059570312), ('rmtree', 2.5700230598449707), ('map', 2.548785090446472)]
Top words for pretrained_CodeBERT neuron indx 8198 [('pass', 3.4883068799972534), ('list', 3.3158184630530223), ('extend', 3.2656776905059814), ('filter', 3.204075574874878), ('response', 2.92800509929657)]
Top words for pretrained_CodeBERT neuron indx 3590 [('list', 3.3356263637542725), ('response', 3.274601035647922), ('headers', 3.1468948017467153), ('filter', 3.1319382190704346), ('dict', 2.9332942962646484)]
Top words for pretrained_CodeBERT neuron indx 776 [('XML', 3.277268886566162), ('257', 3.2294816970825195), ('force', 3.1522319316864014), ('json', 3.0344435274600983), ('xml', 2.8723829984664917)]
Top words for pretrained_CodeBERT neuron indx 7559 [('copy', 3.4589122772216796), ('clone', 3.37388014793396), ('ord', 3.1152481115781345), ('all', 3.032622814178467), ('any', 2.9832139015197754)]
Top words for pretrained_CodeBERT neuron indx 5392 [('println', 3.315438747406006), ('tolist', 3.2497739791870117), ('\\', 3.1547761857509613), ('"\\', 3.1350717743237815), ('crop', 2.8340753316879272)]
Top words for pretrained_CodeBERT neuron indx 3856 [('tolist', 3.1722676753997803), ('crop', 3.004173994064331), ('\\', 2.8784602656960487), ('"\\', 2.8762118220329285), ('numpy', 2.7750076055526733)]
Top words for pretrained_CodeBERT neuron indx 7696 [('println', 3.2158737182617188), ('tolist', 3.0802940130233765), ('unpack', 2.7975754737854004), ('sleep', 2.738288164138794), ('debug', 2.6788463592529297)]
Top words for pretrained_CodeBERT neuron indx 3088 [('crop', 3.3543968200683594), ('round', 3.0653717041015627), ('\\', 2.7949798752864203), ('tolist', 2.7917438745498657), ('"\\', 2.662283703684807)]
Top words for pretrained_CodeBERT neuron indx 6037 [('channels', 3.026357889175415), ('find', 2.995471954345703), ("'cpu'", 2.973823070526123), ('parts', 2.8373117446899414), ('get', 2.752759583971717)]
Top words for pretrained_CodeBERT neuron indx 1022 [('24', 3.381978392601013), ('200', 3.1247203747431436), ('line', 2.8584787845611572), ('Contrast', 2.841014862060547), ('23', 2.8208537101745605)]
Top words for pretrained_CodeBERT neuron indx 1047 [('torch', 4.563989375088666), ('800', 3.7361927032470703), ('307', 3.633262872695923), ('259', 3.5397918224334717), ('224', 3.3862996101379395)]
Top words for pretrained_CodeBERT neuron indx 1560 [('strip', 3.547686139742533), ('keywords', 3.4900834560394287), ('720', 3.4179022312164307), ('len', 3.3527201414108276), ('mul', 3.345616340637207)]
Top words for pretrained_CodeBERT neuron indx 1305 [('update', 3.8637659549713135), ('logger', 3.715488910675049), ('gui', 3.5361034870147705), ('skill', 3.3313452005386353), ('patch', 3.254590630531311)]
Top words for pretrained_CodeBERT neuron indx 9626 [('parse', 2.5011224150657654), ("'%d'", 2.4470155239105225), ('request', 2.303913338617845), ('self', 2.2986222917788495), ('Exception', 2.23984956741333)]
Top words for pretrained_CodeBERT neuron indx 4251 [('replace', 3.788183033466339), ('index', 3.3195498500551497), ('suffix', 3.1254186630249023), ('query', 2.9893770868128), ('seek', 2.9472341537475586)]
Top words for pretrained_CodeBERT neuron indx 412 [('upper', 3.0082974433898926), ('requests', 2.949887752532959), ('print', 2.8287447799335825), ('264', 2.7231357097625732), ('hours', 2.6891340017318726)]
Top words for pretrained_CodeBERT neuron indx 29 [('x', 4.2954923659563065), ('copy', 4.286635208129883), ('total', 4.039706707000732), ('202', 3.893605351448059), ('420', 3.8046910762786865)]
Top words for pretrained_CodeBERT neuron indx 7962 [('map', 3.684044122695923), ('160', 3.363377571105957), ('384', 3.235489845275879), ('420', 3.2343900203704834), ('13', 3.1578454971313477)]
Top words for pretrained_CodeBERT neuron indx 538 [('420', 4.059515953063965), ('raise', 3.9401058111435328), ('255', 3.7324066502707347), ('struct', 3.5066120624542236), ('301', 3.3256874084472656)]
Top words for pretrained_CodeBERT neuron indx 1440 [('exceptions', 2.958305835723877), ('words', 2.754561424255371), ('400', 2.670022487640381), ('id', 2.6328779458999634), ('"\\', 2.5930813004573188)]
Top words for pretrained_CodeBERT neuron indx 5025 [('StringIO', 2.952061176300049), ('77', 2.9117995500564575), ('160', 2.891662120819092), ('isinstance', 2.7903970380624137), ('io', 2.7229795455932617)]
Top words for pretrained_CodeBERT neuron indx 5280 [('reshape', 2.803135395050049), ('unsqueeze', 2.6500085989634194), ('Concatenate', 2.614668130874634), ('rstrip', 2.5634043216705322), ('narrow', 2.5392322540283203)]
Top words for pretrained_CodeBERT neuron indx 3744 [('stdout', 2.625141143798828), ('400', 2.5956998666127524), ('path', 2.5641433644023808), ('reshape', 2.5501039028167725), ('id', 2.5319312512874603)]
Top words for pretrained_CodeBERT neuron indx 5630 [('264', 2.9785120487213135), ('line', 2.7332412004470825), ('issubclass', 2.5375680923461914), ('re', 2.4100831896066666), ('await', 2.375256833102968)]
Top words for pretrained_CodeBERT neuron indx 6695 [("'Z5H5wqd06ExFVPNfJiqhKvAFjkf+cTVodOUirucHGcEVAMO1LfvgqWUkZ/X1ITDZbI0w+SMwVkEQZlkeThbVS/54M22StNDUtfz4Ua20xNDpIPwcWIACAmZ38XxbbTEFJI5WwqrbilNcfzqiGrIPfdO5rl+/xUjHFUdcJdUY/QzBxXsceytVYfEiR9MzOCN2m4C0XnpThUavAu159KrLj8AkuzN0JF87iXv+zOEeZRgEuwmsAnJrRUwkJ4yWokEPnSVdjF0D6f6CscfyvRe9nsWShq7/zRTa41meweh+n006zvf58MbzRdXPB22RI4AN0ksWW7hSC8/QLAKQE+lvaw=='", 7.484455108642578), ("'u'", 5.878924369812012), ("'v'", 5.354887247085571), ('"pm_lat"', 5.316206455230713), ("r'm\\\\.miaopai\\\\.com/show/channel/([^.]+)'", 5.063684940338135)]
Top words for pretrained_CodeBERT neuron indx 3881 [('15', 3.230339378118515), ('exit', 3.229806423187256), ('140', 3.1260602474212646), ('262', 3.080806016921997), ('14', 2.86262880052839)]
Top words for pretrained_CodeBERT neuron indx 682 [('410', 4.568387508392334), ('image', 4.284512042999268), ('307', 4.134746551513672), ('communicate', 3.512517213821411), ('children', 3.3617438077926636)]
Top words for pretrained_CodeBERT neuron indx 3113 [('15', 3.360079824924469), ('140', 3.338975667953491), ('12', 3.2269400778938744), ('exit', 3.1235251426696777), ('14', 3.0934483210245767)]
Top words for pretrained_CodeBERT neuron indx 3246 [('pop', 4.147747993469238), ('Iterable', 3.517688751220703), ('join', 3.501877632406023), ('remove', 3.3836899995803833), ('get', 2.9391151666641235)]
Top words for pretrained_CodeBERT neuron indx 6714 [('pow', 3.728407621383667), ('ord', 3.713859283007108), ('prepare', 3.566307783126831), ('map', 3.5596953630447388), ('extend', 3.4397709369659424)]
Top words for pretrained_CodeBERT neuron indx 6202 [('get', 3.763804405588995), ('clone', 3.35677433013916), ('rpartition', 3.26079785823822), ('days', 3.21311092376709), ('class', 3.1409958600997925)]
Top words for pretrained_CodeBERT neuron indx 1597 [('img', 3.3580035778192374), ('11', 3.3171369433403015), ('gamma', 3.2287094593048096), ('13', 3.1853933334350586), ('xml', 3.1072118282318115)]
Top words for pretrained_CodeBERT neuron indx 8509 [('engine', 3.1609983444213867), ('img', 2.976643076309791), ('ET', 2.95035719871521), ('c', 2.852378249168396), ('npimg', 2.849902561732701)]
Top words for pretrained_CodeBERT neuron indx 3133 [('ET', 3.3218932151794434), ('img', 3.01735242330111), ('gui', 2.9747767448425293), ('country', 2.971332550048828), ('993', 2.9264633655548096)]
Top words for pretrained_CodeBERT neuron indx 5437 [('ET', 3.4345507621765137), ('K', 2.923094908396403), ('country', 2.90456223487854), ('img', 2.902527744953449), ('dist', 2.842508316040039)]
Top words for pretrained_CodeBERT neuron indx 9277 [('ET', 3.672163724899292), ('engine', 3.6175789833068848), ('img', 3.195620821072505), ('tar', 3.0937963724136353), ('K', 3.089770555496216)]
Top words for pretrained_CodeBERT neuron indx 4287 [('close', 3.918696641921997), ('save', 3.725522518157959), ('32768', 3.0862905979156494), ('moves', 3.049805164337158), ('29', 3.0177329778671265)]
Top words for pretrained_CodeBERT neuron indx 835 [('os', 3.1013111451576494), ('dict', 2.9209256172180176), ('class', 2.7153183221817017), ('type', 2.7128429412841797), ('exp', 2.6076245307922363)]
Top words for pretrained_CodeBERT neuron indx 4669 [('ET', 3.259291410446167), ('img', 3.006446234996502), ('K', 2.925022840499878), ('dist', 2.828347325325012), ('country', 2.780771017074585)]
Top words for pretrained_CodeBERT neuron indx 709 [('language', 4.025045224598476), ('to', 3.483128786087036), ('720', 3.429490089416504), ('225', 3.266007423400879), ('257', 3.1037919521331787)]
Top words for pretrained_CodeBERT neuron indx 4422 [('now', 3.2337783575057983), ('pad', 2.8111162185668945), ('datetime', 2.7134639024734497), ('0.01683697', 2.6218628883361816), ('round', 2.4714877128601076)]
Top words for pretrained_CodeBERT neuron indx 3525 [('246', 3.9502923488616943), ('ET', 3.3195559978485107), ('uint8', 3.198930114507675), ('301', 2.9306654930114746), ('and', 2.886934968558225)]
Top words for pretrained_CodeBERT neuron indx 1600 [('gui', 3.46683406829834), ('print', 3.081665580922907), ('suggestions', 2.8438453674316406), ('git', 2.83172345161438), ('cat', 2.814457058906555)]
Top words for pretrained_CodeBERT neuron indx 1865 [('type', 3.8400204181671143), ('sleep', 2.6221230030059814), ('request', 2.6042076164122783), ('port', 2.527007579803467), ('default', 2.523045063018799)]
Top words for pretrained_CodeBERT neuron indx 586 [('symbols', 3.884516716003418), ('git', 3.5893959999084473), ("'['", 3.2181719541549683), ('131', 3.2096776962280273), ('exceptions', 3.160353660583496)]
Top words for pretrained_CodeBERT neuron indx 6475 [('Optional', 2.838045597076416), ('unicode', 2.761742353439331), ('Session', 2.728116989135742), ('append', 2.7058066565815997), ("'aac_adtstoasc'", 2.6662890911102295)]
Top words for pretrained_CodeBERT neuron indx 7243 [('append', 2.7309565253374055), ('Optional', 2.703791856765747), ("'aac_adtstoasc'", 2.4854531288146973), ('array', 2.478004902601242), ('unicode', 2.417726516723633)]
Top words for pretrained_CodeBERT neuron indx 1869 [('6', 3.937546403319747), ('307', 3.714154005050659), ('div', 3.238654375076294), ('ret', 3.206069367272513), ('502', 3.022842228412628)]
Top words for pretrained_CodeBERT neuron indx 2765 [('locales', 3.347806692123413), ('method', 3.19431608915329), ("'/Cell'", 2.8077096939086914), ('random', 2.776233966151873), ('246', 2.7359089851379395)]
Top words for pretrained_CodeBERT neuron indx 8656 [('extend', 4.3297858238220215), ('array', 3.2952177822589874), ('print', 3.221111618659713), ('exceptions', 3.1137149333953857), ('StringIO', 3.0804290771484375)]
Top words for pretrained_CodeBERT neuron indx 2002 [("'filename'", 2.7340047359466553), ('"type"', 2.711078405380249), ("'card'", 2.674940347671509), ("'access'", 2.6189329624176025), ("'line'", 2.5976368188858032)]
Top words for pretrained_CodeBERT neuron indx 2644 [('240', 3.5084145863850913), ('moves', 3.4740381240844727), ('path', 3.3879516422748566), ('480', 3.3340489864349365), ('100', 3.325679905274335)]
Top words for pretrained_CodeBERT neuron indx 213 [('numbers', 3.081843852996826), ('stats', 3.0771865844726562), ('Number', 2.8055968284606934), ('12', 2.5517284870147705), ('mode', 2.408357434802585)]
Top words for pretrained_CodeBERT neuron indx 4571 [('seconds', 3.960292100906372), ('terminated', 3.0637383460998535), ('720', 2.9415395259857178), ('suffix', 2.877281069755554), ('numbers', 2.8715697129567466)]
Top words for pretrained_CodeBERT neuron indx 9947 [('seconds', 3.4319623708724976), ('exceptions', 2.9504282474517822), ('training_file', 2.8422930240631104), ('moves', 2.8363654613494873), ('suffix', 2.6566227674484253)]
Top words for pretrained_CodeBERT neuron indx 9179 [('seconds', 3.3696467876434326), ('moves', 3.1359989643096924), ('720', 2.981666326522827), ('1024', 2.6663037538528442), ('404', 2.6118500232696533)]
Top words for pretrained_CodeBERT neuron indx 8411 [('seconds', 3.1231884956359863), ('moves', 2.8889667987823486), ('720', 2.8521409034729004), ('67', 2.679006576538086), ('channels', 2.5979855060577393)]
Top words for pretrained_CodeBERT neuron indx 2273 [('reshape', 3.0609817504882812), ('squeeze', 2.9490387439727783), ('Reshape', 2.9083199501037598), ('prepare', 2.807819128036499), ('moves', 2.7844691276550293)]
Top words for pretrained_CodeBERT neuron indx 1891 [('graph', 4.3599255084991455), ('barrier', 3.930087089538574), ('550', 3.899322271347046), ('41', 3.8921356201171875), ('grid', 3.770132827758789)]
Top words for pretrained_CodeBERT neuron indx 9833 [('attempt', 3.34818696975708), ('prehash', 3.0522343516349792), ('session', 2.8524423042933145), ('makedirs', 2.712205410003662), ('Multiply', 2.6988096237182617)]
Top words for pretrained_CodeBERT neuron indx 2284 [('225', 4.83436918258667), ('Session', 4.177473545074463), ('410', 3.878539482752482), ('45', 3.6084837118784585), ('encoding', 3.492376724878947)]
Top words for pretrained_CodeBERT neuron indx 367 [('RED', 5.797682762145996), ('quote', 5.659419536590576), ('crop', 4.203132778406143), ('"[\\', 3.906911849975586), ('cat', 3.6699225902557373)]
Top words for pretrained_CodeBERT neuron indx 3991 [('tile', 3.6655361652374268), ('filter', 3.587414026260376), ('Conv2d', 3.4236161708831787), ('YELLOW', 3.4233245849609375), ('escape', 3.3850167989730835)]
Top words for pretrained_CodeBERT neuron indx 629 [('results', 3.1496201237042745), ('uniform', 2.5564809170636265), ('hit', 2.5535019874572753), ('engine', 2.5203475952148438), ('Response', 2.469983386993408)]
Top words for pretrained_CodeBERT neuron indx 3317 [('512', 4.000410364895332), ('259', 3.9223246574401855), ('code', 3.4342970848083496), ('int', 3.226285934448242), ('2048', 3.1477280902862548)]
Top words for pretrained_CodeBERT neuron indx 5621 [('512', 3.9793716640007206), ('2048', 3.631048002243042), ('code', 3.359583258628845), ('int', 3.19586219266057), ('str', 3.1356984078884125)]
Top words for pretrained_CodeBERT neuron indx 4088 [('zeros', 2.9617061614990234), ('url_for', 2.955246686935425), ("'corrections'", 2.923766613006592), ("'ip'", 2.8243002891540527), ('0x1', 2.799516439437866)]
Top words for pretrained_CodeBERT neuron indx 4862 [('264', 2.8690757751464844), ('23', 2.6914565563201904), ('await', 2.4910880244440503), ('requests', 2.4523978233337402), ('issubclass', 2.446669816970825)]
Creating control dataset for pretrained_CodeBERT POS tagging task
Stops at epoch 5,Best training score:0.7676,validation score:0.35462962962962963,test score:0.18835616438356165

pretrained_CodeBERT_control_task Selectivity (Diff. between true task and probing task performance):  0.8047945205479452
~~~~~~~~~~~~~~~~~~~~~~~Summary~~~~~~~~~~~~~~~~~~~~~~~
Experimental results for pretrained_CodeBERT:
Baseline score (probing using all neurons, 768 each, of all layers 13) :{'__OVERALL__': 0.9931506849315068, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 1.0}

The accuracy when only using the intercept:{'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}

Independent layerwise probing:
Layer 0:{'__OVERALL__': 0.8876712328767123, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.5616438356164384}
Layer 1:{'__OVERALL__': 0.9719178082191781, 'NAME': 0.9863013698630136, 'STRING': 0.9972602739726028, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9178082191780822}
Layer 2:{'__OVERALL__': 0.9904109589041096, 'NAME': 1.0, 'STRING': 0.9972602739726028, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9808219178082191}
Layer 3:{'__OVERALL__': 0.9691780821917808, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 0.9534246575342465, 'KEYWORD': 0.9260273972602739}
Layer 4:{'__OVERALL__': 0.9863013698630136, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9643835616438357}
Layer 5:{'__OVERALL__': 0.9773972602739726, 'NAME': 0.9945205479452055, 'STRING': 0.9972602739726028, 'NUMBER': 0.9671232876712329, 'KEYWORD': 0.9506849315068493}
Layer 6:{'__OVERALL__': 0.9808219178082191, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.958904109589041}
Layer 7:{'__OVERALL__': 0.9863013698630136, 'NAME': 0.9780821917808219, 'STRING': 1.0, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9808219178082191}
Layer 8:{'__OVERALL__': 0.9876712328767123, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9835616438356164}
Layer 9:{'__OVERALL__': 0.989041095890411, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9808219178082191, 'KEYWORD': 0.9917808219178083}
Layer 10:{'__OVERALL__': 0.9856164383561644, 'NAME': 0.9835616438356164, 'STRING': 0.9972602739726028, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9753424657534246}
Layer 11:{'__OVERALL__': 0.9780821917808219, 'NAME': 0.9835616438356164, 'STRING': 0.9945205479452055, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9452054794520548}
Layer 12:{'__OVERALL__': 0.9780821917808219, 'NAME': 0.9835616438356164, 'STRING': 0.9945205479452055, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9452054794520548}

'Incremental-layerwise probing:
Layer [0]:{'__OVERALL__': 0.897945205479452, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.6054794520547945}
Layer [0, 1]:{'__OVERALL__': 0.9609589041095891, 'NAME': 0.9945205479452055, 'STRING': 0.9972602739726028, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.863013698630137}
Layer [0, 1, 2]:{'__OVERALL__': 0.9794520547945206, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9808219178082191, 'KEYWORD': 0.936986301369863}
Layer [0, 1, 2, 3]:{'__OVERALL__': 0.9863013698630136, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9534246575342465}
Layer [0, 1, 2, 3, 4]:{'__OVERALL__': 0.9917808219178083, 'NAME': 0.9917808219178083, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9835616438356164}
Layer [0, 1, 2, 3, 4, 5]:{'__OVERALL__': 0.9904109589041096, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.989041095890411}
Layer [0, 1, 2, 3, 4, 5, 6]:{'__OVERALL__': 0.9917808219178083, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.989041095890411}
Layer [0, 1, 2, 3, 4, 5, 6, 7]:{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.9972602739726028}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8]:{'__OVERALL__': 0.9924657534246575, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9945205479452055}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:{'__OVERALL__': 0.9931506849315068, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9972602739726028}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 1.0}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 1.0}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]:{'__OVERALL__': 0.9931506849315068, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 1.0}

select minimum layers:(LS+CC+LCA)
Layerwise (LS):To lose 0.03*100% accuracy based on all layers, keep the layers from 0 to 2
The number of neurons to keep is 2304
The accuracy is:{'__OVERALL__': 0.9794520547945206, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9808219178082191, 'KEYWORD': 0.936986301369863}
Percentage reduction (neurons):0.7692307692307692

Clustering based on the layers above: 0 to 2:
When no clustering:
the probing result is {'__OVERALL__': 0.9856164383561644, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9643835616438357}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 199
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9780821917808219, 'NAME': 1.0, 'STRING': 0.9945205479452055, 'NUMBER': 0.9698630136986301, 'KEYWORD': 0.947945205479452}

Clustering threshold:0.3
The number of independent neurons:1456
The number of clusters:2304
The probing result (CC score) is :{'__OVERALL__': 0.9684931506849315, 'NAME': 1.0, 'STRING': 0.9972602739726028, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.8931506849315068}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 199
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9726027397260274, 'NAME': 1.0, 'STRING': 0.9945205479452055, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9095890410958904}

Layerwise (LS):To lose 0.02*100% accuracy based on all layers, keep the layers from 0 to 2
The number of neurons to keep is 2304
The accuracy is:{'__OVERALL__': 0.9794520547945206, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9808219178082191, 'KEYWORD': 0.936986301369863}
Percentage reduction (neurons):0.7692307692307692

Clustering based on the layers above: 0 to 2:
When no clustering:
the probing result is {'__OVERALL__': 0.9856164383561644, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9643835616438357}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 199
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9780821917808219, 'NAME': 1.0, 'STRING': 0.9945205479452055, 'NUMBER': 0.9698630136986301, 'KEYWORD': 0.947945205479452}

Clustering threshold:0.3
The number of independent neurons:1456
The number of clusters:2304
The probing result (CC score) is :{'__OVERALL__': 0.9684931506849315, 'NAME': 1.0, 'STRING': 0.9972602739726028, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.8931506849315068}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 199
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9726027397260274, 'NAME': 1.0, 'STRING': 0.9945205479452055, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9095890410958904}

Layerwise (LS):To lose 0.01*100% accuracy based on all layers, keep the layers from 0 to 3
The number of neurons to keep is 3072
The accuracy is:{'__OVERALL__': 0.9863013698630136, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9534246575342465}
Percentage reduction (neurons):0.6923076923076923

Clustering based on the layers above: 0 to 3:
When no clustering:
the probing result is {'__OVERALL__': 0.9849315068493151, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9506849315068493}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 299
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9801369863013699, 'NAME': 1.0, 'STRING': 0.9972602739726028, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9397260273972603}

Clustering threshold:0.3
The number of independent neurons:1927
The number of clusters:3072
The probing result (CC score) is :{'__OVERALL__': 0.9897260273972602, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9753424657534246}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 798
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9924657534246575, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9835616438356164}

The result of Layerwise (LS):
Keep the layer from 0 to 3
The best layer delta:0.01
The best number of neurons:3072
The best accuracy:0.9863013698630136
The best percentage reduction: 0.6923076923076923

The result of LS+CC+LCA
Keep the layer from 0 to 3
The best performance delta: 0.01,0.01
The best clustering threshold:0.3
The best number of neurons:798
The best accuracy: 0.9924657534246575
The best neuron percentage reduction: 0.9200721153846154

probe independent neurons based on all layers with clustering (run_cc_all.py)
When no clustering:
The probing result (CC score) is :{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 1.0}
Clustering threshold:0.1
The number of independent neurons:8556
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 1.0}
Clustering threshold:0.2
The number of independent neurons:7204
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9842465753424657, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9616438356164384}
Clustering threshold:0.3
The number of independent neurons:5809
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.986986301369863, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9753424657534246}
Clustering threshold:0.4
The number of independent neurons:4439
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9828767123287672, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.958904109589041}
Clustering threshold:0.5
The number of independent neurons:3244
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9815068493150685, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9534246575342465}
Clustering threshold:0.6
The number of independent neurons:2277
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9746575342465753, 'NAME': 0.989041095890411, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.9205479452054794}
Clustering threshold:0.7
The number of independent neurons:1463
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9691780821917808, 'NAME': 0.9808219178082191, 'STRING': 0.9972602739726028, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9068493150684932}
Clustering threshold:0.8
The number of independent neurons:716
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.8897260273972603, 'NAME': 0.9835616438356164, 'STRING': 0.9917808219178083, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.589041095890411}
Clustering threshold:0.9
The number of independent neurons:107
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.8643835616438356, 'NAME': 0.8904109589041096, 'STRING': 0.9671232876712329, 'NUMBER': 0.8684931506849315, 'KEYWORD': 0.7315068493150685}
The result of CC:
The best clustering threshold is :-1
The best number of neurons:9984
The best accuracy is: 0.9938356164383562
Percentage reduction (neurons):0.0

probe independent neurons based on all layers without clustering (run_max_features.py)
The result of LCA:
Based on all layers: from 0 to 12, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is 89
The performance is {'model_name': 'pretrained_CodeBERT', 'best_l1': 0, 'best_l2': 0.01, 'scores': {'__OVERALL__': 0.986986301369863, 'NAME': 0.9945205479452055, 'STRING': 0.9945205479452055, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9726027397260274}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 0.0, 'STRING': 0.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.9910857371794872

Probeless:
The result of probeless:
Based on all layers, from 0 to 12, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is :609
The performance is :{'model_name': 'pretrained_CodeBERT', 'best_l1': 0.001, 'best_l2': 0, 'scores': {'__OVERALL__': 0.9863013698630136, 'NAME': 0.9972602739726028, 'STRING': 0.9945205479452055, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9671232876712329}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.9390024038461539
----------------------------------------------------------------
