"def is_edge_consistent(graph, u, v):\n    \"\"\"Check if all edges between two nodes have the same relation.\n\n    :param pybel.BELGraph graph: A BEL Graph\n    :param tuple u: The source BEL node\n    :param tuple v: The target BEL node\n    :return: If all edges from the source to target node have the same relation\n    :rtype: bool\n    \"\"\"\n    if not graph.has_edge(u, v):\n        raise ValueError('{} does not contain an edge ({}, {})'.format(graph, u, v))\n\n    return 0 == len(set(d[RELATION] for d in graph.edge[u][v].values()))"
"def split_multiline(value):\n    \"\"\"Split a multiline string into a list, excluding blank lines.\"\"\"\n    return [element for element in (line.strip() for line in value.split('\\n'))\n            if element]"
"def wait_until_exit(self):\n        \"\"\" Wait until all the threads are finished.\n\n        \"\"\"\n        [t.join() for t in self.threads]\n\n        self.threads = list()"
"def load_preprocess_images(image_paths: List[str], image_size: tuple) -> List[np.ndarray]:\n    \"\"\"\n    Load and pre-process the images specified with absolute paths.\n\n    :param image_paths: List of images specified with paths.\n    :param image_size: Tuple to resize the image to (Channels, Height, Width)\n    :return: A list of loaded images (numpy arrays).\n    \"\"\"\n    image_size = image_size[1:]  # we do not need the number of channels\n    images = []\n    for image_path in image_paths:\n        images.append(load_preprocess_image(image_path, image_size))\n    return images"
"def shape_list(l,shape,dtype):\n    \"\"\" Shape a list of lists into the appropriate shape and data type \"\"\"\n    return np.array(l, dtype=dtype).reshape(shape)"
"def to_dotfile(G: nx.DiGraph, filename: str):\n    \"\"\" Output a networkx graph to a DOT file. \"\"\"\n    A = to_agraph(G)\n    A.write(filename)"
"def write_color(string, name, style='normal', when='auto'):\n    \"\"\" Write the given colored string to standard out. \"\"\"\n    write(color(string, name, style, when))"
"def supports_py3(project_name):\n    \"\"\"Check with PyPI if a project supports Python 3.\"\"\"\n    log = logging.getLogger(\"ciu\")\n    log.info(\"Checking {} ...\".format(project_name))\n    request = requests.get(\"https://pypi.org/pypi/{}/json\".format(project_name))\n    if request.status_code >= 400:\n        log = logging.getLogger(\"ciu\")\n        log.warning(\"problem fetching {}, assuming ported ({})\".format(\n                        project_name, request.status_code))\n        return True\n    response = request.json()\n    return any(c.startswith(\"Programming Language :: Python :: 3\")\n               for c in response[\"info\"][\"classifiers\"])"
"def load(self, name):\n        \"\"\"Loads and returns foreign library.\"\"\"\n        name = ctypes.util.find_library(name)\n        return ctypes.cdll.LoadLibrary(name)"
"def truncate(value: Decimal, n_digits: int) -> Decimal:\n    \"\"\"Truncates a value to a number of decimals places\"\"\"\n    return Decimal(math.trunc(value * (10 ** n_digits))) / (10 ** n_digits)"
"def get_last_id(self, cur, table='reaction'):\n        \"\"\"\n        Get the id of the last written row in table\n\n        Parameters\n        ----------\n        cur: database connection().cursor() object\n        table: str\n            'reaction', 'publication', 'publication_system', 'reaction_system'\n\n        Returns: id\n        \"\"\"\n        cur.execute(\"SELECT seq FROM sqlite_sequence WHERE name='{0}'\"\n                    .format(table))\n        result = cur.fetchone()\n        if result is not None:\n            id = result[0]\n        else:\n            id = 0\n        return id"
"def inheritdoc(method):\n    \"\"\"Set __doc__ of *method* to __doc__ of *method* in its parent class.\n\n    Since this is used on :class:`.StringMixIn`, the \"parent class\" used is\n    ``str``. This function can be used as a decorator.\n    \"\"\"\n    method.__doc__ = getattr(str, method.__name__).__doc__\n    return method"
"def setDictDefaults (d, defaults):\n  \"\"\"Sets all defaults for the given dictionary to those contained in a\n  second defaults dictionary.  This convenience method calls:\n\n    d.setdefault(key, value)\n\n  for each key and value in the given defaults dictionary.\n  \"\"\"\n  for key, val in defaults.items():\n    d.setdefault(key, val)\n\n  return d"
"def _ratelimited_get(self, *args, **kwargs):\n        \"\"\"Perform get request, handling rate limiting.\"\"\"\n        with self._ratelimiter:\n            resp = self.session.get(*args, **kwargs)\n\n        # It's possible that Space-Track will return HTTP status 500 with a\n        # query rate limit violation. This can happen if a script is cancelled\n        # before it has finished sleeping to satisfy the rate limit and it is\n        # started again.\n        #\n        # Let's catch this specific instance and retry once if it happens.\n        if resp.status_code == 500:\n            # Let's only retry if the error page tells us it's a rate limit\n            # violation.\n            if 'violated your query rate limit' in resp.text:\n                # Mimic the RateLimiter callback behaviour.\n                until = time.time() + self._ratelimiter.period\n                t = threading.Thread(target=self._ratelimit_callback, args=(until,))\n                t.daemon = True\n                t.start()\n                time.sleep(self._ratelimiter.period)\n\n                # Now retry\n                with self._ratelimiter:\n                    resp = self.session.get(*args, **kwargs)\n\n        return resp"
"def test():\n    \"\"\"Run the unit tests.\"\"\"\n    import unittest\n    tests = unittest.TestLoader().discover('tests')\n    unittest.TextTestRunner(verbosity=2).run(tests)"
"def get_distance_matrix(x):\n    \"\"\"Get distance matrix given a matrix. Used in testing.\"\"\"\n    square = nd.sum(x ** 2.0, axis=1, keepdims=True)\n    distance_square = square + square.transpose() - (2.0 * nd.dot(x, x.transpose()))\n    return nd.sqrt(distance_square)"
"def _opt_call_from_base_type(self, value):\n    \"\"\"Call _from_base_type() if necessary.\n\n    If the value is a _BaseValue instance, unwrap it and call all\n    _from_base_type() methods.  Otherwise, return the value\n    unchanged.\n    \"\"\"\n    if isinstance(value, _BaseValue):\n      value = self._call_from_base_type(value.b_val)\n    return value"
"def assert_is_not(expected, actual, message=None, extra=None):\n    \"\"\"Raises an AssertionError if expected is actual.\"\"\"\n    assert expected is not actual, _assert_fail_message(\n        message, expected, actual, \"is\", extra\n    )"
"def get_keys_of_max_n(dict_obj, n):\n    \"\"\"Returns the keys that maps to the top n max values in the given dict.\n\n    Example:\n    --------\n    >>> dict_obj = {'a':2, 'b':1, 'c':5}\n    >>> get_keys_of_max_n(dict_obj, 2)\n    ['a', 'c']\n    \"\"\"\n    return sorted([\n        item[0]\n        for item in sorted(\n            dict_obj.items(), key=lambda item: item[1], reverse=True\n        )[:n]\n    ])"
"def CleanseComments(line):\n  \"\"\"Removes //-comments and single-line C-style /* */ comments.\n\n  Args:\n    line: A line of C++ source.\n\n  Returns:\n    The line with single-line comments removed.\n  \"\"\"\n  commentpos = line.find('//')\n  if commentpos != -1 and not IsCppString(line[:commentpos]):\n    line = line[:commentpos].rstrip()\n  # get rid of /* ... */\n  return _RE_PATTERN_CLEANSE_LINE_C_COMMENTS.sub('', line)"
"def exit(self):\n        \"\"\"Handle interactive exit.\n\n        This method calls the ask_exit callback.\"\"\"\n        if self.confirm_exit:\n            if self.ask_yes_no('Do you really want to exit ([y]/n)?','y'):\n                self.ask_exit()\n        else:\n            self.ask_exit()"
"def command_py2to3(args):\n    \"\"\"\n    Apply '2to3' tool (Python2 to Python3 conversion tool) to Python sources.\n    \"\"\"\n    from lib2to3.main import main\n    sys.exit(main(\"lib2to3.fixes\", args=args.sources))"
"def map_wrap(f):\n    \"\"\"Wrap standard function to easily pass into 'map' processing.\n    \"\"\"\n    @functools.wraps(f)\n    def wrapper(*args, **kwargs):\n        return f(*args, **kwargs)\n    return wrapper"
"def cli_run():\n    \"\"\"docstring for argparse\"\"\"\n    parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow')\n    parser.add_argument('query', help=\"What's the problem ?\", type=str, nargs='+')\n    parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda')\n    args = parser.parse_args()\n    main(args)"
"def is_scalar(value):\n    \"\"\"Test if the given value is a scalar.\n\n    This function also works with memory mapped array values, in contrast to the numpy is_scalar method.\n\n    Args:\n        value: the value to test for being a scalar value\n\n    Returns:\n        boolean: if the given value is a scalar or not\n    \"\"\"\n    return np.isscalar(value) or (isinstance(value, np.ndarray) and (len(np.squeeze(value).shape) == 0))"
"def setup_path():\n    \"\"\"Sets up the python include paths to include src\"\"\"\n    import os.path; import sys\n\n    if sys.argv[0]:\n        top_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\n        sys.path = [os.path.join(top_dir, \"src\")] + sys.path\n        pass\n    return"
"def getPrimeFactors(n):\n    \"\"\"\n    Get all the prime factor of given integer\n    @param n integer\n    @return list [1, ..., n]\n    \"\"\"\n    lo = [1]\n    n2 = n // 2\n    k = 2\n    for k in range(2, n2 + 1):\n        if (n // k)*k == n:\n            lo.append(k)\n    return lo + [n, ]"
"def expect_all(a, b):\n    \"\"\"\\\n    Asserts that two iterables contain the same values.\n    \"\"\"\n    assert all(_a == _b for _a, _b in zip_longest(a, b))"
"def intToBin(i):\n    \"\"\" Integer to two bytes \"\"\"\n    # devide in two parts (bytes)\n    i1 = i % 256\n    i2 = int(i / 256)\n    # make string (little endian)\n    return chr(i1) + chr(i2)"
"def _extract_node_text(node):\n    \"\"\"Extract text from a given lxml node.\"\"\"\n\n    texts = map(\n        six.text_type.strip, map(six.text_type, map(unescape, node.xpath(\".//text()\")))\n    )\n    return \" \".join(text for text in texts if text)"
"def is_float_array(l):\n    r\"\"\"Checks if l is a numpy array of floats (any dimension\n\n    \"\"\"\n    if isinstance(l, np.ndarray):\n        if l.dtype.kind == 'f':\n            return True\n    return False"
"def loadb(b):\n    \"\"\"Deserialize ``b`` (instance of ``bytes``) to a Python object.\"\"\"\n    assert isinstance(b, (bytes, bytearray))\n    return std_json.loads(b.decode('utf-8'))"
"def psutil_phymem_usage():\n    \"\"\"\n    Return physical memory usage (float)\n    Requires the cross-platform psutil (>=v0.3) library\n    (https://github.com/giampaolo/psutil)\n    \"\"\"\n    import psutil\n    # This is needed to avoid a deprecation warning error with\n    # newer psutil versions\n    try:\n        percent = psutil.virtual_memory().percent\n    except:\n        percent = psutil.phymem_usage().percent\n    return percent"
"def is_line_in_file(filename: str, line: str) -> bool:\n    \"\"\"\n    Detects whether a line is present within a file.\n\n    Args:\n        filename: file to check\n        line: line to search for (as an exact match)\n    \"\"\"\n    assert \"\\n\" not in line\n    with open(filename, \"r\") as file:\n        for fileline in file:\n            if fileline == line:\n                return True\n        return False"
"def plot(self):\n        \"\"\"Plot the empirical histogram versus best-fit distribution's PDF.\"\"\"\n        plt.plot(self.bin_edges, self.hist, self.bin_edges, self.best_pdf)"
"def adapter(data, headers, **kwargs):\n    \"\"\"Wrap vertical table in a function for TabularOutputFormatter.\"\"\"\n    keys = ('sep_title', 'sep_character', 'sep_length')\n    return vertical_table(data, headers, **filter_dict_by_key(kwargs, keys))"
"def get_language(self):\n        \"\"\"\n        Get the language parameter from the current request.\n        \"\"\"\n        return get_language_parameter(self.request, self.query_language_key, default=self.get_default_language(object=object))"
"def rnormal(mu, tau, size=None):\n    \"\"\"\n    Random normal variates.\n    \"\"\"\n    return np.random.normal(mu, 1. / np.sqrt(tau), size)"
"def write(self, text):\n        \"\"\"Write text. An additional attribute terminator with a value of\n           None is added to the logging record to indicate that StreamHandler\n           should not add a newline.\"\"\"\n        self.logger.log(self.loglevel, text, extra={'terminator': None})"
"def sorted_index(values, x):\n    \"\"\"\n    For list, values, returns the index location of element x. If x does not exist will raise an error.\n\n    :param values: list\n    :param x: item\n    :return: integer index\n    \"\"\"\n    i = bisect_left(values, x)\n    j = bisect_right(values, x)\n    return values[i:j].index(x) + i"
"def _get_compiled_ext():\n    \"\"\"Official way to get the extension of compiled files (.pyc or .pyo)\"\"\"\n    for ext, mode, typ in imp.get_suffixes():\n        if typ == imp.PY_COMPILED:\n            return ext"
"def flatten_list(l: List[list]) -> list:\n    \"\"\" takes a list of lists, l and returns a flat list\n    \"\"\"\n    return [v for inner_l in l for v in inner_l]"
"def cmd_reindex():\n    \"\"\"Uses CREATE INDEX CONCURRENTLY to create a duplicate index, then tries to swap the new index for the original.\n\n    The index swap is done using a short lock timeout to prevent it from interfering with running queries. Retries until\n    the rename succeeds.\n    \"\"\"\n    db = connect(args.database)\n    for idx in args.indexes:\n        pg_reindex(db, idx)"
"def pop(h):\n    \"\"\"Pop the heap value from the heap.\"\"\"\n    n = h.size() - 1\n    h.swap(0, n)\n    down(h, 0, n)\n    return h.pop()"
"def on_source_directory_chooser_clicked(self):\n        \"\"\"Autoconnect slot activated when tbSourceDir is clicked.\"\"\"\n\n        title = self.tr('Set the source directory for script and scenario')\n        self.choose_directory(self.source_directory, title)"
"def save_keras_definition(keras_model, path):\n    \"\"\"\n    Save a Keras model definition to JSON with given path\n    \"\"\"\n    model_json = keras_model.to_json()\n    with open(path, \"w\") as json_file:\n        json_file.write(model_json)"
"def bytes_to_str(s, encoding='utf-8'):\n    \"\"\"Returns a str if a bytes object is given.\"\"\"\n    if six.PY3 and isinstance(s, bytes):\n        return s.decode(encoding)\n    return s"
"def set_xticks_for_all(self, row_column_list=None, ticks=None):\n        \"\"\"Manually specify the x-axis tick values.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :type row_column_list: list or None\n        :param ticks: list of tick values.\n\n        \"\"\"\n        if row_column_list is None:\n            self.ticks['x'] = ticks\n        else:\n            for row, column in row_column_list:\n                self.set_xticks(row, column, ticks)"
"def __str__(self):\n    \"\"\"Returns a pretty-printed string for this object.\"\"\"\n    return 'Output name: \"%s\" watts: %d type: \"%s\" id: %d' % (\n        self._name, self._watts, self._output_type, self._integration_id)"
"def separator(self, menu=None):\n        \"\"\"Add a separator\"\"\"\n        self.gui.get_menu(menu or self.menu).addSeparator()"
"def unit_vector(x):\n    \"\"\"Return a unit vector in the same direction as x.\"\"\"\n    y = np.array(x, dtype='float')\n    return y/norm(y)"
"def find_first_in_list(txt: str, str_list: [str]) -> int:  # type: ignore\n    \"\"\"\n    Returns the index of the earliest occurence of an item from a list in a string\n\n    Ex: find_first_in_list('foobar', ['bar', 'fin']) -> 3\n    \"\"\"\n    start = len(txt) + 1\n    for item in str_list:\n        if start > txt.find(item) > -1:\n            start = txt.find(item)\n    return start if len(txt) + 1 > start > -1 else -1"
"def _manhattan_distance(vec_a, vec_b):\n    \"\"\"Return manhattan distance between two lists of numbers.\"\"\"\n    if len(vec_a) != len(vec_b):\n        raise ValueError('len(vec_a) must equal len(vec_b)')\n    return sum(map(lambda a, b: abs(a - b), vec_a, vec_b))"
"def _parse(self, date_str, format='%Y-%m-%d'):\n        \"\"\"\n        helper function for parsing FRED date string into datetime\n        \"\"\"\n        rv = pd.to_datetime(date_str, format=format)\n        if hasattr(rv, 'to_pydatetime'):\n            rv = rv.to_pydatetime()\n        return rv"
"def remove_legend(ax=None):\n    \"\"\"Remove legend for axes or gca.\n\n    See http://osdir.com/ml/python.matplotlib.general/2005-07/msg00285.html\n    \"\"\"\n    from pylab import gca, draw\n    if ax is None:\n        ax = gca()\n    ax.legend_ = None\n    draw()"
"def get_average_length_of_string(strings):\n    \"\"\"Computes average length of words\n\n    :param strings: list of words\n    :return: Average length of word on list\n    \"\"\"\n    if not strings:\n        return 0\n\n    return sum(len(word) for word in strings) / len(strings)"
"def issuperset(self, items):\n        \"\"\"Return whether this collection contains all items.\n\n        >>> Unique(['spam', 'eggs']).issuperset(['spam', 'spam', 'spam'])\n        True\n        \"\"\"\n        return all(_compat.map(self._seen.__contains__, items))"
"def post_process(self):\n        \"\"\" Apply last 2D transforms\"\"\"\n        self.image.putdata(self.pixels)\n        self.image = self.image.transpose(Image.ROTATE_90)"
"def add_suffix(fullname, suffix):\n    \"\"\" Add suffix to a full file name\"\"\"\n    name, ext = os.path.splitext(fullname)\n    return name + '_' + suffix + ext"
"def _heappush_max(heap, item):\n    \"\"\" why is this not in heapq \"\"\"\n    heap.append(item)\n    heapq._siftdown_max(heap, 0, len(heap) - 1)"
"def __rmatmul__(self, other):\n        \"\"\"\n        Matrix multiplication using binary `@` operator in Python>=3.5.\n        \"\"\"\n        return self.T.dot(np.transpose(other)).T"
"def _send_cmd(self, cmd):\n        \"\"\"Write command to remote process\n        \"\"\"\n        self._process.stdin.write(\"{}\\n\".format(cmd).encode(\"utf-8\"))\n        self._process.stdin.flush()"
"def parse_reading(val: str) -> Optional[float]:\n    \"\"\" Convert reading value to float (if possible) \"\"\"\n    try:\n        return float(val)\n    except ValueError:\n        logging.warning('Reading of \"%s\" is not a number', val)\n        return None"
"def omnihash(obj):\n    \"\"\" recursively hash unhashable objects \"\"\"\n    if isinstance(obj, set):\n        return hash(frozenset(omnihash(e) for e in obj))\n    elif isinstance(obj, (tuple, list)):\n        return hash(tuple(omnihash(e) for e in obj))\n    elif isinstance(obj, dict):\n        return hash(frozenset((k, omnihash(v)) for k, v in obj.items()))\n    else:\n        return hash(obj)"
"def quaternion_imag(quaternion):\n    \"\"\"Return imaginary part of quaternion.\n\n    >>> quaternion_imag([3, 0, 1, 2])\n    array([0., 1., 2.])\n\n    \"\"\"\n    return np.array(quaternion[1:4], dtype=np.float64, copy=True)"
"def clear_caches():\n    \"\"\"Jinja2 keeps internal caches for environments and lexers.  These are\n    used so that Jinja2 doesn't have to recreate environments and lexers all\n    the time.  Normally you don't have to care about that but if you are\n    measuring memory consumption you may want to clean the caches.\n    \"\"\"\n    from jinja2.environment import _spontaneous_environments\n    from jinja2.lexer import _lexer_cache\n    _spontaneous_environments.clear()\n    _lexer_cache.clear()"
"def create_object(cls, members):\n    \"\"\"Promise an object of class `cls` with content `members`.\"\"\"\n    obj = cls.__new__(cls)\n    obj.__dict__ = members\n    return obj"
"def remove_from_lib(self, name):\n        \"\"\" Remove an object from the bin folder. \"\"\"\n        self.__remove_path(os.path.join(self.root_dir, \"lib\", name))"
"def format_exc(*exc_info):\n    \"\"\"Show exception with traceback.\"\"\"\n    typ, exc, tb = exc_info or sys.exc_info()\n    error = traceback.format_exception(typ, exc, tb)\n    return \"\".join(error)"
"def sqliteRowsToDicts(sqliteRows):\n    \"\"\"\n    Unpacks sqlite rows as returned by fetchall\n    into an array of simple dicts.\n\n    :param sqliteRows: array of rows returned from fetchall DB call\n    :return:  array of dicts, keyed by the column names.\n    \"\"\"\n    return map(lambda r: dict(zip(r.keys(), r)), sqliteRows)"
"def delete(self):\n        \"\"\"Remove this object.\"\"\"\n        self._client.remove_object(self._instance, self._bucket, self.name)"
"def get_builder_toplevel(self, builder):\n        \"\"\"Get the toplevel widget from a gtk.Builder file.\n\n        The main view implementation first searches for the widget named as\n        self.toplevel_name (which defaults to \"main\". If this is missing, or not\n        a gtk.Window, the first toplevel window found in the gtk.Builder is\n        used.\n        \"\"\"\n        toplevel = builder.get_object(self.toplevel_name)\n        if not gobject.type_is_a(toplevel, gtk.Window):\n            toplevel = None\n        if toplevel is None:\n            toplevel = get_first_builder_window(builder)\n        return toplevel"
"def strids2ids(tokens: Iterable[str]) -> List[int]:\n    \"\"\"\n    Returns sequence of integer ids given a sequence of string ids.\n\n    :param tokens: List of integer tokens.\n    :return: List of word ids.\n    \"\"\"\n    return list(map(int, tokens))"
"def _get_binary_from_ipv4(self, ip_addr):\n        \"\"\"Converts IPv4 address to binary form.\"\"\"\n\n        return struct.unpack(\"!L\", socket.inet_pton(socket.AF_INET,\n                                                    ip_addr))[0]"
"def _pdf_at_peak(self):\n    \"\"\"Pdf evaluated at the peak.\"\"\"\n    return (self.peak - self.low) / (self.high - self.low)"
"def is_cached(file_name):\n\t\"\"\"\n\tCheck if a given file is available in the cache or not\n\t\"\"\"\n\n\tgml_file_path = join(join(expanduser('~'), OCTOGRID_DIRECTORY), file_name)\n\n\treturn isfile(gml_file_path)"
"def strip_spaces(s):\n    \"\"\" Strip excess spaces from a string \"\"\"\n    return u\" \".join([c for c in s.split(u' ') if c])"
"def _get_str_columns(sf):\n    \"\"\"\n    Returns a list of names of columns that are string type.\n    \"\"\"\n    return [name for name in sf.column_names() if sf[name].dtype == str]"
"def revrank_dict(dict, key=lambda t: t[1], as_tuple=False):\n    \"\"\" Reverse sorts a #dict by a given key, optionally returning it as a\n        #tuple. By default, the @dict is sorted by it's value.\n\n        @dict: the #dict you wish to sorts\n        @key: the #sorted key to use\n        @as_tuple: returns result as a #tuple ((k, v),...)\n\n        -> :class:OrderedDict or #tuple\n    \"\"\"\n    sorted_list = sorted(dict.items(), key=key, reverse=True)\n    return OrderedDict(sorted_list) if not as_tuple else tuple(sorted_list)"
"def _default(self, obj):\n        \"\"\" return a serialized version of obj or raise a TypeError\n\n        :param obj:\n        :return: Serialized version of obj\n        \"\"\"\n        return obj.__dict__ if isinstance(obj, JsonObj) else json.JSONDecoder().decode(obj)"
"def runiform(lower, upper, size=None):\n    \"\"\"\n    Random uniform variates.\n    \"\"\"\n    return np.random.uniform(lower, upper, size)"
"def get_hline():\n    \"\"\" gets a horiztonal line \"\"\"\n    return Window(\n        width=LayoutDimension.exact(1),\n        height=LayoutDimension.exact(1),\n        content=FillControl('-', token=Token.Line))"
"def sort_by_modified(files_or_folders: list) -> list:\n    \"\"\"\n    Sort files or folders by modified time\n\n    Args:\n        files_or_folders: list of files or folders\n\n    Returns:\n        list\n    \"\"\"\n    return sorted(files_or_folders, key=os.path.getmtime, reverse=True)"
"def parse_datetime(dt_str):\n    \"\"\"Parse datetime.\"\"\"\n    date_format = \"%Y-%m-%dT%H:%M:%S %z\"\n    dt_str = dt_str.replace(\"Z\", \" +0000\")\n    return datetime.datetime.strptime(dt_str, date_format)"
"def spline_interpolate_by_datetime(datetime_axis, y_axis, datetime_new_axis):\n    \"\"\"A datetime-version that takes datetime object list as x_axis\n    \"\"\"\n    numeric_datetime_axis = [\n        totimestamp(a_datetime) for a_datetime in datetime_axis\n    ]\n\n    numeric_datetime_new_axis = [\n        totimestamp(a_datetime) for a_datetime in datetime_new_axis\n    ]\n\n    return spline_interpolate(\n        numeric_datetime_axis, y_axis, numeric_datetime_new_axis)"
"def _openResources(self):\n        \"\"\" Uses numpy.load to open the underlying file\n        \"\"\"\n        arr = np.load(self._fileName, allow_pickle=ALLOW_PICKLE)\n        check_is_an_array(arr)\n        self._array = arr"
"def _linear_interpolation(x, X, Y):\n    \"\"\"Given two data points [X,Y], linearly interpolate those at x.\n    \"\"\"\n    return (Y[1] * (x - X[0]) + Y[0] * (X[1] - x)) / (X[1] - X[0])"
"def map_wrap(f):\n    \"\"\"Wrap standard function to easily pass into 'map' processing.\n    \"\"\"\n    @functools.wraps(f)\n    def wrapper(*args, **kwargs):\n        return f(*args, **kwargs)\n    return wrapper"
"def __run(self):\n    \"\"\"Hacked run function, which installs the trace.\"\"\"\n    sys.settrace(self.globaltrace)\n    self.__run_backup()\n    self.run = self.__run_backup"
"def samefile(a: str, b: str) -> bool:\n    \"\"\"Check if two pathes represent the same file.\"\"\"\n    try:\n        return os.path.samefile(a, b)\n    except OSError:\n        return os.path.normpath(a) == os.path.normpath(b)"
"def remove_ext(fname):\n    \"\"\"Removes the extension from a filename\n    \"\"\"\n    bn = os.path.basename(fname)\n    return os.path.splitext(bn)[0]"
"def setdefaults(dct, defaults):\n    \"\"\"Given a target dct and a dict of {key:default value} pairs,\n    calls setdefault for all of those pairs.\"\"\"\n    for key in defaults:\n        dct.setdefault(key, defaults[key])\n\n    return dct"
"def _convert_to_array(array_like, dtype):\n        \"\"\"\n        Convert Matrix attributes which are array-like or buffer to array.\n        \"\"\"\n        if isinstance(array_like, bytes):\n            return np.frombuffer(array_like, dtype=dtype)\n        return np.asarray(array_like, dtype=dtype)"
"def _xxrange(self, start, end, step_count):\n        \"\"\"Generate n values between start and end.\"\"\"\n        _step = (end - start) / float(step_count)\n        return (start + (i * _step) for i in xrange(int(step_count)))"
"def _rindex(mylist: Sequence[T], x: T) -> int:\n    \"\"\"Index of the last occurrence of x in the sequence.\"\"\"\n    return len(mylist) - mylist[::-1].index(x) - 1"
"def get_api_url(self, lambda_name, stage_name):\n        \"\"\"\n        Given a lambda_name and stage_name, return a valid API URL.\n        \"\"\"\n        api_id = self.get_api_id(lambda_name)\n        if api_id:\n            return \"https://{}.execute-api.{}.amazonaws.com/{}\".format(api_id, self.boto_session.region_name, stage_name)\n        else:\n            return None"
"def CleanseComments(line):\n  \"\"\"Removes //-comments and single-line C-style /* */ comments.\n\n  Args:\n    line: A line of C++ source.\n\n  Returns:\n    The line with single-line comments removed.\n  \"\"\"\n  commentpos = line.find('//')\n  if commentpos != -1 and not IsCppString(line[:commentpos]):\n    line = line[:commentpos].rstrip()\n  # get rid of /* ... */\n  return _RE_PATTERN_CLEANSE_LINE_C_COMMENTS.sub('', line)"
"async def sysinfo(dev: Device):\n    \"\"\"Print out system information (version, MAC addrs).\"\"\"\n    click.echo(await dev.get_system_info())\n    click.echo(await dev.get_interface_information())"
"def split_comment(cls, code):\n        \"\"\" Removes comments (#...) from python code. \"\"\"\n        if '#' not in code: return code\n        #: Remove comments only (leave quoted strings as they are)\n        subf = lambda m: '' if m.group(0)[0]=='#' else m.group(0)\n        return re.sub(cls.re_pytokens, subf, code)"
"def csort(objs, key):\n    \"\"\"Order-preserving sorting function.\"\"\"\n    idxs = dict((obj, i) for (i, obj) in enumerate(objs))\n    return sorted(objs, key=lambda obj: (key(obj), idxs[obj]))"
"def reset(self):\n        \"\"\"Reset the instance\n\n        - reset rows and header\n        \"\"\"\n\n        self._hline_string = None\n        self._row_size = None\n        self._header = []\n        self._rows = []"
"def _remove_from_index(index, obj):\n    \"\"\"Removes object ``obj`` from the ``index``.\"\"\"\n    try:\n        index.value_map[indexed_value(index, obj)].remove(obj.id)\n    except KeyError:\n        pass"
"def get_system_cpu_times():\n    \"\"\"Return system CPU times as a namedtuple.\"\"\"\n    user, nice, system, idle = _psutil_osx.get_system_cpu_times()\n    return _cputimes_ntuple(user, nice, system, idle)"
"def cli(yamlfile, directory, out, classname, format):\n    \"\"\" Generate graphviz representations of the biolink model \"\"\"\n    DotGenerator(yamlfile, format).serialize(classname=classname, dirname=directory, filename=out)"
"def comment (self, s, **args):\n        \"\"\"Write DOT comment.\"\"\"\n        self.write(u\"// \")\n        self.writeln(s=s, **args)"
"def _heappush_max(heap, item):\n    \"\"\" why is this not in heapq \"\"\"\n    heap.append(item)\n    heapq._siftdown_max(heap, 0, len(heap) - 1)"
"def sorted_index(values, x):\n    \"\"\"\n    For list, values, returns the index location of element x. If x does not exist will raise an error.\n\n    :param values: list\n    :param x: item\n    :return: integer index\n    \"\"\"\n    i = bisect_left(values, x)\n    j = bisect_right(values, x)\n    return values[i:j].index(x) + i"
"def clear():\n    \"\"\"Clears the console.\"\"\"\n    if sys.platform.startswith(\"win\"):\n        call(\"cls\", shell=True)\n    else:\n        call(\"clear\", shell=True)"
"def parse_value(self, value):\n        \"\"\"Cast value to `bool`.\"\"\"\n        parsed = super(BoolField, self).parse_value(value)\n        return bool(parsed) if parsed is not None else None"
"def get_known_read_position(fp, buffered=True):\n    \"\"\" \n    Return a position in a file which is known to be read & handled.\n    It assumes a buffered file and streaming processing. \n    \"\"\"\n    buffer_size = io.DEFAULT_BUFFER_SIZE if buffered else 0\n    return max(fp.tell() - buffer_size, 0)"
"def check_str(obj):\n        \"\"\" Returns a string for various input types \"\"\"\n        if isinstance(obj, str):\n            return obj\n        if isinstance(obj, float):\n            return str(int(obj))\n        else:\n            return str(obj)"
"def crop_box(im, box=False, **kwargs):\n    \"\"\"Uses box coordinates to crop an image without resizing it first.\"\"\"\n    if box:\n        im = im.crop(box)\n    return im"
"def _cumprod(l):\n  \"\"\"Cumulative product of a list.\n\n  Args:\n    l: a list of integers\n  Returns:\n    a list with one more element (starting with 1)\n  \"\"\"\n  ret = [1]\n  for item in l:\n    ret.append(ret[-1] * item)\n  return ret"
"def _isstring(dtype):\n    \"\"\"Given a numpy dtype, determines whether it is a string. Returns True\n    if the dtype is string or unicode.\n    \"\"\"\n    return dtype.type == numpy.unicode_ or dtype.type == numpy.string_"
"def _cnx_is_empty(in_file):\n    \"\"\"Check if cnr or cns files are empty (only have a header)\n    \"\"\"\n    with open(in_file) as in_handle:\n        for i, line in enumerate(in_handle):\n            if i > 0:\n                return False\n    return True"
"def first_sunday(self, year, month):\n        \"\"\"Get the first sunday of a month.\"\"\"\n        date = datetime(year, month, 1, 0)\n        days_until_sunday = 6 - date.weekday()\n\n        return date + timedelta(days=days_until_sunday)"
"def list_to_csv(value):\n    \"\"\"\n    Converts list to string with comma separated values. For string is no-op.\n    \"\"\"\n    if isinstance(value, (list, tuple, set)):\n        value = \",\".join(value)\n    return value"
"def csv_to_dicts(file, header=None):\n    \"\"\"Reads a csv and returns a List of Dicts with keys given by header row.\"\"\"\n    with open(file) as csvfile:\n        return [row for row in csv.DictReader(csvfile, fieldnames=header)]"
"def get_period_last_3_months() -> str:\n    \"\"\" Returns the last week as a period string \"\"\"\n    today = Datum()\n    today.today()\n\n    # start_date = today - timedelta(weeks=13)\n    start_date = today.clone()\n    start_date.subtract_months(3)\n\n    period = get_period(start_date.date, today.date)\n    return period"
"def truncate(value: Decimal, n_digits: int) -> Decimal:\n    \"\"\"Truncates a value to a number of decimals places\"\"\"\n    return Decimal(math.trunc(value * (10 ** n_digits))) / (10 ** n_digits)"
"def set_font_size(self, size):\n        \"\"\"Convenience method for just changing font size.\"\"\"\n        if self.font.font_size == size:\n            pass\n        else:\n            self.font._set_size(size)"
"def chmod_plus_w(path):\n  \"\"\"Equivalent of unix `chmod +w path`\"\"\"\n  path_mode = os.stat(path).st_mode\n  path_mode &= int('777', 8)\n  path_mode |= stat.S_IWRITE\n  os.chmod(path, path_mode)"
"def _rnd_datetime(self, start, end):\n        \"\"\"Internal random datetime generator.\n        \"\"\"\n        return self.from_utctimestamp(\n            random.randint(\n                int(self.to_utctimestamp(start)),\n                int(self.to_utctimestamp(end)),\n            )\n        )"
"def distance(vec1, vec2):\n        \"\"\"Calculate the distance between two Vectors\"\"\"\n        if isinstance(vec1, Vector2) \\\n                and isinstance(vec2, Vector2):\n            dist_vec = vec2 - vec1\n            return dist_vec.length()\n        else:\n            raise TypeError(\"vec1 and vec2 must be Vector2's\")"
"def get():\n    \"\"\" Get local facts about this machine.\n\n    Returns:\n        json-compatible dict with all facts of this host\n    \"\"\"\n    result = runCommand('facter --json', raise_error_on_fail=True)\n    json_facts = result[1]\n    facts = json.loads(json_facts)\n    return facts"
"def _relative_frequency(self, word):\n\t\t\"\"\"Computes the log relative frequency for a word form\"\"\"\n\n\t\tcount = self.type_counts.get(word, 0)\n\t\treturn math.log(count/len(self.type_counts)) if count > 0 else 0"
"def invertDictMapping(d):\n    \"\"\" Invert mapping of dictionary (i.e. map values to list of keys) \"\"\"\n    inv_map = {}\n    for k, v in d.items():\n        inv_map[v] = inv_map.get(v, [])\n        inv_map[v].append(k)\n    return inv_map"
"def _factor_generator(n):\n    \"\"\"\n    From a given natural integer, returns the prime factors and their multiplicity\n    :param n: Natural integer\n    :return:\n    \"\"\"\n    p = prime_factors(n)\n    factors = {}\n    for p1 in p:\n        try:\n            factors[p1] += 1\n        except KeyError:\n            factors[p1] = 1\n    return factors"
"def restart_program():\n    \"\"\"\n    DOES NOT WORK WELL WITH MOPIDY\n    Hack from\n    https://www.daniweb.com/software-development/python/code/260268/restart-your-python-program\n    to support updating the settings, since mopidy is not able to do that yet\n    Restarts the current program\n    Note: this function does not return. Any cleanup action (like\n    saving data) must be done before calling this function\n    \"\"\"\n\n    python = sys.executable\n    os.execl(python, python, * sys.argv)"
"def is_empty(self):\n        \"\"\"Returns True if the root node contains no child elements, no text,\n        and no attributes other than **type**. Returns False if any are present.\"\"\"\n        non_type_attributes = [attr for attr in self.node.attrib.keys() if attr != 'type']\n        return len(self.node) == 0 and len(non_type_attributes) == 0 \\\n            and not self.node.text and not self.node.tail"
"def downsample(array, k):\n    \"\"\"Choose k random elements of array.\"\"\"\n    length = array.shape[0]\n    indices = random.sample(xrange(length), k)\n    return array[indices]"
"def _expand(self, str, local_vars={}):\n        \"\"\"Expand $vars in a string.\"\"\"\n        return ninja_syntax.expand(str, self.vars, local_vars)"
"def accel_prev(self, *args):\n        \"\"\"Callback to go to the previous tab. Called by the accel key.\n        \"\"\"\n        if self.get_notebook().get_current_page() == 0:\n            self.get_notebook().set_current_page(self.get_notebook().get_n_pages() - 1)\n        else:\n            self.get_notebook().prev_page()\n        return True"
"def get_server(address=None):\n        \"\"\"Return an SMTP servername guess from outgoing email address.\"\"\"\n        if address:\n            domain = address.split(\"@\")[1]\n            try:\n                return SMTP_SERVERS[domain]\n            except KeyError:\n                return (\"smtp.\" + domain, 465)\n        return (None, None)"
"def equal(obj1, obj2):\n    \"\"\"Calculate equality between two (Comparable) objects.\"\"\"\n    Comparable.log(obj1, obj2, '==')\n    equality = obj1.equality(obj2)\n    Comparable.log(obj1, obj2, '==', result=equality)\n    return equality"
"def find_one_by_id(self, _id):\n        \"\"\"\n        Find a single document by id\n\n        :param str _id: BSON string repreentation of the Id\n        :return: a signle object\n        :rtype: dict\n\n        \"\"\"\n        document = (yield self.collection.find_one({\"_id\": ObjectId(_id)}))\n        raise Return(self._obj_cursor_to_dictionary(document))"
"def levenshtein_distance_metric(a, b):\n    \"\"\" 1 - farthest apart (same number of words, all diff). 0 - same\"\"\"\n    return (levenshtein_distance(a, b) / (2.0 * max(len(a), len(b), 1)))"
"def save_dict_to_file(filename, dictionary):\n  \"\"\"Saves dictionary as CSV file.\"\"\"\n  with open(filename, 'w') as f:\n    writer = csv.writer(f)\n    for k, v in iteritems(dictionary):\n      writer.writerow([str(k), str(v)])"
"def script_repr(val,imports,prefix,settings):\n    \"\"\"\n    Variant of repr() designed for generating a runnable script.\n\n    Instances of types that require special handling can use the\n    script_repr_reg dictionary. Using the type as a key, add a\n    function that returns a suitable representation of instances of\n    that type, and adds the required import statement.\n\n    The repr of a parameter can be suppressed by returning None from\n    the appropriate hook in script_repr_reg.\n    \"\"\"\n    return pprint(val,imports,prefix,settings,unknown_value=None,\n                  qualify=True,separator=\"\\n\")"
"def get_enum_from_name(self, enum_name):\n        \"\"\"\n            Return an enum from a name\n        Args:\n            enum_name (str): name of the enum\n        Returns:\n            Enum\n        \"\"\"\n        return next((e for e in self.enums if e.name == enum_name), None)"
"def mmap(func, iterable):\n    \"\"\"Wrapper to make map() behave the same on Py2 and Py3.\"\"\"\n\n    if sys.version_info[0] > 2:\n        return [i for i in map(func, iterable)]\n    else:\n        return map(func, iterable)"
"def remove_elements(target, indices):\n    \"\"\"Remove multiple elements from a list and return result.\n    This implementation is faster than the alternative below.\n    Also note the creation of a new list to avoid altering the\n    original. We don't have any current use for the original\n    intact list, but may in the future...\"\"\"\n\n    copied = list(target)\n\n    for index in reversed(indices):\n        del copied[index]\n    return copied"
"def __call__(self, _):\n        \"\"\"Update the progressbar.\"\"\"\n        if self.iter % self.step == 0:\n            self.pbar.update(self.step)\n\n        self.iter += 1"
"def text_cleanup(data, key, last_type):\n    \"\"\" I strip extra whitespace off multi-line strings if they are ready to be stripped!\"\"\"\n    if key in data and last_type == STRING_TYPE:\n        data[key] = data[key].strip()\n    return data"
"def cli(yamlfile, directory, out, classname, format):\n    \"\"\" Generate graphviz representations of the biolink model \"\"\"\n    DotGenerator(yamlfile, format).serialize(classname=classname, dirname=directory, filename=out)"
"def clear_global(self):\n        \"\"\"Clear only any cached global data.\n\n        \"\"\"\n        vname = self.varname\n        logger.debug(f'global clearning {vname}')\n        if vname in globals():\n            logger.debug('removing global instance var: {}'.format(vname))\n            del globals()[vname]"
"def monthly(date=datetime.date.today()):\n    \"\"\"\n    Take a date object and return the first day of the month.\n    \"\"\"\n    return datetime.date(date.year, date.month, 1)"
"def debug_src(src, pm=False, globs=None):\n    \"\"\"Debug a single doctest docstring, in argument `src`'\"\"\"\n    testsrc = script_from_examples(src)\n    debug_script(testsrc, pm, globs)"
"def multi_pop(d, *args):\n    \"\"\" pops multiple keys off a dict like object \"\"\"\n    retval = {}\n    for key in args:\n        if key in d:\n            retval[key] = d.pop(key)\n    return retval"
"def clean_error(err):\n    \"\"\"\n    Take stderr bytes returned from MicroPython and attempt to create a\n    non-verbose error message.\n    \"\"\"\n    if err:\n        decoded = err.decode('utf-8')\n        try:\n            return decoded.split('\\r\\n')[-2]\n        except Exception:\n            return decoded\n    return 'There was an error.'"
"def get_month_start(day=None):\n    \"\"\"Returns the first day of the given month.\"\"\"\n    day = add_timezone(day or datetime.date.today())\n    return day.replace(day=1)"
"def staticdir():\n    \"\"\"Return the location of the static data directory.\"\"\"\n    root = os.path.abspath(os.path.dirname(__file__))\n    return os.path.join(root, \"static\")"
"def set_subparsers_args(self, *args, **kwargs):\n        \"\"\"\n        Sets args and kwargs that are passed when creating a subparsers group\n        in an argparse.ArgumentParser i.e. when calling\n        argparser.ArgumentParser.add_subparsers\n        \"\"\"\n        self.subparsers_args = args\n        self.subparsers_kwargs = kwargs"
"def terminate(self):\n        \"\"\"Terminate all workers and threads.\"\"\"\n        for t in self._threads:\n            t.quit()\n        self._thread = []\n        self._workers = []"
"def convert_camel_case_to_snake_case(name):\n    \"\"\"Convert CamelCase to snake_case.\"\"\"\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()"
"def __init__(self,operand,operator,**args):\n        \"\"\"\n        Accepts a NumberGenerator operand, an operator, and\n        optional arguments to be provided to the operator when calling\n        it on the operand.\n        \"\"\"\n        # Note that it's currently not possible to set\n        # parameters in the superclass when creating an instance,\n        # because **args is used by this class itself.\n        super(UnaryOperator,self).__init__()\n\n        self.operand=operand\n        self.operator=operator\n        self.args=args"
"def remove_from_lib(self, name):\n        \"\"\" Remove an object from the bin folder. \"\"\"\n        self.__remove_path(os.path.join(self.root_dir, \"lib\", name))"
"def _isstring(dtype):\n    \"\"\"Given a numpy dtype, determines whether it is a string. Returns True\n    if the dtype is string or unicode.\n    \"\"\"\n    return dtype.type == numpy.unicode_ or dtype.type == numpy.string_"
"def get_last_or_frame_exception():\n    \"\"\"Intended to be used going into post mortem routines.  If\n    sys.last_traceback is set, we will return that and assume that\n    this is what post-mortem will want. If sys.last_traceback has not\n    been set, then perhaps we *about* to raise an error and are\n    fielding an exception. So assume that sys.exc_info()[2]\n    is where we want to look.\"\"\"\n\n    try:\n        if inspect.istraceback(sys.last_traceback):\n            # We do have a traceback so prefer that.\n            return sys.last_type, sys.last_value, sys.last_traceback\n    except AttributeError:\n        pass\n    return sys.exc_info()"
"def is_unicode(string):\n    \"\"\"Validates that the object itself is some kinda string\"\"\"\n    str_type = str(type(string))\n\n    if str_type.find('str') > 0 or str_type.find('unicode') > 0:\n        return True\n\n    return False"
"def find_le(a, x):\n    \"\"\"Find rightmost value less than or equal to x.\"\"\"\n    i = bs.bisect_right(a, x)\n    if i: return i - 1\n    raise ValueError"
"def warn_deprecated(message, stacklevel=2):  # pragma: no cover\n    \"\"\"Warn deprecated.\"\"\"\n\n    warnings.warn(\n        message,\n        category=DeprecationWarning,\n        stacklevel=stacklevel\n    )"
"def show(self, title=''):\n        \"\"\"\n        Display Bloch sphere and corresponding data sets.\n        \"\"\"\n        self.render(title=title)\n        if self.fig:\n            plt.show(self.fig)"
"def from_array(cls, arr):\n        \"\"\"Convert a structured NumPy array into a Table.\"\"\"\n        return cls().with_columns([(f, arr[f]) for f in arr.dtype.names])"
"def to_list(self):\n        \"\"\"Convert this confusion matrix into a 2x2 plain list of values.\"\"\"\n        return [[int(self.table.cell_values[0][1]), int(self.table.cell_values[0][2])],\n                [int(self.table.cell_values[1][1]), int(self.table.cell_values[1][2])]]"
"def is_file_exists_error(e):\n    \"\"\"\n    Returns whether the exception *e* was raised due to an already existing file or directory.\n    \"\"\"\n    if six.PY3:\n        return isinstance(e, FileExistsError)  # noqa: F821\n    else:\n        return isinstance(e, OSError) and e.errno == 17"
"def __replace_all(repls: dict, input: str) -> str:\n    \"\"\" Replaces from a string **input** all the occurrences of some\n    symbols according to mapping **repls**.\n\n    :param dict repls: where #key is the old character and\n    #value is the one to substitute with;\n    :param str input: original string where to apply the\n    replacements;\n    :return: *(str)* the string with the desired characters replaced\n    \"\"\"\n    return re.sub('|'.join(re.escape(key) for key in repls.keys()),\n                  lambda k: repls[k.group(0)], input)"
"def kill(self):\n        \"\"\"Kill the browser.\n\n        This is useful when the browser is stuck.\n        \"\"\"\n        if self.process:\n            self.process.kill()\n            self.process.wait()"
"def get_table_list(dbconn):\n    \"\"\"\n    Get a list of tables that exist in dbconn\n    :param dbconn: database connection\n    :return: List of table names\n    \"\"\"\n    cur = dbconn.cursor()\n    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    try:\n        return [item[0] for item in cur.fetchall()]\n    except IndexError:\n        return get_table_list(dbconn)"
"def is_iterable(value):\n    \"\"\"must be an iterable (list, array, tuple)\"\"\"\n    return isinstance(value, np.ndarray) or isinstance(value, list) or isinstance(value, tuple), value"
"def read_text_from_file(path: str) -> str:\n    \"\"\" Reads text file contents \"\"\"\n    with open(path) as text_file:\n        content = text_file.read()\n\n    return content"
"def is_delimiter(line):\n    \"\"\" True if a line consists only of a single punctuation character.\"\"\"\n    return bool(line) and line[0] in punctuation and line[0]*len(line) == line"
"def str2int(num, radix=10, alphabet=BASE85):\n    \"\"\"helper function for quick base conversions from strings to integers\"\"\"\n    return NumConv(radix, alphabet).str2int(num)"
"def flatten(l, types=(list, float)):\n    \"\"\"\n    Flat nested list of lists into a single list.\n    \"\"\"\n    l = [item if isinstance(item, types) else [item] for item in l]\n    return [item for sublist in l for item in sublist]"
"def _trim(image):\n    \"\"\"Trim a PIL image and remove white space.\"\"\"\n    background = PIL.Image.new(image.mode, image.size, image.getpixel((0, 0)))\n    diff = PIL.ImageChops.difference(image, background)\n    diff = PIL.ImageChops.add(diff, diff, 2.0, -100)\n    bbox = diff.getbbox()\n    if bbox:\n        image = image.crop(bbox)\n    return image"
"def _get_background_color(self):\n        \"\"\"Returns background color rgb tuple of right line\"\"\"\n\n        color = self.cell_attributes[self.key][\"bgcolor\"]\n        return tuple(c / 255.0 for c in color_pack2rgb(color))"
"def is_string(obj):\n    \"\"\"Is this a string.\n\n    :param object obj:\n    :rtype: bool\n    \"\"\"\n    if PYTHON3:\n        str_type = (bytes, str)\n    else:\n        str_type = (bytes, str, unicode)\n    return isinstance(obj, str_type)"
"def _check_elements_equal(lst):\n    \"\"\"\n    Returns true if all of the elements in the list are equal.\n    \"\"\"\n    assert isinstance(lst, list), \"Input value must be a list.\"\n    return not lst or lst.count(lst[0]) == len(lst)"
"def round_sig(x, sig):\n    \"\"\"Round the number to the specified number of significant figures\"\"\"\n    return round(x, sig - int(floor(log10(abs(x)))) - 1)"
"def astensor(array: TensorLike) -> BKTensor:\n    \"\"\"Covert numpy array to tensorflow tensor\"\"\"\n    tensor = tf.convert_to_tensor(value=array, dtype=CTYPE)\n    return tensor"
"def contains_extractor(document):\n    \"\"\"A basic document feature extractor that returns a dict of words that the\n    document contains.\"\"\"\n    tokens = _get_document_tokens(document)\n    features = dict((u'contains({0})'.format(w), True) for w in tokens)\n    return features"
"def min_max_normalize(img):\n    \"\"\"Centre and normalize a given array.\n\n    Parameters:\n    ----------\n    img: np.ndarray\n\n    \"\"\"\n\n    min_img = img.min()\n    max_img = img.max()\n\n    return (img - min_img) / (max_img - min_img)"
"def clean_dataframe(df):\n    \"\"\"Fill NaNs with the previous value, the next value or if all are NaN then 1.0\"\"\"\n    df = df.fillna(method='ffill')\n    df = df.fillna(0.0)\n    return df"
"def l2_norm(params):\n    \"\"\"Computes l2 norm of params by flattening them into a vector.\"\"\"\n    flattened, _ = flatten(params)\n    return np.dot(flattened, flattened)"
"def main(ctx, connection):\n    \"\"\"Command line interface for PyBEL.\"\"\"\n    ctx.obj = Manager(connection=connection)\n    ctx.obj.bind()"
"def isin(value, values):\n    \"\"\" Check that value is in values \"\"\"\n    for i, v in enumerate(value):\n        if v not in np.array(values)[:, i]:\n            return False\n    return True"
"def solr_to_date(d):\n    \"\"\" converts YYYY-MM-DDT00:00:00Z to DD-MM-YYYY \"\"\"\n    return \"{day}:{m}:{y}\".format(y=d[:4], m=d[5:7], day=d[8:10]) if d else d"
"def cat_acc(y_true, y_pred):\n    \"\"\"Categorical accuracy\n    \"\"\"\n    return np.mean(y_true.argmax(axis=1) == y_pred.argmax(axis=1))"
"def count_(self):\n        \"\"\"\n        Returns the number of rows of the main dataframe\n        \"\"\"\n        try:\n            num = len(self.df.index)\n        except Exception as e:\n            self.err(e, \"Can not count data\")\n            return\n        return num"
"def libpath(self):\n        \"\"\"Returns the full path to the shared *wrapper* library created for the\n        module.\n        \"\"\"\n        from os import path\n        return path.join(self.dirpath, self.libname)"
"def _visual_width(line):\n    \"\"\"Get the the number of columns required to display a string\"\"\"\n\n    return len(re.sub(colorama.ansitowin32.AnsiToWin32.ANSI_CSI_RE, \"\", line))"
"def create_opengl_object(gl_gen_function, n=1):\n    \"\"\"Returns int pointing to an OpenGL texture\"\"\"\n    handle = gl.GLuint(1)\n    gl_gen_function(n, byref(handle))  # Create n Empty Objects\n    if n > 1:\n        return [handle.value + el for el in range(n)]  # Return list of handle values\n    else:\n        return handle.value"
"def load_data(filename):\n    \"\"\"\n    :rtype : numpy matrix\n    \"\"\"\n    data = pandas.read_csv(filename, header=None, delimiter='\\t', skiprows=9)\n    return data.as_matrix()"
"def process_docstring(app, what, name, obj, options, lines):\n    \"\"\"React to a docstring event and append contracts to it.\"\"\"\n    # pylint: disable=unused-argument\n    # pylint: disable=too-many-arguments\n    lines.extend(_format_contracts(what=what, obj=obj))"
"def info(txt):\n    \"\"\"Print, emphasized 'neutral', the given 'txt' message\"\"\"\n\n    print(\"%s# %s%s%s\" % (PR_EMPH_CC, get_time_stamp(), txt, PR_NC))\n    sys.stdout.flush()"
"def zero_pad(m, n=1):\n    \"\"\"Pad a matrix with zeros, on all sides.\"\"\"\n    return np.pad(m, (n, n), mode='constant', constant_values=[0])"
"def logout():\n    \"\"\" Log out the active user\n    \"\"\"\n    flogin.logout_user()\n    next = flask.request.args.get('next')\n    return flask.redirect(next or flask.url_for(\"user\"))"
"def get_default_bucket_key(buckets: List[Tuple[int, int]]) -> Tuple[int, int]:\n    \"\"\"\n    Returns the default bucket from a list of buckets, i.e. the largest bucket.\n\n    :param buckets: List of buckets.\n    :return: The largest bucket in the list.\n    \"\"\"\n    return max(buckets)"
"def with_headers(self, headers):\n        \"\"\"Sets multiple headers on the request and returns the request itself.\n\n        Keyword arguments:\n        headers -- a dict-like object which contains the headers to set.\n        \"\"\"\n        for key, value in headers.items():\n            self.with_header(key, value)\n        return self"
"def raise_os_error(_errno, path=None):\n    \"\"\"\n    Helper for raising the correct exception under Python 3 while still\n    being able to raise the same common exception class in Python 2.7.\n    \"\"\"\n\n    msg = \"%s: '%s'\" % (strerror(_errno), path) if path else strerror(_errno)\n    raise OSError(_errno, msg)"
"def check(self, var):\n        \"\"\"Check whether the provided value is a valid enum constant.\"\"\"\n        if not isinstance(var, _str_type): return False\n        return _enum_mangle(var) in self._consts"
"def finish_plot():\n    \"\"\"Helper for plotting.\"\"\"\n    plt.legend()\n    plt.grid(color='0.7')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.show()"
"def _get_random_id():\n    \"\"\" Get a random (i.e., unique) string identifier\"\"\"\n    symbols = string.ascii_uppercase + string.ascii_lowercase + string.digits\n    return ''.join(random.choice(symbols) for _ in range(15))"
"def translate_fourier(image, dx):\n    \"\"\" Translate an image in fourier-space with plane waves \"\"\"\n    N = image.shape[0]\n\n    f = 2*np.pi*np.fft.fftfreq(N)\n    kx,ky,kz = np.meshgrid(*(f,)*3, indexing='ij')\n    kv = np.array([kx,ky,kz]).T\n\n    q = np.fft.fftn(image)*np.exp(-1.j*(kv*dx).sum(axis=-1)).T\n    return np.real(np.fft.ifftn(q))"
"def remove_prefix(text, prefix):\n\t\"\"\"\n\tRemove the prefix from the text if it exists.\n\n\t>>> remove_prefix('underwhelming performance', 'underwhelming ')\n\t'performance'\n\n\t>>> remove_prefix('something special', 'sample')\n\t'something special'\n\t\"\"\"\n\tnull, prefix, rest = text.rpartition(prefix)\n\treturn rest"
"def batch(items, size):\n    \"\"\"Batches a list into a list of lists, with sub-lists sized by a specified\n    batch size.\"\"\"\n    return [items[x:x + size] for x in xrange(0, len(items), size)]"
"def read_text_from_file(path: str) -> str:\n    \"\"\" Reads text file contents \"\"\"\n    with open(path) as text_file:\n        content = text_file.read()\n\n    return content"
"def _pip_exists(self):\n        \"\"\"Returns True if pip exists inside the virtual environment. Can be\n        used as a naive way to verify that the environment is installed.\"\"\"\n        return os.path.isfile(os.path.join(self.path, 'bin', 'pip'))"
"def extract_module_locals(depth=0):\n    \"\"\"Returns (module, locals) of the funciton `depth` frames away from the caller\"\"\"\n    f = sys._getframe(depth + 1)\n    global_ns = f.f_globals\n    module = sys.modules[global_ns['__name__']]\n    return (module, f.f_locals)"
"def FromString(self, string):\n    \"\"\"Parse a bool from a string.\"\"\"\n    if string.lower() in (\"false\", \"no\", \"n\"):\n      return False\n\n    if string.lower() in (\"true\", \"yes\", \"y\"):\n      return True\n\n    raise TypeValueError(\"%s is not recognized as a boolean value.\" % string)"
"def join(self):\n\t\t\"\"\"Note that the Executor must be close()'d elsewhere,\n\t\tor join() will never return.\n\t\t\"\"\"\n\t\tself.inputfeeder_thread.join()\n\t\tself.pool.join()\n\t\tself.resulttracker_thread.join()\n\t\tself.failuretracker_thread.join()"
"def str2bool(value):\n    \"\"\"Parse Yes/No/Default string\n    https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse\"\"\"\n    if value.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    if value.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    if value.lower() in ('d', 'default', ''):\n        return None\n    raise argparse.ArgumentTypeError('Expected: (Y)es/(T)rue/(N)o/(F)alse/(D)efault')"
"def us2mc(string):\n    \"\"\"Transform an underscore_case string to a mixedCase string\"\"\"\n    return re.sub(r'_([a-z])', lambda m: (m.group(1).upper()), string)"
"def lock_file(f, block=False):\n    \"\"\"\n    If block=False (the default), die hard and fast if another process has\n    already grabbed the lock for this file.\n\n    If block=True, wait for the lock to be released, then continue.\n    \"\"\"\n    try:\n        flags = fcntl.LOCK_EX\n        if not block:\n            flags |= fcntl.LOCK_NB\n        fcntl.flock(f.fileno(), flags)\n    except IOError as e:\n        if e.errno in (errno.EACCES, errno.EAGAIN):\n            raise SystemExit(\"ERROR: %s is locked by another process.\" %\n                             f.name)\n        raise"
"def dot_v3(v, w):\n    \"\"\"Return the dotproduct of two vectors.\"\"\"\n\n    return sum([x * y for x, y in zip(v, w)])"
"def fail(message=None, exit_status=None):\n    \"\"\"Prints the specified message and exits the program with the specified\n    exit status.\n\n    \"\"\"\n    print('Error:', message, file=sys.stderr)\n    sys.exit(exit_status or 1)"
"def gray2bgr(img):\n    \"\"\"Convert a grayscale image to BGR image.\n\n    Args:\n        img (ndarray or str): The input image.\n\n    Returns:\n        ndarray: The converted BGR image.\n    \"\"\"\n    img = img[..., None] if img.ndim == 2 else img\n    out_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    return out_img"
"def lpush(self, key, *args):\n        \"\"\"Emulate lpush.\"\"\"\n        redis_list = self._get_list(key, 'LPUSH', create=True)\n\n        # Creates the list at this key if it doesn't exist, and appends args to its beginning\n        args_reversed = [self._encode(arg) for arg in args]\n        args_reversed.reverse()\n        updated_list = args_reversed + redis_list\n        self.redis[self._encode(key)] = updated_list\n\n        # Return the length of the list after the push operation\n        return len(updated_list)"
"def _go_to_line(editor, line):\n    \"\"\"\n    Move cursor to this line in the current buffer.\n    \"\"\"\n    b = editor.application.current_buffer\n    b.cursor_position = b.document.translate_row_col_to_index(max(0, int(line) - 1), 0)"
"def service_available(service_name):\n    \"\"\"Determine whether a system service is available\"\"\"\n    try:\n        subprocess.check_output(\n            ['service', service_name, 'status'],\n            stderr=subprocess.STDOUT).decode('UTF-8')\n    except subprocess.CalledProcessError as e:\n        return b'unrecognized service' not in e.output\n    else:\n        return True"
"def isnamedtuple(obj):\n    \"\"\"Heuristic check if an object is a namedtuple.\"\"\"\n    return isinstance(obj, tuple) \\\n           and hasattr(obj, \"_fields\") \\\n           and hasattr(obj, \"_asdict\") \\\n           and callable(obj._asdict)"
"def heappop_max(heap):\n    \"\"\"Maxheap version of a heappop.\"\"\"\n    lastelt = heap.pop()    # raises appropriate IndexError if heap is empty\n    if heap:\n        returnitem = heap[0]\n        heap[0] = lastelt\n        _siftup_max(heap, 0)\n        return returnitem\n    return lastelt"
"def decompress(f):\n    \"\"\"Decompress a Plan 9 image file.  Assumes f is already cued past the\n    initial 'compressed\\n' string.\n    \"\"\"\n\n    r = meta(f.read(60))\n    return r, decomprest(f, r[4])"
"def schedule_task(self):\n        \"\"\"\n        Schedules this publish action as a Celery task.\n        \"\"\"\n        from .tasks import publish_task\n\n        publish_task.apply_async(kwargs={'pk': self.pk}, eta=self.scheduled_time)"
"def step_impl06(context):\n    \"\"\"Prepare test for singleton property.\n\n    :param context: test context.\n    \"\"\"\n    store = context.SingleStore\n    context.st_1 = store()\n    context.st_2 = store()\n    context.st_3 = store()"
"def timediff(time):\n    \"\"\"Return the difference in seconds between now and the given time.\"\"\"\n    now = datetime.datetime.utcnow()\n    diff = now - time\n    diff_sec = diff.total_seconds()\n    return diff_sec"
"def alter_change_column(self, table, column, field):\n        \"\"\"Support change columns.\"\"\"\n        return self._update_column(table, column, lambda a, b: b)"
"def denorm(self,arr):\n        \"\"\"Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        \"\"\"\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))"
"def valid_date(x: str) -> bool:\n    \"\"\"\n    Retrun ``True`` if ``x`` is a valid YYYYMMDD date;\n    otherwise return ``False``.\n    \"\"\"\n    try:\n        if x != dt.datetime.strptime(x, DATE_FORMAT).strftime(DATE_FORMAT):\n            raise ValueError\n        return True\n    except ValueError:\n        return False"
"def col_rename(df,col_name,new_col_name):\n    \"\"\" Changes a column name in a DataFrame\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_name - string\n        Name of column to change\n    new_col_name - string\n        New name of column\n    \"\"\"\n    col_list = list(df.columns)\n    for index,value in enumerate(col_list):\n        if value == col_name:\n            col_list[index] = new_col_name\n            break\n    df.columns = col_list"
"def stop(self) -> None:\n        \"\"\"Stops the analysis as soon as possible.\"\"\"\n        if self._stop and not self._posted_kork:\n            self._stop()\n            self._stop = None"
"def is_alive(self):\n        \"\"\"\n        @rtype:  bool\n        @return: C{True} if the process is currently running.\n        \"\"\"\n        try:\n            self.wait(0)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            return e.winerror == win32.WAIT_TIMEOUT\n        return False"
"def split_every(n, iterable):\n    \"\"\"Returns a generator that spits an iteratable into n-sized chunks. The last chunk may have\n    less than n elements.\n\n    See http://stackoverflow.com/a/22919323/503377.\"\"\"\n    items = iter(iterable)\n    return itertools.takewhile(bool, (list(itertools.islice(items, n)) for _ in itertools.count()))"
"def get_shape(img):\n    \"\"\"Return the shape of img.\n\n    Paramerers\n    -----------\n    img:\n\n    Returns\n    -------\n    shape: tuple\n    \"\"\"\n    if hasattr(img, 'shape'):\n        shape = img.shape\n    else:\n        shape = img.get_data().shape\n    return shape"
"def read_text_from_file(path: str) -> str:\n    \"\"\" Reads text file contents \"\"\"\n    with open(path) as text_file:\n        content = text_file.read()\n\n    return content"
"def gaussian_distribution(mean, stdev, num_pts=50):\n    \"\"\" get an x and y numpy.ndarray that spans the +/- 4\n    standard deviation range of a gaussian distribution with\n    a given mean and standard deviation. useful for plotting\n\n    Parameters\n    ----------\n    mean : float\n        the mean of the distribution\n    stdev : float\n        the standard deviation of the distribution\n    num_pts : int\n        the number of points in the returned ndarrays.\n        Default is 50\n\n    Returns\n    -------\n    x : numpy.ndarray\n        the x-values of the distribution\n    y : numpy.ndarray\n        the y-values of the distribution\n\n    \"\"\"\n    xstart = mean - (4.0 * stdev)\n    xend = mean + (4.0 * stdev)\n    x = np.linspace(xstart,xend,num_pts)\n    y = (1.0/np.sqrt(2.0*np.pi*stdev*stdev)) * np.exp(-1.0 * ((x - mean)**2)/(2.0*stdev*stdev))\n    return x,y"
"def _internet_on(address):\n    \"\"\"\n    Check to see if the internet is on by pinging a set address.\n    :param address: the IP or address to hit\n    :return: a boolean - true if can be reached, false if not.\n    \"\"\"\n    try:\n        urllib2.urlopen(address, timeout=1)\n        return True\n    except urllib2.URLError as err:\n        return False"
"def apply(f, obj, *args, **kwargs):\n    \"\"\"Apply a function in parallel to each element of the input\"\"\"\n    return vectorize(f)(obj, *args, **kwargs)"
"def top_1_tpu(inputs):\n  \"\"\"find max and argmax over the last dimension.\n\n  Works well on TPU\n\n  Args:\n    inputs: A tensor with shape [..., depth]\n\n  Returns:\n    values: a Tensor with shape [...]\n    indices: a Tensor with shape [...]\n  \"\"\"\n  inputs_max = tf.reduce_max(inputs, axis=-1, keepdims=True)\n  mask = tf.to_int32(tf.equal(inputs_max, inputs))\n  index = tf.range(tf.shape(inputs)[-1]) * mask\n  return tf.squeeze(inputs_max, -1), tf.reduce_max(index, axis=-1)"
"def mixedcase(path):\n    \"\"\"Removes underscores and capitalizes the neighbouring character\"\"\"\n    words = path.split('_')\n    return words[0] + ''.join(word.title() for word in words[1:])"
"def update_not_existing_kwargs(to_update, update_from):\n    \"\"\"\n    This function updates the keyword aguments from update_from in\n    to_update, only if the keys are not set in to_update.\n\n    This is used for updated kwargs from the default dicts.\n    \"\"\"\n    if to_update is None:\n        to_update = {}\n    to_update.update({k:v for k,v in update_from.items() if k not in to_update})\n    return to_update"
"def fast_median(a):\n    \"\"\"Fast median operation for masked array using 50th-percentile\n    \"\"\"\n    a = checkma(a)\n    #return scoreatpercentile(a.compressed(), 50)\n    if a.count() > 0:\n        out = np.percentile(a.compressed(), 50)\n    else:\n        out = np.ma.masked\n    return out"
"def cell_ends_with_code(lines):\n    \"\"\"Is the last line of the cell a line with code?\"\"\"\n    if not lines:\n        return False\n    if not lines[-1].strip():\n        return False\n    if lines[-1].startswith('#'):\n        return False\n    return True"
"def csv_to_numpy(string_like, dtype=None):  # type: (str) -> np.array\n    \"\"\"Convert a CSV object to a numpy array.\n\n    Args:\n        string_like (str): CSV string.\n        dtype (dtype, optional):  Data type of the resulting array. If None, the dtypes will be determined by the\n                                        contents of each column, individually. This argument can only be used to\n                                        'upcast' the array.  For downcasting, use the .astype(t) method.\n    Returns:\n        (np.array): numpy array\n    \"\"\"\n    stream = StringIO(string_like)\n    return np.genfromtxt(stream, dtype=dtype, delimiter=',')"
"def is_clicked(self, MouseStateType):\n        \"\"\"\n        Did the user depress and release the button to signify a click?\n        MouseStateType is the button to query. Values found under StateTypes.py\n        \"\"\"\n        return self.previous_mouse_state.query_state(MouseStateType) and (\n        not self.current_mouse_state.query_state(MouseStateType))"
"def isetdiff_flags(list1, list2):\n    \"\"\"\n    move to util_iter\n    \"\"\"\n    set2 = set(list2)\n    return (item not in set2 for item in list1)"
"def process_docstring(app, what, name, obj, options, lines):\n    \"\"\"React to a docstring event and append contracts to it.\"\"\"\n    # pylint: disable=unused-argument\n    # pylint: disable=too-many-arguments\n    lines.extend(_format_contracts(what=what, obj=obj))"
"def other_ind(self):\n        \"\"\"last row or column of square A\"\"\"\n        return np.full(self.n_min, self.size - 1, dtype=np.int)"
"def money(min=0, max=10):\n    \"\"\"Return a str of decimal with two digits after a decimal mark.\"\"\"\n    value = random.choice(range(min * 100, max * 100))\n    return \"%1.2f\" % (float(value) / 100)"
"def split_multiline(value):\n    \"\"\"Split a multiline string into a list, excluding blank lines.\"\"\"\n    return [element for element in (line.strip() for line in value.split('\\n'))\n            if element]"
"def plot(self):\n        \"\"\"Plot the empirical histogram versus best-fit distribution's PDF.\"\"\"\n        plt.plot(self.bin_edges, self.hist, self.bin_edges, self.best_pdf)"
"def create_task(coro, loop):\n    # pragma: no cover\n    \"\"\"Compatibility wrapper for the loop.create_task() call introduced in\n    3.4.2.\"\"\"\n    if hasattr(loop, 'create_task'):\n        return loop.create_task(coro)\n    return asyncio.Task(coro, loop=loop)"
"def launched():\n    \"\"\"Test whether the current python environment is the correct lore env.\n\n    :return:  :any:`True` if the environment is launched\n    :rtype: bool\n    \"\"\"\n    if not PREFIX:\n        return False\n\n    return os.path.realpath(sys.prefix) == os.path.realpath(PREFIX)"
"def stringToDate(fmt=\"%Y-%m-%d\"):\n    \"\"\"returns a function to convert a string to a datetime.date instance\n    using the formatting string fmt as in time.strftime\"\"\"\n    import time\n    import datetime\n    def conv_func(s):\n        return datetime.date(*time.strptime(s,fmt)[:3])\n    return conv_func"
"def unique(_list):\n    \"\"\"\n    Makes the list have unique items only and maintains the order\n\n    list(set()) won't provide that\n\n    :type _list list\n    :rtype: list\n    \"\"\"\n    ret = []\n\n    for item in _list:\n        if item not in ret:\n            ret.append(item)\n\n    return ret"
"def get_default_bucket_key(buckets: List[Tuple[int, int]]) -> Tuple[int, int]:\n    \"\"\"\n    Returns the default bucket from a list of buckets, i.e. the largest bucket.\n\n    :param buckets: List of buckets.\n    :return: The largest bucket in the list.\n    \"\"\"\n    return max(buckets)"
"def ver_to_tuple(value):\n    \"\"\"\n    Convert version like string to a tuple of integers.\n    \"\"\"\n    return tuple(int(_f) for _f in re.split(r'\\D+', value) if _f)"
"def lastmod(self, author):\n        \"\"\"Return the last modification of the entry.\"\"\"\n        lastitems = EntryModel.objects.published().order_by('-modification_date').filter(author=author).only('modification_date')\n        return lastitems[0].modification_date"
"def run_tests(self):\n\t\t\"\"\"\n\t\tInvoke pytest, replacing argv. Return result code.\n\t\t\"\"\"\n\t\twith _save_argv(_sys.argv[:1] + self.addopts):\n\t\t\tresult_code = __import__('pytest').main()\n\t\t\tif result_code:\n\t\t\t\traise SystemExit(result_code)"
"def is_subdir(a, b):\n    \"\"\"\n    Return true if a is a subdirectory of b\n    \"\"\"\n    a, b = map(os.path.abspath, [a, b])\n\n    return os.path.commonpath([a, b]) == b"
"def get_order(self, codes):\n        \"\"\"Return evidence codes in order shown in code2name.\"\"\"\n        return sorted(codes, key=lambda e: [self.ev2idx.get(e)])"
"def cprint(string, fg=None, bg=None, end='\\n', target=sys.stdout):\n    \"\"\"Print a colored string to the target handle.\n\n    fg and bg specify foreground- and background colors, respectively. The\n    remaining keyword arguments are the same as for Python's built-in print\n    function. Colors are returned to their defaults before the function\n    returns.\n\n    \"\"\"\n    _color_manager.set_color(fg, bg)\n    target.write(string + end)\n    target.flush()  # Needed for Python 3.x\n    _color_manager.set_defaults()"
"def store_many(self, sql, values):\n        \"\"\"Abstraction over executemany method\"\"\"\n        cursor = self.get_cursor()\n        cursor.executemany(sql, values)\n        self.conn.commit()"
"def split_string(text, chars_per_string):\n    \"\"\"\n    Splits one string into multiple strings, with a maximum amount of `chars_per_string` characters per string.\n    This is very useful for splitting one giant message into multiples.\n\n    :param text: The text to split\n    :param chars_per_string: The number of characters per line the text is split into.\n    :return: The splitted text as a list of strings.\n    \"\"\"\n    return [text[i:i + chars_per_string] for i in range(0, len(text), chars_per_string)]"
"def Output(self):\n    \"\"\"Output all sections of the page.\"\"\"\n    self.Open()\n    self.Header()\n    self.Body()\n    self.Footer()"
"def inverse_jacobian(self, maps):\n        \"\"\"Returns the Jacobian for transforming mass1 and mass2 to\n        mchirp and eta.\n        \"\"\"\n        m1 = maps[parameters.mass1]\n        m2 = maps[parameters.mass2]\n        mchirp = conversions.mchirp_from_mass1_mass2(m1, m2)\n        eta = conversions.eta_from_mass1_mass2(m1, m2)\n        return -1. * mchirp / eta**(6./5)"
"def format_result(input):\n        \"\"\"From: http://stackoverflow.com/questions/13062300/convert-a-dict-to-sorted-dict-in-python\n        \"\"\"\n        items = list(iteritems(input))\n        return OrderedDict(sorted(items, key=lambda x: x[0]))"
"def is_valid_variable_name(string_to_check):\n    \"\"\"\n    Returns whether the provided name is a valid variable name in Python\n\n    :param string_to_check: the string to be checked\n    :return: True or False\n    \"\"\"\n\n    try:\n\n        parse('{} = None'.format(string_to_check))\n        return True\n\n    except (SyntaxError, ValueError, TypeError):\n\n        return False"
"def covariance(self,pt0,pt1):\n        \"\"\" get the covarince between two points implied by Vario2d\n\n        Parameters\n        ----------\n        pt0 : (iterable of len 2)\n            first point x and y\n        pt1 : (iterable of len 2)\n            second point x and y\n\n        Returns\n        -------\n        cov : float\n            covariance between pt0 and pt1\n\n        \"\"\"\n\n        x = np.array([pt0[0],pt1[0]])\n        y = np.array([pt0[1],pt1[1]])\n        names = [\"n1\",\"n2\"]\n        return self.covariance_matrix(x,y,names=names).x[0,1]"
"def is_orthogonal(\n        matrix: np.ndarray,\n        *,\n        rtol: float = 1e-5,\n        atol: float = 1e-8) -> bool:\n    \"\"\"Determines if a matrix is approximately orthogonal.\n\n    A matrix is orthogonal if it's square and real and its transpose is its\n    inverse.\n\n    Args:\n        matrix: The matrix to check.\n        rtol: The per-matrix-entry relative tolerance on equality.\n        atol: The per-matrix-entry absolute tolerance on equality.\n\n    Returns:\n        Whether the matrix is orthogonal within the given tolerance.\n    \"\"\"\n    return (matrix.shape[0] == matrix.shape[1] and\n            np.all(np.imag(matrix) == 0) and\n            np.allclose(matrix.dot(matrix.T), np.eye(matrix.shape[0]),\n                        rtol=rtol,\n                        atol=atol))"
"def requests_post(url, data=None, json=None, **kwargs):\n    \"\"\"Requests-mock requests.post wrapper.\"\"\"\n    return requests_request('post', url, data=data, json=json, **kwargs)"
"def set_json_item(key, value):\n    \"\"\" manipulate json data on the fly\n    \"\"\"\n    data = get_json()\n    data[key] = value\n\n    request = get_request()\n    request[\"BODY\"] = json.dumps(data)"
"def shot_noise(x, severity=1):\n  \"\"\"Shot noise corruption to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added shot noise.\n  \"\"\"\n  c = [60, 25, 12, 5, 3][severity - 1]\n  x = np.array(x) / 255.\n  x_clip = np.clip(np.random.poisson(x * c) / float(c), 0, 1) * 255\n  return around_and_astype(x_clip)"
"def timeit(func, *args, **kwargs):\n    \"\"\"\n    Time execution of function. Returns (res, seconds).\n\n    >>> res, timing = timeit(time.sleep, 1)\n    \"\"\"\n    start_time = time.time()\n    res = func(*args, **kwargs)\n    timing = time.time() - start_time\n    return res, timing"
"def energy_string_to_float( string ):\n    \"\"\"\n    Convert a string of a calculation energy, e.g. '-1.2345 eV' to a float.\n\n    Args:\n        string (str): The string to convert.\n  \n    Return\n        (float) \n    \"\"\"\n    energy_re = re.compile( \"(-?\\d+\\.\\d+)\" )\n    return float( energy_re.match( string ).group(0) )"
"def cfloat64_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes double pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):\n        return np.fromiter(cptr, dtype=np.float64, count=length)\n    else:\n        raise RuntimeError('Expected double pointer')"
"def from_file(filename):\n    \"\"\"\n    load an nparray object from a json filename\n\n    @parameter str filename: path to the file\n    \"\"\"\n    f = open(filename, 'r')\n    j = json.load(f)\n    f.close()\n\n    return from_dict(j)"
"def cross_join(df1, df2):\n    \"\"\"\n    Return a dataframe that is a cross between dataframes\n    df1 and df2\n\n    ref: https://github.com/pydata/pandas/issues/5401\n    \"\"\"\n    if len(df1) == 0:\n        return df2\n\n    if len(df2) == 0:\n        return df1\n\n    # Add as lists so that the new index keeps the items in\n    # the order that they are added together\n    all_columns = pd.Index(list(df1.columns) + list(df2.columns))\n    df1['key'] = 1\n    df2['key'] = 1\n    return pd.merge(df1, df2, on='key').loc[:, all_columns]"
"def escape_link(url):\n    \"\"\"Remove dangerous URL schemes like javascript: and escape afterwards.\"\"\"\n    lower_url = url.lower().strip('\\x00\\x1a \\n\\r\\t')\n    for scheme in _scheme_blacklist:\n        if lower_url.startswith(scheme):\n            return ''\n    return escape(url, quote=True, smart_amp=False)"
"def timed (log=sys.stderr, limit=2.0):\n    \"\"\"Decorator to run a function with timing info.\"\"\"\n    return lambda func: timeit(func, log, limit)"
"def yaml_to_param(obj, name):\n\t\"\"\"\n\tReturn the top-level element of a document sub-tree containing the\n\tYAML serialization of a Python object.\n\t\"\"\"\n\treturn from_pyvalue(u\"yaml:%s\" % name, unicode(yaml.dump(obj)))"
"def _clear(self):\n        \"\"\"Resets all assigned data for the current message.\"\"\"\n        self._finished = False\n        self._measurement = None\n        self._message = None\n        self._message_body = None"
"def pickle_save(thing,fname):\n    \"\"\"save something to a pickle file\"\"\"\n    pickle.dump(thing, open(fname,\"wb\"),pickle.HIGHEST_PROTOCOL)\n    return thing"
"def xor(a, b):\n        \"\"\"Bitwise xor on equal length bytearrays.\"\"\"\n        return bytearray(i ^ j for i, j in zip(a, b))"
"def __hash__(self):\n        \"\"\"Return ``hash(self)``.\"\"\"\n        return hash((type(self), self.domain, self.range, self.partition))"
"def erase_lines(n=1):\n    \"\"\" Erases n lines from the screen and moves the cursor up to follow\n    \"\"\"\n    for _ in range(n):\n        print(codes.cursor[\"up\"], end=\"\")\n        print(codes.cursor[\"eol\"], end=\"\")"
"def type_converter(text):\n    \"\"\" I convert strings into integers, floats, and strings! \"\"\"\n    if text.isdigit():\n        return int(text), int\n\n    try:\n        return float(text), float\n    except ValueError:\n        return text, STRING_TYPE"
"def _config_win32_domain(self, domain):\n        \"\"\"Configure a Domain registry entry.\"\"\"\n        # we call str() on domain to convert it from unicode to ascii\n        self.domain = dns.name.from_text(str(domain))"
"def load_yaml(filepath):\n    \"\"\"Convenience function for loading yaml-encoded data from disk.\"\"\"\n    with open(filepath) as f:\n        txt = f.read()\n    return yaml.load(txt)"
"def get_longest_orf(orfs):\n    \"\"\"Find longest ORF from the given list of ORFs.\"\"\"\n    sorted_orf = sorted(orfs, key=lambda x: len(x['sequence']), reverse=True)[0]\n    return sorted_orf"
"def _digits(minval, maxval):\n    \"\"\"Digits needed to comforatbly display values in [minval, maxval]\"\"\"\n    if minval == maxval:\n        return 3\n    else:\n        return min(10, max(2, int(1 + abs(np.log10(maxval - minval)))))"
"def clean(self, text):\n        \"\"\"Remove all unwanted characters from text.\"\"\"\n        return ''.join([c for c in text if c in self.alphabet])"
"def batch(items, size):\n    \"\"\"Batches a list into a list of lists, with sub-lists sized by a specified\n    batch size.\"\"\"\n    return [items[x:x + size] for x in xrange(0, len(items), size)]"
"def file_writelines_flush_sync(path, lines):\n    \"\"\"\n    Fill file at @path with @lines then flush all buffers\n    (Python and system buffers)\n    \"\"\"\n    fp = open(path, 'w')\n    try:\n        fp.writelines(lines)\n        flush_sync_file_object(fp)\n    finally:\n        fp.close()"
"def is_element_present(driver, selector, by=By.CSS_SELECTOR):\n    \"\"\"\n    Returns whether the specified element selector is present on the page.\n    @Params\n    driver - the webdriver object (required)\n    selector - the locator that is used (required)\n    by - the method to search for the locator (Default: By.CSS_SELECTOR)\n    @Returns\n    Boolean (is element present)\n    \"\"\"\n    try:\n        driver.find_element(by=by, value=selector)\n        return True\n    except Exception:\n        return False"
"def _encode_bool(name, value, dummy0, dummy1):\n    \"\"\"Encode a python boolean (True/False).\"\"\"\n    return b\"\\x08\" + name + (value and b\"\\x01\" or b\"\\x00\")"
"def rate_limited(max_per_hour: int, *args: Any) -> Callable[..., Any]:\n    \"\"\"Rate limit a function.\"\"\"\n    return util.rate_limited(max_per_hour, *args)"
"def get_adjacent_matrix(self):\n        \"\"\"Get adjacency matrix.\n\n        Returns:\n            :param adj: adjacency matrix\n            :type adj: np.ndarray\n        \"\"\"\n        edges = self.edges\n        num_edges = len(edges) + 1\n        adj = np.zeros([num_edges, num_edges])\n\n        for k in range(num_edges - 1):\n            adj[edges[k].L, edges[k].R] = 1\n            adj[edges[k].R, edges[k].L] = 1\n\n        return adj"
"def fast_distinct(self):\n        \"\"\"\n        Because standard distinct used on the all fields are very slow and works only with PostgreSQL database\n        this method provides alternative to the standard distinct method.\n        :return: qs with unique objects\n        \"\"\"\n        return self.model.objects.filter(pk__in=self.values_list('pk', flat=True))"
"def __get_xml_text(root):\n    \"\"\" Return the text for the given root node (xml.dom.minidom). \"\"\"\n    txt = \"\"\n    for e in root.childNodes:\n        if (e.nodeType == e.TEXT_NODE):\n            txt += e.data\n    return txt"
"def remove_last_entry(self):\n        \"\"\"Remove the last NoteContainer in the Bar.\"\"\"\n        self.current_beat -= 1.0 / self.bar[-1][1]\n        self.bar = self.bar[:-1]\n        return self.current_beat"
"def connected_socket(address, timeout=3):\n    \"\"\" yields a connected socket \"\"\"\n    sock = socket.create_connection(address, timeout)\n    yield sock\n    sock.close()"
"def main(idle):\n    \"\"\"Any normal python logic which runs a loop. Can take arguments.\"\"\"\n    while True:\n\n        LOG.debug(\"Sleeping for {0} seconds.\".format(idle))\n        time.sleep(idle)"
"def is_iter_non_string(obj):\n    \"\"\"test if object is a list or tuple\"\"\"\n    if isinstance(obj, list) or isinstance(obj, tuple):\n        return True\n    return False"
"def full(self):\n        \"\"\"Return True if the queue is full\"\"\"\n        if not self.size: return False\n        return len(self.pq) == (self.size + self.removed_count)"
"def parse_comments_for_file(filename):\n    \"\"\"\n    Return a list of all parsed comments in a file.  Mostly for testing &\n    interactive use.\n    \"\"\"\n    return [parse_comment(strip_stars(comment), next_line)\n            for comment, next_line in get_doc_comments(read_file(filename))]"
"def palettebar(height, length, colormap):\n    \"\"\"Return the channels of a palettebar.\n    \"\"\"\n    cbar = np.tile(np.arange(length) * 1.0 / (length - 1), (height, 1))\n    cbar = (cbar * (colormap.values.max() + 1 - colormap.values.min())\n            + colormap.values.min())\n\n    return colormap.palettize(cbar)"
"def str2int(num, radix=10, alphabet=BASE85):\n    \"\"\"helper function for quick base conversions from strings to integers\"\"\"\n    return NumConv(radix, alphabet).str2int(num)"
"def help(self, level=0):\n        \"\"\"return the usage string for available options \"\"\"\n        self.cmdline_parser.formatter.output_level = level\n        with _patch_optparse():\n            return self.cmdline_parser.format_help()"
"def line_count(fn):\n    \"\"\" Get line count of file\n\n    Args:\n        fn (str): Path to file\n\n    Return:\n          Number of lines in file (int)\n    \"\"\"\n\n    with open(fn) as f:\n        for i, l in enumerate(f):\n            pass\n    return i + 1"
"def __setitem__(self, field, value):\n        \"\"\" :see::meth:RedisMap.__setitem__ \"\"\"\n        return self._client.hset(self.key_prefix, field, self._dumps(value))"
"def get_list_index(lst, index_or_name):\n    \"\"\"\n    Return the index of an element in the list.\n\n    Args:\n        lst (list): The list.\n        index_or_name (int or str): The value of the reference element, or directly its numeric index.\n\n    Returns:\n        (int) The index of the element in the list.\n    \"\"\"\n    if isinstance(index_or_name, six.integer_types):\n        return index_or_name\n\n    return lst.index(index_or_name)"
"def activate_subplot(numPlot):\n    \"\"\"Make subplot *numPlot* active on the canvas.\n\n    Use this if a simple ``subplot(numRows, numCols, numPlot)``\n    overwrites the subplot instead of activating it.\n    \"\"\"\n    # see http://www.mail-archive.com/matplotlib-users@lists.sourceforge.net/msg07156.html\n    from pylab import gcf, axes\n    numPlot -= 1  # index is 0-based, plots are 1-based\n    return axes(gcf().get_axes()[numPlot])"
"def downsample_with_striding(array, factor):\n    \"\"\"Downsample x by factor using striding.\n\n    @return: The downsampled array, of the same type as x.\n    \"\"\"\n    return array[tuple(np.s_[::f] for f in factor)]"
"def check_dependency(self, dependency_path):\n        \"\"\"Check if mtime of dependency_path is greater than stored mtime.\"\"\"\n        stored_hash = self._stamp_file_hashes.get(dependency_path)\n\n        # This file was newly added, or we don't have a file\n        # with stored hashes yet. Assume out of date.\n        if not stored_hash:\n            return False\n\n        return stored_hash == _sha1_for_file(dependency_path)"
"def min_max_normalize(img):\n    \"\"\"Centre and normalize a given array.\n\n    Parameters:\n    ----------\n    img: np.ndarray\n\n    \"\"\"\n\n    min_img = img.min()\n    max_img = img.max()\n\n    return (img - min_img) / (max_img - min_img)"
"def starts_with_prefix_in_list(text, prefixes):\n    \"\"\"\n    Return True if the given string starts with one of the prefixes in the given list, otherwise\n    return False.\n\n    Arguments:\n        text (str): Text to check for prefixes.\n        prefixes (list): List of prefixes to check for.\n\n    Returns:\n        bool: True if the given text starts with any of the given prefixes, otherwise False.\n    \"\"\"\n    for prefix in prefixes:\n        if text.startswith(prefix):\n            return True\n    return False"
"def _dict(content):\n    \"\"\"\n    Helper funcation that converts text-based get response\n    to a python dictionary for additional manipulation.\n    \"\"\"\n    if _has_pandas:\n        data = _data_frame(content).to_dict(orient='records')\n    else:\n        response = loads(content)\n        key = [x for x in response.keys() if x in c.response_data][0]\n        data = response[key]\n    return data"
"def debug(self, text):\n\t\t\"\"\" Ajout d'un message de log de type DEBUG \"\"\"\n\t\tself.logger.debug(\"{}{}\".format(self.message_prefix, text))"
"def boolean(value):\n    \"\"\"\n    Configuration-friendly boolean type converter.\n\n    Supports both boolean-valued and string-valued inputs (e.g. from env vars).\n\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n\n    if value == \"\":\n        return False\n\n    return strtobool(value)"
"def parse_datetime(dt_str):\n    \"\"\"Parse datetime.\"\"\"\n    date_format = \"%Y-%m-%dT%H:%M:%S %z\"\n    dt_str = dt_str.replace(\"Z\", \" +0000\")\n    return datetime.datetime.strptime(dt_str, date_format)"
"def long_substr(data):\n    \"\"\"Return the longest common substring in a list of strings.\n    \n    Credit: http://stackoverflow.com/questions/2892931/longest-common-substring-from-more-than-two-strings-python\n    \"\"\"\n    substr = ''\n    if len(data) > 1 and len(data[0]) > 0:\n        for i in range(len(data[0])):\n            for j in range(len(data[0])-i+1):\n                if j > len(substr) and all(data[0][i:i+j] in x for x in data):\n                    substr = data[0][i:i+j]\n    elif len(data) == 1:\n        substr = data[0]\n    return substr"
"def __del__(self):\n        \"\"\"Frees all resources.\n        \"\"\"\n        if hasattr(self, '_Api'):\n            self._Api.close()\n\n        self._Logger.info('object destroyed')"
"async def wait_and_quit(loop):\n\t\"\"\"Wait until all task are executed.\"\"\"\n\tfrom pylp.lib.tasks import running\n\tif running:\n\t\tawait asyncio.wait(map(lambda runner: runner.future, running))"
"def reconnect(self):\n        \"\"\"Reconnect to rabbitmq server\"\"\"\n        import pika\n        import pika.exceptions\n\n        self.connection = pika.BlockingConnection(pika.URLParameters(self.amqp_url))\n        self.channel = self.connection.channel()\n        try:\n            self.channel.queue_declare(self.name)\n        except pika.exceptions.ChannelClosed:\n            self.connection = pika.BlockingConnection(pika.URLParameters(self.amqp_url))\n            self.channel = self.connection.channel()"
"def require_root(fn):\n    \"\"\"\n    Decorator to make sure, that user is root.\n    \"\"\"\n    @wraps(fn)\n    def xex(*args, **kwargs):\n        assert os.geteuid() == 0, \\\n            \"You have to be root to run function '%s'.\" % fn.__name__\n        return fn(*args, **kwargs)\n\n    return xex"
"def _my_hash(arg_list):\n    # type: (List[Any]) -> int\n    \"\"\"Simple helper hash function\"\"\"\n    res = 0\n    for arg in arg_list:\n        res = res * 31 + hash(arg)\n    return res"
"def is_timestamp(obj):\n    \"\"\"\n    Yaml either have automatically converted it to a datetime object\n    or it is a string that will be validated later.\n    \"\"\"\n    return isinstance(obj, datetime.datetime) or is_string(obj) or is_int(obj) or is_float(obj)"
"def multi_replace(instr, search_list=[], repl_list=None):\n    \"\"\"\n    Does a string replace with a list of search and replacements\n\n    TODO: rename\n    \"\"\"\n    repl_list = [''] * len(search_list) if repl_list is None else repl_list\n    for ser, repl in zip(search_list, repl_list):\n        instr = instr.replace(ser, repl)\n    return instr"
"def fn_abs(self, value):\n        \"\"\"\n        Return the absolute value of a number.\n\n        :param value: The number.\n        :return: The absolute value of the number.\n        \"\"\"\n\n        if is_ndarray(value):\n            return numpy.absolute(value)\n        else:\n            return abs(value)"
"def unique(iterable):\n    \"\"\" Returns a list copy in which each item occurs only once (in-order).\n    \"\"\"\n    seen = set()\n    return [x for x in iterable if x not in seen and not seen.add(x)]"
"def dotproduct(X, Y):\n    \"\"\"Return the sum of the element-wise product of vectors x and y.\n    >>> dotproduct([1, 2, 3], [1000, 100, 10])\n    1230\n    \"\"\"\n    return sum([x * y for x, y in zip(X, Y)])"
"def count_list(the_list):\n    \"\"\"\n    Generates a count of the number of times each unique item appears in a list\n    \"\"\"\n    count = the_list.count\n    result = [(item, count(item)) for item in set(the_list)]\n    result.sort()\n    return result"
"def matches(self, s):\n    \"\"\"Whether the pattern matches anywhere in the string s.\"\"\"\n    regex_matches = self.compiled_regex.search(s) is not None\n    return not regex_matches if self.inverted else regex_matches"
"def iter_with_last(iterable):\n    \"\"\"\n    :return: generator of tuples (isLastFlag, item)\n    \"\"\"\n    # Ensure it's an iterator and get the first field\n    iterable = iter(iterable)\n    prev = next(iterable)\n    for item in iterable:\n        # Lag by one item so I know I'm not at the end\n        yield False, prev\n        prev = item\n    # Last item\n    yield True, prev"
"def b(s):\n\t\"\"\" Encodes Unicode strings to byte strings, if necessary. \"\"\"\n\n\treturn s if isinstance(s, bytes) else s.encode(locale.getpreferredencoding())"
"def _columns_for_table(table_name):\n    \"\"\"\n    Return all of the columns registered for a given table.\n\n    Parameters\n    ----------\n    table_name : str\n\n    Returns\n    -------\n    columns : dict of column wrappers\n        Keys will be column names.\n\n    \"\"\"\n    return {cname: col\n            for (tname, cname), col in _COLUMNS.items()\n            if tname == table_name}"
"def get_order(self, codes):\n        \"\"\"Return evidence codes in order shown in code2name.\"\"\"\n        return sorted(codes, key=lambda e: [self.ev2idx.get(e)])"
"def caller_locals():\n    \"\"\"Get the local variables in the caller's frame.\"\"\"\n    import inspect\n    frame = inspect.currentframe()\n    try:\n        return frame.f_back.f_back.f_locals\n    finally:\n        del frame"
"def last_location_of_minimum(x):\n    \"\"\"\n    Returns the last location of the minimal value of x.\n    The position is calculated relatively to the length of x.\n\n    :param x: the time series to calculate the feature of\n    :type x: numpy.ndarray\n    :return: the value of this feature\n    :return type: float\n    \"\"\"\n    x = np.asarray(x)\n    return 1.0 - np.argmin(x[::-1]) / len(x) if len(x) > 0 else np.NaN"
"def timed (log=sys.stderr, limit=2.0):\n    \"\"\"Decorator to run a function with timing info.\"\"\"\n    return lambda func: timeit(func, log, limit)"
"def flatten_multidict(multidict):\n    \"\"\"Return flattened dictionary from ``MultiDict``.\"\"\"\n    return dict([(key, value if len(value) > 1 else value[0])\n                 for (key, value) in multidict.iterlists()])"
"def skip_connection_distance(a, b):\n    \"\"\"The distance between two skip-connections.\"\"\"\n    if a[2] != b[2]:\n        return 1.0\n    len_a = abs(a[1] - a[0])\n    len_b = abs(b[1] - b[0])\n    return (abs(a[0] - b[0]) + abs(len_a - len_b)) / (max(a[0], b[0]) + max(len_a, len_b))"
"def get_hline():\n    \"\"\" gets a horiztonal line \"\"\"\n    return Window(\n        width=LayoutDimension.exact(1),\n        height=LayoutDimension.exact(1),\n        content=FillControl('-', token=Token.Line))"
"def setup_detect_python2():\n        \"\"\"\n        Call this before using the refactoring tools to create them on demand\n        if needed.\n        \"\"\"\n        if None in [RTs._rt_py2_detect, RTs._rtp_py2_detect]:\n            RTs._rt_py2_detect = RefactoringTool(py2_detect_fixers)\n            RTs._rtp_py2_detect = RefactoringTool(py2_detect_fixers,\n                                                  {'print_function': True})"
"def mean(inlist):\n    \"\"\"\nReturns the arithematic mean of the values in the passed list.\nAssumes a '1D' list, but will function on the 1st dim of an array(!).\n\nUsage:   lmean(inlist)\n\"\"\"\n    sum = 0\n    for item in inlist:\n        sum = sum + item\n    return sum / float(len(inlist))"
"def on_close(self, evt):\n    \"\"\"\n    Pop-up menu and wx.EVT_CLOSE closing event\n    \"\"\"\n    self.stop() # DoseWatcher\n    if evt.EventObject is not self: # Avoid deadlocks\n      self.Close() # wx.Frame\n    evt.Skip()"
"def filter_dict(d, keys):\n    \"\"\"\n    Creates a new dict from an existing dict that only has the given keys\n    \"\"\"\n    return {k: v for k, v in d.items() if k in keys}"
"def command(self, cmd, *args):\n        \"\"\"\n        Sends a command and an (optional) sequence of arguments through to the\n        delegated serial interface. Note that the arguments are passed through\n        as data.\n        \"\"\"\n        self._serial_interface.command(cmd)\n        if len(args) > 0:\n            self._serial_interface.data(list(args))"
"def multiple_replace(string, replacements):\n    # type: (str, Dict[str,str]) -> str\n    \"\"\"Simultaneously replace multiple strigns in a string\n\n    Args:\n        string (str): Input string\n        replacements (Dict[str,str]): Replacements dictionary\n\n    Returns:\n        str: String with replacements\n\n    \"\"\"\n    pattern = re.compile(\"|\".join([re.escape(k) for k in sorted(replacements, key=len, reverse=True)]), flags=re.DOTALL)\n    return pattern.sub(lambda x: replacements[x.group(0)], string)"
"def __del__(self):\n        \"\"\"Frees all resources.\n        \"\"\"\n        if hasattr(self, '_Api'):\n            self._Api.close()\n\n        self._Logger.info('object destroyed')"
"def getCollectDServer(queue, cfg):\n    \"\"\"Get the appropriate collectd server (multi processed or not)\"\"\"\n    server = CollectDServerMP if cfg.collectd_workers > 1 else CollectDServer\n    return server(queue, cfg)"
"def IsBinary(self, filename):\n\t\t\"\"\"Returns true if the guessed mimetyped isnt't in text group.\"\"\"\n\t\tmimetype = mimetypes.guess_type(filename)[0]\n\t\tif not mimetype:\n\t\t\treturn False  # e.g. README, \"real\" binaries usually have an extension\n\t\t# special case for text files which don't start with text/\n\t\tif mimetype in TEXT_MIMETYPES:\n\t\t\treturn False\n\t\treturn not mimetype.startswith(\"text/\")"
"def find_le(a, x):\n    \"\"\"Find rightmost value less than or equal to x.\"\"\"\n    i = bs.bisect_right(a, x)\n    if i: return i - 1\n    raise ValueError"
"def py3round(number):\n    \"\"\"Unified rounding in all python versions.\"\"\"\n    if abs(round(number) - number) == 0.5:\n        return int(2.0 * round(number / 2.0))\n\n    return int(round(number))"
"def checkbox_uncheck(self, force_check=False):\n        \"\"\"\n        Wrapper to uncheck a checkbox\n        \"\"\"\n        if self.get_attribute('checked'):\n            self.click(force_click=force_check)"
"def ranges_to_set(lst):\n    \"\"\"\n    Convert a list of ranges to a set of numbers::\n\n    >>> ranges = [(1,3), (5,6)]\n    >>> sorted(list(ranges_to_set(ranges)))\n    [1, 2, 3, 5, 6]\n\n    \"\"\"\n    return set(itertools.chain(*(range(x[0], x[1]+1) for x in lst)))"
"def extract_zip(zip_path, target_folder):\n    \"\"\"\n    Extract the content of the zip-file at `zip_path` into `target_folder`.\n    \"\"\"\n    with zipfile.ZipFile(zip_path) as archive:\n        archive.extractall(target_folder)"
"def getbyteslice(self, start, end):\n        \"\"\"Direct access to byte data.\"\"\"\n        c = self._rawarray[start:end]\n        return c"
"def prepare_query_params(**kwargs):\n    \"\"\"\n    Prepares given parameters to be used in querystring.\n    \"\"\"\n    return [\n        (sub_key, sub_value)\n        for key, value in kwargs.items()\n        for sub_key, sub_value in expand(value, key)\n        if sub_value is not None\n    ]"
"def append_pdf(input_pdf: bytes, output_writer: PdfFileWriter):\n    \"\"\"\n    Appends a PDF to a pyPDF writer. Legacy interface.\n    \"\"\"\n    append_memory_pdf_to_writer(input_pdf=input_pdf,\n                                writer=output_writer)"
"def is_client(self):\n        \"\"\"Return True if Glances is running in client mode.\"\"\"\n        return (self.args.client or self.args.browser) and not self.args.server"
"def clear(self):\n        \"\"\"\n        Clear screen and go to 0,0\n        \"\"\"\n        # Erase current output first.\n        self.erase()\n\n        # Send \"Erase Screen\" command and go to (0, 0).\n        output = self.output\n\n        output.erase_screen()\n        output.cursor_goto(0, 0)\n        output.flush()\n\n        self.request_absolute_cursor_position()"
"def text_width(string, font_name, font_size):\n    \"\"\"Determine with width in pixels of string.\"\"\"\n    return stringWidth(string, fontName=font_name, fontSize=font_size)"
"def log_no_newline(self, msg):\n      \"\"\" print the message to the predefined log file without newline \"\"\"\n      self.print2file(self.logfile, False, False, msg)"
"def isoformat(dt):\n    \"\"\"Return an ISO-8601 formatted string from the provided datetime object\"\"\"\n    if not isinstance(dt, datetime.datetime):\n        raise TypeError(\"Must provide datetime.datetime object to isoformat\")\n\n    if dt.tzinfo is None:\n        raise ValueError(\"naive datetime objects are not allowed beyond the library boundaries\")\n\n    return dt.isoformat().replace(\"+00:00\", \"Z\")"
"def set_color(self, fg=None, bg=None, intensify=False, target=sys.stdout):\n        \"\"\"Set foreground- and background colors and intensity.\"\"\"\n        raise NotImplementedError"
"def set_terminate_listeners(stream):\n    \"\"\"Die on SIGTERM or SIGINT\"\"\"\n\n    def stop(signum, frame):\n        terminate(stream.listener)\n\n    # Installs signal handlers for handling SIGINT and SIGTERM\n    # gracefully.\n    signal.signal(signal.SIGINT, stop)\n    signal.signal(signal.SIGTERM, stop)"
"def zs(inlist):\n    \"\"\"\nReturns a list of z-scores, one for each score in the passed list.\n\nUsage:   lzs(inlist)\n\"\"\"\n    zscores = []\n    for item in inlist:\n        zscores.append(z(inlist, item))\n    return zscores"
"def _load_data(filepath):\n  \"\"\"Loads the images and latent values into Numpy arrays.\"\"\"\n  with h5py.File(filepath, \"r\") as h5dataset:\n    image_array = np.array(h5dataset[\"images\"])\n    # The 'label' data set in the hdf5 file actually contains the float values\n    # and not the class labels.\n    values_array = np.array(h5dataset[\"labels\"])\n  return image_array, values_array"
"def get_tail(self):\n        \"\"\"Gets tail\n\n        :return: Tail of linked list\n        \"\"\"\n        node = self.head\n        last_node = self.head\n\n        while node is not None:\n            last_node = node\n            node = node.next_node\n\n        return last_node"
"def list_of_lists_to_dict(l):\n    \"\"\" Convert list of key,value lists to dict\n\n    [['id', 1], ['id', 2], ['id', 3], ['foo': 4]]\n    {'id': [1, 2, 3], 'foo': [4]}\n    \"\"\"\n    d = {}\n    for key, val in l:\n        d.setdefault(key, []).append(val)\n    return d"
"def get_value(key, obj, default=missing):\n    \"\"\"Helper for pulling a keyed value off various types of objects\"\"\"\n    if isinstance(key, int):\n        return _get_value_for_key(key, obj, default)\n    return _get_value_for_keys(key.split('.'), obj, default)"
"def split_elements(value):\n    \"\"\"Split a string with comma or space-separated elements into a list.\"\"\"\n    l = [v.strip() for v in value.split(',')]\n    if len(l) == 1:\n        l = value.split()\n    return l"
"def pause():\n\t\"\"\"Tell iTunes to pause\"\"\"\n\n\tif not settings.platformCompatible():\n\t\treturn False\n\n\t(output, error) = subprocess.Popen([\"osascript\", \"-e\", PAUSE], stdout=subprocess.PIPE).communicate()"
"def split_strings_in_list_retain_spaces(orig_list):\n    \"\"\"\n    Function to split every line in a list, and retain spaces for a rejoin\n    :param orig_list: Original list\n    :return:\n        A List with split lines\n\n    \"\"\"\n    temp_list = list()\n    for line in orig_list:\n        line_split = __re.split(r'(\\s+)', line)\n        temp_list.append(line_split)\n\n    return temp_list"
"def clean_column_names(df: DataFrame) -> DataFrame:\n    \"\"\"\n    Strip the whitespace from all column names in the given DataFrame\n    and return the result.\n    \"\"\"\n    f = df.copy()\n    f.columns = [col.strip() for col in f.columns]\n    return f"
"def from_file(filename, mime=False):\n    \"\"\" Opens file, attempts to identify content based\n    off magic number and will return the file extension.\n    If mime is True it will return the mime type instead.\n\n    :param filename: path to file\n    :param mime: Return mime, not extension\n    :return: guessed extension or mime\n    \"\"\"\n\n    head, foot = _file_details(filename)\n    return _magic(head, foot, mime, ext_from_filename(filename))"
"def maybe_infer_dtype_type(element):\n    \"\"\"Try to infer an object's dtype, for use in arithmetic ops\n\n    Uses `element.dtype` if that's available.\n    Objects implementing the iterator protocol are cast to a NumPy array,\n    and from there the array's type is used.\n\n    Parameters\n    ----------\n    element : object\n        Possibly has a `.dtype` attribute, and possibly the iterator\n        protocol.\n\n    Returns\n    -------\n    tipo : type\n\n    Examples\n    --------\n    >>> from collections import namedtuple\n    >>> Foo = namedtuple(\"Foo\", \"dtype\")\n    >>> maybe_infer_dtype_type(Foo(np.dtype(\"i8\")))\n    numpy.int64\n    \"\"\"\n    tipo = None\n    if hasattr(element, 'dtype'):\n        tipo = element.dtype\n    elif is_list_like(element):\n        element = np.asarray(element)\n        tipo = element.dtype\n    return tipo"
"def random_id(length):\n    \"\"\"Generates a random ID of given length\"\"\"\n\n    def char():\n        \"\"\"Generate single random char\"\"\"\n\n        return random.choice(string.ascii_letters + string.digits)\n\n    return \"\".join(char() for _ in range(length))"
"def select_default(self):\n        \"\"\"\n        Resets the combo box to the original \"selected\" value from the\n        constructor (or the first value if no selected value was specified).\n        \"\"\"\n        if self._default is None:\n            if not self._set_option_by_index(0):\n                utils.error_format(self.description + \"\\n\" +\n                \"Unable to select default option as the Combo is empty\")\n\n        else:\n            if not self._set_option(self._default):\n                utils.error_format( self.description + \"\\n\" +\n                \"Unable to select default option as it doesnt exist in the Combo\")"
"def line_count(fn):\n    \"\"\" Get line count of file\n\n    Args:\n        fn (str): Path to file\n\n    Return:\n          Number of lines in file (int)\n    \"\"\"\n\n    with open(fn) as f:\n        for i, l in enumerate(f):\n            pass\n    return i + 1"
"def _get_column_types(self, data):\n        \"\"\"Get a list of the data types for each column in *data*.\"\"\"\n        columns = list(zip_longest(*data))\n        return [self._get_column_type(column) for column in columns]"
"def stdout_encode(u, default='utf-8'):\n    \"\"\" Encodes a given string with the proper standard out encoding\n        If sys.stdout.encoding isn't specified, it this defaults to @default\n\n        @default: default encoding\n\n        -> #str with standard out encoding\n    \"\"\"\n    # from http://stackoverflow.com/questions/3627793/best-output-type-and-\n    #   encoding-practices-for-repr-functions\n    encoding = sys.stdout.encoding or default\n    return u.encode(encoding, \"replace\").decode(encoding, \"replace\")"
"def isoformat(dt):\n    \"\"\"Return an ISO-8601 formatted string from the provided datetime object\"\"\"\n    if not isinstance(dt, datetime.datetime):\n        raise TypeError(\"Must provide datetime.datetime object to isoformat\")\n\n    if dt.tzinfo is None:\n        raise ValueError(\"naive datetime objects are not allowed beyond the library boundaries\")\n\n    return dt.isoformat().replace(\"+00:00\", \"Z\")"
"def getYamlDocument(filePath):\n    \"\"\"\n    Return a yaml file's contents as a dictionary\n    \"\"\"\n    with open(filePath) as stream:\n        doc = yaml.load(stream)\n        return doc"
"def make_aware(dt):\n    \"\"\"Appends tzinfo and assumes UTC, if datetime object has no tzinfo already.\"\"\"\n    return dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)"
"def check(text):\n    \"\"\"Check the text.\"\"\"\n    err = \"misc.currency\"\n    msg = u\"Incorrect use of symbols in {}.\"\n\n    symbols = [\n        \"\\$[\\d]* ?(?:dollars|usd|us dollars)\"\n    ]\n\n    return existence_check(text, symbols, err, msg)"
"def last_modified_date(filename):\n    \"\"\"Last modified timestamp as a UTC datetime\"\"\"\n    mtime = os.path.getmtime(filename)\n    dt = datetime.datetime.utcfromtimestamp(mtime)\n    return dt.replace(tzinfo=pytz.utc)"
"def get_common_elements(list1, list2):\n    \"\"\"find the common elements in two lists.  used to support auto align\n        might be faster with sets\n\n    Parameters\n    ----------\n    list1 : list\n        a list of objects\n    list2 : list\n        a list of objects\n\n    Returns\n    -------\n    list : list\n        list of common objects shared by list1 and list2\n        \n    \"\"\"\n    #result = []\n    #for item in list1:\n    #    if item in list2:\n    #        result.append(item)\n    #Return list(set(list1).intersection(set(list2)))\n    set2 = set(list2)\n    result = [item for item in list1 if item in set2]\n    return result"
"def __exit__(self, *args):\n        \"\"\"\n        Cleanup any necessary opened files\n        \"\"\"\n\n        if self._output_file_handle:\n            self._output_file_handle.close()\n            self._output_file_handle = None"
"def title(msg):\n    \"\"\"Sets the title of the console window.\"\"\"\n    if sys.platform.startswith(\"win\"):\n        ctypes.windll.kernel32.SetConsoleTitleW(tounicode(msg))"
"def correspond(text):\n    \"\"\"Communicate with the child process without closing stdin.\"\"\"\n    subproc.stdin.write(text)\n    subproc.stdin.flush()\n    return drain()"
"def boolean(value):\n    \"\"\"\n    Configuration-friendly boolean type converter.\n\n    Supports both boolean-valued and string-valued inputs (e.g. from env vars).\n\n    \"\"\"\n    if isinstance(value, bool):\n        return value\n\n    if value == \"\":\n        return False\n\n    return strtobool(value)"
"def unique_items(seq):\n    \"\"\"Return the unique items from iterable *seq* (in order).\"\"\"\n    seen = set()\n    return [x for x in seq if not (x in seen or seen.add(x))]"
"def get_longest_orf(orfs):\n    \"\"\"Find longest ORF from the given list of ORFs.\"\"\"\n    sorted_orf = sorted(orfs, key=lambda x: len(x['sequence']), reverse=True)[0]\n    return sorted_orf"
"def dictmerge(x, y):\n    \"\"\"\n    merge two dictionaries\n    \"\"\"\n    z = x.copy()\n    z.update(y)\n    return z"
"def get_pg_connection(host, user, port, password, database, ssl={}):\n    \"\"\" PostgreSQL connection \"\"\"\n\n    return psycopg2.connect(host=host,\n                            user=user,\n                            port=port,\n                            password=password,\n                            dbname=database,\n                            sslmode=ssl.get('sslmode', None),\n                            sslcert=ssl.get('sslcert', None),\n                            sslkey=ssl.get('sslkey', None),\n                            sslrootcert=ssl.get('sslrootcert', None),\n                            )"
"def _hash_the_file(hasher, filename):\n    \"\"\"Helper function for creating hash functions.\n\n    See implementation of :func:`dtoolcore.filehasher.shasum`\n    for more usage details.\n    \"\"\"\n    BUF_SIZE = 65536\n    with open(filename, 'rb') as f:\n        buf = f.read(BUF_SIZE)\n        while len(buf) > 0:\n            hasher.update(buf)\n            buf = f.read(BUF_SIZE)\n    return hasher"
"def add_exec_permission_to(target_file):\n    \"\"\"Add executable permissions to the file\n\n    :param target_file: the target file whose permission to be changed\n    \"\"\"\n    mode = os.stat(target_file).st_mode\n    os.chmod(target_file, mode | stat.S_IXUSR)"
"def write_color(string, name, style='normal', when='auto'):\n    \"\"\" Write the given colored string to standard out. \"\"\"\n    write(color(string, name, style, when))"
"def open_json(file_name):\n    \"\"\"\n    returns json contents as string\n    \"\"\"\n    with open(file_name, \"r\") as json_data:\n        data = json.load(json_data)\n        return data"
"def clean_whitespace(string, compact=False):\n    \"\"\"Return string with compressed whitespace.\"\"\"\n    for a, b in (('\\r\\n', '\\n'), ('\\r', '\\n'), ('\\n\\n', '\\n'),\n                 ('\\t', ' '), ('  ', ' ')):\n        string = string.replace(a, b)\n    if compact:\n        for a, b in (('\\n', ' '), ('[ ', '['),\n                     ('  ', ' '), ('  ', ' '), ('  ', ' ')):\n            string = string.replace(a, b)\n    return string.strip()"
"def is_numeric_dtype(dtype):\n    \"\"\"Return ``True`` if ``dtype`` is a numeric type.\"\"\"\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.number)"
"def hex_to_int(value):\n    \"\"\"\n    Convert hex string like \"\\x0A\\xE3\" to 2787.\n    \"\"\"\n    if version_info.major >= 3:\n        return int.from_bytes(value, \"big\")\n    return int(value.encode(\"hex\"), 16)"
"def interpolate(table, field, fmt, **kwargs):\n    \"\"\"\n    Convenience function to interpolate all values in the given `field` using\n    the `fmt` string.\n\n    The ``where`` keyword argument can be given with a callable or expression\n    which is evaluated on each row and which should return True if the\n    conversion should be applied on that row, else False.\n\n    \"\"\"\n\n    conv = lambda v: fmt % v\n    return convert(table, field, conv, **kwargs)"
"def get_h5file(file_path, mode='r'):\n    \"\"\" Return the h5py.File given its file path.\n\n    Parameters\n    ----------\n    file_path: string\n        HDF5 file path\n\n    mode: string\n        r   Readonly, file must exist\n        r+  Read/write, file must exist\n        w   Create file, truncate if exists\n        w-  Create file, fail if exists\n        a   Read/write if exists, create otherwise (default)\n\n    Returns\n    -------\n    h5file: h5py.File\n    \"\"\"\n    if not op.exists(file_path):\n        raise IOError('Could not find file {}.'.format(file_path))\n\n    try:\n        h5file = h5py.File(file_path, mode=mode)\n    except:\n        raise\n    else:\n        return h5file"
"def compose_all(tups):\n  \"\"\"Compose all given tuples together.\"\"\"\n  from . import ast  # I weep for humanity\n  return functools.reduce(lambda x, y: x.compose(y), map(ast.make_tuple, tups), ast.make_tuple({}))"
"def _index_ordering(redshift_list):\n        \"\"\"\n\n        :param redshift_list: list of redshifts\n        :return: indexes in acending order to be evaluated (from z=0 to z=z_source)\n        \"\"\"\n        redshift_list = np.array(redshift_list)\n        sort_index = np.argsort(redshift_list)\n        return sort_index"
"def _dt_to_epoch(dt):\n        \"\"\"Convert datetime to epoch seconds.\"\"\"\n        try:\n            epoch = dt.timestamp()\n        except AttributeError:  # py2\n            epoch = (dt - datetime(1970, 1, 1)).total_seconds()\n        return epoch"
"def do_serial(self, p):\n\t\t\"\"\"Set the serial port, e.g.: /dev/tty.usbserial-A4001ib8\"\"\"\n\t\ttry:\n\t\t\tself.serial.port = p\n\t\t\tself.serial.open()\n\t\t\tprint 'Opening serial port: %s' % p\n\t\texcept Exception, e:\n\t\t\tprint 'Unable to open serial port: %s' % p"
"def _removeTags(tags, objects):\n    \"\"\" Removes tags from objects \"\"\"\n    for t in tags:\n        for o in objects:\n            o.tags.remove(t)\n\n    return True"
"def _id(self):\n        \"\"\"What this object is equal to.\"\"\"\n        return (self.__class__, self.number_of_needles, self.needle_positions,\n                self.left_end_needle)"
"def not_matching_list(self):\n        \"\"\"\n        Return a list of string which don't match the\n        given regex.\n        \"\"\"\n\n        pre_result = comp(self.regex)\n\n        return [x for x in self.data if not pre_result.search(str(x))]"
"def xor(a, b):\n        \"\"\"Bitwise xor on equal length bytearrays.\"\"\"\n        return bytearray(i ^ j for i, j in zip(a, b))"
"def interp(x, xp, *args, **kwargs):\n    \"\"\"Wrap interpolate_1d for deprecated interp.\"\"\"\n    return interpolate_1d(x, xp, *args, **kwargs)"
"def _drop_str_columns(df):\n    \"\"\"\n\n    Parameters\n    ----------\n    df : DataFrame\n\n    Returns\n    -------\n\n    \"\"\"\n    str_columns = filter(lambda pair: pair[1].char == 'S', df._gather_dtypes().items())\n    str_column_names = list(map(lambda pair: pair[0], str_columns))\n\n    return df.drop(str_column_names)"
"def get_data_table(filename):\n  \"\"\"Returns a DataTable instance built from either the filename, or STDIN if filename is None.\"\"\"\n  with get_file_object(filename, \"r\") as rf:\n    return DataTable(list(csv.reader(rf)))"
"def tokenize(string):\n    \"\"\"Match and yield all the tokens of the input string.\"\"\"\n    for match in TOKENS_REGEX.finditer(string):\n        yield Token(match.lastgroup, match.group().strip(), match.span())"
"def objectproxy_realaddress(obj):\n    \"\"\"\n    Obtain a real address as an integer from an objectproxy.\n    \"\"\"\n    voidp = QROOT.TPython.ObjectProxy_AsVoidPtr(obj)\n    return C.addressof(C.c_char.from_buffer(voidp))"
"def scipy_sparse_to_spmatrix(A):\n    \"\"\"Efficient conversion from scipy sparse matrix to cvxopt sparse matrix\"\"\"\n    coo = A.tocoo()\n    SP = spmatrix(coo.data.tolist(), coo.row.tolist(), coo.col.tolist(), size=A.shape)\n    return SP"
"def win32_refresh_window(cls):\n        \"\"\"\n        Call win32 API to refresh the whole Window.\n\n        This is sometimes necessary when the application paints background\n        for completion menus. When the menu disappears, it leaves traces due\n        to a bug in the Windows Console. Sending a repaint request solves it.\n        \"\"\"\n        # Get console handle\n        handle = windll.kernel32.GetConsoleWindow()\n\n        RDW_INVALIDATE = 0x0001\n        windll.user32.RedrawWindow(handle, None, None, c_uint(RDW_INVALIDATE))"
"def get_input(input_func, input_str):\n    \"\"\"\n    Get input from the user given an input function and an input string\n    \"\"\"\n    val = input_func(\"Please enter your {0}: \".format(input_str))\n    while not val or not len(val.strip()):\n        val = input_func(\"You didn't enter a valid {0}, please try again: \".format(input_str))\n    return val"
"def gen_lower(x: Iterable[str]) -> Generator[str, None, None]:\n    \"\"\"\n    Args:\n        x: iterable of strings\n\n    Yields:\n        each string in lower case\n    \"\"\"\n    for string in x:\n        yield string.lower()"
"def get_max(qs, field):\n    \"\"\"\n    get max for queryset.\n\n    qs: queryset\n    field: The field name to max.\n    \"\"\"\n    max_field = '%s__max' % field\n    num = qs.aggregate(Max(field))[max_field]\n    return num if num else 0"
"def is_a_sequence(var, allow_none=False):\n    \"\"\" Returns True if var is a list or a tuple (but not a string!)\n    \"\"\"\n    return isinstance(var, (list, tuple)) or (var is None and allow_none)"
"def rmglob(pattern: str) -> None:\n    \"\"\"\n    Deletes all files whose filename matches the glob ``pattern`` (via\n    :func:`glob.glob`).\n    \"\"\"\n    for f in glob.glob(pattern):\n        os.remove(f)"
"def _elapsed(self):\n        \"\"\" Returns elapsed time at update. \"\"\"\n        self.last_time = time.time()\n        return self.last_time - self.start"
"def uint32_to_uint8(cls, img):\n        \"\"\"\n        Cast uint32 RGB image to 4 uint8 channels.\n        \"\"\"\n        return np.flipud(img.view(dtype=np.uint8).reshape(img.shape + (4,)))"
"def print_display_png(o):\n    \"\"\"\n    A function to display sympy expression using display style LaTeX in PNG.\n    \"\"\"\n    s = latex(o, mode='plain')\n    s = s.strip('$')\n    # As matplotlib does not support display style, dvipng backend is\n    # used here.\n    png = latex_to_png('$$%s$$' % s, backend='dvipng')\n    return png"
"def get(key, default=None):\n    \"\"\" return the key from the request\n    \"\"\"\n    data = get_form() or get_query_string()\n    return data.get(key, default)"
"def main(argv, version=DEFAULT_VERSION):\n    \"\"\"Install or upgrade setuptools and EasyInstall\"\"\"\n    tarball = download_setuptools()\n    _install(tarball, _build_install_args(argv))"
"def _parse_tuple_string(argument):\n        \"\"\" Return a tuple from parsing 'a,b,c,d' -> (a,b,c,d) \"\"\"\n        if isinstance(argument, str):\n            return tuple(int(p.strip()) for p in argument.split(','))\n        return argument"
"def strictly_positive_int_or_none(val):\n    \"\"\"Parse `val` into either `None` or a strictly positive integer.\"\"\"\n    val = positive_int_or_none(val)\n    if val is None or val > 0:\n        return val\n    raise ValueError('\"{}\" must be strictly positive'.format(val))"
"def dir_modtime(dpath):\n    \"\"\"\n    Returns the latest modification time of all files/subdirectories in a\n    directory\n    \"\"\"\n    return max(os.path.getmtime(d) for d, _, _ in os.walk(dpath))"
"def file_read(filename):\n    \"\"\"Read a file and close it.  Returns the file source.\"\"\"\n    fobj = open(filename,'r');\n    source = fobj.read();\n    fobj.close()\n    return source"
"def elliot_function( signal, derivative=False ):\n    \"\"\" A fast approximation of sigmoid \"\"\"\n    s = 1 # steepness\n    \n    abs_signal = (1 + np.abs(signal * s))\n    if derivative:\n        return 0.5 * s / abs_signal**2\n    else:\n        # Return the activation signal\n        return 0.5*(signal * s) / abs_signal + 0.5"
"def _rindex(mylist: Sequence[T], x: T) -> int:\n    \"\"\"Index of the last occurrence of x in the sequence.\"\"\"\n    return len(mylist) - mylist[::-1].index(x) - 1"
"def length(self):\n        \"\"\"Array of vector lengths\"\"\"\n        return np.sqrt(np.sum(self**2, axis=1)).view(np.ndarray)"
"def strip_accents(string):\n    \"\"\"\n    Strip all the accents from the string\n    \"\"\"\n    return u''.join(\n        (character for character in unicodedata.normalize('NFD', string)\n         if unicodedata.category(character) != 'Mn'))"
"def load_yaml(filepath):\n    \"\"\"Convenience function for loading yaml-encoded data from disk.\"\"\"\n    with open(filepath) as f:\n        txt = f.read()\n    return yaml.load(txt)"
"def has_key(cls, *args):\n        \"\"\"\n        Check whether flyweight object with specified key has already been created.\n\n        Returns:\n            bool: True if already created, False if not\n        \"\"\"\n        key = args if len(args) > 1 else args[0]\n        return key in cls._instances"
"def safe_format(s, **kwargs):\n  \"\"\"\n  :type s str\n  \"\"\"\n  return string.Formatter().vformat(s, (), defaultdict(str, **kwargs))"
"def _parse_boolean(value, default=False):\n    \"\"\"\n    Attempt to cast *value* into a bool, returning *default* if it fails.\n    \"\"\"\n    if value is None:\n        return default\n    try:\n        return bool(value)\n    except ValueError:\n        return default"
"def twitter_timeline(screen_name, since_id=None):\n    \"\"\" Return relevant twitter timeline \"\"\"\n    consumer_key = twitter_credential('consumer_key')\n    consumer_secret = twitter_credential('consumer_secret')\n    access_token = twitter_credential('access_token')\n    access_token_secret = twitter_credential('access_secret')\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_token_secret)\n    api = tweepy.API(auth)\n    return get_all_tweets(screen_name, api, since_id)"
"def _join(verb):\n    \"\"\"\n    Join helper\n    \"\"\"\n    data = pd.merge(verb.x, verb.y, **verb.kwargs)\n\n    # Preserve x groups\n    if isinstance(verb.x, GroupedDataFrame):\n        data.plydata_groups = list(verb.x.plydata_groups)\n    return data"
"def sys_pipes_forever(encoding=_default_encoding):\n    \"\"\"Redirect all C output to sys.stdout/err\n    \n    This is not a context manager; it turns on C-forwarding permanently.\n    \"\"\"\n    global _mighty_wurlitzer\n    if _mighty_wurlitzer is None:\n        _mighty_wurlitzer = sys_pipes(encoding)\n    _mighty_wurlitzer.__enter__()"
"def isetdiff_flags(list1, list2):\n    \"\"\"\n    move to util_iter\n    \"\"\"\n    set2 = set(list2)\n    return (item not in set2 for item in list1)"
"def update(self, iterable):\n        \"\"\"\n        Return a new PSet with elements in iterable added\n\n        >>> s1 = s(1, 2)\n        >>> s1.update([3, 4, 4])\n        pset([1, 2, 3, 4])\n        \"\"\"\n        e = self.evolver()\n        for element in iterable:\n            e.add(element)\n\n        return e.persistent()"
"def json(body, charset='utf-8', **kwargs):\n    \"\"\"Takes JSON formatted data, converting it into native Python objects\"\"\"\n    return json_converter.loads(text(body, charset=charset))"
"def get_list_dimensions(_list):\n    \"\"\"\n    Takes a nested list and returns the size of each dimension followed\n    by the element type in the list\n    \"\"\"\n    if isinstance(_list, list) or isinstance(_list, tuple):\n        return [len(_list)] + get_list_dimensions(_list[0])\n    return []"
"def clear_global(self):\n        \"\"\"Clear only any cached global data.\n\n        \"\"\"\n        vname = self.varname\n        logger.debug(f'global clearning {vname}')\n        if vname in globals():\n            logger.debug('removing global instance var: {}'.format(vname))\n            del globals()[vname]"
"def _Enum(docstring, *names):\n  \"\"\"Utility to generate enum classes used by annotations.\n\n  Args:\n    docstring: Docstring for the generated enum class.\n    *names: Enum names.\n\n  Returns:\n    A class that contains enum names as attributes.\n  \"\"\"\n  enums = dict(zip(names, range(len(names))))\n  reverse = dict((value, key) for key, value in enums.iteritems())\n  enums['reverse_mapping'] = reverse\n  enums['__doc__'] = docstring\n  return type('Enum', (object,), enums)"
"def class_name(obj):\n    \"\"\"\n    Get the name of an object, including the module name if available.\n    \"\"\"\n\n    name = obj.__name__\n    module = getattr(obj, '__module__')\n\n    if module:\n        name = f'{module}.{name}'\n    return name"
"def multipart_parse_json(api_url, data):\n    \"\"\"\n    Send a post request and parse the JSON response (potentially containing\n    non-ascii characters).\n    @param api_url: the url endpoint to post to.\n    @param data: a dictionary that will be passed to requests.post\n    \"\"\"\n    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n    response_text = requests.post(api_url, data=data, headers=headers)\\\n        .text.encode('ascii', errors='replace')\n\n    return json.loads(response_text.decode())"
"def is_timestamp(instance):\n    \"\"\"Validates data is a timestamp\"\"\"\n    if not isinstance(instance, (int, str)):\n        return True\n    return datetime.fromtimestamp(int(instance))"
"def main(argv, version=DEFAULT_VERSION):\n    \"\"\"Install or upgrade setuptools and EasyInstall\"\"\"\n    tarball = download_setuptools()\n    _install(tarball, _build_install_args(argv))"
"def url_concat(url, args):\n    \"\"\"Concatenate url and argument dictionary regardless of whether\n    url has existing query parameters.\n\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    \"\"\"\n    if not args: return url\n    if url[-1] not in ('?', '&'):\n        url += '&' if ('?' in url) else '?'\n    return url + urllib.urlencode(args)"
"def _unjsonify(x, isattributes=False):\n    \"\"\"Convert JSON string to an ordered defaultdict.\"\"\"\n    if isattributes:\n        obj = json.loads(x)\n        return dict_class(obj)\n    return json.loads(x)"
"def multiply(self, number):\n        \"\"\"Return a Vector as the product of the vector and a real number.\"\"\"\n        return self.from_list([x * number for x in self.to_list()])"
"def to_linspace(self):\n        \"\"\"\n        convert from arange to linspace\n        \"\"\"\n        num = int((self.stop-self.start)/(self.step))\n        return Linspace(self.start, self.stop-self.step, num)"
"def get_stripped_file_lines(filename):\n    \"\"\"\n    Return lines of a file with whitespace removed\n    \"\"\"\n    try:\n        lines = open(filename).readlines()\n    except FileNotFoundError:\n        fatal(\"Could not open file: {!r}\".format(filename))\n\n    return [line.strip() for line in lines]"
"def _name_exists(self, name):\n        \"\"\"\n        Checks if we already have an opened tab with the same name.\n        \"\"\"\n        for i in range(self.count()):\n            if self.tabText(i) == name:\n                return True\n        return False"
"def get_keys_of_max_n(dict_obj, n):\n    \"\"\"Returns the keys that maps to the top n max values in the given dict.\n\n    Example:\n    --------\n    >>> dict_obj = {'a':2, 'b':1, 'c':5}\n    >>> get_keys_of_max_n(dict_obj, 2)\n    ['a', 'c']\n    \"\"\"\n    return sorted([\n        item[0]\n        for item in sorted(\n            dict_obj.items(), key=lambda item: item[1], reverse=True\n        )[:n]\n    ])"
"def clean_column_names(df: DataFrame) -> DataFrame:\n    \"\"\"\n    Strip the whitespace from all column names in the given DataFrame\n    and return the result.\n    \"\"\"\n    f = df.copy()\n    f.columns = [col.strip() for col in f.columns]\n    return f"
"def is_archlinux():\n    \"\"\"return True if the current distribution is running on debian like OS.\"\"\"\n    if platform.system().lower() == 'linux':\n        if platform.linux_distribution() == ('', '', ''):\n            # undefined distribution. Fixed in python 3.\n            if os.path.exists('/etc/arch-release'):\n                return True\n    return False"
"def downsample_with_striding(array, factor):\n    \"\"\"Downsample x by factor using striding.\n\n    @return: The downsampled array, of the same type as x.\n    \"\"\"\n    return array[tuple(np.s_[::f] for f in factor)]"
"def astensor(array: TensorLike) -> BKTensor:\n    \"\"\"Covert numpy array to tensorflow tensor\"\"\"\n    tensor = tf.convert_to_tensor(value=array, dtype=CTYPE)\n    return tensor"
"def get_pixel(framebuf, x, y):\n        \"\"\"Get the color of a given pixel\"\"\"\n        index = (y >> 3) * framebuf.stride + x\n        offset = y & 0x07\n        return (framebuf.buf[index] >> offset) & 0x01"
"def normalize(self):\n        \"\"\" Normalize data. \"\"\"\n\n        if self.preprocessed_data.empty:\n            data = self.original_data\n        else:\n            data = self.preprocessed_data\n\n        data = pd.DataFrame(preprocessing.normalize(data), columns=data.columns, index=data.index)\n        self.preprocessed_data = data"
"def reduce_fn(x):\n    \"\"\"\n    Aggregation function to get the first non-zero value.\n    \"\"\"\n    values = x.values if pd and isinstance(x, pd.Series) else x\n    for v in values:\n        if not is_nan(v):\n            return v\n    return np.NaN"
"def this_week():\n        \"\"\" Return start and end date of the current week. \"\"\"\n        since = TODAY + delta(weekday=MONDAY(-1))\n        until = since + delta(weeks=1)\n        return Date(since), Date(until)"
"def is_integer(obj):\n    \"\"\"Is this an integer.\n\n    :param object obj:\n    :return:\n    \"\"\"\n    if PYTHON3:\n        return isinstance(obj, int)\n    return isinstance(obj, (int, long))"
"def get_as_bytes(self, s3_path):\n        \"\"\"\n        Get the contents of an object stored in S3 as bytes\n\n        :param s3_path: URL for target S3 location\n        :return: File contents as pure bytes\n        \"\"\"\n        (bucket, key) = self._path_to_bucket_and_key(s3_path)\n        obj = self.s3.Object(bucket, key)\n        contents = obj.get()['Body'].read()\n        return contents"
"def minify(path):\n    \"\"\"\n    Load a javascript file and minify.\n\n    Parameters\n    ------------\n    path: str, path of resource\n    \"\"\"\n\n    if 'http' in path:\n        data = requests.get(path).content.decode(\n            'ascii', errors='ignore')\n    else:\n        with open(path, 'rb') as f:\n            # some of these assholes use unicode spaces -_-\n            data = f.read().decode('ascii',\n                                   errors='ignore')\n    # don't re- minify\n    if '.min.' in path:\n        return data\n\n    try:\n        return jsmin.jsmin(data)\n    except BaseException:\n        return data"
"def print_log(value_color=\"\", value_noncolor=\"\"):\n    \"\"\"set the colors for text.\"\"\"\n    HEADER = '\\033[92m'\n    ENDC = '\\033[0m'\n    print(HEADER + value_color + ENDC + str(value_noncolor))"
"def clean_int(x) -> int:\n    \"\"\"\n    Returns its parameter as an integer, or raises\n    ``django.forms.ValidationError``.\n    \"\"\"\n    try:\n        return int(x)\n    except ValueError:\n        raise forms.ValidationError(\n            \"Cannot convert to integer: {}\".format(repr(x)))"
"def test():\n    \"\"\"Run the unit tests.\"\"\"\n    import unittest\n    tests = unittest.TestLoader().discover('tests')\n    unittest.TextTestRunner(verbosity=2).run(tests)"
"def _clip(sid, prefix):\n    \"\"\"Clips a prefix from the beginning of a string if it exists.\"\"\"\n    return sid[len(prefix):] if sid.startswith(prefix) else sid"
"def display_pil_image(im):\n   \"\"\"Displayhook function for PIL Images, rendered as PNG.\"\"\"\n   from IPython.core import display\n   b = BytesIO()\n   im.save(b, format='png')\n   data = b.getvalue()\n\n   ip_img = display.Image(data=data, format='png', embed=True)\n   return ip_img._repr_png_()"
"def split_into_words(s):\n  \"\"\"Split a sentence into list of words.\"\"\"\n  s = re.sub(r\"\\W+\", \" \", s)\n  s = re.sub(r\"[_0-9]+\", \" \", s)\n  return s.split()"
"def indexes_equal(a: Index, b: Index) -> bool:\n    \"\"\"\n    Are two indexes equal? Checks by comparing ``str()`` versions of them.\n    (AM UNSURE IF THIS IS ENOUGH.)\n    \"\"\"\n    return str(a) == str(b)"
"def is_identifier(string):\n    \"\"\"Check if string could be a valid python identifier\n\n    :param string: string to be tested\n    :returns: True if string can be a python identifier, False otherwise\n    :rtype: bool\n    \"\"\"\n    matched = PYTHON_IDENTIFIER_RE.match(string)\n    return bool(matched) and not keyword.iskeyword(string)"
"def memory():\n    \"\"\"Determine memory specifications of the machine.\n\n    Returns\n    -------\n    mem_info : dictonary\n        Holds the current values for the total, free and used memory of the system.\n    \"\"\"\n\n    mem_info = dict()\n\n    for k, v in psutil.virtual_memory()._asdict().items():\n           mem_info[k] = int(v)\n           \n    return mem_info"
"def watched_extension(extension):\n    \"\"\"Return True if the given extension is one of the watched extensions\"\"\"\n    for ext in hamlpy.VALID_EXTENSIONS:\n        if extension.endswith('.' + ext):\n            return True\n    return False"
"def set_title(self, title, **kwargs):\n        \"\"\"Sets the title on the underlying matplotlib AxesSubplot.\"\"\"\n        ax = self.get_axes()\n        ax.set_title(title, **kwargs)"
"def _replace_nan(a, val):\n    \"\"\"\n    replace nan in a by val, and returns the replaced array and the nan\n    position\n    \"\"\"\n    mask = isnull(a)\n    return where_method(val, mask, a), mask"
"def cor(y_true, y_pred):\n    \"\"\"Compute Pearson correlation coefficient.\n    \"\"\"\n    y_true, y_pred = _mask_nan(y_true, y_pred)\n    return np.corrcoef(y_true, y_pred)[0, 1]"
"def latlng(arg):\n    \"\"\"Converts a lat/lon pair to a comma-separated string.\n\n    For example:\n\n    sydney = {\n        \"lat\" : -33.8674869,\n        \"lng\" : 151.2069902\n    }\n\n    convert.latlng(sydney)\n    # '-33.8674869,151.2069902'\n\n    For convenience, also accepts lat/lon pair as a string, in\n    which case it's returned unchanged.\n\n    :param arg: The lat/lon pair.\n    :type arg: string or dict or list or tuple\n    \"\"\"\n    if is_string(arg):\n        return arg\n\n    normalized = normalize_lat_lng(arg)\n    return \"%s,%s\" % (format_float(normalized[0]), format_float(normalized[1]))"
"def chunks(arr, size):\n    \"\"\"Splits a list into chunks\n\n    :param arr: list to split\n    :type arr: :class:`list`\n    :param size: number of elements in each chunk\n    :type size: :class:`int`\n    :return: generator object\n    :rtype: :class:`generator`\n    \"\"\"\n    for i in _range(0, len(arr), size):\n        yield arr[i:i+size]"
"def map_keys_deep(f, dct):\n    \"\"\"\n    Implementation of map that recurses. This tests the same keys at every level of dict and in lists\n    :param f: 2-ary function expecting a key and value and returns a modified key\n    :param dct: Dict for deep processing\n    :return: Modified dct with matching props mapped\n    \"\"\"\n    return _map_deep(lambda k, v: [f(k, v), v], dct)"
"def reraise(error):\n    \"\"\"Re-raises the error that was processed by prepare_for_reraise earlier.\"\"\"\n    if hasattr(error, \"_type_\"):\n        six.reraise(type(error), error, error._traceback)\n    raise error"
"def replace(scope, strings, source, dest):\n    \"\"\"\n    Returns a copy of the given string (or list of strings) in which all\n    occurrences of the given source are replaced by the given dest.\n\n    :type  strings: string\n    :param strings: A string, or a list of strings.\n    :type  source: string\n    :param source: What to replace.\n    :type  dest: string\n    :param dest: What to replace it with.\n    :rtype:  string\n    :return: The resulting string, or list of strings.\n    \"\"\"\n    return [s.replace(source[0], dest[0]) for s in strings]"
"def get_category(self):\n        \"\"\"Get the category of the item.\n\n        :return: the category of the item.\n        :returntype: `unicode`\"\"\"\n        var = self.xmlnode.prop(\"category\")\n        if not var:\n            var = \"?\"\n        return var.decode(\"utf-8\")"
"def datetime_from_str(string):\n    \"\"\"\n\n    Args:\n        string: string of the form YYMMDD-HH_MM_SS, e.g 160930-18_43_01\n\n    Returns: a datetime object\n\n    \"\"\"\n\n\n    return datetime.datetime(year=2000+int(string[0:2]), month=int(string[2:4]), day=int(string[4:6]), hour=int(string[7:9]), minute=int(string[10:12]),second=int(string[13:15]))"
"def _draw_lines_internal(self, coords, colour, bg):\n        \"\"\"Helper to draw lines connecting a set of nodes that are scaled for the Screen.\"\"\"\n        for i, (x, y) in enumerate(coords):\n            if i == 0:\n                self._screen.move(x, y)\n            else:\n                self._screen.draw(x, y, colour=colour, bg=bg, thin=True)"
"def l2_norm(arr):\n    \"\"\"\n    The l2 norm of an array is is defined as: sqrt(||x||), where ||x|| is the\n    dot product of the vector.\n    \"\"\"\n    arr = np.asarray(arr)\n    return np.sqrt(np.dot(arr.ravel().squeeze(), arr.ravel().squeeze()))"
"def prune(self, n):\n        \"\"\"prune all but the first (=best) n items\"\"\"\n        if self.minimize:\n            self.data = self.data[:n]\n        else:\n            self.data = self.data[-1 * n:]"
"def get_tail(self):\n        \"\"\"Gets tail\n\n        :return: Tail of linked list\n        \"\"\"\n        node = self.head\n        last_node = self.head\n\n        while node is not None:\n            last_node = node\n            node = node.next_node\n\n        return last_node"
"def flatten(nested):\n    \"\"\" Return a flatten version of the nested argument \"\"\"\n    flat_return = list()\n\n    def __inner_flat(nested,flat):\n        for i in nested:\n            __inner_flat(i, flat) if isinstance(i, list) else flat.append(i)\n        return flat\n\n    __inner_flat(nested,flat_return)\n\n    return flat_return"
"def zeros(self, name, **kwargs):\n        \"\"\"Create an array. Keyword arguments as per\n        :func:`zarr.creation.zeros`.\"\"\"\n        return self._write_op(self._zeros_nosync, name, **kwargs)"
"def urlencoded(body, charset='ascii', **kwargs):\n    \"\"\"Converts query strings into native Python objects\"\"\"\n    return parse_query_string(text(body, charset=charset), False)"
"def safe_exit(output):\n    \"\"\"exit without breaking pipes.\"\"\"\n    try:\n        sys.stdout.write(output)\n        sys.stdout.flush()\n    except IOError:\n        pass"
"def get_last_id(self, cur, table='reaction'):\n        \"\"\"\n        Get the id of the last written row in table\n\n        Parameters\n        ----------\n        cur: database connection().cursor() object\n        table: str\n            'reaction', 'publication', 'publication_system', 'reaction_system'\n\n        Returns: id\n        \"\"\"\n        cur.execute(\"SELECT seq FROM sqlite_sequence WHERE name='{0}'\"\n                    .format(table))\n        result = cur.fetchone()\n        if result is not None:\n            id = result[0]\n        else:\n            id = 0\n        return id"
"def trim(self):\n        \"\"\"Clear not used counters\"\"\"\n        for key, value in list(iteritems(self.counters)):\n            if value.empty():\n                del self.counters[key]"
"def strip_columns(tab):\n    \"\"\"Strip whitespace from string columns.\"\"\"\n    for colname in tab.colnames:\n        if tab[colname].dtype.kind in ['S', 'U']:\n            tab[colname] = np.core.defchararray.strip(tab[colname])"
"def add_to_parser(self, parser):\n        \"\"\"\n        Adds the argument to an argparse.ArgumentParser instance\n\n        @param parser An argparse.ArgumentParser instance\n        \"\"\"\n        kwargs = self._get_kwargs()\n        args = self._get_args()\n        parser.add_argument(*args, **kwargs)"
"def _truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n    \"\"\"\n    Truncates a colormap to use.\n    Code originall from http://stackoverflow.com/questions/18926031/how-to-extract-a-subset-of-a-colormap-as-a-new-colormap-in-matplotlib\n    \"\"\"\n    new_cmap = LinearSegmentedColormap.from_list(\n        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n        cmap(numpy.linspace(minval, maxval, n))\n    )\n    return new_cmap"
"def base64ToImage(imgData, out_path, out_file):\n        \"\"\" converts a base64 string to a file \"\"\"\n        fh = open(os.path.join(out_path, out_file), \"wb\")\n        fh.write(imgData.decode('base64'))\n        fh.close()\n        del fh\n        return os.path.join(out_path, out_file)"
"def distance_to_line(a, b, p):\n    \"\"\"Closest distance between a line segment and a point\n\n    Args:\n        a ([float, float]): x and y coordinates. Line start\n        b ([float, float]): x and y coordinates. Line end\n        p ([float, float]): x and y coordinates. Point to compute the distance\n    Returns:\n        float\n    \"\"\"\n    return distance(closest_point(a, b, p), p)"
"def apply_kwargs(func, **kwargs):\n    \"\"\"Call *func* with kwargs, but only those kwargs that it accepts.\n    \"\"\"\n    new_kwargs = {}\n    params = signature(func).parameters\n    for param_name in params.keys():\n        if param_name in kwargs:\n            new_kwargs[param_name] = kwargs[param_name]\n    return func(**new_kwargs)"
"def hard_equals(a, b):\n    \"\"\"Implements the '===' operator.\"\"\"\n    if type(a) != type(b):\n        return False\n    return a == b"
"def money(min=0, max=10):\n    \"\"\"Return a str of decimal with two digits after a decimal mark.\"\"\"\n    value = random.choice(range(min * 100, max * 100))\n    return \"%1.2f\" % (float(value) / 100)"
"def join(self):\n\t\t\"\"\"Note that the Executor must be close()'d elsewhere,\n\t\tor join() will never return.\n\t\t\"\"\"\n\t\tself.inputfeeder_thread.join()\n\t\tself.pool.join()\n\t\tself.resulttracker_thread.join()\n\t\tself.failuretracker_thread.join()"
"def region_from_segment(image, segment):\n    \"\"\"given a segment (rectangle) and an image, returns it's corresponding subimage\"\"\"\n    x, y, w, h = segment\n    return image[y:y + h, x:x + w]"
"def _obj_cursor_to_dictionary(self, cursor):\n        \"\"\"Handle conversion of pymongo cursor into a JSON object formatted for UI consumption\n\n        :param dict cursor: a mongo document that should be converted to primitive types for the client code\n        :returns: a primitive dictionary\n        :rtype: dict\n        \"\"\"\n        if not cursor:\n            return cursor\n\n        cursor = json.loads(json.dumps(cursor, cls=BSONEncoder))\n\n        if cursor.get(\"_id\"):\n            cursor[\"id\"] = cursor.get(\"_id\")\n            del cursor[\"_id\"]\n\n        return cursor"
"def write_wav(path, samples, sr=16000):\n    \"\"\"\n    Write to given samples to a wav file.\n    The samples are expected to be floating point numbers\n    in the range of -1.0 to 1.0.\n\n    Args:\n        path (str): The path to write the wav to.\n        samples (np.array): A float array .\n        sr (int): The sampling rate.\n    \"\"\"\n    max_value = np.abs(np.iinfo(np.int16).min)\n    data = (samples * max_value).astype(np.int16)\n    scipy.io.wavfile.write(path, sr, data)"
"def created_today(self):\n        \"\"\"Return True if created today.\"\"\"\n        if self.datetime.date() == datetime.today().date():\n            return True\n        return False"
"def stringify_dict_contents(dct):\n    \"\"\"Turn dict keys and values into native strings.\"\"\"\n    return {\n        str_if_nested_or_str(k): str_if_nested_or_str(v)\n        for k, v in dct.items()\n    }"
"def is_image_file_valid(file_path_name):\n    \"\"\"\n    Indicate whether the specified image file is valid or not.\n\n\n    @param file_path_name: absolute path and file name of an image.\n\n\n    @return: ``True`` if the image file is valid, ``False`` if the file is\n        truncated or does not correspond to a supported image.\n    \"\"\"\n    # Image.verify is only implemented for PNG images, and it only verifies\n    # the CRC checksum in the image.  The only way to check from within\n    # Pillow is to load the image in a try/except and check the error.  If\n    # as much info as possible is from the image is needed,\n    # ``ImageFile.LOAD_TRUNCATED_IMAGES=True`` needs to bet set and it\n    # will attempt to parse as much as possible.\n    try:\n        with Image.open(file_path_name) as image:\n            image.load()\n    except IOError:\n        return False\n\n    return True"
"def rstjinja(app, docname, source):\n    \"\"\"\n    Render our pages as a jinja template for fancy templating goodness.\n    \"\"\"\n    # Make sure we're outputting HTML\n    if app.builder.format != 'html':\n        return\n    src = source[0]\n    rendered = app.builder.templates.render_string(\n        src, app.config.html_context\n    )\n    source[0] = rendered"
"def main(argv=None):\n  \"\"\"Run a Tensorflow model on the Iris dataset.\"\"\"\n  args = parse_arguments(sys.argv if argv is None else argv)\n\n  tf.logging.set_verbosity(tf.logging.INFO)\n  learn_runner.run(\n      experiment_fn=get_experiment_fn(args),\n      output_dir=args.job_dir)"
"def makedirs(path, mode=0o777, exist_ok=False):\n    \"\"\"A wrapper of os.makedirs().\"\"\"\n    os.makedirs(path, mode, exist_ok)"
"def current_zipfile():\n    \"\"\"A function to vend the current zipfile, if any\"\"\"\n    if zipfile.is_zipfile(sys.argv[0]):\n        fd = open(sys.argv[0], \"rb\")\n        return zipfile.ZipFile(fd)"
"def strtobytes(input, encoding):\n    \"\"\"Take a str and transform it into a byte array.\"\"\"\n    py_version = sys.version_info[0]\n    if py_version >= 3:\n        return _strtobytes_py3(input, encoding)\n    return _strtobytes_py2(input, encoding)"
"def round_to_float(number, precision):\n    \"\"\"Round a float to a precision\"\"\"\n    rounded = Decimal(str(floor((number + precision / 2) // precision))\n                      ) * Decimal(str(precision))\n    return float(rounded)"
"def rank(self):\n        \"\"\"how high in sorted list each key is. inverse permutation of sorter, such that sorted[rank]==keys\"\"\"\n        r = np.empty(self.size, np.int)\n        r[self.sorter] = np.arange(self.size)\n        return r"
"def _normalize(mat: np.ndarray):\n    \"\"\"rescales a numpy array, so that min is 0 and max is 255\"\"\"\n    return ((mat - mat.min()) * (255 / mat.max())).astype(np.uint8)"
"def insort_no_dup(lst, item):\n    \"\"\"\n    If item is not in lst, add item to list at its sorted position\n    \"\"\"\n    import bisect\n    ix = bisect.bisect_left(lst, item)\n    if lst[ix] != item: \n        lst[ix:ix] = [item]"
"def get_url_nofollow(url):\n\t\"\"\" \n\tfunction to get return code of a url\n\n\tCredits: http://blog.jasonantman.com/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/\n\t\"\"\"\n\ttry:\n\t\tresponse = urlopen(url)\n\t\tcode = response.getcode()\n\t\treturn code\n\texcept HTTPError as e:\n\t\treturn e.code\n\texcept:\n\t\treturn 0"
"def Flush(self):\n    \"\"\"Flush all items from cache.\"\"\"\n    while self._age:\n      node = self._age.PopLeft()\n      self.KillObject(node.data)\n\n    self._hash = dict()"
"def is_lazy_iterable(obj):\n    \"\"\"\n    Returns whether *obj* is iterable lazily, such as generators, range objects, etc.\n    \"\"\"\n    return isinstance(obj,\n        (types.GeneratorType, collections.MappingView, six.moves.range, enumerate))"
"def _digits(minval, maxval):\n    \"\"\"Digits needed to comforatbly display values in [minval, maxval]\"\"\"\n    if minval == maxval:\n        return 3\n    else:\n        return min(10, max(2, int(1 + abs(np.log10(maxval - minval)))))"
"def makedirs(path, mode=0o777, exist_ok=False):\n    \"\"\"A wrapper of os.makedirs().\"\"\"\n    os.makedirs(path, mode, exist_ok)"
"def _saferound(value, decimal_places):\n    \"\"\"\n    Rounds a float value off to the desired precision\n    \"\"\"\n    try:\n        f = float(value)\n    except ValueError:\n        return ''\n    format = '%%.%df' % decimal_places\n    return format % f"
"def __getitem__(self, name):\n        \"\"\"\n        A pymongo-like behavior for dynamically obtaining a collection of documents\n        \"\"\"\n        if name not in self._collections:\n            self._collections[name] = Collection(self.db, name)\n        return self._collections[name]"
"def ex(self, cmd):\n        \"\"\"Execute a normal python statement in user namespace.\"\"\"\n        with self.builtin_trap:\n            exec cmd in self.user_global_ns, self.user_ns"
"def dot_v3(v, w):\n    \"\"\"Return the dotproduct of two vectors.\"\"\"\n\n    return sum([x * y for x, y in zip(v, w)])"
"def write_image(filename, image):\n    \"\"\" Write image data to PNG, JPG file\n\n    :param filename: name of PNG or JPG file to write data to\n    :type filename: str\n    :param image: image data to write to file\n    :type image: numpy array\n    \"\"\"\n    data_format = get_data_format(filename)\n    if data_format is MimeType.JPG:\n        LOGGER.warning('Warning: jpeg is a lossy format therefore saved data will be modified.')\n    return Image.fromarray(image).save(filename)"
"def auto_up(self, count=1, go_to_start_of_line_if_history_changes=False):\n        \"\"\"\n        If we're not on the first line (of a multiline input) go a line up,\n        otherwise go back in history. (If nothing is selected.)\n        \"\"\"\n        if self.complete_state:\n            self.complete_previous(count=count)\n        elif self.document.cursor_position_row > 0:\n            self.cursor_up(count=count)\n        elif not self.selection_state:\n            self.history_backward(count=count)\n\n            # Go to the start of the line?\n            if go_to_start_of_line_if_history_changes:\n                self.cursor_position += self.document.get_start_of_line_position()"
"def c2s(self,p=[0,0]):\n        \"\"\"Convert from canvas to screen coordinates\"\"\"\n\n        return((p[0]-self.canvasx(self.cx1),p[1]-self.canvasy(self.cy1)))"
"def lsr_pairwise_dense(comp_mat, alpha=0.0, initial_params=None):\n    \"\"\"Compute the LSR estimate of model parameters given dense data.\n\n    This function implements the Luce Spectral Ranking inference algorithm\n    [MG15]_ for dense pairwise-comparison data.\n\n    The data is described by a pairwise-comparison matrix ``comp_mat`` such\n    that ``comp_mat[i,j]`` contains the number of times that item ``i`` wins\n    against item ``j``.\n\n    In comparison to :func:`~choix.lsr_pairwise`, this function is particularly\n    efficient for dense pairwise-comparison datasets (i.e., containing many\n    comparisons for a large fraction of item pairs).\n\n    The argument ``initial_params`` can be used to iteratively refine an\n    existing parameter estimate (see the implementation of\n    :func:`~choix.ilsr_pairwise` for an idea on how this works). If it is set\n    to `None` (the default), the all-ones vector is used.\n\n    The transition rates of the LSR Markov chain are initialized with\n    ``alpha``. When ``alpha > 0``, this corresponds to a form of regularization\n    (see :ref:`regularization` for details).\n\n    Parameters\n    ----------\n    comp_mat : np.array\n        2D square matrix describing the pairwise-comparison outcomes.\n    alpha : float, optional\n        Regularization parameter.\n    initial_params : array_like, optional\n        Parameters used to build the transition rates of the LSR Markov chain.\n\n    Returns\n    -------\n    params : np.array\n        An estimate of model parameters.\n    \"\"\"\n    n_items = comp_mat.shape[0]\n    ws, chain = _init_lsr(n_items, alpha, initial_params)\n    denom = np.tile(ws, (n_items, 1))\n    chain += comp_mat.T / (denom + denom.T)\n    chain -= np.diag(chain.sum(axis=1))\n    return log_transform(statdist(chain))"
"def deprecate(func):\n  \"\"\" A deprecation warning emmiter as a decorator. \"\"\"\n  @wraps(func)\n  def wrapper(*args, **kwargs):\n    warn(\"Deprecated, this will be removed in the future\", DeprecationWarning)\n    return func(*args, **kwargs)\n  wrapper.__doc__ = \"Deprecated.\\n\" + (wrapper.__doc__ or \"\")\n  return wrapper"
"def all_strings(arr):\n        \"\"\"\n        Ensures that the argument is a list that either is empty or contains only strings\n        :param arr: list\n        :return:\n        \"\"\"\n        if not isinstance([], list):\n            raise TypeError(\"non-list value found where list is expected\")\n        return all(isinstance(x, str) for x in arr)"
"def getElementsBy(self, cond: Callable[[Element], bool]) -> NodeList:\n        \"\"\"Get elements in this document which matches condition.\"\"\"\n        return getElementsBy(self, cond)"
"def na_if(series, *values):\n    \"\"\"\n    If values in a series match a specified value, change them to `np.nan`.\n\n    Args:\n        series: Series or vector, often symbolic.\n        *values: Value(s) to convert to `np.nan` in the series.\n    \"\"\"\n\n    series = pd.Series(series)\n    series[series.isin(values)] = np.nan\n    return series"
"def print_statements(self):\n        \"\"\"Print all INDRA Statements collected by the processors.\"\"\"\n        for i, stmt in enumerate(self.statements):\n            print(\"%s: %s\" % (i, stmt))"
"def clean_all_buckets(self):\n        \"\"\"\n        Removes all buckets from all hashes and their content.\n        \"\"\"\n        bucket_keys = self.redis_object.keys(pattern='nearpy_*')\n        if len(bucket_keys) > 0:\n            self.redis_object.delete(*bucket_keys)"
"def frombits(cls, bits):\n        \"\"\"Series from binary string arguments.\"\"\"\n        return cls.frombitsets(map(cls.BitSet.frombits, bits))"
"def __remove_trailing_zeros(self, collection):\n        \"\"\"Removes trailing zeroes from indexable collection of numbers\"\"\"\n        index = len(collection) - 1\n        while index >= 0 and collection[index] == 0:\n            index -= 1\n\n        return collection[:index + 1]"
"def _fullname(o):\n    \"\"\"Return the fully-qualified name of a function.\"\"\"\n    return o.__module__ + \".\" + o.__name__ if o.__module__ else o.__name__"
"def retry_on_signal(function):\n    \"\"\"Retries function until it doesn't raise an EINTR error\"\"\"\n    while True:\n        try:\n            return function()\n        except EnvironmentError, e:\n            if e.errno != errno.EINTR:\n                raise"
"def str_to_time(time_str: str) -> datetime.datetime:\n    \"\"\"\n    Convert human readable string to datetime.datetime.\n    \"\"\"\n    pieces: Any = [int(piece) for piece in time_str.split('-')]\n    return datetime.datetime(*pieces)"
"def safe_unicode(string):\n    \"\"\"If Python 2, replace non-ascii characters and return encoded string.\"\"\"\n    if not PY3:\n        uni = string.replace(u'\\u2019', \"'\")\n        return uni.encode('utf-8')\n        \n    return string"
"def debugTreePrint(node,pfx=\"->\"):\n  \"\"\"Purely a debugging aid: Ascii-art picture of a tree descended from node\"\"\"\n  print pfx,node.item\n  for c in node.children:\n    debugTreePrint(c,\"  \"+pfx)"
"def dtypes(self):\n        \"\"\"Returns all column names and their data types as a list.\n\n        >>> df.dtypes\n        [('age', 'int'), ('name', 'string')]\n        \"\"\"\n        return [(str(f.name), f.dataType.simpleString()) for f in self.schema.fields]"
"def is_date_type(cls):\n    \"\"\"Return True if the class is a date type.\"\"\"\n    if not isinstance(cls, type):\n        return False\n    return issubclass(cls, date) and not issubclass(cls, datetime)"
"def convolve_gaussian_2d(image, gaussian_kernel_1d):\n    \"\"\"Convolve 2d gaussian.\"\"\"\n    result = scipy.ndimage.filters.correlate1d(\n        image, gaussian_kernel_1d, axis=0)\n    result = scipy.ndimage.filters.correlate1d(\n        result, gaussian_kernel_1d, axis=1)\n    return result"
"def clear(self):\n        \"\"\"Remove all items.\"\"\"\n        self._fwdm.clear()\n        self._invm.clear()\n        self._sntl.nxt = self._sntl.prv = self._sntl"
"def s3_get(url: str, temp_file: IO) -> None:\n    \"\"\"Pull a file directly from S3.\"\"\"\n    s3_resource = boto3.resource(\"s3\")\n    bucket_name, s3_path = split_s3_path(url)\n    s3_resource.Bucket(bucket_name).download_fileobj(s3_path, temp_file)"
"def get_files(dir_name):\n    \"\"\"Simple directory walker\"\"\"\n    return [(os.path.join('.', d), [os.path.join(d, f) for f in files]) for d, _, files in os.walk(dir_name)]"
"def is_readable_dir(path):\n  \"\"\"Returns whether a path names an existing directory we can list and read files from.\"\"\"\n  return os.path.isdir(path) and os.access(path, os.R_OK) and os.access(path, os.X_OK)"
"def load(cls, fp, **kwargs):\n    \"\"\"wrapper for :py:func:`json.load`\"\"\"\n    json_obj = json.load(fp, **kwargs)\n    return parse(cls, json_obj)"
"def get_site_name(request):\n    \"\"\"Return the domain:port part of the URL without scheme.\n    Eg: facebook.com, 127.0.0.1:8080, etc.\n    \"\"\"\n    urlparts = request.urlparts\n    return ':'.join([urlparts.hostname, str(urlparts.port)])"
"def version_triple(tag):\n    \"\"\"\n    returns: a triple of integers from a version tag\n    \"\"\"\n    groups = re.match(r'v?(\\d+)\\.(\\d+)\\.(\\d+)', tag).groups()\n    return tuple(int(n) for n in groups)"
"def strip_figures(figure):\n\t\"\"\"\n\tStrips a figure into multiple figures with a trace on each of them\n\n\tParameters:\n\t-----------\n\t\tfigure : Figure\n\t\t\tPlotly Figure\n\t\"\"\"\n\tfig=[]\n\tfor trace in figure['data']:\n\t\tfig.append(dict(data=[trace],layout=figure['layout']))\n\treturn fig"
"def matches_glob_list(path, glob_list):\n    \"\"\"\n    Given a list of glob patterns, returns a boolean\n    indicating if a path matches any glob in the list\n    \"\"\"\n    for glob in glob_list:\n        try:\n            if PurePath(path).match(glob):\n                return True\n        except TypeError:\n            pass\n    return False"
"def get_domain(url):\n    \"\"\"\n    Get domain part of an url.\n\n    For example: https://www.python.org/doc/ -> https://www.python.org\n    \"\"\"\n    parse_result = urlparse(url)\n    domain = \"{schema}://{netloc}\".format(\n        schema=parse_result.scheme, netloc=parse_result.netloc)\n    return domain"
"def getBuffer(x):\n    \"\"\"\n    Copy @x into a (modifiable) ctypes byte array\n    \"\"\"\n    b = bytes(x)\n    return (c_ubyte * len(b)).from_buffer_copy(bytes(x))"
"def get_column_keys_and_names(table):\n    \"\"\"\n    Return a generator of tuples k, c such that k is the name of the python attribute for\n    the column and c is the name of the column in the sql table.\n    \"\"\"\n    ins = inspect(table)\n    return ((k, c.name) for k, c in ins.mapper.c.items())"
"def stretch(iterable, n=2):\n    r\"\"\"Repeat each item in `iterable` `n` times.\n\n    Example:\n\n    >>> list(stretch(range(3), 2))\n    [0, 0, 1, 1, 2, 2]\n    \"\"\"\n    times = range(n)\n    for item in iterable:\n        for i in times: yield item"
"def fast_median(a):\n    \"\"\"Fast median operation for masked array using 50th-percentile\n    \"\"\"\n    a = checkma(a)\n    #return scoreatpercentile(a.compressed(), 50)\n    if a.count() > 0:\n        out = np.percentile(a.compressed(), 50)\n    else:\n        out = np.ma.masked\n    return out"
"def isetdiff_flags(list1, list2):\n    \"\"\"\n    move to util_iter\n    \"\"\"\n    set2 = set(list2)\n    return (item not in set2 for item in list1)"
"def prepend_line(filepath, line):\n    \"\"\"Rewrite a file adding a line to its beginning.\n    \"\"\"\n    with open(filepath) as f:\n        lines = f.readlines()\n\n    lines.insert(0, line)\n\n    with open(filepath, 'w') as f:\n        f.writelines(lines)"
"def show(self, title=''):\n        \"\"\"\n        Display Bloch sphere and corresponding data sets.\n        \"\"\"\n        self.render(title=title)\n        if self.fig:\n            plt.show(self.fig)"
"def close_all():\n    r\"\"\"Close all opened windows.\"\"\"\n\n    # Windows can be closed by releasing all references to them so they can be\n    # garbage collected. May not be necessary to call close().\n    global _qtg_windows\n    for window in _qtg_windows:\n        window.close()\n    _qtg_windows = []\n\n    global _qtg_widgets\n    for widget in _qtg_widgets:\n        widget.close()\n    _qtg_widgets = []\n\n    global _plt_figures\n    for fig in _plt_figures:\n        _, plt, _ = _import_plt()\n        plt.close(fig)\n    _plt_figures = []"
"def _repr(obj):\n    \"\"\"Show the received object as precise as possible.\"\"\"\n    vals = \", \".join(\"{}={!r}\".format(\n        name, getattr(obj, name)) for name in obj._attribs)\n    if vals:\n        t = \"{}(name={}, {})\".format(obj.__class__.__name__, obj.name, vals)\n    else:\n        t = \"{}(name={})\".format(obj.__class__.__name__, obj.name)\n    return t"
"def numpy_aware_eq(a, b):\n    \"\"\"Return whether two objects are equal via recursion, using\n    :func:`numpy.array_equal` for comparing numpy arays.\n    \"\"\"\n    if isinstance(a, np.ndarray) or isinstance(b, np.ndarray):\n        return np.array_equal(a, b)\n    if ((isinstance(a, Iterable) and isinstance(b, Iterable)) and\n            not isinstance(a, str) and not isinstance(b, str)):\n        if len(a) != len(b):\n            return False\n        return all(numpy_aware_eq(x, y) for x, y in zip(a, b))\n    return a == b"
"def ylabelsize(self, size, index=1):\n        \"\"\"Set the size of the label.\n\n        Parameters\n        ----------\n        size : int\n\n        Returns\n        -------\n        Chart\n\n        \"\"\"\n        self.layout['yaxis' + str(index)]['titlefont']['size'] = size\n        return self"
"def argmax(self, rows: List[Row], column: ComparableColumn) -> List[Row]:\n        \"\"\"\n        Takes a list of rows and a column name and returns a list containing a single row (dict from\n        columns to cells) that has the maximum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"\n        if not rows:\n            return []\n        value_row_pairs = [(row.values[column.name], row) for row in rows]\n        if not value_row_pairs:\n            return []\n        # Returns a list containing the row with the max cell value.\n        return [sorted(value_row_pairs, key=lambda x: x[0], reverse=True)[0][1]]"
"def Distance(lat1, lon1, lat2, lon2):\n    \"\"\"Get distance between pairs of lat-lon points\"\"\"\n\n    az12, az21, dist = wgs84_geod.inv(lon1, lat1, lon2, lat2)\n    return az21, dist"
"def get_closest_index(myList, myNumber):\n    \"\"\"\n    Assumes myList is sorted. Returns closest value to myNumber.\n    If two numbers are equally close, return the smallest number.\n\n    Parameters\n    ----------\n    myList : array\n        The list in which to find the closest value to myNumber\n    myNumber : float\n        The number to find the closest to in MyList\n\n    Returns\n    -------\n    closest_values_index : int\n        The index in the array of the number closest to myNumber in myList\n    \"\"\"\n    closest_values_index = _np.where(self.time == take_closest(myList, myNumber))[0][0]\n    return closest_values_index"
"def remove_property(self, key=None, value=None):\n        \"\"\"Remove all properties matching both key and value.\n\n        :param str key: Key of the property.\n        :param str value: Value of the property.\n        \"\"\"\n        for k, v in self.properties[:]:\n            if (key is None or key == k) and (value is None or value == v):\n                del(self.properties[self.properties.index((k, v))])"
"def get_column_keys_and_names(table):\n    \"\"\"\n    Return a generator of tuples k, c such that k is the name of the python attribute for\n    the column and c is the name of the column in the sql table.\n    \"\"\"\n    ins = inspect(table)\n    return ((k, c.name) for k, c in ins.mapper.c.items())"
"def _escape(s):\n    \"\"\" Helper method that escapes parameters to a SQL query. \"\"\"\n    e = s\n    e = e.replace('\\\\', '\\\\\\\\')\n    e = e.replace('\\n', '\\\\n')\n    e = e.replace('\\r', '\\\\r')\n    e = e.replace(\"'\", \"\\\\'\")\n    e = e.replace('\"', '\\\\\"')\n    return e"
"def exists(self):\n        \"\"\"\n        Determine if any rows exist for the current query.\n\n        :return: Whether the rows exist or not\n        :rtype: bool\n        \"\"\"\n        limit = self.limit_\n\n        result = self.limit(1).count() > 0\n\n        self.limit(limit)\n\n        return result"
"def __str__(self):\n        \"\"\"Return human readable string.\"\"\"\n        return \", \".join(\"{:02x}{:02x}={:02x}{:02x}\".format(c[0][0], c[0][1], c[1][0], c[1][1]) for c in self.alias_array_)"
"def _mid(pt1, pt2):\n    \"\"\"\n    (Point, Point) -> Point\n    Return the point that lies in between the two input points.\n    \"\"\"\n    (x0, y0), (x1, y1) = pt1, pt2\n    return 0.5 * (x0 + x1), 0.5 * (y0 + y1)"
"def parse_json_date(value):\n    \"\"\"\n    Parses an ISO8601 formatted datetime from a string value\n    \"\"\"\n    if not value:\n        return None\n\n    return datetime.datetime.strptime(value, JSON_DATETIME_FORMAT).replace(tzinfo=pytz.UTC)"
"def __add__(self, other):\n        \"\"\"Left addition.\"\"\"\n        return chaospy.poly.collection.arithmetics.add(self, other)"
"def QA_util_datetime_to_strdate(dt):\n    \"\"\"\n    :param dt:  pythone datetime.datetime\n    :return:  1999-02-01 string type\n    \"\"\"\n    strdate = \"%04d-%02d-%02d\" % (dt.year, dt.month, dt.day)\n    return strdate"
"def vector_distance(a, b):\n    \"\"\"The Euclidean distance between two vectors.\"\"\"\n    a = np.array(a)\n    b = np.array(b)\n    return np.linalg.norm(a - b)"
"def toHdlConversion(self, top, topName: str, saveTo: str) -> List[str]:\n        \"\"\"\n        :param top: object which is represenation of design\n        :param topName: name which should be used for ipcore\n        :param saveTo: path of directory where generated files should be stored\n\n        :return: list of file namens in correct compile order\n        \"\"\"\n        raise NotImplementedError(\n            \"Implement this function for your type of your top module\")"
"def debug(self, text):\n\t\t\"\"\" Ajout d'un message de log de type DEBUG \"\"\"\n\t\tself.logger.debug(\"{}{}\".format(self.message_prefix, text))"
"def test():  # pragma: no cover\n    \"\"\"Execute the unit tests on an installed copy of unyt.\n\n    Note that this function requires pytest to run. If pytest is not\n    installed this function will raise ImportError.\n    \"\"\"\n    import pytest\n    import os\n\n    pytest.main([os.path.dirname(os.path.abspath(__file__))])"
"def title(self):\n        \"\"\" The title of this window \"\"\"\n        with switch_window(self._browser, self.name):\n            return self._browser.title"
"def parse_form(self, req, name, field):\n        \"\"\"Pull a form value from the request.\"\"\"\n        return get_value(req.body_arguments, name, field)"
"def block(seed):\n    \"\"\" Return block of normal random numbers\n\n    Parameters\n    ----------\n    seed : {None, int}\n        The seed to generate the noise.sd\n\n    Returns\n    --------\n    noise : numpy.ndarray\n        Array of random numbers\n    \"\"\"\n    num = SAMPLE_RATE * BLOCK_SIZE\n    rng = RandomState(seed % 2**32)\n    variance = SAMPLE_RATE / 2\n    return rng.normal(size=num, scale=variance**0.5)"
"def any_contains_any(strings, candidates):\n    \"\"\"Whether any of the strings contains any of the candidates.\"\"\"\n    for string in strings:\n        for c in candidates:\n            if c in string:\n                return True"
"def _skip_section(self):\n        \"\"\"Skip a section\"\"\"\n        self._last = self._f.readline()\n        while len(self._last) > 0 and len(self._last[0].strip()) == 0:\n            self._last = self._f.readline()"
"def make_symmetric(dict):\n    \"\"\"Makes the given dictionary symmetric. Values are assumed to be unique.\"\"\"\n    for key, value in list(dict.items()):\n        dict[value] = key\n    return dict"
"def isnamedtuple(obj):\n    \"\"\"Heuristic check if an object is a namedtuple.\"\"\"\n    return isinstance(obj, tuple) \\\n           and hasattr(obj, \"_fields\") \\\n           and hasattr(obj, \"_asdict\") \\\n           and callable(obj._asdict)"
"def add_blank_row(self, label):\n        \"\"\"\n        Add a blank row with only an index value to self.df.\n        This is done inplace.\n        \"\"\"\n        col_labels = self.df.columns\n        blank_item = pd.Series({}, index=col_labels, name=label)\n        # use .loc to add in place (append won't do that)\n        self.df.loc[blank_item.name] = blank_item\n        return self.df"
"def zfill(x, width):\n    \"\"\"zfill(x, width) -> string\n\n    Pad a numeric string x with zeros on the left, to fill a field\n    of the specified width.  The string x is never truncated.\n\n    \"\"\"\n    if not isinstance(x, basestring):\n        x = repr(x)\n    return x.zfill(width)"
