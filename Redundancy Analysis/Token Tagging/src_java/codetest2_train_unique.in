protected final void fastPathOrderedEmit ( U value , boolean delayError , Disposable disposable ) { 
final Observer < ? super V > observer = downstream ; 
final SimplePlainQueue < U > q = queue ; 
if ( wip . get ( ) == 0 && wip . compareAndSet ( 0 , 1 ) ) { 
if ( q . isEmpty ( ) ) { 
accept ( observer , value ) ; 
if ( leave ( - 1 ) == 0 ) { 
return ; 
} 
} else { 
q . offer ( value ) ; 
if ( ! enter ( ) ) { 
QueueDrainHelper . drainLoop ( q , observer , delayError , disposable , this ) ; 
} @ CheckReturnValue 
@ NonNull 
@ SchedulerSupport ( SchedulerSupport . NONE ) 
public static < T > Observable < T > amb ( Iterable < ? extends ObservableSource < ? extends T > > sources ) { 
return RxJavaPlugins . onAssembly ( new ObservableAmb < T > ( null , sources ) ) ; 
} @ SuppressWarnings ( "unchecked" ) 
@ CheckReturnValue 
public static < T > Observable < T > ambArray ( ObservableSource < ? extends T > ... sources ) { 
int len = sources . length ; 
if ( len == 0 ) { 
return empty ( ) ; 
if ( len == 1 ) { 
return ( Observable < T > ) wrap ( sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new ObservableAmb < T > ( sources , null ) ) ; 
} @ SuppressWarnings ( { "unchecked" , "rawtypes" } ) 
public static < T > Observable < T > concat ( Iterable < ? extends ObservableSource < ? extends T > > sources ) { 
return fromIterable ( sources ) . concatMapDelayError ( ( Function ) Functions . identity ( ) , bufferSize ( ) , false ) ; 
public static < T > Observable < T > concat ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , int prefetch ) { 
ObjectHelper . verifyPositive ( prefetch , "prefetch" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableConcatMap ( sources , Functions . identity ( ) , prefetch , ErrorMode . IMMEDIATE ) ) ; 
public static < T > Observable < T > concatArray ( ObservableSource < ? extends T > ... sources ) { 
if ( sources . length == 0 ) { 
} else 
if ( sources . length == 1 ) { 
return wrap ( ( ObservableSource < T > ) sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new ObservableConcatMap ( fromArray ( sources ) , Functions . identity ( ) , bufferSize ( ) , ErrorMode . BOUNDARY ) ) ; 
} @ SuppressWarnings ( { "unchecked" } ) 
public static < T > Observable < T > concatArrayDelayError ( ObservableSource < ? extends T > ... sources ) { 
return concatDelayError ( fromArray ( sources ) ) ; 
public static < T > Observable < T > concatArrayEager ( ObservableSource < ? extends T > ... sources ) { 
return concatArrayEager ( bufferSize ( ) , bufferSize ( ) , sources ) ; 
} @ SuppressWarnings ( { "rawtypes" , "unchecked" } ) 
public static < T > Observable < T > concatArrayEager ( int maxConcurrency , int prefetch , ObservableSource < ? extends T > ... sources ) { 
return fromArray ( sources ) . concatMapEagerDelayError ( ( Function ) Functions . identity ( ) , maxConcurrency , prefetch , false ) ; 
public static < T > Observable < T > concatArrayEagerDelayError ( int maxConcurrency , int prefetch , ObservableSource < ? extends T > ... sources ) { 
return fromArray ( sources ) . concatMapEagerDelayError ( ( Function ) Functions . identity ( ) , maxConcurrency , prefetch , true ) ; 
public static < T > Observable < T > concatDelayError ( ObservableSource < ? extends ObservableSource < ? extends T > > sources ) { 
return concatDelayError ( sources , bufferSize ( ) , true ) ; 
public static < T > Observable < T > concatDelayError ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , int prefetch , boolean tillTheEnd ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMap ( sources , Functions . identity ( ) , prefetch , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY ) ) ; 
public static < T > Observable < T > concatEager ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , int maxConcurrency , int prefetch ) { 
return wrap ( sources ) . concatMapEager ( ( Function ) Functions . identity ( ) , maxConcurrency , prefetch ) ; 
public static < T > Observable < T > concatEager ( Iterable < ? extends ObservableSource < ? extends T > > sources , int maxConcurrency , int prefetch ) { 
return fromIterable ( sources ) . concatMapEagerDelayError ( ( Function ) Functions . identity ( ) , maxConcurrency , prefetch , false ) ; 
@ SuppressWarnings ( "unchecked" ) 
public static < T > Observable < T > empty ( ) { 
return RxJavaPlugins . onAssembly ( ( Observable < T > ) ObservableEmpty . INSTANCE ) ; 
public static < T > Observable < T > error ( Callable < ? extends Throwable > errorSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableError < T > ( errorSupplier ) ) ; 
public static < T > Observable < T > fromArray ( T ... items ) { 
if ( items . length == 0 ) { 
if ( items . length == 1 ) { 
return just ( items [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new ObservableFromArray < T > ( items ) ) ; 
public static < T > Observable < T > fromIterable ( Iterable < ? extends T > source ) { 
return RxJavaPlugins . onAssembly ( new ObservableFromIterable < T > ( source ) ) ; 
} @ BackpressureSupport ( BackpressureKind . UNBOUNDED_IN ) 
public static < T > Observable < T > fromPublisher ( Publisher < ? extends T > publisher ) { 
return RxJavaPlugins . onAssembly ( new ObservableFromPublisher < T > ( publisher ) ) ; 
public static < T > Observable < T > generate ( final Consumer < Emitter < T > > generator ) { 
return generate ( Functions . < Object > nullSupplier ( ) , 
ObservableInternalHelper . simpleGenerator ( generator ) , Functions . < Object > emptyConsumer ( ) ) ; 
public static < T , S > Observable < T > generate ( Callable < S > initialState , BiFunction < S , Emitter < T > , S > generator ) { 
return generate ( initialState , generator , Functions . emptyConsumer ( ) ) ; 
@ SchedulerSupport ( SchedulerSupport . CUSTOM ) 
public static Observable < Long > interval ( long initialDelay , long period , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableInterval ( Math . max ( 0L , initialDelay ) , Math . max ( 0L , period ) , unit , scheduler ) ) ; 
@ SchedulerSupport ( SchedulerSupport . COMPUTATION ) 
public static Observable < Long > interval ( long period , TimeUnit unit ) { 
return interval ( period , period , unit , Schedulers . computation ( ) ) ; 
public static Observable < Long > interval ( long period , TimeUnit unit , Scheduler scheduler ) { 
return interval ( period , period , unit , scheduler ) ; 
public static Observable < Long > intervalRange ( long start , long count , long initialDelay , long period , TimeUnit unit ) { 
return intervalRange ( start , count , initialDelay , period , unit , Schedulers . computation ( ) ) ; 
public static Observable < Long > intervalRange ( long start , long count , long initialDelay , long period , TimeUnit unit , Scheduler scheduler ) { 
if ( count < 0 ) { 
if ( count == 0L ) { 
return Observable . < Long > empty ( ) . delay ( initialDelay , unit , scheduler ) ; 
long end = start + ( count - 1 ) ; 
if ( start > 0 && end < 0 ) { 
return RxJavaPlugins . onAssembly ( new ObservableIntervalRange ( start , end , Math . max ( 0L , initialDelay ) , Math . max ( 0L , period ) , unit , scheduler ) ) ; 
public static < T > Observable < T > just ( T item ) { 
return RxJavaPlugins . onAssembly ( new ObservableJust < T > ( item ) ) ; 
public static < T > Observable < T > merge ( Iterable < ? extends ObservableSource < ? extends T > > sources , int maxConcurrency , int bufferSize ) { 
return fromIterable ( sources ) . flatMap ( ( Function ) Functions . identity ( ) , false , maxConcurrency , bufferSize ) ; 
public static < T > Observable < T > mergeArray ( int maxConcurrency , int bufferSize , ObservableSource < ? extends T > ... sources ) { 
return fromArray ( sources ) . flatMap ( ( Function ) Functions . identity ( ) , false , maxConcurrency , bufferSize ) ; 
@ SuppressWarnings ( { "unchecked" , "rawtypes" } ) 
public static < T > Observable < T > merge ( ObservableSource < ? extends ObservableSource < ? extends T > > sources ) { 
return RxJavaPlugins . onAssembly ( new ObservableFlatMap ( sources , Functions . identity ( ) , false , Integer . MAX_VALUE , bufferSize ( ) ) ) ; 
public static < T > Observable < T > mergeArray ( ObservableSource < ? extends T > ... sources ) { 
return fromArray ( sources ) . flatMap ( ( Function ) Functions . identity ( ) , sources . length ) ; 
public static < T > Observable < T > mergeDelayError ( ObservableSource < ? extends T > source1 , ObservableSource < ? extends T > source2 , ObservableSource < ? extends T > source3 ) { 
return fromArray ( source1 , source2 , source3 ) . flatMap ( ( Function ) Functions . identity ( ) , true , 3 ) ; 
public static < T > Observable < T > never ( ) { 
return RxJavaPlugins . onAssembly ( ( Observable < T > ) ObservableNever . INSTANCE ) ; 
public static Observable < Integer > range ( final int start , final int count ) { 
if ( count == 0 ) { 
if ( count == 1 ) { 
return just ( start ) ; 
if ( ( long ) start + ( count - 1 ) > Integer . MAX_VALUE ) { 
return RxJavaPlugins . onAssembly ( new ObservableRange ( start , count ) ) ; 
public static Observable < Long > rangeLong ( long start , long count ) { 
return RxJavaPlugins . onAssembly ( new ObservableRangeLong ( start , count ) ) ; 
public static < T > Single < Boolean > sequenceEqual ( ObservableSource < ? extends T > source1 , ObservableSource < ? extends T > source2 , 
BiPredicate < ? super T , ? super T > isEqual ) { 
return sequenceEqual ( source1 , source2 , isEqual , bufferSize ( ) ) ; 
BiPredicate < ? super T , ? super T > isEqual , int bufferSize ) { 
ObjectHelper . verifyPositive ( bufferSize , "bufferSize" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableSequenceEqualSingle < T > ( source1 , source2 , isEqual , bufferSize ) ) ; 
int bufferSize ) { 
return sequenceEqual ( source1 , source2 , ObjectHelper . equalsPredicate ( ) , bufferSize ) ; 
public static < T > Observable < T > switchOnNext ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMap ( sources , Functions . identity ( ) , bufferSize , false ) ) ; 
public static < T > Observable < T > switchOnNextDelayError ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMap ( sources , Functions . identity ( ) , prefetch , true ) ) ; 
public static < T > Observable < T > unsafeCreate ( ObservableSource < T > onSubscribe ) { 
if ( onSubscribe instanceof Observable ) { 
return RxJavaPlugins . onAssembly ( new ObservableFromUnsafeSource < T > ( onSubscribe ) ) ; 
public static < T , D > Observable < T > using ( Callable < ? extends D > resourceSupplier , Function < ? super D , ? extends ObservableSource < ? extends T > > sourceSupplier , Consumer < ? super D > disposer ) { 
return using ( resourceSupplier , sourceSupplier , disposer , true ) ; 
public static < T , D > Observable < T > using ( Callable < ? extends D > resourceSupplier , Function < ? super D , ? extends ObservableSource < ? extends T > > sourceSupplier , Consumer < ? super D > disposer , boolean eager ) { 
return RxJavaPlugins . onAssembly ( new ObservableUsing < T , D > ( resourceSupplier , sourceSupplier , disposer , eager ) ) ; 
public static < T > Observable < T > wrap ( ObservableSource < T > source ) { 
if ( source instanceof Observable ) { 
return RxJavaPlugins . onAssembly ( ( Observable < T > ) source ) ; 
return RxJavaPlugins . onAssembly ( new ObservableFromUnsafeSource < T > ( source ) ) ; 
public static < T , R > Observable < R > zip ( Iterable < ? extends ObservableSource < ? extends T > > sources , Function < ? super Object [ ] , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new ObservableZip < T , R > ( null , sources , zipper , bufferSize ( ) , false ) ) ; 
public static < T , R > Observable < R > zip ( ObservableSource < ? extends ObservableSource < ? extends T > > sources , final Function < ? super Object [ ] , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new ObservableToList ( sources , 16 ) 
. flatMap ( ObservableInternalHelper . zipIterable ( zipper ) ) ) ; 
public static < T , R > Observable < R > zipArray ( Function < ? super Object [ ] , ? extends R > zipper , 
boolean delayError , int bufferSize , ObservableSource < ? extends T > ... sources ) { 
return RxJavaPlugins . onAssembly ( new ObservableZip < T , R > ( sources , null , zipper , bufferSize , delayError ) ) ; 
public final Single < Boolean > all ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableAllSingle < T > ( this , predicate ) ) ; 
public final Observable < T > ambWith ( ObservableSource < ? extends T > other ) { 
return ambArray ( this , other ) ; 
public final Single < Boolean > any ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableAnySingle < T > ( this , predicate ) ) ; 
public final T blockingFirst ( ) { 
BlockingFirstObserver < T > observer = new BlockingFirstObserver < T > ( ) ; 
subscribe ( observer ) ; 
T v = observer . blockingGet ( ) ; 
if ( v != null ) { 
return v ; 
throw new NoSuchElementException ( ) ; 
} @ SchedulerSupport ( SchedulerSupport . NONE ) 
public final void blockingForEach ( Consumer < ? super T > onNext ) { 
Iterator < T > it = blockingIterable ( ) . iterator ( ) ; 
while ( it . hasNext ( ) ) { 
try { 
onNext . accept ( it . next ( ) ) ; 
} catch ( Throwable e ) { 
Exceptions . throwIfFatal ( e ) ; 
( ( Disposable ) it ) . dispose ( ) ; 
throw ExceptionHelper . wrapOrThrow ( e ) ; 
public final Iterable < T > blockingIterable ( int bufferSize ) { 
return new BlockingObservableIterable < T > ( this , bufferSize ) ; 
public final T blockingLast ( ) { 
BlockingLastObserver < T > observer = new BlockingLastObserver < T > ( ) ; 
public final Iterable < T > blockingMostRecent ( T initialValue ) { 
return new BlockingObservableMostRecent < T > ( this , initialValue ) ; 
public final T blockingSingle ( ) { 
T v = singleElement ( ) . blockingGet ( ) ; 
if ( v == null ) { 
public final T blockingSingle ( T defaultItem ) { 
return single ( defaultItem ) . blockingGet ( ) ; 
public final Future < T > toFuture ( ) { 
return subscribeWith ( new FutureObserver < T > ( ) ) ; 
public final void blockingSubscribe ( Consumer < ? super T > onNext ) { 
ObservableBlockingSubscribe . subscribe ( this , onNext , Functions . ON_ERROR_MISSING , Functions . EMPTY_ACTION ) ; 
public final void blockingSubscribe ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError ) { 
ObservableBlockingSubscribe . subscribe ( this , onNext , onError , Functions . EMPTY_ACTION ) ; 
public final void blockingSubscribe ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError , Action onComplete ) { 
ObservableBlockingSubscribe . subscribe ( this , onNext , onError , onComplete ) ; 
public final void blockingSubscribe ( Observer < ? super T > observer ) { 
ObservableBlockingSubscribe . subscribe ( this , observer ) ; 
public final Observable < List < T > > buffer ( int count ) { 
return buffer ( count , count ) ; 
public final Observable < List < T > > buffer ( int count , int skip ) { 
return buffer ( count , skip , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final < U extends Collection < ? super T > > Observable < U > buffer ( int count , int skip , Callable < U > bufferSupplier ) { 
ObjectHelper . verifyPositive ( count , "count" ) ; 
ObjectHelper . verifyPositive ( skip , "skip" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableBuffer < T , U > ( this , count , skip , bufferSupplier ) ) ; 
public final < U extends Collection < ? super T > > Observable < U > buffer ( int count , Callable < U > bufferSupplier ) { 
return buffer ( count , count , bufferSupplier ) ; 
public final Observable < List < T > > buffer ( long timespan , long timeskip , TimeUnit unit ) { 
return buffer ( timespan , timeskip , unit , Schedulers . computation ( ) , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final < U extends Collection < ? super T > > Observable < U > buffer ( long timespan , long timeskip , TimeUnit unit , Scheduler scheduler , Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableBufferTimed < T , U > ( this , timespan , timeskip , unit , scheduler , bufferSupplier , Integer . MAX_VALUE , false ) ) ; 
public final Observable < List < T > > buffer ( long timespan , TimeUnit unit , int count ) { 
return buffer ( timespan , unit , Schedulers . computation ( ) , count ) ; 
public final Observable < List < T > > buffer ( long timespan , TimeUnit unit , Scheduler scheduler , int count ) { 
return buffer ( timespan , unit , scheduler , count , ArrayListSupplier . < T > asCallable ( ) , false ) ; 
public final < U extends Collection < ? super T > > Observable < U > buffer ( 
long timespan , TimeUnit unit , 
Scheduler scheduler , int count , 
Callable < U > bufferSupplier , 
boolean restartTimerOnMaxSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableBufferTimed < T , U > ( this , timespan , timespan , unit , scheduler , bufferSupplier , count , restartTimerOnMaxSize ) ) ; 
public final < TOpening , TClosing > Observable < List < T > > buffer ( 
ObservableSource < ? extends TOpening > openingIndicator , 
Function < ? super TOpening , ? extends ObservableSource < ? extends TClosing > > closingIndicator ) { 
return buffer ( openingIndicator , closingIndicator , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final < TOpening , TClosing , U extends Collection < ? super T > > Observable < U > buffer ( 
Function < ? super TOpening , ? extends ObservableSource < ? extends TClosing > > closingIndicator , 
Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableBufferBoundary < T , U , TOpening , TClosing > ( this , openingIndicator , closingIndicator , bufferSupplier ) ) ; 
public final < B > Observable < List < T > > buffer ( ObservableSource < B > boundary ) { 
return buffer ( boundary , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final < B > Observable < List < T > > buffer ( ObservableSource < B > boundary , final int initialCapacity ) { 
ObjectHelper . verifyPositive ( initialCapacity , "initialCapacity" ) ; 
return buffer ( boundary , Functions . < T > createArrayList ( initialCapacity ) ) ; 
public final < B , U extends Collection < ? super T > > Observable < U > buffer ( ObservableSource < B > boundary , Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableBufferExactBoundary < T , U , B > ( this , boundary , bufferSupplier ) ) ; 
public final < B > Observable < List < T > > buffer ( Callable < ? extends ObservableSource < B > > boundarySupplier ) { 
return buffer ( boundarySupplier , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final Observable < T > cacheWithInitialCapacity ( int initialCapacity ) { 
return RxJavaPlugins . onAssembly ( new ObservableCache < T > ( this , initialCapacity ) ) ; 
public final < U > Single < U > collect ( Callable < ? extends U > initialValueSupplier , BiConsumer < ? super U , ? super T > collector ) { 
return RxJavaPlugins . onAssembly ( new ObservableCollectSingle < T , U > ( this , initialValueSupplier , collector ) ) ; 
public final < U > Single < U > collectInto ( final U initialValue , BiConsumer < ? super U , ? super T > collector ) { 
return collect ( Functions . justCallable ( initialValue ) , collector ) ; 
public final < R > Observable < R > compose ( ObservableTransformer < ? super T , ? extends R > composer ) { 
public final < R > Observable < R > concatMap ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
return concatMap ( mapper , 2 ) ; 
public final < R > Observable < R > concatMap ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , int prefetch ) { 
if ( this instanceof ScalarCallable ) { 
T v = ( ( ScalarCallable < T > ) this ) . call ( ) ; 
return ObservableScalarXMap . scalarXMap ( v , mapper ) ; 
return RxJavaPlugins . onAssembly ( new ObservableConcatMap < T , R > ( this , mapper , prefetch , ErrorMode . IMMEDIATE ) ) ; 
public final < R > Observable < R > concatMapDelayError ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
return concatMapDelayError ( mapper , bufferSize ( ) , true ) ; 
public final < R > Observable < R > concatMapEager ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
return concatMapEager ( mapper , Integer . MAX_VALUE , bufferSize ( ) ) ; 
public final < R > Observable < R > concatMapEager ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , 
int maxConcurrency , int prefetch ) { 
ObjectHelper . verifyPositive ( maxConcurrency , "maxConcurrency" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapEager < T , R > ( this , mapper , ErrorMode . IMMEDIATE , maxConcurrency , prefetch ) ) ; 
public final < R > Observable < R > concatMapEagerDelayError ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , 
int maxConcurrency , int prefetch , boolean tillTheEnd ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapEager < T , R > ( this , mapper , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY , maxConcurrency , prefetch ) ) ; 
public final Completable concatMapCompletable ( Function < ? super T , ? extends CompletableSource > mapper ) { 
return concatMapCompletable ( mapper , 2 ) ; 
public final Completable concatMapCompletable ( Function < ? super T , ? extends CompletableSource > mapper , int capacityHint ) { 
ObjectHelper . verifyPositive ( capacityHint , "capacityHint" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapCompletable < T > ( this , mapper , ErrorMode . IMMEDIATE , capacityHint ) ) ; 
public final Completable concatMapCompletableDelayError ( Function < ? super T , ? extends CompletableSource > mapper ) { 
return concatMapCompletableDelayError ( mapper , true , 2 ) ; 
public final Completable concatMapCompletableDelayError ( Function < ? super T , ? extends CompletableSource > mapper , boolean tillTheEnd , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapCompletable < T > ( this , mapper , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY , prefetch ) ) ; 
public final < U > Observable < U > concatMapIterable ( final Function < ? super T , ? extends Iterable < ? extends U > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableFlattenIterable < T , U > ( this , mapper ) ) ; 
public final < U > Observable < U > concatMapIterable ( final Function < ? super T , ? extends Iterable < ? extends U > > mapper , int prefetch ) { 
return concatMap ( ObservableInternalHelper . flatMapIntoIterable ( mapper ) , prefetch ) ; 
public final < R > Observable < R > concatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return concatMapMaybe ( mapper , 2 ) ; 
public final < R > Observable < R > concatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapMaybe < T , R > ( this , mapper , ErrorMode . IMMEDIATE , prefetch ) ) ; 
public final < R > Observable < R > concatMapMaybeDelayError ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return concatMapMaybeDelayError ( mapper , true , 2 ) ; 
public final < R > Observable < R > concatMapMaybeDelayError ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper , boolean tillTheEnd , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapMaybe < T , R > ( this , mapper , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY , prefetch ) ) ; 
public final < R > Observable < R > concatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return concatMapSingle ( mapper , 2 ) ; 
public final < R > Observable < R > concatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapSingle < T , R > ( this , mapper , ErrorMode . IMMEDIATE , prefetch ) ) ; 
public final < R > Observable < R > concatMapSingleDelayError ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , boolean tillTheEnd ) { 
return concatMapSingleDelayError ( mapper , tillTheEnd , 2 ) ; 
public final < R > Observable < R > concatMapSingleDelayError ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , boolean tillTheEnd , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatMapSingle < T , R > ( this , mapper , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY , prefetch ) ) ; 
public final Observable < T > concatWith ( ObservableSource < ? extends T > other ) { 
return concat ( this , other ) ; 
public final Observable < T > concatWith ( @ NonNull SingleSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatWithSingle < T > ( this , other ) ) ; 
public final Observable < T > concatWith ( @ NonNull MaybeSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatWithMaybe < T > ( this , other ) ) ; 
public final Observable < T > concatWith ( @ NonNull CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new ObservableConcatWithCompletable < T > ( this , other ) ) ; 
public final Single < Boolean > contains ( final Object element ) { 
return any ( Functions . equalsWith ( element ) ) ; 
public final < U > Observable < T > debounce ( Function < ? super T , ? extends ObservableSource < U > > debounceSelector ) { 
return RxJavaPlugins . onAssembly ( new ObservableDebounce < T , U > ( this , debounceSelector ) ) ; 
public final Observable < T > debounce ( long timeout , TimeUnit unit ) { 
return debounce ( timeout , unit , Schedulers . computation ( ) ) ; 
public final Observable < T > debounce ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableDebounceTimed < T > ( this , timeout , unit , scheduler ) ) ; 
public final Observable < T > defaultIfEmpty ( T defaultItem ) { 
return switchIfEmpty ( just ( defaultItem ) ) ; 
public final < U > Observable < T > delay ( final Function < ? super T , ? extends ObservableSource < U > > itemDelay ) { 
return flatMap ( ObservableInternalHelper . itemDelay ( itemDelay ) ) ; 
public final Observable < T > delay ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return delay ( delay , unit , scheduler , false ) ; 
public final Observable < T > delay ( long delay , TimeUnit unit , Scheduler scheduler , boolean delayError ) { 
return RxJavaPlugins . onAssembly ( new ObservableDelay < T > ( this , delay , unit , scheduler , delayError ) ) ; 
public final < U , V > Observable < T > delay ( ObservableSource < U > subscriptionDelay , 
Function < ? super T , ? extends ObservableSource < V > > itemDelay ) { 
return delaySubscription ( subscriptionDelay ) . delay ( itemDelay ) ; 
public final < U > Observable < T > delaySubscription ( ObservableSource < U > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableDelaySubscriptionOther < T , U > ( this , other ) ) ; 
public final Observable < T > delaySubscription ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return delaySubscription ( timer ( delay , unit , scheduler ) ) ; 
@ Deprecated 
public final < T2 > Observable < T2 > dematerialize ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableDematerialize ( this , Functions . identity ( ) ) ) ; 
} @ Experimental 
public final < R > Observable < R > dematerialize ( Function < ? super T , Notification < R > > selector ) { 
return RxJavaPlugins . onAssembly ( new ObservableDematerialize < T , R > ( this , selector ) ) ; 
public final Observable < T > distinct ( ) { 
return distinct ( Functions . identity ( ) , Functions . createHashSet ( ) ) ; 
public final < K > Observable < T > distinct ( Function < ? super T , K > keySelector ) { 
return distinct ( keySelector , Functions . createHashSet ( ) ) ; 
public final < K > Observable < T > distinct ( Function < ? super T , K > keySelector , Callable < ? extends Collection < ? super K > > collectionSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableDistinct < T , K > ( this , keySelector , collectionSupplier ) ) ; 
public final Observable < T > distinctUntilChanged ( ) { 
return distinctUntilChanged ( Functions . identity ( ) ) ; 
public final < K > Observable < T > distinctUntilChanged ( Function < ? super T , K > keySelector ) { 
return RxJavaPlugins . onAssembly ( new ObservableDistinctUntilChanged < T , K > ( this , keySelector , ObjectHelper . equalsPredicate ( ) ) ) ; 
public final Observable < T > distinctUntilChanged ( BiPredicate < ? super T , ? super T > comparer ) { 
return RxJavaPlugins . onAssembly ( new ObservableDistinctUntilChanged < T , T > ( this , Functions . < T > identity ( ) , comparer ) ) ; 
public final Observable < T > doAfterNext ( Consumer < ? super T > onAfterNext ) { 
return RxJavaPlugins . onAssembly ( new ObservableDoAfterNext < T > ( this , onAfterNext ) ) ; 
public final Observable < T > doAfterTerminate ( Action onFinally ) { 
return doOnEach ( Functions . emptyConsumer ( ) , Functions . emptyConsumer ( ) , Functions . EMPTY_ACTION , onFinally ) ; 
public final Observable < T > doFinally ( Action onFinally ) { 
return RxJavaPlugins . onAssembly ( new ObservableDoFinally < T > ( this , onFinally ) ) ; 
public final Observable < T > doOnDispose ( Action onDispose ) { 
return doOnLifecycle ( Functions . emptyConsumer ( ) , onDispose ) ; 
public final Observable < T > doOnComplete ( Action onComplete ) { 
return doOnEach ( Functions . emptyConsumer ( ) , Functions . emptyConsumer ( ) , onComplete , Functions . EMPTY_ACTION ) ; 
private Observable < T > doOnEach ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError , Action onComplete , Action onAfterTerminate ) { 
return RxJavaPlugins . onAssembly ( new ObservableDoOnEach < T > ( this , onNext , onError , onComplete , onAfterTerminate ) ) ; 
public final Observable < T > doOnEach ( final Consumer < ? super Notification < T > > onNotification ) { 
return doOnEach ( 
Functions . notificationOnNext ( onNotification ) , 
Functions . notificationOnError ( onNotification ) , 
Functions . notificationOnComplete ( onNotification ) , 
Functions . EMPTY_ACTION 
) ; 
public final Observable < T > doOnEach ( final Observer < ? super T > observer ) { 
ObservableInternalHelper . observerOnNext ( observer ) , 
ObservableInternalHelper . observerOnError ( observer ) , 
ObservableInternalHelper . observerOnComplete ( observer ) , 
Functions . EMPTY_ACTION ) ; 
public final Observable < T > doOnError ( Consumer < ? super Throwable > onError ) { 
return doOnEach ( Functions . emptyConsumer ( ) , onError , Functions . EMPTY_ACTION , Functions . EMPTY_ACTION ) ; 
public final Observable < T > doOnLifecycle ( final Consumer < ? super Disposable > onSubscribe , final Action onDispose ) { 
return RxJavaPlugins . onAssembly ( new ObservableDoOnLifecycle < T > ( this , onSubscribe , onDispose ) ) ; 
public final Observable < T > doOnNext ( Consumer < ? super T > onNext ) { 
return doOnEach ( onNext , Functions . emptyConsumer ( ) , Functions . EMPTY_ACTION , Functions . EMPTY_ACTION ) ; 
public final Observable < T > doOnSubscribe ( Consumer < ? super Disposable > onSubscribe ) { 
return doOnLifecycle ( onSubscribe , Functions . EMPTY_ACTION ) ; 
public final Observable < T > doOnTerminate ( final Action onTerminate ) { 
return doOnEach ( Functions . emptyConsumer ( ) , 
Functions . actionConsumer ( onTerminate ) , onTerminate , 
public final Maybe < T > elementAt ( long index ) { 
if ( index < 0 ) { 
return RxJavaPlugins . onAssembly ( new ObservableElementAtMaybe < T > ( this , index ) ) ; 
public final Single < T > elementAt ( long index , T defaultItem ) { 
return RxJavaPlugins . onAssembly ( new ObservableElementAtSingle < T > ( this , index , defaultItem ) ) ; 
public final Single < T > elementAtOrError ( long index ) { 
return RxJavaPlugins . onAssembly ( new ObservableElementAtSingle < T > ( this , index , null ) ) ; 
public final Observable < T > filter ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableFilter < T > ( this , predicate ) ) ; 
public final Single < T > first ( T defaultItem ) { 
return elementAt ( 0L , defaultItem ) ; 
public final < R > Observable < R > flatMap ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , boolean delayErrors ) { 
return flatMap ( mapper , delayErrors , Integer . MAX_VALUE ) ; 
public final < R > Observable < R > flatMap ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , 
boolean delayErrors , int maxConcurrency , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableFlatMap < T , R > ( this , mapper , delayErrors , maxConcurrency , bufferSize ) ) ; 
public final < R > Observable < R > flatMap ( 
Function < ? super T , ? extends ObservableSource < ? extends R > > onNextMapper , 
Function < ? super Throwable , ? extends ObservableSource < ? extends R > > onErrorMapper , 
Callable < ? extends ObservableSource < ? extends R > > onCompleteSupplier ) { 
return merge ( new ObservableMapNotification < T , R > ( this , onNextMapper , onErrorMapper , onCompleteSupplier ) ) ; 
public final < U , R > Observable < R > flatMap ( Function < ? super T , ? extends ObservableSource < ? extends U > > mapper , 
BiFunction < ? super T , ? super U , ? extends R > resultSelector ) { 
return flatMap ( mapper , resultSelector , false , bufferSize ( ) , bufferSize ( ) ) ; 
public final Completable flatMapCompletable ( Function < ? super T , ? extends CompletableSource > mapper ) { 
return flatMapCompletable ( mapper , false ) ; 
public final < U , V > Observable < V > flatMapIterable ( final Function < ? super T , ? extends Iterable < ? extends U > > mapper , 
BiFunction < ? super T , ? super U , ? extends V > resultSelector ) { 
return flatMap ( ObservableInternalHelper . flatMapIntoIterable ( mapper ) , resultSelector , false , bufferSize ( ) , bufferSize ( ) ) ; 
public final < R > Observable < R > flatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return flatMapMaybe ( mapper , false ) ; 
public final < R > Observable < R > flatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper , boolean delayErrors ) { 
return RxJavaPlugins . onAssembly ( new ObservableFlatMapMaybe < T , R > ( this , mapper , delayErrors ) ) ; 
public final < R > Observable < R > flatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return flatMapSingle ( mapper , false ) ; 
public final < R > Observable < R > flatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , boolean delayErrors ) { 
return RxJavaPlugins . onAssembly ( new ObservableFlatMapSingle < T , R > ( this , mapper , delayErrors ) ) ; 
public final Disposable forEachWhile ( final Predicate < ? super T > onNext , Consumer < ? super Throwable > onError , 
final Action onComplete ) { 
ForEachWhileObserver < T > o = new ForEachWhileObserver < T > ( onNext , onError , onComplete ) ; 
subscribe ( o ) ; 
return o ; 
public final < K > Observable < GroupedObservable < K , T > > groupBy ( Function < ? super T , ? extends K > keySelector ) { 
return groupBy ( keySelector , ( Function ) Functions . identity ( ) , false , bufferSize ( ) ) ; 
public final < K , V > Observable < GroupedObservable < K , V > > groupBy ( Function < ? super T , ? extends K > keySelector , 
Function < ? super T , ? extends V > valueSelector ) { 
return groupBy ( keySelector , valueSelector , false , bufferSize ( ) ) ; 
Function < ? super T , ? extends V > valueSelector , 
boolean delayError , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableGroupBy < T , K , V > ( this , keySelector , valueSelector , bufferSize , delayError ) ) ; 
public final Observable < T > hide ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableHide < T > ( this ) ) ; 
public final Completable ignoreElements ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableIgnoreElementsCompletable < T > ( this ) ) ; 
public final Single < Boolean > isEmpty ( ) { 
return all ( Functions . alwaysFalse ( ) ) ; 
public final < TRight , TLeftEnd , TRightEnd , R > Observable < R > join ( 
ObservableSource < ? extends TRight > other , 
Function < ? super T , ? extends ObservableSource < TLeftEnd > > leftEnd , 
Function < ? super TRight , ? extends ObservableSource < TRightEnd > > rightEnd , 
BiFunction < ? super T , ? super TRight , ? extends R > resultSelector 
) { 
return RxJavaPlugins . onAssembly ( new ObservableJoin < T , TRight , TLeftEnd , TRightEnd , R > ( 
this , other , leftEnd , rightEnd , resultSelector ) ) ; 
public final Maybe < T > lastElement ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableLastMaybe < T > ( this ) ) ; 
public final Single < T > last ( T defaultItem ) { 
return RxJavaPlugins . onAssembly ( new ObservableLastSingle < T > ( this , defaultItem ) ) ; 
public final Single < T > lastOrError ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableLastSingle < T > ( this , null ) ) ; 
public final < R > Observable < R > map ( Function < ? super T , ? extends R > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableMap < T , R > ( this , mapper ) ) ; 
public final Observable < Notification < T > > materialize ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableMaterialize < T > ( this ) ) ; 
public final Observable < T > mergeWith ( ObservableSource < ? extends T > other ) { 
return merge ( this , other ) ; 
public final Observable < T > mergeWith ( @ NonNull SingleSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableMergeWithSingle < T > ( this , other ) ) ; 
public final Observable < T > mergeWith ( @ NonNull MaybeSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableMergeWithMaybe < T > ( this , other ) ) ; 
public final Observable < T > mergeWith ( @ NonNull CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new ObservableMergeWithCompletable < T > ( this , other ) ) ; 
public final Observable < T > observeOn ( Scheduler scheduler ) { 
return observeOn ( scheduler , false , bufferSize ( ) ) ; 
public final Observable < T > observeOn ( Scheduler scheduler , boolean delayError , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableObserveOn < T > ( this , scheduler , delayError , bufferSize ) ) ; 
public final Observable < T > onErrorResumeNext ( Function < ? super Throwable , ? extends ObservableSource < ? extends T > > resumeFunction ) { 
return RxJavaPlugins . onAssembly ( new ObservableOnErrorNext < T > ( this , resumeFunction , false ) ) ; 
public final Observable < T > onErrorResumeNext ( final ObservableSource < ? extends T > next ) { 
return onErrorResumeNext ( Functions . justFunction ( next ) ) ; 
public final Observable < T > onErrorReturn ( Function < ? super Throwable , ? extends T > valueSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableOnErrorReturn < T > ( this , valueSupplier ) ) ; 
public final Observable < T > onExceptionResumeNext ( final ObservableSource < ? extends T > next ) { 
return RxJavaPlugins . onAssembly ( new ObservableOnErrorNext < T > ( this , Functions . justFunction ( next ) , true ) ) ; 
public final Observable < T > onTerminateDetach ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableDetach < T > ( this ) ) ; 
public final < R > Observable < R > publish ( Function < ? super Observable < T > , ? extends ObservableSource < R > > selector ) { 
return RxJavaPlugins . onAssembly ( new ObservablePublishSelector < T , R > ( this , selector ) ) ; 
public final Maybe < T > reduce ( BiFunction < T , T , T > reducer ) { 
return RxJavaPlugins . onAssembly ( new ObservableReduceMaybe < T > ( this , reducer ) ) ; 
public final < R > Single < R > reduce ( R seed , BiFunction < R , ? super T , R > reducer ) { 
return RxJavaPlugins . onAssembly ( new ObservableReduceSeedSingle < T , R > ( this , seed , reducer ) ) ; 
public final < R > Single < R > reduceWith ( Callable < R > seedSupplier , BiFunction < R , ? super T , R > reducer ) { 
return RxJavaPlugins . onAssembly ( new ObservableReduceWithSingle < T , R > ( this , seedSupplier , reducer ) ) ; 
public final Observable < T > repeat ( ) { 
return repeat ( Long . MAX_VALUE ) ; 
public final Observable < T > repeat ( long times ) { 
if ( times < 0 ) { 
if ( times == 0 ) { 
return RxJavaPlugins . onAssembly ( new ObservableRepeat < T > ( this , times ) ) ; 
public final Observable < T > repeatUntil ( BooleanSupplier stop ) { 
return RxJavaPlugins . onAssembly ( new ObservableRepeatUntil < T > ( this , stop ) ) ; 
public final Observable < T > repeatWhen ( final Function < ? super Observable < Object > , ? extends ObservableSource < ? > > handler ) { 
return RxJavaPlugins . onAssembly ( new ObservableRepeatWhen < T > ( this , handler ) ) ; 
public final < R > Observable < R > replay ( Function < ? super Observable < T > , ? extends ObservableSource < R > > selector ) { 
return ObservableReplay . multicastSelector ( ObservableInternalHelper . replayCallable ( this ) , selector ) ; 
public final < R > Observable < R > replay ( Function < ? super Observable < T > , ? extends ObservableSource < R > > selector , int bufferSize , long time , TimeUnit unit ) { 
return replay ( selector , bufferSize , time , unit , Schedulers . computation ( ) ) ; 
public final < R > Observable < R > replay ( final Function < ? super Observable < T > , ? extends ObservableSource < R > > selector , final Scheduler scheduler ) { 
return ObservableReplay . multicastSelector ( ObservableInternalHelper . replayCallable ( this ) , 
ObservableInternalHelper . replayFunction ( selector , scheduler ) ) ; 
public final ConnectableObservable < T > replay ( final int bufferSize ) { 
return ObservableReplay . create ( this , bufferSize ) ; 
public final ConnectableObservable < T > replay ( int bufferSize , long time , TimeUnit unit ) { 
return replay ( bufferSize , time , unit , Schedulers . computation ( ) ) ; 
public final ConnectableObservable < T > replay ( final int bufferSize , final long time , final TimeUnit unit , final Scheduler scheduler ) { 
return ObservableReplay . create ( this , time , unit , scheduler , bufferSize ) ; 
public final ConnectableObservable < T > replay ( final int bufferSize , final Scheduler scheduler ) { 
return ObservableReplay . observeOn ( replay ( bufferSize ) , scheduler ) ; 
public final ConnectableObservable < T > replay ( final Scheduler scheduler ) { 
return ObservableReplay . observeOn ( replay ( ) , scheduler ) ; 
public final Observable < T > retry ( ) { 
return retry ( Long . MAX_VALUE , Functions . alwaysTrue ( ) ) ; 
public final Observable < T > retry ( BiPredicate < ? super Integer , ? super Throwable > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableRetryBiPredicate < T > ( this , predicate ) ) ; 
public final Observable < T > retry ( long times ) { 
return retry ( times , Functions . alwaysTrue ( ) ) ; 
public final Observable < T > retry ( long times , Predicate < ? super Throwable > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableRetryPredicate < T > ( this , times , predicate ) ) ; 
public final Observable < T > retry ( Predicate < ? super Throwable > predicate ) { 
return retry ( Long . MAX_VALUE , predicate ) ; 
public final Observable < T > retryWhen ( 
final Function < ? super Observable < Throwable > , ? extends ObservableSource < ? > > handler ) { 
return RxJavaPlugins . onAssembly ( new ObservableRetryWhen < T > ( this , handler ) ) ; 
public final Observable < T > sample ( long period , TimeUnit unit ) { 
return sample ( period , unit , Schedulers . computation ( ) ) ; 
public final Observable < T > sample ( long period , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableSampleTimed < T > ( this , period , unit , scheduler , false ) ) ; 
public final < U > Observable < T > sample ( ObservableSource < U > sampler ) { 
return RxJavaPlugins . onAssembly ( new ObservableSampleWithObservable < T > ( this , sampler , false ) ) ; 
public final Observable < T > scan ( BiFunction < T , T , T > accumulator ) { 
return RxJavaPlugins . onAssembly ( new ObservableScan < T > ( this , accumulator ) ) ; 
public final < R > Observable < R > scan ( final R initialValue , BiFunction < R , ? super T , R > accumulator ) { 
return scanWith ( Functions . justCallable ( initialValue ) , accumulator ) ; 
public final < R > Observable < R > scanWith ( Callable < R > seedSupplier , BiFunction < R , ? super T , R > accumulator ) { 
return RxJavaPlugins . onAssembly ( new ObservableScanSeed < T , R > ( this , seedSupplier , accumulator ) ) ; 
public final Observable < T > serialize ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableSerialized < T > ( this ) ) ; 
public final Maybe < T > singleElement ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableSingleMaybe < T > ( this ) ) ; 
public final Single < T > single ( T defaultItem ) { 
return RxJavaPlugins . onAssembly ( new ObservableSingleSingle < T > ( this , defaultItem ) ) ; 
public final Single < T > singleOrError ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableSingleSingle < T > ( this , null ) ) ; 
public final Observable < T > skip ( long count ) { 
if ( count <= 0 ) { 
return RxJavaPlugins . onAssembly ( this ) ; 
return RxJavaPlugins . onAssembly ( new ObservableSkip < T > ( this , count ) ) ; 
public final Observable < T > skip ( long time , TimeUnit unit ) { 
return skipUntil ( timer ( time , unit ) ) ; 
public final Observable < T > skip ( long time , TimeUnit unit , Scheduler scheduler ) { 
return skipUntil ( timer ( time , unit , scheduler ) ) ; 
public final Observable < T > skipLast ( int count ) { 
return RxJavaPlugins . onAssembly ( new ObservableSkipLast < T > ( this , count ) ) ; 
@ SchedulerSupport ( SchedulerSupport . TRAMPOLINE ) 
public final Observable < T > skipLast ( long time , TimeUnit unit ) { 
return skipLast ( time , unit , Schedulers . trampoline ( ) , false , bufferSize ( ) ) ; 
public final Observable < T > skipLast ( long time , TimeUnit unit , Scheduler scheduler ) { 
return skipLast ( time , unit , scheduler , false , bufferSize ( ) ) ; 
public final Observable < T > skipLast ( long time , TimeUnit unit , Scheduler scheduler , boolean delayError , int bufferSize ) { 
int s = bufferSize << 1 ; 
return RxJavaPlugins . onAssembly ( new ObservableSkipLastTimed < T > ( this , time , unit , scheduler , s , delayError ) ) ; 
public final < U > Observable < T > skipUntil ( ObservableSource < U > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableSkipUntil < T , U > ( this , other ) ) ; 
public final Observable < T > skipWhile ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableSkipWhile < T > ( this , predicate ) ) ; 
public final Observable < T > sorted ( ) { 
return toList ( ) . toObservable ( ) . map ( Functions . listSorter ( Functions . < T > naturalComparator ( ) ) ) . flatMapIterable ( Functions . < List < T > > identity ( ) ) ; 
public final Observable < T > sorted ( Comparator < ? super T > sortFunction ) { 
return toList ( ) . toObservable ( ) . map ( Functions . listSorter ( sortFunction ) ) . flatMapIterable ( Functions . < List < T > > identity ( ) ) ; 
public final Observable < T > startWith ( Iterable < ? extends T > items ) { 
return concatArray ( fromIterable ( items ) , this ) ; 
public final Observable < T > startWith ( ObservableSource < ? extends T > other ) { 
return concatArray ( other , this ) ; 
public final Observable < T > startWith ( T item ) { 
return concatArray ( just ( item ) , this ) ; 
public final Observable < T > startWithArray ( T ... items ) { 
Observable < T > fromArray = fromArray ( items ) ; 
if ( fromArray == empty ( ) ) { 
return concatArray ( fromArray , this ) ; 
public final Disposable subscribe ( Consumer < ? super T > onNext ) { 
return subscribe ( onNext , Functions . ON_ERROR_MISSING , Functions . EMPTY_ACTION , Functions . emptyConsumer ( ) ) ; 
public final Disposable subscribe ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError ) { 
return subscribe ( onNext , onError , Functions . EMPTY_ACTION , Functions . emptyConsumer ( ) ) ; 
public final Disposable subscribe ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError , 
Action onComplete , Consumer < ? super Disposable > onSubscribe ) { 
LambdaObserver < T > ls = new LambdaObserver < T > ( onNext , onError , onComplete , onSubscribe ) ; 
subscribe ( ls ) ; 
return ls ; 
public final Observable < T > subscribeOn ( Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableSubscribeOn < T > ( this , scheduler ) ) ; 
public final Observable < T > switchIfEmpty ( ObservableSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchIfEmpty < T > ( this , other ) ) ; 
public final < R > Observable < R > switchMap ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMap < T , R > ( this , mapper , bufferSize , false ) ) ; 
public final Completable switchMapCompletable ( @ NonNull Function < ? super T , ? extends CompletableSource > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapCompletable < T > ( this , mapper , false ) ) ; 
public final Completable switchMapCompletableDelayError ( @ NonNull Function < ? super T , ? extends CompletableSource > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapCompletable < T > ( this , mapper , true ) ) ; 
public final < R > Observable < R > switchMapMaybe ( @ NonNull Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapMaybe < T , R > ( this , mapper , false ) ) ; 
public final < R > Observable < R > switchMapMaybeDelayError ( @ NonNull Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapMaybe < T , R > ( this , mapper , true ) ) ; 
public final < R > Observable < R > switchMapSingle ( @ NonNull Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapSingle < T , R > ( this , mapper , false ) ) ; 
public final < R > Observable < R > switchMapSingleDelayError ( @ NonNull Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ObservableSwitchMapSingle < T , R > ( this , mapper , true ) ) ; 
public final < R > Observable < R > switchMapDelayError ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
return switchMapDelayError ( mapper , bufferSize ( ) ) ; 
public final Observable < T > take ( long count ) { 
return RxJavaPlugins . onAssembly ( new ObservableTake < T > ( this , count ) ) ; 
public final Observable < T > take ( long time , TimeUnit unit ) { 
return takeUntil ( timer ( time , unit ) ) ; 
public final Observable < T > take ( long time , TimeUnit unit , Scheduler scheduler ) { 
return takeUntil ( timer ( time , unit , scheduler ) ) ; 
public final Observable < T > takeLast ( int count ) { 
return RxJavaPlugins . onAssembly ( new ObservableIgnoreElements < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new ObservableTakeLastOne < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new ObservableTakeLast < T > ( this , count ) ) ; 
public final Observable < T > takeLast ( long count , long time , TimeUnit unit , Scheduler scheduler , boolean delayError , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableTakeLastTimed < T > ( this , count , time , unit , scheduler , bufferSize , delayError ) ) ; 
public final < U > Observable < T > takeUntil ( ObservableSource < U > other ) { 
return RxJavaPlugins . onAssembly ( new ObservableTakeUntil < T , U > ( this , other ) ) ; 
public final Observable < T > takeWhile ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new ObservableTakeWhile < T > ( this , predicate ) ) ; 
public final Observable < T > throttleFirst ( long windowDuration , TimeUnit unit ) { 
return throttleFirst ( windowDuration , unit , Schedulers . computation ( ) ) ; 
public final Observable < T > throttleFirst ( long skipDuration , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableThrottleFirstTimed < T > ( this , skipDuration , unit , scheduler ) ) ; 
public final Observable < T > throttleLast ( long intervalDuration , TimeUnit unit ) { 
return sample ( intervalDuration , unit ) ; 
public final Observable < T > throttleLast ( long intervalDuration , TimeUnit unit , Scheduler scheduler ) { 
return sample ( intervalDuration , unit , scheduler ) ; 
public final Observable < T > throttleWithTimeout ( long timeout , TimeUnit unit ) { 
return debounce ( timeout , unit ) ; 
public final Observable < T > throttleWithTimeout ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
return debounce ( timeout , unit , scheduler ) ; 
public final Observable < Timed < T > > timeInterval ( ) { 
return timeInterval ( TimeUnit . MILLISECONDS , Schedulers . computation ( ) ) ; 
public final Observable < Timed < T > > timeInterval ( TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableTimeInterval < T > ( this , unit , scheduler ) ) ; 
public final < V > Observable < T > timeout ( Function < ? super T , ? extends ObservableSource < V > > itemTimeoutIndicator ) { 
return timeout0 ( null , itemTimeoutIndicator , null ) ; 
public final < V > Observable < T > timeout ( Function < ? super T , ? extends ObservableSource < V > > itemTimeoutIndicator , 
ObservableSource < ? extends T > other ) { 
return timeout0 ( null , itemTimeoutIndicator , other ) ; 
public final Observable < T > timeout ( long timeout , TimeUnit timeUnit ) { 
return timeout0 ( timeout , timeUnit , null , Schedulers . computation ( ) ) ; 
public final Observable < T > timeout ( long timeout , TimeUnit timeUnit , ObservableSource < ? extends T > other ) { 
return timeout0 ( timeout , timeUnit , other , Schedulers . computation ( ) ) ; 
public final Observable < T > timeout ( long timeout , TimeUnit timeUnit , Scheduler scheduler , ObservableSource < ? extends T > other ) { 
return timeout0 ( timeout , timeUnit , other , scheduler ) ; 
public final Observable < T > timeout ( long timeout , TimeUnit timeUnit , Scheduler scheduler ) { 
return timeout0 ( timeout , timeUnit , null , scheduler ) ; 
public final Observable < Timed < T > > timestamp ( Scheduler scheduler ) { 
return timestamp ( TimeUnit . MILLISECONDS , scheduler ) ; 
public final Observable < Timed < T > > timestamp ( final TimeUnit unit , final Scheduler scheduler ) { 
return map ( Functions . < T > timestampWith ( unit , scheduler ) ) ; 
public final Single < List < T > > toList ( final int capacityHint ) { 
return RxJavaPlugins . onAssembly ( new ObservableToListSingle < T , List < T > > ( this , capacityHint ) ) ; 
public final < U extends Collection < ? super T > > Single < U > toList ( Callable < U > collectionSupplier ) { 
return RxJavaPlugins . onAssembly ( new ObservableToListSingle < T , U > ( this , collectionSupplier ) ) ; 
public final < K > Single < Map < K , Collection < T > > > toMultimap ( Function < ? super T , ? extends K > keySelector ) { 
@ SuppressWarnings ( { "rawtypes" , "unchecked" } ) 
Function < ? super T , ? extends T > valueSelector = ( Function ) Functions . identity ( ) ; 
Callable < Map < K , Collection < T > > > mapSupplier = HashMapSupplier . asCallable ( ) ; 
Function < K , List < T > > collectionFactory = ArrayListSupplier . asFunction ( ) ; 
return toMultimap ( keySelector , valueSelector , mapSupplier , collectionFactory ) ; 
} @ BackpressureSupport ( BackpressureKind . SPECIAL ) 
public final Flowable < T > toFlowable ( BackpressureStrategy strategy ) { 
Flowable < T > f = new FlowableFromObservable < T > ( this ) ; 
switch ( strategy ) { 
case DROP : 
return f . onBackpressureDrop ( ) ; 
case LATEST : 
return f . onBackpressureLatest ( ) ; 
case MISSING : 
return f ; 
case ERROR : 
return RxJavaPlugins . onAssembly ( new FlowableOnBackpressureError < T > ( f ) ) ; 
default : 
return f . onBackpressureBuffer ( ) ; 
public final Single < List < T > > toSortedList ( ) { 
return toSortedList ( Functions . naturalOrder ( ) ) ; 
public final Observable < T > unsubscribeOn ( Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new ObservableUnsubscribeOn < T > ( this , scheduler ) ) ; 
public final Observable < Observable < T > > window ( long count ) { 
return window ( count , count , bufferSize ( ) ) ; 
public final Observable < Observable < T > > window ( long count , long skip , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableWindow < T > ( this , count , skip , bufferSize ) ) ; 
public final Observable < Observable < T > > window ( long timespan , long timeskip , TimeUnit unit ) { 
return window ( timespan , timeskip , unit , Schedulers . computation ( ) , bufferSize ( ) ) ; 
public final Observable < Observable < T > > window ( long timespan , long timeskip , TimeUnit unit , Scheduler scheduler , int bufferSize ) { 
ObjectHelper . verifyPositive ( timespan , "timespan" ) ; 
ObjectHelper . verifyPositive ( timeskip , "timeskip" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableWindowTimed < T > ( this , timespan , timeskip , unit , scheduler , Long . MAX_VALUE , bufferSize , false ) ) ; 
public final Observable < Observable < T > > window ( long timespan , TimeUnit unit ) { 
return window ( timespan , unit , Schedulers . computation ( ) , Long . MAX_VALUE , false ) ; 
public final Observable < Observable < T > > window ( long timespan , TimeUnit unit , 
Scheduler scheduler , long count ) { 
return window ( timespan , unit , scheduler , count , false ) ; 
public final Observable < Observable < T > > window ( 
long timespan , TimeUnit unit , Scheduler scheduler , 
long count , boolean restart , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableWindowTimed < T > ( this , timespan , timespan , unit , scheduler , count , bufferSize , restart ) ) ; 
public final < B > Observable < Observable < T > > window ( ObservableSource < B > boundary ) { 
return window ( boundary , bufferSize ( ) ) ; 
public final < U , V > Observable < Observable < T > > window ( 
ObservableSource < U > openingIndicator , 
Function < ? super U , ? extends ObservableSource < V > > closingIndicator ) { 
return window ( openingIndicator , closingIndicator , bufferSize ( ) ) ; 
Function < ? super U , ? extends ObservableSource < V > > closingIndicator , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableWindowBoundarySelector < T , U , V > ( this , openingIndicator , closingIndicator , bufferSize ) ) ; 
public final < B > Observable < Observable < T > > window ( Callable < ? extends ObservableSource < B > > boundary , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new ObservableWindowBoundarySupplier < T , B > ( this , boundary , bufferSize ) ) ; 
public final < U , R > Observable < R > zipWith ( Iterable < U > other , BiFunction < ? super T , ? super U , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new ObservableZipIterable < T , U , R > ( this , other , zipper ) ) ; 
public final < U , R > Observable < R > zipWith ( ObservableSource < ? extends U > other , 
BiFunction < ? super T , ? super U , ? extends R > zipper ) { 
return zip ( this , other , zipper ) ; 
} @ Override 
protected void subscribeActual ( MaybeObserver < ? super T > observer ) { 
source . subscribe ( new LastObserver < T > ( observer ) ) ; 
} @ NonNull 
public Observable < T > refCount ( ) { 
return RxJavaPlugins . onAssembly ( new ObservableRefCount < T > ( this ) ) ; 
public final Observable < T > refCount ( int subscriberCount ) { 
return refCount ( subscriberCount , 0 , TimeUnit . NANOSECONDS , Schedulers . trampoline ( ) ) ; 
public final Observable < T > refCount ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
return refCount ( 1 , timeout , unit , scheduler ) ; 
public final Observable < T > refCount ( int subscriberCount , long timeout , TimeUnit unit , Scheduler scheduler ) { 
ObjectHelper . verifyPositive ( subscriberCount , "subscriberCount" ) ; 
return RxJavaPlugins . onAssembly ( new ObservableRefCount < T > ( this , subscriberCount , timeout , unit , scheduler ) ) ; 
public Observable < T > autoConnect ( int numberOfSubscribers , @ NonNull Consumer < ? super Disposable > connection ) { 
if ( numberOfSubscribers <= 0 ) { 
this . connect ( connection ) ; 
return RxJavaPlugins . onAssembly ( new ObservableAutoConnect < T > ( this , numberOfSubscribers , connection ) ) ; 
} protected final boolean validate ( @ NonNull Subscriber < ? > [ ] subscribers ) { 
int p = parallelism ( ) ; 
if ( subscribers . length != p ) { 
for ( Subscriber < ? > s : subscribers ) { 
EmptySubscription . error ( iae , s ) ; 
return false ; 
return true ; 
public static < T > ParallelFlowable < T > from ( @ NonNull Publisher < ? extends T > source ) { 
return from ( source , Runtime . getRuntime ( ) . availableProcessors ( ) , Flowable . bufferSize ( ) ) ; 
public static < T > ParallelFlowable < T > from ( @ NonNull Publisher < ? extends T > source , int parallelism ) { 
return from ( source , parallelism , Flowable . bufferSize ( ) ) ; 
public static < T > ParallelFlowable < T > from ( @ NonNull Publisher < ? extends T > source , 
int parallelism , int prefetch ) { 
ObjectHelper . requireNonNull ( source , "source" ) ; 
ObjectHelper . verifyPositive ( parallelism , "parallelism" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelFromPublisher < T > ( source , parallelism , prefetch ) ) ; 
public final < R > R as ( @ NonNull ParallelFlowableConverter < T , R > converter ) { 
public final < R > ParallelFlowable < R > map ( @ NonNull Function < ? super T , ? extends R > mapper ) { 
ObjectHelper . requireNonNull ( mapper , "mapper" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelMap < T , R > ( this , mapper ) ) ; 
public final < R > ParallelFlowable < R > map ( @ NonNull Function < ? super T , ? extends R > mapper , @ NonNull ParallelFailureHandling errorHandler ) { 
return RxJavaPlugins . onAssembly ( new ParallelMapTry < T , R > ( this , mapper , errorHandler ) ) ; 
public final ParallelFlowable < T > filter ( @ NonNull Predicate < ? super T > predicate ) { 
ObjectHelper . requireNonNull ( predicate , "predicate" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelFilter < T > ( this , predicate ) ) ; 
public final ParallelFlowable < T > filter ( @ NonNull Predicate < ? super T > predicate , @ NonNull ParallelFailureHandling errorHandler ) { 
return RxJavaPlugins . onAssembly ( new ParallelFilterTry < T > ( this , predicate , errorHandler ) ) ; 
public final ParallelFlowable < T > runOn ( @ NonNull Scheduler scheduler ) { 
return runOn ( scheduler , Flowable . bufferSize ( ) ) ; 
public final ParallelFlowable < T > runOn ( @ NonNull Scheduler scheduler , int prefetch ) { 
ObjectHelper . requireNonNull ( scheduler , "scheduler" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelRunOn < T > ( this , scheduler , prefetch ) ) ; 
public final Flowable < T > reduce ( @ NonNull BiFunction < T , T , T > reducer ) { 
ObjectHelper . requireNonNull ( reducer , "reducer" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelReduceFull < T > ( this , reducer ) ) ; 
public final < R > ParallelFlowable < R > reduce ( @ NonNull Callable < R > initialSupplier , @ NonNull BiFunction < R , ? super T , R > reducer ) { 
ObjectHelper . requireNonNull ( initialSupplier , "initialSupplier" ) ; 
return RxJavaPlugins . onAssembly ( new ParallelReduce < T , R > ( this , initialSupplier , reducer ) ) ; 
} @ BackpressureSupport ( BackpressureKind . FULL ) 
public final Flowable < T > sequential ( ) { 
return sequential ( Flowable . bufferSize ( ) ) ; 
public final Flowable < T > sequential ( int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ParallelJoin < T > ( this , prefetch , false ) ) ; 
public final Flowable < T > sequentialDelayError ( ) { 
return sequentialDelayError ( Flowable . bufferSize ( ) ) ; 
public final Flowable < T > sequentialDelayError ( int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ParallelJoin < T > ( this , prefetch , true ) ) ; 
public final Flowable < T > sorted ( @ NonNull Comparator < ? super T > comparator ) { 
return sorted ( comparator , 16 ) ; 
public final Flowable < List < T > > toSortedList ( @ NonNull Comparator < ? super T > comparator ) { 
return toSortedList ( comparator , 16 ) ; 
public final Flowable < List < T > > toSortedList ( @ NonNull Comparator < ? super T > comparator , int capacityHint ) { 
int ch = capacityHint / parallelism ( ) + 1 ; 
ParallelFlowable < List < T > > railReduced = reduce ( Functions . < T > createArrayList ( ch ) , ListAddBiConsumer . < T > instance ( ) ) ; 
ParallelFlowable < List < T > > railSorted = railReduced . map ( new SorterFunction < T > ( comparator ) ) ; 
Flowable < List < T > > merged = railSorted . reduce ( new MergerBiFunction < T > ( comparator ) ) ; 
return RxJavaPlugins . onAssembly ( merged ) ; 
public final ParallelFlowable < T > doOnNext ( @ NonNull Consumer < ? super T > onNext ) { 
return RxJavaPlugins . onAssembly ( new ParallelPeek < T > ( this , 
onNext , 
Functions . emptyConsumer ( ) , 
Functions . EMPTY_ACTION , 
Functions . EMPTY_LONG_CONSUMER , 
) ) ; 
public final ParallelFlowable < T > doOnNext ( @ NonNull Consumer < ? super T > onNext , @ NonNull ParallelFailureHandling errorHandler ) { 
return RxJavaPlugins . onAssembly ( new ParallelDoOnNextTry < T > ( this , onNext , errorHandler ) ) ; 
public final ParallelFlowable < T > doAfterNext ( @ NonNull Consumer < ? super T > onAfterNext ) { 
onAfterNext , 
public final ParallelFlowable < T > doOnError ( @ NonNull Consumer < Throwable > onError ) { 
onError , 
public final ParallelFlowable < T > doOnComplete ( @ NonNull Action onComplete ) { 
onComplete , 
public final ParallelFlowable < T > doAfterTerminated ( @ NonNull Action onAfterTerminate ) { 
onAfterTerminate , 
public final ParallelFlowable < T > doOnSubscribe ( @ NonNull Consumer < ? super Subscription > onSubscribe ) { 
onSubscribe , 
public final ParallelFlowable < T > doOnRequest ( @ NonNull LongConsumer onRequest ) { 
onRequest , 
public final ParallelFlowable < T > doOnCancel ( @ NonNull Action onCancel ) { 
onCancel 
public final < C > ParallelFlowable < C > collect ( @ NonNull Callable < ? extends C > collectionSupplier , @ NonNull BiConsumer < ? super C , ? super T > collector ) { 
return RxJavaPlugins . onAssembly ( new ParallelCollect < T , C > ( this , collectionSupplier , collector ) ) ; 
public static < T > ParallelFlowable < T > fromArray ( @ NonNull Publisher < T > ... publishers ) { 
if ( publishers . length == 0 ) { 
return RxJavaPlugins . onAssembly ( new ParallelFromArray < T > ( publishers ) ) ; 
public final < U > U to ( @ NonNull Function < ? super ParallelFlowable < T > , U > converter ) { 
} catch ( Throwable ex ) { 
Exceptions . throwIfFatal ( ex ) ; 
throw ExceptionHelper . wrapOrThrow ( ex ) ; 
public final < U > ParallelFlowable < U > compose ( @ NonNull ParallelTransformer < T , U > composer ) { 
public final < R > ParallelFlowable < R > flatMap ( 
@ NonNull Function < ? super T , ? extends Publisher < ? extends R > > mapper , boolean delayError ) { 
return flatMap ( mapper , delayError , Integer . MAX_VALUE , Flowable . bufferSize ( ) ) ; 
@ NonNull Function < ? super T , ? extends Publisher < ? extends R > > mapper , 
boolean delayError , int maxConcurrency , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ParallelFlatMap < T , R > ( this , mapper , delayError , maxConcurrency , prefetch ) ) ; 
public final < R > ParallelFlowable < R > concatMap ( 
@ NonNull Function < ? super T , ? extends Publisher < ? extends R > > mapper ) { 
int prefetch ) { 
return RxJavaPlugins . onAssembly ( new ParallelConcatMap < T , R > ( this , mapper , prefetch , ErrorMode . IMMEDIATE ) ) ; 
public final < R > ParallelFlowable < R > concatMapDelayError ( 
boolean tillTheEnd ) { 
return concatMapDelayError ( mapper , 2 , tillTheEnd ) ; 
int prefetch , boolean tillTheEnd ) { 
return RxJavaPlugins . onAssembly ( new ParallelConcatMap < T , R > ( 
this , mapper , prefetch , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY ) ) ; 
} public static < U , R > Observable < R > multicastSelector ( 
final Callable < ? extends ConnectableObservable < U > > connectableFactory , 
final Function < ? super Observable < U > , ? extends ObservableSource < R > > selector ) { 
return RxJavaPlugins . onAssembly ( new MulticastReplay < R , U > ( connectableFactory , selector ) ) ; 
} public static < T > ConnectableObservable < T > observeOn ( final ConnectableObservable < T > co , final Scheduler scheduler ) { 
final Observable < T > observable = co . observeOn ( scheduler ) ; 
return RxJavaPlugins . onAssembly ( new Replay < T > ( co , observable ) ) ; 
public static < T > ConnectableObservable < T > createFrom ( ObservableSource < ? extends T > source ) { 
return create ( source , DEFAULT_UNBOUNDED_FACTORY ) ; 
} public static < T > ConnectableObservable < T > create ( ObservableSource < T > source , 
final int bufferSize ) { 
if ( bufferSize == Integer . MAX_VALUE ) { 
return createFrom ( source ) ; 
return create ( source , new ReplayBufferSupplier < T > ( bufferSize ) ) ; 
long maxAge , TimeUnit unit , Scheduler scheduler ) { 
return create ( source , maxAge , unit , scheduler , Integer . MAX_VALUE ) ; 
final long maxAge , final TimeUnit unit , final Scheduler scheduler , final int bufferSize ) { 
return create ( source , new ScheduledReplaySupplier < T > ( bufferSize , maxAge , unit , scheduler ) ) ; 
} static < T > ConnectableObservable < T > create ( ObservableSource < T > source , 
final BufferSupplier < T > bufferFactory ) { 
final AtomicReference < ReplayObserver < T > > curr = new AtomicReference < ReplayObserver < T > > ( ) ; 
ObservableSource < T > onSubscribe = new ReplaySource < T > ( curr , bufferFactory ) ; 
return RxJavaPlugins . onAssembly ( new ObservableReplay < T > ( onSubscribe , source , curr , bufferFactory ) ) ; 
} public boolean setResource ( int index , Subscription resource ) { 
for ( ; ; ) { 
Subscription o = get ( index ) ; 
if ( o == SubscriptionHelper . CANCELLED ) { 
if ( resource != null ) { 
resource . cancel ( ) ; 
if ( compareAndSet ( index , o , resource ) ) { 
if ( o != null ) { 
o . cancel ( ) ; 
} public Subscription replaceResource ( int index , Subscription resource ) { 
return null ; 
public static < T > UnicastProcessor < T > create ( int capacityHint ) { 
return new UnicastProcessor < T > ( capacityHint ) ; 
public static < T > UnicastProcessor < T > create ( boolean delayError ) { 
return new UnicastProcessor < T > ( bufferSize ( ) , null , delayError ) ; 
public static < T > UnicastProcessor < T > create ( int capacityHint , Runnable onCancelled ) { 
ObjectHelper . requireNonNull ( onCancelled , "onTerminate" ) ; 
return new UnicastProcessor < T > ( capacityHint , onCancelled ) ; 
public static < T , R > boolean tryScalarXMapSubscribe ( Publisher < T > source , 
Subscriber < ? super R > subscriber , 
Function < ? super T , ? extends Publisher < ? extends R > > mapper ) { 
if ( source instanceof Callable ) { 
T t ; 
t = ( ( Callable < T > ) source ) . call ( ) ; 
EmptySubscription . error ( ex , subscriber ) ; 
if ( t == null ) { 
EmptySubscription . complete ( subscriber ) ; 
Publisher < ? extends R > r ; 
if ( r instanceof Callable ) { 
R u ; 
u = ( ( Callable < R > ) r ) . call ( ) ; 
if ( u == null ) { 
subscriber . onSubscribe ( new ScalarSubscription < R > ( subscriber , u ) ) ; 
r . subscribe ( subscriber ) ; 
} public static < T , U > Flowable < U > scalarXMap ( final T value , final Function < ? super T , ? extends Publisher < ? extends U > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ScalarXMapFlowable < T , U > ( value , mapper ) ) ; 
public static Disposable fromRunnable ( @ NonNull Runnable run ) { 
return new RunnableDisposable ( run ) ; 
public static Disposable fromAction ( @ NonNull Action run ) { 
return new ActionDisposable ( run ) ; 
public static Disposable fromFuture ( @ NonNull Future < ? > future ) { 
return fromFuture ( future , true ) ; 
public static Disposable fromFuture ( @ NonNull Future < ? > future , boolean allowInterrupt ) { 
return new FutureDisposable ( future , allowInterrupt ) ; 
public static Disposable fromSubscription ( @ NonNull Subscription subscription ) { 
return new SubscriptionDisposable ( subscription ) ; 
} public final T blockingGet ( ) { 
if ( getCount ( ) != 0 ) { 
BlockingHelper . verifyNonBlocking ( ) ; 
await ( ) ; 
} catch ( InterruptedException ex ) { 
dispose ( ) ; 
Throwable e = error ; 
if ( e != null ) { 
return value ; 
public static Scheduler initComputationScheduler ( @ NonNull Callable < Scheduler > defaultScheduler ) { 
Function < ? super Callable < Scheduler > , ? extends Scheduler > f = onInitComputationHandler ; 
if ( f == null ) { 
return callRequireNonNull ( defaultScheduler ) ; 
return applyRequireNonNull ( f , defaultScheduler ) ; 
public static Scheduler initIoScheduler ( @ NonNull Callable < Scheduler > defaultScheduler ) { 
Function < ? super Callable < Scheduler > , ? extends Scheduler > f = onInitIoHandler ; 
public static Scheduler initNewThreadScheduler ( @ NonNull Callable < Scheduler > defaultScheduler ) { 
Function < ? super Callable < Scheduler > , ? extends Scheduler > f = onInitNewThreadHandler ; 
public static Scheduler initSingleScheduler ( @ NonNull Callable < Scheduler > defaultScheduler ) { 
Function < ? super Callable < Scheduler > , ? extends Scheduler > f = onInitSingleHandler ; 
public static Scheduler onComputationScheduler ( @ NonNull Scheduler defaultScheduler ) { 
Function < ? super Scheduler , ? extends Scheduler > f = onComputationHandler ; 
return defaultScheduler ; 
return apply ( f , defaultScheduler ) ; 
} public static void onError ( @ NonNull Throwable error ) { 
Consumer < ? super Throwable > f = errorHandler ; 
if ( error == null ) { 
if ( ! isBug ( error ) ) { 
error = new UndeliverableException ( error ) ; 
if ( f != null ) { 
f . accept ( error ) ; 
e . printStackTrace ( ) ; 
uncaught ( e ) ; 
error . printStackTrace ( ) ; 
uncaught ( error ) ; 
public static Scheduler onIoScheduler ( @ NonNull Scheduler defaultScheduler ) { 
Function < ? super Scheduler , ? extends Scheduler > f = onIoHandler ; 
public static Scheduler onNewThreadScheduler ( @ NonNull Scheduler defaultScheduler ) { 
Function < ? super Scheduler , ? extends Scheduler > f = onNewThreadHandler ; 
public static Runnable onSchedule ( @ NonNull Runnable run ) { 
Function < ? super Runnable , ? extends Runnable > f = onScheduleHandler ; 
return run ; 
return apply ( f , run ) ; 
public static Scheduler onSingleScheduler ( @ NonNull Scheduler defaultScheduler ) { 
Function < ? super Scheduler , ? extends Scheduler > f = onSingleHandler ; 
} public static void reset ( ) { 
setErrorHandler ( null ) ; 
setScheduleHandler ( null ) ; 
setComputationSchedulerHandler ( null ) ; 
setInitComputationSchedulerHandler ( null ) ; 
setIoSchedulerHandler ( null ) ; 
setInitIoSchedulerHandler ( null ) ; 
setSingleSchedulerHandler ( null ) ; 
setInitSingleSchedulerHandler ( null ) ; 
setNewThreadSchedulerHandler ( null ) ; 
setInitNewThreadSchedulerHandler ( null ) ; 
setOnFlowableAssembly ( null ) ; 
setOnFlowableSubscribe ( null ) ; 
setOnObservableAssembly ( null ) ; 
setOnObservableSubscribe ( null ) ; 
setOnSingleAssembly ( null ) ; 
setOnSingleSubscribe ( null ) ; 
setOnCompletableAssembly ( null ) ; 
setOnCompletableSubscribe ( null ) ; 
setOnConnectableFlowableAssembly ( null ) ; 
setOnConnectableObservableAssembly ( null ) ; 
setOnMaybeAssembly ( null ) ; 
setOnMaybeSubscribe ( null ) ; 
setOnParallelAssembly ( null ) ; 
setFailOnNonBlockingScheduler ( false ) ; 
setOnBeforeBlocking ( null ) ; 
} public static void setComputationSchedulerHandler ( @ Nullable Function < ? super Scheduler , ? extends Scheduler > handler ) { 
if ( lockdown ) { 
onComputationHandler = handler ; 
} public static void setInitComputationSchedulerHandler ( @ Nullable Function < ? super Callable < Scheduler > , ? extends Scheduler > handler ) { 
onInitComputationHandler = handler ; 
} public static void setInitIoSchedulerHandler ( @ Nullable Function < ? super Callable < Scheduler > , ? extends Scheduler > handler ) { 
onInitIoHandler = handler ; 
} public static void setInitNewThreadSchedulerHandler ( @ Nullable Function < ? super Callable < Scheduler > , ? extends Scheduler > handler ) { 
onInitNewThreadHandler = handler ; 
} public static void setInitSingleSchedulerHandler ( @ Nullable Function < ? super Callable < Scheduler > , ? extends Scheduler > handler ) { 
onInitSingleHandler = handler ; 
} public static void setIoSchedulerHandler ( @ Nullable Function < ? super Scheduler , ? extends Scheduler > handler ) { 
onIoHandler = handler ; 
} public static void setNewThreadSchedulerHandler ( @ Nullable Function < ? super Scheduler , ? extends Scheduler > handler ) { 
onNewThreadHandler = handler ; 
} public static void setScheduleHandler ( @ Nullable Function < ? super Runnable , ? extends Runnable > handler ) { 
onScheduleHandler = handler ; 
} public static void setSingleSchedulerHandler ( @ Nullable Function < ? super Scheduler , ? extends Scheduler > handler ) { 
onSingleHandler = handler ; 
} public static void setOnCompletableAssembly ( @ Nullable Function < ? super Completable , ? extends Completable > onCompletableAssembly ) { 
RxJavaPlugins . onCompletableAssembly = onCompletableAssembly ; 
} public static void setOnCompletableSubscribe ( 
@ Nullable BiFunction < ? super Completable , ? super CompletableObserver , ? extends CompletableObserver > onCompletableSubscribe ) { 
RxJavaPlugins . onCompletableSubscribe = onCompletableSubscribe ; 
} @ SuppressWarnings ( "rawtypes" ) 
public static void setOnFlowableAssembly ( @ Nullable Function < ? super Flowable , ? extends Flowable > onFlowableAssembly ) { 
RxJavaPlugins . onFlowableAssembly = onFlowableAssembly ; 
public static void setOnMaybeAssembly ( @ Nullable Function < ? super Maybe , ? extends Maybe > onMaybeAssembly ) { 
RxJavaPlugins . onMaybeAssembly = onMaybeAssembly ; 
public static void setOnConnectableFlowableAssembly ( @ Nullable Function < ? super ConnectableFlowable , ? extends ConnectableFlowable > onConnectableFlowableAssembly ) { 
RxJavaPlugins . onConnectableFlowableAssembly = onConnectableFlowableAssembly ; 
public static void setOnFlowableSubscribe ( @ Nullable BiFunction < ? super Flowable , ? super Subscriber , ? extends Subscriber > onFlowableSubscribe ) { 
RxJavaPlugins . onFlowableSubscribe = onFlowableSubscribe ; 
public static void setOnMaybeSubscribe ( @ Nullable BiFunction < ? super Maybe , MaybeObserver , ? extends MaybeObserver > onMaybeSubscribe ) { 
RxJavaPlugins . onMaybeSubscribe = onMaybeSubscribe ; 
public static void setOnObservableAssembly ( @ Nullable Function < ? super Observable , ? extends Observable > onObservableAssembly ) { 
RxJavaPlugins . onObservableAssembly = onObservableAssembly ; 
public static void setOnConnectableObservableAssembly ( @ Nullable Function < ? super ConnectableObservable , ? extends ConnectableObservable > onConnectableObservableAssembly ) { 
RxJavaPlugins . onConnectableObservableAssembly = onConnectableObservableAssembly ; 
public static void setOnObservableSubscribe ( 
@ Nullable BiFunction < ? super Observable , ? super Observer , ? extends Observer > onObservableSubscribe ) { 
RxJavaPlugins . onObservableSubscribe = onObservableSubscribe ; 
public static void setOnSingleAssembly ( @ Nullable Function < ? super Single , ? extends Single > onSingleAssembly ) { 
RxJavaPlugins . onSingleAssembly = onSingleAssembly ; 
public static void setOnSingleSubscribe ( @ Nullable BiFunction < ? super Single , ? super SingleObserver , ? extends SingleObserver > onSingleSubscribe ) { 
RxJavaPlugins . onSingleSubscribe = onSingleSubscribe ; 
public static < T > Subscriber < ? super T > onSubscribe ( @ NonNull Flowable < T > source , @ NonNull Subscriber < ? super T > subscriber ) { 
BiFunction < ? super Flowable , ? super Subscriber , ? extends Subscriber > f = onFlowableSubscribe ; 
return apply ( f , source , subscriber ) ; 
return subscriber ; 
public static < T > Observer < ? super T > onSubscribe ( @ NonNull Observable < T > source , @ NonNull Observer < ? super T > observer ) { 
BiFunction < ? super Observable , ? super Observer , ? extends Observer > f = onObservableSubscribe ; 
return apply ( f , source , observer ) ; 
return observer ; 
public static < T > SingleObserver < ? super T > onSubscribe ( @ NonNull Single < T > source , @ NonNull SingleObserver < ? super T > observer ) { 
BiFunction < ? super Single , ? super SingleObserver , ? extends SingleObserver > f = onSingleSubscribe ; 
public static CompletableObserver onSubscribe ( @ NonNull Completable source , @ NonNull CompletableObserver observer ) { 
BiFunction < ? super Completable , ? super CompletableObserver , ? extends CompletableObserver > f = onCompletableSubscribe ; 
public static < T > MaybeObserver < ? super T > onSubscribe ( @ NonNull Maybe < T > source , @ NonNull MaybeObserver < ? super T > observer ) { 
BiFunction < ? super Maybe , ? super MaybeObserver , ? extends MaybeObserver > f = onMaybeSubscribe ; 
public static < T > Maybe < T > onAssembly ( @ NonNull Maybe < T > source ) { 
Function < ? super Maybe , ? extends Maybe > f = onMaybeAssembly ; 
return apply ( f , source ) ; 
return source ; 
public static < T > Flowable < T > onAssembly ( @ NonNull Flowable < T > source ) { 
Function < ? super Flowable , ? extends Flowable > f = onFlowableAssembly ; 
public static < T > ConnectableFlowable < T > onAssembly ( @ NonNull ConnectableFlowable < T > source ) { 
Function < ? super ConnectableFlowable , ? extends ConnectableFlowable > f = onConnectableFlowableAssembly ; 
public static < T > Observable < T > onAssembly ( @ NonNull Observable < T > source ) { 
Function < ? super Observable , ? extends Observable > f = onObservableAssembly ; 
public static < T > ConnectableObservable < T > onAssembly ( @ NonNull ConnectableObservable < T > source ) { 
Function < ? super ConnectableObservable , ? extends ConnectableObservable > f = onConnectableObservableAssembly ; 
public static < T > Single < T > onAssembly ( @ NonNull Single < T > source ) { 
Function < ? super Single , ? extends Single > f = onSingleAssembly ; 
public static Completable onAssembly ( @ NonNull Completable source ) { 
Function < ? super Completable , ? extends Completable > f = onCompletableAssembly ; 
public static void setOnParallelAssembly ( @ Nullable Function < ? super ParallelFlowable , ? extends ParallelFlowable > handler ) { 
onParallelAssembly = handler ; 
public static < T > ParallelFlowable < T > onAssembly ( @ NonNull ParallelFlowable < T > source ) { 
Function < ? super ParallelFlowable , ? extends ParallelFlowable > f = onParallelAssembly ; 
} public static boolean onBeforeBlocking ( ) { 
BooleanSupplier f = onBeforeBlocking ; 
return f . getAsBoolean ( ) ; 
public static Scheduler createComputationScheduler ( @ NonNull ThreadFactory threadFactory ) { 
static < T , R > R apply ( @ NonNull Function < T , R > f , @ NonNull T t ) { 
return f . apply ( t ) ; 
static < T , U , R > R apply ( @ NonNull BiFunction < T , U , R > f , @ NonNull T t , @ NonNull U u ) { 
return f . apply ( t , u ) ; 
static Scheduler callRequireNonNull ( @ NonNull Callable < Scheduler > s ) { 
static Scheduler applyRequireNonNull ( @ NonNull Function < ? super Callable < Scheduler > , ? extends Scheduler > f , Callable < Scheduler > s ) { 
public static < T > Maybe < T > amb ( final Iterable < ? extends MaybeSource < ? extends T > > sources ) { 
return RxJavaPlugins . onAssembly ( new MaybeAmb < T > ( null , sources ) ) ; 
public static < T > Maybe < T > ambArray ( final MaybeSource < ? extends T > ... sources ) { 
return wrap ( ( MaybeSource < T > ) sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new MaybeAmb < T > ( sources , null ) ) ; 
public static < T > Flowable < T > concat ( Publisher < ? extends MaybeSource < ? extends T > > sources ) { 
return concat ( sources , 2 ) ; 
@ BackpressureSupport ( BackpressureKind . FULL ) 
public static < T > Flowable < T > concatArrayDelayError ( MaybeSource < ? extends T > ... sources ) { 
return Flowable . empty ( ) ; 
return RxJavaPlugins . onAssembly ( new MaybeToFlowable < T > ( ( MaybeSource < T > ) sources [ 0 ] ) ) ; 
return RxJavaPlugins . onAssembly ( new MaybeConcatArrayDelayError < T > ( sources ) ) ; 
public static < T > Flowable < T > concatArrayEager ( MaybeSource < ? extends T > ... sources ) { 
return Flowable . fromArray ( sources ) . concatMapEager ( ( Function ) MaybeToPublisher . instance ( ) ) ; 
public static < T > Flowable < T > concatEager ( Iterable < ? extends MaybeSource < ? extends T > > sources ) { 
return Flowable . fromIterable ( sources ) . concatMapEager ( ( Function ) MaybeToPublisher . instance ( ) ) ; 
public static < T > Maybe < T > create ( MaybeOnSubscribe < T > onSubscribe ) { 
return RxJavaPlugins . onAssembly ( new MaybeCreate < T > ( onSubscribe ) ) ; 
public static < T > Maybe < T > defer ( final Callable < ? extends MaybeSource < ? extends T > > maybeSupplier ) { 
return RxJavaPlugins . onAssembly ( new MaybeDefer < T > ( maybeSupplier ) ) ; 
public static < T > Maybe < T > empty ( ) { 
return RxJavaPlugins . onAssembly ( ( Maybe < T > ) MaybeEmpty . INSTANCE ) ; 
public static < T > Maybe < T > error ( Throwable exception ) { 
return RxJavaPlugins . onAssembly ( new MaybeError < T > ( exception ) ) ; 
public static < T > Maybe < T > error ( Callable < ? extends Throwable > supplier ) { 
return RxJavaPlugins . onAssembly ( new MaybeErrorCallable < T > ( supplier ) ) ; 
public static < T > Maybe < T > fromCompletable ( CompletableSource completableSource ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromCompletable < T > ( completableSource ) ) ; 
public static < T > Maybe < T > fromSingle ( SingleSource < T > singleSource ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromSingle < T > ( singleSource ) ) ; 
public static < T > Maybe < T > fromCallable ( @ NonNull final Callable < ? extends T > callable ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromCallable < T > ( callable ) ) ; 
public static < T > Maybe < T > fromFuture ( Future < ? extends T > future ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromFuture < T > ( future , 0L , null ) ) ; 
public static < T > Maybe < T > fromFuture ( Future < ? extends T > future , long timeout , TimeUnit unit ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromFuture < T > ( future , timeout , unit ) ) ; 
public static < T > Maybe < T > fromRunnable ( final Runnable run ) { 
return RxJavaPlugins . onAssembly ( new MaybeFromRunnable < T > ( run ) ) ; 
public static < T > Maybe < T > just ( T item ) { 
return RxJavaPlugins . onAssembly ( new MaybeJust < T > ( item ) ) ; 
public static < T > Flowable < T > merge ( Publisher < ? extends MaybeSource < ? extends T > > sources ) { 
return merge ( sources , Integer . MAX_VALUE ) ; 
public static < T > Flowable < T > mergeArrayDelayError ( MaybeSource < ? extends T > ... sources ) { 
return Flowable . fromArray ( sources ) . flatMap ( ( Function ) MaybeToPublisher . instance ( ) , true , sources . length ) ; 
public static < T > Flowable < T > mergeDelayError ( Iterable < ? extends MaybeSource < ? extends T > > sources ) { 
return Flowable . fromIterable ( sources ) . flatMap ( ( Function ) MaybeToPublisher . instance ( ) , true ) ; 
public static < T > Maybe < T > never ( ) { 
return RxJavaPlugins . onAssembly ( ( Maybe < T > ) MaybeNever . INSTANCE ) ; 
public static < T > Single < Boolean > sequenceEqual ( MaybeSource < ? extends T > source1 , MaybeSource < ? extends T > source2 ) { 
return sequenceEqual ( source1 , source2 , ObjectHelper . equalsPredicate ( ) ) ; 
public static < T > Single < Boolean > sequenceEqual ( MaybeSource < ? extends T > source1 , MaybeSource < ? extends T > source2 , 
return RxJavaPlugins . onAssembly ( new MaybeEqualSingle < T > ( source1 , source2 , isEqual ) ) ; 
public static Maybe < Long > timer ( long delay , TimeUnit unit ) { 
return timer ( delay , unit , Schedulers . computation ( ) ) ; 
public static Maybe < Long > timer ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new MaybeTimer ( Math . max ( 0L , delay ) , unit , scheduler ) ) ; 
public static < T > Maybe < T > unsafeCreate ( MaybeSource < T > onSubscribe ) { 
if ( onSubscribe instanceof Maybe ) { 
return RxJavaPlugins . onAssembly ( new MaybeUnsafeCreate < T > ( onSubscribe ) ) ; 
public static < T , D > Maybe < T > using ( Callable < ? extends D > resourceSupplier , 
Function < ? super D , ? extends MaybeSource < ? extends T > > sourceSupplier , 
Consumer < ? super D > resourceDisposer ) { 
return using ( resourceSupplier , sourceSupplier , resourceDisposer , true ) ; 
Consumer < ? super D > resourceDisposer , boolean eager ) { 
return RxJavaPlugins . onAssembly ( new MaybeUsing < T , D > ( resourceSupplier , sourceSupplier , resourceDisposer , eager ) ) ; 
public static < T > Maybe < T > wrap ( MaybeSource < T > source ) { 
if ( source instanceof Maybe ) { 
return RxJavaPlugins . onAssembly ( ( Maybe < T > ) source ) ; 
return RxJavaPlugins . onAssembly ( new MaybeUnsafeCreate < T > ( source ) ) ; 
public static < T , R > Maybe < R > zip ( Iterable < ? extends MaybeSource < ? extends T > > sources , Function < ? super Object [ ] , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new MaybeZipIterable < T , R > ( sources , zipper ) ) ; 
public static < T , R > Maybe < R > zipArray ( Function < ? super Object [ ] , ? extends R > zipper , 
MaybeSource < ? extends T > ... sources ) { 
return RxJavaPlugins . onAssembly ( new MaybeZipArray < T , R > ( sources , zipper ) ) ; 
public final Maybe < T > ambWith ( MaybeSource < ? extends T > other ) { 
public final T blockingGet ( ) { 
BlockingMultiObserver < T > observer = new BlockingMultiObserver < T > ( ) ; 
return observer . blockingGet ( ) ; 
public final T blockingGet ( T defaultValue ) { 
return observer . blockingGet ( defaultValue ) ; 
public final Maybe < T > cache ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeCache < T > ( this ) ) ; 
public final < R > Maybe < R > compose ( MaybeTransformer < ? super T , ? extends R > transformer ) { 
public final < R > Maybe < R > concatMap ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new MaybeFlatten < T , R > ( this , mapper ) ) ; 
public final Flowable < T > concatWith ( MaybeSource < ? extends T > other ) { 
public final Single < Boolean > contains ( final Object item ) { 
return RxJavaPlugins . onAssembly ( new MaybeContains < T > ( this , item ) ) ; 
public final Single < Long > count ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeCount < T > ( this ) ) ; 
public final Maybe < T > delay ( long delay , TimeUnit unit ) { 
return delay ( delay , unit , Schedulers . computation ( ) ) ; 
public final Maybe < T > delay ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new MaybeDelay < T > ( this , Math . max ( 0L , delay ) , unit , scheduler ) ) ; 
public final < U > Maybe < T > delaySubscription ( Publisher < U > subscriptionIndicator ) { 
return RxJavaPlugins . onAssembly ( new MaybeDelaySubscriptionOtherPublisher < T , U > ( this , subscriptionIndicator ) ) ; 
public final Maybe < T > delaySubscription ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return delaySubscription ( Flowable . timer ( delay , unit , scheduler ) ) ; 
public final Maybe < T > doOnError ( Consumer < ? super Throwable > onError ) { 
return RxJavaPlugins . onAssembly ( new MaybePeek < T > ( this , 
public final Maybe < T > doOnEvent ( BiConsumer < ? super T , ? super Throwable > onEvent ) { 
return RxJavaPlugins . onAssembly ( new MaybeDoOnEvent < T > ( this , onEvent ) ) ; 
public final Maybe < T > doOnTerminate ( final Action onTerminate ) { 
return RxJavaPlugins . onAssembly ( new MaybeDoOnTerminate < T > ( this , onTerminate ) ) ; 
public final < U , R > Maybe < R > flatMap ( Function < ? super T , ? extends MaybeSource < ? extends U > > mapper , 
return RxJavaPlugins . onAssembly ( new MaybeFlatMapBiSelector < T , U , R > ( this , mapper , resultSelector ) ) ; 
public final < U > Flowable < U > flattenAsFlowable ( final Function < ? super T , ? extends Iterable < ? extends U > > mapper ) { 
return RxJavaPlugins . onAssembly ( new MaybeFlatMapIterableFlowable < T , U > ( this , mapper ) ) ; 
public final Maybe < T > hide ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeHide < T > ( this ) ) ; 
public final Completable ignoreElement ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeIgnoreElementCompletable < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new MaybeIsEmptySingle < T > ( this ) ) ; 
public final < R > Maybe < R > lift ( final MaybeOperator < ? extends R , ? super T > lift ) { 
return RxJavaPlugins . onAssembly ( new MaybeLift < T , R > ( this , lift ) ) ; 
public final < R > Maybe < R > map ( Function < ? super T , ? extends R > mapper ) { 
return RxJavaPlugins . onAssembly ( new MaybeMap < T , R > ( this , mapper ) ) ; 
public final < U > Maybe < U > ofType ( final Class < U > clazz ) { 
return filter ( Functions . isInstanceOf ( clazz ) ) . cast ( clazz ) ; 
public final < R > R to ( Function < ? super Maybe < T > , R > convert ) { 
public final Observable < T > toObservable ( ) { 
if ( this instanceof FuseToObservable ) { 
return ( ( FuseToObservable < T > ) this ) . fuseToObservable ( ) ; 
return RxJavaPlugins . onAssembly ( new MaybeToObservable < T > ( this ) ) ; 
public final Single < T > toSingle ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeToSingle < T > ( this , null ) ) ; 
public final Maybe < T > onErrorComplete ( ) { 
return onErrorComplete ( Functions . alwaysTrue ( ) ) ; 
public final Maybe < T > onErrorResumeNext ( final MaybeSource < ? extends T > next ) { 
public final Maybe < T > onErrorResumeNext ( Function < ? super Throwable , ? extends MaybeSource < ? extends T > > resumeFunction ) { 
return RxJavaPlugins . onAssembly ( new MaybeOnErrorNext < T > ( this , resumeFunction , true ) ) ; 
public final Maybe < T > onErrorReturn ( Function < ? super Throwable , ? extends T > valueSupplier ) { 
return RxJavaPlugins . onAssembly ( new MaybeOnErrorReturn < T > ( this , valueSupplier ) ) ; 
public final Maybe < T > onTerminateDetach ( ) { 
return RxJavaPlugins . onAssembly ( new MaybeDetach < T > ( this ) ) ; 
public final Flowable < T > repeatUntil ( BooleanSupplier stop ) { 
return toFlowable ( ) . repeatUntil ( stop ) ; 
public final Flowable < T > repeatWhen ( final Function < ? super Flowable < Object > , ? extends Publisher < ? > > handler ) { 
return toFlowable ( ) . repeatWhen ( handler ) ; 
public final Maybe < T > retry ( BiPredicate < ? super Integer , ? super Throwable > predicate ) { 
return toFlowable ( ) . retry ( predicate ) . singleElement ( ) ; 
public final Maybe < T > retry ( long count ) { 
return retry ( count , Functions . alwaysTrue ( ) ) ; 
public final Maybe < T > retry ( long times , Predicate < ? super Throwable > predicate ) { 
return toFlowable ( ) . retry ( times , predicate ) . singleElement ( ) ; 
public final Maybe < T > retryWhen ( 
final Function < ? super Flowable < Throwable > , ? extends Publisher < ? > > handler ) { 
return toFlowable ( ) . retryWhen ( handler ) . singleElement ( ) ; 
public final Disposable subscribe ( ) { 
return subscribe ( Functions . emptyConsumer ( ) , Functions . ON_ERROR_MISSING , Functions . EMPTY_ACTION ) ; 
public final Disposable subscribe ( Consumer < ? super T > onSuccess , Consumer < ? super Throwable > onError ) { 
return subscribe ( onSuccess , onError , Functions . EMPTY_ACTION ) ; 
public final Maybe < T > switchIfEmpty ( MaybeSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new MaybeSwitchIfEmpty < T > ( this , other ) ) ; 
public final Single < T > switchIfEmpty ( SingleSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new MaybeSwitchIfEmptySingle < T > ( this , other ) ) ; 
public final < U > Maybe < T > takeUntil ( MaybeSource < U > other ) { 
return RxJavaPlugins . onAssembly ( new MaybeTakeUntilMaybe < T , U > ( this , other ) ) ; 
public final Maybe < T > timeout ( long timeout , TimeUnit timeUnit ) { 
return timeout ( timeout , timeUnit , Schedulers . computation ( ) ) ; 
public final Maybe < T > timeout ( long timeout , TimeUnit timeUnit , Scheduler scheduler ) { 
return timeout ( timer ( timeout , timeUnit , scheduler ) ) ; 
public final < U > Maybe < T > timeout ( MaybeSource < U > timeoutIndicator ) { 
return RxJavaPlugins . onAssembly ( new MaybeTimeoutMaybe < T , U > ( this , timeoutIndicator , null ) ) ; 
public final < U > Maybe < T > timeout ( Publisher < U > timeoutIndicator ) { 
return RxJavaPlugins . onAssembly ( new MaybeTimeoutPublisher < T , U > ( this , timeoutIndicator , null ) ) ; 
public final Maybe < T > unsubscribeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new MaybeUnsubscribeOn < T > ( this , scheduler ) ) ; 
} public static < T > ConnectableFlowable < T > create ( Flowable < T > source , final int bufferSize ) { 
final AtomicReference < PublishSubscriber < T > > curr = new AtomicReference < PublishSubscriber < T > > ( ) ; 
Publisher < T > onSubscribe = new FlowablePublisher < T > ( curr , bufferSize ) ; 
return RxJavaPlugins . onAssembly ( new FlowablePublish < T > ( onSubscribe , source , curr , bufferSize ) ) ; 
} public static < T > SingleObserver < T > create ( Observer < ? super T > downstream ) { 
return new SingleToObservableObserver < T > ( downstream ) ; 
} public static < T > T requireNonNull ( T object , String message ) { 
if ( object == null ) { 
throw new NullPointerException ( message ) ; 
return object ; 
public static < T > BiPredicate < T , T > equalsPredicate ( ) { 
return ( BiPredicate < T , T > ) EQUALS ; 
} public static void onError ( Subscriber < ? > subscriber , Throwable ex , 
AtomicInteger wip , AtomicThrowable error ) { 
if ( error . addThrowable ( ex ) ) { 
if ( wip . getAndIncrement ( ) == 0 ) { 
subscriber . onError ( error . terminate ( ) ) ; 
RxJavaPlugins . onError ( ex ) ; 
} public static void onComplete ( Subscriber < ? > subscriber , AtomicInteger wip , AtomicThrowable error ) { 
Throwable ex = error . terminate ( ) ; 
if ( ex != null ) { 
subscriber . onError ( ex ) ; 
subscriber . onComplete ( ) ; 
} public static void onError ( Observer < ? > observer , Throwable ex , 
observer . onError ( error . terminate ( ) ) ; 
} public static void onComplete ( Observer < ? > observer , AtomicInteger wip , AtomicThrowable error ) { 
observer . onError ( ex ) ; 
observer . onComplete ( ) ; 
public static < T > Function < T , T > identity ( ) { 
return ( Function < T , T > ) IDENTITY ; 
} public static < T > Callable < T > justCallable ( T value ) { 
return new JustValue < Object , T > ( value ) ; 
} public static < T , U > Function < T , U > justFunction ( U value ) { 
return new JustValue < T , U > ( value ) ; 
} public static < T , U > Function < T , U > castFunction ( Class < U > target ) { 
return new CastToClass < T , U > ( target ) ; 
} private void printStackTrace ( PrintStreamOrWriter s ) { 
StringBuilder b = new StringBuilder ( 128 ) ; 
b . append ( this ) . append ( '\n' ) ; 
for ( StackTraceElement myStackElement : getStackTrace ( ) ) { 
int i = 1 ; 
for ( Throwable ex : exceptions ) { 
appendStackTrace ( b , ex , "\t" ) ; 
i ++ ; 
s . println ( b . toString ( ) ) ; 
} Throwable getRootCause ( Throwable e ) { 
Throwable root = e . getCause ( ) ; 
if ( root == null || e == root ) { 
return e ; 
while ( true ) { 
Throwable cause = root . getCause ( ) ; 
if ( cause == null || cause == root ) { 
return root ; 
root = cause ; 
public static < T > UnicastSubject < T > create ( ) { 
return new UnicastSubject < T > ( bufferSize ( ) , true ) ; 
public static < T > UnicastSubject < T > create ( int capacityHint ) { 
return new UnicastSubject < T > ( capacityHint , true ) ; 
public static < T > UnicastSubject < T > create ( int capacityHint , Runnable onTerminate ) { 
return new UnicastSubject < T > ( capacityHint , onTerminate , true ) ; 
public static < T > UnicastSubject < T > create ( boolean delayError ) { 
return new UnicastSubject < T > ( bufferSize ( ) , delayError ) ; 
} public boolean offer ( T t ) { 
PublishSubscription < T > [ ] array = subscribers . get ( ) ; 
for ( PublishSubscription < T > s : array ) { 
if ( s . isFull ( ) ) { 
s . onNext ( t ) ; 
@ Override 
public final void onSubscribe ( Disposable d ) { 
if ( DisposableHelper . validate ( this . upstream , d ) ) { 
this . upstream = d ; 
if ( d instanceof QueueDisposable ) { 
this . qd = ( QueueDisposable < T > ) d ; 
if ( beforeDownstream ( ) ) { 
downstream . onSubscribe ( this ) ; 
afterDownstream ( ) ; 
public void onError ( Throwable t ) { 
if ( done ) { 
RxJavaPlugins . onError ( t ) ; 
done = true ; 
downstream . onError ( t ) ; 
} protected final void fail ( Throwable t ) { 
Exceptions . throwIfFatal ( t ) ; 
upstream . dispose ( ) ; 
onError ( t ) ; 
} protected final int transitiveBoundaryFusion ( int mode ) { 
QueueDisposable < T > qd = this . qd ; 
if ( qd != null ) { 
if ( ( mode & BOUNDARY ) == 0 ) { 
int m = qd . requestFusion ( mode ) ; 
if ( m != NONE ) { 
sourceMode = m ; 
return m ; 
return NONE ; 
} public Throwable blockingGetError ( ) { 
return ex ; 
return error ; 
} public Throwable blockingGetError ( long timeout , TimeUnit unit ) { 
if ( ! await ( timeout , unit ) ) { 
throw ExceptionHelper . wrapOrThrow ( new TimeoutException ( timeoutMessage ( timeout , unit ) ) ) ; 
} public boolean blockingAwait ( long timeout , TimeUnit unit ) { 
Throwable ex = error ; 
public static < T > ReplayProcessor < T > create ( int capacityHint ) { 
return new ReplayProcessor < T > ( new UnboundedReplayBuffer < T > ( capacityHint ) ) ; 
public static < T > ReplayProcessor < T > createWithSize ( int maxSize ) { 
return new ReplayProcessor < T > ( new SizeBoundReplayBuffer < T > ( maxSize ) ) ; 
} static < T > ReplayProcessor < T > createUnbounded ( ) { 
return new ReplayProcessor < T > ( new SizeBoundReplayBuffer < T > ( Integer . MAX_VALUE ) ) ; 
public static < T > ReplayProcessor < T > createWithTime ( long maxAge , TimeUnit unit , Scheduler scheduler ) { 
return new ReplayProcessor < T > ( new SizeAndTimeBoundReplayBuffer < T > ( Integer . MAX_VALUE , maxAge , unit , scheduler ) ) ; 
public final void onSubscribe ( Subscription s ) { 
if ( SubscriptionHelper . validate ( this . upstream , s ) ) { 
this . upstream = s ; 
if ( s instanceof QueueSubscription ) { 
this . qs = ( QueueSubscription < T > ) s ; 
upstream . cancel ( ) ; 
QueueSubscription < T > qs = this . qs ; 
if ( qs != null ) { 
int m = qs . requestFusion ( mode ) ; 
public static < T > BehaviorSubject < T > createDefault ( T defaultValue ) { 
return new BehaviorSubject < T > ( defaultValue ) ; 
} @ Nullable 
public T getValue ( ) { 
Object o = value . get ( ) ; 
if ( NotificationLite . isComplete ( o ) || NotificationLite . isError ( o ) ) { 
return NotificationLite . getValue ( o ) ; 
} @ Deprecated 
public Object [ ] getValues ( ) { 
T [ ] a = ( T [ ] ) EMPTY_ARRAY ; 
T [ ] b = getValues ( a ) ; 
if ( b == EMPTY_ARRAY ) { 
return new Object [ 0 ] ; 
return b ; 
public T [ ] getValues ( T [ ] array ) { 
if ( o == null || NotificationLite . isComplete ( o ) || NotificationLite . isError ( o ) ) { 
if ( array . length != 0 ) { 
array [ 0 ] = null ; 
return array ; 
T v = NotificationLite . getValue ( o ) ; 
array [ 0 ] = v ; 
if ( array . length != 1 ) { 
array [ 1 ] = null ; 
array = ( T [ ] ) Array . newInstance ( array . getClass ( ) . getComponentType ( ) , 1 ) ; 
} public boolean hasValue ( ) { 
return o != null && ! NotificationLite . isComplete ( o ) && ! NotificationLite . isError ( o ) ; 
} public static < T , U > void drainMaxLoop ( SimplePlainQueue < T > q , Subscriber < ? super U > a , boolean delayError , 
Disposable dispose , QueueDrain < T , U > qd ) { 
int missed = 1 ; 
boolean d = qd . done ( ) ; 
T v = q . poll ( ) ; 
boolean empty = v == null ; 
if ( checkTerminated ( d , empty , a , delayError , q , qd ) ) { 
if ( dispose != null ) { 
dispose . dispose ( ) ; 
if ( empty ) { 
break ; 
long r = qd . requested ( ) ; 
if ( r != 0L ) { 
if ( qd . accept ( a , v ) ) { 
if ( r != Long . MAX_VALUE ) { 
qd . produced ( 1 ) ; 
q . clear ( ) ; 
missed = qd . leave ( - missed ) ; 
if ( missed == 0 ) { 
} public static < T > SimpleQueue < T > createQueue ( int capacityHint ) { 
if ( capacityHint < 0 ) { 
return new SpscLinkedArrayQueue < T > ( - capacityHint ) ; 
return new SpscArrayQueue < T > ( capacityHint ) ; 
} public static void request ( Subscription s , int prefetch ) { 
s . request ( prefetch < 0 ? Long . MAX_VALUE : prefetch ) ; 
} public static < T > boolean postCompleteRequest ( long n , 
Subscriber < ? super T > actual , 
Queue < T > queue , 
AtomicLong state , 
BooleanSupplier isCancelled ) { 
long r = state . get ( ) ; 
long r0 = r & REQUESTED_MASK ; 
long u = ( r & COMPLETED_MASK ) | BackpressureHelper . addCap ( r0 , n ) ; 
if ( state . compareAndSet ( r , u ) ) { 
if ( r == COMPLETED_MASK ) { 
postCompleteDrain ( n | COMPLETED_MASK , actual , queue , state , isCancelled ) ; 
} static < T > boolean postCompleteDrain ( long n , 
long e = n & COMPLETED_MASK ; 
while ( e != n ) { 
if ( isCancelled ( isCancelled ) ) { 
T t = queue . poll ( ) ; 
actual . onComplete ( ) ; 
actual . onNext ( t ) ; 
e ++ ; 
if ( queue . isEmpty ( ) ) { 
n = state . get ( ) ; 
if ( n == e ) { 
n = state . addAndGet ( - ( e & REQUESTED_MASK ) ) ; 
if ( ( n & REQUESTED_MASK ) == 0L ) { 
e = n & COMPLETED_MASK ; 
} public static < T > void postComplete ( Subscriber < ? super T > actual , 
if ( postCompleteDrain ( state . get ( ) , actual , queue , state , isCancelled ) ) { 
if ( ( r & COMPLETED_MASK ) != 0L ) { 
long u = r | COMPLETED_MASK ; 
postCompleteDrain ( u , actual , queue , state , isCancelled ) ; 
public static < T > ReplaySubject < T > create ( ) { 
return new ReplaySubject < T > ( new UnboundedReplayBuffer < T > ( 16 ) ) ; 
public static < T > ReplaySubject < T > createWithSize ( int maxSize ) { 
return new ReplaySubject < T > ( new SizeBoundReplayBuffer < T > ( maxSize ) ) ; 
} static < T > ReplaySubject < T > createUnbounded ( ) { 
return new ReplaySubject < T > ( new SizeBoundReplayBuffer < T > ( Integer . MAX_VALUE ) ) ; 
} protected final void complete ( R n ) { 
long p = produced ; 
if ( p != 0 ) { 
BackpressureHelper . produced ( this , p ) ; 
long r = get ( ) ; 
if ( ( r & COMPLETE_MASK ) != 0 ) { 
onDrop ( n ) ; 
if ( ( r & REQUEST_MASK ) != 0 ) { 
lazySet ( COMPLETE_MASK + 1 ) ; 
downstream . onNext ( n ) ; 
downstream . onComplete ( ) ; 
value = n ; 
if ( compareAndSet ( 0 , COMPLETE_MASK ) ) { 
value = null ; 
T v = getValue ( ) ; 
return v != null ? new Object [ ] { v } : new Object [ 0 ] ; 
if ( array . length == 0 ) { 
array = Arrays . copyOf ( array , 1 ) ; 
@ Nullable 
Object o = value ; 
if ( o != null && ! NotificationLite . isError ( o ) ) { 
return ( T ) value ; 
public Throwable getError ( ) { 
if ( NotificationLite . isError ( o ) ) { 
return NotificationLite . getError ( o ) ; 
public static < T > Notification < T > createOnNext ( @ NonNull T value ) { 
return new Notification < T > ( value ) ; 
public static < T > Notification < T > createOnError ( @ NonNull Throwable error ) { 
return new Notification < T > ( NotificationLite . error ( error ) ) ; 
} public static boolean validate ( Disposable upstream , Disposable next , Class < ? > observer ) { 
if ( upstream != null ) { 
next . dispose ( ) ; 
if ( upstream != DisposableHelper . DISPOSED ) { 
reportDoubleSubscription ( observer ) ; 
} public static boolean setOnce ( AtomicReference < Disposable > upstream , Disposable next , Class < ? > observer ) { 
if ( ! upstream . compareAndSet ( null , next ) ) { 
if ( upstream . get ( ) != DisposableHelper . DISPOSED ) { 
} public static boolean validate ( Subscription upstream , Subscription next , Class < ? > subscriber ) { 
next . cancel ( ) ; 
if ( upstream != SubscriptionHelper . CANCELLED ) { 
reportDoubleSubscription ( subscriber ) ; 
} public static boolean setOnce ( AtomicReference < Subscription > upstream , Subscription next , Class < ? > subscriber ) { 
if ( upstream . get ( ) != SubscriptionHelper . CANCELLED ) { 
} void add ( CacheSubscription < T > consumer ) { 
CacheSubscription < T > [ ] current = subscribers . get ( ) ; 
if ( current == TERMINATED ) { 
int n = current . length ; 
CacheSubscription < T > [ ] next = new CacheSubscription [ n + 1 ] ; 
System . arraycopy ( current , 0 , next , 0 , n ) ; 
next [ n ] = consumer ; 
if ( subscribers . compareAndSet ( current , next ) ) { 
void remove ( CacheSubscription < T > consumer ) { 
if ( n == 0 ) { 
int j = - 1 ; 
for ( int i = 0 ; i < n ; i ++ ) { 
if ( current [ i ] == consumer ) { 
j = i ; 
if ( j < 0 ) { 
CacheSubscription < T > [ ] next ; 
if ( n == 1 ) { 
next = EMPTY ; 
next = new CacheSubscription [ n - 1 ] ; 
System . arraycopy ( current , 0 , next , 0 , j ) ; 
System . arraycopy ( current , j + 1 , next , j , n - j - 1 ) ; 
} void replay ( CacheSubscription < T > consumer ) { 
if ( consumer . getAndIncrement ( ) != 0 ) { 
long index = consumer . index ; 
int offset = consumer . offset ; 
Node < T > node = consumer . node ; 
AtomicLong requested = consumer . requested ; 
Subscriber < ? super T > downstream = consumer . downstream ; 
int capacity = capacityHint ; 
boolean sourceDone = done ; 
boolean empty = size == index ; 
if ( sourceDone && empty ) { 
consumer . node = null ; 
downstream . onError ( ex ) ; 
if ( ! empty ) { 
long consumerRequested = requested . get ( ) ; 
if ( consumerRequested == Long . MIN_VALUE ) { 
if ( consumerRequested != index ) { 
if ( offset == capacity ) { 
node = node . next ; 
offset = 0 ; 
downstream . onNext ( node . values [ offset ] ) ; 
offset ++ ; 
index ++ ; 
continue ; 
consumer . index = index ; 
consumer . offset = offset ; 
consumer . node = node ; 
missed = consumer . addAndGet ( - missed ) ; 
} public static long addCap ( long a , long b ) { 
long u = a + b ; 
if ( u < 0L ) { 
return Long . MAX_VALUE ; 
return u ; 
} public static long multiplyCap ( long a , long b ) { 
long u = a * b ; 
if ( ( ( a | b ) > > > 31 ) != 0 ) { 
if ( u / a != b ) { 
} public static long add ( AtomicLong requested , long n ) { 
long r = requested . get ( ) ; 
if ( r == Long . MAX_VALUE ) { 
long u = addCap ( r , n ) ; 
if ( requested . compareAndSet ( r , u ) ) { 
return r ; 
} public static long addCancel ( AtomicLong requested , long n ) { 
if ( r == Long . MIN_VALUE ) { 
return Long . MIN_VALUE ; 
} public static long produced ( AtomicLong requested , long n ) { 
long current = requested . get ( ) ; 
if ( current == Long . MAX_VALUE ) { 
long update = current - n ; 
if ( update < 0L ) { 
update = 0L ; 
if ( requested . compareAndSet ( current , update ) ) { 
return update ; 
} public static < T > void subscribe ( ObservableSource < ? extends T > o , Observer < ? super T > observer ) { 
final BlockingQueue < Object > queue = new LinkedBlockingQueue < Object > ( ) ; 
BlockingObserver < T > bs = new BlockingObserver < T > ( queue ) ; 
observer . onSubscribe ( bs ) ; 
o . subscribe ( bs ) ; 
if ( bs . isDisposed ( ) ) { 
Object v = queue . poll ( ) ; 
v = queue . take ( ) ; 
bs . dispose ( ) ; 
if ( bs . isDisposed ( ) 
|| o == BlockingObserver . TERMINATED 
|| NotificationLite . acceptFull ( v , observer ) ) { 
} public static < T > void subscribe ( ObservableSource < ? extends T > o ) { 
BlockingIgnoringReceiver callback = new BlockingIgnoringReceiver ( ) ; 
LambdaObserver < T > ls = new LambdaObserver < T > ( Functions . emptyConsumer ( ) , 
callback , callback , Functions . emptyConsumer ( ) ) ; 
o . subscribe ( ls ) ; 
BlockingHelper . awaitForComplete ( callback , ls ) ; 
Throwable e = callback . error ; 
} public static < T > void subscribe ( ObservableSource < ? extends T > o , final Consumer < ? super T > onNext , 
final Consumer < ? super Throwable > onError , final Action onComplete ) { 
subscribe ( o , new LambdaObserver < T > ( onNext , onError , onComplete , Functions . emptyConsumer ( ) ) ) ; 
public static Completable concatArray ( CompletableSource ... sources ) { 
return complete ( ) ; 
return wrap ( sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new CompletableConcatArray ( sources ) ) ; 
public static Completable concat ( Iterable < ? extends CompletableSource > sources ) { 
return RxJavaPlugins . onAssembly ( new CompletableConcatIterable ( sources ) ) ; 
public static Completable concat ( Publisher < ? extends CompletableSource > sources ) { 
public static Completable concat ( Publisher < ? extends CompletableSource > sources , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new CompletableConcat ( sources , prefetch ) ) ; 
public static Completable create ( CompletableOnSubscribe source ) { 
return RxJavaPlugins . onAssembly ( new CompletableCreate ( source ) ) ; 
public static Completable error ( final Throwable error ) { 
return RxJavaPlugins . onAssembly ( new CompletableError ( error ) ) ; 
public static Completable fromAction ( final Action run ) { 
return RxJavaPlugins . onAssembly ( new CompletableFromAction ( run ) ) ; 
public static Completable fromCallable ( final Callable < ? > callable ) { 
return RxJavaPlugins . onAssembly ( new CompletableFromCallable ( callable ) ) ; 
public static Completable fromFuture ( final Future < ? > future ) { 
return fromAction ( Functions . futureAction ( future ) ) ; 
public static < T > Completable fromMaybe ( final MaybeSource < T > maybe ) { 
return RxJavaPlugins . onAssembly ( new MaybeIgnoreElementCompletable < T > ( maybe ) ) ; 
public static Completable fromRunnable ( final Runnable run ) { 
return RxJavaPlugins . onAssembly ( new CompletableFromRunnable ( run ) ) ; 
public static < T > Completable fromSingle ( final SingleSource < T > single ) { 
return RxJavaPlugins . onAssembly ( new CompletableFromSingle < T > ( single ) ) ; 
public static Completable mergeArray ( CompletableSource ... sources ) { 
return RxJavaPlugins . onAssembly ( new CompletableMergeArray ( sources ) ) ; 
public static Completable merge ( Iterable < ? extends CompletableSource > sources ) { 
return RxJavaPlugins . onAssembly ( new CompletableMergeIterable ( sources ) ) ; 
@ BackpressureSupport ( BackpressureKind . UNBOUNDED_IN ) 
public static Completable merge ( Publisher < ? extends CompletableSource > sources ) { 
return merge0 ( sources , Integer . MAX_VALUE , false ) ; 
public static Completable merge ( Publisher < ? extends CompletableSource > sources , int maxConcurrency ) { 
return merge0 ( sources , maxConcurrency , false ) ; 
public static Completable mergeDelayError ( Publisher < ? extends CompletableSource > sources ) { 
return merge0 ( sources , Integer . MAX_VALUE , true ) ; 
public static Completable mergeDelayError ( Publisher < ? extends CompletableSource > sources , int maxConcurrency ) { 
return merge0 ( sources , maxConcurrency , true ) ; 
public static Completable never ( ) { 
return RxJavaPlugins . onAssembly ( CompletableNever . INSTANCE ) ; 
public static Completable timer ( long delay , TimeUnit unit ) { 
} private static NullPointerException toNpe ( Throwable ex ) { 
npe . initCause ( ex ) ; 
return npe ; 
public static < R > Completable using ( Callable < R > resourceSupplier , 
Function < ? super R , ? extends CompletableSource > completableFunction , 
Consumer < ? super R > disposer ) { 
return using ( resourceSupplier , completableFunction , disposer , true ) ; 
public static Completable wrap ( CompletableSource source ) { 
if ( source instanceof Completable ) { 
return RxJavaPlugins . onAssembly ( ( Completable ) source ) ; 
return RxJavaPlugins . onAssembly ( new CompletableFromUnsafeSource ( source ) ) ; 
public final Completable ambWith ( CompletableSource other ) { 
public final < T > Observable < T > andThen ( ObservableSource < T > next ) { 
return RxJavaPlugins . onAssembly ( new CompletableAndThenObservable < T > ( this , next ) ) ; 
public final < T > Flowable < T > andThen ( Publisher < T > next ) { 
return RxJavaPlugins . onAssembly ( new CompletableAndThenPublisher < T > ( this , next ) ) ; 
public final < T > Single < T > andThen ( SingleSource < T > next ) { 
return RxJavaPlugins . onAssembly ( new SingleDelayWithCompletable < T > ( next , this ) ) ; 
public final < T > Maybe < T > andThen ( MaybeSource < T > next ) { 
return RxJavaPlugins . onAssembly ( new MaybeDelayWithCompletable < T > ( next , this ) ) ; 
public final Completable andThen ( CompletableSource next ) { 
return RxJavaPlugins . onAssembly ( new CompletableAndThenCompletable ( this , next ) ) ; 
public final < R > R as ( @ NonNull CompletableConverter < ? extends R > converter ) { 
public final void blockingAwait ( ) { 
BlockingMultiObserver < Void > observer = new BlockingMultiObserver < Void > ( ) ; 
observer . blockingGet ( ) ; 
public final Completable compose ( CompletableTransformer transformer ) { 
public final Completable concatWith ( CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new CompletableAndThenCompletable ( this , other ) ) ; 
public final Completable delay ( long delay , TimeUnit unit , Scheduler scheduler ) { 
public final Completable delay ( final long delay , final TimeUnit unit , final Scheduler scheduler , final boolean delayError ) { 
return RxJavaPlugins . onAssembly ( new CompletableDelay ( this , delay , unit , scheduler , delayError ) ) ; 
@ Experimental 
public final Completable delaySubscription ( long delay , TimeUnit unit ) { 
return delaySubscription ( delay , unit , Schedulers . computation ( ) ) ; 
public final Completable delaySubscription ( long delay , TimeUnit unit , Scheduler scheduler ) { 
return Completable . timer ( delay , unit , scheduler ) . andThen ( this ) ; 
public final Completable doOnComplete ( Action onComplete ) { 
return doOnLifecycle ( Functions . emptyConsumer ( ) , Functions . emptyConsumer ( ) , 
onComplete , Functions . EMPTY_ACTION , 
Functions . EMPTY_ACTION , Functions . EMPTY_ACTION ) ; 
public final Completable doOnDispose ( Action onDispose ) { 
Functions . EMPTY_ACTION , Functions . EMPTY_ACTION , 
Functions . EMPTY_ACTION , onDispose ) ; 
public final Completable doOnError ( Consumer < ? super Throwable > onError ) { 
return doOnLifecycle ( Functions . emptyConsumer ( ) , onError , 
private Completable doOnLifecycle ( 
final Consumer < ? super Disposable > onSubscribe , 
final Consumer < ? super Throwable > onError , 
final Action onComplete , 
final Action onTerminate , 
final Action onAfterTerminate , 
final Action onDispose ) { 
return RxJavaPlugins . onAssembly ( new CompletablePeek ( this , onSubscribe , onError , onComplete , onTerminate , onAfterTerminate , onDispose ) ) ; 
public final Completable doOnSubscribe ( Consumer < ? super Disposable > onSubscribe ) { 
return doOnLifecycle ( onSubscribe , Functions . emptyConsumer ( ) , 
public final Completable doOnTerminate ( final Action onTerminate ) { 
Functions . EMPTY_ACTION , onTerminate , 
public final Completable doAfterTerminate ( final Action onAfterTerminate ) { 
return doOnLifecycle ( 
public final Completable observeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new CompletableObserveOn ( this , scheduler ) ) ; 
public final Completable onErrorComplete ( final Predicate < ? super Throwable > predicate ) { 
return RxJavaPlugins . onAssembly ( new CompletableOnErrorComplete ( this , predicate ) ) ; 
public final Completable onErrorResumeNext ( final Function < ? super Throwable , ? extends CompletableSource > errorMapper ) { 
return RxJavaPlugins . onAssembly ( new CompletableResumeNext ( this , errorMapper ) ) ; 
public final Completable repeat ( long times ) { 
return fromPublisher ( toFlowable ( ) . repeat ( times ) ) ; 
public final Completable repeatUntil ( BooleanSupplier stop ) { 
return fromPublisher ( toFlowable ( ) . repeatUntil ( stop ) ) ; 
public final Completable repeatWhen ( Function < ? super Flowable < Object > , ? extends Publisher < ? > > handler ) { 
return fromPublisher ( toFlowable ( ) . repeatWhen ( handler ) ) ; 
public final Completable retry ( BiPredicate < ? super Integer , ? super Throwable > predicate ) { 
return fromPublisher ( toFlowable ( ) . retry ( predicate ) ) ; 
public final Completable retry ( long times ) { 
return fromPublisher ( toFlowable ( ) . retry ( times ) ) ; 
public final Completable retry ( long times , Predicate < ? super Throwable > predicate ) { 
return fromPublisher ( toFlowable ( ) . retry ( times , predicate ) ) ; 
public final Completable retryWhen ( Function < ? super Flowable < Throwable > , ? extends Publisher < ? > > handler ) { 
return fromPublisher ( toFlowable ( ) . retryWhen ( handler ) ) ; 
public final < T > Observable < T > startWith ( Observable < T > other ) { 
return other . concatWith ( this . < T > toObservable ( ) ) ; 
EmptyCompletableObserver observer = new EmptyCompletableObserver ( ) ; 
public final < E extends CompletableObserver > E subscribeWith ( E observer ) { 
public final Completable subscribeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new CompletableSubscribeOn ( this , scheduler ) ) ; 
public final Completable takeUntil ( CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new CompletableTakeUntilCompletable ( this , other ) ) ; 
public final Completable timeout ( long timeout , TimeUnit unit ) { 
return timeout0 ( timeout , unit , Schedulers . computation ( ) , null ) ; 
public final Completable timeout ( long timeout , TimeUnit unit , CompletableSource other ) { 
return timeout0 ( timeout , unit , Schedulers . computation ( ) , other ) ; 
public final Completable timeout ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
return timeout0 ( timeout , unit , scheduler , null ) ; 
public final Completable timeout ( long timeout , TimeUnit unit , Scheduler scheduler , CompletableSource other ) { 
return timeout0 ( timeout , unit , scheduler , other ) ; 
public final < U > U to ( Function < ? super Completable , U > converter ) { 
public final < T > Flowable < T > toFlowable ( ) { 
if ( this instanceof FuseToFlowable ) { 
return ( ( FuseToFlowable < T > ) this ) . fuseToFlowable ( ) ; 
return RxJavaPlugins . onAssembly ( new CompletableToFlowable < T > ( this ) ) ; 
public final < T > Maybe < T > toMaybe ( ) { 
if ( this instanceof FuseToMaybe ) { 
return ( ( FuseToMaybe < T > ) this ) . fuseToMaybe ( ) ; 
return RxJavaPlugins . onAssembly ( new MaybeFromCompletable < T > ( this ) ) ; 
} static < T > boolean tryAsCompletable ( Object source , 
Function < ? super T , ? extends CompletableSource > mapper , 
CompletableObserver observer ) { 
Callable < T > call = ( Callable < T > ) source ; 
CompletableSource cs = null ; 
T item = call . call ( ) ; 
if ( item != null ) { 
EmptyDisposable . error ( ex , observer ) ; 
if ( cs == null ) { 
EmptyDisposable . complete ( observer ) ; 
cs . subscribe ( observer ) ; 
} static < T , R > boolean tryAsMaybe ( Object source , 
Function < ? super T , ? extends MaybeSource < ? extends R > > mapper , 
Observer < ? super R > observer ) { 
MaybeSource < ? extends R > cs = null ; 
cs . subscribe ( MaybeToObservable . create ( observer ) ) ; 
} public void add ( Object o ) { 
if ( size == 0 ) { 
head = new Object [ capacityHint + 1 ] ; 
tail = head ; 
head [ 0 ] = o ; 
indexInTail = 1 ; 
size = 1 ; 
if ( indexInTail == capacityHint ) { 
Object [ ] t = new Object [ capacityHint + 1 ] ; 
t [ 0 ] = o ; 
tail [ capacityHint ] = t ; 
tail = t ; 
size ++ ; 
tail [ indexInTail ] = o ; 
indexInTail ++ ; 
} public static void shutdown ( ) { 
ScheduledExecutorService exec = PURGE_THREAD . getAndSet ( null ) ; 
if ( exec != null ) { 
exec . shutdownNow ( ) ; 
POOLS . clear ( ) ; 
} public static ScheduledExecutorService create ( ThreadFactory factory ) { 
final ScheduledExecutorService exec = Executors . newScheduledThreadPool ( 1 , factory ) ; 
tryPutIntoPool ( PURGE_ENABLED , exec ) ; 
return exec ; 
} public final void setSubscription ( Subscription s ) { 
if ( cancelled ) { 
s . cancel ( ) ; 
if ( get ( ) == 0 && compareAndSet ( 0 , 1 ) ) { 
Subscription a = actual ; 
if ( a != null && cancelOnReplace ) { 
a . cancel ( ) ; 
actual = s ; 
long r = requested ; 
if ( decrementAndGet ( ) != 0 ) { 
drainLoop ( ) ; 
s . request ( r ) ; 
Subscription a = missedSubscription . getAndSet ( s ) ; 
drain ( ) ; 
} void emitLoop ( ) { 
AppendOnlyLinkedArrayList < Object > q ; 
synchronized ( this ) { 
q = queue ; 
if ( q == null ) { 
emitting = false ; 
queue = null ; 
q . forEachWhile ( this ) ; 
protected void subscribeActual ( SingleObserver < ? super T > observer ) { 
source . subscribe ( new LastSubscriber < T > ( observer , defaultItem ) ) ; 
} public static void throwIfFatal ( @ NonNull Throwable t ) { 
if ( t instanceof VirtualMachineError ) { 
throw ( VirtualMachineError ) t ; 
} else if ( t instanceof ThreadDeath ) { 
throw ( ThreadDeath ) t ; 
} else if ( t instanceof LinkageError ) { 
throw ( LinkageError ) t ; 
} public static RuntimeException wrapOrThrow ( Throwable error ) { 
if ( error instanceof Error ) { 
throw ( Error ) error ; 
if ( error instanceof RuntimeException ) { 
return ( RuntimeException ) error ; 
return new RuntimeException ( error ) ; 
} public static List < Throwable > flatten ( Throwable t ) { 
List < Throwable > list = new ArrayList < Throwable > ( ) ; 
ArrayDeque < Throwable > deque = new ArrayDeque < Throwable > ( ) ; 
deque . offer ( t ) ; 
while ( ! deque . isEmpty ( ) ) { 
Throwable e = deque . removeFirst ( ) ; 
if ( e instanceof CompositeException ) { 
CompositeException ce = ( CompositeException ) e ; 
List < Throwable > exceptions = ce . getExceptions ( ) ; 
for ( int i = exceptions . size ( ) - 1 ; i >= 0 ; i -- ) { 
deque . offerFirst ( exceptions . get ( i ) ) ; 
list . add ( e ) ; 
return list ; 
public static < E extends Throwable > Exception throwIfThrowable ( Throwable e ) throws E { 
if ( e instanceof Exception ) { 
return ( Exception ) e ; 
throw ( E ) e ; 
} void add ( CacheDisposable < T > consumer ) { 
CacheDisposable < T > [ ] current = observers . get ( ) ; 
CacheDisposable < T > [ ] next = new CacheDisposable [ n + 1 ] ; 
if ( observers . compareAndSet ( current , next ) ) { 
void remove ( CacheDisposable < T > consumer ) { 
CacheDisposable < T > [ ] next ; 
next = new CacheDisposable [ n - 1 ] ; 
} void replay ( CacheDisposable < T > consumer ) { 
Observer < ? super T > downstream = consumer . downstream ; 
if ( consumer . disposed ) { 
} @ Benchmark 
public void oneStreamOfNthatMergesIn1 ( final InputMillion input ) throws InterruptedException { 
Flowable < Flowable < Integer > > os = Flowable . range ( 1 , input . size ) 
. map ( new Function < Integer , Flowable < Integer > > ( ) { 
public Flowable < Integer > apply ( Integer v ) { 
return Flowable . just ( v ) ; 
} ) ; 
PerfSubscriber o = input . newLatchedObserver ( ) ; 
Flowable . merge ( os ) . subscribe ( o ) ; 
if ( input . size == 1 ) { 
while ( o . latch . getCount ( ) != 0 ) { } 
o . latch . await ( ) ; 
public boolean add ( @ NonNull Disposable disposable ) { 
if ( ! disposed ) { 
OpenHashSet < Disposable > set = resources ; 
if ( set == null ) { 
set = new OpenHashSet < Disposable > ( ) ; 
resources = set ; 
set . add ( disposable ) ; 
disposable . dispose ( ) ; 
} public boolean addAll ( @ NonNull Disposable ... disposables ) { 
set = new OpenHashSet < Disposable > ( disposables . length + 1 ) ; 
for ( Disposable d : disposables ) { 
set . add ( d ) ; 
d . dispose ( ) ; 
public boolean remove ( @ NonNull Disposable disposable ) { 
if ( delete ( disposable ) ) { 
public boolean delete ( @ NonNull Disposable disposable ) { 
if ( disposed ) { 
if ( set == null || ! set . remove ( disposable ) ) { 
} public void clear ( ) { 
OpenHashSet < Disposable > set ; 
set = resources ; 
resources = null ; 
dispose ( set ) ; 
} public int size ( ) { 
return 0 ; 
return set != null ? set . size ( ) : 0 ; 
} public static < T > void subscribe ( Publisher < ? extends T > o , Subscriber < ? super T > subscriber ) { 
BlockingSubscriber < T > bs = new BlockingSubscriber < T > ( queue ) ; 
if ( bs . isCancelled ( ) ) { 
if ( v == BlockingSubscriber . TERMINATED 
|| NotificationLite . acceptFull ( v , subscriber ) ) { 
} catch ( InterruptedException e ) { 
bs . cancel ( ) ; 
subscriber . onError ( e ) ; 
} public static < T > void subscribe ( Publisher < ? extends T > o ) { 
LambdaSubscriber < T > ls = new LambdaSubscriber < T > ( Functions . emptyConsumer ( ) , 
callback , callback , Functions . REQUEST_MAX ) ; 
} public static < T > void subscribe ( Publisher < ? extends T > o , final Consumer < ? super T > onNext , 
subscribe ( o , new LambdaSubscriber < T > ( onNext , onError , onComplete , Functions . REQUEST_MAX ) ) ; 
final Consumer < ? super Throwable > onError , final Action onComplete , int bufferSize ) { 
subscribe ( o , new BoundedSubscriber < T > ( onNext , onError , onComplete , Functions . boundedConsumer ( bufferSize ) , 
bufferSize ) ) ; 
} public final void add ( @ NonNull Disposable resource ) { 
resources . add ( resource ) ; 
public static < T , R > boolean tryScalarXMapSubscribe ( ObservableSource < T > source , 
Observer < ? super R > observer , 
Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
ObservableSource < ? extends R > r ; 
ScalarDisposable < R > sd = new ScalarDisposable < R > ( observer , u ) ; 
observer . onSubscribe ( sd ) ; 
sd . run ( ) ; 
r . subscribe ( observer ) ; 
} public static < T , U > Observable < U > scalarXMap ( T value , 
Function < ? super T , ? extends ObservableSource < ? extends U > > mapper ) { 
return RxJavaPlugins . onAssembly ( new ScalarXMapObservable < T , U > ( value , mapper ) ) ; 
} public static < T > MaybeObserver < T > create ( Observer < ? super T > downstream ) { 
return new MaybeToObservableObserver < T > ( downstream ) ; 
public static Scheduler from ( @ NonNull Executor executor , boolean interruptibleWorker ) { 
return new ExecutorScheduler ( executor , interruptibleWorker ) ; 
computation ( ) . shutdown ( ) ; 
io ( ) . shutdown ( ) ; 
newThread ( ) . shutdown ( ) ; 
single ( ) . shutdown ( ) ; 
trampoline ( ) . shutdown ( ) ; 
SchedulerPoolFactory . shutdown ( ) ; 
} public void add ( T value ) { 
final int c = capacity ; 
int o = offset ; 
if ( o == c ) { 
Object [ ] next = new Object [ c + 1 ] ; 
tail [ c ] = next ; 
tail = next ; 
o = 0 ; 
tail [ o ] = value ; 
offset = o + 1 ; 
public void forEachWhile ( NonThrowingPredicate < ? super T > consumer ) { 
Object [ ] a = head ; 
while ( a != null ) { 
for ( int i = 0 ; i < c ; i ++ ) { 
Object o = a [ i ] ; 
if ( o == null ) { 
if ( consumer . test ( ( T ) o ) ) { 
a = ( Object [ ] ) a [ c ] ; 
} public < U > boolean accept ( Subscriber < ? super U > subscriber ) { 
if ( NotificationLite . acceptFull ( o , subscriber ) ) { 
} public < U > boolean accept ( Observer < ? super U > observer ) { 
if ( NotificationLite . acceptFull ( o , observer ) ) { 
public < S > void forEachWhile ( S state , BiPredicate < ? super S , ? super T > consumer ) throws Exception { 
if ( consumer . test ( state , ( T ) o ) ) { 
public static < T > Single < T > amb ( final Iterable < ? extends SingleSource < ? extends T > > sources ) { 
return RxJavaPlugins . onAssembly ( new SingleAmb < T > ( null , sources ) ) ; 
public static < T > Single < T > ambArray ( final SingleSource < ? extends T > ... sources ) { 
return error ( SingleInternalHelper . < T > emptyThrower ( ) ) ; 
return wrap ( ( SingleSource < T > ) sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new SingleAmb < T > ( sources , null ) ) ; 
public static < T > Flowable < T > concatArray ( SingleSource < ? extends T > ... sources ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatMap ( Flowable . fromArray ( sources ) , SingleInternalHelper . toFlowable ( ) , 2 , ErrorMode . BOUNDARY ) ) ; 
public static < T > Single < T > defer ( final Callable < ? extends SingleSource < ? extends T > > singleSupplier ) { 
return RxJavaPlugins . onAssembly ( new SingleDefer < T > ( singleSupplier ) ) ; 
public static < T > Single < T > error ( final Callable < ? extends Throwable > errorSupplier ) { 
return RxJavaPlugins . onAssembly ( new SingleError < T > ( errorSupplier ) ) ; 
public static < T > Single < T > fromCallable ( final Callable < ? extends T > callable ) { 
return RxJavaPlugins . onAssembly ( new SingleFromCallable < T > ( callable ) ) ; 
public static < T > Single < T > fromFuture ( Future < ? extends T > future ) { 
return toSingle ( Flowable . < T > fromFuture ( future ) ) ; 
public static < T > Single < T > fromFuture ( Future < ? extends T > future , long timeout , TimeUnit unit ) { 
return toSingle ( Flowable . < T > fromFuture ( future , timeout , unit ) ) ; 
public static < T > Single < T > fromFuture ( Future < ? extends T > future , long timeout , TimeUnit unit , Scheduler scheduler ) { 
return toSingle ( Flowable . < T > fromFuture ( future , timeout , unit , scheduler ) ) ; 
public static < T > Single < T > merge ( SingleSource < ? extends SingleSource < ? extends T > > source ) { 
return RxJavaPlugins . onAssembly ( new SingleFlatMap < SingleSource < ? extends T > , T > ( source , ( Function ) Functions . identity ( ) ) ) ; 
public static < T > Flowable < T > mergeDelayError ( Publisher < ? extends SingleSource < ? extends T > > sources ) { 
return RxJavaPlugins . onAssembly ( new FlowableFlatMapPublisher ( sources , SingleInternalHelper . toFlowable ( ) , true , Integer . MAX_VALUE , Flowable . bufferSize ( ) ) ) ; 
public static < T > Single < T > never ( ) { 
return RxJavaPlugins . onAssembly ( ( Single < T > ) SingleNever . INSTANCE ) ; 
public static Single < Long > timer ( final long delay , final TimeUnit unit , final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new SingleTimer ( delay , unit , scheduler ) ) ; 
public static < T > Single < T > unsafeCreate ( SingleSource < T > onSubscribe ) { 
if ( onSubscribe instanceof Single ) { 
return RxJavaPlugins . onAssembly ( new SingleFromUnsafeSource < T > ( onSubscribe ) ) ; 
public static < T , U > Single < T > using ( Callable < U > resourceSupplier , 
Function < ? super U , ? extends SingleSource < ? extends T > > singleFunction , 
Consumer < ? super U > disposer ) { 
return using ( resourceSupplier , singleFunction , disposer , true ) ; 
public final < R > R as ( @ NonNull SingleConverter < T , ? extends R > converter ) { 
public final Single < T > hide ( ) { 
return RxJavaPlugins . onAssembly ( new SingleHide < T > ( this ) ) ; 
public final < R > Single < R > compose ( SingleTransformer < ? super T , ? extends R > transformer ) { 
public final Single < T > cache ( ) { 
return RxJavaPlugins . onAssembly ( new SingleCache < T > ( this ) ) ; 
public final Flowable < T > concatWith ( SingleSource < ? extends T > other ) { 
public final Single < T > delay ( long time , TimeUnit unit ) { 
return delay ( time , unit , Schedulers . computation ( ) , false ) ; 
public final Single < T > delay ( final long time , final TimeUnit unit , final Scheduler scheduler ) { 
return delay ( time , unit , scheduler , false ) ; 
public final Single < T > delay ( final long time , final TimeUnit unit , final Scheduler scheduler , boolean delayError ) { 
return RxJavaPlugins . onAssembly ( new SingleDelay < T > ( this , time , unit , scheduler , delayError ) ) ; 
public final Single < T > delaySubscription ( CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new SingleDelayWithCompletable < T > ( this , other ) ) ; 
public final Single < T > delaySubscription ( long time , TimeUnit unit ) { 
return delaySubscription ( time , unit , Schedulers . computation ( ) ) ; 
public final Single < T > delaySubscription ( long time , TimeUnit unit , Scheduler scheduler ) { 
return delaySubscription ( Observable . timer ( time , unit , scheduler ) ) ; 
public final < R > Maybe < R > dematerialize ( Function < ? super T , Notification < R > > selector ) { 
return RxJavaPlugins . onAssembly ( new SingleDematerialize < T , R > ( this , selector ) ) ; 
public final Single < T > doAfterSuccess ( Consumer < ? super T > onAfterSuccess ) { 
return RxJavaPlugins . onAssembly ( new SingleDoAfterSuccess < T > ( this , onAfterSuccess ) ) ; 
public final Single < T > doAfterTerminate ( Action onAfterTerminate ) { 
return RxJavaPlugins . onAssembly ( new SingleDoAfterTerminate < T > ( this , onAfterTerminate ) ) ; 
public final Single < T > doFinally ( Action onFinally ) { 
return RxJavaPlugins . onAssembly ( new SingleDoFinally < T > ( this , onFinally ) ) ; 
public final Single < T > doOnSubscribe ( final Consumer < ? super Disposable > onSubscribe ) { 
return RxJavaPlugins . onAssembly ( new SingleDoOnSubscribe < T > ( this , onSubscribe ) ) ; 
public final Single < T > doOnTerminate ( final Action onTerminate ) { 
return RxJavaPlugins . onAssembly ( new SingleDoOnTerminate < T > ( this , onTerminate ) ) ; 
public final Single < T > doOnSuccess ( final Consumer < ? super T > onSuccess ) { 
return RxJavaPlugins . onAssembly ( new SingleDoOnSuccess < T > ( this , onSuccess ) ) ; 
public final Single < T > doOnError ( final Consumer < ? super Throwable > onError ) { 
return RxJavaPlugins . onAssembly ( new SingleDoOnError < T > ( this , onError ) ) ; 
public final Single < T > doOnDispose ( final Action onDispose ) { 
return RxJavaPlugins . onAssembly ( new SingleDoOnDispose < T > ( this , onDispose ) ) ; 
public final < R > Single < R > flatMap ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new SingleFlatMap < T , R > ( this , mapper ) ) ; 
public final < R > Maybe < R > flatMapMaybe ( final Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new SingleFlatMapMaybe < T , R > ( this , mapper ) ) ; 
public final < R > Observable < R > flatMapObservable ( Function < ? super T , ? extends ObservableSource < ? extends R > > mapper ) { 
return RxJavaPlugins . onAssembly ( new SingleFlatMapObservable < T , R > ( this , mapper ) ) ; 
public final < R > Single < R > lift ( final SingleOperator < ? extends R , ? super T > lift ) { 
return RxJavaPlugins . onAssembly ( new SingleLift < T , R > ( this , lift ) ) ; 
public final < R > Single < R > map ( Function < ? super T , ? extends R > mapper ) { 
return RxJavaPlugins . onAssembly ( new SingleMap < T , R > ( this , mapper ) ) ; 
public final Single < Notification < T > > materialize ( ) { 
return RxJavaPlugins . onAssembly ( new SingleMaterialize < T > ( this ) ) ; 
public final Single < Boolean > contains ( Object value ) { 
return contains ( value , ObjectHelper . equalsPredicate ( ) ) ; 
public final Flowable < T > mergeWith ( SingleSource < ? extends T > other ) { 
public final Single < T > observeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new SingleObserveOn < T > ( this , scheduler ) ) ; 
public final Single < T > onErrorReturn ( final Function < Throwable , ? extends T > resumeFunction ) { 
return RxJavaPlugins . onAssembly ( new SingleOnErrorReturn < T > ( this , resumeFunction , null ) ) ; 
public final Single < T > onTerminateDetach ( ) { 
return RxJavaPlugins . onAssembly ( new SingleDetach < T > ( this ) ) ; 
public final Flowable < T > repeat ( ) { 
return toFlowable ( ) . repeat ( ) ; 
public final Single < T > retry ( ) { 
return toSingle ( toFlowable ( ) . retry ( ) ) ; 
public final Single < T > retry ( BiPredicate < ? super Integer , ? super Throwable > predicate ) { 
return toSingle ( toFlowable ( ) . retry ( predicate ) ) ; 
public final Single < T > retry ( long times , Predicate < ? super Throwable > predicate ) { 
return toSingle ( toFlowable ( ) . retry ( times , predicate ) ) ; 
public final Single < T > retryWhen ( Function < ? super Flowable < Throwable > , ? extends Publisher < ? > > handler ) { 
return toSingle ( toFlowable ( ) . retryWhen ( handler ) ) ; 
public final Disposable subscribe ( Consumer < ? super T > onSuccess ) { 
return subscribe ( onSuccess , Functions . ON_ERROR_MISSING ) ; 
public final Disposable subscribe ( final Consumer < ? super T > onSuccess , final Consumer < ? super Throwable > onError ) { 
ConsumerSingleObserver < T > observer = new ConsumerSingleObserver < T > ( onSuccess , onError ) ; 
public final < E extends SingleObserver < ? super T > > E subscribeWith ( E observer ) { 
public final Single < T > subscribeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new SingleSubscribeOn < T > ( this , scheduler ) ) ; 
public final Single < T > takeUntil ( final CompletableSource other ) { 
return takeUntil ( new CompletableToFlowable < T > ( other ) ) ; 
public final Single < T > timeout ( long timeout , TimeUnit unit ) { 
public final Single < T > timeout ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
public final Completable toCompletable ( ) { 
return RxJavaPlugins . onAssembly ( new CompletableFromSingle < T > ( this ) ) ; 
return subscribeWith ( new FutureSingleObserver < T > ( ) ) ; 
public final Single < T > unsubscribeOn ( final Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new SingleUnsubscribeOn < T > ( this , scheduler ) ) ; 
public final < U , R > Single < R > zipWith ( SingleSource < U > other , BiFunction < ? super T , ? super U , ? extends R > zipper ) { 
public static < T > MulticastProcessor < T > create ( ) { 
return new MulticastProcessor < T > ( bufferSize ( ) , false ) ; 
public static < T > MulticastProcessor < T > create ( boolean refCount ) { 
return new MulticastProcessor < T > ( bufferSize ( ) , refCount ) ; 
} public void start ( ) { 
if ( SubscriptionHelper . setOnce ( upstream , EmptySubscription . INSTANCE ) ) { 
queue = new SpscArrayQueue < T > ( bufferSize ) ; 
} public void startUnbounded ( ) { 
queue = new SpscLinkedArrayQueue < T > ( bufferSize ) ; 
if ( once . get ( ) ) { 
if ( fusionMode == QueueSubscription . NONE ) { 
if ( queue . offer ( t ) ) { 
public boolean offer ( final T e ) { 
if ( null == e ) { 
final AtomicReferenceArray < Object > buffer = producerBuffer ; 
final long index = lpProducerIndex ( ) ; 
final int mask = producerMask ; 
final int offset = calcWrappedOffset ( index , mask ) ; 
if ( index < producerLookAhead ) { 
return writeToQueue ( buffer , e , index , offset ) ; 
final int lookAheadStep = producerLookAheadStep ; 
int lookAheadElementOffset = calcWrappedOffset ( index + lookAheadStep , mask ) ; 
if ( null == lvElement ( buffer , lookAheadElementOffset ) ) { 
producerLookAhead = index + lookAheadStep - 1 ; 
} else if ( null == lvElement ( buffer , calcWrappedOffset ( index + 1 , mask ) ) ) { 
resize ( buffer , index , offset , e , mask ) ; 
public T poll ( ) { 
final AtomicReferenceArray < Object > buffer = consumerBuffer ; 
final long index = lpConsumerIndex ( ) ; 
final int mask = consumerMask ; 
final Object e = lvElement ( buffer , offset ) ; 
boolean isNextBuffer = e == HAS_NEXT ; 
if ( null != e && ! isNextBuffer ) { 
soElement ( buffer , offset , null ) ; 
soConsumerIndex ( index + 1 ) ; 
return ( T ) e ; 
} else if ( isNextBuffer ) { 
return newBufferPoll ( lvNextBufferAndUnlink ( buffer , mask + 1 ) , index , mask ) ; 
public boolean offer ( T first , T second ) { 
final long p = lvProducerIndex ( ) ; 
final int m = producerMask ; 
int pi = calcWrappedOffset ( p + 2 , m ) ; 
if ( null == lvElement ( buffer , pi ) ) { 
pi = calcWrappedOffset ( p , m ) ; 
soElement ( buffer , pi + 1 , second ) ; 
soElement ( buffer , pi , first ) ; 
soProducerIndex ( p + 2 ) ; 
final int capacity = buffer . length ( ) ; 
final AtomicReferenceArray < Object > newBuffer = new AtomicReferenceArray < Object > ( capacity ) ; 
producerBuffer = newBuffer ; 
soElement ( newBuffer , pi + 1 , second ) ; 
soElement ( newBuffer , pi , first ) ; 
soNext ( buffer , newBuffer ) ; 
soElement ( buffer , pi , HAS_NEXT ) ; 
public Disposable get ( ) { 
Disposable d = resource . get ( ) ; 
if ( d == DisposableHelper . DISPOSED ) { 
return Disposables . disposed ( ) ; 
return d ; 
} public static < T > ConnectableObservable < T > create ( ObservableSource < T > source ) { 
final AtomicReference < PublishObserver < T > > curr = new AtomicReference < PublishObserver < T > > ( ) ; 
ObservableSource < T > onSubscribe = new PublishSource < T > ( curr ) ; 
return RxJavaPlugins . onAssembly ( new ObservablePublish < T > ( onSubscribe , source , curr ) ) ; 
} public final void complete ( T value ) { 
int state = get ( ) ; 
if ( ( state & ( FUSED_READY | FUSED_CONSUMED | TERMINATED | DISPOSED ) ) != 0 ) { 
Observer < ? super T > a = downstream ; 
if ( state == FUSED_EMPTY ) { 
this . value = value ; 
lazySet ( FUSED_READY ) ; 
a . onNext ( null ) ; 
lazySet ( TERMINATED ) ; 
a . onNext ( value ) ; 
if ( get ( ) != DISPOSED ) { 
a . onComplete ( ) ; 
} public final void error ( Throwable t ) { 
} public final void complete ( ) { 
public static < T > Flowable < T > concat ( Publisher < ? extends Publisher < ? extends T > > sources , int prefetch ) { 
return fromPublisher ( sources ) . concatMap ( ( Function ) Functions . identity ( ) , prefetch ) ; 
public static < T > Flowable < T > concatArray ( Publisher < ? extends T > ... sources ) { 
return fromPublisher ( sources [ 0 ] ) ; 
return RxJavaPlugins . onAssembly ( new FlowableConcatArray < T > ( sources , false ) ) ; 
public static < T > Flowable < T > concatArrayEager ( int maxConcurrency , int prefetch , Publisher < ? extends T > ... sources ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatMapEager ( new FlowableFromArray ( sources ) , Functions . identity ( ) , maxConcurrency , prefetch , ErrorMode . IMMEDIATE ) ) ; 
public static < T > Flowable < T > concatArrayEagerDelayError ( int maxConcurrency , int prefetch , Publisher < ? extends T > ... sources ) { 
public static < T > Flowable < T > concatDelayError ( Publisher < ? extends Publisher < ? extends T > > sources ) { 
public static < T > Flowable < T > concatDelayError ( Publisher < ? extends Publisher < ? extends T > > sources , int prefetch , boolean tillTheEnd ) { 
return fromPublisher ( sources ) . concatMapDelayError ( ( Function ) Functions . identity ( ) , prefetch , tillTheEnd ) ; 
@ BackpressureSupport ( BackpressureKind . SPECIAL ) 
public static < T > Flowable < T > create ( FlowableOnSubscribe < T > source , BackpressureStrategy mode ) { 
return RxJavaPlugins . onAssembly ( new FlowableCreate < T > ( source , mode ) ) ; 
@ BackpressureSupport ( BackpressureKind . PASS_THROUGH ) 
public static < T > Flowable < T > empty ( ) { 
return RxJavaPlugins . onAssembly ( ( Flowable < T > ) FlowableEmpty . INSTANCE ) ; 
public static < T > Flowable < T > error ( Callable < ? extends Throwable > supplier ) { 
return RxJavaPlugins . onAssembly ( new FlowableError < T > ( supplier ) ) ; 
public static < T > Flowable < T > fromIterable ( Iterable < ? extends T > source ) { 
return RxJavaPlugins . onAssembly ( new FlowableFromIterable < T > ( source ) ) ; 
public static < T , S > Flowable < T > generate ( Callable < S > initialState , BiFunction < S , Emitter < T > , S > generator ) { 
@ BackpressureSupport ( BackpressureKind . ERROR ) 
public static Flowable < Long > interval ( long initialDelay , long period , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableInterval ( Math . max ( 0L , initialDelay ) , Math . max ( 0L , period ) , unit , scheduler ) ) ; 
public static Flowable < Long > interval ( long period , TimeUnit unit ) { 
public static Flowable < Long > interval ( long period , TimeUnit unit , Scheduler scheduler ) { 
public static Flowable < Long > intervalRange ( long start , long count , long initialDelay , long period , TimeUnit unit ) { 
public static Flowable < Long > intervalRange ( long start , long count , long initialDelay , long period , TimeUnit unit , Scheduler scheduler ) { 
if ( count < 0L ) { 
return Flowable . < Long > empty ( ) . delay ( initialDelay , unit , scheduler ) ; 
return RxJavaPlugins . onAssembly ( new FlowableIntervalRange ( start , end , Math . max ( 0L , initialDelay ) , Math . max ( 0L , period ) , unit , scheduler ) ) ; 
public static < T > Flowable < T > just ( T item ) { 
return RxJavaPlugins . onAssembly ( new FlowableJust < T > ( item ) ) ; 
public static < T > Flowable < T > mergeArray ( int maxConcurrency , int bufferSize , Publisher < ? extends T > ... sources ) { 
public static < T > Flowable < T > merge ( 
Publisher < ? extends T > source1 , Publisher < ? extends T > source2 , 
Publisher < ? extends T > source3 , Publisher < ? extends T > source4 ) { 
return fromArray ( source1 , source2 , source3 , source4 ) . flatMap ( ( Function ) Functions . identity ( ) , false , 4 ) ; 
public static < T > Flowable < T > mergeDelayError ( Iterable < ? extends Publisher < ? extends T > > sources ) { 
return fromIterable ( sources ) . flatMap ( ( Function ) Functions . identity ( ) , true ) ; 
public static < T > Flowable < T > never ( ) { 
return RxJavaPlugins . onAssembly ( ( Flowable < T > ) FlowableNever . INSTANCE ) ; 
public static Flowable < Integer > range ( int start , int count ) { 
return RxJavaPlugins . onAssembly ( new FlowableRange ( start , count ) ) ; 
public static Flowable < Long > rangeLong ( long start , long count ) { 
return RxJavaPlugins . onAssembly ( new FlowableRangeLong ( start , count ) ) ; 
public static < T > Single < Boolean > sequenceEqual ( Publisher < ? extends T > source1 , Publisher < ? extends T > source2 , 
return RxJavaPlugins . onAssembly ( new FlowableSequenceEqualSingle < T > ( source1 , source2 , isEqual , bufferSize ) ) ; 
public static < T > Single < Boolean > sequenceEqual ( Publisher < ? extends T > source1 , Publisher < ? extends T > source2 , int bufferSize ) { 
public static < T > Flowable < T > switchOnNext ( Publisher < ? extends Publisher < ? extends T > > sources , int bufferSize ) { 
return fromPublisher ( sources ) . switchMap ( ( Function ) Functions . identity ( ) , bufferSize ) ; 
public static < T > Flowable < T > switchOnNextDelayError ( Publisher < ? extends Publisher < ? extends T > > sources , int prefetch ) { 
return fromPublisher ( sources ) . switchMapDelayError ( Functions . < Publisher < ? extends T > > identity ( ) , prefetch ) ; 
public static Flowable < Long > timer ( long delay , TimeUnit unit ) { 
@ BackpressureSupport ( BackpressureKind . NONE ) 
public static < T > Flowable < T > unsafeCreate ( Publisher < T > onSubscribe ) { 
if ( onSubscribe instanceof Flowable ) { 
return RxJavaPlugins . onAssembly ( new FlowableFromPublisher < T > ( onSubscribe ) ) ; 
public static < T , D > Flowable < T > using ( Callable < ? extends D > resourceSupplier , 
Function < ? super D , ? extends Publisher < ? extends T > > sourceSupplier , Consumer < ? super D > resourceDisposer ) { 
public static < T , R > Flowable < R > zip ( Iterable < ? extends Publisher < ? extends T > > sources , Function < ? super Object [ ] , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new FlowableZip < T , R > ( null , sources , zipper , bufferSize ( ) , false ) ) ; 
} @ SuppressWarnings ( { "rawtypes" , "unchecked" , "cast" } ) 
public static < T , R > Flowable < R > zip ( Publisher < ? extends Publisher < ? extends T > > sources , 
final Function < ? super Object [ ] , ? extends R > zipper ) { 
return fromPublisher ( sources ) . toList ( ) . flatMapPublisher ( ( Function ) FlowableInternalHelper . < T , R > zipIterable ( zipper ) ) ; 
public final < R > R as ( @ NonNull FlowableConverter < T , ? extends R > converter ) { 
BlockingFirstSubscriber < T > s = new BlockingFirstSubscriber < T > ( ) ; 
subscribe ( s ) ; 
T v = s . blockingGet ( ) ; 
public final Iterable < T > blockingIterable ( ) { 
return blockingIterable ( bufferSize ( ) ) ; 
return new BlockingFlowableIterable < T > ( this , bufferSize ) ; 
BlockingLastSubscriber < T > s = new BlockingLastSubscriber < T > ( ) ; 
public final Iterable < T > blockingMostRecent ( T initialItem ) { 
return new BlockingFlowableMostRecent < T > ( this , initialItem ) ; 
public final Iterable < T > blockingNext ( ) { 
return new BlockingFlowableNext < T > ( this ) ; 
return singleOrError ( ) . blockingGet ( ) ; 
return subscribeWith ( new FutureSubscriber < T > ( ) ) ; 
FlowableBlockingSubscribe . subscribe ( this , onNext , Functions . ON_ERROR_MISSING , Functions . EMPTY_ACTION ) ; 
public final void blockingSubscribe ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError , Action onComplete , 
FlowableBlockingSubscribe . subscribe ( this , onNext , onError , onComplete , bufferSize ) ; 
public final void blockingSubscribe ( Subscriber < ? super T > subscriber ) { 
FlowableBlockingSubscribe . subscribe ( this , subscriber ) ; 
public final Flowable < List < T > > buffer ( int count ) { 
public final Flowable < List < T > > buffer ( int count , int skip ) { 
public final < U extends Collection < ? super T > > Flowable < U > buffer ( int count , int skip , Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new FlowableBuffer < T , U > ( this , count , skip , bufferSupplier ) ) ; 
public final < U extends Collection < ? super T > > Flowable < U > buffer ( int count , Callable < U > bufferSupplier ) { 
public final Flowable < List < T > > buffer ( long timespan , long timeskip , TimeUnit unit ) { 
public final < U extends Collection < ? super T > > Flowable < U > buffer ( long timespan , long timeskip , TimeUnit unit , 
Scheduler scheduler , Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new FlowableBufferTimed < T , U > ( this , timespan , timeskip , unit , scheduler , bufferSupplier , Integer . MAX_VALUE , false ) ) ; 
public final Flowable < List < T > > buffer ( long timespan , TimeUnit unit ) { 
return buffer ( timespan , unit , Schedulers . computation ( ) , Integer . MAX_VALUE ) ; 
public final Flowable < List < T > > buffer ( long timespan , TimeUnit unit , Scheduler scheduler , int count ) { 
public final < U extends Collection < ? super T > > Flowable < U > buffer ( 
return RxJavaPlugins . onAssembly ( new FlowableBufferTimed < T , U > ( this , timespan , timespan , unit , scheduler , bufferSupplier , count , restartTimerOnMaxSize ) ) ; 
public final < TOpening , TClosing > Flowable < List < T > > buffer ( 
Flowable < ? extends TOpening > openingIndicator , 
Function < ? super TOpening , ? extends Publisher < ? extends TClosing > > closingIndicator ) { 
public final < TOpening , TClosing , U extends Collection < ? super T > > Flowable < U > buffer ( 
Function < ? super TOpening , ? extends Publisher < ? extends TClosing > > closingIndicator , 
return RxJavaPlugins . onAssembly ( new FlowableBufferBoundary < T , U , TOpening , TClosing > ( this , openingIndicator , closingIndicator , bufferSupplier ) ) ; 
public final < B > Flowable < List < T > > buffer ( Publisher < B > boundaryIndicator ) { 
return buffer ( boundaryIndicator , ArrayListSupplier . < T > asCallable ( ) ) ; 
public final < B > Flowable < List < T > > buffer ( Publisher < B > boundaryIndicator , final int initialCapacity ) { 
return buffer ( boundaryIndicator , Functions . < T > createArrayList ( initialCapacity ) ) ; 
public final < B , U extends Collection < ? super T > > Flowable < U > buffer ( Publisher < B > boundaryIndicator , Callable < U > bufferSupplier ) { 
return RxJavaPlugins . onAssembly ( new FlowableBufferExactBoundary < T , U , B > ( this , boundaryIndicator , bufferSupplier ) ) ; 
public final Flowable < T > cache ( ) { 
return cacheWithInitialCapacity ( 16 ) ; 
public final Flowable < T > cacheWithInitialCapacity ( int initialCapacity ) { 
return RxJavaPlugins . onAssembly ( new FlowableCache < T > ( this , initialCapacity ) ) ; 
public final < U > Single < U > collect ( Callable < ? extends U > initialItemSupplier , BiConsumer < ? super U , ? super T > collector ) { 
return RxJavaPlugins . onAssembly ( new FlowableCollectSingle < T , U > ( this , initialItemSupplier , collector ) ) ; 
public final < R > Flowable < R > compose ( FlowableTransformer < ? super T , ? extends R > composer ) { 
public final Completable concatMapCompletableDelayError ( Function < ? super T , ? extends CompletableSource > mapper , boolean tillTheEnd ) { 
return concatMapCompletableDelayError ( mapper , tillTheEnd , 2 ) ; 
return RxJavaPlugins . onAssembly ( new FlowableConcatMapCompletable < T > ( this , mapper , tillTheEnd ? ErrorMode . END : ErrorMode . BOUNDARY , prefetch ) ) ; 
public final < R > Flowable < R > concatMapDelayError ( Function < ? super T , ? extends Publisher < ? extends R > > mapper ) { 
return concatMapDelayError ( mapper , 2 , true ) ; 
public final < R > Flowable < R > concatMapEager ( Function < ? super T , ? extends Publisher < ? extends R > > mapper , 
return RxJavaPlugins . onAssembly ( new FlowableConcatMapEager < T , R > ( this , mapper , maxConcurrency , prefetch , ErrorMode . IMMEDIATE ) ) ; 
public final < U > Flowable < U > concatMapIterable ( Function < ? super T , ? extends Iterable < ? extends U > > mapper ) { 
return concatMapIterable ( mapper , 2 ) ; 
public final < R > Flowable < R > concatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
public final < R > Flowable < R > concatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , int prefetch ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatMapSingle < T , R > ( this , mapper , ErrorMode . IMMEDIATE , prefetch ) ) ; 
public final < R > Flowable < R > concatMapSingleDelayError ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return concatMapSingleDelayError ( mapper , true , 2 ) ; 
public final Flowable < T > concatWith ( @ NonNull SingleSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatWithSingle < T > ( this , other ) ) ; 
public final Flowable < T > concatWith ( @ NonNull MaybeSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatWithMaybe < T > ( this , other ) ) ; 
public final Flowable < T > concatWith ( @ NonNull CompletableSource other ) { 
return RxJavaPlugins . onAssembly ( new FlowableConcatWithCompletable < T > ( this , other ) ) ; 
return any ( Functions . equalsWith ( item ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableCountSingle < T > ( this ) ) ; 
public final < U > Flowable < T > debounce ( Function < ? super T , ? extends Publisher < U > > debounceIndicator ) { 
return RxJavaPlugins . onAssembly ( new FlowableDebounce < T , U > ( this , debounceIndicator ) ) ; 
public final Flowable < T > debounce ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableDebounceTimed < T > ( this , timeout , unit , scheduler ) ) ; 
public final Flowable < T > delay ( long delay , TimeUnit unit , boolean delayError ) { 
return delay ( delay , unit , Schedulers . computation ( ) , delayError ) ; 
public final Flowable < T > delay ( long delay , TimeUnit unit , Scheduler scheduler ) { 
public final < U , V > Flowable < T > delay ( Publisher < U > subscriptionIndicator , 
Function < ? super T , ? extends Publisher < V > > itemDelayIndicator ) { 
return delaySubscription ( subscriptionIndicator ) . delay ( itemDelayIndicator ) ; 
public final < T2 > Flowable < T2 > dematerialize ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableDematerialize ( this , Functions . identity ( ) ) ) ; 
public final < R > Flowable < R > dematerialize ( Function < ? super T , Notification < R > > selector ) { 
return RxJavaPlugins . onAssembly ( new FlowableDematerialize < T , R > ( this , selector ) ) ; 
public final Flowable < T > distinct ( ) { 
return distinct ( ( Function ) Functions . identity ( ) , Functions . < T > createHashSet ( ) ) ; 
public final < K > Flowable < T > distinct ( Function < ? super T , K > keySelector ) { 
return distinct ( keySelector , Functions . < K > createHashSet ( ) ) ; 
public final < K > Flowable < T > distinct ( Function < ? super T , K > keySelector , 
Callable < ? extends Collection < ? super K > > collectionSupplier ) { 
return RxJavaPlugins . onAssembly ( new FlowableDistinct < T , K > ( this , keySelector , collectionSupplier ) ) ; 
public final Flowable < T > distinctUntilChanged ( ) { 
public final < K > Flowable < T > distinctUntilChanged ( Function < ? super T , K > keySelector ) { 
return RxJavaPlugins . onAssembly ( new FlowableDistinctUntilChanged < T , K > ( this , keySelector , ObjectHelper . equalsPredicate ( ) ) ) ; 
public final Flowable < T > distinctUntilChanged ( BiPredicate < ? super T , ? super T > comparer ) { 
return RxJavaPlugins . onAssembly ( new FlowableDistinctUntilChanged < T , T > ( this , Functions . < T > identity ( ) , comparer ) ) ; 
public final Flowable < T > doFinally ( Action onFinally ) { 
return RxJavaPlugins . onAssembly ( new FlowableDoFinally < T > ( this , onFinally ) ) ; 
public final Flowable < T > doAfterNext ( Consumer < ? super T > onAfterNext ) { 
return RxJavaPlugins . onAssembly ( new FlowableDoAfterNext < T > ( this , onAfterNext ) ) ; 
public final Flowable < T > doAfterTerminate ( Action onAfterTerminate ) { 
return doOnEach ( Functions . emptyConsumer ( ) , Functions . emptyConsumer ( ) , 
Functions . EMPTY_ACTION , onAfterTerminate ) ; 
public final Flowable < T > doOnCancel ( Action onCancel ) { 
return doOnLifecycle ( Functions . emptyConsumer ( ) , Functions . EMPTY_LONG_CONSUMER , onCancel ) ; 
public final Flowable < T > doOnComplete ( Action onComplete ) { 
onComplete , Functions . EMPTY_ACTION ) ; 
private Flowable < T > doOnEach ( Consumer < ? super T > onNext , Consumer < ? super Throwable > onError , 
Action onComplete , Action onAfterTerminate ) { 
return RxJavaPlugins . onAssembly ( new FlowableDoOnEach < T > ( this , onNext , onError , onComplete , onAfterTerminate ) ) ; 
public final Flowable < T > doOnEach ( final Consumer < ? super Notification < T > > onNotification ) { 
public final Flowable < T > doOnEach ( final Subscriber < ? super T > subscriber ) { 
FlowableInternalHelper . subscriberOnNext ( subscriber ) , 
FlowableInternalHelper . subscriberOnError ( subscriber ) , 
FlowableInternalHelper . subscriberOnComplete ( subscriber ) , 
public final Flowable < T > doOnError ( Consumer < ? super Throwable > onError ) { 
return doOnEach ( Functions . emptyConsumer ( ) , onError , 
public final Flowable < T > doOnNext ( Consumer < ? super T > onNext ) { 
return doOnEach ( onNext , Functions . emptyConsumer ( ) , 
public final Flowable < T > doOnRequest ( LongConsumer onRequest ) { 
return doOnLifecycle ( Functions . emptyConsumer ( ) , onRequest , Functions . EMPTY_ACTION ) ; 
public final Flowable < T > doOnSubscribe ( Consumer < ? super Subscription > onSubscribe ) { 
return doOnLifecycle ( onSubscribe , Functions . EMPTY_LONG_CONSUMER , Functions . EMPTY_ACTION ) ; 
public final Flowable < T > doOnTerminate ( final Action onTerminate ) { 
return doOnEach ( Functions . emptyConsumer ( ) , Functions . actionConsumer ( onTerminate ) , 
onTerminate , Functions . EMPTY_ACTION ) ; 
return RxJavaPlugins . onAssembly ( new FlowableElementAtMaybe < T > ( this , index ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableElementAtSingle < T > ( this , index , null ) ) ; 
public final Flowable < T > filter ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new FlowableFilter < T > ( this , predicate ) ) ; 
public final Maybe < T > firstElement ( ) { 
return elementAt ( 0 ) ; 
return elementAt ( 0 , defaultItem ) ; 
public final Single < T > firstOrError ( ) { 
return elementAtOrError ( 0 ) ; 
public final < R > Flowable < R > flatMap ( Function < ? super T , ? extends Publisher < ? extends R > > mapper , 
return FlowableScalarXMap . scalarXMap ( v , mapper ) ; 
return RxJavaPlugins . onAssembly ( new FlowableFlatMap < T , R > ( this , mapper , delayErrors , maxConcurrency , bufferSize ) ) ; 
public final < R > Flowable < R > flatMap ( 
Function < ? super T , ? extends Publisher < ? extends R > > onNextMapper , 
Function < ? super Throwable , ? extends Publisher < ? extends R > > onErrorMapper , 
Callable < ? extends Publisher < ? extends R > > onCompleteSupplier ) { 
return merge ( new FlowableMapNotification < T , Publisher < ? extends R > > ( this , onNextMapper , onErrorMapper , onCompleteSupplier ) ) ; 
public final < U , R > Flowable < R > flatMap ( final Function < ? super T , ? extends Publisher < ? extends U > > mapper , 
final BiFunction < ? super T , ? super U , ? extends R > combiner , boolean delayErrors , int maxConcurrency , int bufferSize ) { 
return flatMap ( FlowableInternalHelper . flatMapWithCombiner ( mapper , combiner ) , delayErrors , maxConcurrency , bufferSize ) ; 
return flatMapCompletable ( mapper , false , Integer . MAX_VALUE ) ; 
public final Completable flatMapCompletable ( Function < ? super T , ? extends CompletableSource > mapper , boolean delayErrors , int maxConcurrency ) { 
return RxJavaPlugins . onAssembly ( new FlowableFlatMapCompletableCompletable < T > ( this , mapper , delayErrors , maxConcurrency ) ) ; 
public final < R > Flowable < R > flatMapMaybe ( Function < ? super T , ? extends MaybeSource < ? extends R > > mapper ) { 
return flatMapMaybe ( mapper , false , Integer . MAX_VALUE ) ; 
public final < R > Flowable < R > flatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper ) { 
return flatMapSingle ( mapper , false , Integer . MAX_VALUE ) ; 
public final < R > Flowable < R > flatMapSingle ( Function < ? super T , ? extends SingleSource < ? extends R > > mapper , boolean delayErrors , int maxConcurrency ) { 
return RxJavaPlugins . onAssembly ( new FlowableFlatMapSingle < T , R > ( this , mapper , delayErrors , maxConcurrency ) ) ; 
public final Disposable forEach ( Consumer < ? super T > onNext ) { 
return subscribe ( onNext ) ; 
public final Disposable forEachWhile ( Predicate < ? super T > onNext ) { 
return forEachWhile ( onNext , Functions . ON_ERROR_MISSING , Functions . EMPTY_ACTION ) ; 
public final Disposable forEachWhile ( Predicate < ? super T > onNext , Consumer < ? super Throwable > onError ) { 
return forEachWhile ( onNext , onError , Functions . EMPTY_ACTION ) ; 
public final Disposable forEachWhile ( final Predicate < ? super T > onNext , final Consumer < ? super Throwable > onError , 
ForEachWhileSubscriber < T > s = new ForEachWhileSubscriber < T > ( onNext , onError , onComplete ) ; 
return s ; 
public final < K > Flowable < GroupedFlowable < K , T > > groupBy ( Function < ? super T , ? extends K > keySelector ) { 
return groupBy ( keySelector , Functions . < T > identity ( ) , false , bufferSize ( ) ) ; 
public final < K , V > Flowable < GroupedFlowable < K , V > > groupBy ( Function < ? super T , ? extends K > keySelector , 
return RxJavaPlugins . onAssembly ( new FlowableGroupBy < T , K , V > ( this , keySelector , valueSelector , bufferSize , delayError , null ) ) ; 
public final Flowable < T > hide ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableHide < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableIgnoreElementsCompletable < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableLastMaybe < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableLastSingle < T > ( this , null ) ) ; 
public final Flowable < T > limit ( long count ) { 
return RxJavaPlugins . onAssembly ( new FlowableLimit < T > ( this , count ) ) ; 
public final Flowable < Notification < T > > materialize ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableMaterialize < T > ( this ) ) ; 
public final Flowable < T > mergeWith ( Publisher < ? extends T > other ) { 
public final Flowable < T > mergeWith ( @ NonNull SingleSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableMergeWithSingle < T > ( this , other ) ) ; 
public final Flowable < T > mergeWith ( @ NonNull MaybeSource < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableMergeWithMaybe < T > ( this , other ) ) ; 
public final Flowable < T > observeOn ( Scheduler scheduler ) { 
public final Flowable < T > onBackpressureBuffer ( ) { 
return onBackpressureBuffer ( bufferSize ( ) , false , true ) ; 
public final Flowable < T > onBackpressureBuffer ( int capacity ) { 
return onBackpressureBuffer ( capacity , false , false ) ; 
public final Flowable < T > onBackpressureDrop ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableOnBackpressureDrop < T > ( this ) ) ; 
public final Flowable < T > onBackpressureDrop ( Consumer < ? super T > onDrop ) { 
return RxJavaPlugins . onAssembly ( new FlowableOnBackpressureDrop < T > ( this , onDrop ) ) ; 
public final Flowable < T > onErrorResumeNext ( Function < ? super Throwable , ? extends Publisher < ? extends T > > resumeFunction ) { 
return RxJavaPlugins . onAssembly ( new FlowableOnErrorNext < T > ( this , resumeFunction , false ) ) ; 
public final Flowable < T > onTerminateDetach ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableDetach < T > ( this ) ) ; 
public final ParallelFlowable < T > parallel ( ) { 
return ParallelFlowable . from ( this ) ; 
public final ParallelFlowable < T > parallel ( int parallelism ) { 
return ParallelFlowable . from ( this , parallelism ) ; 
public final ConnectableFlowable < T > publish ( ) { 
return publish ( bufferSize ( ) ) ; 
public final < R > Flowable < R > publish ( Function < ? super Flowable < T > , ? extends Publisher < R > > selector ) { 
return publish ( selector , bufferSize ( ) ) ; 
public final ConnectableFlowable < T > publish ( int bufferSize ) { 
return FlowablePublish . create ( this , bufferSize ) ; 
public final Flowable < T > rebatchRequests ( int n ) { 
return observeOn ( ImmediateThinScheduler . INSTANCE , true , n ) ; 
return RxJavaPlugins . onAssembly ( new FlowableReduceMaybe < T > ( this , reducer ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableReduceSeedSingle < T , R > ( this , seed , reducer ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableReduceWithSingle < T , R > ( this , seedSupplier , reducer ) ) ; 
public final Flowable < T > repeat ( long times ) { 
return RxJavaPlugins . onAssembly ( new FlowableRepeat < T > ( this , times ) ) ; 
public final ConnectableFlowable < T > replay ( ) { 
return FlowableReplay . createFrom ( this ) ; 
public final < R > Flowable < R > replay ( Function < ? super Flowable < T > , ? extends Publisher < R > > selector , int bufferSize , long time , TimeUnit unit ) { 
public final < R > Flowable < R > replay ( final Function < ? super Flowable < T > , ? extends Publisher < R > > selector , final Scheduler scheduler ) { 
return FlowableReplay . multicastSelector ( FlowableInternalHelper . replayCallable ( this ) , 
FlowableInternalHelper . replayFunction ( selector , scheduler ) ) ; 
public final ConnectableFlowable < T > replay ( final int bufferSize ) { 
return FlowableReplay . create ( this , bufferSize ) ; 
public final ConnectableFlowable < T > replay ( int bufferSize , long time , TimeUnit unit ) { 
public final ConnectableFlowable < T > replay ( final int bufferSize , final long time , final TimeUnit unit , final Scheduler scheduler ) { 
return FlowableReplay . create ( this , time , unit , scheduler , bufferSize ) ; 
public final ConnectableFlowable < T > replay ( final int bufferSize , final Scheduler scheduler ) { 
return FlowableReplay . observeOn ( replay ( bufferSize ) , scheduler ) ; 
public final Flowable < T > retry ( ) { 
public final Flowable < T > retry ( long count ) { 
public final Flowable < T > retry ( Predicate < ? super Throwable > predicate ) { 
} @ BackpressureSupport ( BackpressureKind . PASS_THROUGH ) 
public final void safeSubscribe ( Subscriber < ? super T > s ) { 
if ( s instanceof SafeSubscriber ) { 
subscribe ( ( SafeSubscriber < ? super T > ) s ) ; 
subscribe ( new SafeSubscriber < T > ( s ) ) ; 
public final Flowable < T > sample ( long period , TimeUnit unit ) { 
public final Flowable < T > sample ( long period , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableSampleTimed < T > ( this , period , unit , scheduler , false ) ) ; 
public final < U > Flowable < T > sample ( Publisher < U > sampler ) { 
return RxJavaPlugins . onAssembly ( new FlowableSamplePublisher < T > ( this , sampler , false ) ) ; 
public final < R > Flowable < R > scanWith ( Callable < R > seedSupplier , BiFunction < R , ? super T , R > accumulator ) { 
return RxJavaPlugins . onAssembly ( new FlowableScanSeed < T , R > ( this , seedSupplier , accumulator ) ) ; 
public final Flowable < T > serialize ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableSerialized < T > ( this ) ) ; 
public final Flowable < T > share ( ) { 
return publish ( ) . refCount ( ) ; 
return RxJavaPlugins . onAssembly ( new FlowableSingleMaybe < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableSingleSingle < T > ( this , null ) ) ; 
public final Flowable < T > skip ( long count ) { 
if ( count <= 0L ) { 
return RxJavaPlugins . onAssembly ( new FlowableSkip < T > ( this , count ) ) ; 
public final Flowable < T > skip ( long time , TimeUnit unit ) { 
public final Flowable < T > skip ( long time , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < T > skipLast ( int count ) { 
return RxJavaPlugins . onAssembly ( new FlowableSkipLast < T > ( this , count ) ) ; 
public final Flowable < T > skipLast ( long time , TimeUnit unit ) { 
return skipLast ( time , unit , Schedulers . computation ( ) , false , bufferSize ( ) ) ; 
public final Flowable < T > skipLast ( long time , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < T > skipWhile ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new FlowableSkipWhile < T > ( this , predicate ) ) ; 
public final Flowable < T > sorted ( ) { 
return toList ( ) . toFlowable ( ) . map ( Functions . listSorter ( Functions . < T > naturalComparator ( ) ) ) . flatMapIterable ( Functions . < List < T > > identity ( ) ) ; 
public final Flowable < T > sorted ( Comparator < ? super T > sortFunction ) { 
ObjectHelper . requireNonNull ( sortFunction , "sortFunction" ) ; 
return toList ( ) . toFlowable ( ) . map ( Functions . listSorter ( sortFunction ) ) . flatMapIterable ( Functions . < List < T > > identity ( ) ) ; 
public final Flowable < T > startWith ( Iterable < ? extends T > items ) { 
public final Flowable < T > startWithArray ( T ... items ) { 
Flowable < T > fromArray = fromArray ( items ) ; 
return subscribe ( Functions . emptyConsumer ( ) , Functions . ON_ERROR_MISSING , 
Functions . EMPTY_ACTION , FlowableInternalHelper . RequestMax . INSTANCE ) ; 
return subscribe ( onNext , Functions . ON_ERROR_MISSING , 
public final void subscribe ( FlowableSubscriber < ? super T > s ) { 
Subscriber < ? super T > z = RxJavaPlugins . onSubscribe ( this , s ) ; 
subscribeActual ( z ) ; 
} catch ( NullPointerException e ) { 
throw e ; 
RxJavaPlugins . onError ( e ) ; 
npe . initCause ( e ) ; 
throw npe ; 
public final < E extends Subscriber < ? super T > > E subscribeWith ( E subscriber ) { 
subscribe ( subscriber ) ; 
public final Flowable < T > subscribeOn ( @ NonNull Scheduler scheduler , boolean requestOn ) { 
return RxJavaPlugins . onAssembly ( new FlowableSubscribeOn < T > ( this , scheduler , requestOn ) ) ; 
public final Flowable < T > switchIfEmpty ( Publisher < ? extends T > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableSwitchIfEmpty < T > ( this , other ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableSwitchMapCompletable < T > ( this , mapper , false ) ) ; 
public final < R > Flowable < R > switchMapDelayError ( Function < ? super T , ? extends Publisher < ? extends R > > mapper ) { 
public final Flowable < T > take ( long count ) { 
return RxJavaPlugins . onAssembly ( new FlowableTake < T > ( this , count ) ) ; 
public final Flowable < T > take ( long time , TimeUnit unit ) { 
public final Flowable < T > take ( long time , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < T > takeLast ( int count ) { 
return RxJavaPlugins . onAssembly ( new FlowableIgnoreElements < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableTakeLastOne < T > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableTakeLast < T > ( this , count ) ) ; 
public final Flowable < T > takeLast ( long count , long time , TimeUnit unit ) { 
return takeLast ( count , time , unit , Schedulers . computation ( ) , false , bufferSize ( ) ) ; 
public final Flowable < T > takeLast ( long count , long time , TimeUnit unit , Scheduler scheduler , boolean delayError , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new FlowableTakeLastTimed < T > ( this , count , time , unit , scheduler , bufferSize , delayError ) ) ; 
public final Flowable < T > takeLast ( long time , TimeUnit unit , Scheduler scheduler , boolean delayError , int bufferSize ) { 
return takeLast ( Long . MAX_VALUE , time , unit , scheduler , delayError , bufferSize ) ; 
public final Flowable < T > takeUntil ( Predicate < ? super T > stopPredicate ) { 
return RxJavaPlugins . onAssembly ( new FlowableTakeUntilPredicate < T > ( this , stopPredicate ) ) ; 
public final < U > Flowable < T > takeUntil ( Publisher < U > other ) { 
return RxJavaPlugins . onAssembly ( new FlowableTakeUntil < T , U > ( this , other ) ) ; 
public final Flowable < T > takeWhile ( Predicate < ? super T > predicate ) { 
return RxJavaPlugins . onAssembly ( new FlowableTakeWhile < T > ( this , predicate ) ) ; 
public final Flowable < T > throttleFirst ( long windowDuration , TimeUnit unit ) { 
public final Flowable < T > throttleLast ( long intervalDuration , TimeUnit unit ) { 
public final Flowable < T > throttleLast ( long intervalDuration , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < T > throttleWithTimeout ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < Timed < T > > timeInterval ( TimeUnit unit ) { 
return timeInterval ( unit , Schedulers . computation ( ) ) ; 
public final Flowable < Timed < T > > timeInterval ( TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableTimeInterval < T > ( this , unit , scheduler ) ) ; 
public final < V > Flowable < T > timeout ( Function < ? super T , ? extends Publisher < V > > itemTimeoutIndicator ) { 
public final Flowable < T > timeout ( long timeout , TimeUnit timeUnit ) { 
public final Flowable < T > timeout ( long timeout , TimeUnit timeUnit , Scheduler scheduler ) { 
public final < U , V > Flowable < T > timeout ( Publisher < U > firstTimeoutIndicator , 
Function < ? super T , ? extends Publisher < V > > itemTimeoutIndicator ) { 
return timeout0 ( firstTimeoutIndicator , itemTimeoutIndicator , null ) ; 
public final Flowable < Timed < T > > timestamp ( Scheduler scheduler ) { 
public final < R > R to ( Function < ? super Flowable < T > , R > converter ) { 
public final Single < List < T > > toList ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableToListSingle < T , List < T > > ( this ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableToListSingle < T , List < T > > ( this , Functions . < T > createArrayList ( capacityHint ) ) ) ; 
return RxJavaPlugins . onAssembly ( new FlowableToListSingle < T , U > ( this , collectionSupplier ) ) ; 
public final < K , V > Single < Map < K , Collection < V > > > toMultimap ( 
final Function < ? super T , ? extends K > keySelector , 
final Function < ? super T , ? extends V > valueSelector , 
final Callable < ? extends Map < K , Collection < V > > > mapSupplier , 
final Function < ? super K , ? extends Collection < ? super V > > collectionFactory ) { 
return collect ( mapSupplier , Functions . toMultimapKeyValueSelector ( keySelector , valueSelector , collectionFactory ) ) ; 
return RxJavaPlugins . onAssembly ( new ObservableFromPublisher < T > ( this ) ) ; 
return toSortedList ( Functions . naturalComparator ( ) ) ; 
public final Flowable < T > unsubscribeOn ( Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableUnsubscribeOn < T > ( this , scheduler ) ) ; 
public final Flowable < Flowable < T > > window ( long count ) { 
public final Flowable < Flowable < T > > window ( long count , long skip , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new FlowableWindow < T > ( this , count , skip , bufferSize ) ) ; 
public final Flowable < Flowable < T > > window ( long timespan , long timeskip , TimeUnit unit ) { 
public final Flowable < Flowable < T > > window ( long timespan , TimeUnit unit , 
long count ) { 
return window ( timespan , unit , Schedulers . computation ( ) , count , false ) ; 
Scheduler scheduler ) { 
return window ( timespan , unit , scheduler , Long . MAX_VALUE , false ) ; 
public final < U , V > Flowable < Flowable < T > > window ( 
Publisher < U > openingIndicator , 
Function < ? super U , ? extends Publisher < V > > closingIndicator ) { 
Function < ? super U , ? extends Publisher < V > > closingIndicator , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new FlowableWindowBoundarySelector < T , U , V > ( this , openingIndicator , closingIndicator , bufferSize ) ) ; 
public final < B > Flowable < Flowable < T > > window ( Callable < ? extends Publisher < B > > boundaryIndicatorSupplier ) { 
return window ( boundaryIndicatorSupplier , bufferSize ( ) ) ; 
public final < B > Flowable < Flowable < T > > window ( Callable < ? extends Publisher < B > > boundaryIndicatorSupplier , int bufferSize ) { 
return RxJavaPlugins . onAssembly ( new FlowableWindowBoundarySupplier < T , B > ( this , boundaryIndicatorSupplier , bufferSize ) ) ; 
public final < U , R > Flowable < R > zipWith ( Iterable < U > other , BiFunction < ? super T , ? super U , ? extends R > zipper ) { 
return RxJavaPlugins . onAssembly ( new FlowableZipIterable < T , U , R > ( this , other , zipper ) ) ; 
public final < U , R > Flowable < R > zipWith ( Publisher < ? extends U > other , 
BiFunction < ? super T , ? super U , ? extends R > zipper , boolean delayError ) { 
return zip ( this , other , zipper , delayError ) ; 
final LinkedQueueNode < T > nextNode = new LinkedQueueNode < T > ( e ) ; 
final LinkedQueueNode < T > prevProducerNode = xchgProducerNode ( nextNode ) ; 
prevProducerNode . soNext ( nextNode ) ; 
LinkedQueueNode < T > currConsumerNode = lpConsumerNode ( ) ; 
LinkedQueueNode < T > nextNode = currConsumerNode . lvNext ( ) ; 
if ( nextNode != null ) { 
final T nextValue = nextNode . getAndNullValue ( ) ; 
spConsumerNode ( nextNode ) ; 
return nextValue ; 
else if ( currConsumerNode != lvProducerNode ( ) ) { 
while ( ( nextNode = currConsumerNode . lvNext ( ) ) == null ) { } 
public ScheduledRunnable scheduleActual ( final Runnable run , long delayTime , @ NonNull TimeUnit unit , @ Nullable DisposableContainer parent ) { 
Runnable decoratedRun = RxJavaPlugins . onSchedule ( run ) ; 
ScheduledRunnable sr = new ScheduledRunnable ( decoratedRun , parent ) ; 
if ( parent != null ) { 
if ( ! parent . add ( sr ) ) { 
return sr ; 
Future < ? > f ; 
if ( delayTime <= 0 ) { 
f = executor . submit ( ( Callable < Object > ) sr ) ; 
f = executor . schedule ( ( Callable < Object > ) sr , delayTime , unit ) ; 
sr . setFuture ( f ) ; 
} catch ( RejectedExecutionException ex ) { 
parent . remove ( sr ) ; 
} public PerfAsyncConsumer await ( int count ) { 
if ( count <= 1000 ) { 
while ( getCount ( ) != 0 ) { } 
throw new RuntimeException ( ex ) ; 
return this ; 
} public final void complete ( T v ) { 
value = v ; 
Subscriber < ? super T > a = downstream ; 
a . onNext ( v ) ; 
if ( get ( ) != CANCELLED ) { 
if ( ( state & ~ HAS_REQUEST_NO_VALUE ) != 0 ) { 
if ( state == HAS_REQUEST_NO_VALUE ) { 
lazySet ( HAS_REQUEST_HAS_VALUE ) ; 
if ( compareAndSet ( NO_REQUEST_NO_VALUE , NO_REQUEST_HAS_VALUE ) ) { 
state = get ( ) ; 
if ( state == CANCELLED ) { 
public static < T > BehaviorProcessor < T > createDefault ( T defaultValue ) { 
return new BehaviorProcessor < T > ( defaultValue ) ; 
BehaviorSubscription < T > [ ] array = subscribers . get ( ) ; 
for ( BehaviorSubscription < T > s : array ) { 
Object o = NotificationLite . next ( t ) ; 
setCurrent ( o ) ; 
for ( BehaviorSubscription < T > bs : array ) { 
bs . emitNext ( o , index ) ; 
source . subscribe ( new LastSubscriber < T > ( observer ) ) ; 
} public static void verifyNonBlocking ( ) { 
if ( RxJavaPlugins . isFailOnNonBlockingScheduler ( ) 
&& ( Thread . currentThread ( ) instanceof NonBlockingThread 
|| RxJavaPlugins . onBeforeBlocking ( ) ) ) { 
public Flowable < T > refCount ( ) { 
return RxJavaPlugins . onAssembly ( new FlowableRefCount < T > ( this ) ) ; 
public final Flowable < T > refCount ( int subscriberCount ) { 
public final Flowable < T > refCount ( long timeout , TimeUnit unit ) { 
return refCount ( 1 , timeout , unit , Schedulers . computation ( ) ) ; 
public final Flowable < T > refCount ( long timeout , TimeUnit unit , Scheduler scheduler ) { 
public final Flowable < T > refCount ( int subscriberCount , long timeout , TimeUnit unit , Scheduler scheduler ) { 
return RxJavaPlugins . onAssembly ( new FlowableRefCount < T > ( this , subscriberCount , timeout , unit , scheduler ) ) ; 
public Flowable < T > autoConnect ( int numberOfSubscribers , @ NonNull Consumer < ? super Disposable > connection ) { 
return RxJavaPlugins . onAssembly ( new FlowableAutoConnect < T > ( this , numberOfSubscribers , connection ) ) ; 
} protected final void request ( long n ) { 
Subscription s = this . upstream ; 
if ( s != null ) { 
s . request ( n ) ; 
} public boolean setResource ( int index , Disposable resource ) { 
Disposable o = get ( index ) ; 
if ( o == DisposableHelper . DISPOSED ) { 
resource . dispose ( ) ; 
o . dispose ( ) ; 
} public Disposable replaceResource ( int index , Disposable resource ) { 
this . upstream = SubscriptionHelper . CANCELLED ; 
} boolean add ( PublishDisposable < T > ps ) { 
PublishDisposable < T > [ ] a = subscribers . get ( ) ; 
if ( a == TERMINATED ) { 
int n = a . length ; 
PublishDisposable < T > [ ] b = new PublishDisposable [ n + 1 ] ; 
System . arraycopy ( a , 0 , b , 0 , n ) ; 
b [ n ] = ps ; 
if ( subscribers . compareAndSet ( a , b ) ) { 
void remove ( PublishDisposable < T > ps ) { 
if ( a == TERMINATED || a == EMPTY ) { 
if ( a [ i ] == ps ) { 
PublishDisposable < T > [ ] b ; 
b = EMPTY ; 
b = new PublishDisposable [ n - 1 ] ; 
System . arraycopy ( a , 0 , b , 0 , j ) ; 
System . arraycopy ( a , j + 1 , b , j , n - j - 1 ) ; 
} public static < U , R > Flowable < R > multicastSelector ( 
final Callable < ? extends ConnectableFlowable < U > > connectableFactory , 
final Function < ? super Flowable < U > , ? extends Publisher < R > > selector ) { 
return new MulticastFlowable < R , U > ( connectableFactory , selector ) ; 
} public static < T > ConnectableFlowable < T > observeOn ( final ConnectableFlowable < T > cf , final Scheduler scheduler ) { 
final Flowable < T > flowable = cf . observeOn ( scheduler ) ; 
return RxJavaPlugins . onAssembly ( new ConnectableFlowableReplay < T > ( cf , flowable ) ) ; 
public static < T > ConnectableFlowable < T > createFrom ( Flowable < ? extends T > source ) { 
} public static < T > ConnectableFlowable < T > create ( Flowable < T > source , 
return create ( source , new ReplayBufferTask < T > ( bufferSize ) ) ; 
return create ( source , new ScheduledReplayBufferTask < T > ( bufferSize , maxAge , unit , scheduler ) ) ; 
} static < T > ConnectableFlowable < T > create ( Flowable < T > source , 
final Callable < ? extends ReplayBuffer < T > > bufferFactory ) { 
final AtomicReference < ReplaySubscriber < T > > curr = new AtomicReference < ReplaySubscriber < T > > ( ) ; 
Publisher < T > onSubscribe = new ReplayPublisher < T > ( curr , bufferFactory ) ; 
return RxJavaPlugins . onAssembly ( new FlowableReplay < T > ( onSubscribe , source , curr , bufferFactory ) ) ; 
} public void onEvent ( ConnectionEventType type , String remoteAddr , Connection conn ) { 
List < ConnectionEventProcessor > processorList = this . processors . get ( type ) ; 
if ( processorList != null ) { 
for ( ConnectionEventProcessor processor : processorList ) { 
processor . onEvent ( remoteAddr , conn ) ; 
} public void addConnectionEventProcessor ( ConnectionEventType type , 
ConnectionEventProcessor processor ) { 
if ( processorList == null ) { 
this . processors . putIfAbsent ( type , new ArrayList < ConnectionEventProcessor > ( 1 ) ) ; 
processorList = this . processors . get ( type ) ; 
processorList . add ( processor ) ; 
} public static < T > T getFutureTaskResult ( RunStateRecordedFutureTask < T > task , Logger logger ) { 
T t = null ; 
if ( null != task ) { 
t = task . getAfterRun ( ) ; 
} catch ( ExecutionException e ) { 
} catch ( FutureTaskNotRunYetException e ) { 
} catch ( FutureTaskNotCompleted e ) { 
return t ; 
} public static void launderThrowable ( Throwable t ) { 
if ( t instanceof RuntimeException ) { 
throw ( RuntimeException ) t ; 
} else if ( t instanceof Error ) { 
throw ( Error ) t ; 
} public void registerProcessor ( CommandCode cmdCode , RemotingProcessor < ? > processor ) { 
if ( this . cmd2processors . containsKey ( cmdCode ) ) { 
logger 
. warn ( 
cmdCode , cmd2processors . get ( cmdCode ) . getClass ( ) . getName ( ) , processor . getClass ( ) 
. getName ( ) ) ; 
this . cmd2processors . put ( cmdCode , processor ) ; 
} public void registerDefaultProcessor ( RemotingProcessor < ? > processor ) { 
if ( this . defaultProcessor == null ) { 
this . defaultProcessor = processor ; 
+ this . defaultProcessor . getClass ( ) ) ; 
} public RemotingProcessor < ? > getProcessor ( CommandCode cmdCode ) { 
RemotingProcessor < ? > processor = this . cmd2processors . get ( cmdCode ) ; 
if ( processor != null ) { 
return processor ; 
return this . defaultProcessor ; 
} private Url tryGet ( String url ) { 
SoftReference < Url > softRef = Url . parsedUrls . get ( url ) ; 
return ( null == softRef ) ? null : softRef . get ( ) ; 
} protected ProtocolCode decodeProtocolCode ( ByteBuf in ) { 
if ( in . readableBytes ( ) >= protocolCodeLength ) { 
byte [ ] protocolCodeBytes = new byte [ protocolCodeLength ] ; 
in . readBytes ( protocolCodeBytes ) ; 
return ProtocolCode . fromBytes ( protocolCodeBytes ) ; 
public Map < String , List < Connection > > getAll ( ) { 
Map < String , List < Connection > > allConnections = new HashMap < String , List < Connection > > ( ) ; 
Iterator < Map . Entry < String , RunStateRecordedFutureTask < ConnectionPool > > > iterator = this 
. getConnPools ( ) . entrySet ( ) . iterator ( ) ; 
while ( iterator . hasNext ( ) ) { 
Map . Entry < String , RunStateRecordedFutureTask < ConnectionPool > > entry = iterator . next ( ) ; 
ConnectionPool pool = FutureTaskUtil . getFutureTaskResult ( entry . getValue ( ) , logger ) ; 
if ( null != pool ) { 
allConnections . put ( entry . getKey ( ) , pool . getAll ( ) ) ; 
return allConnections ; 
public void removeAll ( ) { 
if ( null == this . connTasks || this . connTasks . isEmpty ( ) ) { 
if ( null != this . connTasks && ! this . connTasks . isEmpty ( ) ) { 
Iterator < String > iter = this . connTasks . keySet ( ) . iterator ( ) ; 
while ( iter . hasNext ( ) ) { 
String poolKey = iter . next ( ) ; 
this . removeTask ( poolKey ) ; 
iter . remove ( ) ; 
public void scan ( ) { 
ConnectionPool pool = this . getConnectionPool ( this . connTasks . get ( poolKey ) ) ; 
pool . scan ( ) ; 
if ( pool . isEmpty ( ) ) { 
if ( ( System . currentTimeMillis ( ) - pool . getLastAccessTimestamp ( ) ) > DEFAULT_EXPIRE_TIME ) { 
poolKey ) ; 
public Connection getAndCreateIfAbsent ( Url url ) throws InterruptedException , RemotingException { 
ConnectionPool pool = this . getConnectionPoolAndCreateIfAbsent ( url . getUniqueKey ( ) , 
new ConnectionPoolCall ( url ) ) ; 
return pool . get ( ) ; 
public void createConnectionAndHealIfNeed ( Url url ) throws InterruptedException , 
RemotingException { 
healIfNeed ( pool , url ) ; 
} private ConnectionPool getConnectionPoolAndCreateIfAbsent ( String poolKey , 
Callable < ConnectionPool > callable ) 
throws RemotingException , 
InterruptedException { 
RunStateRecordedFutureTask < ConnectionPool > initialTask = null ; 
ConnectionPool pool = null ; 
int retry = DEFAULT_RETRY_TIMES ; 
int timesOfResultNull = 0 ; 
int timesOfInterrupt = 0 ; 
for ( int i = 0 ; ( i < retry ) && ( pool == null ) ; ++ i ) { 
initialTask = this . connTasks . get ( poolKey ) ; 
if ( null == initialTask ) { 
initialTask = new RunStateRecordedFutureTask < ConnectionPool > ( callable ) ; 
initialTask = this . connTasks . putIfAbsent ( poolKey , initialTask ) ; 
initialTask . run ( ) ; 
pool = initialTask . get ( ) ; 
if ( null == pool ) { 
if ( i + 1 < retry ) { 
timesOfResultNull ++ ; 
this . connTasks . remove ( poolKey ) ; 
throw new RemotingException ( errMsg ) ; 
timesOfInterrupt ++ ; 
poolKey , ( timesOfInterrupt + 1 ) , e ) ; 
Throwable cause = e . getCause ( ) ; 
if ( cause instanceof RemotingException ) { 
throw ( RemotingException ) cause ; 
FutureTaskUtil . launderThrowable ( cause ) ; 
return pool ; 
} private void removeTask ( String poolKey ) { 
RunStateRecordedFutureTask < ConnectionPool > task = this . connTasks . remove ( poolKey ) ; 
ConnectionPool pool = FutureTaskUtil . getFutureTaskResult ( task , logger ) ; 
pool . removeAllAndTryClose ( ) ; 
} private void healIfNeed ( ConnectionPool pool , Url url ) throws RemotingException , 
String poolKey = url . getUniqueKey ( ) ; 
if ( pool . isAsyncCreationDone ( ) && pool . size ( ) < url . getConnNum ( ) ) { 
FutureTask < Integer > task = this . healTasks . get ( poolKey ) ; 
if ( null == task ) { 
task = new FutureTask < Integer > ( new HealConnectionCall ( url , pool ) ) ; 
task = this . healTasks . putIfAbsent ( poolKey , task ) ; 
task = this . healTasks . get ( poolKey ) ; 
task . run ( ) ; 
int numAfterHeal = task . get ( ) ; 
if ( logger . isDebugEnabled ( ) ) { 
numAfterHeal , url . getConnNum ( ) , url . isConnWarmup ( ) ) ; 
this . healTasks . remove ( poolKey ) ; 
} private void doCreate ( final Url url , final ConnectionPool pool , final String taskName , 
final int syncCreateNumWhenNotWarmup ) throws RemotingException { 
final int actualNum = pool . size ( ) ; 
final int expectNum = url . getConnNum ( ) ; 
if ( actualNum < expectNum ) { 
taskName ) ; 
if ( url . isConnWarmup ( ) ) { 
for ( int i = actualNum ; i < expectNum ; ++ i ) { 
Connection connection = create ( url ) ; 
pool . add ( connection ) ; 
if ( syncCreateNumWhenNotWarmup < 0 || syncCreateNumWhenNotWarmup > url . getConnNum ( ) ) { 
throw new IllegalArgumentException ( 
if ( syncCreateNumWhenNotWarmup > 0 ) { 
for ( int i = 0 ; i < syncCreateNumWhenNotWarmup ; ++ i ) { 
if ( syncCreateNumWhenNotWarmup == url . getConnNum ( ) ) { 
initializeExecutor ( ) ; 
pool . markAsyncCreationStart ( ) ; 
this . asyncCreateConnectionExecutor . execute ( new Runnable ( ) { 
public void run ( ) { 
for ( int i = pool . size ( ) ; i < url . getConnNum ( ) ; ++ i ) { 
Connection conn = null ; 
conn = create ( url ) ; 
} catch ( RemotingException e ) { 
. error ( 
url . getUniqueKey ( ) , taskName , e ) ; 
pool . add ( conn ) ; 
} finally { 
pool . markAsyncCreationDone ( ) ; 
} catch ( RejectedExecutionException e ) { 
} private void initializeExecutor ( ) { 
if ( ! this . executorInitialized ) { 
this . executorInitialized = true ; 
this . asyncCreateConnectionExecutor = new ThreadPoolExecutor ( minPoolSize , maxPoolSize , 
keepAliveTime , TimeUnit . SECONDS , new ArrayBlockingQueue < Runnable > ( queueSize ) , 
new NamedThreadFactory ( "Bolt-conn-warmup-executor" , true ) ) ; 
} public void shutdown ( ) { 
this . connectionManager . removeAll ( ) ; 
this . taskScanner . shutdown ( ) ; 
if ( reconnectManager != null ) { 
reconnectManager . stop ( ) ; 
if ( connectionMonitor != null ) { 
connectionMonitor . destroy ( ) ; 
} public void oneway ( final String addr , final Object request ) throws RemotingException , 
this . rpcRemoting . oneway ( addr , request , null ) ; 
} public void oneway ( final Connection conn , final Object request ) throws RemotingException { 
this . rpcRemoting . oneway ( conn , request , null ) ; 
} public void oneway ( final Connection conn , final Object request , 
final InvokeContext invokeContext ) throws RemotingException { 
this . rpcRemoting . oneway ( conn , request , invokeContext ) ; 
} public Object invokeSync ( final String addr , final Object request , final int timeoutMillis ) 
return this . rpcRemoting . invokeSync ( addr , request , null , timeoutMillis ) ; 
} public Object invokeSync ( final String addr , final Object request , 
final InvokeContext invokeContext , final int timeoutMillis ) 
return this . rpcRemoting . invokeSync ( addr , request , invokeContext , timeoutMillis ) ; 
} public Object invokeSync ( final Url url , final Object request , final int timeoutMillis ) 
return this . invokeSync ( url , request , null , timeoutMillis ) ; 
} public Object invokeSync ( final Url url , final Object request , 
return this . rpcRemoting . invokeSync ( url , request , invokeContext , timeoutMillis ) ; 
} public Object invokeSync ( final Connection conn , final Object request , final int timeoutMillis ) 
return this . rpcRemoting . invokeSync ( conn , request , null , timeoutMillis ) ; 
} public Object invokeSync ( final Connection conn , final Object request , 
return this . rpcRemoting . invokeSync ( conn , request , invokeContext , timeoutMillis ) ; 
} public RpcResponseFuture invokeWithFuture ( final Connection conn , final Object request , 
int timeoutMillis ) throws RemotingException { 
return this . rpcRemoting . invokeWithFuture ( conn , request , null , timeoutMillis ) ; 
} public void invokeWithCallback ( final Url url , final Object request , 
final InvokeContext invokeContext , 
final InvokeCallback invokeCallback , final int timeoutMillis ) 
this . rpcRemoting . invokeWithCallback ( url , request , invokeContext , invokeCallback , 
timeoutMillis ) ; 
} public void invokeWithCallback ( final Connection conn , final Object request , 
throws RemotingException { 
this . rpcRemoting . invokeWithCallback ( conn , request , null , invokeCallback , timeoutMillis ) ; 
this . rpcRemoting . invokeWithCallback ( conn , request , invokeContext , invokeCallback , 
} public Connection createStandaloneConnection ( String ip , int port , int connectTimeout ) 
return this . connectionManager . create ( ip , port , connectTimeout ) ; 
} public Connection createStandaloneConnection ( String addr , int connectTimeout ) 
return this . connectionManager . create ( addr , connectTimeout ) ; 
} public Connection getConnection ( String addr , int connectTimeout ) throws RemotingException , 
Url url = this . addressParser . parse ( addr ) ; 
return this . getConnection ( url , connectTimeout ) ; 
} public Connection getConnection ( Url url , int connectTimeout ) throws RemotingException , 
url . setConnectTimeout ( connectTimeout ) ; 
return this . connectionManager . getAndCreateIfAbsent ( url ) ; 
} public boolean checkConnection ( String addr ) { 
Connection conn = this . connectionManager . get ( url . getUniqueKey ( ) ) ; 
this . connectionManager . check ( conn ) ; 
} catch ( Exception e ) { 
} public void closeConnection ( String addr ) { 
this . connectionManager . remove ( url . getUniqueKey ( ) ) ; 
} public void enableConnHeartbeat ( String addr ) { 
this . enableConnHeartbeat ( url ) ; 
} public void enableConnHeartbeat ( Url url ) { 
if ( null != url ) { 
this . connectionManager . enableHeartbeat ( this . connectionManager . get ( url . getUniqueKey ( ) ) ) ; 
} public void disableConnHeartbeat ( String addr ) { 
this . disableConnHeartbeat ( url ) ; 
} public void disableConnHeartbeat ( Url url ) { 
this . connectionManager . disableHeartbeat ( this . connectionManager . get ( url . getUniqueKey ( ) ) ) ; 
} private void init ( ) { 
this . channel . attr ( HEARTBEAT_COUNT ) . set ( new Integer ( 0 ) ) ; 
this . channel . attr ( PROTOCOL ) . set ( this . protocolCode ) ; 
this . channel . attr ( VERSION ) . set ( this . version ) ; 
this . channel . attr ( HEARTBEAT_SWITCH ) . set ( true ) ; 
} public void onClose ( ) { 
Iterator < Entry < Integer , InvokeFuture > > iter = invokeFutureMap . entrySet ( ) . iterator ( ) ; 
Entry < Integer , InvokeFuture > entry = iter . next ( ) ; 
InvokeFuture future = entry . getValue ( ) ; 
if ( future != null ) { 
future . putResponse ( future . createConnectionClosedResponse ( this . getRemoteAddress ( ) ) ) ; 
future . cancelTimeout ( ) ; 
future . tryAsyncExecuteInvokeCallbackAbnormally ( ) ; 
} public void close ( ) { 
if ( closed . compareAndSet ( false , true ) ) { 
if ( this . getChannel ( ) != null ) { 
this . getChannel ( ) . close ( ) . addListener ( new ChannelFutureListener ( ) { 
public void operationComplete ( ChannelFuture future ) throws Exception { 
if ( logger . isInfoEnabled ( ) ) { 
. info ( 
RemotingUtil . parseRemoteAddress ( Connection . this 
. getChannel ( ) ) , future . isSuccess ( ) , future . cause ( ) ) ; 
RemotingUtil . parseRemoteAddress ( Connection . this . getChannel ( ) ) , e ) ; 
} public Object setAttributeIfAbsent ( String key , Object value ) { 
return attributes . putIfAbsent ( key , value ) ; 
public void channelRead ( ChannelHandlerContext ctx , Object msg ) throws Exception { 
if ( msg instanceof ByteBuf ) { 
RecyclableArrayList out = RecyclableArrayList . newInstance ( ) ; 
ByteBuf data = ( ByteBuf ) msg ; 
first = cumulation == null ; 
if ( first ) { 
cumulation = data ; 
cumulation = cumulator . cumulate ( ctx . alloc ( ) , cumulation , data ) ; 
callDecode ( ctx , cumulation , out ) ; 
} catch ( DecoderException e ) { 
} catch ( Throwable t ) { 
throw new DecoderException ( t ) ; 
if ( cumulation != null && ! cumulation . isReadable ( ) ) { 
numReads = 0 ; 
cumulation . release ( ) ; 
cumulation = null ; 
} else if ( ++ numReads >= discardAfterReads ) { 
discardSomeReadBytes ( ) ; 
int size = out . size ( ) ; 
decodeWasNull = true ; 
} else if ( size == 1 ) { 
ctx . fireChannelRead ( out . get ( 0 ) ) ; 
ArrayList < Object > ret = new ArrayList < Object > ( size ) ; 
for ( int i = 0 ; i < size ; i ++ ) { 
ret . add ( out . get ( i ) ) ; 
ctx . fireChannelRead ( ret ) ; 
out . recycle ( ) ; 
ctx . fireChannelRead ( msg ) ; 
} protected void callDecode ( ChannelHandlerContext ctx , ByteBuf in , List < Object > out ) { 
while ( in . isReadable ( ) ) { 
int outSize = out . size ( ) ; 
int oldInputLength = in . readableBytes ( ) ; 
decode ( ctx , in , out ) ; 
if ( ctx . isRemoved ( ) ) { 
if ( outSize == out . size ( ) ) { 
if ( oldInputLength == in . readableBytes ( ) ) { 
throw new DecoderException ( 
StringUtil . simpleClassName ( getClass ( ) ) 
if ( isSingleDecode ( ) ) { 
} catch ( Throwable cause ) { 
throw new DecoderException ( cause ) ; 
} public static void registerUserProcessor ( UserProcessor < ? > processor , 
ConcurrentHashMap < String , UserProcessor < ? > > userProcessors ) { 
if ( null == processor ) { 
if ( processor instanceof MultiInterestUserProcessor ) { 
registerUserProcessor ( ( MultiInterestUserProcessor ) processor , userProcessors ) ; 
if ( StringUtils . isBlank ( processor . interest ( ) ) ) { 
UserProcessor < ? > preProcessor = userProcessors . putIfAbsent ( processor . interest ( ) , 
processor ) ; 
if ( preProcessor != null ) { 
+ processor . interest ( ) 
throw new RuntimeException ( errMsg ) ; 
} private static void registerUserProcessor ( MultiInterestUserProcessor < ? > processor , 
if ( null == processor . multiInterest ( ) || processor . multiInterest ( ) . isEmpty ( ) ) { 
for ( String interest : processor . multiInterest ( ) ) { 
UserProcessor < ? > preProcessor = userProcessors . putIfAbsent ( interest , processor ) ; 
+ interest 
} public void sendResponseIfNecessary ( final RemotingContext ctx , byte type , 
final RemotingCommand response ) { 
final int id = response . getId ( ) ; 
if ( type != RpcCommandType . REQUEST_ONEWAY ) { 
RemotingCommand serializedResponse = response ; 
response . serialize ( ) ; 
} catch ( SerializationException e ) { 
+ id ; 
logger . error ( errMsg , e ) ; 
serializedResponse = this . getCommandFactory ( ) . createExceptionResponse ( id , 
ResponseStatus . SERVER_SERIAL_EXCEPTION , e ) ; 
serializedResponse . serialize ( ) ; 
} catch ( SerializationException e1 ) { 
logger . error ( errMsg , t ) ; 
serializedResponse = this . getCommandFactory ( ) 
. createExceptionResponse ( id , t , errMsg ) ; 
ctx . writeAndFlush ( serializedResponse ) . addListener ( new ChannelFutureListener ( ) { 
+ id 
+ RemotingUtil . parseRemoteAddress ( ctx . getChannelContext ( ) 
. channel ( ) ) ) ; 
if ( ! future . isSuccess ( ) ) { 
logger . error ( 
. channel ( ) ) , future . cause ( ) ) ; 
+ RemotingUtil . parseRemoteAddress ( ctx . getChannelContext ( ) . channel ( ) ) ) ; 
} private void dispatchToUserProcessor ( RemotingContext ctx , RpcRequestCommand cmd ) { 
final int id = cmd . getId ( ) ; 
final byte type = cmd . getType ( ) ; 
UserProcessor processor = ctx . getUserProcessor ( cmd . getRequestClass ( ) ) ; 
if ( processor instanceof AsyncUserProcessor ) { 
processor . handleRequest ( processor . preHandleRequest ( ctx , cmd . getRequestObject ( ) ) , 
new RpcAsyncContext ( ctx , cmd , this ) , cmd . getRequestObject ( ) ) ; 
sendResponseIfNecessary ( ctx , type , this . getCommandFactory ( ) 
. createExceptionResponse ( id , ResponseStatus . SERVER_THREADPOOL_BUSY ) ) ; 
. createExceptionResponse ( id , t , errMsg ) ) ; 
Object responseObject = processor 
. handleRequest ( processor . preHandleRequest ( ctx , cmd . getRequestObject ( ) ) , 
cmd . getRequestObject ( ) ) ; 
sendResponseIfNecessary ( ctx , type , 
this . getCommandFactory ( ) . createResponse ( responseObject , cmd ) ) ; 
} private boolean deserializeRequestCommand ( RemotingContext ctx , RpcRequestCommand cmd , int level ) { 
boolean result ; 
cmd . deserialize ( level ) ; 
result = true ; 
} catch ( DeserializationException e ) { 
cmd . getId ( ) , RpcDeserializeLevel . valueOf ( level ) , e ) ; 
sendResponseIfNecessary ( ctx , cmd . getType ( ) , this . getCommandFactory ( ) 
. createExceptionResponse ( cmd . getId ( ) , ResponseStatus . SERVER_DESERIAL_EXCEPTION , e ) ) ; 
result = false ; 
. createExceptionResponse ( cmd . getId ( ) , t , errMsg ) ) ; 
return result ; 
} private void preProcessRemotingContext ( RemotingContext ctx , RpcRequestCommand cmd , 
long currentTimestamp ) { 
ctx . setArriveTimestamp ( cmd . getArriveTime ( ) ) ; 
ctx . setTimeout ( cmd . getTimeout ( ) ) ; 
ctx . setRpcCommandType ( cmd . getType ( ) ) ; 
ctx . getInvokeContext ( ) . putIfAbsent ( InvokeContext . BOLT_PROCESS_WAIT_TIME , 
currentTimestamp - cmd . getArriveTime ( ) ) ; 
} private void timeoutLog ( final RpcRequestCommand cmd , long currentTimestamp , RemotingContext ctx ) { 
. debug ( 
cmd . getId ( ) , currentTimestamp , cmd . getArriveTime ( ) , 
( currentTimestamp - cmd . getArriveTime ( ) ) , cmd . getTimeout ( ) ) ; 
String remoteAddr = "UNKNOWN" ; 
if ( null != ctx ) { 
ChannelHandlerContext channelCtx = ctx . getChannelContext ( ) ; 
Channel channel = channelCtx . channel ( ) ; 
if ( null != channel ) { 
remoteAddr = RemotingUtil . parseRemoteAddress ( channel ) ; 
cmd . getId ( ) , remoteAddr , ( currentTimestamp - cmd . getArriveTime ( ) ) , cmd . getTimeout ( ) ) ; 
} private void debugLog ( RemotingContext ctx , RpcRequestCommand cmd , long currentTimestamp ) { 
RemotingUtil . parseRemoteAddress ( ctx . getChannelContext ( ) . channel ( ) ) ) ; 
logger . debug ( 
public void process ( RemotingContext ctx , T msg , ExecutorService defaultExecutor ) 
throws Exception { 
ProcessTask task = new ProcessTask ( ctx , msg ) ; 
if ( this . getExecutor ( ) != null ) { 
this . getExecutor ( ) . execute ( task ) ; 
defaultExecutor . execute ( task ) ; 
} protected RemotingCommand invokeSync ( final Connection conn , final RemotingCommand request , 
final int timeoutMillis ) throws RemotingException , 
final InvokeFuture future = createInvokeFuture ( request , request . getInvokeContext ( ) ) ; 
conn . addInvokeFuture ( future ) ; 
final int requestId = request . getId ( ) ; 
conn . getChannel ( ) . writeAndFlush ( request ) . addListener ( new ChannelFutureListener ( ) { 
public void operationComplete ( ChannelFuture f ) throws Exception { 
if ( ! f . isSuccess ( ) ) { 
conn . removeInvokeFuture ( requestId ) ; 
future . putResponse ( commandFactory . createSendFailedResponse ( 
conn . getRemoteAddress ( ) , f . cause ( ) ) ) ; 
future . putResponse ( commandFactory . createSendFailedResponse ( conn . getRemoteAddress ( ) , e ) ) ; 
RemotingCommand response = future . waitResponse ( timeoutMillis ) ; 
if ( response == null ) { 
response = this . commandFactory . createTimeoutResponse ( conn . getRemoteAddress ( ) ) ; 
return response ; 
} protected void invokeWithCallback ( final Connection conn , final RemotingCommand request , 
final InvokeCallback invokeCallback , final int timeoutMillis ) { 
final InvokeFuture future = createInvokeFuture ( conn , request , request . getInvokeContext ( ) , 
invokeCallback ) ; 
Timeout timeout = TimerHolder . getTimer ( ) . newTimeout ( new TimerTask ( ) { 
public void run ( Timeout timeout ) throws Exception { 
InvokeFuture future = conn . removeInvokeFuture ( requestId ) ; 
future . putResponse ( commandFactory . createTimeoutResponse ( conn 
. getRemoteAddress ( ) ) ) ; 
} , timeoutMillis , TimeUnit . MILLISECONDS ) ; 
future . addTimeout ( timeout ) ; 
public void operationComplete ( ChannelFuture cf ) throws Exception { 
if ( ! cf . isSuccess ( ) ) { 
InvokeFuture f = conn . removeInvokeFuture ( requestId ) ; 
f . cancelTimeout ( ) ; 
f . putResponse ( commandFactory . createSendFailedResponse ( 
conn . getRemoteAddress ( ) , cf . cause ( ) ) ) ; 
f . tryAsyncExecuteInvokeCallbackAbnormally ( ) ; 
RemotingUtil . parseRemoteAddress ( conn . getChannel ( ) ) , cf . cause ( ) ) ; 
f . putResponse ( commandFactory . createSendFailedResponse ( conn . getRemoteAddress ( ) , e ) ) ; 
RemotingUtil . parseRemoteAddress ( conn . getChannel ( ) ) , e ) ; 
} protected void oneway ( final Connection conn , final RemotingCommand request ) { 
RemotingUtil . parseRemoteAddress ( conn . getChannel ( ) ) , f . cause ( ) ) ; 
if ( null == conn ) { 
} public static ProtocolSwitch create ( int value ) { 
ProtocolSwitch status = new ProtocolSwitch ( ) ; 
status . setBs ( toBitSet ( value ) ) ; 
return status ; 
} public static ProtocolSwitch create ( int [ ] index ) { 
for ( int i = 0 ; i < index . length ; ++ i ) { 
status . turnOn ( index [ i ] ) ; 
} public static byte toByte ( BitSet bs ) { 
int value = 0 ; 
for ( int i = 0 ; i < bs . length ( ) ; ++ i ) { 
if ( bs . get ( i ) ) { 
value += 1 << i ; 
if ( bs . length ( ) > 7 ) { 
return ( byte ) value ; 
} public static BitSet toBitSet ( int value ) { 
if ( value > Byte . MAX_VALUE || value < Byte . MIN_VALUE ) { 
BitSet bs = new BitSet ( ) ; 
int index = 0 ; 
while ( value != 0 ) { 
if ( value % 2 != 0 ) { 
bs . set ( index ) ; 
++ index ; 
value = ( byte ) ( value > > 1 ) ; 
return bs ; 
} protected Connection getConnectionAndInitInvokeContext ( Url url , InvokeContext invokeContext ) 
long start = System . currentTimeMillis ( ) ; 
Connection conn ; 
conn = this . connectionManager . getAndCreateIfAbsent ( url ) ; 
if ( null != invokeContext ) { 
invokeContext . putIfAbsent ( InvokeContext . CLIENT_CONN_CREATETIME , 
( System . currentTimeMillis ( ) - start ) ) ; 
return conn ; 
} public void addReconnectTask ( Url url ) { 
ReconnectTask task = new ReconnectTask ( ) ; 
task . url = url ; 
tasks . add ( task ) ; 
} public void stop ( ) { 
if ( ! this . started ) { 
this . started = false ; 
healConnectionThreads . interrupt ( ) ; 
this . tasks . clear ( ) ; 
this . canceled . clear ( ) ; 
} public void oneway ( final String addr , final Object request , final InvokeContext invokeContext ) 
this . oneway ( url , request , invokeContext ) ; 
RequestCommand requestCommand = ( RequestCommand ) toRemotingCommand ( request , conn , 
invokeContext , - 1 ) ; 
requestCommand . setType ( RpcCommandType . REQUEST_ONEWAY ) ; 
preProcessInvokeContext ( invokeContext , requestCommand , conn ) ; 
super . oneway ( conn , requestCommand ) ; 
return this . invokeSync ( url , request , invokeContext , timeoutMillis ) ; 
RemotingCommand requestCommand = toRemotingCommand ( request , conn , invokeContext , 
ResponseCommand responseCommand = ( ResponseCommand ) super . invokeSync ( conn , requestCommand , 
responseCommand . setInvokeContext ( invokeContext ) ; 
Object responseObject = RpcResponseResolver . resolveResponseObject ( responseCommand , 
RemotingUtil . parseRemoteAddress ( conn . getChannel ( ) ) ) ; 
return responseObject ; 
final int timeoutMillis ) throws RemotingException { 
InvokeFuture future = super . invokeWithFuture ( conn , requestCommand , timeoutMillis ) ; 
return new RpcResponseFuture ( RemotingUtil . parseRemoteAddress ( conn . getChannel ( ) ) , future ) ; 
} public void invokeWithCallback ( String addr , Object request , final InvokeContext invokeContext , 
InvokeCallback invokeCallback , int timeoutMillis ) 
this . invokeWithCallback ( url , request , invokeContext , invokeCallback , timeoutMillis ) ; 
super . invokeWithCallback ( conn , requestCommand , invokeCallback , timeoutMillis ) ; 
} protected RemotingCommand toRemotingCommand ( Object request , Connection conn , 
InvokeContext invokeContext , int timeoutMillis ) 
throws SerializationException { 
RpcRequestCommand command = this . getCommandFactory ( ) . createRequestCommand ( request ) ; 
Object clientCustomSerializer = invokeContext . get ( InvokeContext . BOLT_CUSTOM_SERIALIZER ) ; 
if ( null != clientCustomSerializer ) { 
command . setSerializer ( ( Byte ) clientCustomSerializer ) ; 
} catch ( ClassCastException e ) { 
+ clientCustomSerializer . getClass ( ) . getName ( ) + "]." ) ; 
Boolean crcSwitch = invokeContext . get ( InvokeContext . BOLT_CRC_SWITCH , 
ProtocolSwitch . CRC_SWITCH_DEFAULT_VALUE ) ; 
if ( null != crcSwitch && crcSwitch ) { 
command . setProtocolSwitch ( ProtocolSwitch 
. create ( new int [ ] { ProtocolSwitch . CRC_SWITCH_INDEX } ) ) ; 
command . setTimeout ( timeoutMillis ) ; 
command . setRequestClass ( request . getClass ( ) . getName ( ) ) ; 
command . setInvokeContext ( invokeContext ) ; 
command . serialize ( ) ; 
logDebugInfo ( command ) ; 
return command ; 
public Map < String , List < Connection > > filter ( List < Connection > connections ) { 
List < Connection > serviceOnConnections = new ArrayList < Connection > ( ) ; 
List < Connection > serviceOffConnections = new ArrayList < Connection > ( ) ; 
Map < String , List < Connection > > filteredConnections = new ConcurrentHashMap < String , List < Connection > > ( ) ; 
for ( Connection connection : connections ) { 
String serviceStatus = ( String ) connection . getAttribute ( Configs . CONN_SERVICE_STATUS ) ; 
if ( serviceStatus != null ) { 
if ( connection . isInvokeFutureMapFinish ( ) 
&& ! freshSelectConnections . containsValue ( connection ) ) { 
serviceOffConnections . add ( connection ) ; 
serviceOnConnections . add ( connection ) ; 
filteredConnections . put ( Configs . CONN_SERVICE_STATUS_ON , serviceOnConnections ) ; 
filteredConnections . put ( Configs . CONN_SERVICE_STATUS_OFF , serviceOffConnections ) ; 
return filteredConnections ; 
public void monitor ( Map < String , RunStateRecordedFutureTask < ConnectionPool > > connPools ) { 
if ( null != connPools && ! connPools . isEmpty ( ) ) { 
Iterator < Map . Entry < String , RunStateRecordedFutureTask < ConnectionPool > > > iter = connPools 
. entrySet ( ) . iterator ( ) ; 
Map . Entry < String , RunStateRecordedFutureTask < ConnectionPool > > entry = iter 
. next ( ) ; 
String poolKey = entry . getKey ( ) ; 
ConnectionPool pool = FutureTaskUtil . getFutureTaskResult ( entry . getValue ( ) , 
logger ) ; 
List < Connection > connections = pool . getAll ( ) ; 
Map < String , List < Connection > > filteredConnectons = this . filter ( connections ) ; 
List < Connection > serviceOnConnections = filteredConnectons 
. get ( Configs . CONN_SERVICE_STATUS_ON ) ; 
List < Connection > serviceOffConnections = filteredConnectons 
. get ( Configs . CONN_SERVICE_STATUS_OFF ) ; 
if ( serviceOnConnections . size ( ) > CONNECTION_THRESHOLD ) { 
Connection freshSelectConnect = serviceOnConnections . get ( random 
. nextInt ( serviceOnConnections . size ( ) ) ) ; 
freshSelectConnect . setAttribute ( Configs . CONN_SERVICE_STATUS , 
Configs . CONN_SERVICE_STATUS_OFF ) ; 
Connection lastSelectConnect = freshSelectConnections . remove ( poolKey ) ; 
freshSelectConnections . put ( poolKey , freshSelectConnect ) ; 
closeFreshSelectConnections ( lastSelectConnect , serviceOffConnections ) ; 
if ( freshSelectConnections . containsKey ( poolKey ) ) { 
serviceOnConnections . size ( ) , CONNECTION_THRESHOLD ) ; 
for ( Connection offConn : serviceOffConnections ) { 
if ( offConn . isFine ( ) ) { 
offConn . close ( ) ; 
} private void closeFreshSelectConnections ( Connection lastSelectConnect , 
List < Connection > serviceOffConnections ) 
throws InterruptedException { 
if ( null != lastSelectConnect ) { 
if ( lastSelectConnect . isInvokeFutureMapFinish ( ) ) { 
serviceOffConnections . add ( lastSelectConnect ) ; 
Thread . sleep ( RETRY_DETECT_PERIOD ) ; 
RemotingUtil . parseRemoteAddress ( lastSelectConnect . getChannel ( ) ) ) ; 
} private void handle ( final RemotingContext ctx , final Object msg ) { 
if ( msg instanceof List ) { 
final Runnable handleTask = new Runnable ( ) { 
for ( final Object m : ( List < ? > ) msg ) { 
RpcCommandHandler . this . process ( ctx , m ) ; 
} ; 
if ( RpcConfigManager . dispatch_msg_list_in_default_executor ( ) ) { 
processorManager . getDefaultExecutor ( ) . execute ( handleTask ) ; 
handleTask . run ( ) ; 
process ( ctx , msg ) ; 
} catch ( final Throwable t ) { 
processException ( ctx , msg , t ) ; 
} private void processExceptionForSingleCommand ( RemotingContext ctx , Object msg , Throwable t ) { 
final int id = ( ( RpcCommand ) msg ) . getId ( ) ; 
logger . warn ( emsg + id , t ) ; 
if ( msg instanceof RequestCommand ) { 
final RequestCommand cmd = ( RequestCommand ) msg ; 
if ( cmd . getType ( ) != RpcCommandType . REQUEST_ONEWAY ) { 
if ( t instanceof RejectedExecutionException ) { 
final ResponseCommand response = this . commandFactory . createExceptionResponse ( 
id , ResponseStatus . SERVER_THREADPOOL_BUSY ) ; 
ctx . getChannelContext ( ) . writeAndFlush ( response ) 
. addListener ( new ChannelFutureListener ( ) { 
if ( future . isSuccess ( ) ) { 
id , response . getResponseStatus ( ) ) ; 
future . cause ( ) ) ; 
} public static boolean getBool ( String key , String defaultValue ) { 
return Boolean . parseBoolean ( System . getProperty ( key , defaultValue ) ) ; 
} public void deserialize ( long mask ) throws DeserializationException { 
if ( mask <= RpcDeserializeLevel . DESERIALIZE_CLAZZ ) { 
this . deserializeClazz ( ) ; 
} else if ( mask <= RpcDeserializeLevel . DESERIALIZE_HEADER ) { 
this . deserializeHeader ( this . getInvokeContext ( ) ) ; 
} else if ( mask <= RpcDeserializeLevel . DESERIALIZE_ALL ) { 
this . deserialize ( ) ; 
} public CustomSerializer getCustomSerializer ( ) { 
if ( this . customSerializer != null ) { 
return customSerializer ; 
if ( this . requestClass != null ) { 
this . customSerializer = CustomSerializerManager . getCustomSerializer ( this . requestClass ) ; 
if ( this . customSerializer == null ) { 
this . customSerializer = CustomSerializerManager . getCustomSerializer ( this . getCmdCode ( ) ) ; 
return this . customSerializer ; 
} public void setConnectionEventListener ( ConnectionEventListener listener ) { 
if ( listener != null ) { 
this . eventListener = listener ; 
if ( this . eventExecutor == null ) { 
this . eventExecutor = new ConnectionEventExecutor ( ) ; 
} private void infoLog ( String format , String addr ) { 
if ( StringUtils . isNotEmpty ( addr ) ) { 
logger . info ( format , addr ) ; 
logger . info ( format , "UNKNOWN-ADDR" ) ; 
} public boolean isRequestTimeout ( ) { 
if ( this . timeout > 0 && ( this . rpcCommandType != RpcCommandType . REQUEST_ONEWAY ) 
&& ( System . currentTimeMillis ( ) - this . arriveTimestamp ) > this . timeout ) { 
} public UserProcessor < ? > getUserProcessor ( String className ) { 
return StringUtils . isBlank ( className ) ? null : this . userProcessors . get ( className ) ; 
} private Connection randomGet ( List < Connection > conns ) { 
if ( null == conns || conns . isEmpty ( ) ) { 
int size = conns . size ( ) ; 
int tries = 0 ; 
Connection result = null ; 
while ( ( result == null || ! result . isFine ( ) ) && tries ++ < MAX_TIMES ) { 
result = conns . get ( this . random . nextInt ( size ) ) ; 
if ( result != null && ! result . isFine ( ) ) { 
result = null ; 
if ( this . responseClass != null ) { 
this . customSerializer = CustomSerializerManager . getCustomSerializer ( this . responseClass ) ; 
public < T > T get ( String key ) { 
return ( T ) this . context . get ( key ) ; 
public < T > T get ( String key , T defaultIfNotFound ) { 
return this . context . get ( key ) != null ? ( T ) this . context . get ( key ) : defaultIfNotFound ; 
} public String getProperty ( String key ) { 
if ( properties == null ) { 
return properties . getProperty ( key ) ; 
} public static final int crc32 ( byte [ ] array , int offset , int length ) { 
CRC32 crc32 = CRC_32_THREAD_LOCAL . get ( ) ; 
crc32 . update ( array , offset , length ) ; 
int ret = ( int ) crc32 . getValue ( ) ; 
crc32 . reset ( ) ; 
return ret ; 
} public static Object resolveResponseObject ( ResponseCommand responseCommand , String addr ) 
preProcess ( responseCommand , addr ) ; 
if ( responseCommand . getResponseStatus ( ) == ResponseStatus . SUCCESS ) { 
return toResponseObject ( responseCommand ) ; 
responseCommand . getResponseStatus ( ) , addr , responseCommand . getId ( ) ) ; 
logger . warn ( msg ) ; 
if ( responseCommand . getCause ( ) != null ) { 
throw new InvokeException ( msg , responseCommand . getCause ( ) ) ; 
} private static Object toResponseObject ( ResponseCommand responseCommand ) throws CodecException { 
RpcResponseCommand response = ( RpcResponseCommand ) responseCommand ; 
response . deserialize ( ) ; 
return response . getResponseObject ( ) ; 
} private static Throwable toThrowable ( ResponseCommand responseCommand ) throws CodecException { 
RpcResponseCommand resp = ( RpcResponseCommand ) responseCommand ; 
resp . deserialize ( ) ; 
Object ex = resp . getResponseObject ( ) ; 
if ( ex != null && ex instanceof Throwable ) { 
return ( Throwable ) ex ; 
} private static String detailErrMsg ( String clientErrMsg , ResponseCommand responseCommand ) { 
if ( StringUtils . isNotBlank ( resp . getErrorMsg ( ) ) ) { 
} private RpcServerException createServerException ( Throwable t , String errMsg ) { 
String formattedErrMsg = String . format ( 
t . getMessage ( ) , errMsg ) ; 
RpcServerException e = new RpcServerException ( formattedErrMsg ) ; 
e . setStackTrace ( t . getStackTrace ( ) ) ; 
} public static void printConnectionTraceLog ( Logger logger , String traceId , 
InvokeContext invokeContext ) { 
String sourceIp = invokeContext . get ( InvokeContext . CLIENT_LOCAL_IP ) ; 
Integer sourcePort = invokeContext . get ( InvokeContext . CLIENT_LOCAL_PORT ) ; 
String targetIp = invokeContext . get ( InvokeContext . CLIENT_REMOTE_IP ) ; 
Integer targetPort = invokeContext . get ( InvokeContext . CLIENT_REMOTE_PORT ) ; 
StringBuilder logMsg = new StringBuilder ( ) ; 
logMsg . append ( traceId ) . append ( "," ) ; 
logMsg . append ( sourceIp ) . append ( "," ) ; 
logMsg . append ( sourcePort ) . append ( "," ) ; 
logMsg . append ( targetIp ) . append ( "," ) ; 
logMsg . append ( targetPort ) ; 
logger . info ( logMsg . toString ( ) ) ; 
} public static EventLoopGroup newEventLoopGroup ( int nThreads , ThreadFactory threadFactory ) { 
return epollEnabled ? new EpollEventLoopGroup ( nThreads , threadFactory ) 
: new NioEventLoopGroup ( nThreads , threadFactory ) ; 
} public static void enableTriggeredMode ( ServerBootstrap serverBootstrap ) { 
if ( epollEnabled ) { 
if ( ConfigManager . netty_epoll_lt_enabled ( ) ) { 
serverBootstrap . childOption ( EpollChannelOption . EPOLL_MODE , 
EpollMode . LEVEL_TRIGGERED ) ; 
serverBootstrap 
. childOption ( EpollChannelOption . EPOLL_MODE , EpollMode . EDGE_TRIGGERED ) ; 
scheduledService . scheduleWithFixedDelay ( new Runnable ( ) { 
for ( Scannable scanned : scanList ) { 
scanned . scan ( ) ; 
} , 10000 , 10000 , TimeUnit . MILLISECONDS ) ; 
} public static String parseRemoteAddress ( final Channel channel ) { 
if ( null == channel ) { 
return StringUtils . EMPTY ; 
final SocketAddress remote = channel . remoteAddress ( ) ; 
return doParse ( remote != null ? remote . toString ( ) . trim ( ) : StringUtils . EMPTY ) ; 
} public static String parseLocalAddress ( final Channel channel ) { 
final SocketAddress local = channel . localAddress ( ) ; 
return doParse ( local != null ? local . toString ( ) . trim ( ) : StringUtils . EMPTY ) ; 
} public static String parseRemoteIP ( final Channel channel ) { 
final InetSocketAddress remote = ( InetSocketAddress ) channel . remoteAddress ( ) ; 
if ( remote != null ) { 
return remote . getAddress ( ) . getHostAddress ( ) ; 
} public static String parseRemoteHostName ( final Channel channel ) { 
return remote . getAddress ( ) . getHostName ( ) ; 
} public static String parseLocalIP ( final Channel channel ) { 
final InetSocketAddress local = ( InetSocketAddress ) channel . localAddress ( ) ; 
if ( local != null ) { 
return local . getAddress ( ) . getHostAddress ( ) ; 
} public static int parseRemotePort ( final Channel channel ) { 
return - 1 ; 
return remote . getPort ( ) ; 
} public static int parseLocalPort ( final Channel channel ) { 
return local . getPort ( ) ; 
} public static String parseSocketAddressToString ( SocketAddress socketAddress ) { 
if ( socketAddress != null ) { 
return doParse ( socketAddress . toString ( ) . trim ( ) ) ; 
} public static String parseSocketAddressToHostIp ( SocketAddress socketAddress ) { 
final InetSocketAddress addrs = ( InetSocketAddress ) socketAddress ; 
if ( addrs != null ) { 
InetAddress addr = addrs . getAddress ( ) ; 
if ( null != addr ) { 
return addr . getHostAddress ( ) ; 
} private static String doParse ( String addr ) { 
if ( StringUtils . isBlank ( addr ) ) { 
if ( addr . charAt ( 0 ) == '/' ) { 
return addr . substring ( 1 ) ; 
int len = addr . length ( ) ; 
for ( int i = 1 ; i < len ; ++ i ) { 
if ( addr . charAt ( i ) == '/' ) { 
return addr . substring ( i + 1 ) ; 
return addr ; 
} public void add ( Connection connection ) { 
markAccess ( ) ; 
if ( null == connection ) { 
boolean res = this . conns . addIfAbsent ( connection ) ; 
if ( res ) { 
connection . increaseRef ( ) ; 
} public void removeAndTryClose ( Connection connection ) { 
boolean res = this . conns . remove ( connection ) ; 
connection . decreaseRef ( ) ; 
if ( connection . noRef ( ) ) { 
connection . close ( ) ; 
} public Connection get ( ) { 
if ( null != this . conns ) { 
List < Connection > snapshot = new ArrayList < Connection > ( this . conns ) ; 
if ( snapshot . size ( ) > 0 ) { 
return this . strategy . select ( snapshot ) ; 
} public static void registerCustomSerializer ( String className , CustomSerializer serializer ) { 
CustomSerializer prevSerializer = classCustomSerializer . putIfAbsent ( className , serializer ) ; 
if ( prevSerializer != null ) { 
+ prevSerializer . getClass ( ) . getName ( ) ) ; 
} public static CustomSerializer getCustomSerializer ( String className ) { 
if ( ! classCustomSerializer . isEmpty ( ) ) { 
return classCustomSerializer . get ( className ) ; 
} public static void registerCustomSerializer ( CommandCode code , CustomSerializer serializer ) { 
CustomSerializer prevSerializer = commandCustomSerializer . putIfAbsent ( code , serializer ) ; 
} public static CustomSerializer getCustomSerializer ( CommandCode code ) { 
if ( ! commandCustomSerializer . isEmpty ( ) ) { 
return commandCustomSerializer . get ( code ) ; 
long initialDelay = ConfigManager . conn_monitor_initial_delay ( ) ; 
long period = ConfigManager . conn_monitor_period ( ) ; 
this . executor = new ScheduledThreadPoolExecutor ( 1 , new NamedThreadFactory ( 
"ConnectionMonitorThread" , true ) , new ThreadPoolExecutor . AbortPolicy ( ) ) ; 
MonitorTask monitorTask = new MonitorTask ( ) ; 
this . executor . scheduleAtFixedRate ( monitorTask , initialDelay , period , TimeUnit . MILLISECONDS ) ; 
protected boolean doStop ( ) { 
if ( null != this . channelFuture ) { 
this . channelFuture . channel ( ) . close ( ) ; 
if ( this . switches ( ) . isOn ( GlobalSwitch . SERVER_SYNC_STOP ) ) { 
this . bossGroup . shutdownGracefully ( ) . awaitUninterruptibly ( ) ; 
this . bossGroup . shutdownGracefully ( ) ; 
if ( this . switches ( ) . isOn ( GlobalSwitch . SERVER_MANAGE_CONNECTION_SWITCH ) 
&& null != this . connectionManager ) { 
check ( ) ; 
this . rpcRemoting . oneway ( addr , request , invokeContext ) ; 
} public void oneway ( final Url url , final Object request ) throws RemotingException , 
this . rpcRemoting . oneway ( url , request , null ) ; 
} public void oneway ( final Url url , final Object request , final InvokeContext invokeContext ) 
this . rpcRemoting . oneway ( url , request , invokeContext ) ; 
} public RpcResponseFuture invokeWithFuture ( final String addr , final Object request , 
return this . rpcRemoting . invokeWithFuture ( addr , request , null , timeoutMillis ) ; 
return this . rpcRemoting . invokeWithFuture ( addr , request , invokeContext , timeoutMillis ) ; 
} public RpcResponseFuture invokeWithFuture ( final Url url , final Object request , 
return this . rpcRemoting . invokeWithFuture ( url , request , null , timeoutMillis ) ; 
return this . rpcRemoting . invokeWithFuture ( url , request , invokeContext , timeoutMillis ) ; 
return this . rpcRemoting . invokeWithFuture ( conn , request , invokeContext , timeoutMillis ) ; 
} public void invokeWithCallback ( final String addr , final Object request , 
this . rpcRemoting . invokeWithCallback ( addr , request , null , invokeCallback , timeoutMillis ) ; 
} public boolean isConnected ( String remoteAddr ) { 
Url url = this . rpcRemoting . addressParser . parse ( remoteAddr ) ; 
return this . isConnected ( url ) ; 
} public boolean isConnected ( Url url ) { 
Connection conn = this . rpcRemoting . connectionManager . get ( url . getUniqueKey ( ) ) ; 
if ( null != conn ) { 
return conn . isFine ( ) ; 
} private void initWriteBufferWaterMark ( ) { 
int lowWaterMark = this . netty_buffer_low_watermark ( ) ; 
int highWaterMark = this . netty_buffer_high_watermark ( ) ; 
if ( lowWaterMark > highWaterMark ) { 
String 
. format ( 
highWaterMark , lowWaterMark ) ) ; 
logger . warn ( 
lowWaterMark , highWaterMark ) ; 
this . bootstrap . childOption ( ChannelOption . WRITE_BUFFER_WATER_MARK , new WriteBufferWaterMark ( 
lowWaterMark , highWaterMark ) ) ; 
} public UnsafeBuffer [ ] duplicateTermBuffers ( ) 
{ 
final UnsafeBuffer [ ] buffers = new UnsafeBuffer [ PARTITION_COUNT ] ; 
for ( int i = 0 ; i < PARTITION_COUNT ; i ++ ) 
buffers [ i ] = new UnsafeBuffer ( termBuffers [ i ] . duplicate ( ) . order ( ByteOrder . LITTLE_ENDIAN ) ) ; 
return buffers ; 
} public static void main ( final String [ ] args ) 
loadPropertiesFiles ( args ) ; 
try ( ClusteredServiceContainer container = launch ( ) ) 
container . context ( ) . shutdownSignalBarrier ( ) . await ( ) ; 
} public static AtomicCounter allocate ( 
final MutableDirectBuffer tempBuffer , 
final String name , 
final CountersManager countersManager , 
final long registrationId , 
final int sessionId , 
final int streamId , 
final String channel ) 
final int counterId = StreamCounter . allocateCounterId ( 
tempBuffer , name , PER_IMAGE_TYPE_ID , countersManager , registrationId , sessionId , streamId , channel ) ; 
return new AtomicCounter ( countersManager . valuesBuffer ( ) , counterId , countersManager ) ; 
} public void run ( ) 
do 
LockSupport . parkNanos ( parkNs ) ; 
final long currentTotalMessages = totalMessages ; 
final long currentTotalBytes = totalBytes ; 
final long currentTimestamp = System . nanoTime ( ) ; 
final long timeSpanNs = currentTimestamp - lastTimestamp ; 
final double messagesPerSec = 
( ( currentTotalMessages - lastTotalMessages ) * ( double ) reportIntervalNs ) / ( double ) timeSpanNs ; 
final double bytesPerSec = 
( ( currentTotalBytes - lastTotalBytes ) * ( double ) reportIntervalNs ) / ( double ) timeSpanNs ; 
reportingFunc . onReport ( messagesPerSec , bytesPerSec , currentTotalMessages , currentTotalBytes ) ; 
lastTotalBytes = currentTotalBytes ; 
lastTotalMessages = currentTotalMessages ; 
lastTimestamp = currentTimestamp ; 
while ( ! halt ) ; 
} public static FragmentHandler rateReporterHandler ( final RateReporter reporter ) 
return ( buffer , offset , length , header ) -> reporter . onMessage ( 1 , length ) ; 
} @ SuppressWarnings ( "unused" ) 
public static void printError ( 
final String channel , 
final String message , 
final HeaderFlyweight cause ) 
System . out . println ( message ) ; 
} public static void printRate ( 
final double messagesPerSec , 
final double bytesPerSec , 
final long totalMessages , 
final long totalBytes ) 
System . out . println ( String . format ( 
messagesPerSec , bytesPerSec , totalMessages , totalBytes / ( 1024 * 1024 ) ) ) ; 
} public static MappedByteBuffer mapExistingFileReadOnly ( final File location ) 
if ( ! location . exists ( ) ) 
throw new IllegalStateException ( msg ) ; 
MappedByteBuffer mappedByteBuffer = null ; 
try ( RandomAccessFile file = new RandomAccessFile ( location , "r" ) ; 
FileChannel channel = file . getChannel ( ) ) 
mappedByteBuffer = channel . map ( READ_ONLY , 0 , channel . size ( ) ) ; 
catch ( final IOException ex ) 
LangUtil . rethrowUnchecked ( ex ) ; 
return mappedByteBuffer ; 
} public void close ( ) 
final State state = this . state ; 
if ( State . CLOSED != state ) 
if ( isReplayActive ) 
isReplayActive = false ; 
archive . stopReplay ( replaySessionId ) ; 
if ( State . MERGED != state ) 
subscription . removeDestination ( replayDestination ) ; 
state ( State . CLOSED ) ; 
} public int doWork ( ) 
int workCount = 0 ; 
switch ( state ) 
case AWAIT_INITIAL_RECORDING_POSITION : 
workCount += awaitInitialRecordingPosition ( ) ; 
case AWAIT_REPLAY : 
workCount += awaitReplay ( ) ; 
case AWAIT_CATCH_UP : 
workCount += awaitCatchUp ( ) ; 
case AWAIT_CURRENT_RECORDING_POSITION : 
workCount += awaitUpdatedRecordingPosition ( ) ; 
case AWAIT_STOP_REPLAY : 
workCount += awaitStopReplay ( ) ; 
return workCount ; 
} public int poll ( final FragmentHandler fragmentHandler , final int fragmentLimit ) 
doWork ( ) ; 
return null == image ? 0 : image . poll ( fragmentHandler , fragmentLimit ) ; 
} public long position ( ) 
if ( isClosed ) 
return CLOSED ; 
final long rawTail = rawTailVolatile ( logMetaDataBuffer ) ; 
final int termOffset = termOffset ( rawTail , termBufferLength ) ; 
return computePosition ( termId ( rawTail ) , termOffset , positionBitsToShift , initialTermId ) ; 
} public final long offer ( final DirectBuffer buffer , final int offset , final int length ) 
return offer ( buffer , offset , length , null ) ; 
} public final long offer ( 
final DirectBuffer bufferOne , 
final int offsetOne , 
final int lengthOne , 
final DirectBuffer bufferTwo , 
final int offsetTwo , 
final int lengthTwo ) 
return offer ( bufferOne , offsetOne , lengthOne , bufferTwo , offsetTwo , lengthTwo , null ) ; 
} public long offer ( 
final DirectBuffer buffer , 
final int offset , 
final int length , 
final ReservedValueSupplier reservedValueSupplier ) 
long newPosition = CLOSED ; 
if ( ! isClosed ) 
final long limit = positionLimit . getVolatile ( ) ; 
final ExclusiveTermAppender termAppender = termAppenders [ activePartitionIndex ] ; 
final long position = termBeginPosition + termOffset ; 
if ( position < limit ) 
final int result ; 
if ( length <= maxPayloadLength ) 
checkPositiveLength ( length ) ; 
result = termAppender . appendUnfragmentedMessage ( 
termId , termOffset , headerWriter , buffer , offset , length , reservedValueSupplier ) ; 
else 
checkMaxMessageLength ( length ) ; 
result = termAppender . appendFragmentedMessage ( 
termId , 
termOffset , 
headerWriter , 
buffer , 
offset , 
length , 
maxPayloadLength , 
reservedValueSupplier ) ; 
newPosition = newPosition ( result ) ; 
newPosition = backPressureStatus ( position , length ) ; 
return newPosition ; 
final int lengthTwo , 
final int length = validateAndComputeLength ( lengthOne , lengthTwo ) ; 
bufferOne , offsetOne , lengthOne , 
bufferTwo , offsetTwo , lengthTwo , 
} public long offer ( final DirectBufferVector [ ] vectors , final ReservedValueSupplier reservedValueSupplier ) 
final int length = DirectBufferVector . validateAndComputeLength ( vectors ) ; 
termId , termOffset , headerWriter , vectors , length , reservedValueSupplier ) ; 
vectors , 
} public long tryClaim ( final int length , final BufferClaim bufferClaim ) 
checkPayloadLength ( length ) ; 
final int result = termAppender . claim ( termId , termOffset , headerWriter , length , bufferClaim ) ; 
} public long appendPadding ( final int length ) 
final int result = termAppender . appendPadding ( termId , termOffset , headerWriter , length ) ; 
} public DestinationMessageFlyweight channel ( final String channel ) 
lengthOfChannel = buffer . putStringAscii ( offset + CHANNEL_OFFSET , channel ) ; 
lock . lock ( ) ; 
try 
isClosed = true ; 
archiveProxy . closeSession ( controlSessionId ) ; 
if ( ! context . ownsAeronClient ( ) ) 
CloseHelper . close ( controlResponsePoller . subscription ( ) ) ; 
CloseHelper . close ( archiveProxy . publication ( ) ) ; 
context . close ( ) ; 
finally 
lock . unlock ( ) ; 
} public static AeronArchive connect ( final Context ctx ) 
Subscription subscription = null ; 
Publication publication = null ; 
AsyncConnect asyncConnect = null ; 
ctx . conclude ( ) ; 
final Aeron aeron = ctx . aeron ( ) ; 
final long messageTimeoutNs = ctx . messageTimeoutNs ( ) ; 
final long deadlineNs = aeron . context ( ) . nanoClock ( ) . nanoTime ( ) + messageTimeoutNs ; 
subscription = aeron . addSubscription ( ctx . controlResponseChannel ( ) , ctx . controlResponseStreamId ( ) ) ; 
final ControlResponsePoller controlResponsePoller = new ControlResponsePoller ( subscription ) ; 
publication = aeron . addExclusivePublication ( ctx . controlRequestChannel ( ) , ctx . controlRequestStreamId ( ) ) ; 
final ArchiveProxy archiveProxy = new ArchiveProxy ( 
publication , ctx . idleStrategy ( ) , aeron . context ( ) . nanoClock ( ) , messageTimeoutNs , DEFAULT_RETRY_ATTEMPTS ) ; 
asyncConnect = new AsyncConnect ( ctx , controlResponsePoller , archiveProxy , deadlineNs ) ; 
final IdleStrategy idleStrategy = ctx . idleStrategy ( ) ; 
final AgentInvoker aeronClientInvoker = aeron . conductorAgentInvoker ( ) ; 
AeronArchive aeronArchive ; 
while ( null == ( aeronArchive = asyncConnect . poll ( ) ) ) 
if ( null != aeronClientInvoker ) 
aeronClientInvoker . invoke ( ) ; 
idleStrategy . idle ( ) ; 
return aeronArchive ; 
catch ( final Exception ex ) 
if ( ! ctx . ownsAeronClient ( ) ) 
CloseHelper . quietClose ( subscription ) ; 
CloseHelper . quietClose ( publication ) ; 
CloseHelper . quietClose ( asyncConnect ) ; 
ctx . close ( ) ; 
throw ex ; 
} public static AsyncConnect asyncConnect ( final Context ctx ) 
return new AsyncConnect ( ctx , controlResponsePoller , archiveProxy , deadlineNs ) ; 
} public String pollForErrorResponse ( ) 
ensureOpen ( ) ; 
if ( controlResponsePoller . poll ( ) != 0 && controlResponsePoller . isPollComplete ( ) ) 
if ( controlResponsePoller . controlSessionId ( ) == controlSessionId && 
controlResponsePoller . templateId ( ) == ControlResponseDecoder . TEMPLATE_ID && 
controlResponsePoller . code ( ) == ControlResponseCode . ERROR ) 
return controlResponsePoller . errorMessage ( ) ; 
} public void checkForErrorResponse ( ) 
final ArchiveException ex = new ArchiveException ( 
controlResponsePoller . errorMessage ( ) , ( int ) controlResponsePoller . relevantId ( ) ) ; 
if ( null != context . errorHandler ( ) ) 
context . errorHandler ( ) . onError ( ex ) ; 
} public Publication addRecordedPublication ( final String channel , final int streamId ) 
publication = aeron . addPublication ( channel , streamId ) ; 
if ( ! publication . isOriginal ( ) ) 
throw new ArchiveException ( 
startRecording ( ChannelUri . addSessionId ( channel , publication . sessionId ( ) ) , streamId , SourceLocation . LOCAL ) ; 
catch ( final RuntimeException ex ) 
return publication ; 
} public ExclusivePublication addRecordedExclusivePublication ( final String channel , final int streamId ) 
ExclusivePublication publication = null ; 
publication = aeron . addExclusivePublication ( channel , streamId ) ; 
} public long startRecording ( final String channel , final int streamId , final SourceLocation sourceLocation ) 
final long correlationId = aeron . nextCorrelationId ( ) ; 
if ( ! archiveProxy . startRecording ( channel , streamId , sourceLocation , correlationId , controlSessionId ) ) 
return pollForResponse ( correlationId ) ; 
} public void stopRecording ( final String channel , final int streamId ) 
if ( ! archiveProxy . stopRecording ( channel , streamId , correlationId , controlSessionId ) ) 
pollForResponse ( correlationId ) ; 
} public void stopRecording ( final Publication publication ) 
final String recordingChannel = ChannelUri . addSessionId ( publication . channel ( ) , publication . sessionId ( ) ) ; 
stopRecording ( recordingChannel , publication . streamId ( ) ) ; 
} public void stopRecording ( final long subscriptionId ) 
if ( ! archiveProxy . stopRecording ( subscriptionId , correlationId , controlSessionId ) ) 
} public long startReplay ( 
final long recordingId , 
final long position , 
final long length , 
final String replayChannel , 
final int replayStreamId ) 
if ( ! archiveProxy . replay ( 
recordingId , 
position , 
replayChannel , 
replayStreamId , 
correlationId , 
controlSessionId ) ) 
} public void stopReplay ( final long replaySessionId ) 
if ( ! archiveProxy . stopReplay ( replaySessionId , correlationId , controlSessionId ) ) 
} public Subscription replay ( 
final ChannelUri replayChannelUri = ChannelUri . parse ( replayChannel ) ; 
final int replaySessionId = ( int ) pollForResponse ( correlationId ) ; 
replayChannelUri . put ( CommonContext . SESSION_ID_PARAM_NAME , Integer . toString ( replaySessionId ) ) ; 
return aeron . addSubscription ( replayChannelUri . toString ( ) , replayStreamId ) ; 
} public int listRecordings ( 
final long fromRecordingId , final int recordCount , final RecordingDescriptorConsumer consumer ) 
if ( ! archiveProxy . listRecordings ( fromRecordingId , recordCount , correlationId , controlSessionId ) ) 
return pollForDescriptors ( correlationId , recordCount , consumer ) ; 
} public int listRecordingsForUri ( 
final long fromRecordingId , 
final int recordCount , 
final String channelFragment , 
final RecordingDescriptorConsumer consumer ) 
if ( ! archiveProxy . listRecordingsForUri ( 
fromRecordingId , 
recordCount , 
channelFragment , 
streamId , 
} public int listRecording ( final long recordingId , final RecordingDescriptorConsumer consumer ) 
if ( ! archiveProxy . listRecording ( recordingId , correlationId , controlSessionId ) ) 
return pollForDescriptors ( correlationId , 1 , consumer ) ; 
} public long getRecordingPosition ( final long recordingId ) 
if ( ! archiveProxy . getRecordingPosition ( recordingId , correlationId , controlSessionId ) ) 
} public long findLastMatchingRecording ( 
final long minRecordingId , final String channelFragment , final int streamId , final int sessionId ) 
if ( ! archiveProxy . findLastMatchingRecording ( 
minRecordingId , channelFragment , streamId , sessionId , correlationId , controlSessionId ) ) 
} public void truncateRecording ( final long recordingId , final long position ) 
if ( ! archiveProxy . truncateRecording ( recordingId , position , correlationId , controlSessionId ) ) 
} public int listRecordingSubscriptions ( 
final int pseudoIndex , 
final int subscriptionCount , 
final boolean applyStreamId , 
final RecordingSubscriptionDescriptorConsumer consumer ) 
if ( ! archiveProxy . listRecordingSubscriptions ( 
pseudoIndex , 
subscriptionCount , 
applyStreamId , 
return pollForSubscriptionDescriptors ( correlationId , subscriptionCount , consumer ) ; 
} public static void dumpSegment ( final PrintStream out , final int messageDumpLimit , final UnsafeBuffer buffer ) 
final DataHeaderFlyweight dataHeaderFlyweight = new DataHeaderFlyweight ( ) ; 
final int length = buffer . capacity ( ) ; 
int offset = 0 ; 
while ( offset < length ) 
dataHeaderFlyweight . wrap ( buffer , offset , length - offset ) ; 
final int frameLength = dataHeaderFlyweight . frameLength ( ) ; 
if ( frameLength < DataHeaderFlyweight . HEADER_LENGTH ) 
final int limit = min ( frameLength - HEADER_LENGTH , messageDumpLimit ) ; 
out . println ( LogInspector . formatBytes ( buffer , offset + HEADER_LENGTH , limit ) ) ; 
offset += BitUtil . align ( frameLength , FrameDescriptor . FRAME_ALIGNMENT ) ; 
} public static void eventAvailableImage ( final Image image ) 
final Subscription subscription = image . subscription ( ) ; 
System . out . format ( 
subscription . channel ( ) , subscription . streamId ( ) , image . sessionId ( ) , image . sourceIdentity ( ) ) ; 
} public static void eventUnavailableImage ( final Image image ) 
subscription . channel ( ) , subscription . streamId ( ) , image . sessionId ( ) ) ; 
} public static FragmentHandler reassembledStringMessage1 ( final int streamId ) 
return ( buffer , offset , length , header ) -> 
final byte [ ] data = new byte [ length ] ; 
buffer . getBytes ( offset , data ) ; 
streamId , header . sessionId ( ) , header . termId ( ) , header . termOffset ( ) , length , offset ) ; 
if ( length != 10000 ) 
length ) ; 
} public static StatusIndicator controllableIdleStrategy ( final CountersReader countersReader ) 
StatusIndicator statusIndicator = null ; 
final MutableInteger id = new MutableInteger ( - 1 ) ; 
countersReader . forEach ( 
( counterId , label ) -> 
if ( counterId == SystemCounterDescriptor . CONTROLLABLE_IDLE_STRATEGY . id ( ) && 
label . equals ( SystemCounterDescriptor . CONTROLLABLE_IDLE_STRATEGY . label ( ) ) ) 
id . value = counterId ; 
if ( Aeron . NULL_VALUE != id . value ) 
statusIndicator = new UnsafeBufferStatusIndicator ( countersReader . valuesBuffer ( ) , id . value ) ; 
return statusIndicator ; 
} public static StatusIndicatorReader sendChannelStatus ( final CountersReader countersReader , final String channel ) 
StatusIndicatorReader statusReader = null ; 
( counterId , typeId , keyBuffer , label ) -> 
if ( typeId == SendChannelStatus . SEND_CHANNEL_STATUS_TYPE_ID ) 
if ( channel . startsWith ( keyBuffer . getStringAscii ( ChannelEndpointStatus . CHANNEL_OFFSET ) ) ) 
statusReader = new UnsafeBufferStatusIndicator ( countersReader . valuesBuffer ( ) , id . value ) ; 
return statusReader ; 
} public static StatusIndicatorReader receiveChannelStatus ( final CountersReader countersReader , final String channel ) 
if ( typeId == ReceiveChannelStatus . RECEIVE_CHANNEL_STATUS_TYPE_ID ) 
} public void limit ( final int limit ) 
if ( limit < 0 || limit >= buffer . capacity ( ) ) 
this . limit = limit ; 
} public BufferBuilder append ( final DirectBuffer srcBuffer , final int srcOffset , final int length ) 
ensureCapacity ( length ) ; 
buffer . putBytes ( limit , srcBuffer , srcOffset , length ) ; 
limit += length ; 
} public int poll ( ) 
controlSessionId = - 1 ; 
correlationId = - 1 ; 
relevantId = - 1 ; 
templateId = - 1 ; 
errorMessage = null ; 
pollComplete = false ; 
return subscription . controlledPoll ( fragmentAssembler , fragmentLimit ) ; 
} public static MappedByteBuffer mapLossReport ( final String aeronDirectoryName , final int reportFileLength ) 
return mapNewFile ( file ( aeronDirectoryName ) , reportFileLength , false ) ; 
} public Action onFragment ( final DirectBuffer buffer , final int offset , final int length , final Header header ) 
final byte flags = header . flags ( ) ; 
Action action = Action . CONTINUE ; 
if ( ( flags & UNFRAGMENTED ) == UNFRAGMENTED ) 
action = delegate . onFragment ( buffer , offset , length , header ) ; 
if ( ( flags & BEGIN_FRAG_FLAG ) == BEGIN_FRAG_FLAG ) 
builder . reset ( ) . append ( buffer , offset , length ) ; 
final int limit = builder . limit ( ) ; 
builder . append ( buffer , offset , length ) ; 
if ( ( flags & END_FRAG_FLAG ) == END_FRAG_FLAG ) 
final int msgLength = builder . limit ( ) ; 
action = delegate . onFragment ( builder . buffer ( ) , 0 , msgLength , header ) ; 
if ( Action . ABORT == action ) 
builder . limit ( limit ) ; 
builder . reset ( ) ; 
return action ; 
} public Map < StreamCompositeKey , List < StreamPosition > > snapshot ( ) 
final Map < StreamCompositeKey , List < StreamPosition > > streams = new HashMap < > ( ) ; 
counters . forEach ( 
if ( ( typeId >= PUBLISHER_LIMIT_TYPE_ID && typeId <= RECEIVER_POS_TYPE_ID ) || 
typeId == SENDER_LIMIT_TYPE_ID || typeId == PER_IMAGE_TYPE_ID || typeId == PUBLISHER_POS_TYPE_ID ) 
final StreamCompositeKey key = new StreamCompositeKey ( 
keyBuffer . getInt ( SESSION_ID_OFFSET ) , 
keyBuffer . getInt ( STREAM_ID_OFFSET ) , 
keyBuffer . getStringAscii ( CHANNEL_OFFSET ) ) ; 
final StreamPosition position = new StreamPosition ( 
keyBuffer . getLong ( REGISTRATION_ID_OFFSET ) , 
counters . getCounterValue ( counterId ) , 
typeId ) ; 
streams 
. computeIfAbsent ( key , ( ignore ) -> new ArrayList < > ( ) ) 
. add ( position ) ; 
return streams ; 
} public int print ( final PrintStream out ) 
final Map < StreamCompositeKey , List < StreamPosition > > streams = snapshot ( ) ; 
final StringBuilder builder = new StringBuilder ( ) ; 
for ( final Map . Entry < StreamCompositeKey , List < StreamPosition > > entry : streams . entrySet ( ) ) 
builder . setLength ( 0 ) ; 
final StreamCompositeKey key = entry . getKey ( ) ; 
builder 
. append ( "sessionId=" ) . append ( key . sessionId ( ) ) 
for ( final StreamPosition streamPosition : entry . getValue ( ) ) 
. append ( labelName ( streamPosition . typeId ( ) ) ) 
. append ( ':' ) . append ( streamPosition . id ( ) ) 
. append ( ':' ) . append ( streamPosition . value ( ) ) ; 
out . println ( builder ) ; 
return streams . size ( ) ; 
} public double generateNewOptimalDelay ( ) 
final double x = uniformRandom ( randMax ) + baseX ; 
return constantT * Math . log ( x * factorT ) ; 
} public long onStatusMessage ( 
final StatusMessageFlyweight flyweight , 
final InetSocketAddress receiverAddress , 
final long senderLimit , 
final int initialTermId , 
final int positionBitsToShift , 
final long timeNs ) 
final long position = computePosition ( 
flyweight . consumptionTermId ( ) , 
flyweight . consumptionTermOffset ( ) , 
positionBitsToShift , 
initialTermId ) ; 
lastPosition = Math . max ( lastPosition , position ) ; 
timeOfLastStatusMessage = timeNs ; 
return Math . max ( senderLimit , position + flyweight . receiverWindowLength ( ) ) ; 
} public long onIdle ( final long timeNs , final long senderLimit , final long senderPosition , final boolean isEos ) 
if ( isEos && shouldLinger ) 
if ( lastPosition >= senderPosition || ( ( timeOfLastStatusMessage + RECEIVER_TIMEOUT_NS ) - timeNs < 0 ) ) 
shouldLinger = false ; 
return senderLimit ; 
} public void reset ( final long correlationId , final int recordCount , final RecordingDescriptorConsumer consumer ) 
this . correlationId = correlationId ; 
this . consumer = consumer ; 
this . remainingRecordCount = recordCount ; 
isDispatchComplete = false ; 
} public static int read ( final AtomicBuffer buffer , final EntryConsumer entryConsumer ) 
final int capacity = buffer . capacity ( ) ; 
int recordsRead = 0 ; 
while ( offset < capacity ) 
final long observationCount = buffer . getLongVolatile ( offset + OBSERVATION_COUNT_OFFSET ) ; 
if ( observationCount <= 0 ) 
++ recordsRead ; 
final String channel = buffer . getStringAscii ( offset + CHANNEL_OFFSET ) ; 
final String source = buffer . getStringAscii ( offset + CHANNEL_OFFSET + SIZE_OF_INT + channel . length ( ) ) ; 
entryConsumer . accept ( 
observationCount , 
buffer . getLong ( offset + TOTAL_BYTES_LOST_OFFSET ) , 
buffer . getLong ( offset + FIRST_OBSERVATION_OFFSET ) , 
buffer . getLong ( offset + LAST_OBSERVATION_OFFSET ) , 
buffer . getInt ( offset + SESSION_ID_OFFSET ) , 
buffer . getInt ( offset + STREAM_ID_OFFSET ) , 
channel , 
source ) ; 
final int recordLength = CHANNEL_OFFSET + ( SIZE_OF_INT * 2 ) + channel . length ( ) + source . length ( ) ; 
offset += BitUtil . align ( recordLength , ENTRY_ALIGNMENT ) ; 
return recordsRead ; 
} public static UnsafeBuffer createDefaultHeader ( final int sessionId , final int streamId , final int termId ) 
final UnsafeBuffer buffer = new UnsafeBuffer ( 
BufferUtil . allocateDirectAligned ( HEADER_LENGTH , CACHE_LINE_LENGTH ) ) ; 
buffer . putByte ( VERSION_FIELD_OFFSET , CURRENT_VERSION ) ; 
buffer . putByte ( FLAGS_FIELD_OFFSET , ( byte ) BEGIN_AND_END_FLAGS ) ; 
buffer . putShort ( TYPE_FIELD_OFFSET , ( short ) HDR_TYPE_DATA , LITTLE_ENDIAN ) ; 
buffer . putInt ( SESSION_ID_FIELD_OFFSET , sessionId , LITTLE_ENDIAN ) ; 
buffer . putInt ( STREAM_ID_FIELD_OFFSET , streamId , LITTLE_ENDIAN ) ; 
buffer . putInt ( TERM_ID_FIELD_OFFSET , termId , LITTLE_ENDIAN ) ; 
buffer . putLong ( RESERVED_VALUE_OFFSET , DEFAULT_RESERVE_VALUE ) ; 
return buffer ; 
} public CounterMessageFlyweight keyBuffer ( final DirectBuffer keyBuffer , final int keyOffset , final int keyLength ) 
buffer . putInt ( KEY_LENGTH_OFFSET , keyLength ) ; 
if ( null != keyBuffer && keyLength > 0 ) 
buffer . putBytes ( keyBufferOffset ( ) , keyBuffer , keyOffset , keyLength ) ; 
} public CounterMessageFlyweight labelBuffer ( 
final DirectBuffer labelBuffer , final int labelOffset , final int labelLength ) 
buffer . putInt ( labelOffset ( ) , labelLength ) ; 
buffer . putBytes ( labelBufferOffset ( ) , labelBuffer , labelOffset , labelLength ) ; 
final Image [ ] images = this . images ; 
final int length = images . length ; 
int fragmentsRead = 0 ; 
int startingIndex = roundRobinIndex ++ ; 
if ( startingIndex >= length ) 
roundRobinIndex = startingIndex = 0 ; 
for ( int i = startingIndex ; i < length && fragmentsRead < fragmentLimit ; i ++ ) 
fragmentsRead += images [ i ] . poll ( fragmentHandler , fragmentLimit - fragmentsRead ) ; 
for ( int i = 0 ; i < startingIndex && fragmentsRead < fragmentLimit ; i ++ ) 
return fragmentsRead ; 
} public int controlledPoll ( final ControlledFragmentHandler fragmentHandler , final int fragmentLimit ) 
fragmentsRead += images [ i ] . controlledPoll ( fragmentHandler , fragmentLimit - fragmentsRead ) ; 
} public long blockPoll ( final BlockHandler blockHandler , final int blockLengthLimit ) 
long bytesConsumed = 0 ; 
for ( final Image image : images ) 
bytesConsumed += image . blockPoll ( blockHandler , blockLengthLimit ) ; 
return bytesConsumed ; 
} public long rawPoll ( final RawBlockHandler rawBlockHandler , final int blockLengthLimit ) 
bytesConsumed += image . rawPoll ( rawBlockHandler , blockLengthLimit ) ; 
} public Image imageBySessionId ( final int sessionId ) 
Image result = null ; 
if ( sessionId == image . sessionId ( ) ) 
result = image ; 
} public void forEachImage ( final Consumer < Image > consumer ) 
consumer . accept ( image ) ; 
} public static ArchivingMediaDriver launch ( final MediaDriver . Context driverCtx , final Archive . Context archiveCtx ) 
final MediaDriver driver = MediaDriver . launch ( driverCtx ) ; 
final Archive archive = Archive . launch ( archiveCtx 
. mediaDriverAgentInvoker ( driver . sharedAgentInvoker ( ) ) 
. errorHandler ( driverCtx . errorHandler ( ) ) 
. errorCounter ( driverCtx . systemCounters ( ) . get ( SystemCounterDescriptor . ERRORS ) ) ) ; 
return new ArchivingMediaDriver ( driver , archive ) ; 
} public static boolean originalChannelContains ( 
final RecordingDescriptorDecoder descriptorDecoder , final byte [ ] channelFragment ) 
final int fragmentLength = channelFragment . length ; 
if ( fragmentLength == 0 ) 
final int limit = descriptorDecoder . limit ( ) ; 
final int strippedChannelLength = descriptorDecoder . strippedChannelLength ( ) ; 
final int originalChannelOffset = limit + 
RecordingDescriptorDecoder . strippedChannelHeaderLength ( ) + strippedChannelLength ; 
descriptorDecoder . limit ( originalChannelOffset ) ; 
final int channelLength = descriptorDecoder . originalChannelLength ( ) ; 
descriptorDecoder . limit ( limit ) ; 
final DirectBuffer buffer = descriptorDecoder . buffer ( ) ; 
int offset = descriptorDecoder . offset ( ) + descriptorDecoder . sbeBlockLength ( ) + 
RecordingDescriptorDecoder . strippedChannelHeaderLength ( ) + strippedChannelLength + 
RecordingDescriptorDecoder . originalChannelHeaderLength ( ) ; 
nextChar : 
for ( int end = offset + ( channelLength - fragmentLength ) ; offset <= end ; offset ++ ) 
for ( int i = 0 ; i < fragmentLength ; i ++ ) 
if ( buffer . getByte ( offset + i ) != channelFragment [ i ] ) 
continue nextChar ; 
} private void refreshCatalog ( final boolean fixOnRefresh ) 
if ( fixOnRefresh ) 
forEach ( this :: refreshAndFixDescriptor ) ; 
forEach ( ( ( headerEncoder , headerDecoder , descriptorEncoder , descriptorDecoder ) -> nextRecordingId ++ ) ) ; 
} public int claim ( 
final HeaderWriter header , 
final BufferClaim bufferClaim , 
final int activeTermId ) 
final int frameLength = length + HEADER_LENGTH ; 
final int alignedLength = align ( frameLength , FRAME_ALIGNMENT ) ; 
final UnsafeBuffer termBuffer = this . termBuffer ; 
final int termLength = termBuffer . capacity ( ) ; 
final long rawTail = getAndAddRawTail ( alignedLength ) ; 
final int termId = termId ( rawTail ) ; 
checkTerm ( activeTermId , termId ) ; 
long resultingOffset = termOffset + alignedLength ; 
if ( resultingOffset > termLength ) 
resultingOffset = handleEndOfLogCondition ( termBuffer , termOffset , header , termLength , termId ) ; 
final int frameOffset = ( int ) termOffset ; 
header . write ( termBuffer , frameOffset , frameLength , termId ) ; 
bufferClaim . wrap ( termBuffer , frameOffset , frameLength ) ; 
return ( int ) resultingOffset ; 
} public int appendUnfragmentedMessage ( 
final ReservedValueSupplier reservedValueSupplier , 
final int frameLength = lengthOne + lengthTwo + HEADER_LENGTH ; 
termBuffer . putBytes ( frameOffset + HEADER_LENGTH , bufferOne , offsetOne , lengthOne ) ; 
termBuffer . putBytes ( frameOffset + HEADER_LENGTH + lengthOne , bufferTwo , offsetTwo , lengthTwo ) ; 
if ( null != reservedValueSupplier ) 
final long reservedValue = reservedValueSupplier . get ( termBuffer , frameOffset , frameLength ) ; 
termBuffer . putLong ( frameOffset + RESERVED_VALUE_OFFSET , reservedValue , LITTLE_ENDIAN ) ; 
frameLengthOrdered ( termBuffer , frameOffset , frameLength ) ; 
final long termOffset = rawTail & 0xFFFF_FFFFL ; 
termBuffer . putBytes ( frameOffset + HEADER_LENGTH , buffer , offset , length ) ; 
} public int appendFragmentedMessage ( 
final int maxPayloadLength , 
final int length = lengthOne + lengthTwo ; 
final int numMaxPayloads = length / maxPayloadLength ; 
final int remainingPayload = length % maxPayloadLength ; 
final int lastFrameLength = remainingPayload > 0 ? align ( remainingPayload + HEADER_LENGTH , FRAME_ALIGNMENT ) : 0 ; 
final int requiredLength = ( numMaxPayloads * ( maxPayloadLength + HEADER_LENGTH ) ) + lastFrameLength ; 
final long rawTail = getAndAddRawTail ( requiredLength ) ; 
long resultingOffset = termOffset + requiredLength ; 
int frameOffset = ( int ) termOffset ; 
byte flags = BEGIN_FRAG_FLAG ; 
int remaining = length ; 
int positionOne = 0 ; 
int positionTwo = 0 ; 
final int bytesToWrite = Math . min ( remaining , maxPayloadLength ) ; 
final int frameLength = bytesToWrite + HEADER_LENGTH ; 
int bytesWritten = 0 ; 
int payloadOffset = frameOffset + HEADER_LENGTH ; 
final int remainingOne = lengthOne - positionOne ; 
if ( remainingOne > 0 ) 
final int numBytes = Math . min ( bytesToWrite - bytesWritten , remainingOne ) ; 
termBuffer . putBytes ( payloadOffset , bufferOne , offsetOne + positionOne , numBytes ) ; 
bytesWritten += numBytes ; 
payloadOffset += numBytes ; 
positionOne += numBytes ; 
final int numBytes = Math . min ( bytesToWrite - bytesWritten , lengthTwo - positionTwo ) ; 
termBuffer . putBytes ( payloadOffset , bufferTwo , offsetTwo + positionTwo , numBytes ) ; 
positionTwo += numBytes ; 
while ( bytesWritten < bytesToWrite ) ; 
if ( remaining <= maxPayloadLength ) 
flags |= END_FRAG_FLAG ; 
frameFlags ( termBuffer , frameOffset , flags ) ; 
flags = 0 ; 
frameOffset += alignedLength ; 
remaining -= bytesToWrite ; 
while ( remaining > 0 ) ; 
} public boolean connect ( final String responseChannel , final int responseStreamId , final long correlationId ) 
connectRequestEncoder 
. wrapAndApplyHeader ( buffer , 0 , messageHeaderEncoder ) 
. correlationId ( correlationId ) 
. responseStreamId ( responseStreamId ) 
. version ( AeronArchive . Configuration . SEMANTIC_VERSION ) 
. responseChannel ( responseChannel ) ; 
return offerWithTimeout ( connectRequestEncoder . encodedLength ( ) , null ) ; 
} public boolean tryConnect ( final String responseChannel , final int responseStreamId , final long correlationId ) 
final int length = MessageHeaderEncoder . ENCODED_LENGTH + connectRequestEncoder . encodedLength ( ) ; 
return publication . offer ( buffer , 0 , length ) > 0 ; 
} public boolean closeSession ( final long controlSessionId ) 
closeSessionRequestEncoder 
. controlSessionId ( controlSessionId ) ; 
return offer ( closeSessionRequestEncoder . encodedLength ( ) ) ; 
} public boolean startRecording ( 
final SourceLocation sourceLocation , 
final long correlationId , 
final long controlSessionId ) 
startRecordingRequestEncoder 
. controlSessionId ( controlSessionId ) 
. streamId ( streamId ) 
. sourceLocation ( sourceLocation ) 
. channel ( channel ) ; 
return offer ( startRecordingRequestEncoder . encodedLength ( ) ) ; 
} public boolean stopRecording ( 
stopRecordingRequestEncoder 
return offer ( stopRecordingRequestEncoder . encodedLength ( ) ) ; 
final long subscriptionId , 
stopRecordingSubscriptionRequestEncoder 
. subscriptionId ( subscriptionId ) ; 
return offer ( stopRecordingSubscriptionRequestEncoder . encodedLength ( ) ) ; 
} public boolean replay ( 
final int replayStreamId , 
replayRequestEncoder 
. recordingId ( recordingId ) 
. position ( position ) 
. length ( length ) 
. replayStreamId ( replayStreamId ) 
. replayChannel ( replayChannel ) ; 
return offer ( replayRequestEncoder . encodedLength ( ) ) ; 
} public boolean stopReplay ( final long replaySessionId , final long correlationId , final long controlSessionId ) 
stopReplayRequestEncoder 
. replaySessionId ( replaySessionId ) ; 
} public boolean listRecordings ( 
final long fromRecordingId , final int recordCount , final long correlationId , final long controlSessionId ) 
listRecordingsRequestEncoder 
. fromRecordingId ( fromRecordingId ) 
. recordCount ( recordCount ) ; 
return offer ( listRecordingsRequestEncoder . encodedLength ( ) ) ; 
} public boolean listRecordingsForUri ( 
listRecordingsForUriRequestEncoder 
. recordCount ( recordCount ) 
. channel ( channelFragment ) ; 
return offer ( listRecordingsForUriRequestEncoder . encodedLength ( ) ) ; 
} public boolean listRecording ( final long recordingId , final long correlationId , final long controlSessionId ) 
listRecordingRequestEncoder 
. recordingId ( recordingId ) ; 
return offer ( listRecordingRequestEncoder . encodedLength ( ) ) ; 
} public boolean extendRecording ( 
extendRecordingRequestEncoder 
return offer ( extendRecordingRequestEncoder . encodedLength ( ) ) ; 
} public boolean getRecordingPosition ( final long recordingId , final long correlationId , final long controlSessionId ) 
recordingPositionRequestEncoder 
return offer ( recordingPositionRequestEncoder . encodedLength ( ) ) ; 
} public boolean truncateRecording ( 
final long recordingId , final long position , final long correlationId , final long controlSessionId ) 
truncateRecordingRequestEncoder 
. position ( position ) ; 
return offer ( truncateRecordingRequestEncoder . encodedLength ( ) ) ; 
} public boolean getStopPosition ( final long recordingId , final long correlationId , final long controlSessionId ) 
stopPositionRequestEncoder 
return offer ( stopPositionRequestEncoder . encodedLength ( ) ) ; 
} public boolean findLastMatchingRecording ( 
final long minRecordingId , 
findLastMatchingRecordingRequestEncoder 
. minRecordingId ( minRecordingId ) 
. sessionId ( sessionId ) 
return offer ( findLastMatchingRecordingRequestEncoder . encodedLength ( ) ) ; 
} public boolean listRecordingSubscriptions ( 
listRecordingSubscriptionsRequestEncoder 
. pseudoIndex ( pseudoIndex ) 
. subscriptionCount ( subscriptionCount ) 
. applyStreamId ( applyStreamId ? BooleanType . TRUE : BooleanType . FALSE ) 
return offer ( listRecordingSubscriptionsRequestEncoder . encodedLength ( ) ) ; 
} @ SuppressWarnings ( "MethodLength" ) 
public static UdpChannel parse ( final String channelUriString ) 
final ChannelUri channelUri = ChannelUri . parse ( channelUriString ) ; 
validateConfiguration ( channelUri ) ; 
InetSocketAddress endpointAddress = getEndpointAddress ( channelUri ) ; 
final InetSocketAddress explicitControlAddress = getExplicitControlAddress ( channelUri ) ; 
final String tagIdStr = channelUri . channelTag ( ) ; 
final String controlMode = channelUri . get ( CommonContext . MDC_CONTROL_MODE_PARAM_NAME ) ; 
final boolean hasNoDistinguishingCharacteristic = 
null == endpointAddress && null == explicitControlAddress && null == tagIdStr ; 
if ( hasNoDistinguishingCharacteristic && null == controlMode ) 
if ( null != endpointAddress && endpointAddress . isUnresolved ( ) ) 
if ( null != explicitControlAddress && explicitControlAddress . isUnresolved ( ) ) 
final Context context = new Context ( ) 
. uriStr ( channelUriString ) 
. channelUri ( channelUri ) 
. hasNoDistinguishingCharacteristic ( hasNoDistinguishingCharacteristic ) ; 
if ( null != tagIdStr ) 
context . hasTagId ( true ) . tagId ( Long . parseLong ( tagIdStr ) ) ; 
if ( null == endpointAddress ) 
endpointAddress = new InetSocketAddress ( "0.0.0.0" , 0 ) ; 
if ( endpointAddress . getAddress ( ) . isMulticastAddress ( ) ) 
final InetSocketAddress controlAddress = getMulticastControlAddress ( endpointAddress ) ; 
final InterfaceSearchAddress searchAddress = getInterfaceSearchAddress ( channelUri ) ; 
final NetworkInterface localInterface = findInterface ( searchAddress ) ; 
final InetSocketAddress resolvedAddress = resolveToAddressOfInterface ( localInterface , searchAddress ) ; 
context 
. isMulticast ( true ) 
. localControlAddress ( resolvedAddress ) 
. remoteControlAddress ( controlAddress ) 
. localDataAddress ( resolvedAddress ) 
. remoteDataAddress ( endpointAddress ) 
. localInterface ( localInterface ) 
. protocolFamily ( getProtocolFamily ( endpointAddress . getAddress ( ) ) ) 
. canonicalForm ( canonicalise ( resolvedAddress , endpointAddress ) ) ; 
final String ttlValue = channelUri . get ( CommonContext . TTL_PARAM_NAME ) ; 
if ( null != ttlValue ) 
context . hasMulticastTtl ( true ) . multicastTtl ( Integer . parseInt ( ttlValue ) ) ; 
else if ( null != explicitControlAddress ) 
. hasExplicitControl ( true ) 
. remoteControlAddress ( endpointAddress ) 
. localControlAddress ( explicitControlAddress ) 
. localDataAddress ( explicitControlAddress ) 
. canonicalForm ( canonicalise ( explicitControlAddress , endpointAddress ) ) ; 
final InetSocketAddress localAddress = searchAddress . getInetAddress ( ) . isAnyLocalAddress ( ) ? 
searchAddress . getAddress ( ) : 
resolveToAddressOfInterface ( findInterface ( searchAddress ) , searchAddress ) ; 
final String uniqueCanonicalFormSuffix = hasNoDistinguishingCharacteristic ? 
( "-" + UNIQUE_CANONICAL_FORM_VALUE . getAndAdd ( 1 ) ) : "" ; 
. localControlAddress ( localAddress ) 
. localDataAddress ( localAddress ) 
. canonicalForm ( canonicalise ( localAddress , endpointAddress ) + uniqueCanonicalFormSuffix ) ; 
return new UdpChannel ( context ) ; 
throw new InvalidChannelException ( ErrorCode . INVALID_CHANNEL , ex ) ; 
} public static String canonicalise ( final InetSocketAddress localData , final InetSocketAddress remoteData ) 
final StringBuilder builder = new StringBuilder ( 48 ) ; 
builder . append ( "UDP-" ) ; 
toHex ( builder , localData . getAddress ( ) . getAddress ( ) ) 
. append ( '-' ) 
. append ( localData . getPort ( ) ) ; 
builder . append ( '-' ) ; 
toHex ( builder , remoteData . getAddress ( ) . getAddress ( ) ) 
. append ( remoteData . getPort ( ) ) ; 
return builder . toString ( ) ; 
} public boolean matchesTag ( final UdpChannel udpChannel ) 
if ( ! hasTag || ! udpChannel . hasTag ( ) || tag != udpChannel . tag ( ) ) 
if ( udpChannel . remoteData ( ) . getAddress ( ) . isAnyLocalAddress ( ) && 
udpChannel . remoteData ( ) . getPort ( ) == 0 && 
udpChannel . localData ( ) . getAddress ( ) . isAnyLocalAddress ( ) && 
udpChannel . localData ( ) . getPort ( ) == 0 ) 
} public static InetSocketAddress destinationAddress ( final ChannelUri uri ) 
validateConfiguration ( uri ) ; 
return getEndpointAddress ( uri ) ; 
} public String description ( ) 
if ( null != localInterface ) 
. append ( localInterface . getDisplayName ( ) ) 
hwmPosition . close ( ) ; 
rebuildPosition . close ( ) ; 
for ( final ReadablePosition position : subscriberPositions ) 
position . close ( ) ; 
for ( int i = 0 , size = untetheredSubscriptions . size ( ) ; i < size ; i ++ ) 
final UntetheredSubscription untetheredSubscription = untetheredSubscriptions . get ( i ) ; 
if ( UntetheredSubscription . RESTING == untetheredSubscription . state ) 
untetheredSubscription . position . close ( ) ; 
congestionControl . close ( ) ; 
rawLog . close ( ) ; 
} public void addSubscriber ( final SubscriptionLink subscriptionLink , final ReadablePosition subscriberPosition ) 
subscriberPositions = ArrayUtil . add ( subscriberPositions , subscriberPosition ) ; 
if ( ! subscriptionLink . isTether ( ) ) 
untetheredSubscriptions . add ( new UntetheredSubscription ( 
subscriptionLink , subscriberPosition , timeOfLastStatusMessageScheduleNs ) ) ; 
} public void removeSubscriber ( final SubscriptionLink subscriptionLink , final ReadablePosition subscriberPosition ) 
subscriberPositions = ArrayUtil . remove ( subscriberPositions , subscriberPosition ) ; 
subscriberPosition . close ( ) ; 
for ( int lastIndex = untetheredSubscriptions . size ( ) - 1 , i = lastIndex ; i >= 0 ; i -- ) 
if ( untetheredSubscriptions . get ( i ) . subscriptionLink == subscriptionLink ) 
ArrayListUtil . fastUnorderedRemove ( untetheredSubscriptions , i , lastIndex ) ; 
} public void onGapDetected ( final int termId , final int termOffset , final int length ) 
final long changeNumber = beginLossChange + 1 ; 
beginLossChange = changeNumber ; 
lossTermId = termId ; 
lossTermOffset = termOffset ; 
lossLength = length ; 
endLossChange = changeNumber ; 
if ( null != reportEntry ) 
reportEntry . recordObservation ( length , cachedEpochClock . time ( ) ) ; 
else if ( null != lossReport ) 
reportEntry = lossReport . createEntry ( 
length , cachedEpochClock . time ( ) , sessionId , streamId , channel ( ) , sourceAddress . toString ( ) ) ; 
if ( null == reportEntry ) 
lossReport = null ; 
} void addDestination ( final int transportIndex , final ReceiveDestinationUdpTransport transport ) 
imageConnections = ArrayUtil . ensureCapacity ( imageConnections , transportIndex + 1 ) ; 
if ( transport . isMulticast ( ) ) 
imageConnections [ transportIndex ] = new ImageConnection ( 
cachedNanoClock . nanoTime ( ) , transport . udpChannel ( ) . remoteControl ( ) ) ; 
else if ( transport . hasExplicitControl ( ) ) 
cachedNanoClock . nanoTime ( ) , transport . explicitControlAddress ( ) ) ; 
} final void trackRebuild ( final long nowNs , final long statusMessageTimeoutNs ) 
long minSubscriberPosition = Long . MAX_VALUE ; 
long maxSubscriberPosition = Long . MIN_VALUE ; 
for ( final ReadablePosition subscriberPosition : subscriberPositions ) 
final long position = subscriberPosition . getVolatile ( ) ; 
minSubscriberPosition = Math . min ( minSubscriberPosition , position ) ; 
maxSubscriberPosition = Math . max ( maxSubscriberPosition , position ) ; 
final long rebuildPosition = Math . max ( this . rebuildPosition . get ( ) , maxSubscriberPosition ) ; 
final long hwmPosition = this . hwmPosition . getVolatile ( ) ; 
final long scanOutcome = lossDetector . scan ( 
termBuffers [ indexByPosition ( rebuildPosition , positionBitsToShift ) ] , 
rebuildPosition , 
hwmPosition , 
nowNs , 
termLengthMask , 
final int rebuildTermOffset = ( int ) rebuildPosition & termLengthMask ; 
final long newRebuildPosition = ( rebuildPosition - rebuildTermOffset ) + rebuildOffset ( scanOutcome ) ; 
this . rebuildPosition . proposeMaxOrdered ( newRebuildPosition ) ; 
final long ccOutcome = congestionControl . onTrackRebuild ( 
minSubscriberPosition , 
nextSmPosition , 
newRebuildPosition , 
lossFound ( scanOutcome ) ) ; 
final int windowLength = CongestionControl . receiverWindowLength ( ccOutcome ) ; 
final int threshold = CongestionControl . threshold ( windowLength ) ; 
if ( CongestionControl . shouldForceStatusMessage ( ccOutcome ) || 
( ( timeOfLastStatusMessageScheduleNs + statusMessageTimeoutNs ) - nowNs < 0 ) || 
( minSubscriberPosition > ( nextSmPosition + threshold ) ) ) 
scheduleStatusMessage ( nowNs , minSubscriberPosition , windowLength ) ; 
cleanBufferTo ( minSubscriberPosition - ( termLengthMask + 1 ) ) ; 
} int insertPacket ( 
final int termId , 
final int termOffset , 
final UnsafeBuffer buffer , 
final int transportIndex , 
final InetSocketAddress srcAddress ) 
final boolean isHeartbeat = DataHeaderFlyweight . isHeartbeat ( buffer , length ) ; 
final long packetPosition = computePosition ( termId , termOffset , positionBitsToShift , initialTermId ) ; 
final long proposedPosition = isHeartbeat ? packetPosition : packetPosition + length ; 
if ( ! isFlowControlUnderRun ( packetPosition ) && ! isFlowControlOverRun ( proposedPosition ) ) 
trackConnection ( transportIndex , srcAddress , lastPacketTimestampNs ) ; 
if ( isHeartbeat ) 
if ( DataHeaderFlyweight . isEndOfStream ( buffer ) && ! isEndOfStream && allEos ( transportIndex ) ) 
LogBufferDescriptor . endOfStreamPosition ( rawLog . metaData ( ) , proposedPosition ) ; 
isEndOfStream = true ; 
heartbeatsReceived . incrementOrdered ( ) ; 
final UnsafeBuffer termBuffer = termBuffers [ indexByPosition ( packetPosition , positionBitsToShift ) ] ; 
TermRebuilder . insert ( termBuffer , termOffset , buffer , length ) ; 
lastPacketTimestampNs = cachedNanoClock . nanoTime ( ) ; 
hwmPosition . proposeMaxOrdered ( proposedPosition ) ; 
return length ; 
} boolean hasActivityAndNotEndOfStream ( final long nowNs ) 
boolean isActive = true ; 
if ( ( ( lastPacketTimestampNs + imageLivenessTimeoutNs ) - nowNs < 0 ) || 
( isEndOfStream && rebuildPosition . getVolatile ( ) >= hwmPosition . get ( ) ) ) 
isActive = false ; 
return isActive ; 
} int sendPendingStatusMessage ( ) 
if ( ACTIVE == state ) 
final long changeNumber = endSmChange ; 
if ( changeNumber != lastSmChangeNumber ) 
final long smPosition = nextSmPosition ; 
final int receiverWindowLength = nextSmReceiverWindowLength ; 
UNSAFE . loadFence ( ) ; 
if ( changeNumber == beginSmChange ) 
final int termId = computeTermIdFromPosition ( smPosition , positionBitsToShift , initialTermId ) ; 
final int termOffset = ( int ) smPosition & termLengthMask ; 
channelEndpoint . sendStatusMessage ( 
imageConnections , sessionId , streamId , termId , termOffset , receiverWindowLength , ( byte ) 0 ) ; 
statusMessagesSent . incrementOrdered ( ) ; 
lastSmPosition = smPosition ; 
lastSmWindowLimit = smPosition + receiverWindowLength ; 
lastSmChangeNumber = changeNumber ; 
workCount = 1 ; 
} int processPendingLoss ( ) 
final long changeNumber = endLossChange ; 
if ( changeNumber != lastLossChangeNumber ) 
final int termId = lossTermId ; 
final int termOffset = lossTermOffset ; 
final int length = lossLength ; 
if ( changeNumber == beginLossChange ) 
if ( isReliable ) 
channelEndpoint . sendNakMessage ( imageConnections , sessionId , streamId , termId , termOffset , length ) ; 
nakMessagesSent . incrementOrdered ( ) ; 
final UnsafeBuffer termBuffer = termBuffers [ indexByTerm ( initialTermId , termId ) ] ; 
if ( tryFillGap ( rawLog . metaData ( ) , termBuffer , termId , termOffset , length ) ) 
lossGapFills . incrementOrdered ( ) ; 
lastLossChangeNumber = changeNumber ; 
} int initiateAnyRttMeasurements ( final long nowNs ) 
if ( congestionControl . shouldMeasureRtt ( nowNs ) ) 
final long preciseTimeNs = nanoClock . nanoTime ( ) ; 
channelEndpoint . sendRttMeasurement ( imageConnections , sessionId , streamId , preciseTimeNs , 0 , true ) ; 
congestionControl . onRttMeasurementSent ( preciseTimeNs ) ; 
} void onRttMeasurement ( 
final RttMeasurementFlyweight header , 
@ SuppressWarnings ( "unused" ) final int transportIndex , 
final long nowNs = nanoClock . nanoTime ( ) ; 
final long rttInNs = nowNs - header . echoTimestampNs ( ) - header . receptionDelta ( ) ; 
congestionControl . onRttMeasurement ( nowNs , rttInNs , srcAddress ) ; 
} public void onTimeEvent ( final long timeNs , final long timesMs , final DriverConductor conductor ) 
case ACTIVE : 
checkUntetheredSubscriptions ( timeNs , conductor ) ; 
case INACTIVE : 
if ( isDrained ( ) ) 
state = State . LINGER ; 
timeOfLastStateChangeNs = timeNs ; 
conductor . transitionToLinger ( this ) ; 
isTrackingRebuild = false ; 
case LINGER : 
if ( ( timeOfLastStateChangeNs + imageLivenessTimeoutNs ) - timeNs < 0 ) 
state = State . DONE ; 
conductor . cleanupImage ( this ) ; 
} public static CountersReader mapCounters ( final File cncFile ) 
final MappedByteBuffer cncByteBuffer = IoUtil . mapExistingFile ( cncFile , "cnc" ) ; 
final DirectBuffer cncMetaData = createMetaDataBuffer ( cncByteBuffer ) ; 
final int cncVersion = cncMetaData . getInt ( cncVersionOffset ( 0 ) ) ; 
if ( CncFileDescriptor . CNC_VERSION != cncVersion ) 
throw new AeronException ( 
return new CountersReader ( 
createCountersMetaDataBuffer ( cncByteBuffer , cncMetaData ) , 
createCountersValuesBuffer ( cncByteBuffer , cncMetaData ) , 
StandardCharsets . US_ASCII ) ; 
} public static AtomicCounter findControlToggle ( final CountersReader counters ) 
final AtomicBuffer buffer = counters . metaDataBuffer ( ) ; 
for ( int i = 0 , size = counters . maxCounterId ( ) ; i < size ; i ++ ) 
final int recordOffset = CountersReader . metaDataOffset ( i ) ; 
if ( counters . getCounterState ( i ) == RECORD_ALLOCATED && 
buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == CONTROL_TOGGLE_TYPE_ID ) 
return new AtomicCounter ( counters . valuesBuffer ( ) , i , null ) ; 
} public String put ( final String key , final String value ) 
return params . put ( key , value ) ; 
} public String channelTag ( ) 
return ( null != tags && tags . length > CHANNEL_TAG_INDEX ) ? tags [ CHANNEL_TAG_INDEX ] : null ; 
} public String entityTag ( ) 
return ( null != tags && tags . length > ENTITY_TAG_INDEX ) ? tags [ ENTITY_TAG_INDEX ] : null ; 
} public void initialPosition ( final long position , final int initialTermId , final int termLength ) 
if ( position < 0 || 0 != ( position & ( FRAME_ALIGNMENT - 1 ) ) ) 
final int bitsToShift = LogBufferDescriptor . positionBitsToShift ( termLength ) ; 
final int termId = LogBufferDescriptor . computeTermIdFromPosition ( position , bitsToShift , initialTermId ) ; 
final int termOffset = ( int ) ( position & ( termLength - 1 ) ) ; 
put ( INITIAL_TERM_ID_PARAM_NAME , Integer . toString ( initialTermId ) ) ; 
put ( TERM_ID_PARAM_NAME , Integer . toString ( termId ) ) ; 
put ( TERM_OFFSET_PARAM_NAME , Integer . toString ( termOffset ) ) ; 
put ( TERM_LENGTH_PARAM_NAME , Integer . toString ( termLength ) ) ; 
} public static ChannelUri parse ( final CharSequence cs ) 
int position = 0 ; 
final String prefix ; 
if ( startsWith ( cs , 0 , SPY_PREFIX ) ) 
prefix = SPY_QUALIFIER ; 
position = SPY_PREFIX . length ( ) ; 
prefix = "" ; 
if ( ! startsWith ( cs , position , AERON_PREFIX ) ) 
position += AERON_PREFIX . length ( ) ; 
final Map < String , String > params = new Object2ObjectHashMap < > ( ) ; 
String media = null ; 
String key = null ; 
State state = State . MEDIA ; 
for ( int i = position ; i < cs . length ( ) ; i ++ ) 
final char c = cs . charAt ( i ) ; 
case MEDIA : 
switch ( c ) 
case '?' : 
media = builder . toString ( ) ; 
state = State . PARAMS_KEY ; 
case ':' : 
builder . append ( c ) ; 
case PARAMS_KEY : 
if ( c == '=' ) 
key = builder . toString ( ) ; 
state = State . PARAMS_VALUE ; 
case PARAMS_VALUE : 
if ( c == '|' ) 
params . put ( key , builder . toString ( ) ) ; 
return new ChannelUri ( prefix , media , params ) ; 
} public static String addSessionId ( final String channel , final int sessionId ) 
final ChannelUri channelUri = ChannelUri . parse ( channel ) ; 
channelUri . put ( CommonContext . SESSION_ID_PARAM_NAME , Integer . toString ( sessionId ) ) ; 
return channelUri . toString ( ) ; 
} public static long getTag ( final String paramValue ) 
return isTagged ( paramValue ) ? 
AsciiEncoding . parseLongAscii ( paramValue , 4 , paramValue . length ( ) - 4 ) : INVALID_TAG ; 
final BufferClaim bufferClaim ) 
int resultingOffset = termOffset + alignedLength ; 
putRawTailOrdered ( termId , resultingOffset ) ; 
header . write ( termBuffer , termOffset , frameLength , termId ) ; 
bufferClaim . wrap ( termBuffer , termOffset , frameLength ) ; 
return resultingOffset ; 
} public int appendPadding ( 
final int length ) 
frameType ( termBuffer , termOffset , PADDING_FRAME_TYPE ) ; 
frameLengthOrdered ( termBuffer , termOffset , frameLength ) ; 
final DirectBuffer srcBuffer , 
final int srcOffset , 
termBuffer . putBytes ( termOffset + HEADER_LENGTH , srcBuffer , srcOffset , length ) ; 
final long reservedValue = reservedValueSupplier . get ( termBuffer , termOffset , frameLength ) ; 
termBuffer . putLong ( termOffset + RESERVED_VALUE_OFFSET , reservedValue , LITTLE_ENDIAN ) ; 
final DirectBufferVector [ ] vectors , 
int resultingOffset = termOffset + requiredLength ; 
int frameOffset = termOffset ; 
int vectorIndex = 0 ; 
int vectorOffset = 0 ; 
final DirectBufferVector vector = vectors [ vectorIndex ] ; 
final int vectorRemaining = vector . length - vectorOffset ; 
final int numBytes = Math . min ( bytesToWrite - bytesWritten , vectorRemaining ) ; 
termBuffer . putBytes ( payloadOffset , vector . buffer , vector . offset + vectorOffset , numBytes ) ; 
vectorOffset += numBytes ; 
if ( vectorRemaining <= numBytes ) 
vectorIndex ++ ; 
vectorOffset = 0 ; 
} final int updatePublisherLimit ( ) 
final long senderPosition = this . senderPosition . getVolatile ( ) ; 
if ( hasReceivers || ( spiesSimulateConnection && spyPositions . length > 0 ) ) 
long minConsumerPosition = senderPosition ; 
for ( final ReadablePosition spyPosition : spyPositions ) 
minConsumerPosition = Math . min ( minConsumerPosition , spyPosition . getVolatile ( ) ) ; 
final long proposedPublisherLimit = minConsumerPosition + termWindowLength ; 
if ( publisherLimit . proposeMaxOrdered ( proposedPublisherLimit ) ) 
cleanBuffer ( proposedPublisherLimit ) ; 
else if ( publisherLimit . get ( ) > senderPosition ) 
publisherLimit . setOrdered ( senderPosition ) ; 
} public static NetworkInterface [ ] filterBySubnet ( final InetAddress address , final int subnetPrefix ) 
throws SocketException 
return filterBySubnet ( NetworkInterfaceShim . DEFAULT , address , subnetPrefix ) ; 
} public static ByteBuffer allocateDirectAlignedAndPadded ( final int capacity , final int alignment ) 
final ByteBuffer buffer = BufferUtil . allocateDirectAligned ( capacity + alignment , alignment ) ; 
buffer . limit ( buffer . limit ( ) - alignment ) ; 
return buffer . slice ( ) ; 
} public static UnsafeBufferPosition allocate ( 
final int typeId , 
return new UnsafeBufferPosition ( 
( UnsafeBuffer ) countersManager . valuesBuffer ( ) , 
allocateCounterId ( tempBuffer , name , typeId , countersManager , registrationId , sessionId , streamId , channel ) , 
countersManager ) ; 
} public static String labelName ( final int typeId ) 
switch ( typeId ) 
case PublisherLimit . PUBLISHER_LIMIT_TYPE_ID : 
return PublisherLimit . NAME ; 
case SenderPos . SENDER_POSITION_TYPE_ID : 
return SenderPos . NAME ; 
case ReceiverHwm . RECEIVER_HWM_TYPE_ID : 
return ReceiverHwm . NAME ; 
case SubscriberPos . SUBSCRIBER_POSITION_TYPE_ID : 
return SubscriberPos . NAME ; 
case ReceiverPos . RECEIVER_POS_TYPE_ID : 
return ReceiverPos . NAME ; 
case SenderLimit . SENDER_LIMIT_TYPE_ID : 
return SenderLimit . NAME ; 
case PublisherPos . PUBLISHER_POS_TYPE_ID : 
return PublisherPos . NAME ; 
case SenderBpe . SENDER_BPE_TYPE_ID : 
return SenderBpe . NAME ; 
return "<unknown>" ; 
} public static long scanForAvailability ( final UnsafeBuffer termBuffer , final int offset , final int maxLength ) 
final int limit = Math . min ( maxLength , termBuffer . capacity ( ) - offset ) ; 
int available = 0 ; 
int padding = 0 ; 
final int termOffset = offset + available ; 
final int frameLength = frameLengthVolatile ( termBuffer , termOffset ) ; 
if ( frameLength <= 0 ) 
int alignedFrameLength = align ( frameLength , FRAME_ALIGNMENT ) ; 
if ( isPaddingFrame ( termBuffer , termOffset ) ) 
padding = alignedFrameLength - HEADER_LENGTH ; 
alignedFrameLength = HEADER_LENGTH ; 
available += alignedFrameLength ; 
if ( available > limit ) 
available -= alignedFrameLength ; 
padding = 0 ; 
while ( 0 == padding && available < limit ) ; 
return pack ( padding , available ) ; 
} public ChannelUriStringBuilder clear ( ) 
prefix = null ; 
media = null ; 
endpoint = null ; 
networkInterface = null ; 
controlEndpoint = null ; 
controlMode = null ; 
tags = null ; 
alias = null ; 
reliable = null ; 
ttl = null ; 
mtu = null ; 
termLength = null ; 
initialTermId = null ; 
termId = null ; 
termOffset = null ; 
sessionId = null ; 
linger = null ; 
sparse = null ; 
eos = null ; 
tether = null ; 
isSessionIdTagged = false ; 
} public ChannelUriStringBuilder validate ( ) 
if ( null == media ) 
if ( CommonContext . UDP_MEDIA . equals ( media ) && ( null == endpoint && null == controlEndpoint ) ) 
int count = 0 ; 
count += null == initialTermId ? 0 : 1 ; 
count += null == termId ? 0 : 1 ; 
count += null == termOffset ? 0 : 1 ; 
if ( count > 0 ) 
if ( count < 3 ) 
throw new IllegalStateException ( 
if ( termId - initialTermId < 0 ) 
if ( null != termLength && termOffset > termLength ) 
} public ChannelUriStringBuilder prefix ( final String prefix ) 
if ( null != prefix && ! prefix . equals ( "" ) && ! prefix . equals ( SPY_QUALIFIER ) ) 
this . prefix = prefix ; 
} public ChannelUriStringBuilder media ( final String media ) 
switch ( media ) 
case CommonContext . UDP_MEDIA : 
case CommonContext . IPC_MEDIA : 
this . media = media ; 
} public ChannelUriStringBuilder controlMode ( final String controlMode ) 
if ( null != controlMode && 
! controlMode . equals ( CommonContext . MDC_CONTROL_MODE_MANUAL ) && 
! controlMode . equals ( CommonContext . MDC_CONTROL_MODE_DYNAMIC ) ) 
this . controlMode = controlMode ; 
} public ChannelUriStringBuilder ttl ( final Integer ttl ) 
if ( null != ttl && ( ttl < 0 || ttl > 255 ) ) 
this . ttl = ttl ; 
} public ChannelUriStringBuilder mtu ( final Integer mtu ) 
if ( null != mtu ) 
if ( mtu < 32 || mtu > 65504 ) 
if ( ( mtu & ( FRAME_ALIGNMENT - 1 ) ) != 0 ) 
this . mtu = mtu ; 
} public ChannelUriStringBuilder termLength ( final Integer termLength ) 
if ( null != termLength ) 
LogBufferDescriptor . checkTermLength ( termLength ) ; 
this . termLength = termLength ; 
} public ChannelUriStringBuilder termOffset ( final Integer termOffset ) 
if ( null != termOffset ) 
if ( ( termOffset < 0 || termOffset > LogBufferDescriptor . TERM_MAX_LENGTH ) ) 
if ( 0 != ( termOffset & ( FRAME_ALIGNMENT - 1 ) ) ) 
this . termOffset = termOffset ; 
} public ChannelUriStringBuilder linger ( final Long lingerNs ) 
if ( null != lingerNs && lingerNs < 0 ) 
this . linger = lingerNs ; 
} public ChannelUriStringBuilder initialPosition ( final long position , final int initialTermId , final int termLength ) 
this . initialTermId = initialTermId ; 
this . termId = LogBufferDescriptor . computeTermIdFromPosition ( position , bitsToShift , initialTermId ) ; 
this . termOffset = ( int ) ( position & ( termLength - 1 ) ) ; 
public String build ( ) 
sb . setLength ( 0 ) ; 
if ( null != prefix && ! "" . equals ( prefix ) ) 
sb . append ( prefix ) . append ( ':' ) ; 
sb . append ( ChannelUri . AERON_SCHEME ) . append ( ':' ) . append ( media ) . append ( '?' ) ; 
if ( null != tags ) 
sb . append ( TAGS_PARAM_NAME ) . append ( '=' ) . append ( tags ) . append ( '|' ) ; 
if ( null != endpoint ) 
sb . append ( ENDPOINT_PARAM_NAME ) . append ( '=' ) . append ( endpoint ) . append ( '|' ) ; 
if ( null != networkInterface ) 
sb . append ( INTERFACE_PARAM_NAME ) . append ( '=' ) . append ( networkInterface ) . append ( '|' ) ; 
if ( null != controlEndpoint ) 
sb . append ( MDC_CONTROL_PARAM_NAME ) . append ( '=' ) . append ( controlEndpoint ) . append ( '|' ) ; 
if ( null != controlMode ) 
sb . append ( MDC_CONTROL_MODE_PARAM_NAME ) . append ( '=' ) . append ( controlMode ) . append ( '|' ) ; 
sb . append ( MTU_LENGTH_PARAM_NAME ) . append ( '=' ) . append ( mtu . intValue ( ) ) . append ( '|' ) ; 
sb . append ( TERM_LENGTH_PARAM_NAME ) . append ( '=' ) . append ( termLength . intValue ( ) ) . append ( '|' ) ; 
if ( null != initialTermId ) 
sb . append ( INITIAL_TERM_ID_PARAM_NAME ) . append ( '=' ) . append ( initialTermId . intValue ( ) ) . append ( '|' ) ; 
if ( null != termId ) 
sb . append ( TERM_ID_PARAM_NAME ) . append ( '=' ) . append ( termId . intValue ( ) ) . append ( '|' ) ; 
sb . append ( TERM_OFFSET_PARAM_NAME ) . append ( '=' ) . append ( termOffset . intValue ( ) ) . append ( '|' ) ; 
if ( null != sessionId ) 
sb . append ( SESSION_ID_PARAM_NAME ) . append ( '=' ) . append ( prefixTag ( isSessionIdTagged , sessionId ) ) . append ( '|' ) ; 
if ( null != ttl ) 
sb . append ( TTL_PARAM_NAME ) . append ( '=' ) . append ( ttl . intValue ( ) ) . append ( '|' ) ; 
if ( null != reliable ) 
sb . append ( RELIABLE_STREAM_PARAM_NAME ) . append ( '=' ) . append ( reliable ) . append ( '|' ) ; 
if ( null != linger ) 
sb . append ( LINGER_PARAM_NAME ) . append ( '=' ) . append ( linger . intValue ( ) ) . append ( '|' ) ; 
if ( null != alias ) 
sb . append ( ALIAS_PARAM_NAME ) . append ( '=' ) . append ( alias ) . append ( '|' ) ; 
if ( null != sparse ) 
sb . append ( SPARSE_PARAM_NAME ) . append ( '=' ) . append ( sparse ) . append ( '|' ) ; 
if ( null != eos ) 
sb . append ( EOS_PARAM_NAME ) . append ( '=' ) . append ( eos ) . append ( '|' ) ; 
if ( null != tether ) 
sb . append ( TETHER_PARAM_NAME ) . append ( '=' ) . append ( tether ) . append ( '|' ) ; 
final char lastChar = sb . charAt ( sb . length ( ) - 1 ) ; 
if ( lastChar == '|' || lastChar == '?' ) 
sb . setLength ( sb . length ( ) - 1 ) ; 
return sb . toString ( ) ; 
} public static void sendError ( final int bytesToSend , final IOException ex , final InetSocketAddress destination ) 
} public void openDatagramChannel ( final AtomicCounter statusIndicator ) 
sendDatagramChannel = DatagramChannel . open ( udpChannel . protocolFamily ( ) ) ; 
receiveDatagramChannel = sendDatagramChannel ; 
if ( udpChannel . isMulticast ( ) ) 
if ( null != connectAddress ) 
receiveDatagramChannel = DatagramChannel . open ( udpChannel . protocolFamily ( ) ) ; 
receiveDatagramChannel . setOption ( StandardSocketOptions . SO_REUSEADDR , true ) ; 
receiveDatagramChannel . bind ( new InetSocketAddress ( endPointAddress . getPort ( ) ) ) ; 
receiveDatagramChannel . join ( endPointAddress . getAddress ( ) , udpChannel . localInterface ( ) ) ; 
sendDatagramChannel . setOption ( StandardSocketOptions . IP_MULTICAST_IF , udpChannel . localInterface ( ) ) ; 
if ( udpChannel . isHasMulticastTtl ( ) ) 
sendDatagramChannel . setOption ( StandardSocketOptions . IP_MULTICAST_TTL , udpChannel . multicastTtl ( ) ) ; 
multicastTtl = sendDatagramChannel . getOption ( StandardSocketOptions . IP_MULTICAST_TTL ) ; 
else if ( context . socketMulticastTtl ( ) != 0 ) 
sendDatagramChannel . setOption ( StandardSocketOptions . IP_MULTICAST_TTL , context . socketMulticastTtl ( ) ) ; 
sendDatagramChannel . bind ( bindAddress ) ; 
sendDatagramChannel . connect ( connectAddress ) ; 
if ( 0 != context . socketSndbufLength ( ) ) 
sendDatagramChannel . setOption ( SO_SNDBUF , context . socketSndbufLength ( ) ) ; 
if ( 0 != context . socketRcvbufLength ( ) ) 
receiveDatagramChannel . setOption ( SO_RCVBUF , context . socketRcvbufLength ( ) ) ; 
sendDatagramChannel . configureBlocking ( false ) ; 
receiveDatagramChannel . configureBlocking ( false ) ; 
if ( null != statusIndicator ) 
statusIndicator . setOrdered ( ChannelEndpointStatus . ERRORED ) ; 
CloseHelper . quietClose ( sendDatagramChannel ) ; 
if ( receiveDatagramChannel != sendDatagramChannel ) 
CloseHelper . quietClose ( receiveDatagramChannel ) ; 
sendDatagramChannel = null ; 
receiveDatagramChannel = null ; 
udpChannel . originalUriString ( ) , ex ) ; 
if ( null != selectionKey ) 
selectionKey . cancel ( ) ; 
if ( null != transportPoller ) 
transportPoller . cancelRead ( this ) ; 
transportPoller . selectNowWithoutProcessing ( ) ; 
if ( null != sendDatagramChannel ) 
sendDatagramChannel . close ( ) ; 
if ( receiveDatagramChannel != sendDatagramChannel && null != receiveDatagramChannel ) 
receiveDatagramChannel . close ( ) ; 
errorLog . record ( ex ) ; 
} public boolean isValidFrame ( final UnsafeBuffer buffer , final int length ) 
boolean isFrameValid = true ; 
if ( frameVersion ( buffer , 0 ) != HeaderFlyweight . CURRENT_VERSION ) 
isFrameValid = false ; 
invalidPackets . increment ( ) ; 
else if ( length < HeaderFlyweight . MIN_HEADER_LENGTH ) 
return isFrameValid ; 
} public InetSocketAddress receive ( final ByteBuffer buffer ) 
buffer . clear ( ) ; 
InetSocketAddress address = null ; 
if ( receiveDatagramChannel . isOpen ( ) ) 
address = ( InetSocketAddress ) receiveDatagramChannel . receive ( buffer ) ; 
catch ( final PortUnreachableException ignored ) 
return address ; 
} public void onNak ( 
final int termLength , 
final RetransmitSender retransmitSender ) 
if ( ! isInvalid ( termOffset , termLength ) ) 
if ( null == activeRetransmitsMap . get ( termId , termOffset ) && 
activeRetransmitsMap . size ( ) < MAX_RETRANSMITS_DEFAULT ) 
final RetransmitAction action = assignRetransmitAction ( ) ; 
action . termId = termId ; 
action . termOffset = termOffset ; 
action . length = Math . min ( length , termLength - termOffset ) ; 
final long delay = delayGenerator . generateDelay ( ) ; 
if ( 0 == delay ) 
retransmitSender . resend ( termId , termOffset , action . length ) ; 
action . linger ( lingerTimeoutGenerator . generateDelay ( ) , nanoClock . nanoTime ( ) ) ; 
action . delay ( delay , nanoClock . nanoTime ( ) ) ; 
activeRetransmitsMap . put ( termId , termOffset , action ) ; 
} public void onRetransmitReceived ( final int termId , final int termOffset ) 
final RetransmitAction action = activeRetransmitsMap . get ( termId , termOffset ) ; 
if ( null != action && DELAYED == action . state ) 
activeRetransmitsMap . remove ( termId , termOffset ) ; 
action . cancel ( ) ; 
} public void processTimeouts ( final long nowNs , final RetransmitSender retransmitSender ) 
if ( activeRetransmitsMap . size ( ) > 0 ) 
for ( final RetransmitAction action : retransmitActionPool ) 
if ( DELAYED == action . state && ( action . expireNs - nowNs < 0 ) ) 
retransmitSender . resend ( action . termId , action . termOffset , action . length ) ; 
else if ( LINGERING == action . state && ( action . expireNs - nowNs < 0 ) ) 
activeRetransmitsMap . remove ( action . termId , action . termOffset ) ; 
} public void reset ( 
final long correlationId , final int subscriptionCount , final RecordingSubscriptionDescriptorConsumer consumer ) 
this . remainingSubscriptionCount = subscriptionCount ; 
final BufferBuilder builder = getBufferBuilder ( header . sessionId ( ) ) ; 
final BufferBuilder builder = builderBySessionIdMap . get ( header . sessionId ( ) ) ; 
if ( null != builder && builder . limit ( ) != 0 ) 
} public static String status ( final long status ) 
if ( INITIALIZING == status ) 
return "INITIALIZING" ; 
if ( ERRORED == status ) 
return "ERRORED" ; 
if ( ACTIVE == status ) 
return "ACTIVE" ; 
if ( CLOSING == status ) 
return "CLOSING" ; 
final int keyLength = tempBuffer . putStringWithoutLengthAscii ( 
CHANNEL_OFFSET + SIZE_OF_INT , channel , 0 , MAX_CHANNEL_LENGTH ) ; 
tempBuffer . putInt ( CHANNEL_OFFSET , keyLength ) ; 
int labelLength = 0 ; 
labelLength += tempBuffer . putStringWithoutLengthAscii ( keyLength + labelLength , name ) ; 
labelLength += tempBuffer . putStringWithoutLengthAscii ( 
keyLength + labelLength , channel , 0 , MAX_LABEL_LENGTH - labelLength ) ; 
return countersManager . newCounter ( typeId , tempBuffer , 0 , keyLength , tempBuffer , keyLength , labelLength ) ; 
} public void onFragment ( final DirectBuffer buffer , final int offset , final int length , final Header header ) 
delegate . onFragment ( buffer , offset , length , header ) ; 
handleFragment ( buffer , offset , length , header , flags ) ; 
} public DirectBufferVector reset ( final DirectBuffer buffer , final int offset , final int length ) 
this . buffer = buffer ; 
this . offset = offset ; 
this . length = length ; 
} public DirectBufferVector validate ( ) 
if ( offset < 0 || offset >= capacity ) 
if ( length < 0 || length > ( capacity - offset ) ) 
} public static int validateAndComputeLength ( final DirectBufferVector [ ] vectors ) 
int messageLength = 0 ; 
for ( final DirectBufferVector vector : vectors ) 
vector . validate ( ) ; 
messageLength += vector . length ; 
if ( messageLength < 0 ) 
return messageLength ; 
} public static int producerWindowLength ( final int termBufferLength , final int defaultTermWindowLength ) 
int termWindowLength = termBufferLength / 2 ; 
if ( 0 != defaultTermWindowLength ) 
termWindowLength = Math . min ( defaultTermWindowLength , termWindowLength ) ; 
return termWindowLength ; 
} public static IdleStrategy agentIdleStrategy ( final String strategyName , final StatusIndicator controllableStatus ) 
IdleStrategy idleStrategy = null ; 
switch ( strategyName ) 
case DEFAULT_IDLE_STRATEGY : 
idleStrategy = new BackoffIdleStrategy ( 
IDLE_MAX_SPINS , IDLE_MAX_YIELDS , IDLE_MIN_PARK_NS , IDLE_MAX_PARK_NS ) ; 
case CONTROLLABLE_IDLE_STRATEGY : 
idleStrategy = new ControllableIdleStrategy ( controllableStatus ) ; 
controllableStatus . setOrdered ( ControllableIdleStrategy . PARK ) ; 
idleStrategy = ( IdleStrategy ) Class . forName ( strategyName ) . getConstructor ( ) . newInstance ( ) ; 
return idleStrategy ; 
} public static SendChannelEndpointSupplier sendChannelEndpointSupplier ( ) 
SendChannelEndpointSupplier supplier = null ; 
final String className = getProperty ( SEND_CHANNEL_ENDPOINT_SUPPLIER_PROP_NAME ) ; 
if ( null == className ) 
return new DefaultSendChannelEndpointSupplier ( ) ; 
supplier = ( SendChannelEndpointSupplier ) Class . forName ( className ) . getConstructor ( ) . newInstance ( ) ; 
return supplier ; 
} public static ReceiveChannelEndpointSupplier receiveChannelEndpointSupplier ( ) 
ReceiveChannelEndpointSupplier supplier = null ; 
final String className = getProperty ( RECEIVE_CHANNEL_ENDPOINT_SUPPLIER_PROP_NAME ) ; 
return new DefaultReceiveChannelEndpointSupplier ( ) ; 
supplier = ( ReceiveChannelEndpointSupplier ) Class . forName ( className ) . getConstructor ( ) . newInstance ( ) ; 
} public static FlowControlSupplier unicastFlowControlSupplier ( ) 
FlowControlSupplier supplier = null ; 
final String className = getProperty ( UNICAST_FLOW_CONTROL_STRATEGY_SUPPLIER_PROP_NAME ) ; 
return new DefaultUnicastFlowControlSupplier ( ) ; 
supplier = ( FlowControlSupplier ) Class . forName ( className ) . getConstructor ( ) . newInstance ( ) ; 
} public static FlowControlSupplier multicastFlowControlSupplier ( ) 
final String className = getProperty ( MULTICAST_FLOW_CONTROL_STRATEGY_SUPPLIER_PROP_NAME ) ; 
return new DefaultMulticastFlowControlSupplier ( ) ; 
} public static CongestionControlSupplier congestionControlSupplier ( ) 
CongestionControlSupplier supplier = null ; 
final String className = getProperty ( CONGESTION_CONTROL_STRATEGY_SUPPLIER_PROP_NAME ) ; 
return new DefaultCongestionControlSupplier ( ) ; 
supplier = ( CongestionControlSupplier ) Class . forName ( className ) . getConstructor ( ) . newInstance ( ) ; 
} public static void validateMtuLength ( final int mtuLength ) 
if ( mtuLength < DataHeaderFlyweight . HEADER_LENGTH || mtuLength > MAX_UDP_PAYLOAD_LENGTH ) 
throw new ConfigurationException ( 
if ( ( mtuLength & ( FrameDescriptor . FRAME_ALIGNMENT - 1 ) ) != 0 ) 
} public static TerminationValidator terminationValidator ( ) 
TerminationValidator validator = null ; 
final String className = getProperty ( TERMINATION_VALIDATOR_PROP_NAME ) ; 
return new DefaultDenyTerminationValidator ( ) ; 
validator = ( TerminationValidator ) Class . forName ( className ) . getConstructor ( ) . newInstance ( ) ; 
return validator ; 
} public static void validateSocketBufferLengths ( final MediaDriver . Context ctx ) 
try ( DatagramChannel probe = DatagramChannel . open ( ) ) 
final int defaultSoSndBuf = probe . getOption ( StandardSocketOptions . SO_SNDBUF ) ; 
probe . setOption ( StandardSocketOptions . SO_SNDBUF , Integer . MAX_VALUE ) ; 
final int maxSoSndBuf = probe . getOption ( StandardSocketOptions . SO_SNDBUF ) ; 
if ( maxSoSndBuf < ctx . socketSndbufLength ( ) ) 
System . err . format ( 
SOCKET_SNDBUF_LENGTH_PROP_NAME , 
ctx . socketSndbufLength ( ) , 
maxSoSndBuf ) ; 
probe . setOption ( StandardSocketOptions . SO_RCVBUF , Integer . MAX_VALUE ) ; 
final int maxSoRcvBuf = probe . getOption ( StandardSocketOptions . SO_RCVBUF ) ; 
if ( maxSoRcvBuf < ctx . socketRcvbufLength ( ) ) 
SOCKET_RCVBUF_LENGTH_PROP_NAME , 
ctx . socketRcvbufLength ( ) , 
maxSoRcvBuf ) ; 
final int soSndBuf = 0 == ctx . socketSndbufLength ( ) ? defaultSoSndBuf : ctx . socketSndbufLength ( ) ; 
if ( ctx . mtuLength ( ) > soSndBuf ) 
throw new ConfigurationException ( String . format ( 
ctx . mtuLength ( ) , 
soSndBuf ) ) ; 
if ( ctx . initialWindowLength ( ) > maxSoRcvBuf ) 
Configuration . INITIAL_WINDOW_LENGTH_PROP_NAME + 
} public static void validatePageSize ( final int pageSize ) 
if ( pageSize < PAGE_MIN_SIZE ) 
if ( pageSize > PAGE_MAX_SIZE ) 
if ( ! BitUtil . isPowerOfTwo ( pageSize ) ) 
} public static void validateSessionIdRange ( final int low , final int high ) 
if ( low > high ) 
if ( Math . abs ( ( long ) high - low ) > Integer . MAX_VALUE ) 
} public static void validateUnblockTimeout ( 
final long publicationUnblockTimeoutNs , final long clientLivenessTimeoutNs , final long timerIntervalNs ) 
if ( publicationUnblockTimeoutNs <= clientLivenessTimeoutNs ) 
"publicationUnblockTimeoutNs=" + publicationUnblockTimeoutNs + 
if ( clientLivenessTimeoutNs <= timerIntervalNs ) 
"clientLivenessTimeoutNs=" + clientLivenessTimeoutNs + 
} public ErrorResponseFlyweight errorCode ( final ErrorCode code ) 
buffer . putInt ( offset + ERROR_CODE_OFFSET , code . value ( ) ) ; 
} static Set < ClusterEventCode > getEnabledClusterEventCodes ( final String enabledClusterEventCodes ) 
if ( null == enabledClusterEventCodes || "" . equals ( enabledClusterEventCodes ) ) 
return EnumSet . noneOf ( ClusterEventCode . class ) ; 
final Function < Integer , ClusterEventCode > eventCodeById = ClusterEventCode :: get ; 
final Function < String , ClusterEventCode > eventCodeByName = ClusterEventCode :: valueOf ; 
final EnumSet < ClusterEventCode > allEventsSet = EnumSet . allOf ( ClusterEventCode . class ) ; 
return parseEventCodes ( enabledClusterEventCodes , eventCodeById , eventCodeByName , allEventsSet ) ; 
} static Set < ArchiveEventCode > getEnabledArchiveEventCodes ( final String enabledArchiveEventCodes ) 
if ( null == enabledArchiveEventCodes || "" . equals ( enabledArchiveEventCodes ) ) 
return EnumSet . noneOf ( ArchiveEventCode . class ) ; 
final Function < Integer , ArchiveEventCode > eventCodeById = ArchiveEventCode :: get ; 
final Function < String , ArchiveEventCode > eventCodeByName = ArchiveEventCode :: valueOf ; 
final EnumSet < ArchiveEventCode > allEventsSet = EnumSet . allOf ( ArchiveEventCode . class ) ; 
return parseEventCodes ( enabledArchiveEventCodes , eventCodeById , eventCodeByName , allEventsSet ) ; 
} static Set < DriverEventCode > getEnabledDriverEventCodes ( final String enabledLoggerEventCodes ) 
if ( null == enabledLoggerEventCodes || "" . equals ( enabledLoggerEventCodes ) ) 
return EnumSet . noneOf ( DriverEventCode . class ) ; 
final Set < DriverEventCode > eventCodeSet = new HashSet < > ( ) ; 
final String [ ] codeIds = enabledLoggerEventCodes . split ( "," ) ; 
for ( final String codeId : codeIds ) 
switch ( codeId ) 
case "all" : 
eventCodeSet . addAll ( ALL_LOGGER_EVENT_CODES ) ; 
case "admin" : 
eventCodeSet . addAll ( ADMIN_ONLY_EVENT_CODES ) ; 
DriverEventCode code = null ; 
code = DriverEventCode . valueOf ( codeId ) ; 
catch ( final IllegalArgumentException ignore ) 
if ( null == code ) 
code = DriverEventCode . get ( Integer . parseInt ( codeId ) ) ; 
if ( null != code ) 
eventCodeSet . add ( code ) ; 
return eventCodeSet ; 
} public void reset ( ) 
isBallotSent = false ; 
isLeader = false ; 
hasRequestedJoin = false ; 
hasSentTerminationAck = false ; 
vote = null ; 
candidateTermId = Aeron . NULL_VALUE ; 
leadershipTermId = Aeron . NULL_VALUE ; 
logPosition = NULL_POSITION ; 
} public static ClusterMember [ ] parse ( final String value ) 
if ( null == value || value . length ( ) == 0 ) 
return ClusterMember . EMPTY_CLUSTER_MEMBER_ARRAY ; 
final String [ ] memberValues = value . split ( "\\|" ) ; 
final int length = memberValues . length ; 
final ClusterMember [ ] members = new ClusterMember [ length ] ; 
for ( int i = 0 ; i < length ; i ++ ) 
final String endpointsDetail = memberValues [ i ] ; 
final String [ ] memberAttributes = endpointsDetail . split ( "," ) ; 
if ( memberAttributes . length != 6 ) 
final String justEndpoints = String . join ( 
"," , 
memberAttributes [ 1 ] , 
memberAttributes [ 2 ] , 
memberAttributes [ 3 ] , 
memberAttributes [ 4 ] , 
memberAttributes [ 5 ] ) ; 
members [ i ] = new ClusterMember ( 
Integer . parseInt ( memberAttributes [ 0 ] ) , 
memberAttributes [ 5 ] , 
justEndpoints ) ; 
return members ; 
} public static String encodeAsString ( final ClusterMember [ ] clusterMembers ) 
for ( int i = 0 , length = clusterMembers . length ; i < length ; i ++ ) 
final ClusterMember member = clusterMembers [ i ] ; 
. append ( member . id ( ) ) 
. append ( ',' ) 
. append ( member . endpointsDetail ( ) ) ; 
if ( ( length - 1 ) != i ) 
builder . append ( '|' ) ; 
} public static void addMemberStatusPublications ( 
final ClusterMember [ ] members , 
final ClusterMember exclude , 
final ChannelUri channelUri , 
final Aeron aeron ) 
for ( final ClusterMember member : members ) 
if ( member != exclude ) 
channelUri . put ( ENDPOINT_PARAM_NAME , member . memberFacingEndpoint ( ) ) ; 
member . publication = aeron . addExclusivePublication ( channelUri . toString ( ) , streamId ) ; 
} public static void closeMemberPublications ( final ClusterMember [ ] clusterMembers ) 
for ( final ClusterMember member : clusterMembers ) 
CloseHelper . close ( member . publication ) ; 
} public static void addMemberStatusPublication ( 
final ClusterMember member , final ChannelUri channelUri , final int streamId , final Aeron aeron ) 
} public static void addClusterMemberIds ( 
final ClusterMember [ ] clusterMembers , final Int2ObjectHashMap < ClusterMember > clusterMemberByIdMap ) 
clusterMemberByIdMap . put ( member . id ( ) , member ) ; 
} public static boolean hasActiveQuorum ( 
final ClusterMember [ ] clusterMembers , final long nowMs , final long timeoutMs ) 
int threshold = quorumThreshold ( clusterMembers . length ) ; 
if ( member . isLeader ( ) || nowMs <= ( member . timeOfLastAppendPositionMs ( ) + timeoutMs ) ) 
if ( -- threshold <= 0 ) 
} public static long quorumPosition ( final ClusterMember [ ] members , final long [ ] rankedPositions ) 
final int length = rankedPositions . length ; 
rankedPositions [ i ] = 0 ; 
long newPosition = member . logPosition ; 
final long rankedPosition = rankedPositions [ i ] ; 
if ( newPosition > rankedPosition ) 
rankedPositions [ i ] = newPosition ; 
newPosition = rankedPosition ; 
return rankedPositions [ length - 1 ] ; 
} public static void resetLogPositions ( final ClusterMember [ ] clusterMembers , final long logPosition ) 
member . logPosition ( logPosition ) ; 
} public static boolean haveVotersReachedPosition ( 
final ClusterMember [ ] clusterMembers , final long position , final long leadershipTermId ) 
if ( member . vote != null && ( member . logPosition < position || member . leadershipTermId != leadershipTermId ) ) 
} public static void becomeCandidate ( 
final ClusterMember [ ] members , final long candidateTermId , final int candidateMemberId ) 
if ( member . id == candidateMemberId ) 
member . vote ( Boolean . TRUE ) 
. candidateTermId ( candidateTermId ) 
. isBallotSent ( true ) ; 
member . vote ( null ) 
. candidateTermId ( Aeron . NULL_VALUE ) 
. isBallotSent ( false ) ; 
} public static boolean hasWonVoteOnFullCount ( final ClusterMember [ ] members , final long candidateTermId ) 
int votes = 0 ; 
if ( null == member . vote || member . candidateTermId != candidateTermId ) 
votes += member . vote ? 1 : 0 ; 
return votes >= ClusterMember . quorumThreshold ( members . length ) ; 
} public static boolean hasMajorityVoteWithCanvassMembers ( final ClusterMember [ ] members , final long candidateTermId ) 
if ( NULL_POSITION != member . logPosition && null == member . vote ) 
if ( Boolean . TRUE . equals ( member . vote ) && member . candidateTermId == candidateTermId ) 
++ votes ; 
} public static boolean hasMajorityVote ( final ClusterMember [ ] clusterMembers , final long candidateTermId ) 
return votes >= ClusterMember . quorumThreshold ( clusterMembers . length ) ; 
} public static ClusterMember determineMember ( 
final ClusterMember [ ] clusterMembers , final int memberId , final String memberEndpoints ) 
ClusterMember member = NULL_VALUE != memberId ? ClusterMember . findMember ( clusterMembers , memberId ) : null ; 
if ( ( null == clusterMembers || 0 == clusterMembers . length ) && null == member ) 
member = ClusterMember . parseEndpoints ( NULL_VALUE , memberEndpoints ) ; 
if ( null == member ) 
if ( ! "" . equals ( memberEndpoints ) ) 
ClusterMember . validateMemberEndpoints ( member , memberEndpoints ) ; 
return member ; 
} public static void validateMemberEndpoints ( final ClusterMember member , final String memberEndpoints ) 
final ClusterMember endpointMember = ClusterMember . parseEndpoints ( Aeron . NULL_VALUE , memberEndpoints ) ; 
if ( ! areSameEndpoints ( member , endpointMember ) ) 
throw new ClusterException ( 
} public static boolean areSameEndpoints ( final ClusterMember lhs , final ClusterMember rhs ) 
return lhs . clientFacingEndpoint ( ) . equals ( rhs . clientFacingEndpoint ( ) ) && 
lhs . memberFacingEndpoint ( ) . equals ( rhs . memberFacingEndpoint ( ) ) && 
lhs . logEndpoint ( ) . equals ( rhs . logEndpoint ( ) ) && 
lhs . transferEndpoint ( ) . equals ( rhs . transferEndpoint ( ) ) && 
lhs . archiveEndpoint ( ) . equals ( rhs . archiveEndpoint ( ) ) ; 
} public static boolean isUnanimousCandidate ( final ClusterMember [ ] clusterMembers , final ClusterMember candidate ) 
if ( NULL_POSITION == member . logPosition || compareLog ( candidate , member ) < 0 ) 
} public static boolean isQuorumCandidate ( final ClusterMember [ ] clusterMembers , final ClusterMember candidate ) 
int possibleVotes = 0 ; 
++ possibleVotes ; 
return possibleVotes >= ClusterMember . quorumThreshold ( clusterMembers . length ) ; 
} public static int compareLog ( 
final long lhsLogLeadershipTermId , 
final long lhsLogPosition , 
final long rhsLogLeadershipTermId , 
final long rhsLogPosition ) 
if ( lhsLogLeadershipTermId > rhsLogLeadershipTermId ) 
return 1 ; 
else if ( lhsLogLeadershipTermId < rhsLogLeadershipTermId ) 
else if ( lhsLogPosition > rhsLogPosition ) 
else if ( lhsLogPosition < rhsLogPosition ) 
} public static int compareLog ( final ClusterMember lhs , final ClusterMember rhs ) 
return compareLog ( lhs . leadershipTermId , lhs . logPosition , rhs . leadershipTermId , rhs . logPosition ) ; 
} public static boolean isNotDuplicateEndpoints ( final ClusterMember [ ] members , final String memberEndpoints ) 
if ( member . endpointsDetail ( ) . equals ( memberEndpoints ) ) 
} public static int findMemberIndex ( final ClusterMember [ ] clusterMembers , final int memberId ) 
final int length = clusterMembers . length ; 
int index = ArrayUtil . UNKNOWN_INDEX ; 
if ( clusterMembers [ i ] . id ( ) == memberId ) 
index = i ; 
return index ; 
} public static ClusterMember findMember ( final ClusterMember [ ] clusterMembers , final int memberId ) 
if ( member . id ( ) == memberId ) 
} public static ClusterMember [ ] addMember ( final ClusterMember [ ] oldMembers , final ClusterMember newMember ) 
return ArrayUtil . add ( oldMembers , newMember ) ; 
} public static ClusterMember [ ] removeMember ( final ClusterMember [ ] oldMembers , final int memberId ) 
return ArrayUtil . remove ( oldMembers , findMemberIndex ( oldMembers , memberId ) ) ; 
} public static int highMemberId ( final ClusterMember [ ] clusterMembers ) 
int highId = Aeron . NULL_VALUE ; 
highId = Math . max ( highId , member . id ( ) ) ; 
return highId ; 
} public static String clientFacingEndpoints ( final ClusterMember [ ] members ) 
final StringBuilder builder = new StringBuilder ( 100 ) ; 
for ( int i = 0 , length = members . length ; i < length ; i ++ ) 
if ( 0 != i ) 
builder . append ( ',' ) ; 
final ClusterMember member = members [ i ] ; 
builder . append ( member . id ( ) ) . append ( '=' ) . append ( member . clientFacingEndpoint ( ) ) ; 
long minPosition = Long . MAX_VALUE ; 
long minLimitPosition = Long . MAX_VALUE ; 
final ArrayList < Receiver > receiverList = this . receiverList ; 
for ( int lastIndex = receiverList . size ( ) - 1 , i = lastIndex ; i >= 0 ; i -- ) 
final Receiver receiver = receiverList . get ( i ) ; 
if ( ( receiver . timeOfLastStatusMessageNs + RECEIVER_TIMEOUT ) - timeNs < 0 ) 
ArrayListUtil . fastUnorderedRemove ( receiverList , i , lastIndex -- ) ; 
minPosition = Math . min ( minPosition , receiver . lastPosition ) ; 
minLimitPosition = Math . min ( minLimitPosition , receiver . lastPositionPlusWindow ) ; 
if ( 0 == receiverList . size ( ) || minPosition >= senderPosition ) 
return receiverList . size ( ) > 0 ? minLimitPosition : senderLimit ; 
} public static Status unblock ( 
final UnsafeBuffer logMetaDataBuffer , 
final UnsafeBuffer termBuffer , 
final int blockedOffset , 
final int tailOffset , 
final int termId ) 
Status status = NO_ACTION ; 
int frameLength = frameLengthVolatile ( termBuffer , blockedOffset ) ; 
if ( frameLength < 0 ) 
resetHeader ( logMetaDataBuffer , termBuffer , blockedOffset , termId , - frameLength ) ; 
status = UNBLOCKED ; 
else if ( 0 == frameLength ) 
int currentOffset = blockedOffset + FRAME_ALIGNMENT ; 
while ( currentOffset < tailOffset ) 
frameLength = frameLengthVolatile ( termBuffer , currentOffset ) ; 
if ( frameLength != 0 ) 
if ( scanBackToConfirmZeroed ( termBuffer , currentOffset , blockedOffset ) ) 
final int length = currentOffset - blockedOffset ; 
resetHeader ( logMetaDataBuffer , termBuffer , blockedOffset , termId , length ) ; 
currentOffset += FRAME_ALIGNMENT ; 
if ( currentOffset == termBuffer . capacity ( ) ) 
if ( 0 == frameLengthVolatile ( termBuffer , blockedOffset ) ) 
status = UNBLOCKED_TO_END ; 
} public MappedByteBuffer mapExistingCncFile ( final Consumer < String > logger ) 
final File cncFile = new File ( aeronDirectory , CncFileDescriptor . CNC_FILE ) ; 
if ( cncFile . exists ( ) && cncFile . length ( ) > 0 ) 
if ( null != logger ) 
return IoUtil . mapExistingFile ( cncFile , CncFileDescriptor . CNC_FILE ) ; 
} public static boolean isDriverActive ( 
final File directory , final long driverTimeoutMs , final Consumer < String > logger ) 
final File cncFile = new File ( directory , CncFileDescriptor . CNC_FILE ) ; 
return isDriverActive ( driverTimeoutMs , logger , cncByteBuffer ) ; 
IoUtil . unmap ( cncByteBuffer ) ; 
} public boolean isDriverActive ( final long driverTimeoutMs , final Consumer < String > logger ) 
final MappedByteBuffer cncByteBuffer = mapExistingCncFile ( logger ) ; 
final long driverTimeoutMs , final Consumer < String > logger , final ByteBuffer cncByteBuffer ) 
if ( null == cncByteBuffer ) 
final UnsafeBuffer cncMetaDataBuffer = CncFileDescriptor . createMetaDataBuffer ( cncByteBuffer ) ; 
final long startTimeMs = System . currentTimeMillis ( ) ; 
int cncVersion ; 
while ( 0 == ( cncVersion = cncMetaDataBuffer . getIntVolatile ( CncFileDescriptor . cncVersionOffset ( 0 ) ) ) ) 
if ( System . currentTimeMillis ( ) > ( startTimeMs + driverTimeoutMs ) ) 
sleep ( 1 ) ; 
if ( CNC_VERSION != cncVersion ) 
final ManyToOneRingBuffer toDriverBuffer = new ManyToOneRingBuffer ( 
CncFileDescriptor . createToDriverBuffer ( cncByteBuffer , cncMetaDataBuffer ) ) ; 
final long timestamp = toDriverBuffer . consumerHeartbeatTime ( ) ; 
final long now = System . currentTimeMillis ( ) ; 
final long timestampAge = now - timestamp ; 
return timestampAge <= driverTimeoutMs ; 
} public static boolean requestDriverTermination ( 
final File directory , 
final DirectBuffer tokenBuffer , 
final int tokenOffset , 
final int tokenLength ) 
final int cncVersion = cncMetaDataBuffer . getIntVolatile ( cncVersionOffset ( 0 ) ) ; 
final long clientId = toDriverBuffer . nextCorrelationId ( ) ; 
final DriverProxy driverProxy = new DriverProxy ( toDriverBuffer , clientId ) ; 
return driverProxy . terminateDriver ( tokenBuffer , tokenOffset , tokenLength ) ; 
} public int saveErrorLog ( final PrintStream out ) 
final MappedByteBuffer cncByteBuffer = mapExistingCncFile ( null ) ; 
return saveErrorLog ( out , cncByteBuffer ) ; 
} public int saveErrorLog ( final PrintStream out , final ByteBuffer cncByteBuffer ) 
final int cncVersion = cncMetaDataBuffer . getInt ( CncFileDescriptor . cncVersionOffset ( 0 ) ) ; 
int distinctErrorCount = 0 ; 
final AtomicBuffer buffer = CncFileDescriptor . createErrorLogBuffer ( cncByteBuffer , cncMetaDataBuffer ) ; 
if ( ErrorLogReader . hasErrors ( buffer ) ) 
final ErrorConsumer errorConsumer = ( count , firstTimestamp , lastTimestamp , ex ) -> 
formatError ( out , dateFormat , count , firstTimestamp , lastTimestamp , ex ) ; 
distinctErrorCount = ErrorLogReader . read ( buffer , errorConsumer ) ; 
out . println ( ) ; 
return distinctErrorCount ; 
} public static int frameLengthVolatile ( final UnsafeBuffer buffer , final int termOffset ) 
int frameLength = buffer . getIntVolatile ( termOffset ) ; 
if ( ByteOrder . nativeOrder ( ) != LITTLE_ENDIAN ) 
frameLength = Integer . reverseBytes ( frameLength ) ; 
return frameLength ; 
} public static void frameLengthOrdered ( final UnsafeBuffer buffer , final int termOffset , final int frameLength ) 
int length = frameLength ; 
length = Integer . reverseBytes ( frameLength ) ; 
buffer . putIntOrdered ( termOffset , length ) ; 
} public static void frameType ( final UnsafeBuffer buffer , final int termOffset , final int type ) 
buffer . putShort ( typeOffset ( termOffset ) , ( short ) type , LITTLE_ENDIAN ) ; 
} public static void frameFlags ( final UnsafeBuffer buffer , final int termOffset , final byte flags ) 
buffer . putByte ( flagsOffset ( termOffset ) , flags ) ; 
} public static void frameTermOffset ( final UnsafeBuffer buffer , final int termOffset ) 
buffer . putInt ( termOffsetOffset ( termOffset ) , termOffset , LITTLE_ENDIAN ) ; 
} public static void frameTermId ( final UnsafeBuffer buffer , final int termOffset , final int termId ) 
buffer . putInt ( termIdOffset ( termOffset ) , termId , LITTLE_ENDIAN ) ; 
} public void registerForSend ( final NetworkPublication publication ) 
publicationBySessionAndStreamId . put ( publication . sessionId ( ) , publication . streamId ( ) , publication ) ; 
} public int send ( final ByteBuffer buffer ) 
int bytesSent = 0 ; 
final int bytesToSend = buffer . remaining ( ) ; 
if ( null == multiDestination ) 
sendHook ( buffer , connectAddress ) ; 
if ( sendDatagramChannel . isConnected ( ) ) 
bytesSent = sendDatagramChannel . write ( buffer ) ; 
catch ( final PortUnreachableException ignore ) 
sendError ( bytesToSend , ex , connectAddress ) ; 
bytesSent = multiDestination . send ( sendDatagramChannel , buffer , this , bytesToSend ) ; 
return bytesSent ; 
} public static int findCounterIdByRecording ( final CountersReader countersReader , final long recordingId ) 
final DirectBuffer buffer = countersReader . metaDataBuffer ( ) ; 
for ( int i = 0 , size = countersReader . maxCounterId ( ) ; i < size ; i ++ ) 
if ( countersReader . getCounterState ( i ) == RECORD_ALLOCATED ) 
if ( buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == RECORDING_POSITION_TYPE_ID && 
buffer . getLong ( recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET ) == recordingId ) 
return i ; 
return NULL_COUNTER_ID ; 
} public static int findCounterIdBySession ( final CountersReader countersReader , final int sessionId ) 
buffer . getInt ( recordOffset + KEY_OFFSET + SESSION_ID_OFFSET ) == sessionId ) 
} public static long getRecordingId ( final CountersReader countersReader , final int counterId ) 
if ( countersReader . getCounterState ( counterId ) == RECORD_ALLOCATED ) 
final int recordOffset = CountersReader . metaDataOffset ( counterId ) ; 
if ( buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == RECORDING_POSITION_TYPE_ID ) 
return buffer . getLong ( recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET ) ; 
return NULL_RECORDING_ID ; 
} public static String getSourceIdentity ( final CountersReader countersReader , final int counterId ) 
return buffer . getStringAscii ( recordOffset + KEY_OFFSET + SOURCE_IDENTITY_LENGTH_OFFSET ) ; 
} public static boolean isActive ( final CountersReader countersReader , final int counterId , final long recordingId ) 
return 
buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == RECORDING_POSITION_TYPE_ID && 
buffer . getLong ( recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET ) == recordingId ; 
} static InetSocketAddress parse ( final CharSequence cs ) 
if ( null == cs || cs . length ( ) == 0 ) 
InetSocketAddress address = tryParseIpV4 ( cs ) ; 
if ( null == address ) 
address = tryParseIpV6 ( cs ) ; 
final long windowLength = flyweight . receiverWindowLength ( ) ; 
final long receiverId = flyweight . receiverId ( ) ; 
final boolean isFromPreferred = isFromPreferred ( flyweight ) ; 
final long lastPositionPlusWindow = position + windowLength ; 
boolean isExisting = false ; 
for ( int i = 0 , size = receiverList . size ( ) ; i < size ; i ++ ) 
if ( isFromPreferred && receiverId == receiver . receiverId ) 
receiver . lastPosition = Math . max ( position , receiver . lastPosition ) ; 
receiver . lastPositionPlusWindow = lastPositionPlusWindow ; 
receiver . timeOfLastStatusMessageNs = timeNs ; 
isExisting = true ; 
minPosition = Math . min ( minPosition , receiver . lastPositionPlusWindow ) ; 
if ( isFromPreferred && ! isExisting ) 
receiverList . add ( new Receiver ( position , lastPositionPlusWindow , timeNs , receiverId , receiverAddress ) ) ; 
minPosition = Math . min ( minPosition , lastPositionPlusWindow ) ; 
return receiverList . size ( ) > 0 ? 
Math . max ( senderLimit , minPosition ) : 
Math . max ( senderLimit , lastPositionPlusWindow ) ; 
} public static int scanForGap ( 
final int limitOffset , 
final GapHandler handler ) 
int offset = termOffset ; 
final int frameLength = frameLengthVolatile ( termBuffer , offset ) ; 
offset += align ( frameLength , FRAME_ALIGNMENT ) ; 
while ( offset < limitOffset ) ; 
final int gapBeginOffset = offset ; 
if ( offset < limitOffset ) 
final int limit = limitOffset - ALIGNED_HEADER_LENGTH ; 
while ( offset < limit ) 
offset += FRAME_ALIGNMENT ; 
if ( 0 != termBuffer . getIntVolatile ( offset ) ) 
offset -= ALIGNED_HEADER_LENGTH ; 
final int gapLength = ( offset - gapBeginOffset ) + ALIGNED_HEADER_LENGTH ; 
handler . onGap ( termId , gapBeginOffset , gapLength ) ; 
return gapBeginOffset ; 
} public static ClusteredMediaDriver launch ( 
final MediaDriver . Context driverCtx , 
final Archive . Context archiveCtx , 
final ConsensusModule . Context consensusModuleCtx ) 
final MediaDriver driver = MediaDriver . launch ( driverCtx 
. spiesSimulateConnection ( true ) ) ; 
final ConsensusModule consensusModule = ConsensusModule . launch ( consensusModuleCtx ) ; 
return new ClusteredMediaDriver ( driver , archive , consensusModule ) ; 
} public long receiverId ( ) 
final long value ; 
if ( ByteOrder . nativeOrder ( ) == LITTLE_ENDIAN ) 
value = 
( 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 7 ) ) << 56 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 6 ) & 0xFF ) << 48 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 5 ) & 0xFF ) << 40 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 4 ) & 0xFF ) << 32 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 3 ) & 0xFF ) << 24 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 2 ) & 0xFF ) << 16 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 1 ) & 0xFF ) << 8 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 0 ) & 0xFF ) ) 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 0 ) ) << 56 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 1 ) & 0xFF ) << 48 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 2 ) & 0xFF ) << 40 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 3 ) & 0xFF ) << 32 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 4 ) & 0xFF ) << 24 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 5 ) & 0xFF ) << 16 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 6 ) & 0xFF ) << 8 ) | 
( ( ( long ) getByte ( RECEIVER_ID_FIELD_OFFSET + 7 ) & 0xFF ) ) 
} public StatusMessageFlyweight receiverId ( final long id ) 
putByte ( RECEIVER_ID_FIELD_OFFSET + 7 , ( byte ) ( id > > 56 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 6 , ( byte ) ( id > > 48 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 5 , ( byte ) ( id > > 40 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 4 , ( byte ) ( id > > 32 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 3 , ( byte ) ( id > > 24 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 2 , ( byte ) ( id > > 16 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 1 , ( byte ) ( id > > 8 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 0 , ( byte ) ( id ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 0 , ( byte ) ( id > > 56 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 1 , ( byte ) ( id > > 48 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 2 , ( byte ) ( id > > 40 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 3 , ( byte ) ( id > > 32 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 4 , ( byte ) ( id > > 24 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 5 , ( byte ) ( id > > 16 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 6 , ( byte ) ( id > > 8 ) ) ; 
putByte ( RECEIVER_ID_FIELD_OFFSET + 7 , ( byte ) ( id ) ) ; 
} public int applicationSpecificFeedback ( final byte [ ] destination ) 
final int frameLength = frameLength ( ) ; 
int result = 0 ; 
if ( frameLength > HEADER_LENGTH ) 
if ( frameLength > capacity ( ) ) 
throw new AeronException ( String . format ( 
frameLength - HEADER_LENGTH , 
capacity ( ) - HEADER_LENGTH ) ) ; 
final int copyLength = Math . min ( destination . length , frameLength - HEADER_LENGTH ) ; 
getBytes ( APP_SPECIFIC_FEEDBACK_FIELD_OFFSET , destination , 0 , copyLength ) ; 
result = copyLength ; 
} public StatusMessageFlyweight applicationSpecificFeedback ( final byte [ ] source , final int offset , final int length ) 
frameLength ( HEADER_LENGTH + length ) ; 
putBytes ( APP_SPECIFIC_FEEDBACK_FIELD_OFFSET , source , offset , length ) ; 
} public void reload ( ) 
entries . clear ( ) ; 
indexByLeadershipTermIdMap . clear ( ) ; 
indexByLeadershipTermIdMap . compact ( ) ; 
nextEntryIndex = 0 ; 
byteBuffer . clear ( ) ; 
while ( true ) 
final int bytes = fileChannel . read ( byteBuffer ) ; 
if ( byteBuffer . remaining ( ) == 0 ) 
byteBuffer . flip ( ) ; 
captureEntriesFromBuffer ( byteBuffer , buffer , entries ) ; 
if ( - 1 == bytes ) 
if ( byteBuffer . position ( ) > 0 ) 
} public long findLastTermRecordingId ( ) 
for ( int i = entries . size ( ) - 1 ; i >= 0 ; i -- ) 
final Entry entry = entries . get ( i ) ; 
if ( ENTRY_TYPE_TERM == entry . type ) 
return entry . recordingId ; 
return RecordingPos . NULL_RECORDING_ID ; 
} public Entry findLastTerm ( ) 
return entry ; 
} public Entry getTermEntry ( final long leadershipTermId ) 
final int index = ( int ) indexByLeadershipTermIdMap . get ( leadershipTermId ) ; 
if ( NULL_VALUE == index ) 
return entries . get ( index ) ; 
} public RecoveryPlan createRecoveryPlan ( final AeronArchive archive , final int serviceCount ) 
final ArrayList < Snapshot > snapshots = new ArrayList < > ( ) ; 
final ArrayList < Log > logs = new ArrayList < > ( ) ; 
planRecovery ( snapshots , logs , entries , archive , serviceCount ) ; 
long lastLeadershipTermId = NULL_VALUE ; 
long lastTermBaseLogPosition = 0 ; 
long committedLogPosition = - 1 ; 
long appendedLogPosition = 0 ; 
final int snapshotStepsSize = snapshots . size ( ) ; 
if ( snapshotStepsSize > 0 ) 
final Snapshot snapshot = snapshots . get ( 0 ) ; 
lastLeadershipTermId = snapshot . leadershipTermId ; 
lastTermBaseLogPosition = snapshot . termBaseLogPosition ; 
appendedLogPosition = snapshot . logPosition ; 
committedLogPosition = snapshot . logPosition ; 
if ( ! logs . isEmpty ( ) ) 
final Log log = logs . get ( 0 ) ; 
lastLeadershipTermId = log . leadershipTermId ; 
lastTermBaseLogPosition = log . termBaseLogPosition ; 
appendedLogPosition = log . stopPosition ; 
committedLogPosition = log . logPosition ; 
return new RecoveryPlan ( 
lastLeadershipTermId , 
lastTermBaseLogPosition , 
appendedLogPosition , 
committedLogPosition , 
snapshots , 
logs ) ; 
} public static RecoveryPlan createRecoveryPlan ( final ArrayList < RecordingLog . Snapshot > snapshots ) 
new ArrayList < > ( ) ) ; 
} public void appendTerm ( 
final long recordingId , final long leadershipTermId , final long termBaseLogPosition , final long timestamp ) 
final int size = entries . size ( ) ; 
if ( size > 0 ) 
final Entry lastEntry = entries . get ( size - 1 ) ; 
if ( lastEntry . type != NULL_VALUE && lastEntry . leadershipTermId >= leadershipTermId ) 
indexByLeadershipTermIdMap . put ( leadershipTermId , nextEntryIndex ) ; 
append ( 
ENTRY_TYPE_TERM , 
leadershipTermId , 
termBaseLogPosition , 
NULL_POSITION , 
timestamp , 
NULL_VALUE ) ; 
} public void appendSnapshot ( 
final long leadershipTermId , 
final long termBaseLogPosition , 
final long logPosition , 
final long timestamp , 
final int serviceId ) 
final Entry entry = entries . get ( size - 1 ) ; 
if ( entry . type == ENTRY_TYPE_TERM && entry . leadershipTermId != leadershipTermId ) 
ENTRY_TYPE_SNAPSHOT , 
logPosition , 
serviceId ) ; 
} public void commitLogPosition ( final long leadershipTermId , final long logPosition ) 
final int index = getLeadershipTermEntryIndex ( leadershipTermId ) ; 
commitEntryValue ( index , logPosition , LOG_POSITION_OFFSET ) ; 
final Entry entry = entries . get ( index ) ; 
entries . set ( index , new Entry ( 
entry . recordingId , 
entry . leadershipTermId , 
entry . termBaseLogPosition , 
entry . timestamp , 
entry . serviceId , 
entry . type , 
entry . entryIndex ) ) ; 
} public void tombstoneEntry ( final long leadershipTermId , final int entryIndex ) 
int index = - 1 ; 
for ( int i = 0 , size = entries . size ( ) ; i < size ; i ++ ) 
if ( entry . leadershipTermId == leadershipTermId && entry . entryIndex == entryIndex ) 
index = entry . entryIndex ; 
indexByLeadershipTermIdMap . remove ( leadershipTermId ) ; 
if ( - 1 == index ) 
buffer . putInt ( 0 , NULL_VALUE , LITTLE_ENDIAN ) ; 
byteBuffer . limit ( SIZE_OF_INT ) . position ( 0 ) ; 
final long filePosition = ( index * ( long ) ENTRY_LENGTH ) + ENTRY_TYPE_OFFSET ; 
if ( SIZE_OF_INT != fileChannel . write ( byteBuffer , filePosition ) ) 
} public static AeronCluster connect ( final AeronCluster . Context ctx ) 
final long deadlineNs = aeron . context ( ) . nanoClock ( ) . nanoTime ( ) + ctx . messageTimeoutNs ( ) ; 
subscription = aeron . addSubscription ( ctx . egressChannel ( ) , ctx . egressStreamId ( ) ) ; 
asyncConnect = new AsyncConnect ( ctx , subscription , deadlineNs ) ; 
AeronCluster aeronCluster ; 
while ( null == ( aeronCluster = asyncConnect . poll ( ) ) ) 
return aeronCluster ; 
CloseHelper . close ( subscription ) ; 
CloseHelper . close ( asyncConnect ) ; 
final long deadlineNs = ctx . aeron ( ) . context ( ) . nanoClock ( ) . nanoTime ( ) + ctx . messageTimeoutNs ( ) ; 
subscription = ctx . aeron ( ) . addSubscription ( ctx . egressChannel ( ) , ctx . egressStreamId ( ) ) ; 
return new AsyncConnect ( ctx , subscription , deadlineNs ) ; 
if ( null != publication && publication . isConnected ( ) ) 
closeSession ( ) ; 
CloseHelper . close ( publication ) ; 
} public long offer ( final DirectBuffer buffer , final int offset , final int length ) 
return publication . offer ( headerBuffer , 0 , INGRESS_HEADER_LENGTH , buffer , offset , length , null ) ; 
} public long offer ( final DirectBufferVector [ ] vectors ) 
if ( headerVector != vectors [ 0 ] ) 
vectors [ 0 ] = headerVector ; 
return publication . offer ( vectors , null ) ; 
} public boolean sendKeepAlive ( ) 
idleStrategy . reset ( ) ; 
int attempts = SEND_ATTEMPTS ; 
final long result = publication . offer ( keepaliveMsgBuffer , 0 , keepaliveMsgBuffer . capacity ( ) , null ) ; 
if ( result > 0 ) 
if ( result == Publication . NOT_CONNECTED || result == Publication . CLOSED ) 
if ( result == Publication . MAX_POSITION_EXCEEDED ) 
if ( -- attempts <= 0 ) 
} public void onNewLeader ( 
final long clusterSessionId , 
final int leaderMemberId , 
final String memberEndpoints ) 
if ( clusterSessionId != this . clusterSessionId ) 
this . leadershipTermId = leadershipTermId ; 
this . leaderMemberId = leaderMemberId ; 
ingressMessageHeaderEncoder . leadershipTermId ( leadershipTermId ) ; 
sessionKeepAliveEncoder . leadershipTermId ( leadershipTermId ) ; 
if ( ctx . clusterMemberEndpoints ( ) != null ) 
ctx . clusterMemberEndpoints ( memberEndpoints ) ; 
updateMemberEndpoints ( memberEndpoints , leaderMemberId ) ; 
fragmentAssembler . clear ( ) ; 
controlledFragmentAssembler . clear ( ) ; 
egressListener . newLeader ( clusterSessionId , leadershipTermId , leaderMemberId , memberEndpoints ) ; 
controlledEgressListener . newLeader ( clusterSessionId , leadershipTermId , leaderMemberId , memberEndpoints ) ; 
} public static boolean unblock ( 
final UnsafeBuffer [ ] termBuffers , 
final long blockedPosition , 
final int termLength ) 
final int positionBitsToShift = LogBufferDescriptor . positionBitsToShift ( termLength ) ; 
final int blockedTermCount = ( int ) ( blockedPosition > > positionBitsToShift ) ; 
final int blockedOffset = ( int ) blockedPosition & ( termLength - 1 ) ; 
final int activeTermCount = activeTermCount ( logMetaDataBuffer ) ; 
if ( activeTermCount == ( blockedTermCount - 1 ) && blockedOffset == 0 ) 
final int currentTermId = termId ( rawTailVolatile ( logMetaDataBuffer , indexByTermCount ( activeTermCount ) ) ) ; 
return rotateLog ( logMetaDataBuffer , activeTermCount , currentTermId ) ; 
final int blockedIndex = indexByTermCount ( blockedTermCount ) ; 
final long rawTail = rawTailVolatile ( logMetaDataBuffer , blockedIndex ) ; 
final int tailOffset = termOffset ( rawTail , termLength ) ; 
final UnsafeBuffer termBuffer = termBuffers [ blockedIndex ] ; 
switch ( TermUnblocker . unblock ( logMetaDataBuffer , termBuffer , blockedOffset , tailOffset , termId ) ) 
case UNBLOCKED_TO_END : 
rotateLog ( logMetaDataBuffer , blockedTermCount , termId ) ; 
case UNBLOCKED : 
} public String channel ( ) 
final int length = buffer . getInt ( offset + CHANNEL_OFFSET ) ; 
lengthOfChannel = SIZE_OF_INT + length ; 
return buffer . getStringAscii ( offset + CHANNEL_OFFSET , length ) ; 
} public ImageMessageFlyweight channel ( final String channel ) 
} public static void checkTermLength ( final int termLength ) 
if ( termLength < TERM_MIN_LENGTH ) 
if ( termLength > TERM_MAX_LENGTH ) 
if ( ! BitUtil . isPowerOfTwo ( termLength ) ) 
} public static void checkPageSize ( final int pageSize ) 
} public static boolean casActiveTermCount ( 
final UnsafeBuffer metadataBuffer , final int expectedTermCount , final int updateTermCount ) 
return metadataBuffer . compareAndSetInt ( LOG_ACTIVE_TERM_COUNT_OFFSET , expectedTermCount , updateTermCount ) ; 
} public static long computePosition ( 
final int activeTermId , final int termOffset , final int positionBitsToShift , final int initialTermId ) 
final long termCount = activeTermId - initialTermId ; 
return ( termCount << positionBitsToShift ) + termOffset ; 
} public static long computeLogLength ( final int termLength , final int filePageSize ) 
if ( termLength < ( 1024 * 1024 * 1024 ) ) 
return align ( ( termLength * PARTITION_COUNT ) + LOG_META_DATA_LENGTH , filePageSize ) ; 
return ( PARTITION_COUNT * ( long ) termLength ) + align ( LOG_META_DATA_LENGTH , filePageSize ) ; 
} public static void storeDefaultFrameHeader ( final UnsafeBuffer metadataBuffer , final DirectBuffer defaultHeader ) 
if ( defaultHeader . capacity ( ) != HEADER_LENGTH ) 
metadataBuffer . putInt ( LOG_DEFAULT_FRAME_HEADER_LENGTH_OFFSET , HEADER_LENGTH ) ; 
metadataBuffer . putBytes ( LOG_DEFAULT_FRAME_HEADER_OFFSET , defaultHeader , 0 , HEADER_LENGTH ) ; 
} public static void applyDefaultHeader ( 
final UnsafeBuffer metadataBuffer , final UnsafeBuffer termBuffer , final int termOffset ) 
termBuffer . putBytes ( termOffset , metadataBuffer , LOG_DEFAULT_FRAME_HEADER_OFFSET , HEADER_LENGTH ) ; 
} public static boolean rotateLog ( final UnsafeBuffer metadataBuffer , final int termCount , final int termId ) 
final int nextTermId = termId + 1 ; 
final int nextTermCount = termCount + 1 ; 
final int nextIndex = indexByTermCount ( nextTermCount ) ; 
final int expectedTermId = nextTermId - PARTITION_COUNT ; 
long rawTail ; 
rawTail = rawTail ( metadataBuffer , nextIndex ) ; 
if ( expectedTermId != termId ( rawTail ) ) 
while ( ! casRawTail ( metadataBuffer , nextIndex , rawTail , packTail ( nextTermId , 0 ) ) ) ; 
return casActiveTermCount ( metadataBuffer , termCount , nextTermCount ) ; 
} public static void initialiseTailWithTermId ( 
final UnsafeBuffer metadataBuffer , final int partitionIndex , final int termId ) 
metadataBuffer . putLong ( TERM_TAIL_COUNTERS_OFFSET + ( partitionIndex * SIZE_OF_LONG ) , packTail ( termId , 0 ) ) ; 
} public static int termOffset ( final long rawTail , final long termLength ) 
final long tail = rawTail & 0xFFFF_FFFFL ; 
return ( int ) Math . min ( tail , termLength ) ; 
} public static void rawTail ( final UnsafeBuffer metadataBuffer , final int partitionIndex , final long rawTail ) 
metadataBuffer . putLong ( TERM_TAIL_COUNTERS_OFFSET + ( SIZE_OF_LONG * partitionIndex ) , rawTail ) ; 
} public static void rawTailVolatile ( final UnsafeBuffer metadataBuffer , final int partitionIndex , final long rawTail ) 
metadataBuffer . putLongVolatile ( TERM_TAIL_COUNTERS_OFFSET + ( SIZE_OF_LONG * partitionIndex ) , rawTail ) ; 
} public static long rawTailVolatile ( final UnsafeBuffer metadataBuffer ) 
final int partitionIndex = indexByTermCount ( activeTermCount ( metadataBuffer ) ) ; 
return metadataBuffer . getLongVolatile ( TERM_TAIL_COUNTERS_OFFSET + ( SIZE_OF_LONG * partitionIndex ) ) ; 
} public static boolean casRawTail ( 
final UnsafeBuffer metadataBuffer , 
final int partitionIndex , 
final long expectedRawTail , 
final long updateRawTail ) 
final int index = TERM_TAIL_COUNTERS_OFFSET + ( SIZE_OF_LONG * partitionIndex ) ; 
return metadataBuffer . compareAndSetLong ( index , expectedRawTail , updateRawTail ) ; 
try ( Archive ignore = launch ( ) ) 
new ShutdownSignalBarrier ( ) . await ( ) ; 
} public TerminateDriverFlyweight tokenBuffer ( 
final DirectBuffer tokenBuffer , final int tokenOffset , final int tokenLength ) 
buffer . putInt ( TOKEN_LENGTH_OFFSET , tokenLength ) ; 
if ( null != tokenBuffer && tokenLength > 0 ) 
buffer . putBytes ( tokenBufferOffset ( ) , tokenBuffer , tokenOffset , tokenLength ) ; 
} public static Counter allocate ( 
final Aeron aeron , 
final boolean hasReplay , 
final long ... snapshotRecordingIds ) 
tempBuffer . putLong ( LEADERSHIP_TERM_ID_OFFSET , leadershipTermId ) ; 
tempBuffer . putLong ( LOG_POSITION_OFFSET , logPosition ) ; 
tempBuffer . putLong ( TIMESTAMP_OFFSET , timestamp ) ; 
tempBuffer . putInt ( REPLAY_FLAG_OFFSET , hasReplay ? 1 : 0 ) ; 
final int serviceCount = snapshotRecordingIds . length ; 
tempBuffer . putInt ( SERVICE_COUNT_OFFSET , serviceCount ) ; 
final int keyLength = SNAPSHOT_RECORDING_IDS_OFFSET + ( serviceCount * SIZE_OF_LONG ) ; 
if ( keyLength > MAX_KEY_LENGTH ) 
for ( int i = 0 ; i < serviceCount ; i ++ ) 
tempBuffer . putLong ( SNAPSHOT_RECORDING_IDS_OFFSET + ( i * SIZE_OF_LONG ) , snapshotRecordingIds [ i ] ) ; 
final int labelOffset = BitUtil . align ( keyLength , SIZE_OF_INT ) ; 
labelLength += tempBuffer . putStringWithoutLengthAscii ( labelOffset + labelLength , NAME ) ; 
labelLength += tempBuffer . putLongAscii ( keyLength + labelLength , leadershipTermId ) ; 
labelLength += tempBuffer . putLongAscii ( labelOffset + labelLength , logPosition ) ; 
return aeron . addCounter ( RECOVERY_STATE_TYPE_ID , tempBuffer , 0 , keyLength , tempBuffer , labelOffset , labelLength ) ; 
} public static int findCounterId ( final CountersReader counters ) 
final DirectBuffer buffer = counters . metaDataBuffer ( ) ; 
if ( counters . getCounterState ( i ) == RECORD_ALLOCATED ) 
if ( buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == RECOVERY_STATE_TYPE_ID ) 
} public static long getLogPosition ( final CountersReader counters , final int counterId ) 
if ( counters . getCounterState ( counterId ) == RECORD_ALLOCATED ) 
return buffer . getLong ( recordOffset + KEY_OFFSET + LOG_POSITION_OFFSET ) ; 
return NULL_VALUE ; 
} public static boolean hasReplay ( final CountersReader counters , final int counterId ) 
return buffer . getInt ( recordOffset + KEY_OFFSET + REPLAY_FLAG_OFFSET ) == 1 ; 
} public static long getSnapshotRecordingId ( final CountersReader counters , final int counterId , final int serviceId ) 
final int serviceCount = buffer . getInt ( recordOffset + KEY_OFFSET + SERVICE_COUNT_OFFSET ) ; 
if ( serviceId < 0 || serviceId >= serviceCount ) 
return buffer . getLong ( 
recordOffset + KEY_OFFSET + SNAPSHOT_RECORDING_IDS_OFFSET + ( serviceId * SIZE_OF_LONG ) ) ; 
} public static char [ ] flagsToChars ( final short flags ) 
final char [ ] chars = new char [ ] { '0' , '0' , '0' , '0' , '0' , '0' , '0' , '0' } ; 
final int length = chars . length ; 
short mask = ( short ) ( 1 << ( length - 1 ) ) ; 
if ( ( flags & mask ) == mask ) 
chars [ i ] = '1' ; 
mask >>= 1 ; 
return chars ; 
} public ReportEntry createEntry ( 
final long initialBytesLost , 
final long timestampMs , 
final String source ) 
ReportEntry reportEntry = null ; 
final int requiredCapacity = CHANNEL_OFFSET + ( SIZE_OF_INT * 2 ) + channel . length ( ) + source . length ( ) ; 
if ( requiredCapacity <= ( buffer . capacity ( ) - nextRecordOffset ) ) 
final int offset = nextRecordOffset ; 
buffer . putLong ( offset + TOTAL_BYTES_LOST_OFFSET , initialBytesLost ) ; 
buffer . putLong ( offset + FIRST_OBSERVATION_OFFSET , timestampMs ) ; 
buffer . putLong ( offset + LAST_OBSERVATION_OFFSET , timestampMs ) ; 
buffer . putInt ( offset + SESSION_ID_OFFSET , sessionId ) ; 
buffer . putInt ( offset + STREAM_ID_OFFSET , streamId ) ; 
final int encodedChannelLength = buffer . putStringAscii ( offset + CHANNEL_OFFSET , channel ) ; 
buffer . putStringAscii ( offset + CHANNEL_OFFSET + encodedChannelLength , source ) ; 
buffer . putLongOrdered ( offset + OBSERVATION_COUNT_OFFSET , 1 ) ; 
reportEntry = new ReportEntry ( buffer , offset ) ; 
nextRecordOffset += BitUtil . align ( requiredCapacity , ENTRY_ALIGNMENT ) ; 
return reportEntry ; 
} public long offer ( final Publication publication , final DirectBuffer buffer , final int offset , final int length ) 
return publication . offer ( headerBuffer , 0 , HEADER_LENGTH , buffer , offset , length , null ) ; 
} public PublicationMessageFlyweight channel ( final String channel ) 
} public static boolean tryFillGap ( 
final int gapOffset , 
final int gapLength ) 
int offset = ( gapOffset + gapLength ) - FRAME_ALIGNMENT ; 
while ( offset >= gapOffset ) 
if ( 0 != termBuffer . getInt ( offset ) ) 
offset -= FRAME_ALIGNMENT ; 
applyDefaultHeader ( logMetaDataBuffer , termBuffer , gapOffset ) ; 
frameType ( termBuffer , gapOffset , HDR_TYPE_PAD ) ; 
frameTermOffset ( termBuffer , gapOffset ) ; 
frameTermId ( termBuffer , gapOffset , termId ) ; 
frameLengthOrdered ( termBuffer , gapOffset , gapLength ) ; 
} public static int read ( 
final FragmentHandler handler , 
final int fragmentsLimit , 
final Header header , 
final ErrorHandler errorHandler , 
final long currentPosition , 
final Position subscriberPosition ) 
final int capacity = termBuffer . capacity ( ) ; 
header . buffer ( termBuffer ) ; 
while ( fragmentsRead < fragmentsLimit && offset < capacity ) 
final int frameOffset = offset ; 
offset += BitUtil . align ( frameLength , FRAME_ALIGNMENT ) ; 
if ( ! isPaddingFrame ( termBuffer , frameOffset ) ) 
header . offset ( frameOffset ) ; 
handler . onFragment ( termBuffer , frameOffset + HEADER_LENGTH , frameLength - HEADER_LENGTH , header ) ; 
++ fragmentsRead ; 
catch ( final Throwable t ) 
errorHandler . onError ( t ) ; 
final long newPosition = currentPosition + ( offset - termOffset ) ; 
if ( newPosition > currentPosition ) 
subscriberPosition . setOrdered ( newPosition ) ; 
} public void write ( final UnsafeBuffer termBuffer , final int offset , final int length , final int termId ) 
termBuffer . putLongOrdered ( offset + FRAME_LENGTH_FIELD_OFFSET , versionFlagsType | ( ( - length ) & 0xFFFF_FFFFL ) ) ; 
UnsafeAccess . UNSAFE . storeFence ( ) ; 
termBuffer . putLong ( offset + TERM_OFFSET_FIELD_OFFSET , sessionId | offset ) ; 
termBuffer . putLong ( offset + STREAM_ID_FIELD_OFFSET , streamId | ( ( ( long ) termId ) << 32 ) ) ; 
return cluster . offer ( id , responsePublication , buffer , offset , length ) ; 
} public final void wrap ( final AtomicBuffer buffer , final int offset , final int length ) 
this . buffer . wrap ( buffer , offset , length ) ; 
} public final BufferClaim putBytes ( final DirectBuffer srcBuffer , final int srcIndex , final int length ) 
buffer . putBytes ( HEADER_LENGTH , srcBuffer , srcIndex , length ) ; 
} public final void commit ( ) 
int frameLength = buffer . capacity ( ) ; 
buffer . putIntOrdered ( FRAME_LENGTH_FIELD_OFFSET , frameLength ) ; 
} public final void abort ( ) 
buffer . putShort ( TYPE_FIELD_OFFSET , ( short ) HDR_TYPE_PAD , LITTLE_ENDIAN ) ; 
final ShutdownSignalBarrier barrier = new ShutdownSignalBarrier ( ) ; 
final MediaDriver . Context ctx = new MediaDriver . Context ( ) ; 
ctx . terminationHook ( barrier :: signal ) ; 
try ( MediaDriver ignore = MediaDriver . launch ( ctx ) ) 
barrier . await ( ) ; 
} public static MediaDriver launchEmbedded ( final Context ctx ) 
if ( CommonContext . AERON_DIR_PROP_DEFAULT . equals ( ctx . aeronDirectoryName ( ) ) ) 
ctx . aeronDirectoryName ( CommonContext . generateRandomDirName ( ) ) ; 
return launch ( ctx ) ; 
CloseHelper . close ( sharedRunner ) ; 
CloseHelper . close ( sharedNetworkRunner ) ; 
CloseHelper . close ( receiverRunner ) ; 
CloseHelper . close ( senderRunner ) ; 
CloseHelper . close ( conductorRunner ) ; 
CloseHelper . close ( sharedInvoker ) ; 
if ( ctx . useWindowsHighResTimer ( ) && SystemUtil . osName ( ) . startsWith ( "win" ) ) 
if ( ! wasHighResTimerEnabled ) 
HighResolutionTimer . disable ( ) ; 
final long position = subscriberPosition . get ( ) ; 
return TermReader . read ( 
activeTermBuffer ( position ) , 
( int ) position & termLengthMask , 
fragmentHandler , 
fragmentLimit , 
header , 
errorHandler , 
subscriberPosition ) ; 
} public int controlledPoll ( final ControlledFragmentHandler handler , final int fragmentLimit ) 
long initialPosition = subscriberPosition . get ( ) ; 
int initialOffset = ( int ) initialPosition & termLengthMask ; 
int resultingOffset = initialOffset ; 
final UnsafeBuffer termBuffer = activeTermBuffer ( initialPosition ) ; 
final Header header = this . header ; 
while ( fragmentsRead < fragmentLimit && resultingOffset < capacity ) 
final int length = frameLengthVolatile ( termBuffer , resultingOffset ) ; 
if ( length <= 0 ) 
final int frameOffset = resultingOffset ; 
final int alignedLength = BitUtil . align ( length , FRAME_ALIGNMENT ) ; 
resultingOffset += alignedLength ; 
if ( isPaddingFrame ( termBuffer , frameOffset ) ) 
final Action action = handler . onFragment ( 
termBuffer , frameOffset + HEADER_LENGTH , length - HEADER_LENGTH , header ) ; 
if ( action == ABORT ) 
resultingOffset -= alignedLength ; 
if ( action == BREAK ) 
else if ( action == COMMIT ) 
initialPosition += ( resultingOffset - initialOffset ) ; 
initialOffset = resultingOffset ; 
subscriberPosition . setOrdered ( initialPosition ) ; 
final long resultingPosition = initialPosition + ( resultingOffset - initialOffset ) ; 
if ( resultingPosition > initialPosition ) 
subscriberPosition . setOrdered ( resultingPosition ) ; 
} public long controlledPeek ( 
final long initialPosition , final ControlledFragmentHandler handler , final long limitPosition ) 
validatePosition ( initialPosition ) ; 
int offset = initialOffset ; 
long position = initialPosition ; 
long resultingPosition = initialPosition ; 
while ( position < limitPosition && offset < capacity ) 
final int length = frameLengthVolatile ( termBuffer , offset ) ; 
offset += alignedLength ; 
position += ( offset - initialOffset ) ; 
initialOffset = offset ; 
resultingPosition = position ; 
if ( ( header . flags ( ) & END_FRAG_FLAG ) == END_FRAG_FLAG ) 
return resultingPosition ; 
} public int blockPoll ( final BlockHandler handler , final int blockLengthLimit ) 
final int termOffset = ( int ) position & termLengthMask ; 
final UnsafeBuffer termBuffer = activeTermBuffer ( position ) ; 
final int limitOffset = Math . min ( termOffset + blockLengthLimit , termBuffer . capacity ( ) ) ; 
final int resultingOffset = TermBlockScanner . scan ( termBuffer , termOffset , limitOffset ) ; 
final int length = resultingOffset - termOffset ; 
if ( resultingOffset > termOffset ) 
final int termId = termBuffer . getInt ( termOffset + TERM_ID_FIELD_OFFSET , LITTLE_ENDIAN ) ; 
handler . onBlock ( termBuffer , termOffset , length , sessionId , termId ) ; 
subscriberPosition . setOrdered ( position + length ) ; 
} public int rawPoll ( final RawBlockHandler handler , final int blockLengthLimit ) 
final int activeIndex = indexByPosition ( position , positionBitsToShift ) ; 
final UnsafeBuffer termBuffer = termBuffers [ activeIndex ] ; 
final int limitOffset = Math . min ( termOffset + blockLengthLimit , capacity ) ; 
final long fileOffset = ( ( long ) capacity * activeIndex ) + termOffset ; 
handler . onBlock ( 
logBuffers . fileChannel ( ) , fileOffset , termBuffer , termOffset , length , sessionId , termId ) ; 
} public final long position ( ) 
final int resultingOffset = BitUtil . align ( termOffset ( ) + frameLength ( ) , FRAME_ALIGNMENT ) ; 
return computePosition ( termId ( ) , resultingOffset , positionBitsToShift , initialTermId ) ; 
} public SubscriptionMessageFlyweight channel ( final String channel ) 
} public RawLog newPublication ( 
final int termBufferLength , 
final boolean useSparseFiles ) 
return newInstance ( 
publicationsDir , channel , sessionId , streamId , correlationId , termBufferLength , useSparseFiles ) ; 
} public RawLog newImage ( 
return newInstance ( imagesDir , channel , sessionId , streamId , correlationId , termBufferLength , useSparseFiles ) ; 
tempBuffer . putInt ( SERVICE_ID_OFFSET , serviceId ) ; 
final int labelOffset = BitUtil . align ( KEY_LENGTH , SIZE_OF_INT ) ; 
labelLength += tempBuffer . putIntAscii ( labelOffset + labelLength , serviceId ) ; 
return aeron . addCounter ( 
SERVICE_HEARTBEAT_TYPE_ID , tempBuffer , 0 , KEY_LENGTH , tempBuffer , labelOffset , labelLength ) ; 
} public static int findCounterId ( final CountersReader counters , final int serviceId ) 
if ( buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == SERVICE_HEARTBEAT_TYPE_ID && 
buffer . getInt ( recordOffset + KEY_OFFSET + SERVICE_ID_OFFSET ) == serviceId ) 
} public Map < StreamCompositeKey , StreamBacklog > snapshot ( ) 
final Map < StreamCompositeKey , StreamBacklog > streams = new HashMap < > ( ) ; 
final StreamBacklog streamBacklog = streams . computeIfAbsent ( key , ( ignore ) -> new StreamBacklog ( ) ) ; 
final long registrationId = keyBuffer . getLong ( REGISTRATION_ID_OFFSET ) ; 
final long value = counters . getCounterValue ( counterId ) ; 
streamBacklog . createPublisherIfAbsent ( ) . registrationId ( registrationId ) ; 
streamBacklog . createPublisherIfAbsent ( ) . limit ( value ) ; 
streamBacklog . createPublisherIfAbsent ( ) . position ( value ) ; 
streamBacklog . createSenderIfAbsent ( ) . registrationId ( registrationId ) ; 
streamBacklog . createSenderIfAbsent ( ) . position ( value ) ; 
streamBacklog . createSenderIfAbsent ( ) . limit ( value ) ; 
streamBacklog . createReceiverIfAbsent ( ) . registrationId ( registrationId ) ; 
streamBacklog . createReceiverIfAbsent ( ) . highWaterMark ( value ) ; 
streamBacklog . createReceiverIfAbsent ( ) . position ( value ) ; 
streamBacklog . subscriberBacklogs ( ) . put ( registrationId , new Subscriber ( value ) ) ; 
} public void print ( final PrintStream out ) 
for ( final Map . Entry < StreamCompositeKey , StreamBacklog > entry : snapshot ( ) . entrySet ( ) ) 
final StreamBacklog streamBacklog = entry . getValue ( ) ; 
if ( streamBacklog . publisher ( ) != null ) 
. append ( streamBacklog . publisher ( ) . registrationId ( ) ) 
. append ( streamBacklog . publisher ( ) . position ( ) ) 
. append ( streamBacklog . publisher ( ) . remainingWindow ( ) ) 
final Sender sender = streamBacklog . sender ( ) ; 
if ( sender != null ) 
final long senderBacklog = sender . backlog ( streamBacklog . publisher ( ) . position ( ) ) ; 
if ( senderBacklog >= 0 ) 
if ( streamBacklog . receiver ( ) != null ) 
. append ( streamBacklog . receiver ( ) . registrationId ( ) ) 
. append ( streamBacklog . receiver ( ) . position ( ) ) ; 
final Iterator < Map . Entry < Long , Subscriber > > subscriberIterator = 
streamBacklog . subscriberBacklogs ( ) . entrySet ( ) . iterator ( ) ; 
while ( subscriberIterator . hasNext ( ) ) 
final Map . Entry < Long , Subscriber > subscriber = subscriberIterator . next ( ) ; 
. append ( subscriberIterator . hasNext ( ) ? "\n├" : "\n└" ) 
. append ( subscriber . getKey ( ) ) 
. append ( subscriber . getValue ( ) . backlog ( streamBacklog . receiver ( ) . highWaterMark ( ) ) ) 
builder . append ( '\n' ) ; 
} public long scan ( 
final long rebuildPosition , 
final long hwmPosition , 
final long nowNs , 
final int termLengthMask , 
final int initialTermId ) 
boolean lossFound = false ; 
int rebuildOffset = ( int ) rebuildPosition & termLengthMask ; 
if ( rebuildPosition < hwmPosition ) 
final int rebuildTermCount = ( int ) ( rebuildPosition > > > positionBitsToShift ) ; 
final int hwmTermCount = ( int ) ( hwmPosition > > > positionBitsToShift ) ; 
final int rebuildTermId = initialTermId + rebuildTermCount ; 
final int hwmTermOffset = ( int ) hwmPosition & termLengthMask ; 
final int limitOffset = rebuildTermCount == hwmTermCount ? hwmTermOffset : termLengthMask + 1 ; 
rebuildOffset = scanForGap ( termBuffer , rebuildTermId , rebuildOffset , limitOffset , this ) ; 
if ( rebuildOffset < limitOffset ) 
if ( scannedTermOffset != activeTermOffset || scannedTermId != activeTermId ) 
activateGap ( nowNs ) ; 
lossFound = true ; 
checkTimerExpiry ( nowNs ) ; 
return pack ( rebuildOffset , lossFound ) ; 
final int termCount = activeTermCount ( logMetaDataBuffer ) ; 
final TermAppender termAppender = termAppenders [ indexByTermCount ( termCount ) ] ; 
final long rawTail = termAppender . rawTailVolatile ( ) ; 
final long position = computeTermBeginPosition ( termId , positionBitsToShift , initialTermId ) + termOffset ; 
if ( termCount != ( termId - initialTermId ) ) 
return ADMIN_ACTION ; 
final int resultingOffset ; 
resultingOffset = termAppender . appendUnfragmentedMessage ( 
headerWriter , buffer , offset , length , reservedValueSupplier , termId ) ; 
resultingOffset = termAppender . appendFragmentedMessage ( 
headerWriter , buffer , offset , length , maxPayloadLength , reservedValueSupplier , termId ) ; 
newPosition = newPosition ( termCount , ( int ) termOffset , termId , position , resultingOffset ) ; 
reservedValueSupplier , 
termId ) ; 
final int resultingOffset = termAppender . claim ( headerWriter , length , bufferClaim , termId ) ; 
} public static int scan ( final UnsafeBuffer termBuffer , final int termOffset , final int limitOffset ) 
while ( offset < limitOffset ) 
final int alignedFrameLength = align ( frameLength , FRAME_ALIGNMENT ) ; 
if ( isPaddingFrame ( termBuffer , offset ) ) 
if ( termOffset == offset ) 
offset += alignedFrameLength ; 
if ( offset + alignedFrameLength > limitOffset ) 
return offset ; 
try ( ConsensusModule consensusModule = launch ( ) ) 
consensusModule . context ( ) . shutdownSignalBarrier ( ) . await ( ) ; 
final long registrationId ) 
return new AtomicCounter ( 
countersManager . valuesBuffer ( ) , 
allocateCounterId ( tempBuffer , name , typeId , countersManager , registrationId ) , 
} public static Aeron connect ( final Context ctx ) 
final Aeron aeron = new Aeron ( ctx ) ; 
if ( ctx . useConductorAgentInvoker ( ) ) 
aeron . conductorInvoker . start ( ) ; 
AgentRunner . startOnThread ( aeron . conductorRunner , ctx . threadFactory ( ) ) ; 
return aeron ; 
} public void printCounters ( final PrintStream out ) 
final CountersReader counters = countersReader ( ) ; 
} public Subscription addSubscription ( 
final AvailableImageHandler availableImageHandler , 
final UnavailableImageHandler unavailableImageHandler ) 
return conductor . addSubscription ( channel , streamId , availableImageHandler , unavailableImageHandler ) ; 
} public Counter addCounter ( 
final DirectBuffer keyBuffer , 
final int keyOffset , 
final int keyLength , 
final DirectBuffer labelBuffer , 
final int labelOffset , 
final int labelLength ) 
return conductor . addCounter ( typeId , keyBuffer , keyOffset , keyLength , labelBuffer , labelOffset , labelLength ) ; 
} public Context conclude ( ) 
super . conclude ( ) ; 
if ( null == clientLock ) 
clientLock = new ReentrantLock ( ) ; 
if ( null == epochClock ) 
epochClock = new SystemEpochClock ( ) ; 
if ( null == nanoClock ) 
nanoClock = new SystemNanoClock ( ) ; 
if ( null == idleStrategy ) 
idleStrategy = new SleepingMillisIdleStrategy ( Configuration . IDLE_SLEEP_MS ) ; 
if ( cncFile ( ) != null ) 
connectToDriver ( ) ; 
interServiceTimeoutNs = CncFileDescriptor . clientLivenessTimeout ( cncMetaDataBuffer ) ; 
if ( interServiceTimeoutNs <= keepAliveIntervalNs ) 
throw new ConfigurationException ( "interServiceTimeoutNs=" + interServiceTimeoutNs + 
if ( null == toDriverBuffer ) 
toDriverBuffer = new ManyToOneRingBuffer ( 
if ( null == toClientBuffer ) 
toClientBuffer = new CopyBroadcastReceiver ( new BroadcastReceiver ( 
CncFileDescriptor . createToClientsBuffer ( cncByteBuffer , cncMetaDataBuffer ) ) ) ; 
if ( countersMetaDataBuffer ( ) == null ) 
countersMetaDataBuffer ( 
CncFileDescriptor . createCountersMetaDataBuffer ( cncByteBuffer , cncMetaDataBuffer ) ) ; 
if ( countersValuesBuffer ( ) == null ) 
countersValuesBuffer ( CncFileDescriptor . createCountersValuesBuffer ( cncByteBuffer , cncMetaDataBuffer ) ) ; 
if ( null == logBuffersFactory ) 
logBuffersFactory = new MappedLogBuffersFactory ( ) ; 
if ( null == errorHandler ) 
errorHandler = Configuration . DEFAULT_ERROR_HANDLER ; 
if ( null == driverProxy ) 
clientId = toDriverBuffer . nextCorrelationId ( ) ; 
driverProxy = new DriverProxy ( toDriverBuffer , clientId ) ; 
final MappedByteBuffer cncByteBuffer = this . cncByteBuffer ; 
this . cncByteBuffer = null ; 
super . close ( ) ; 
} public static void dispatchDescriptor ( 
final RecordingDescriptorDecoder decoder , final RecordingDescriptorConsumer consumer ) 
consumer . onRecordingDescriptor ( 
decoder . controlSessionId ( ) , 
decoder . correlationId ( ) , 
decoder . recordingId ( ) , 
decoder . startTimestamp ( ) , 
decoder . stopTimestamp ( ) , 
decoder . startPosition ( ) , 
decoder . stopPosition ( ) , 
decoder . initialTermId ( ) , 
decoder . segmentFileLength ( ) , 
decoder . termBufferLength ( ) , 
decoder . mtuLength ( ) , 
decoder . sessionId ( ) , 
decoder . streamId ( ) , 
decoder . strippedChannel ( ) , 
decoder . originalChannel ( ) , 
decoder . sourceIdentity ( ) ) ; 
} public static void insert ( 
final UnsafeBuffer termBuffer , final int termOffset , final UnsafeBuffer packet , final int length ) 
if ( 0 == termBuffer . getInt ( termOffset ) ) 
termBuffer . putBytes ( termOffset + HEADER_LENGTH , packet , HEADER_LENGTH , length - HEADER_LENGTH ) ; 
termBuffer . putLong ( termOffset + 24 , packet . getLong ( 24 ) ) ; 
termBuffer . putLong ( termOffset + 16 , packet . getLong ( 16 ) ) ; 
termBuffer . putLong ( termOffset + 8 , packet . getLong ( 8 ) ) ; 
termBuffer . putLongOrdered ( termOffset , packet . getLong ( 0 ) ) ; 
} public static void main ( String [ ] args ) { 
int port = 8080 ; 
String host = null ; 
List < File > rootDirs = new ArrayList < File > ( ) ; 
boolean quiet = false ; 
String cors = null ; 
Map < String , String > options = new HashMap < String , String > ( ) ; 
for ( int i = 0 ; i < args . length ; ++ i ) { 
if ( "-h" . equalsIgnoreCase ( args [ i ] ) || "--host" . equalsIgnoreCase ( args [ i ] ) ) { 
host = args [ i + 1 ] ; 
} else if ( "-p" . equalsIgnoreCase ( args [ i ] ) || "--port" . equalsIgnoreCase ( args [ i ] ) ) { 
port = Integer . parseInt ( args [ i + 1 ] ) ; 
} else if ( "-q" . equalsIgnoreCase ( args [ i ] ) || "--quiet" . equalsIgnoreCase ( args [ i ] ) ) { 
quiet = true ; 
} else if ( "-d" . equalsIgnoreCase ( args [ i ] ) || "--dir" . equalsIgnoreCase ( args [ i ] ) ) { 
rootDirs . add ( new File ( args [ i + 1 ] ) . getAbsoluteFile ( ) ) ; 
} else if ( args [ i ] . startsWith ( "--cors" ) ) { 
cors = "*" ; 
int equalIdx = args [ i ] . indexOf ( '=' ) ; 
if ( equalIdx > 0 ) { 
cors = args [ i ] . substring ( equalIdx + 1 ) ; 
} else if ( "--licence" . equalsIgnoreCase ( args [ i ] ) ) { 
System . out . println ( SimpleWebServer . LICENCE + "\n" ) ; 
} else if ( args [ i ] . startsWith ( "-X:" ) ) { 
int dot = args [ i ] . indexOf ( '=' ) ; 
if ( dot > 0 ) { 
String name = args [ i ] . substring ( 0 , dot ) ; 
String value = args [ i ] . substring ( dot + 1 , args [ i ] . length ( ) ) ; 
options . put ( name , value ) ; 
if ( rootDirs . isEmpty ( ) ) { 
rootDirs . add ( new File ( "." ) . getAbsoluteFile ( ) ) ; 
options . put ( "host" , host ) ; 
options . put ( "port" , "" + port ) ; 
options . put ( "quiet" , String . valueOf ( quiet ) ) ; 
StringBuilder sb = new StringBuilder ( ) ; 
for ( File dir : rootDirs ) { 
if ( sb . length ( ) > 0 ) { 
sb . append ( ":" ) ; 
sb . append ( dir . getCanonicalPath ( ) ) ; 
} catch ( IOException ignored ) { 
options . put ( "home" , sb . toString ( ) ) ; 
ServiceLoader < WebServerPluginInfo > serviceLoader = ServiceLoader . load ( WebServerPluginInfo . class ) ; 
for ( WebServerPluginInfo info : serviceLoader ) { 
String [ ] mimeTypes = info . getMimeTypes ( ) ; 
for ( String mime : mimeTypes ) { 
String [ ] indexFiles = info . getIndexFilesForMimeType ( mime ) ; 
if ( ! quiet ) { 
if ( indexFiles != null ) { 
for ( String indexFile : indexFiles ) { 
System . out . println ( ")." ) ; 
registerPluginForMimeType ( indexFiles , mime , info . getWebServerPlugin ( mime ) , options ) ; 
ServerRunner . executeInstance ( new SimpleWebServer ( host , port , rootDirs , quiet , cors ) ) ; 
} Response serveFile ( String uri , Map < String , String > header , File file , String mime ) { 
Response res ; 
String etag = Integer . toHexString ( ( file . getAbsolutePath ( ) + file . lastModified ( ) + "" + file . length ( ) ) . hashCode ( ) ) ; 
long startFrom = 0 ; 
long endAt = - 1 ; 
String range = header . get ( "range" ) ; 
if ( range != null ) { 
if ( range . startsWith ( "bytes=" ) ) { 
range = range . substring ( "bytes=" . length ( ) ) ; 
int minus = range . indexOf ( '-' ) ; 
if ( minus > 0 ) { 
startFrom = Long . parseLong ( range . substring ( 0 , minus ) ) ; 
endAt = Long . parseLong ( range . substring ( minus + 1 ) ) ; 
} catch ( NumberFormatException ignored ) { 
String ifRange = header . get ( "if-range" ) ; 
boolean headerIfRangeMissingOrMatching = ( ifRange == null || etag . equals ( ifRange ) ) ; 
String ifNoneMatch = header . get ( "if-none-match" ) ; 
boolean headerIfNoneMatchPresentAndMatching = ifNoneMatch != null && ( "*" . equals ( ifNoneMatch ) || ifNoneMatch . equals ( etag ) ) ; 
long fileLen = file . length ( ) ; 
if ( headerIfRangeMissingOrMatching && range != null && startFrom >= 0 && startFrom < fileLen ) { 
if ( headerIfNoneMatchPresentAndMatching ) { 
res = newFixedLengthResponse ( Status . NOT_MODIFIED , mime , "" ) ; 
res . addHeader ( "ETag" , etag ) ; 
if ( endAt < 0 ) { 
endAt = fileLen - 1 ; 
long newLen = endAt - startFrom + 1 ; 
if ( newLen < 0 ) { 
newLen = 0 ; 
FileInputStream fis = new FileInputStream ( file ) ; 
fis . skip ( startFrom ) ; 
res = Response . newFixedLengthResponse ( Status . PARTIAL_CONTENT , mime , fis , newLen ) ; 
res . addHeader ( "Accept-Ranges" , "bytes" ) ; 
res . addHeader ( "Content-Length" , "" + newLen ) ; 
if ( headerIfRangeMissingOrMatching && range != null && startFrom >= fileLen ) { 
res = newFixedLengthResponse ( Status . RANGE_NOT_SATISFIABLE , NanoHTTPD . MIME_PLAINTEXT , "" ) ; 
} else if ( range == null && headerIfNoneMatchPresentAndMatching ) { 
} else if ( ! headerIfRangeMissingOrMatching && headerIfNoneMatchPresentAndMatching ) { 
res = newFixedFileResponse ( file , mime ) ; 
res . addHeader ( "Content-Length" , "" + fileLen ) ; 
} catch ( IOException ioe ) { 
return res ; 
} private void decodeHeader ( BufferedReader in , Map < String , String > pre , Map < String , List < String > > parms , Map < String , String > headers ) throws ResponseException { 
String inLine = in . readLine ( ) ; 
if ( inLine == null ) { 
StringTokenizer st = new StringTokenizer ( inLine ) ; 
if ( ! st . hasMoreTokens ( ) ) { 
pre . put ( "method" , st . nextToken ( ) ) ; 
String uri = st . nextToken ( ) ; 
int qmi = uri . indexOf ( '?' ) ; 
if ( qmi >= 0 ) { 
decodeParms ( uri . substring ( qmi + 1 ) , parms ) ; 
uri = NanoHTTPD . decodePercent ( uri . substring ( 0 , qmi ) ) ; 
uri = NanoHTTPD . decodePercent ( uri ) ; 
if ( st . hasMoreTokens ( ) ) { 
protocolVersion = st . nextToken ( ) ; 
protocolVersion = "HTTP/1.1" ; 
String line = in . readLine ( ) ; 
while ( line != null && ! line . trim ( ) . isEmpty ( ) ) { 
int p = line . indexOf ( ':' ) ; 
if ( p >= 0 ) { 
headers . put ( line . substring ( 0 , p ) . trim ( ) . toLowerCase ( Locale . US ) , line . substring ( p + 1 ) . trim ( ) ) ; 
line = in . readLine ( ) ; 
pre . put ( "uri" , uri ) ; 
} private void decodeMultipartFormData ( ContentType contentType , ByteBuffer fbuf , Map < String , List < String > > parms , Map < String , String > files ) throws ResponseException { 
int pcount = 0 ; 
int [ ] boundaryIdxs = getBoundaryPositions ( fbuf , contentType . getBoundary ( ) . getBytes ( ) ) ; 
if ( boundaryIdxs . length < 2 ) { 
byte [ ] partHeaderBuff = new byte [ MAX_HEADER_SIZE ] ; 
for ( int boundaryIdx = 0 ; boundaryIdx < boundaryIdxs . length - 1 ; boundaryIdx ++ ) { 
fbuf . position ( boundaryIdxs [ boundaryIdx ] ) ; 
int len = ( fbuf . remaining ( ) < MAX_HEADER_SIZE ) ? fbuf . remaining ( ) : MAX_HEADER_SIZE ; 
fbuf . get ( partHeaderBuff , 0 , len ) ; 
BufferedReader in = 
new BufferedReader ( new InputStreamReader ( new ByteArrayInputStream ( partHeaderBuff , 0 , len ) , Charset . forName ( contentType . getEncoding ( ) ) ) , len ) ; 
int headerLines = 0 ; 
String mpline = in . readLine ( ) ; 
headerLines ++ ; 
if ( mpline == null || ! mpline . contains ( contentType . getBoundary ( ) ) ) { 
String partName = null , fileName = null , partContentType = null ; 
mpline = in . readLine ( ) ; 
while ( mpline != null && mpline . trim ( ) . length ( ) > 0 ) { 
Matcher matcher = NanoHTTPD . CONTENT_DISPOSITION_PATTERN . matcher ( mpline ) ; 
if ( matcher . matches ( ) ) { 
String attributeString = matcher . group ( 2 ) ; 
matcher = NanoHTTPD . CONTENT_DISPOSITION_ATTRIBUTE_PATTERN . matcher ( attributeString ) ; 
while ( matcher . find ( ) ) { 
String key = matcher . group ( 1 ) ; 
if ( "name" . equalsIgnoreCase ( key ) ) { 
partName = matcher . group ( 2 ) ; 
} else if ( "filename" . equalsIgnoreCase ( key ) ) { 
fileName = matcher . group ( 2 ) ; 
if ( ! fileName . isEmpty ( ) ) { 
if ( pcount > 0 ) 
partName = partName + String . valueOf ( pcount ++ ) ; 
pcount ++ ; 
matcher = NanoHTTPD . CONTENT_TYPE_PATTERN . matcher ( mpline ) ; 
partContentType = matcher . group ( 2 ) . trim ( ) ; 
int partHeaderLength = 0 ; 
while ( headerLines -- > 0 ) { 
partHeaderLength = scipOverNewLine ( partHeaderBuff , partHeaderLength ) ; 
if ( partHeaderLength >= len - 4 ) { 
int partDataStart = boundaryIdxs [ boundaryIdx ] + partHeaderLength ; 
int partDataEnd = boundaryIdxs [ boundaryIdx + 1 ] - 4 ; 
fbuf . position ( partDataStart ) ; 
List < String > values = parms . get ( partName ) ; 
if ( values == null ) { 
values = new ArrayList < String > ( ) ; 
parms . put ( partName , values ) ; 
if ( partContentType == null ) { 
byte [ ] data_bytes = new byte [ partDataEnd - partDataStart ] ; 
fbuf . get ( data_bytes ) ; 
values . add ( new String ( data_bytes , contentType . getEncoding ( ) ) ) ; 
String path = saveTmpFile ( fbuf , partDataStart , partDataEnd - partDataStart , fileName ) ; 
if ( ! files . containsKey ( partName ) ) { 
files . put ( partName , path ) ; 
int count = 2 ; 
while ( files . containsKey ( partName + count ) ) { 
count ++ ; 
files . put ( partName + count , path ) ; 
values . add ( fileName ) ; 
} catch ( ResponseException re ) { 
throw re ; 
throw new ResponseException ( Status . INTERNAL_ERROR , e . toString ( ) ) ; 
} private void decodeParms ( String parms , Map < String , List < String > > p ) { 
if ( parms == null ) { 
this . queryParameterString = "" ; 
this . queryParameterString = parms ; 
StringTokenizer st = new StringTokenizer ( parms , "&" ) ; 
while ( st . hasMoreTokens ( ) ) { 
String e = st . nextToken ( ) ; 
int sep = e . indexOf ( '=' ) ; 
String value = null ; 
if ( sep >= 0 ) { 
key = NanoHTTPD . decodePercent ( e . substring ( 0 , sep ) ) . trim ( ) ; 
value = NanoHTTPD . decodePercent ( e . substring ( sep + 1 ) ) ; 
key = NanoHTTPD . decodePercent ( e ) . trim ( ) ; 
value = "" ; 
List < String > values = p . get ( key ) ; 
p . put ( key , values ) ; 
values . add ( value ) ; 
} private int findHeaderEnd ( final byte [ ] buf , int rlen ) { 
int splitbyte = 0 ; 
while ( splitbyte + 1 < rlen ) { 
if ( buf [ splitbyte ] == '\r' && buf [ splitbyte + 1 ] == '\n' && splitbyte + 3 < rlen && buf [ splitbyte + 2 ] == '\r' && buf [ splitbyte + 3 ] == '\n' ) { 
return splitbyte + 4 ; 
if ( buf [ splitbyte ] == '\n' && buf [ splitbyte + 1 ] == '\n' ) { 
return splitbyte + 2 ; 
splitbyte ++ ; 
} private int [ ] getBoundaryPositions ( ByteBuffer b , byte [ ] boundary ) { 
int [ ] res = new int [ 0 ] ; 
if ( b . remaining ( ) < boundary . length ) { 
int search_window_pos = 0 ; 
byte [ ] search_window = new byte [ 4 * 1024 + boundary . length ] ; 
int first_fill = ( b . remaining ( ) < search_window . length ) ? b . remaining ( ) : search_window . length ; 
b . get ( search_window , 0 , first_fill ) ; 
int new_bytes = first_fill - boundary . length ; 
do { 
for ( int j = 0 ; j < new_bytes ; j ++ ) { 
for ( int i = 0 ; i < boundary . length ; i ++ ) { 
if ( search_window [ j + i ] != boundary [ i ] ) 
if ( i == boundary . length - 1 ) { 
int [ ] new_res = new int [ res . length + 1 ] ; 
System . arraycopy ( res , 0 , new_res , 0 , res . length ) ; 
new_res [ res . length ] = search_window_pos + j ; 
res = new_res ; 
search_window_pos += new_bytes ; 
System . arraycopy ( search_window , search_window . length - boundary . length , search_window , 0 , boundary . length ) ; 
new_bytes = search_window . length - boundary . length ; 
new_bytes = ( b . remaining ( ) < new_bytes ) ? b . remaining ( ) : new_bytes ; 
b . get ( search_window , boundary . length , new_bytes ) ; 
} while ( new_bytes > 0 ) ; 
} public long getBodySize ( ) { 
if ( this . headers . containsKey ( "content-length" ) ) { 
return Long . parseLong ( this . headers . get ( "content-length" ) ) ; 
} else if ( this . splitbyte < this . rlen ) { 
return this . rlen - this . splitbyte ; 
} private String saveTmpFile ( ByteBuffer b , int offset , int len , String filename_hint ) { 
String path = "" ; 
if ( len > 0 ) { 
FileOutputStream fileOutputStream = null ; 
ITempFile tempFile = this . tempFileManager . createTempFile ( filename_hint ) ; 
ByteBuffer src = b . duplicate ( ) ; 
fileOutputStream = new FileOutputStream ( tempFile . getName ( ) ) ; 
FileChannel dest = fileOutputStream . getChannel ( ) ; 
src . position ( offset ) . limit ( offset + len ) ; 
dest . write ( src . slice ( ) ) ; 
path = tempFile . getName ( ) ; 
throw new Error ( e ) ; 
NanoHTTPD . safeClose ( fileOutputStream ) ; 
return path ; 
} public static SSLServerSocketFactory makeSSLSocketFactory ( KeyStore loadedKeyStore , KeyManager [ ] keyManagers ) throws IOException { 
SSLServerSocketFactory res = null ; 
TrustManagerFactory trustManagerFactory = TrustManagerFactory . getInstance ( TrustManagerFactory . getDefaultAlgorithm ( ) ) ; 
trustManagerFactory . init ( loadedKeyStore ) ; 
SSLContext ctx = SSLContext . getInstance ( "TLS" ) ; 
ctx . init ( keyManagers , trustManagerFactory . getTrustManagers ( ) , null ) ; 
res = ctx . getServerSocketFactory ( ) ; 
throw new IOException ( e . getMessage ( ) ) ; 
} public static SSLServerSocketFactory makeSSLSocketFactory ( KeyStore loadedKeyStore , KeyManagerFactory loadedKeyFactory ) throws IOException { 
return makeSSLSocketFactory ( loadedKeyStore , loadedKeyFactory . getKeyManagers ( ) ) ; 
} public static SSLServerSocketFactory makeSSLSocketFactory ( String keyAndTrustStoreClasspathPath , char [ ] passphrase ) throws IOException { 
KeyStore keystore = KeyStore . getInstance ( KeyStore . getDefaultType ( ) ) ; 
InputStream keystoreStream = NanoHTTPD . class . getResourceAsStream ( keyAndTrustStoreClasspathPath ) ; 
if ( keystoreStream == null ) { 
keystore . load ( keystoreStream , passphrase ) ; 
KeyManagerFactory keyManagerFactory = KeyManagerFactory . getInstance ( KeyManagerFactory . getDefaultAlgorithm ( ) ) ; 
keyManagerFactory . init ( keystore , passphrase ) ; 
return makeSSLSocketFactory ( keystore , keyManagerFactory ) ; 
} public static String getMimeTypeForFile ( String uri ) { 
int dot = uri . lastIndexOf ( '.' ) ; 
String mime = null ; 
if ( dot >= 0 ) { 
mime = mimeTypes ( ) . get ( uri . substring ( dot + 1 ) . toLowerCase ( ) ) ; 
return mime == null ? "application/octet-stream" : mime ; 
} public Response handle ( IHTTPSession session ) { 
for ( IHandler < IHTTPSession , Response > interceptor : interceptors ) { 
Response response = interceptor . handle ( session ) ; 
if ( response != null ) 
return httpHandler . handle ( session ) ; 
protected Response serve ( IHTTPSession session ) { 
safeClose ( this . myServerSocket ) ; 
this . asyncRunner . closeAll ( ) ; 
if ( this . myThread != null ) { 
this . myThread . join ( ) ; 
} public void addMappings ( ) { 
router . setNotImplemented ( NotImplementedHandler . class ) ; 
router . setNotFoundHandler ( Error404UriHandler . class ) ; 
router . addRoute ( "/" , Integer . MAX_VALUE / 2 , IndexHandler . class ) ; 
router . addRoute ( "/index.html" , Integer . MAX_VALUE / 2 , IndexHandler . class ) ; 
} public void send ( OutputStream outputStream ) { 
gmtFrmt . setTimeZone ( TimeZone . getTimeZone ( "GMT" ) ) ; 
if ( this . status == null ) { 
PrintWriter pw = new PrintWriter ( new BufferedWriter ( new OutputStreamWriter ( outputStream , new ContentType ( this . mimeType ) . getEncoding ( ) ) ) , false ) ; 
if ( this . mimeType != null ) { 
printHeader ( pw , "Content-Type" , this . mimeType ) ; 
if ( getHeader ( "date" ) == null ) { 
printHeader ( pw , "Date" , gmtFrmt . format ( new Date ( ) ) ) ; 
for ( Entry < String , String > entry : this . header . entrySet ( ) ) { 
printHeader ( pw , entry . getKey ( ) , entry . getValue ( ) ) ; 
for ( String cookieHeader : this . cookieHeaders ) { 
printHeader ( pw , "Set-Cookie" , cookieHeader ) ; 
if ( getHeader ( "connection" ) == null ) { 
printHeader ( pw , "Connection" , ( this . keepAlive ? "keep-alive" : "close" ) ) ; 
if ( getHeader ( "content-length" ) != null ) { 
setUseGzip ( false ) ; 
if ( useGzipWhenAccepted ( ) ) { 
printHeader ( pw , "Content-Encoding" , "gzip" ) ; 
setChunkedTransfer ( true ) ; 
long pending = this . data != null ? this . contentLength : 0 ; 
if ( this . requestMethod != Method . HEAD && this . chunkedTransfer ) { 
printHeader ( pw , "Transfer-Encoding" , "chunked" ) ; 
} else if ( ! useGzipWhenAccepted ( ) ) { 
pending = sendContentLengthHeaderIfNotAlreadyPresent ( pw , pending ) ; 
pw . append ( "\r\n" ) ; 
pw . flush ( ) ; 
sendBodyWithCorrectTransferAndEncoding ( outputStream , pending ) ; 
outputStream . flush ( ) ; 
NanoHTTPD . safeClose ( this . data ) ; 
} private void sendBody ( OutputStream outputStream , long pending ) throws IOException { 
long BUFFER_SIZE = 16 * 1024 ; 
byte [ ] buff = new byte [ ( int ) BUFFER_SIZE ] ; 
boolean sendEverything = pending == - 1 ; 
while ( pending > 0 || sendEverything ) { 
long bytesToRead = sendEverything ? BUFFER_SIZE : Math . min ( pending , BUFFER_SIZE ) ; 
int read = this . data . read ( buff , 0 , ( int ) bytesToRead ) ; 
if ( read <= 0 ) { 
outputStream . write ( buff , 0 , read ) ; 
if ( this . data != null ) { 
this . data . close ( ) ; 
if ( ! sendEverything ) { 
pending -= read ; 
} public static Response newChunkedResponse ( IStatus status , String mimeType , InputStream data ) { 
return new Response ( status , mimeType , data , - 1 ) ; 
} public static Response newFixedLengthResponse ( IStatus status , String mimeType , InputStream data , long totalBytes ) { 
return new Response ( status , mimeType , data , totalBytes ) ; 
} public static Response newFixedLengthResponse ( IStatus status , String mimeType , String txt ) { 
ContentType contentType = new ContentType ( mimeType ) ; 
if ( txt == null ) { 
return newFixedLengthResponse ( status , mimeType , new ByteArrayInputStream ( new byte [ 0 ] ) , 0 ) ; 
byte [ ] bytes ; 
CharsetEncoder newEncoder = Charset . forName ( contentType . getEncoding ( ) ) . newEncoder ( ) ; 
if ( ! newEncoder . canEncode ( txt ) ) { 
contentType = contentType . tryUTF8 ( ) ; 
bytes = txt . getBytes ( contentType . getEncoding ( ) ) ; 
} catch ( UnsupportedEncodingException e ) { 
bytes = new byte [ 0 ] ; 
return newFixedLengthResponse ( status , contentType . getContentTypeHeader ( ) , new ByteArrayInputStream ( bytes ) , bytes . length ) ; 
} public static Response newFixedLengthResponse ( String msg ) { 
return newFixedLengthResponse ( Status . OK , NanoHTTPD . MIME_HTML , msg ) ; 
} public boolean useGzipWhenAccepted ( ) { 
if ( gzipUsage == GzipUsage . DEFAULT ) 
return getMimeType ( ) != null && ( getMimeType ( ) . toLowerCase ( ) . contains ( "text/" ) || getMimeType ( ) . toLowerCase ( ) . contains ( "/json" ) ) ; 
return gzipUsage == GzipUsage . ALWAYS ; 
} private void readWebsocket ( ) { 
while ( this . state == State . OPEN ) { 
handleWebsocketFrame ( WebSocketFrame . read ( this . in ) ) ; 
} catch ( CharacterCodingException e ) { 
onException ( e ) ; 
doClose ( CloseCode . InvalidFramePayloadData , e . toString ( ) , false ) ; 
} catch ( IOException e ) { 
if ( e instanceof WebSocketException ) { 
doClose ( ( ( WebSocketException ) e ) . getCode ( ) , ( ( WebSocketException ) e ) . getReason ( ) , false ) ; 
} private static String encodeBase64 ( byte [ ] buf ) { 
int size = buf . length ; 
char [ ] ar = new char [ ( size + 2 ) / 3 * 4 ] ; 
int a = 0 ; 
int i = 0 ; 
while ( i < size ) { 
byte b0 = buf [ i ++ ] ; 
byte b1 = i < size ? buf [ i ++ ] : 0 ; 
byte b2 = i < size ? buf [ i ++ ] : 0 ; 
int mask = 0x3F ; 
ar [ a ++ ] = NanoWSD . ALPHABET [ b0 > > 2 & mask ] ; 
ar [ a ++ ] = NanoWSD . ALPHABET [ ( b0 << 4 | ( b1 & 0xFF ) > > 4 ) & mask ] ; 
ar [ a ++ ] = NanoWSD . ALPHABET [ ( b1 << 2 | ( b2 & 0xFF ) > > 6 ) & mask ] ; 
ar [ a ++ ] = NanoWSD . ALPHABET [ b2 & mask ] ; 
switch ( size % 3 ) { 
case 1 : 
ar [ -- a ] = '=' ; 
case 2 : 
return new String ( ar ) ; 
} public String getTextPayload ( ) { 
if ( this . _payloadString == null ) { 
this . _payloadString = binary2Text ( getBinaryPayload ( ) ) ; 
return this . _payloadString ; 
} private void readPayloadInfo ( InputStream in ) throws IOException { 
byte b = ( byte ) checkedRead ( in . read ( ) ) ; 
boolean masked = ( b & 0x80 ) != 0 ; 
this . _payloadLength = ( byte ) ( 0x7F & b ) ; 
if ( this . _payloadLength == 126 ) { 
this . _payloadLength = ( checkedRead ( in . read ( ) ) << 8 | checkedRead ( in . read ( ) ) ) & 0xFFFF ; 
if ( this . _payloadLength < 126 ) { 
} else if ( this . _payloadLength == 127 ) { 
long _payloadLength = 
( long ) checkedRead ( in . read ( ) ) << 56 | ( long ) checkedRead ( in . read ( ) ) << 48 | ( long ) checkedRead ( in . read ( ) ) << 40 | ( long ) checkedRead ( in . read ( ) ) << 32 
| checkedRead ( in . read ( ) ) << 24 | checkedRead ( in . read ( ) ) << 16 | checkedRead ( in . read ( ) ) << 8 | checkedRead ( in . read ( ) ) ; 
if ( _payloadLength < 65536 ) { 
if ( _payloadLength < 0 || _payloadLength > Integer . MAX_VALUE ) { 
this . _payloadLength = ( int ) _payloadLength ; 
if ( this . opCode . isControlFrame ( ) ) { 
if ( this . _payloadLength > 125 ) { 
if ( this . opCode == OpCode . Close && this . _payloadLength == 1 ) { 
if ( masked ) { 
this . maskingKey = new byte [ 4 ] ; 
int read = 0 ; 
while ( read < this . maskingKey . length ) { 
read += checkedRead ( in . read ( this . maskingKey , read , this . maskingKey . length - read ) ) ; 
} public void write ( OutputStream out ) throws IOException { 
byte header = 0 ; 
if ( this . fin ) { 
header |= 0x80 ; 
header |= this . opCode . getValue ( ) & 0x0F ; 
out . write ( header ) ; 
this . _payloadLength = getBinaryPayload ( ) . length ; 
if ( this . _payloadLength <= 125 ) { 
out . write ( isMasked ( ) ? 0x80 | ( byte ) this . _payloadLength : ( byte ) this . _payloadLength ) ; 
} else if ( this . _payloadLength <= 0xFFFF ) { 
out . write ( isMasked ( ) ? 0xFE : 126 ) ; 
out . write ( this . _payloadLength > > > 8 ) ; 
out . write ( this . _payloadLength ) ; 
out . write ( isMasked ( ) ? 0xFF : 127 ) ; 
out . write ( this . _payloadLength > > > 56 & 0 ) ; 
out . write ( this . _payloadLength > > > 48 & 0 ) ; 
out . write ( this . _payloadLength > > > 40 & 0 ) ; 
out . write ( this . _payloadLength > > > 32 & 0 ) ; 
out . write ( this . _payloadLength > > > 24 ) ; 
out . write ( this . _payloadLength > > > 16 ) ; 
if ( isMasked ( ) ) { 
out . write ( this . maskingKey ) ; 
for ( int i = 0 ; i < this . _payloadLength ; i ++ ) { 
out . write ( getBinaryPayload ( ) [ i ] ^ this . maskingKey [ i % 4 ] ) ; 
out . write ( getBinaryPayload ( ) ) ; 
out . flush ( ) ; 
} public void set ( String name , String value , int expires ) { 
this . queue . add ( new Cookie ( name , value , Cookie . getHTTPTime ( expires ) ) ) ; 
} public void unloadQueue ( Response response ) { 
for ( Cookie cookie : this . queue ) { 
response . addCookieHeader ( cookie . getHTTPHeader ( ) ) ; 
} @ RequestMapping ( value = "/sessions/{sessionIdToDelete}" , method = RequestMethod . DELETE ) 
public String removeSession ( Principal principal , 
@ PathVariable String sessionIdToDelete ) { 
Set < String > usersSessionIds = this . sessions 
. findByPrincipalName ( principal . getName ( ) ) . keySet ( ) ; 
if ( usersSessionIds . contains ( sessionIdToDelete ) ) { 
this . sessions . deleteById ( sessionIdToDelete ) ; 
return "redirect:/" ; 
public List < String > readCookieValues ( HttpServletRequest request ) { 
Cookie [ ] cookies = request . getCookies ( ) ; 
List < String > matchingCookieValues = new ArrayList < > ( ) ; 
if ( cookies != null ) { 
for ( Cookie cookie : cookies ) { 
if ( this . cookieName . equals ( cookie . getName ( ) ) ) { 
String sessionId = ( this . useBase64Encoding 
? base64Decode ( cookie . getValue ( ) ) 
: cookie . getValue ( ) ) ; 
if ( sessionId == null ) { 
if ( this . jvmRoute != null && sessionId . endsWith ( this . jvmRoute ) ) { 
sessionId = sessionId . substring ( 0 , 
sessionId . length ( ) - this . jvmRoute . length ( ) ) ; 
matchingCookieValues . add ( sessionId ) ; 
return matchingCookieValues ; 
public void writeCookieValue ( CookieValue cookieValue ) { 
HttpServletRequest request = cookieValue . getRequest ( ) ; 
HttpServletResponse response = cookieValue . getResponse ( ) ; 
sb . append ( this . cookieName ) . append ( '=' ) ; 
String value = getValue ( cookieValue ) ; 
if ( value != null && value . length ( ) > 0 ) { 
validateValue ( value ) ; 
sb . append ( value ) ; 
int maxAge = getMaxAge ( cookieValue ) ; 
if ( maxAge > - 1 ) { 
OffsetDateTime expires = ( maxAge != 0 ) 
? OffsetDateTime . now ( ) . plusSeconds ( maxAge ) 
: Instant . EPOCH . atOffset ( ZoneOffset . UTC ) ; 
. append ( expires . format ( DateTimeFormatter . RFC_1123_DATE_TIME ) ) ; 
String domain = getDomainName ( request ) ; 
if ( domain != null && domain . length ( ) > 0 ) { 
validateDomain ( domain ) ; 
String path = getCookiePath ( request ) ; 
if ( path != null && path . length ( ) > 0 ) { 
validatePath ( path ) ; 
if ( isSecureCookie ( request ) ) { 
if ( this . useHttpOnlyCookie ) { 
if ( this . sameSite != null ) { 
response . addHeader ( "Set-Cookie" , sb . toString ( ) ) ; 
} private String base64Decode ( String base64Value ) { 
byte [ ] decodedCookieBytes = Base64 . getDecoder ( ) . decode ( base64Value ) ; 
return new String ( decodedCookieBytes ) ; 
catch ( Exception ex ) { 
} private String base64Encode ( String value ) { 
byte [ ] encodedCookieBytes = Base64 . getEncoder ( ) . encode ( value . getBytes ( ) ) ; 
return new String ( encodedCookieBytes ) ; 
} public void setDomainNamePattern ( String domainNamePattern ) { 
if ( this . domainName != null ) { 
this . domainNamePattern = Pattern . compile ( domainNamePattern , 
Pattern . CASE_INSENSITIVE ) ; 
} public void setTableName ( String tableName ) { 
this . tableName = tableName . trim ( ) ; 
prepareQueries ( ) ; 
public void onApplicationEvent ( AbstractSessionEvent event ) { 
if ( this . listeners . isEmpty ( ) ) { 
HttpSessionEvent httpSessionEvent = createHttpSessionEvent ( event ) ; 
for ( HttpSessionListener listener : this . listeners ) { 
if ( event instanceof SessionDestroyedEvent ) { 
listener . sessionDestroyed ( httpSessionEvent ) ; 
else if ( event instanceof SessionCreatedEvent ) { 
listener . sessionCreated ( httpSessionEvent ) ; 
} @ Bean 
public CookieSerializer cookieSerializer ( ) { 
DefaultCookieSerializer serializer = new DefaultCookieSerializer ( ) ; 
serializer . setCookieName ( "JSESSIONID" ) ; 
serializer . setCookiePath ( "/" ) ; 
serializer . setDomainNamePattern ( "^.+?\\.(\\w+\\.[a-z]+)$" ) ; 
return serializer ; 
} private ObjectMapper objectMapper ( ) { 
ObjectMapper mapper = new ObjectMapper ( ) ; 
mapper . registerModules ( SecurityJackson2Modules . getModules ( this . loader ) ) ; 
return mapper ; 
public void doFilterInternal ( HttpServletRequest request , HttpServletResponse response , 
FilterChain chain ) throws IOException , ServletException { 
chain . doFilter ( request , response ) ; 
HttpSession session = request . getSession ( false ) ; 
if ( session != null ) { 
String remoteAddr = getRemoteAddress ( request ) ; 
String geoLocation = getGeoLocation ( remoteAddr ) ; 
SessionDetails details = new SessionDetails ( ) ; 
details . setAccessType ( request . getHeader ( "User-Agent" ) ) ; 
session . setAttribute ( "SESSION_DETAILS" , details ) ; 
} String getGeoLocation ( String remoteAddr ) { 
CityResponse city = this . reader . city ( InetAddress . getByName ( remoteAddr ) ) ; 
String cityName = city . getCity ( ) . getName ( ) ; 
String countryName = city . getCountry ( ) . getName ( ) ; 
if ( cityName == null && countryName == null ) { 
else if ( cityName == null ) { 
return countryName ; 
else if ( countryName == null ) { 
return cityName ; 
return UNKNOWN ; 
public void configure ( RedisConnection connection ) { 
String notifyOptions = getNotifyOptions ( connection ) ; 
String customizedNotifyOptions = notifyOptions ; 
if ( ! customizedNotifyOptions . contains ( "E" ) ) { 
customizedNotifyOptions += "E" ; 
boolean A = customizedNotifyOptions . contains ( "A" ) ; 
if ( ! ( A || customizedNotifyOptions . contains ( "g" ) ) ) { 
customizedNotifyOptions += "g" ; 
if ( ! ( A || customizedNotifyOptions . contains ( "x" ) ) ) { 
customizedNotifyOptions += "x" ; 
if ( ! notifyOptions . equals ( customizedNotifyOptions ) ) { 
connection . setConfig ( CONFIG_NOTIFY_KEYSPACE_EVENTS , customizedNotifyOptions ) ; 
} @ Bean ( WebHttpHandlerBuilder . WEB_SESSION_MANAGER_BEAN_NAME ) 
public WebSessionManager webSessionManager ( ReactiveSessionRepository < ? extends Session > repository ) { 
SpringSessionWebSessionStore < ? extends Session > sessionStore = new SpringSessionWebSessionStore < > ( repository ) ; 
DefaultWebSessionManager manager = new DefaultWebSessionManager ( ) ; 
manager . setSessionStore ( sessionStore ) ; 
if ( this . webSessionIdResolver != null ) { 
manager . setSessionIdResolver ( this . webSessionIdResolver ) ; 
return manager ; 
public UserDetails loadUserByUsername ( String username ) 
throws UsernameNotFoundException { 
User user = this . userRepository . findByEmail ( username ) ; 
if ( user == null ) { 
return new CustomUserDetails ( user ) ; 
} protected boolean rememberMeRequested ( HttpServletRequest request , String parameter ) { 
String rememberMe = request . getParameter ( parameter ) ; 
if ( rememberMe != null ) { 
if ( rememberMe . equalsIgnoreCase ( "true" ) || rememberMe . equalsIgnoreCase ( "on" ) 
|| rememberMe . equalsIgnoreCase ( "yes" ) || rememberMe . equals ( "1" ) ) { 
} protected String name ( Object principal ) { 
if ( principal instanceof UserDetails ) { 
return ( ( UserDetails ) principal ) . getUsername ( ) ; 
if ( principal instanceof Principal ) { 
return ( ( Principal ) principal ) . getName ( ) ; 
return principal . toString ( ) ; 
} private void insertSessionRepositoryFilter ( ServletContext servletContext ) { 
String filterName = DEFAULT_FILTER_NAME ; 
DelegatingFilterProxy springSessionRepositoryFilter = new DelegatingFilterProxy ( 
filterName ) ; 
String contextAttribute = getWebApplicationContextAttribute ( ) ; 
if ( contextAttribute != null ) { 
springSessionRepositoryFilter . setContextAttribute ( contextAttribute ) ; 
registerFilter ( servletContext , true , filterName , springSessionRepositoryFilter ) ; 
} protected EnumSet < DispatcherType > getSessionDispatcherTypes ( ) { 
return EnumSet . of ( DispatcherType . REQUEST , DispatcherType . ERROR , 
DispatcherType . ASYNC ) ; 
} private static String resolvePrincipal ( Session session ) { 
String principalName = session 
. getAttribute ( FindByIndexNameSessionRepository . PRINCIPAL_NAME_INDEX_NAME ) ; 
if ( principalName != null ) { 
return principalName ; 
SecurityContext securityContext = session 
. getAttribute ( SPRING_SECURITY_CONTEXT ) ; 
if ( securityContext != null 
&& securityContext . getAuthentication ( ) != null ) { 
return securityContext . getAuthentication ( ) . getName ( ) ; 
return "" ; 
public final void doFilter ( ServletRequest request , ServletResponse response , 
FilterChain filterChain ) throws ServletException , IOException { 
if ( ! ( request instanceof HttpServletRequest ) 
|| ! ( response instanceof HttpServletResponse ) ) { 
throw new ServletException ( 
HttpServletRequest httpRequest = ( HttpServletRequest ) request ; 
HttpServletResponse httpResponse = ( HttpServletResponse ) response ; 
boolean hasAlreadyFilteredAttribute = request 
. getAttribute ( this . alreadyFilteredAttributeName ) != null ; 
if ( hasAlreadyFilteredAttribute ) { 
filterChain . doFilter ( request , response ) ; 
else { 
request . setAttribute ( this . alreadyFilteredAttributeName , Boolean . TRUE ) ; 
doFilterInternal ( httpRequest , httpResponse , filterChain ) ; 
finally { 
request . removeAttribute ( this . alreadyFilteredAttributeName ) ; 
} private RedisSession getSession ( String id , boolean allowExpired ) { 
Map < Object , Object > entries = getSessionBoundHashOperations ( id ) . entries ( ) ; 
if ( entries . isEmpty ( ) ) { 
MapSession loaded = loadSession ( id , entries ) ; 
if ( ! allowExpired && loaded . isExpired ( ) ) { 
RedisSession result = new RedisSession ( loaded ) ; 
result . originalLastAccessTime = loaded . getLastAccessedTime ( ) ; 
} private BoundHashOperations < Object , Object , Object > getSessionBoundHashOperations ( 
String sessionId ) { 
String key = getSessionKey ( sessionId ) ; 
return this . sessionRedisOperations . boundHashOps ( key ) ; 
} protected void setTypeInternal ( final OType iType ) { 
getDatabase ( ) . checkSecurity ( ORule . ResourceGeneric . SCHEMA , ORole . PERMISSION_UPDATE ) ; 
acquireSchemaWriteLock ( ) ; 
if ( iType == globalRef . getType ( ) ) 
if ( ! iType . getCastable ( ) . contains ( globalRef . getType ( ) ) ) 
this . globalRef = owner . owner . findOrCreateGlobalProperty ( this . globalRef . getName ( ) , iType ) ; 
releaseSchemaWriteLock ( ) ; 
public static void getPageData ( final ByteBuffer buffer , final byte [ ] data , final int offset , final int length ) { 
buffer . position ( 0 ) ; 
buffer . get ( data , offset , length ) ; 
public static OLogSequenceNumber getLogSequenceNumber ( final int offset , final byte [ ] data ) { 
final long segment = OLongSerializer . INSTANCE . deserializeNative ( data , offset + WAL_SEGMENT_OFFSET ) ; 
final long position = OLongSerializer . INSTANCE . deserializeNative ( data , offset + WAL_POSITION_OFFSET ) ; 
return new OLogSequenceNumber ( segment , position ) ; 
public static Object cloneObject ( final Object objectToClone , final Object previousClone ) { 
if ( objectToClone instanceof Map ) { 
Map recycledMap = ( Map ) previousClone ; 
if ( recycledMap == null ) 
recycledMap = new HashMap ( ) ; 
recycledMap . clear ( ) ; 
recycledMap . putAll ( ( Map < ? , ? > ) objectToClone ) ; 
return recycledMap ; 
} else if ( objectToClone instanceof Collection ) { 
Collection recycledCollection = ( Collection ) previousClone ; 
if ( recycledCollection == null ) 
recycledCollection = new ArrayList ( ) ; 
recycledCollection . clear ( ) ; 
recycledCollection . addAll ( ( Collection < ? > ) objectToClone ) ; 
return recycledCollection ; 
} else if ( objectToClone instanceof String ) { 
return objectToClone ; 
} else if ( objectToClone instanceof Number ) { 
} else if ( objectToClone instanceof Date ) { 
return ( Date ) ( ( Date ) objectToClone ) . clone ( ) ; 
Object newClone ; 
for ( Class < ? > obj = objectToClone . getClass ( ) ; ! obj . equals ( Object . class ) ; obj = obj . getSuperclass ( ) ) { 
Method m [ ] = obj . getDeclaredMethods ( ) ; 
for ( int i = 0 ; i < m . length ; i ++ ) { 
if ( m [ i ] . getName ( ) . equals ( "clone" ) ) { 
m [ i ] . setAccessible ( true ) ; 
newClone = m [ i ] . invoke ( objectToClone ) ; 
System . out . println ( objectToClone . getClass ( ) 
return newClone ; 
} catch ( Exception e1 ) { 
final ByteArrayOutputStream bytes = new ByteArrayOutputStream ( ) { 
public synchronized byte [ ] toByteArray ( ) { 
return buf ; 
final ObjectOutputStream out = new ObjectOutputStream ( bytes ) ; 
out . writeObject ( objectToClone ) ; 
out . close ( ) ; 
final ObjectInputStream in = new ObjectInputStream ( new ByteArrayInputStream ( bytes . toByteArray ( ) ) ) ; 
return in . readObject ( ) ; 
} catch ( Exception e2 ) { 
OLogManager . instance ( ) 
} public void inputGraph ( final String filename , int bufferSize , final Set < String > edgePropertyKeys , 
final Set < String > vertexPropertyKeys ) throws IOException { 
final File file = new File ( filename ) ; 
if ( ! file . exists ( ) ) 
inputSize = file . length ( ) ; 
final FileInputStream fis = new FileInputStream ( filename ) ; 
inputGraph ( fis , bufferSize , edgePropertyKeys , vertexPropertyKeys ) ; 
fis . close ( ) ; 
} public void inputGraph ( final InputStream jsonInputStream , int bufferSize , final Set < String > edgePropertyKeys , 
final JsonParser jp = jsonFactory . createJsonParser ( jsonInputStream ) ; 
final BatchGraph batchGraph = BatchGraph . wrap ( graph , bufferSize ) ; 
final ElementFactory elementFactory = new GraphElementFactory ( batchGraph ) ; 
OGraphSONUtility graphson = new OGraphSONUtility ( GraphSONMode . NORMAL , elementFactory , vertexPropertyKeys , edgePropertyKeys ) ; 
long importedVertices = 0 ; 
long importedEdges = 0 ; 
while ( jp . nextToken ( ) != JsonToken . END_OBJECT ) { 
final String fieldname = jp . getCurrentName ( ) == null ? "" : jp . getCurrentName ( ) ; 
if ( fieldname . equals ( GraphSONTokens . MODE ) ) { 
jp . nextToken ( ) ; 
final GraphSONMode mode = GraphSONMode . valueOf ( jp . getText ( ) ) ; 
graphson = new OGraphSONUtility ( mode , elementFactory , vertexPropertyKeys , edgePropertyKeys ) ; 
} else if ( fieldname . equals ( GraphSONTokens . VERTICES ) ) { 
while ( jp . nextToken ( ) != JsonToken . END_ARRAY ) { 
final JsonNode node = jp . readValueAsTree ( ) ; 
graphson . vertexFromJson ( node ) ; 
importedVertices ++ ; 
printStatus ( jp , importedVertices , importedEdges ) ; 
if ( importedVertices % 1000 == 0 ) 
ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getLocalCache ( ) . invalidate ( ) ; 
} else if ( fieldname . equals ( GraphSONTokens . EDGES ) ) { 
final Vertex inV = batchGraph . getVertex ( OGraphSONUtility . getTypedValueFromJsonNode ( node . get ( GraphSONTokens . _IN_V ) ) ) ; 
final Vertex outV = batchGraph . getVertex ( OGraphSONUtility . getTypedValueFromJsonNode ( node . get ( GraphSONTokens . _OUT_V ) ) ) ; 
graphson . edgeFromJson ( node , outV , inV ) ; 
importedEdges ++ ; 
if ( importedEdges % 1000 == 0 ) 
jp . close ( ) ; 
batchGraph . commit ( ) ; 
} public static OIndexDefinition createIndexDefinition ( final OClass oClass , final List < String > fieldNames , final List < OType > types , 
List < OCollate > collates , String indexKind , String algorithm ) { 
checkTypes ( oClass , fieldNames , types ) ; 
if ( fieldNames . size ( ) == 1 ) 
return createSingleFieldIndexDefinition ( oClass , fieldNames . get ( 0 ) , types . get ( 0 ) , collates == null ? null : collates . get ( 0 ) , 
indexKind , algorithm ) ; 
return createMultipleFieldIndexDefinition ( oClass , fieldNames , types , collates , indexKind , algorithm ) ; 
} public static String extractFieldName ( final String fieldDefinition ) { 
String [ ] fieldNameParts = FILED_NAME_PATTERN . split ( fieldDefinition ) ; 
if ( fieldNameParts . length == 0 ) { 
if ( fieldNameParts . length == 3 && "by" . equalsIgnoreCase ( fieldNameParts [ 1 ] ) ) 
return fieldNameParts [ 0 ] ; 
if ( fieldNameParts . length == 1 ) 
return fieldDefinition ; 
StringBuilder result = new StringBuilder ( ) ; 
result . append ( fieldNameParts [ 0 ] ) ; 
for ( int i = 1 ; i < fieldNameParts . length ; i ++ ) { 
result . append ( fieldNameParts [ i ] ) ; 
return result . toString ( ) ; 
} public boolean canExecuteIndexedFunctionWithoutIndex ( OFromClause target , OCommandContext context , OBinaryCompareOperator operator , 
Object right ) { 
if ( this . identifier == null ) { 
return identifier . canExecuteIndexedFunctionWithoutIndex ( target , context , operator , right ) ; 
} public long estimate ( OClass oClass , long threshold , OCommandContext ctx ) { 
long count = oClass . count ( ) ; 
if ( count > 1 ) { 
count = count / 2 ; 
if ( count < threshold ) { 
return count ; 
long indexesCount = 0l ; 
List < OAndBlock > flattenedConditions = flatten ( ) ; 
Set < OIndex < ? > > indexes = oClass . getIndexes ( ) ; 
for ( OAndBlock condition : flattenedConditions ) { 
List < OBinaryCondition > indexedFunctConditions = condition 
. getIndexedFunctionConditions ( oClass , ( ODatabaseDocumentInternal ) ctx . getDatabase ( ) ) ; 
long conditionEstimation = Long . MAX_VALUE ; 
if ( indexedFunctConditions != null ) { 
for ( OBinaryCondition cond : indexedFunctConditions ) { 
OFromClause from = new OFromClause ( - 1 ) ; 
OFromItem item = new OFromItem ( - 1 ) ; 
from . item = item ; 
from . item . setIdentifier ( new OIdentifier ( oClass . getName ( ) ) ) ; 
long newCount = cond . estimateIndexed ( from , ctx ) ; 
if ( newCount < conditionEstimation ) { 
conditionEstimation = newCount ; 
Map < String , Object > conditions = getEqualityOperations ( condition , ctx ) ; 
for ( OIndex index : indexes ) { 
if ( index . getType ( ) . equals ( OClass . INDEX_TYPE . FULLTEXT . name ( ) ) || index . getType ( ) 
. equals ( OClass . INDEX_TYPE . FULLTEXT_HASH_INDEX . name ( ) ) ) { 
List < String > indexedFields = index . getDefinition ( ) . getFields ( ) ; 
int nMatchingKeys = 0 ; 
for ( String indexedField : indexedFields ) { 
if ( conditions . containsKey ( indexedField ) ) { 
nMatchingKeys ++ ; 
if ( nMatchingKeys > 0 ) { 
long newCount = estimateFromIndex ( index , conditions , nMatchingKeys ) ; 
if ( conditionEstimation > count ) { 
indexesCount += conditionEstimation ; 
return Math . min ( indexesCount , count ) ; 
} private static List < Class < ? > > findClasses ( final File iDirectory , String iPackageName , ClassLoader iClassLoader ) 
throws ClassNotFoundException { 
final List < Class < ? > > classes = new ArrayList < Class < ? > > ( ) ; 
if ( ! iDirectory . exists ( ) ) 
return classes ; 
iPackageName += "." + iDirectory . getName ( ) ; 
String className ; 
final File [ ] files = iDirectory . listFiles ( ) ; 
if ( files != null ) 
for ( File file : files ) { 
if ( file . isDirectory ( ) ) { 
if ( file . getName ( ) . contains ( "." ) ) 
classes . addAll ( findClasses ( file , iPackageName , iClassLoader ) ) ; 
} else if ( file . getName ( ) . endsWith ( CLASS_EXTENSION ) ) { 
className = file . getName ( ) . substring ( 0 , file . getName ( ) . length ( ) - CLASS_EXTENSION . length ( ) ) ; 
classes . add ( Class . forName ( iPackageName + '.' + className , true , iClassLoader ) ) ; 
} public static List < Class < ? > > getClassessOfInterface ( String thePackage , Class < ? > theInterface , final ClassLoader iClassLoader ) { 
List < Class < ? > > classList = new ArrayList < Class < ? > > ( ) ; 
for ( Class < ? > discovered : getClassesFor ( thePackage , iClassLoader ) ) { 
if ( Arrays . asList ( discovered . getInterfaces ( ) ) . contains ( theInterface ) ) { 
classList . add ( discovered ) ; 
} catch ( ClassNotFoundException ex ) { 
return classList ; 
} public static Type [ ] getGenericTypes ( final Class < ? > iClass ) { 
final Type genericType = iClass . getGenericInterfaces ( ) [ 0 ] ; 
if ( genericType != null && genericType instanceof ParameterizedType ) { 
final ParameterizedType pt = ( ParameterizedType ) genericType ; 
if ( pt . getActualTypeArguments ( ) != null && pt . getActualTypeArguments ( ) . length > 1 ) 
return pt . getActualTypeArguments ( ) ; 
} public static Class < ? > getGenericMultivalueType ( final Field p ) { 
if ( p . getType ( ) instanceof Class < ? > ) { 
final Type genericType = p . getGenericType ( ) ; 
if ( pt . getActualTypeArguments ( ) != null && pt . getActualTypeArguments ( ) . length > 0 ) { 
if ( ( ( Class < ? > ) pt . getRawType ( ) ) . isAssignableFrom ( Map . class ) ) { 
if ( pt . getActualTypeArguments ( ) [ 1 ] instanceof Class < ? > ) { 
return ( Class < ? > ) pt . getActualTypeArguments ( ) [ 1 ] ; 
} else if ( pt . getActualTypeArguments ( ) [ 1 ] instanceof ParameterizedType ) 
return ( Class < ? > ) ( ( ParameterizedType ) pt . getActualTypeArguments ( ) [ 1 ] ) . getRawType ( ) ; 
} else if ( pt . getActualTypeArguments ( ) [ 0 ] instanceof Class < ? > ) { 
return ( Class < ? > ) pt . getActualTypeArguments ( ) [ 0 ] ; 
} else if ( pt . getActualTypeArguments ( ) [ 0 ] instanceof ParameterizedType ) 
return ( Class < ? > ) ( ( ParameterizedType ) pt . getActualTypeArguments ( ) [ 0 ] ) . getRawType ( ) ; 
} else if ( p . getType ( ) . isArray ( ) ) 
return p . getType ( ) . getComponentType ( ) ; 
} public static boolean isJavaType ( Class < ? > clazz ) { 
if ( clazz . isPrimitive ( ) ) 
else if ( clazz . getName ( ) . startsWith ( "java.lang" ) ) 
else if ( clazz . getName ( ) . startsWith ( "java.util" ) ) 
else if ( clazz . isArray ( ) ) 
} public Object execute ( final Object iThis , final OIdentifiable iCurrentRecord , final Object iCurrentResult , 
final OCommandContext iContext ) { 
if ( iThis == null ) 
if ( configuredParameters != null ) { 
for ( int i = 0 ; i < configuredParameters . length ; ++ i ) { 
runtimeParameters [ i ] = configuredParameters [ i ] ; 
if ( method . evaluateParameters ( ) ) { 
if ( configuredParameters [ i ] instanceof OSQLFilterItemField ) { 
runtimeParameters [ i ] = ( ( OSQLFilterItemField ) configuredParameters [ i ] ) . getValue ( iCurrentRecord , iCurrentResult , 
iContext ) ; 
if ( runtimeParameters [ i ] == null && iCurrentResult instanceof OIdentifiable ) 
runtimeParameters [ i ] = ( ( OSQLFilterItemField ) configuredParameters [ i ] ) . getValue ( ( OIdentifiable ) iCurrentResult , 
iCurrentResult , iContext ) ; 
} else if ( configuredParameters [ i ] instanceof OSQLMethodRuntime ) 
runtimeParameters [ i ] = ( ( OSQLMethodRuntime ) configuredParameters [ i ] ) . execute ( iThis , iCurrentRecord , iCurrentResult , 
else if ( configuredParameters [ i ] instanceof OSQLFunctionRuntime ) 
runtimeParameters [ i ] = ( ( OSQLFunctionRuntime ) configuredParameters [ i ] ) . execute ( iCurrentRecord , iCurrentRecord , iCurrentResult , 
else if ( configuredParameters [ i ] instanceof OSQLFilterItemVariable ) { 
runtimeParameters [ i ] = ( ( OSQLFilterItemVariable ) configuredParameters [ i ] ) . getValue ( iCurrentRecord , iCurrentResult , 
runtimeParameters [ i ] = ( ( OSQLFilterItemVariable ) configuredParameters [ i ] ) . getValue ( ( OIdentifiable ) iCurrentResult , 
} else if ( configuredParameters [ i ] instanceof OCommandSQL ) { 
runtimeParameters [ i ] = ( ( OCommandSQL ) configuredParameters [ i ] ) . setContext ( iContext ) . execute ( ) ; 
} catch ( OCommandExecutorNotFoundException ignore ) { 
final String text = ( ( OCommandSQL ) configuredParameters [ i ] ) . getText ( ) ; 
final OSQLPredicate pred = new OSQLPredicate ( text ) ; 
runtimeParameters [ i ] = pred . evaluate ( iCurrentRecord instanceof ORecord ? ( ORecord ) iCurrentRecord : null , 
( ODocument ) iCurrentResult , iContext ) ; 
configuredParameters [ i ] = pred ; 
} else if ( configuredParameters [ i ] instanceof OSQLPredicate ) 
runtimeParameters [ i ] = ( ( OSQLPredicate ) configuredParameters [ i ] ) . evaluate ( iCurrentRecord . getRecord ( ) , 
( iCurrentRecord instanceof ODocument ? ( ODocument ) iCurrentResult : null ) , iContext ) ; 
else if ( configuredParameters [ i ] instanceof String ) { 
if ( configuredParameters [ i ] . toString ( ) . startsWith ( "\"" ) || configuredParameters [ i ] . toString ( ) . startsWith ( "'" ) ) 
runtimeParameters [ i ] = OIOUtils . getStringContent ( configuredParameters [ i ] ) ; 
if ( method . getMaxParams ( ) == - 1 || method . getMaxParams ( ) > 0 ) { 
if ( runtimeParameters . length < method . getMinParams ( ) 
|| ( method . getMaxParams ( ) > - 1 && runtimeParameters . length > method . getMaxParams ( ) ) ) 
+ method . getName ( ) 
+ ( method . getMinParams ( ) == method . getMaxParams ( ) ? method . getMinParams ( ) : method . getMinParams ( ) + "-" 
final Object functionResult = method . execute ( iThis , iCurrentRecord , iContext , iCurrentResult , runtimeParameters ) ; 
return transformValue ( iCurrentRecord , iContext , functionResult ) ; 
public Object evaluateRecord ( final OIdentifiable iRecord , ODocument iCurrentResult , final OSQLFilterCondition iCondition , 
final Object iLeft , final Object iRight , OCommandContext iContext , final ODocumentSerializer serializer ) { 
if ( iLeft == null || iRight == null ) 
return iLeft . toString ( ) . indexOf ( iRight . toString ( ) ) > - 1 ; 
} protected OType deriveFieldType ( ODocument iRecord , String fieldName , OType requestedFieldType ) { 
if ( iRecord . getSchemaClass ( ) . existsProperty ( fieldName ) ) { 
return iRecord . getSchemaClass ( ) . getProperty ( fieldName ) . getType ( ) ; 
if ( requestedFieldType != null ) { 
return requestedFieldType ; 
return iRecord . fieldType ( fieldName ) ; 
} public Object execute ( final Map < Object , Object > iArgs ) { 
if ( role == null ) 
role . revoke ( resource , privilege ) ; 
role . save ( ) ; 
return role ; 
} public void updateRecord ( final ORecord record ) { 
if ( record . getIdentity ( ) . getClusterId ( ) != excludedCluster && record . getIdentity ( ) . isValid ( ) && ! record . isDirty ( ) 
&& ! ORecordVersionHelper . isTombstone ( record . getVersion ( ) ) ) { 
if ( underlying . get ( record . getIdentity ( ) ) != record ) 
underlying . put ( record ) ; 
} public ORecord findRecord ( final ORID rid ) { 
ORecord record ; 
record = underlying . get ( rid ) ; 
if ( record != null ) 
"db.*.cache.level1.cache.notFound" ) ; 
return record ; 
if ( name == null ) 
if ( name . equals ( "*" ) ) { 
long totalIndexed = 0 ; 
for ( OIndex < ? > idx : getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . getIndexes ( ) ) { 
getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( idx . getName ( ) ) ; 
totalIndexed ++ ; 
return totalIndexed ; 
getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( name ) ; 
public void serializeInByteBufferObject ( T object , ByteBuffer buffer , Object ... hints ) { 
init ( object , hints ) ; 
buffer . put ( binarySerializer . getId ( ) ) ; 
binarySerializer . serializeInByteBufferObject ( object , buffer ) ; 
public T deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final byte typeId = buffer . get ( ) ; 
init ( typeId ) ; 
return ( T ) binarySerializer . deserializeFromByteBufferObject ( buffer ) ; 
public int getObjectSizeInByteBuffer ( ByteBuffer buffer ) { 
final byte serializerId = buffer . get ( ) ; 
init ( serializerId ) ; 
return OBinarySerializerFactory . TYPE_IDENTIFIER_SIZE + binarySerializer . getObjectSizeInByteBuffer ( buffer ) ; 
public T deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final byte typeId = walChanges . getByteValue ( buffer , offset ++ ) ; 
return ( T ) binarySerializer . deserializeFromByteBufferObject ( buffer , walChanges , offset ) ; 
public int getObjectSizeInByteBuffer ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return OBinarySerializerFactory . TYPE_IDENTIFIER_SIZE + binarySerializer 
. getObjectSizeInByteBuffer ( buffer , walChanges , OBinarySerializerFactory . TYPE_IDENTIFIER_SIZE + offset ) ; 
} public void begin ( ) { 
walActive = OGlobalConfiguration . USE_WAL . getValueAsBoolean ( ) ; 
if ( walActive ) 
OGlobalConfiguration . USE_WAL . setValue ( false ) ; 
if ( averageEdgeNumberPerNode > 0 ) { 
OGlobalConfiguration . RID_BAG_EMBEDDED_DEFAULT_SIZE . setValue ( averageEdgeNumberPerNode ) ; 
OGlobalConfiguration . RID_BAG_EMBEDDED_TO_SBTREEBONSAI_THRESHOLD . setValue ( bonsaiThreshold ) ; 
db = new ODatabaseDocumentTx ( dbUrl ) ; 
if ( db . exists ( ) ) { 
db . open ( userName , password ) ; 
db . create ( ) ; 
if ( this . useLightWeigthEdges == null ) { 
final List < OStorageEntryConfiguration > custom = ( List < OStorageEntryConfiguration > ) db . get ( ODatabase . ATTRIBUTES . CUSTOM ) ; 
for ( OStorageEntryConfiguration c : custom ) { 
if ( c . name . equalsIgnoreCase ( "useLightweightEdges" ) ) { 
this . useLightWeigthEdges = Boolean . parseBoolean ( c . value ) ; 
this . useLightWeigthEdges = true ; 
createBaseSchema ( ) ; 
out = estimatedEntries > 0 ? new HashMap < Long , List < Object > > ( estimatedEntries ) : new HashMap < Long , List < Object > > ( ) ; 
in = estimatedEntries > 0 ? new HashMap < Long , List < Object > > ( estimatedEntries ) : new HashMap < Long , List < Object > > ( ) ; 
OClass vClass = db . getMetadata ( ) . getSchema ( ) . getClass ( this . vertexClass ) ; 
int [ ] existingClusters = vClass . getClusterIds ( ) ; 
for ( int c = existingClusters . length ; c <= parallel ; c ++ ) { 
vClass . addCluster ( vClass . getName ( ) + "_" + c ) ; 
clusterIds = vClass . getClusterIds ( ) ; 
lastClusterPositions = new long [ clusterIds . length ] ; 
nextVerticesToCreate = new long [ clusterIds . length ] ; 
for ( int i = 0 ; i < clusterIds . length ; i ++ ) { 
int clusterId = clusterIds [ i ] ; 
nextVerticesToCreate [ i ] = i ; 
lastClusterPositions [ i ] = ( ( ODatabaseDocumentInternal ) db ) . getStorage ( ) . getClusterById ( clusterId ) . getLastPosition ( ) ; 
throw new RuntimeException ( e ) ; 
} public void createEdge ( final Long from , final Long to , Map < String , Object > properties ) { 
if ( settingProperties ) { 
if ( from < 0 ) { 
if ( to < 0 ) { 
if ( useLightWeigthEdges && ( properties == null || properties . size ( ) == 0 ) ) { 
last = last < from ? from : last ; 
last = last < to ? to : last ; 
putInList ( from , out , to ) ; 
putInList ( to , in , from ) ; 
ODocument edgeDoc = new ODocument ( edgeClass ) ; 
edgeDoc . fromMap ( properties ) ; 
edgeDoc . field ( "out" , new ORecordId ( getClusterId ( from ) , getClusterPosition ( from ) ) ) ; 
edgeDoc . field ( "in" , new ORecordId ( getClusterId ( to ) , getClusterPosition ( to ) ) ) ; 
db . save ( edgeDoc ) ; 
ORecordId rid = ( ORecordId ) edgeDoc . getIdentity ( ) ; 
putInList ( from , out , rid ) ; 
putInList ( to , in , rid ) ; 
} private void calculateShardingStrategy ( QueryPlanningInfo info , OCommandContext ctx ) { 
ODatabaseDocumentInternal db = ( ODatabaseDocumentInternal ) ctx . getDatabase ( ) ; 
info . distributedFetchExecutionPlans = new LinkedHashMap < > ( ) ; 
Map < String , Set < String > > clusterMap = db . getActiveClusterMap ( ) ; 
Set < String > queryClusters = calculateTargetClusters ( info , ctx ) ; 
if ( queryClusters == null || queryClusters . size ( ) == 0 ) { 
String localNode = db . getLocalNodeName ( ) ; 
info . serverToClusters = new LinkedHashMap < > ( ) ; 
info . serverToClusters . put ( localNode , clusterMap . get ( localNode ) ) ; 
info . distributedFetchExecutionPlans . put ( localNode , new OSelectExecutionPlan ( ctx ) ) ; 
Map < String , Set < String > > minimalSetOfNodes = getMinimalSetOfNodesForShardedQuery ( db . getLocalNodeName ( ) , clusterMap , 
queryClusters ) ; 
if ( minimalSetOfNodes == null ) { 
info . serverToClusters = minimalSetOfNodes ; 
for ( String node : info . serverToClusters . keySet ( ) ) { 
info . distributedFetchExecutionPlans . put ( node , new OSelectExecutionPlan ( ctx ) ) ; 
} private Map < String , Set < String > > getMinimalSetOfNodesForShardedQuery ( String localNode , Map < String , Set < String > > clusterMap , 
Set < String > queryClusters ) { 
Map < String , Set < String > > result = new LinkedHashMap < > ( ) ; 
Set < String > uncovered = new HashSet < > ( ) ; 
uncovered . addAll ( queryClusters ) ; 
uncovered = uncovered . stream ( ) . filter ( x -> x != null ) . map ( x -> x . toLowerCase ( Locale . ENGLISH ) ) . collect ( Collectors . toSet ( ) ) ; 
Set < String > nextNodeClusters = new HashSet < > ( ) ; 
Set < String > clustersForNode = clusterMap . get ( localNode ) ; 
if ( clustersForNode != null ) { 
nextNodeClusters . addAll ( clustersForNode ) ; 
nextNodeClusters . retainAll ( uncovered ) ; 
if ( nextNodeClusters . size ( ) > 0 ) { 
result . put ( localNode , nextNodeClusters ) ; 
uncovered . removeAll ( nextNodeClusters ) ; 
while ( uncovered . size ( ) > 0 ) { 
String nextNode = findItemThatCoversMore ( uncovered , clusterMap ) ; 
nextNodeClusters = new HashSet < > ( ) ; 
nextNodeClusters . addAll ( clusterMap . get ( nextNode ) ) ; 
if ( nextNodeClusters . size ( ) == 0 ) { 
throw new OCommandExecutionException ( 
. map ( x -> "" + x . getKey ( ) + ":(" + x . getValue ( ) . stream ( ) . collect ( Collectors . joining ( "," ) ) + ")" ) 
result . put ( nextNode , nextNodeClusters ) ; 
} private Set < String > getServersThatHasAllClusters ( Map < String , Set < String > > clusterMap , Set < String > queryClusters ) { 
Set < String > remainingServers = clusterMap . keySet ( ) ; 
for ( String cluster : queryClusters ) { 
for ( Map . Entry < String , Set < String > > serverConfig : clusterMap . entrySet ( ) ) { 
if ( ! serverConfig . getValue ( ) . contains ( cluster ) ) { 
remainingServers . remove ( serverConfig . getKey ( ) ) ; 
return remainingServers ; 
} private Set < String > calculateTargetClusters ( QueryPlanningInfo info , OCommandContext ctx ) { 
if ( info . target == null ) { 
return Collections . EMPTY_SET ; 
Set < String > result = new HashSet < > ( ) ; 
ODatabase db = ctx . getDatabase ( ) ; 
OFromItem item = info . target . getItem ( ) ; 
if ( item . getRids ( ) != null && item . getRids ( ) . size ( ) > 0 ) { 
if ( item . getRids ( ) . size ( ) == 1 ) { 
OInteger cluster = item . getRids ( ) . get ( 0 ) . getCluster ( ) ; 
if ( cluster . getValue ( ) . longValue ( ) > ORID . CLUSTER_MAX ) { 
result . add ( db . getClusterNameById ( cluster . getValue ( ) . intValue ( ) ) ) ; 
for ( ORid rid : item . getRids ( ) ) { 
OInteger cluster = rid . getCluster ( ) ; 
} else if ( item . getInputParams ( ) != null && item . getInputParams ( ) . size ( ) > 0 ) { 
if ( ( ( ODatabaseInternal ) ctx . getDatabase ( ) ) . isSharded ( ) ) { 
} else if ( item . getCluster ( ) != null ) { 
String name = item . getCluster ( ) . getClusterName ( ) ; 
if ( name == null ) { 
name = db . getClusterNameById ( item . getCluster ( ) . getClusterNumber ( ) ) ; 
if ( name != null ) { 
result . add ( name ) ; 
} else if ( item . getClusterList ( ) != null ) { 
for ( OCluster cluster : item . getClusterList ( ) . toListOfClusters ( ) ) { 
String name = cluster . getClusterName ( ) ; 
name = db . getClusterNameById ( cluster . getClusterNumber ( ) ) ; 
} else if ( item . getIndex ( ) != null ) { 
String indexName = item . getIndex ( ) . getIndexName ( ) ; 
OIndex < ? > idx = db . getMetadata ( ) . getIndexManager ( ) . getIndex ( indexName ) ; 
if ( idx == null ) { 
result . addAll ( idx . getClusters ( ) ) ; 
if ( result . isEmpty ( ) ) { 
} else if ( item . getInputParam ( ) != null ) { 
} else if ( item . getIdentifier ( ) != null ) { 
String className = item . getIdentifier ( ) . getStringValue ( ) ; 
OClass clazz = getSchemaFromContext ( ctx ) . getClass ( className ) ; 
if ( clazz == null ) { 
clazz = getSchemaFromContext ( ctx ) . getView ( className ) ; 
int [ ] clusterIds = clazz . getPolymorphicClusterIds ( ) ; 
for ( int clusterId : clusterIds ) { 
String clusterName = db . getClusterNameById ( clusterId ) ; 
if ( clusterName != null ) { 
result . add ( clusterName ) ; 
} protected static OProjection translateDistinct ( OProjection projection ) { 
if ( projection != null && projection . getItems ( ) . size ( ) == 1 ) { 
if ( isDistinct ( projection . getItems ( ) . get ( 0 ) ) ) { 
projection = projection . copy ( ) ; 
OProjectionItem item = projection . getItems ( ) . get ( 0 ) ; 
OFunctionCall function = ( ( OBaseExpression ) item . getExpression ( ) . getMathExpression ( ) ) . getIdentifier ( ) . getLevelZero ( ) 
. getFunctionCall ( ) ; 
OExpression exp = function . getParams ( ) . get ( 0 ) ; 
OProjectionItem resultItem = new OProjectionItem ( - 1 ) ; 
resultItem . setAlias ( item . getAlias ( ) ) ; 
resultItem . setExpression ( exp . copy ( ) ) ; 
OProjection result = new OProjection ( - 1 ) ; 
result . setItems ( new ArrayList < > ( ) ) ; 
result . setDistinct ( true ) ; 
result . getItems ( ) . add ( resultItem ) ; 
return projection ; 
} private static boolean isDistinct ( OProjectionItem item ) { 
if ( item . getExpression ( ) == null ) { 
if ( item . getExpression ( ) . getMathExpression ( ) == null ) { 
if ( ! ( item . getExpression ( ) . getMathExpression ( ) instanceof OBaseExpression ) ) { 
OBaseExpression base = ( OBaseExpression ) item . getExpression ( ) . getMathExpression ( ) ; 
if ( base . getIdentifier ( ) == null ) { 
if ( base . getModifier ( ) != null ) { 
if ( base . getIdentifier ( ) . getLevelZero ( ) == null ) { 
OFunctionCall function = base . getIdentifier ( ) . getLevelZero ( ) . getFunctionCall ( ) ; 
if ( function == null ) { 
return function . getName ( ) . getStringValue ( ) . equalsIgnoreCase ( "distinct" ) ; 
} private boolean isMinimalQuery ( QueryPlanningInfo info ) { 
return info . projectionAfterOrderBy == null && info . globalLetClause == null && info . perRecordLetClause == null 
&& info . whereClause == null && info . flattenedWhereClause == null && info . groupBy == null && info . orderBy == null 
&& info . unwind == null && info . skip == null ; 
} private static void splitLet ( QueryPlanningInfo info , OCommandContext ctx ) { 
if ( info . perRecordLetClause != null && info . perRecordLetClause . getItems ( ) != null ) { 
Iterator < OLetItem > iterator = info . perRecordLetClause . getItems ( ) . iterator ( ) ; 
OLetItem item = iterator . next ( ) ; 
if ( item . getExpression ( ) != null && item . getExpression ( ) . isEarlyCalculated ( ctx ) ) { 
iterator . remove ( ) ; 
addGlobalLet ( info , item . getVarName ( ) , item . getExpression ( ) ) ; 
} else if ( item . getQuery ( ) != null && ! item . getQuery ( ) . refersToParent ( ) ) { 
addGlobalLet ( info , item . getVarName ( ) , item . getQuery ( ) ) ; 
} private static List < OAndBlock > moveFlattededEqualitiesLeft ( List < OAndBlock > flattenedWhereClause ) { 
if ( flattenedWhereClause == null ) { 
List < OAndBlock > result = new ArrayList < > ( ) ; 
for ( OAndBlock block : flattenedWhereClause ) { 
List < OBooleanExpression > equalityExpressions = new ArrayList < > ( ) ; 
List < OBooleanExpression > nonEqualityExpressions = new ArrayList < > ( ) ; 
OAndBlock newBlock = block . copy ( ) ; 
for ( OBooleanExpression exp : newBlock . getSubBlocks ( ) ) { 
if ( exp instanceof OBinaryCondition ) { 
if ( ( ( OBinaryCondition ) exp ) . getOperator ( ) instanceof OEqualsCompareOperator ) { 
equalityExpressions . add ( exp ) ; 
nonEqualityExpressions . add ( exp ) ; 
OAndBlock newAnd = new OAndBlock ( - 1 ) ; 
newAnd . getSubBlocks ( ) . addAll ( equalityExpressions ) ; 
newAnd . getSubBlocks ( ) . addAll ( nonEqualityExpressions ) ; 
result . add ( newAnd ) ; 
} private static void addOrderByProjections ( QueryPlanningInfo info ) { 
if ( info . orderApplied || info . expand || info . unwind != null || info . orderBy == null || info . orderBy . getItems ( ) . size ( ) == 0 
|| info . projection == null || info . projection . getItems ( ) == null || ( info . projection . getItems ( ) . size ( ) == 1 
&& info . projection . getItems ( ) . get ( 0 ) . isAll ( ) ) ) { 
OOrderBy newOrderBy = info . orderBy == null ? null : info . orderBy . copy ( ) ; 
List < OProjectionItem > additionalOrderByProjections = calculateAdditionalOrderByProjections ( info . projection . getAllAliases ( ) , 
newOrderBy ) ; 
if ( additionalOrderByProjections . size ( ) > 0 ) { 
info . orderBy = newOrderBy ; 
info . projectionAfterOrderBy = new OProjection ( - 1 ) ; 
info . projectionAfterOrderBy . setItems ( new ArrayList < > ( ) ) ; 
for ( String alias : info . projection . getAllAliases ( ) ) { 
info . projectionAfterOrderBy . getItems ( ) . add ( projectionFromAlias ( new OIdentifier ( alias ) ) ) ; 
for ( OProjectionItem item : additionalOrderByProjections ) { 
if ( info . preAggregateProjection != null ) { 
info . preAggregateProjection . getItems ( ) . add ( item ) ; 
info . aggregateProjection . getItems ( ) . add ( projectionFromAlias ( item . getAlias ( ) ) ) ; 
info . projection . getItems ( ) . add ( projectionFromAlias ( item . getAlias ( ) ) ) ; 
info . projection . getItems ( ) . add ( item ) ; 
} private static List < OProjectionItem > calculateAdditionalOrderByProjections ( Set < String > allAliases , OOrderBy orderBy ) { 
List < OProjectionItem > result = new ArrayList < > ( ) ; 
int nextAliasCount = 0 ; 
if ( orderBy != null && orderBy . getItems ( ) != null || ! orderBy . getItems ( ) . isEmpty ( ) ) { 
for ( OOrderByItem item : orderBy . getItems ( ) ) { 
if ( ! allAliases . contains ( item . getAlias ( ) ) ) { 
OProjectionItem newProj = new OProjectionItem ( - 1 ) ; 
if ( item . getAlias ( ) != null ) { 
newProj . setExpression ( new OExpression ( new OIdentifier ( item . getAlias ( ) ) , item . getModifier ( ) ) ) ; 
} else if ( item . getRecordAttr ( ) != null ) { 
ORecordAttribute attr = new ORecordAttribute ( - 1 ) ; 
attr . setName ( item . getRecordAttr ( ) ) ; 
newProj . setExpression ( new OExpression ( attr , item . getModifier ( ) ) ) ; 
} else if ( item . getRid ( ) != null ) { 
OExpression exp = new OExpression ( - 1 ) ; 
exp . setRid ( item . getRid ( ) . copy ( ) ) ; 
newProj . setExpression ( exp ) ; 
OIdentifier newAlias = new OIdentifier ( "_$$$ORDER_BY_ALIAS$$$_" + ( nextAliasCount ++ ) ) ; 
newProj . setAlias ( newAlias ) ; 
item . setAlias ( newAlias . getStringValue ( ) ) ; 
item . setModifier ( null ) ; 
result . add ( newProj ) ; 
} private static void splitProjectionsForGroupBy ( QueryPlanningInfo info , OCommandContext ctx ) { 
if ( info . projection == null ) { 
OProjection preAggregate = new OProjection ( - 1 ) ; 
preAggregate . setItems ( new ArrayList < > ( ) ) ; 
OProjection aggregate = new OProjection ( - 1 ) ; 
aggregate . setItems ( new ArrayList < > ( ) ) ; 
OProjection postAggregate = new OProjection ( - 1 ) ; 
postAggregate . setItems ( new ArrayList < > ( ) ) ; 
boolean isSplitted = false ; 
AggregateProjectionSplit result = new AggregateProjectionSplit ( ) ; 
for ( OProjectionItem item : info . projection . getItems ( ) ) { 
result . reset ( ) ; 
if ( isAggregate ( item ) ) { 
isSplitted = true ; 
OProjectionItem post = item . splitForAggregation ( result , ctx ) ; 
OIdentifier postAlias = item . getProjectionAlias ( ) ; 
postAlias = new OIdentifier ( postAlias , true ) ; 
post . setAlias ( postAlias ) ; 
postAggregate . getItems ( ) . add ( post ) ; 
aggregate . getItems ( ) . addAll ( result . getAggregate ( ) ) ; 
preAggregate . getItems ( ) . addAll ( result . getPreAggregate ( ) ) ; 
preAggregate . getItems ( ) . add ( item ) ; 
OProjectionItem aggItem = new OProjectionItem ( - 1 ) ; 
aggItem . setExpression ( new OExpression ( item . getProjectionAlias ( ) ) ) ; 
aggregate . getItems ( ) . add ( aggItem ) ; 
postAggregate . getItems ( ) . add ( aggItem ) ; 
if ( isSplitted ) { 
info . preAggregateProjection = preAggregate ; 
if ( info . preAggregateProjection . getItems ( ) == null || info . preAggregateProjection . getItems ( ) . size ( ) == 0 ) { 
info . preAggregateProjection = null ; 
info . aggregateProjection = aggregate ; 
if ( info . aggregateProjection . getItems ( ) == null || info . aggregateProjection . getItems ( ) . size ( ) == 0 ) { 
info . aggregateProjection = null ; 
info . projection = postAggregate ; 
addGroupByExpressionsToProjections ( info ) ; 
} private static void addGroupByExpressionsToProjections ( QueryPlanningInfo info ) { 
if ( info . groupBy == null || info . groupBy . getItems ( ) == null || info . groupBy . getItems ( ) . size ( ) == 0 ) { 
OGroupBy newGroupBy = new OGroupBy ( - 1 ) ; 
for ( OExpression exp : info . groupBy . getItems ( ) ) { 
if ( exp . isAggregate ( ) ) { 
boolean found = false ; 
for ( String alias : info . preAggregateProjection . getAllAliases ( ) ) { 
if ( alias . equals ( exp . getDefaultAlias ( ) . getStringValue ( ) ) && exp . isBaseIdentifier ( ) ) { 
found = true ; 
newGroupBy . getItems ( ) . add ( exp ) ; 
if ( ! found ) { 
OProjectionItem newItem = new OProjectionItem ( - 1 ) ; 
newItem . setExpression ( exp ) ; 
OIdentifier groupByAlias = new OIdentifier ( "_$$$GROUP_BY_ALIAS$$$_" + ( i ++ ) ) ; 
newItem . setAlias ( groupByAlias ) ; 
if ( info . preAggregateProjection == null ) { 
info . preAggregateProjection = new OProjection ( - 1 ) ; 
if ( info . preAggregateProjection . getItems ( ) == null ) { 
info . preAggregateProjection . setItems ( new ArrayList < > ( ) ) ; 
info . preAggregateProjection . getItems ( ) . add ( newItem ) ; 
newGroupBy . getItems ( ) . add ( new OExpression ( groupByAlias ) ) ; 
info . groupBy = newGroupBy ; 
} private static void extractSubQueries ( QueryPlanningInfo info ) { 
SubQueryCollector collector = new SubQueryCollector ( ) ; 
if ( info . perRecordLetClause != null ) { 
info . perRecordLetClause . extractSubQueries ( collector ) ; 
int j = 0 ; 
for ( Map . Entry < OIdentifier , OStatement > entry : collector . getSubQueries ( ) . entrySet ( ) ) { 
OIdentifier alias = entry . getKey ( ) ; 
OStatement query = entry . getValue ( ) ; 
if ( query . refersToParent ( ) ) { 
addRecordLevelLet ( info , alias , query , j ++ ) ; 
addGlobalLet ( info , alias , query , i ++ ) ; 
collector . reset ( ) ; 
if ( info . whereClause != null ) { 
info . whereClause . extractSubQueries ( collector ) ; 
if ( info . projection != null ) { 
info . projection . extractSubQueries ( collector ) ; 
if ( info . orderBy != null ) { 
info . orderBy . extractSubQueries ( collector ) ; 
if ( info . groupBy != null ) { 
info . groupBy . extractSubQueries ( collector ) ; 
addRecordLevelLet ( info , alias , query ) ; 
addGlobalLet ( info , alias , query ) ; 
} private boolean isFromClusters ( ORid rid , Set < String > filterClusters , ODatabase database ) { 
if ( filterClusters == null ) { 
throw new IllegalArgumentException ( ) ; 
String clusterName = database . getClusterNameById ( rid . getCluster ( ) . getValue ( ) . intValue ( ) ) ; 
return filterClusters . contains ( clusterName ) ; 
} private boolean handleClassWithIndexForSortOnly ( OSelectExecutionPlan plan , OIdentifier queryTarget , Set < String > filterClusters , 
QueryPlanningInfo info , OCommandContext ctx , boolean profilingEnabled ) { 
OSchema schema = getSchemaFromContext ( ctx ) ; 
OClass clazz = schema . getClass ( queryTarget . getStringValue ( ) ) ; 
clazz = schema . getView ( queryTarget . getStringValue ( ) ) ; 
for ( OIndex idx : clazz . getIndexes ( ) . stream ( ) . filter ( i -> i . supportsOrderedIterations ( ) ) . filter ( i -> i . getDefinition ( ) != null ) 
. collect ( Collectors . toList ( ) ) ) { 
List < String > indexFields = idx . getDefinition ( ) . getFields ( ) ; 
if ( indexFields . size ( ) < info . orderBy . getItems ( ) . size ( ) ) { 
boolean indexFound = true ; 
String orderType = null ; 
for ( int i = 0 ; i < info . orderBy . getItems ( ) . size ( ) ; i ++ ) { 
OOrderByItem orderItem = info . orderBy . getItems ( ) . get ( i ) ; 
if ( orderItem . getCollate ( ) != null ) { 
String indexField = indexFields . get ( i ) ; 
if ( i == 0 ) { 
orderType = orderItem . getType ( ) ; 
if ( orderType == null || ! orderType . equals ( orderItem . getType ( ) ) ) { 
indexFound = false ; 
if ( ! ( indexField . equals ( orderItem . getAlias ( ) ) || isInOriginalProjection ( indexField , orderItem . getAlias ( ) ) ) ) { 
if ( indexFound && orderType != null ) { 
plan . chain ( new FetchFromIndexValuesStep ( idx , orderType . equals ( OOrderByItem . ASC ) , ctx , profilingEnabled ) ) ; 
int [ ] filterClusterIds = null ; 
if ( filterClusters != null ) { 
filterClusterIds = filterClusters . stream ( ) . map ( name -> ctx . getDatabase ( ) . getClusterIdByName ( name ) ) . mapToInt ( i -> i ) 
. toArray ( ) ; 
plan . chain ( new GetValueFromIndexEntryStep ( ctx , filterClusterIds , profilingEnabled ) ) ; 
if ( info . serverToClusters . size ( ) == 1 ) { 
info . orderApplied = true ; 
} private boolean isDiamondHierarchy ( OClass clazz ) { 
Set < OClass > traversed = new HashSet < > ( ) ; 
List < OClass > stack = new ArrayList < > ( ) ; 
stack . add ( clazz ) ; 
while ( ! stack . isEmpty ( ) ) { 
OClass current = stack . remove ( 0 ) ; 
traversed . add ( current ) ; 
for ( OClass sub : current . getSubclasses ( ) ) { 
if ( traversed . contains ( sub ) ) { 
stack . add ( sub ) ; 
traversed . add ( sub ) ; 
} private Boolean getOrderDirection ( QueryPlanningInfo info ) { 
if ( info . orderBy == null ) { 
String result = null ; 
for ( OOrderByItem item : info . orderBy . getItems ( ) ) { 
if ( result == null ) { 
result = item . getType ( ) == null ? OOrderByItem . ASC : item . getType ( ) ; 
String newType = item . getType ( ) == null ? OOrderByItem . ASC : item . getType ( ) ; 
if ( ! newType . equals ( result ) ) { 
return result == null || result . equals ( OOrderByItem . ASC ) ; 
} private boolean requiresMultipleIndexLookups ( OAndBlock keyCondition ) { 
for ( OBooleanExpression oBooleanExpression : keyCondition . getSubBlocks ( ) ) { 
if ( ! ( oBooleanExpression instanceof OBinaryCondition ) ) { 
} private IndexSearchDescriptor findBestIndexFor ( OCommandContext ctx , Set < OIndex < ? > > indexes , OAndBlock block , OClass clazz ) { 
List < IndexSearchDescriptor > descriptors = indexes . stream ( ) . filter ( x -> x . getInternal ( ) . canBeUsedInEqualityOperators ( ) ) 
. map ( index -> buildIndexSearchDescriptor ( ctx , index , block , clazz ) ) . filter ( Objects :: nonNull ) 
. filter ( x -> x . keyCondition != null ) . filter ( x -> x . keyCondition . getSubBlocks ( ) . size ( ) > 0 ) . collect ( Collectors . toList ( ) ) ; 
List < IndexSearchDescriptor > fullTextIndexDescriptors = indexes . stream ( ) 
. filter ( idx -> idx . getType ( ) . equalsIgnoreCase ( "FULLTEXT" ) ) 
. filter ( idx -> ! idx . getAlgorithm ( ) . equalsIgnoreCase ( "LUCENE" ) ) 
. map ( idx -> buildIndexSearchDescriptorForFulltext ( ctx , idx , block , clazz ) ) . filter ( Objects :: nonNull ) 
descriptors . addAll ( fullTextIndexDescriptors ) ; 
descriptors = removePrefixIndexes ( descriptors ) ; 
List < OPair < Integer , IndexSearchDescriptor > > sortedDescriptors = descriptors . stream ( ) 
. map ( x -> ( OPair < Integer , IndexSearchDescriptor > ) new OPair ( x . cost ( ctx ) , x ) ) . sorted ( ) . collect ( Collectors . toList ( ) ) ; 
descriptors = sortedDescriptors . isEmpty ( ) ? 
Collections . emptyList ( ) : 
sortedDescriptors . stream ( ) . filter ( x -> x . key . equals ( sortedDescriptors . get ( 0 ) . key ) ) . map ( x -> x . value ) 
. collect ( Collectors . toList ( ) ) ; 
descriptors = descriptors . stream ( ) . sorted ( Comparator . comparingInt ( x -> x . keyCondition . getSubBlocks ( ) . size ( ) ) ) 
return descriptors . isEmpty ( ) ? null : descriptors . get ( descriptors . size ( ) - 1 ) ; 
} private List < IndexSearchDescriptor > findPrefixes ( IndexSearchDescriptor desc , List < IndexSearchDescriptor > descriptors ) { 
List < IndexSearchDescriptor > result = new ArrayList < > ( ) ; 
for ( IndexSearchDescriptor item : descriptors ) { 
if ( isPrefixOf ( item , desc ) ) { 
result . add ( item ) ; 
} private boolean isPrefixOf ( IndexSearchDescriptor item , IndexSearchDescriptor desc ) { 
List < OBooleanExpression > left = item . keyCondition . getSubBlocks ( ) ; 
List < OBooleanExpression > right = desc . keyCondition . getSubBlocks ( ) ; 
if ( left . size ( ) > right . size ( ) ) { 
for ( int i = 0 ; i < left . size ( ) ; i ++ ) { 
if ( ! left . get ( i ) . equals ( right . get ( i ) ) ) { 
} private IndexSearchDescriptor buildIndexSearchDescriptor ( OCommandContext ctx , OIndex < ? > index , OAndBlock block , OClass clazz ) { 
List < String > indexFields = index . getDefinition ( ) . getFields ( ) ; 
OBinaryCondition keyCondition = new OBinaryCondition ( - 1 ) ; 
OIdentifier key = new OIdentifier ( "key" ) ; 
keyCondition . setLeft ( new OExpression ( key ) ) ; 
boolean allowsRange = allowsRangeQueries ( index ) ; 
OAndBlock blockCopy = block . copy ( ) ; 
Iterator < OBooleanExpression > blockIterator ; 
OAndBlock indexKeyValue = new OAndBlock ( - 1 ) ; 
IndexSearchDescriptor result = new IndexSearchDescriptor ( ) ; 
result . idx = index ; 
result . keyCondition = indexKeyValue ; 
for ( String indexField : indexFields ) { 
blockIterator = blockCopy . getSubBlocks ( ) . iterator ( ) ; 
boolean breakHere = false ; 
boolean indexFieldFound = false ; 
while ( blockIterator . hasNext ( ) ) { 
OBooleanExpression singleExp = blockIterator . next ( ) ; 
if ( singleExp instanceof OBinaryCondition ) { 
OExpression left = ( ( OBinaryCondition ) singleExp ) . getLeft ( ) ; 
if ( left . isBaseIdentifier ( ) ) { 
String fieldName = left . getDefaultAlias ( ) . getStringValue ( ) ; 
if ( indexField . equals ( fieldName ) ) { 
OBinaryCompareOperator operator = ( ( OBinaryCondition ) singleExp ) . getOperator ( ) ; 
if ( ! ( ( OBinaryCondition ) singleExp ) . getRight ( ) . isEarlyCalculated ( ctx ) ) { 
if ( operator instanceof OEqualsCompareOperator ) { 
indexFieldFound = true ; 
OBinaryCondition condition = new OBinaryCondition ( - 1 ) ; 
condition . setLeft ( left ) ; 
condition . setOperator ( operator ) ; 
condition . setRight ( ( ( OBinaryCondition ) singleExp ) . getRight ( ) . copy ( ) ) ; 
indexKeyValue . getSubBlocks ( ) . add ( condition ) ; 
blockIterator . remove ( ) ; 
} else if ( operator instanceof OContainsKeyOperator && isMap ( clazz , indexField ) && isIndexByKey ( index , indexField ) ) { 
} else if ( allowsRange && operator . isRangeOperator ( ) ) { 
breakHere = true ; 
OBooleanExpression next = blockIterator . next ( ) ; 
if ( createsRangeWith ( ( OBinaryCondition ) singleExp , next ) ) { 
result . additionalRangeCondition = ( OBinaryCondition ) next ; 
} else if ( singleExp instanceof OContainsValueCondition && ( ( OContainsValueCondition ) singleExp ) . getExpression ( ) != null 
&& isMap ( clazz , indexField ) && isIndexByValue ( index , indexField ) ) { 
OExpression left = ( ( OContainsValueCondition ) singleExp ) . getLeft ( ) ; 
condition . setOperator ( new OContainsValueOperator ( - 1 ) ) ; 
condition . setRight ( ( ( OContainsValueCondition ) singleExp ) . getExpression ( ) . copy ( ) ) ; 
} else if ( singleExp instanceof OContainsAnyCondition ) { 
OExpression left = ( ( OContainsAnyCondition ) singleExp ) . getLeft ( ) ; 
if ( ! ( ( OContainsAnyCondition ) singleExp ) . getRight ( ) . isEarlyCalculated ( ctx ) ) { 
OContainsAnyCondition condition = new OContainsAnyCondition ( - 1 ) ; 
condition . setRight ( ( ( OContainsAnyCondition ) singleExp ) . getRight ( ) . copy ( ) ) ; 
} else if ( singleExp instanceof OInCondition ) { 
OExpression left = ( ( OInCondition ) singleExp ) . getLeft ( ) ; 
if ( ( ( OInCondition ) singleExp ) . getRightMathExpression ( ) != null ) { 
if ( ! ( ( OInCondition ) singleExp ) . getRightMathExpression ( ) . isEarlyCalculated ( ctx ) ) { 
OInCondition condition = new OInCondition ( - 1 ) ; 
condition . setRightMathExpression ( ( ( OInCondition ) singleExp ) . getRightMathExpression ( ) . copy ( ) ) ; 
} else if ( ( ( OInCondition ) singleExp ) . getRightParam ( ) != null ) { 
condition . setRightParam ( ( ( OInCondition ) singleExp ) . getRightParam ( ) . copy ( ) ) ; 
if ( breakHere || ! indexFieldFound ) { 
if ( result . keyCondition . getSubBlocks ( ) . size ( ) < index . getDefinition ( ) . getFields ( ) . size ( ) && ! index 
. supportsOrderedIterations ( ) ) { 
if ( found ) { 
result . remainingCondition = blockCopy ; 
} private IndexSearchDescriptor buildIndexSearchDescriptorForFulltext ( OCommandContext ctx , OIndex < ? > index , OAndBlock block , OClass clazz ) { 
if ( singleExp instanceof OContainsTextCondition ) { 
OExpression left = ( ( OContainsTextCondition ) singleExp ) . getLeft ( ) ; 
OContainsTextCondition condition = new OContainsTextCondition ( - 1 ) ; 
condition . setRight ( ( ( OContainsTextCondition ) singleExp ) . getRight ( ) . copy ( ) ) ; 
} private List < IndexSearchDescriptor > commonFactor ( List < IndexSearchDescriptor > indexSearchDescriptors ) { 
Map < OIndex , Map < IndexCondPair , OOrBlock > > aggregation = new HashMap < > ( ) ; 
for ( IndexSearchDescriptor item : indexSearchDescriptors ) { 
Map < IndexCondPair , OOrBlock > filtersForIndex = aggregation . get ( item . idx ) ; 
if ( filtersForIndex == null ) { 
filtersForIndex = new HashMap < > ( ) ; 
aggregation . put ( item . idx , filtersForIndex ) ; 
IndexCondPair extendedCond = new IndexCondPair ( item . keyCondition , item . additionalRangeCondition ) ; 
OOrBlock existingAdditionalConditions = filtersForIndex . get ( extendedCond ) ; 
if ( existingAdditionalConditions == null ) { 
existingAdditionalConditions = new OOrBlock ( - 1 ) ; 
filtersForIndex . put ( extendedCond , existingAdditionalConditions ) ; 
existingAdditionalConditions . getSubBlocks ( ) . add ( item . remainingCondition ) ; 
for ( Map . Entry < OIndex , Map < IndexCondPair , OOrBlock > > item : aggregation . entrySet ( ) ) { 
for ( Map . Entry < IndexCondPair , OOrBlock > filters : item . getValue ( ) . entrySet ( ) ) { 
result . add ( new IndexSearchDescriptor ( item . getKey ( ) , filters . getKey ( ) . mainCondition , filters . getKey ( ) . additionalRange , 
filters . getValue ( ) ) ) ; 
} public ODocumentFieldHandlingStrategy create ( int strategy ) { 
Optional < ODocumentFieldHandlingStrategy > registered = ODocumentFieldHandlingStrategyRegistry . getInstance ( ) 
. getStrategy ( strategy ) ; 
if ( registered . isPresent ( ) ) { 
return registered . get ( ) ; 
Map < OType , ODocumentFieldOTypeHandlingStrategy > typeHandlingStrategies = new HashMap < OType , ODocumentFieldOTypeHandlingStrategy > ( ) ; 
case SINGLE_ORECORD_BYTES : 
typeHandlingStrategies . put ( OType . BINARY , new ODocumentSingleRecordBytesOTypeHandlingStrategy ( ) ) ; 
case SPLIT_ORECORD_BYTES : 
typeHandlingStrategies . put ( OType . BINARY , new ODocumentSplitRecordBytesOTypeHandlingStrategy ( ) ) ; 
case SIMPLE : 
ODocumentSmartFieldHandlingStrategy strategyInstance = new ODocumentSmartFieldHandlingStrategy ( typeHandlingStrategies ) ; 
ODocumentFieldHandlingStrategyRegistry . getInstance ( ) . registerStrategy ( strategy , strategyInstance ) ; 
return strategyInstance ; 
} public Object fromStream ( final String iStream ) { 
if ( iStream == null || iStream . length ( ) == 0 ) 
OSerializableStream instance = null ; 
int propertyPos = iStream . indexOf ( ':' ) ; 
int pos = iStream . indexOf ( OStringSerializerEmbedded . SEPARATOR ) ; 
if ( pos < 0 || propertyPos > - 1 && pos > propertyPos ) { 
instance = new ODocument ( ) ; 
pos = - 1 ; 
final String className = iStream . substring ( 0 , pos ) ; 
final Class < ? > clazz = Class . forName ( className ) ; 
instance = ( OSerializableStream ) clazz . newInstance ( ) ; 
OLogManager . instance ( ) . error ( this , message , e ) ; 
throw OException . wrapException ( new OSerializationException ( message ) , e ) ; 
instance . fromStream ( Base64 . getDecoder ( ) . decode ( iStream . substring ( pos + 1 ) ) ) ; 
return instance ; 
} public StringBuilder toStream ( final StringBuilder iOutput , Object iValue ) { 
if ( iValue != null ) { 
if ( ! ( iValue instanceof OSerializableStream ) ) 
OSerializableStream stream = ( OSerializableStream ) iValue ; 
iOutput . append ( iValue . getClass ( ) . getName ( ) ) ; 
iOutput . append ( OStringSerializerEmbedded . SEPARATOR ) ; 
iOutput . append ( Base64 . getEncoder ( ) . encodeToString ( stream . toStream ( ) ) ) ; 
return iOutput ; 
runtimeParameters [ i ] = ( ( OSQLFilterItemField ) configuredParameters [ i ] ) . getValue ( iCurrentRecord , iCurrentResult , iContext ) ; 
} else if ( configuredParameters [ i ] instanceof OSQLFunctionRuntime ) 
runtimeParameters [ i ] = ( ( OSQLFunctionRuntime ) configuredParameters [ i ] ) . execute ( iThis , iCurrentRecord , iCurrentResult , 
runtimeParameters [ i ] = ( ( OSQLFilterItemVariable ) configuredParameters [ i ] ) 
. getValue ( iCurrentRecord , iCurrentResult , iContext ) ; 
if ( function . getMaxParams ( ) == - 1 || function . getMaxParams ( ) > 0 ) { 
if ( runtimeParameters . length < function . getMinParams ( ) 
|| ( function . getMaxParams ( ) > - 1 && runtimeParameters . length > function . getMaxParams ( ) ) ) 
+ function . getName ( ) 
+ ( function . getMinParams ( ) == function . getMaxParams ( ) ? function . getMinParams ( ) : function . getMinParams ( ) + "-" 
final Object functionResult = function . execute ( iThis , iCurrentRecord , iCurrentResult , runtimeParameters , iContext ) ; 
if ( functionResult instanceof OAutoConvertToRecord ) 
( ( OAutoConvertToRecord ) functionResult ) . setAutoConvertToRecord ( false ) ; 
} public ORole allow ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { 
if ( roles == null || roles . isEmpty ( ) ) { 
if ( document . field ( "roles" ) != null && ! ( ( Collection < OIdentifiable > ) document . field ( "roles" ) ) . isEmpty ( ) ) { 
final ODocument doc = document ; 
document = null ; 
fromStream ( doc ) ; 
throw new OSecurityAccessException ( document . getDatabase ( ) . getName ( ) , 
final ORole role = checkIfAllowed ( resourceGeneric , resourceSpecific , iOperation ) ; 
} public boolean isRuleDefined ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific ) { 
for ( ORole r : roles ) 
if ( r == null ) 
else if ( r . hasRule ( resourceGeneric , resourceSpecific ) ) 
} public static String getCompactServerStatus ( final ODistributedServerManager manager , final ODocument distribCfg ) { 
final StringBuilder buffer = new StringBuilder ( ) ; 
final Collection < ODocument > members = distribCfg . field ( "members" ) ; 
if ( members != null ) { 
buffer . append ( members . size ( ) ) ; 
buffer . append ( ":[" ) ; 
int memberCount = 0 ; 
for ( ODocument m : members ) { 
if ( m == null ) 
if ( memberCount ++ > 0 ) 
buffer . append ( "," ) ; 
final String serverName = m . field ( "name" ) ; 
buffer . append ( serverName ) ; 
buffer . append ( ( Object ) m . field ( "status" ) ) ; 
final Collection < String > databases = m . field ( "databases" ) ; 
if ( databases != null ) { 
buffer . append ( "{" ) ; 
int dbCount = 0 ; 
for ( String dbName : databases ) { 
final ODistributedConfiguration dbCfg = manager . getDatabaseConfiguration ( dbName , false ) ; 
if ( dbCfg == null ) 
if ( dbCount ++ > 0 ) 
buffer . append ( dbName ) ; 
buffer . append ( "=" ) ; 
buffer . append ( manager . getDatabaseStatus ( serverName , dbName ) ) ; 
buffer . append ( dbCfg . getServerRole ( serverName ) ) ; 
buffer . append ( ")" ) ; 
buffer . append ( "}" ) ; 
buffer . append ( "]" ) ; 
return buffer . toString ( ) ; 
} protected void initSystemDatabase ( ) { 
final ODocument defaultCfg = getStorage ( OSystemDatabase . SYSTEM_DB_NAME ) 
. loadDatabaseConfiguration ( getDefaultDatabaseConfigFile ( ) ) ; 
defaultCfg . field ( "autoDeploy" , false ) ; 
final OModifiableDistributedConfiguration sysCfg = new OModifiableDistributedConfiguration ( defaultCfg ) ; 
sysCfg . removeServer ( "<NEW_NODE>" ) ; 
messageService . registerDatabase ( OSystemDatabase . SYSTEM_DB_NAME , sysCfg ) ; 
sysCfg . addNewNodeInServerList ( getLocalNodeName ( ) ) ; 
} protected void loadLocalDatabases ( ) { 
final List < String > dbs = new ArrayList < String > ( serverInstance . getAvailableStorageNames ( ) . keySet ( ) ) ; 
Collections . sort ( dbs ) ; 
for ( final String databaseName : dbs ) { 
if ( messageService . getDatabase ( databaseName ) == null ) { 
final ODistributedStorage stg = getStorage ( databaseName ) ; 
executeInDistributedDatabaseLock ( databaseName , 60000 , null , new OCallable < Object , OModifiableDistributedConfiguration > ( ) { 
public Object call ( OModifiableDistributedConfiguration cfg ) { 
cfg . getServerRole ( nodeName ) , databaseName ) ; 
final ODistributedDatabaseImpl ddb = messageService . registerDatabase ( databaseName , cfg ) ; 
ddb . resume ( ) ; 
cfg . addNewNodeInServerList ( nodeName ) ; 
reassignClustersOwnership ( nodeName , databaseName , cfg , true ) ; 
ddb . getSyncConfiguration ( ) . setLastLSN ( nodeName , ( ( OAbstractPaginatedStorage ) stg . getUnderlying ( ) ) . getLSN ( ) , false ) ; 
ODistributedServerLog 
databaseName , e . getMessage ( ) ) ; 
ddb . setOnline ( ) ; 
public void memberRemoved ( final MembershipEvent iEvent ) { 
updateLastClusterChange ( ) ; 
if ( iEvent . getMember ( ) == null ) 
final String nodeLeftName = getNodeName ( iEvent . getMember ( ) ) ; 
if ( nodeLeftName == null ) 
removeServer ( nodeLeftName , true ) ; 
} catch ( HazelcastInstanceNotActiveException | RetryableHazelcastException e ) { 
public String electNewLockManager ( ) { 
if ( hazelcastInstance == null ) 
throw new HazelcastInstanceNotActiveException ( ) ; 
final ILock lock = hazelcastInstance . getLock ( "orientdb.lockManagerElection" ) ; 
String lockManagerServer = getLockManagerRequester ( ) . getServer ( ) ; 
if ( lockManagerServer != null && getActiveServers ( ) . contains ( lockManagerServer ) ) 
return lockManagerServer ; 
final String originalLockManager = lockManagerServer ; 
originalLockManager ) ; 
int lockManagerServerId = - 1 ; 
if ( lockManagerServer != null && registeredNodeByName . containsKey ( lockManagerServer ) ) 
lockManagerServerId = registeredNodeByName . get ( lockManagerServer ) ; 
String newServer = null ; 
int currIndex = lockManagerServerId ; 
for ( int i = 0 ; i < registeredNodeById . size ( ) ; ++ i ) { 
currIndex ++ ; 
if ( currIndex >= registeredNodeById . size ( ) ) 
currIndex = 0 ; 
newServer = registeredNodeById . get ( currIndex ) ; 
if ( newServer == null ) 
if ( newServer . equalsIgnoreCase ( getLocalNodeName ( ) ) || activeNodes . containsKey ( newServer ) ) { 
getLockManagerRequester ( ) . setServer ( newServer ) ; 
configurationMap . put ( CONFIG_LOCKMANAGER , getLockManagerRequester ( ) . getServer ( ) ) ; 
e ) ; 
return newServer ; 
} private void assignLockManagerFromCluster ( ) { 
String lockManagerServer = null ; 
while ( lockManagerServer == null ) { 
if ( activeNodes . size ( ) == 1 ) { 
lockManagerServer = nodeName ; 
if ( configurationMap . putIfAbsent ( CONFIG_LOCKMANAGER , lockManagerServer ) == null ) 
lockManagerServer = ( String ) configurationMap . get ( CONFIG_LOCKMANAGER ) ; 
if ( lockManagerServer != null && lockManagerServer . equals ( nodeName ) ) { 
getLockManagerRequester ( ) . setServer ( lockManagerServer ) ; 
lockManagerServer = electNewLockManager ( ) ; 
if ( lockManagerServer != null ) 
Thread . sleep ( 100 ) ; 
public void serializeInByteBufferObject ( Double object , ByteBuffer buffer , Object ... hints ) { 
buffer . putLong ( Double . doubleToLongBits ( object ) ) ; 
public Double deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return Double . longBitsToDouble ( walChanges . getLongValue ( buffer , offset ) ) ; 
public void serializeInByteBufferObject ( OIdentifiable object , ByteBuffer buffer , Object ... hints ) { 
OLinkSerializer . INSTANCE . serializeInByteBufferObject ( object , buffer ) ; 
public OIdentifiable deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return OLinkSerializer . INSTANCE . deserializeFromByteBufferObject ( buffer , walChanges , offset ) ; 
return OLinkSerializer . INSTANCE . getObjectSizeInByteBuffer ( buffer , walChanges , offset ) ; 
} public void commit ( ) { 
if ( ! active ) 
if ( level < 1 ) 
-- level ; 
if ( level == 0 ) { 
active = false ; 
doCommit ( ) ; 
} public void rollback ( ) { 
doRollback ( ) ; 
} public void updateIdentityAfterRecordCommit ( final ORID oldRid , final ORID newRid ) { 
if ( oldRid . equals ( newRid ) ) 
final List < KeyChangesUpdateRecord > keyRecordsToReinsert = new ArrayList < > ( ) ; 
final OIndexManager indexManager = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) ; 
for ( Map . Entry < String , OTransactionIndexChanges > entry : indexOperations . entrySet ( ) ) { 
final OIndex < ? > index = indexManager . getIndex ( entry . getKey ( ) ) ; 
if ( index == null ) 
final Dependency [ ] fieldRidDependencies = getIndexFieldRidDependencies ( index ) ; 
if ( ! isIndexMayDependOnRids ( fieldRidDependencies ) ) 
final OTransactionIndexChanges indexChanges = entry . getValue ( ) ; 
for ( final Iterator < OTransactionIndexChangesPerKey > iterator = indexChanges . changesPerKey . values ( ) . iterator ( ) ; iterator 
. hasNext ( ) ; ) { 
final OTransactionIndexChangesPerKey keyChanges = iterator . next ( ) ; 
if ( isIndexKeyMayDependOnRid ( keyChanges . key , oldRid , fieldRidDependencies ) ) { 
keyRecordsToReinsert . add ( new KeyChangesUpdateRecord ( keyChanges , indexChanges ) ) ; 
final ORecordOperation rec = resolveRecordOperation ( oldRid ) ; 
if ( rec != null ) { 
updatedRids . put ( newRid . copy ( ) , oldRid . copy ( ) ) ; 
if ( ! rec . getRecord ( ) . getIdentity ( ) . equals ( newRid ) ) { 
ORecordInternal . onBeforeIdentityChanged ( rec . getRecord ( ) ) ; 
final ORecordId recordId = ( ORecordId ) rec . getRecord ( ) . getIdentity ( ) ; 
if ( recordId == null ) { 
ORecordInternal . setIdentity ( rec . getRecord ( ) , new ORecordId ( newRid ) ) ; 
recordId . setClusterPosition ( newRid . getClusterPosition ( ) ) ; 
recordId . setClusterId ( newRid . getClusterId ( ) ) ; 
ORecordInternal . onAfterIdentityChanged ( rec . getRecord ( ) ) ; 
for ( KeyChangesUpdateRecord record : keyRecordsToReinsert ) 
record . indexChanges . changesPerKey . put ( record . keyChanges . key , record . keyChanges ) ; 
final List < OTransactionRecordIndexOperation > transactionIndexOperations = recordIndexOperations . get ( translateRid ( oldRid ) ) ; 
if ( transactionIndexOperations != null ) { 
for ( final OTransactionRecordIndexOperation indexOperation : transactionIndexOperations ) { 
OTransactionIndexChanges indexEntryChanges = indexOperations . get ( indexOperation . index ) ; 
if ( indexEntryChanges == null ) 
final OTransactionIndexChangesPerKey keyChanges ; 
if ( indexOperation . key == null ) { 
keyChanges = indexEntryChanges . nullKeyChanges ; 
keyChanges = indexEntryChanges . changesPerKey . get ( indexOperation . key ) ; 
if ( keyChanges != null ) 
updateChangesIdentity ( oldRid , newRid , keyChanges ) ; 
} public void updateRecordCacheAfterRollback ( ) { 
final OLocalRecordCache databaseLocalCache = database . getLocalCache ( ) ; 
for ( ORecordOperation recordOperation : recordOperations . values ( ) ) 
databaseLocalCache . deleteRecord ( recordOperation . getRecord ( ) . getIdentity ( ) ) ; 
} public static void prepareForFileCreationOrReplacement ( Path path , Object requester , String operation ) throws IOException { 
if ( Files . deleteIfExists ( path ) ) 
final Path parent = path . getParent ( ) ; 
if ( parent != null ) 
Files . createDirectories ( parent ) ; 
} public static void atomicMoveWithFallback ( Path source , Path target , Object requester ) throws IOException { 
Files . move ( source , target , StandardCopyOption . ATOMIC_MOVE ) ; 
} catch ( AtomicMoveNotSupportedException ignore ) { 
Files . move ( source , target ) ; 
} public List < Pattern > getDisjointPatterns ( ) { 
Map < PatternNode , String > reverseMap = new IdentityHashMap < > ( ) ; 
reverseMap . putAll ( this . aliasToNode . entrySet ( ) . stream ( ) . collect ( Collectors . toMap ( x -> x . getValue ( ) , x -> x . getKey ( ) ) ) ) ; 
List < Pattern > result = new ArrayList < > ( ) ; 
while ( ! reverseMap . isEmpty ( ) ) { 
Pattern pattern = new Pattern ( ) ; 
result . add ( pattern ) ; 
Map . Entry < PatternNode , String > nextNode = reverseMap . entrySet ( ) . iterator ( ) . next ( ) ; 
Set < PatternNode > toVisit = new HashSet < > ( ) ; 
toVisit . add ( nextNode . getKey ( ) ) ; 
while ( toVisit . size ( ) > 0 ) { 
PatternNode currentNode = toVisit . iterator ( ) . next ( ) ; 
toVisit . remove ( currentNode ) ; 
if ( reverseMap . containsKey ( currentNode ) ) { 
pattern . aliasToNode . put ( reverseMap . get ( currentNode ) , currentNode ) ; 
reverseMap . remove ( currentNode ) ; 
for ( PatternEdge x : currentNode . out ) { 
toVisit . add ( x . in ) ; 
for ( PatternEdge x : currentNode . in ) { 
toVisit . add ( x . out ) ; 
pattern . recalculateNumOfEdges ( ) ; 
} protected boolean executeOnlyLocally ( final String localNodeName , final ODistributedConfiguration dbCfg , 
final OCommandExecutor exec , final Collection < String > involvedClusters , final Collection < String > nodes ) { 
boolean executeLocally = false ; 
if ( exec . isIdempotent ( ) ) { 
final int availableNodes = nodes . size ( ) ; 
int maxReadQuorum ; 
if ( involvedClusters . isEmpty ( ) ) 
maxReadQuorum = dbCfg . getReadQuorum ( null , availableNodes , localNodeName ) ; 
maxReadQuorum = 0 ; 
for ( String cl : involvedClusters ) 
maxReadQuorum = Math . max ( maxReadQuorum , dbCfg . getReadQuorum ( cl , availableNodes , localNodeName ) ) ; 
if ( nodes . contains ( localNodeName ) && maxReadQuorum <= 1 ) 
executeLocally = true ; 
return executeLocally ; 
public boolean isLocalEnv ( ) { 
return localDistributedDatabase == null || dManager == null || distributedConfiguration == null || OScenarioThreadLocal . INSTANCE 
. isRunModeDistributed ( ) ; 
public OStorageOperationResult < ORawBuffer > readRecord ( final ORecordId iRecordId , final String iFetchPlan , 
final boolean iIgnoreCache , final boolean prefetchRecords , final ORecordCallback < ORawBuffer > iCallback ) { 
if ( isLocalEnv ( ) ) { 
return wrapped . readRecord ( iRecordId , iFetchPlan , iIgnoreCache , prefetchRecords , iCallback ) ; 
final ORawBuffer memCopy = localDistributedDatabase . getRecordIfLocked ( iRecordId ) ; 
if ( memCopy != null ) 
return new OStorageOperationResult < ORawBuffer > ( memCopy ) ; 
final String clusterName = getClusterNameByRID ( iRecordId ) ; 
final ODistributedConfiguration dbCfg = distributedConfiguration ; 
final List < String > nodes = dbCfg . getServers ( clusterName , null ) ; 
final String localNodeName = dManager . getLocalNodeName ( ) ; 
if ( nodes . isEmpty ( ) 
|| nodes . contains ( dManager . getLocalNodeName ( ) ) && dbCfg . getReadQuorum ( clusterName , availableNodes , localNodeName ) <= 1 ) { 
return ( OStorageOperationResult < ORawBuffer > ) OScenarioThreadLocal . executeAsDistributed ( new Callable ( ) { 
public Object call ( ) throws Exception { 
final OReadRecordTask task = ( ( OReadRecordTask ) dManager . getTaskFactoryManager ( ) . getFactoryByServerNames ( nodes ) 
. createTask ( OReadRecordTask . FACTORYID ) ) . init ( iRecordId ) ; 
final ODistributedResponse response = dManager 
. sendRequest ( getName ( ) , Collections . singleton ( clusterName ) , nodes , task , dManager . getNextMessageIdCounter ( ) , 
EXECUTION_MODE . RESPONSE , null , null , null ) ; 
final Object dResult = response != null ? response . getPayload ( ) : null ; 
if ( dResult instanceof ONeedRetryException ) 
throw ( ONeedRetryException ) dResult ; 
else if ( dResult instanceof Exception ) 
throw OException 
return new OStorageOperationResult < ORawBuffer > ( ( ORawBuffer ) dResult ) ; 
} catch ( ONeedRetryException e ) { 
public OStorageOperationResult < ORawBuffer > readRecordIfVersionIsNotLatest ( final ORecordId rid , final String fetchPlan , 
final boolean ignoreCache , final int recordVersion ) throws ORecordNotFoundException { 
return wrapped . readRecordIfVersionIsNotLatest ( rid , fetchPlan , ignoreCache , recordVersion ) ; 
final ORawBuffer memCopy = localDistributedDatabase . getRecordIfLocked ( rid ) ; 
final String clusterName = getClusterNameByRID ( rid ) ; 
final OReadRecordIfNotLatestTask task = ( OReadRecordIfNotLatestTask ) dManager . getTaskFactoryManager ( ) 
. getFactoryByServerNames ( nodes ) . createTask ( OReadRecordIfNotLatestTask . FACTORYID ) ; 
task . init ( rid , recordVersion ) ; 
final Object result = dManager 
EXECUTION_MODE . RESPONSE , null , null , null ) . getPayload ( ) ; 
if ( result instanceof ONeedRetryException ) 
throw ( ONeedRetryException ) result ; 
else if ( result instanceof Exception ) 
return new OStorageOperationResult < ORawBuffer > ( ( ORawBuffer ) result ) ; 
public OStorageOperationResult < Boolean > deleteRecord ( final ORecordId iRecordId , final int iVersion , final int iMode , 
final ORecordCallback < Boolean > iCallback ) { 
return wrapped . deleteRecord ( iRecordId , iVersion , iMode , iCallback ) ; 
public void characters ( char [ ] ch , int start , int length ) throws SAXException { 
builder . append ( ch , start , length ) ; 
} public static Date stringToDate ( String dateString ) throws ParseException { 
SimpleDateFormat format = RESOLUTIONS [ dateString . length ( ) ] . format ( ) ; 
return format . parse ( dateString ) ; 
} public boolean isConnected ( ) { 
final Socket s = socket ; 
return s != null && ! s . isClosed ( ) && s . isConnected ( ) && ! s . isInputShutdown ( ) && ! s . isOutputShutdown ( ) ; 
if ( name . isEmpty ( ) ) 
if ( code == null || code . isEmpty ( ) ) 
ODatabaseDocument database = getDatabase ( ) ; 
final OFunction f = database . getMetadata ( ) . getFunctionLibrary ( ) . createFunction ( name ) ; 
f . setCode ( code ) ; 
f . setIdempotent ( idempotent ) ; 
if ( parameters != null ) 
f . setParameters ( parameters ) ; 
if ( language != null ) 
f . setLanguage ( language ) ; 
f . save ( ) ; 
return f . getId ( ) ; 
} public static short mergeShortFromBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 ) { 
short result = 0 ; 
result = ( short ) ( result | ( buffer . get ( ) & MASK ) ) ; 
result = ( short ) ( result << SIZE_OF_BYTE_IN_BITS ) ; 
result = ( short ) ( result | ( buffer1 . get ( ) & MASK ) ) ; 
} public static int mergeIntFromBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 ) { 
final int remaining = buffer . remaining ( ) ; 
for ( int i = 0 ; i < remaining ; ++ i ) { 
result = result | ( buffer . get ( ) & MASK ) ; 
result = result << SIZE_OF_BYTE_IN_BITS ; 
for ( int i = 0 ; i < SIZE_OF_INT - remaining - 1 ; ++ i ) { 
result = result | ( buffer1 . get ( ) & MASK ) ; 
} public static long mergeLongFromBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 ) { 
long result = 0 ; 
result = result | ( MASK & buffer . get ( ) ) ; 
for ( int i = 0 ; i < SIZE_OF_LONG - remaining - 1 ; ++ i ) { 
result = result | ( MASK & buffer1 . get ( ) ) ; 
} public static void splitShortToBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 , final short iValue ) { 
buffer . put ( ( byte ) ( MASK & ( iValue > > > SIZE_OF_BYTE_IN_BITS ) ) ) ; 
buffer1 . put ( ( byte ) ( MASK & iValue ) ) ; 
} public static void splitIntToBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 , final int iValue ) { 
int i ; 
for ( i = 0 ; i < remaining ; ++ i ) { 
buffer . put ( ( byte ) ( MASK & ( iValue > > > SIZE_OF_BYTE_IN_BITS * ( SIZE_OF_INT - i - 1 ) ) ) ) ; 
for ( int j = 0 ; j < SIZE_OF_INT - remaining ; ++ j ) { 
buffer1 . put ( ( byte ) ( MASK & ( iValue > > > SIZE_OF_BYTE_IN_BITS * ( SIZE_OF_INT - i - j - 1 ) ) ) ) ; 
} public static void splitLongToBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 , final long iValue ) { 
buffer . put ( ( byte ) ( iValue > > SIZE_OF_BYTE_IN_BITS * ( SIZE_OF_LONG - i - 1 ) ) ) ; 
for ( int j = 0 ; j < SIZE_OF_LONG - remaining ; ++ j ) { 
buffer1 . put ( ( byte ) ( iValue > > SIZE_OF_BYTE_IN_BITS * ( SIZE_OF_LONG - i - j - 1 ) ) ) ; 
if ( type == null ) 
final ODatabaseDocument database = getDatabase ( ) ; 
final OClassEmbedded sourceClass = ( OClassEmbedded ) database . getMetadata ( ) . getSchema ( ) . getClass ( className ) ; 
if ( sourceClass == null ) 
OPropertyImpl prop = ( OPropertyImpl ) sourceClass . getProperty ( fieldName ) ; 
if ( prop != null ) { 
if ( ifNotExists ) { 
return sourceClass . properties ( ) . size ( ) ; 
OClass linkedClass = null ; 
OType linkedType = null ; 
if ( linked != null ) { 
linkedClass = database . getMetadata ( ) . getSchema ( ) . getClass ( linked ) ; 
if ( linkedClass == null ) 
linkedType = OType . valueOf ( linked . toUpperCase ( Locale . ENGLISH ) ) ; 
OPropertyImpl internalProp = sourceClass . addPropertyInternal ( fieldName , type , linkedType , linkedClass , unsafe ) ; 
if ( readonly ) { 
internalProp . setReadonly ( true ) ; 
if ( mandatory ) { 
internalProp . setMandatory ( true ) ; 
if ( notnull ) { 
internalProp . setNotNull ( true ) ; 
if ( max != null ) { 
internalProp . setMax ( max ) ; 
if ( min != null ) { 
internalProp . setMin ( min ) ; 
if ( defaultValue != null ) { 
internalProp . setDefaultValue ( defaultValue ) ; 
if ( attribute == null ) 
final List < OCluster > clusters = getClusters ( ) ; 
if ( clusters . isEmpty ( ) ) 
Object result = null ; 
for ( OCluster cluster : getClusters ( ) ) { 
if ( clusterId > - 1 && clusterName . equals ( String . valueOf ( clusterId ) ) ) { 
clusterName = cluster . getName ( ) ; 
clusterId = cluster . getId ( ) ; 
if ( attribute == ATTRIBUTES . STATUS && OStorageClusterConfiguration . STATUS . OFFLINE . toString ( ) . equalsIgnoreCase ( value ) ) 
getDatabase ( ) . getMetadata ( ) . getCommandCache ( ) . invalidateResultsOfCluster ( clusterName ) ; 
if ( attribute == ATTRIBUTES . NAME ) 
result = cluster . set ( attribute , value ) ; 
public OIndexFullText put ( Object key , final OIdentifiable singleValue ) { 
if ( key == null ) { 
key = getCollatingValue ( key ) ; 
final Set < String > words = splitIntoWords ( key . toString ( ) ) ; 
for ( final String word : words ) { 
acquireSharedLock ( ) ; 
if ( apiVersion == 0 ) { 
doPutV0 ( singleValue , word ) ; 
} else if ( apiVersion == 1 ) { 
doPutV1 ( singleValue , word ) ; 
releaseSharedLock ( ) ; 
public boolean remove ( Object key , final OIdentifiable value ) { 
final OModifiableBoolean removed = new OModifiableBoolean ( false ) ; 
removeV0 ( value , removed , word ) ; 
removeV1 ( value , removed , word ) ; 
return removed . getValue ( ) ; 
public List < T > run ( final Object ... iArgs ) { 
final ODatabaseDocumentInternal database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; 
if ( database == null ) 
( ( OMetadataInternal ) database . getMetadata ( ) ) . makeThreadLocalSchemaSnapshot ( ) ; 
setParameters ( iArgs ) ; 
Object o = database . getStorage ( ) . command ( this ) ; 
if ( o instanceof List ) { 
return ( List < T > ) o ; 
return ( List < T > ) Collections . singletonList ( o ) ; 
( ( OMetadataInternal ) database . getMetadata ( ) ) . clearThreadLocalSchemaSnapshot ( ) ; 
} public T runFirst ( final Object ... iArgs ) { 
setLimit ( 1 ) ; 
final List < T > result = execute ( iArgs ) ; 
return result != null && ! result . isEmpty ( ) ? result . get ( 0 ) : null ; 
} public OSBTreeValue < V > getValue ( int entryIndex ) { 
assert isLeaf ; 
int entryPosition = getIntValue ( entryIndex * OIntegerSerializer . INT_SIZE + positionsArrayOffset ) ; 
if ( encryption == null ) { 
entryPosition += getObjectSizeInDirectMemory ( keySerializer , entryPosition ) ; 
final int encryptedSize = getIntValue ( entryPosition ) ; 
entryPosition += OIntegerSerializer . INT_SIZE + encryptedSize ; 
boolean isLinkValue = getByteValue ( entryPosition ) > 0 ; 
long link = - 1 ; 
V value = null ; 
if ( isLinkValue ) 
link = deserializeFromDirectMemory ( OLongSerializer . INSTANCE , entryPosition + OByteSerializer . BYTE_SIZE ) ; 
value = deserializeFromDirectMemory ( valueSerializer , entryPosition + OByteSerializer . BYTE_SIZE ) ; 
return new OSBTreeValue < > ( link >= 0 , link , value ) ; 
} public void shrink ( final long size ) throws IOException { 
int attempts = 0 ; 
acquireWriteLock ( ) ; 
channel . truncate ( HEADER_SIZE + size ) ; 
this . size = size ; 
assert this . size >= 0 ; 
releaseWriteLock ( ) ; 
attempts ++ ; 
} catch ( final IOException e ) { 
reopenFile ( attempts , e ) ; 
} public void create ( ) throws IOException { 
acquireExclusiveAccess ( ) ; 
openChannel ( ) ; 
init ( ) ; 
setVersion ( OFileClassic . CURRENT_VERSION ) ; 
version = OFileClassic . CURRENT_VERSION ; 
initAllocationMode ( ) ; 
} private long checkRegions ( final long iOffset , final long iLength ) { 
acquireReadLock ( ) ; 
if ( iOffset < 0 || iOffset + iLength > size ) { 
throw new OIOException ( 
return iOffset + HEADER_SIZE ; 
releaseReadLock ( ) ; 
} public void open ( ) { 
if ( ! Files . exists ( osFile ) ) { 
if ( version < CURRENT_VERSION ) { 
setVersion ( CURRENT_VERSION ) ; 
version = CURRENT_VERSION ; 
if ( channel != null && channel . isOpen ( ) ) { 
channel . close ( ) ; 
channel = null ; 
if ( frnd != null ) { 
frnd . close ( ) ; 
frnd = null ; 
closeFD ( ) ; 
releaseExclusiveAccess ( ) ; 
} catch ( final IOException ioe ) { 
reopenFile ( attempts , ioe ) ; 
} public void delete ( ) throws IOException { 
close ( ) ; 
if ( osFile != null ) { 
Files . deleteIfExists ( osFile ) ; 
} public void replaceContentWith ( final Path newContentFile ) throws IOException { 
Files . copy ( newContentFile , osFile , StandardCopyOption . REPLACE_EXISTING ) ; 
open ( ) ; 
} public Object command ( final OCommandRequestText iCommand ) { 
final boolean live = iCommand instanceof OLiveQuery ; 
final boolean asynch = iCommand instanceof OCommandRequestAsynch && ( ( OCommandRequestAsynch ) iCommand ) . isAsynchronous ( ) ; 
OCommandRequest request = new OCommandRequest ( database , asynch , iCommand , live ) ; 
return response . getResult ( ) ; 
} public void endRequest ( final OChannelBinaryAsynchClient iNetwork ) throws IOException { 
if ( iNetwork == null ) 
iNetwork . flush ( ) ; 
iNetwork . releaseWriteLock ( ) ; 
} protected void parseServerURLs ( ) { 
String lastHost = null ; 
int dbPos = url . indexOf ( '/' ) ; 
if ( dbPos == - 1 ) { 
addHost ( url ) ; 
lastHost = url ; 
name = url ; 
name = url . substring ( url . lastIndexOf ( "/" ) + 1 ) ; 
for ( String host : url . substring ( 0 , dbPos ) . split ( ADDRESS_SEPARATOR ) ) { 
lastHost = host ; 
addHost ( host ) ; 
synchronized ( serverURLs ) { 
if ( serverURLs . size ( ) == 1 && getClientConfiguration ( ) 
. getValueAsBoolean ( OGlobalConfiguration . NETWORK_BINARY_DNS_LOADBALANCING_ENABLED ) ) { 
final String primaryServer = lastHost ; 
getClientConfiguration ( ) . getValueAsInteger ( OGlobalConfiguration . NETWORK_BINARY_DNS_LOADBALANCING_TIMEOUT ) ) ; 
final Hashtable < String , String > env = new Hashtable < String , String > ( ) ; 
env . put ( "java.naming.factory.initial" , "com.sun.jndi.dns.DnsContextFactory" ) ; 
env . put ( "com.sun.jndi.ldap.connect.timeout" , 
getClientConfiguration ( ) . getValueAsString ( OGlobalConfiguration . NETWORK_BINARY_DNS_LOADBALANCING_TIMEOUT ) ) ; 
final DirContext ictx = new InitialDirContext ( env ) ; 
final String hostName = ! primaryServer . contains ( ":" ) ? 
primaryServer : 
primaryServer . substring ( 0 , primaryServer . indexOf ( ":" ) ) ; 
final Attributes attrs = ictx . getAttributes ( hostName , new String [ ] { "TXT" } ) ; 
final Attribute attr = attrs . get ( "TXT" ) ; 
if ( attr != null ) { 
for ( int i = 0 ; i < attr . size ( ) ; ++ i ) { 
String configuration = ( String ) attr . get ( i ) ; 
if ( configuration . startsWith ( "\"" ) ) 
configuration = configuration . substring ( 1 , configuration . length ( ) - 1 ) ; 
if ( configuration != null ) { 
List < String > toAdd = new ArrayList < > ( ) ; 
for ( String part : parts ) { 
if ( part . startsWith ( "s=" ) ) { 
toAdd . add ( part . substring ( "s=" . length ( ) ) ) ; 
if ( toAdd . size ( ) > 0 ) { 
serverURLs . clear ( ) ; 
for ( String host : toAdd ) 
} catch ( NamingException ignore ) { 
} protected String addHost ( String host ) { 
if ( host . startsWith ( LOCALHOST ) ) 
host = LOCAL_IP + host . substring ( "localhost" . length ( ) ) ; 
if ( host . contains ( "/" ) ) 
host = host . substring ( 0 , host . indexOf ( "/" ) ) ; 
if ( ! host . contains ( ":" ) ) 
host += ":" + ( clientConfiguration . getValueAsBoolean ( OGlobalConfiguration . CLIENT_USE_SSL ) ? 
getDefaultSSLPort ( ) : 
getDefaultPort ( ) ) ; 
else if ( host . split ( ":" ) . length < 2 || host . split ( ":" ) [ 1 ] . trim ( ) . length ( ) == 0 ) 
host += ( clientConfiguration . getValueAsBoolean ( OGlobalConfiguration . CLIENT_USE_SSL ) ? getDefaultSSLPort ( ) : getDefaultPort ( ) ) ; 
if ( ! serverURLs . contains ( host ) ) { 
serverURLs . add ( host ) ; 
return host ; 
} public OChannelBinaryAsynchClient beginRequest ( final OChannelBinaryAsynchClient network , final byte iCommand , 
OStorageRemoteSession session ) throws IOException { 
network . beginRequest ( iCommand , session ) ; 
return network ; 
public void serializeInByteBufferObject ( Short object , ByteBuffer buffer , Object ... hints ) { 
buffer . putShort ( object ) ; 
public Short deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return walChanges . getShortValue ( buffer , offset ) ; 
} protected static OObjectDatabaseTx getDatabase ( ) { 
ODatabaseInternal < ? > databaseOwner = ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getDatabaseOwner ( ) ; 
if ( databaseOwner instanceof OObjectDatabaseTx ) { 
return ( OObjectDatabaseTx ) databaseOwner ; 
} else if ( databaseOwner instanceof ODatabaseDocumentInternal ) { 
return new OObjectDatabaseTx ( ( ODatabaseDocumentInternal ) databaseOwner ) ; 
} public String toCreateIndexDDL ( final String indexName , final String indexType , final String engine ) { 
return createIndexDDLWithFieldType ( indexName , indexType , engine ) . toString ( ) ; 
} protected void init ( final Configuration configuration ) { 
final Boolean saveOriginalIds = configuration . getBoolean ( "blueprints.orientdb.saveOriginalIds" , null ) ; 
if ( saveOriginalIds != null ) 
setSaveOriginalIds ( saveOriginalIds ) ; 
final Boolean keepInMemoryReferences = configuration . getBoolean ( "blueprints.orientdb.keepInMemoryReferences" , null ) ; 
if ( keepInMemoryReferences != null ) 
setKeepInMemoryReferences ( keepInMemoryReferences ) ; 
final Boolean useCustomClassesForEdges = configuration . getBoolean ( "blueprints.orientdb.useCustomClassesForEdges" , null ) ; 
if ( useCustomClassesForEdges != null ) 
setUseClassForEdgeLabel ( useCustomClassesForEdges ) ; 
final Boolean useCustomClassesForVertex = configuration . getBoolean ( "blueprints.orientdb.useCustomClassesForVertex" , null ) ; 
if ( useCustomClassesForVertex != null ) 
setUseClassForVertexLabel ( useCustomClassesForVertex ) ; 
final Boolean useVertexFieldsForEdgeLabels = configuration . getBoolean ( "blueprints.orientdb.useVertexFieldsForEdgeLabels" , null ) ; 
if ( useVertexFieldsForEdgeLabels != null ) 
setUseVertexFieldsForEdgeLabels ( useVertexFieldsForEdgeLabels ) ; 
final Boolean lightweightEdges = configuration . getBoolean ( "blueprints.orientdb.lightweightEdges" , null ) ; 
if ( lightweightEdges != null ) 
setUseLightweightEdges ( lightweightEdges ) ; 
final Boolean autoScaleEdgeType = configuration . getBoolean ( "blueprints.orientdb.autoScaleEdgeType" , null ) ; 
if ( autoScaleEdgeType != null ) 
setAutoScaleEdgeType ( autoScaleEdgeType ) ; 
final Boolean requireTransaction = configuration . getBoolean ( "blueprints.orientdb.requireTransaction" , null ) ; 
if ( requireTransaction != null ) 
setRequireTransaction ( requireTransaction ) ; 
final Boolean txRequiredForSQLGraphOperations = configuration 
. getBoolean ( "blueprints.orientdb.txRequiredForSQLGraphOperations" , null ) ; 
if ( txRequiredForSQLGraphOperations != null ) 
setTxRequiredForSQLGraphOperations ( txRequiredForSQLGraphOperations ) ; 
final Integer maxRetries = configuration . getInt ( "blueprints.orientdb.maxRetries" , 50 ) ; 
if ( maxRetries != null ) 
setMaxRetries ( maxRetries ) ; 
} public OClientConnection connect ( final ONetworkProtocol iProtocol ) { 
final OClientConnection connection ; 
connection = new OClientConnection ( connectionSerial . incrementAndGet ( ) , iProtocol ) ; 
connections . put ( connection . getId ( ) , connection ) ; 
OServerPluginHelper . invokeHandlerCallbackOnClientConnection ( iProtocol . getServer ( ) , connection ) ; 
return connection ; 
} public OClientConnection connect ( final ONetworkProtocol iProtocol , final OClientConnection connection , final byte [ ] tokenBytes , 
final OTokenHandler handler ) { 
final OToken token ; 
token = handler . parseBinaryToken ( tokenBytes ) ; 
OClientSessions session ; 
synchronized ( sessions ) { 
session = new OClientSessions ( tokenBytes , token ) ; 
sessions . put ( new OHashToken ( tokenBytes ) , session ) ; 
connection . setTokenBytes ( tokenBytes ) ; 
connection . setTokenBased ( true ) ; 
connection . setToken ( token ) ; 
session . addConnection ( connection ) ; 
} public OClientConnection getConnection ( final int iChannelId , ONetworkProtocol protocol ) { 
OClientConnection connection = connections . get ( iChannelId ) ; 
if ( connection != null ) 
connection . setProtocol ( protocol ) ; 
} public OClientConnection getConnection ( final String iAddress ) { 
for ( OClientConnection conn : connections . values ( ) ) { 
if ( iAddress . equals ( conn . getRemoteAddress ( ) ) ) 
} public void kill ( final OClientConnection connection ) { 
if ( connection != null ) { 
final ONetworkProtocol protocol = connection . getProtocol ( ) ; 
protocol . interrupt ( ) ; 
disconnect ( connection ) ; 
protocol . sendShutdown ( ) ; 
} public void interrupt ( final int iChannelId ) { 
final OClientConnection connection = connections . get ( iChannelId ) ; 
if ( protocol != null ) 
protocol . softShutdown ( ) ; 
} public boolean disconnect ( final int iChannelId ) { 
final OClientConnection connection = connections . remove ( iChannelId ) ; 
OServerPluginHelper . invokeHandlerCallbackOnClientDisconnection ( server , connection ) ; 
removeConnectionFromSession ( connection ) ; 
for ( Entry < Integer , OClientConnection > entry : connections . entrySet ( ) ) { 
if ( entry . getValue ( ) . getProtocol ( ) . equals ( connection . getProtocol ( ) ) ) { 
} public void pushDistribCfg2Clients ( final ODocument iConfig ) { 
if ( iConfig == null ) 
final Set < String > pushed = new HashSet < String > ( ) ; 
for ( OClientConnection c : connections . values ( ) ) { 
if ( ! c . getData ( ) . supportsLegacyPushMessages ) 
final String remoteAddress = c . getRemoteAddress ( ) ; 
if ( pushed . contains ( remoteAddress ) ) 
if ( ! ( c . getProtocol ( ) instanceof ONetworkProtocolBinary ) || c . getData ( ) . getSerializationImpl ( ) == null ) 
final ONetworkProtocolBinary p = ( ONetworkProtocolBinary ) c . getProtocol ( ) ; 
final OChannelBinary channel = p . getChannel ( ) ; 
final ORecordSerializer ser = ORecordSerializerFactory . instance ( ) . getFormat ( c . getData ( ) . getSerializationImpl ( ) ) ; 
if ( ser == null ) 
final byte [ ] content = ser . toStream ( iConfig , false ) ; 
if ( channel . tryAcquireWriteLock ( TIMEOUT_PUSH ) ) { 
channel . writeByte ( OChannelBinaryProtocol . PUSH_DATA ) ; 
channel . writeInt ( Integer . MIN_VALUE ) ; 
channel . writeByte ( OChannelBinaryProtocol . REQUEST_PUSH_DISTRIB_CONFIG ) ; 
channel . writeBytes ( content ) ; 
channel . flush ( ) ; 
pushed . add ( c . getRemoteAddress ( ) ) ; 
channel . releaseWriteLock ( ) ; 
} public boolean swap ( int index , OIdentifiable newValue ) { 
EntriesIterator iter = ( EntriesIterator ) rawIterator ( ) ; 
int currIndex = 0 ; 
iter . next ( ) ; 
if ( index == currIndex ) { 
iter . swapValueOnCurrent ( newValue ) ; 
public void close ( ) { 
for ( Map . Entry < ORID , LockedRecordMetadata > lock : locks . entrySet ( ) ) { 
final LockedRecordMetadata lockedRecordMetadata = lock . getValue ( ) ; 
if ( lockedRecordMetadata . strategy . equals ( OStorage . LOCKING_STRATEGY . EXCLUSIVE_LOCK ) ) { 
( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ) . releaseWriteLock ( lock . getKey ( ) ) ; 
} else if ( lockedRecordMetadata . strategy . equals ( OStorage . LOCKING_STRATEGY . SHARED_LOCK ) ) { 
( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ) . releaseReadLock ( lock . getKey ( ) ) ; 
locks . clear ( ) ; 
} private void handleUpdateEdge ( ODocument record ) { 
Object currentOut = record . field ( "out" ) ; 
Object currentIn = record . field ( "in" ) ; 
Object prevOut = record . getOriginalValue ( "out" ) ; 
Object prevIn = record . getOriginalValue ( "in" ) ; 
if ( currentOut instanceof Collection && ( ( Collection ) currentOut ) . size ( ) == 1 ) { 
currentOut = ( ( Collection ) currentOut ) . iterator ( ) . next ( ) ; 
record . setProperty ( "out" , currentOut ) ; 
if ( currentIn instanceof Collection && ( ( Collection ) currentIn ) . size ( ) == 1 ) { 
currentIn = ( ( Collection ) currentIn ) . iterator ( ) . next ( ) ; 
record . setProperty ( "in" , currentIn ) ; 
validateOutInForEdge ( record , currentOut , currentIn ) ; 
changeVertexEdgePointer ( record , ( OIdentifiable ) prevIn , ( OIdentifiable ) currentIn , "in" ) ; 
changeVertexEdgePointer ( record , ( OIdentifiable ) prevOut , ( OIdentifiable ) currentOut , "out" ) ; 
} private void changeVertexEdgePointer ( ODocument edge , OIdentifiable prevVertex , OIdentifiable currentVertex , String direction ) { 
if ( prevVertex != null && ! prevVertex . equals ( currentVertex ) ) { 
String edgeClassName = edge . getClassName ( ) ; 
if ( edgeClassName . equalsIgnoreCase ( "E" ) ) { 
edgeClassName = "" ; 
String vertexFieldName = direction + "_" + edgeClassName ; 
ODocument prevOutDoc = ( ( OIdentifiable ) prevVertex ) . getRecord ( ) ; 
ORidBag prevBag = prevOutDoc . field ( vertexFieldName ) ; 
if ( prevBag != null ) { 
prevBag . remove ( edge ) ; 
prevOutDoc . save ( ) ; 
ODocument currentVertexDoc = ( ( OIdentifiable ) currentVertex ) . getRecord ( ) ; 
ORidBag currentBag = currentVertexDoc . field ( vertexFieldName ) ; 
if ( currentBag == null ) { 
currentBag = new ORidBag ( ) ; 
currentVertexDoc . field ( vertexFieldName , currentBag ) ; 
currentBag . add ( edge ) ; 
} private boolean isRecordInstanceOf ( Object iRecord , String orientClass ) { 
if ( iRecord == null ) { 
if ( ! ( iRecord instanceof OIdentifiable ) ) { 
ODocument record = ( ( OIdentifiable ) iRecord ) . getRecord ( ) ; 
return ( record . getSchemaClass ( ) . isSubClassOf ( orientClass ) ) ; 
public void serializeInByteBufferObject ( Character object , ByteBuffer buffer , Object ... hints ) { 
buffer . putChar ( object ) ; 
} public synchronized void generateSchema ( final String iPackageName , final ClassLoader iClassLoader ) { 
List < Class < ? > > classes = null ; 
classes = OReflectionHelper . getClassesFor ( iPackageName , iClassLoader ) ; 
} catch ( ClassNotFoundException e ) { 
for ( Class < ? > c : classes ) { 
generateSchema ( c ) ; 
} public synchronized void generateSchema ( final Class < ? > iClass , ODatabaseDocument database ) { 
if ( iClass == null || iClass . isInterface ( ) || iClass . isPrimitive ( ) || iClass . isEnum ( ) || iClass . isAnonymousClass ( ) ) 
OObjectEntitySerializer . registerClass ( iClass ) ; 
OClass schema = database . getMetadata ( ) . getSchema ( ) . getClass ( iClass ) ; 
if ( schema == null ) { 
generateOClass ( iClass , database ) ; 
List < String > fields = OObjectEntitySerializer . getClassFields ( iClass ) ; 
if ( fields != null ) 
for ( String field : fields ) { 
if ( schema . existsProperty ( field ) ) 
if ( OObjectEntitySerializer . isVersionField ( iClass , field ) || OObjectEntitySerializer . isIdField ( iClass , field ) ) 
Field f = OObjectEntitySerializer . getField ( field , iClass ) ; 
if ( f . getType ( ) . equals ( Object . class ) || f . getType ( ) . equals ( ODocument . class ) || OBlob . class . isAssignableFrom ( f . getType ( ) ) ) { 
OType t = OObjectEntitySerializer . getTypeByClass ( iClass , field , f ) ; 
if ( t == OType . CUSTOM ) { 
OEntityManager entityManager = OEntityManager . getEntityManagerByDatabaseURL ( database . getURL ( ) ) ; 
if ( entityManager . getEntityClass ( f . getType ( ) . getSimpleName ( ) ) != null ) { 
t = OType . LINK ; 
if ( f . getType ( ) . isEnum ( ) ) 
t = OType . STRING ; 
switch ( t ) { 
case LINK : 
Class < ? > linkedClazz = OObjectEntitySerializer . getSpecifiedLinkedType ( f ) ; 
if ( linkedClazz == null ) 
linkedClazz = f . getType ( ) ; 
generateLinkProperty ( database , schema , field , t , linkedClazz ) ; 
case LINKLIST : 
case LINKMAP : 
case LINKSET : 
linkedClazz = OObjectEntitySerializer . getSpecifiedMultiLinkedType ( f ) ; 
linkedClazz = OReflectionHelper . getGenericMultivalueType ( f ) ; 
if ( linkedClazz != null ) 
case EMBEDDED : 
if ( linkedClazz == null || linkedClazz . equals ( Object . class ) || linkedClazz . equals ( ODocument . class ) || OBlob . class 
. isAssignableFrom ( f . getType ( ) ) ) { 
case EMBEDDEDLIST : 
case EMBEDDEDSET : 
case EMBEDDEDMAP : 
if ( OReflectionHelper . isJavaType ( linkedClazz ) ) { 
schema . createProperty ( field , t , OType . getTypeByClass ( linkedClazz ) ) ; 
} else if ( linkedClazz . isEnum ( ) ) { 
schema . createProperty ( field , t , OType . STRING ) ; 
schema . createProperty ( field , t ) ; 
} public synchronized void synchronizeSchema ( ) { 
OObjectDatabaseTx database = ( ( OObjectDatabaseTx ) ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getDatabaseOwner ( ) ) ; 
Collection < Class < ? > > registeredEntities = database . getEntityManager ( ) . getRegisteredEntities ( ) ; 
boolean automaticSchemaGeneration = database . isAutomaticSchemaGeneration ( ) ; 
boolean reloadSchema = false ; 
for ( Class < ? > iClass : registeredEntities ) { 
if ( Proxy . class . isAssignableFrom ( iClass ) || iClass . isEnum ( ) || OReflectionHelper . isJavaType ( iClass ) || iClass 
. isAnonymousClass ( ) ) 
if ( ! database . getMetadata ( ) . getSchema ( ) . existsClass ( iClass . getSimpleName ( ) ) ) { 
database . getMetadata ( ) . getSchema ( ) . createClass ( iClass . getSimpleName ( ) ) ; 
reloadSchema = true ; 
for ( Class < ? > currentClass = iClass ; currentClass != Object . class ; ) { 
if ( automaticSchemaGeneration && ! currentClass . equals ( Object . class ) && ! currentClass . equals ( ODocument . class ) ) { 
( ( OSchemaProxyObject ) database . getMetadata ( ) . getSchema ( ) ) . generateSchema ( currentClass , database . getUnderlying ( ) ) ; 
String iClassName = currentClass . getSimpleName ( ) ; 
currentClass = currentClass . getSuperclass ( ) ; 
if ( currentClass == null || currentClass . equals ( ODocument . class ) ) 
currentClass = Object . class ; 
if ( database != null && ! database . isClosed ( ) && ! currentClass . equals ( Object . class ) ) { 
OClass oSuperClass ; 
OClass currentOClass = database . getMetadata ( ) . getSchema ( ) . getClass ( iClassName ) ; 
if ( ! database . getMetadata ( ) . getSchema ( ) . existsClass ( currentClass . getSimpleName ( ) ) ) { 
oSuperClass = database . getMetadata ( ) . getSchema ( ) . createClass ( currentClass . getSimpleName ( ) ) ; 
oSuperClass = database . getMetadata ( ) . getSchema ( ) . getClass ( currentClass . getSimpleName ( ) ) ; 
if ( ! currentOClass . getSuperClasses ( ) . contains ( oSuperClass ) ) { 
currentOClass . setSuperClasses ( Arrays . asList ( oSuperClass ) ) ; 
if ( database != null && ! database . isClosed ( ) && reloadSchema ) { 
database . getMetadata ( ) . getSchema ( ) . reload ( ) ; 
} protected void updateMetadata ( final String iName , final String iDescription , final METRIC_TYPE iType ) { 
if ( iDescription != null && dictionary . putIfAbsent ( iName , iDescription ) == null ) 
types . put ( iName , iType ) ; 
public REC next ( ) { 
checkDirection ( true ) ; 
if ( currentRecord != null ) 
return ( REC ) currentRecord ; 
currentRecord = null ; 
while ( hasNext ( ) ) { 
record = getTransactionEntry ( ) ; 
if ( record == null ) 
record = readCurrentRecord ( null , + 1 ) ; 
if ( include ( record ) ) 
return ( REC ) record ; 
throw new NoSuchElementException ( 
public REC previous ( ) { 
checkDirection ( false ) ; 
ORecord record = getRecord ( ) ; 
while ( hasPrevious ( ) ) { 
record = readCurrentRecord ( null , - 1 ) ; 
public ORecordIteratorClusters < REC > begin ( ) { 
if ( clusterIds . length == 0 ) 
browsedRecords = 0 ; 
currentClusterIdx = 0 ; 
current . setClusterId ( clusterIds [ currentClusterIdx ] ) ; 
updateClusterRange ( ) ; 
resetCurrentPosition ( ) ; 
nextPosition ( ) ; 
final ORecord record = getRecord ( ) ; 
currentRecord = readCurrentRecord ( record , 0 ) ; 
if ( currentRecord != null && ! include ( currentRecord ) ) { 
hasNext ( ) ; 
public ORecordIteratorClusters < REC > last ( ) { 
currentClusterIdx = clusterIds . length - 1 ; 
prevPosition ( ) ; 
hasPrevious ( ) ; 
public ORecordIteratorClusters < REC > setLiveUpdated ( boolean iLiveUpdated ) { 
super . setLiveUpdated ( iLiveUpdated ) ; 
if ( iLiveUpdated ) { 
firstClusterEntry = 0 ; 
lastClusterEntry = Long . MAX_VALUE ; 
if ( clazz == null ) 
return OGraphCommandExecutorSQLFactory . runInConfiguredTxMode ( new OGraphCommandExecutorSQLFactory . GraphCallBack < List < Object > > ( ) { 
public List < Object > call ( OrientBaseGraph graph ) { 
final Set < OIdentifiable > fromIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( graph . getRawGraph ( ) , from , context , iArgs ) ; 
final Set < OIdentifiable > toIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( graph . getRawGraph ( ) , to , context , iArgs ) ; 
final List < Object > edges = new ArrayList < Object > ( ) ; 
for ( OIdentifiable from : fromIds ) { 
final OrientVertex fromVertex = graph . getVertex ( from ) ; 
if ( fromVertex == null ) 
for ( OIdentifiable to : toIds ) { 
final OrientVertex toVertex ; 
if ( from . equals ( to ) ) { 
toVertex = fromVertex ; 
toVertex = graph . getVertex ( to ) ; 
for ( final OPair < String , Object > f : fields ) { 
if ( f . getValue ( ) instanceof OSQLFunctionRuntime ) { 
f . setValue ( ( ( OSQLFunctionRuntime ) f . getValue ( ) ) . getValue ( to , null , context ) ) ; 
} else if ( f . getValue ( ) instanceof OSQLFilterItem ) { 
f . setValue ( ( ( OSQLFilterItem ) f . getValue ( ) ) . getValue ( to , null , context ) ) ; 
OrientEdge edge = null ; 
if ( content != null ) { 
fields . addAll ( OPair . convertFromMap ( content . toMap ( ) ) ) ; 
fields = OPair . convertFromMap ( content . toMap ( ) ) ; 
edge = fromVertex . addEdge ( null , toVertex , edgeLabel , clusterName , fields ) ; 
if ( fields != null && ! fields . isEmpty ( ) ) { 
if ( edge . isLightweight ( ) ) 
edge . convertToDocument ( ) ; 
OSQLHelper . bindParameters ( edge . getRecord ( ) , fields , new OCommandParameters ( iArgs ) , context ) ; 
edge . save ( clusterName ) ; 
edges . add ( edge ) ; 
if ( batch > 0 && edges . size ( ) % batch == 0 ) { 
graph . commit ( ) ; 
graph . begin ( ) ; 
if ( edges . isEmpty ( ) ) { 
if ( fromIds . isEmpty ( ) ) 
else if ( toIds . isEmpty ( ) ) 
return edges ; 
} public int nextChar ( ) throws IOException { 
if ( missedChar != null ) { 
c = missedChar . charValue ( ) ; 
missedChar = null ; 
int read = in . read ( ) ; 
if ( read == - 1 ) 
c = ( char ) read ; 
if ( c == '\\' ) { 
read = in . read ( ) ; 
char c2 = ( char ) read ; 
if ( c2 == 'u' ) { 
final StringBuilder buff = new StringBuilder ( 8 ) ; 
for ( int i = 0 ; i < 4 ; ++ i ) { 
buff . append ( ( char ) read ) ; 
cursor += 6 ; 
return ( char ) Integer . parseInt ( buff . toString ( ) , 16 ) ; 
missedChar = c2 ; 
cursor ++ ; 
if ( c == NEW_LINE ) { 
++ lineNumber ; 
columnNumber = 0 ; 
++ columnNumber ; 
return ( char ) c ; 
if ( recordIds . isEmpty ( ) && subQuery == null ) 
if ( subQuery != null ) { 
final List < OIdentifiable > result = new OCommandSQL ( subQuery . toString ( ) ) . execute ( ) ; 
for ( OIdentifiable id : result ) 
recordIds . add ( id . getIdentity ( ) ) ; 
return OFindReferenceHelper . findReferences ( recordIds , classList ) ; 
} private static OBinaryRequest < ? extends OBinaryResponse > createRequest ( int requestType ) { 
switch ( requestType ) { 
case OChannelBinaryProtocol . REQUEST_DB_OPEN : 
return new OOpenRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CONNECT : 
return new OConnectRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_REOPEN : 
return new OReopenRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_SHUTDOWN : 
return new OShutdownRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_LIST : 
return new OListDatabasesRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_SERVER_INFO : 
return new OServerInfoRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_RELOAD : 
return new OReloadRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_CREATE : 
return new OCreateDatabaseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_CLOSE : 
return new OCloseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_EXIST : 
return new OExistsDatabaseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_DROP : 
return new ODropDatabaseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_SIZE : 
return new OGetSizeRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_COUNTRECORDS : 
return new OCountRecordsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLUSTER : 
return new ODistributedStatusRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLUSTER_COUNT : 
return new OCountRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLUSTER_DATARANGE : 
return new OGetClusterDataRangeRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLUSTER_ADD : 
return new OAddClusterRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLUSTER_DROP : 
return new ODropClusterRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_METADATA : 
return new OGetRecordMetadataRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_LOAD : 
return new OReadRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_LOAD_IF_VERSION_NOT_LATEST : 
return new OReadRecordIfVersionIsNotLatestRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_CREATE : 
return new OCreateRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_UPDATE : 
return new OUpdateRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_DELETE : 
return new ODeleteRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_HIDE : 
return new OHideRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_POSITIONS_HIGHER : 
return new OHigherPhysicalPositionsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_POSITIONS_CEILING : 
return new OCeilingPhysicalPositionsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_POSITIONS_LOWER : 
return new OLowerPhysicalPositionsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_POSITIONS_FLOOR : 
return new OFloorPhysicalPositionsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_COMMAND : 
return new OCommandRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_QUERY : 
return new OQueryRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CLOSE_QUERY : 
return new OCloseQueryRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_QUERY_NEXT_PAGE : 
return new OQueryNextPageRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_TX_COMMIT : 
return new OCommitRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CONFIG_GET : 
return new OGetGlobalConfigurationRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CONFIG_SET : 
return new OSetGlobalConfigurationRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CONFIG_LIST : 
return new OListGlobalConfigurationsRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_FREEZE : 
return new OFreezeDatabaseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_RELEASE : 
return new OReleaseDatabaseRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_RECORD_CLEAN_OUT : 
return new OCleanOutRecordRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_CREATE_SBTREE_BONSAI : 
return new OSBTCreateTreeRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_SBTREE_BONSAI_GET : 
return new OSBTGetRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_SBTREE_BONSAI_FIRST_KEY : 
return new OSBTFirstKeyRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_SBTREE_BONSAI_GET_ENTRIES_MAJOR : 
return new OSBTFetchEntriesMajorRequest < > ( ) ; 
case OChannelBinaryProtocol . REQUEST_RIDBAG_GET_SIZE : 
return new OSBTGetRealBagSizeRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_INCREMENTAL_BACKUP : 
return new OIncrementalBackupRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_DB_IMPORT : 
return new OImportRequest ( ) ; 
case OChannelBinaryProtocol . DISTRIBUTED_CONNECT : 
return new ODistributedConnectRequest ( ) ; 
} public static OBinaryRequest < ? extends OBinaryResponse > createRequest37 ( int requestType ) { 
case OChannelBinaryProtocol . SUBSCRIBE_PUSH : 
return new OSubscribeRequest ( ) ; 
case OChannelBinaryProtocol . EXPERIMENTAL : 
return new OExperimentalRequest ( ) ; 
case OChannelBinaryProtocol . UNSUBSCRIBE_PUSH : 
return new OUnsubscribeRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_TX_FETCH : 
return new OFetchTransactionRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_TX_REBEGIN : 
return new ORebeginTransactionRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_TX_BEGIN : 
return new OBeginTransactionRequest ( ) ; 
return new OCommit37Request ( ) ; 
case OChannelBinaryProtocol . REQUEST_TX_ROLLBACK : 
return new ORollbackTransactionRequest ( ) ; 
case OChannelBinaryProtocol . REQUEST_BATCH_OPERATIONS : 
return new OBatchOperationsRequest ( ) ; 
return new OOpen37Request ( ) ; 
return new OConnect37Request ( ) ; 
return new OReloadRequest37 ( ) ; 
} public static Object parseValue ( String iValue , final OCommandContext iContext ) { 
return parseValue ( iValue , iContext , false ) ; 
public OCommandRequestAbstract onAsyncReplicationError ( final OAsyncReplicationError iCallback ) { 
if ( iCallback != null ) { 
onAsyncReplicationError = new OAsyncReplicationError ( ) { 
int retry = 0 ; 
public ACTION onAsyncReplicationError ( Throwable iException , final int iRetry ) { 
switch ( iCallback . onAsyncReplicationError ( iException , ++ retry ) ) { 
case RETRY : 
execute ( ) ; 
case IGNORE : 
return ACTION . IGNORE ; 
onAsyncReplicationError = null ; 
} public void register ( final Class < ? extends OCompression > compression ) { 
final OCompression tempInstance = compression . newInstance ( ) ; 
final String name = tempInstance . name ( ) ; 
if ( compressions . containsKey ( name ) ) 
if ( compressionClasses . containsKey ( tempInstance . name ( ) ) ) 
compressionClasses . put ( name , compression ) ; 
} public int getOpenFilesLimit ( boolean verbose , int recommended , int defLimit ) { 
if ( Platform . isLinux ( ) ) { 
final OCLibrary . Rlimit rlimit = new OCLibrary . Rlimit ( ) ; 
final int result = C_LIBRARY . getrlimit ( OCLibrary . RLIMIT_NOFILE , rlimit ) ; 
if ( result == 0 && rlimit . rlim_cur > 0 ) { 
if ( verbose ) { 
if ( rlimit . rlim_cur < recommended ) { 
return ( int ) rlimit . rlim_cur / 2 - 512 ; 
} else if ( Platform . isWindows ( ) ) { 
return recommended ; 
return defLimit ; 
} public MemoryLimitResult getMemoryLimit ( final boolean printSteps ) { 
long memoryLimit = getPhysicalMemorySize ( ) ; 
boolean insideContainer = false ; 
if ( printSteps ) { 
convertToGB ( memoryLimit ) ) ; 
final int result = C_LIBRARY . getrlimit ( OCLibrary . RLIMIT_AS , rlimit ) ; 
if ( result == 0 ) { 
if ( printSteps ) 
convertToMB ( rlimit . rlim_cur ) , convertToGB ( rlimit . rlim_cur ) ) ; 
memoryLimit = updateMemoryLimit ( memoryLimit , rlimit . rlim_cur ) ; 
convertToMB ( rlimit . rlim_max ) , convertToGB ( rlimit . rlim_max ) ) ; 
memoryLimit = updateMemoryLimit ( memoryLimit , rlimit . rlim_max ) ; 
final String memoryCGroupPath = findMemoryGCGroupPath ( ) ; 
if ( memoryCGroupPath != null ) { 
final String memoryCGroupRoot = findMemoryGCRoot ( ) ; 
File memoryCGroup = new File ( memoryCGroupRoot , memoryCGroupPath ) ; 
if ( ! memoryCGroup . exists ( ) ) { 
memoryCGroup = new File ( memoryCGroupRoot ) ; 
insideContainer = true ; 
final long softMemoryLimit = fetchCGroupSoftMemoryLimit ( memoryCGroup , printSteps ) ; 
memoryLimit = updateMemoryLimit ( memoryLimit , softMemoryLimit ) ; 
final long hardMemoryLimit = fetchCGroupHardMemoryLimit ( memoryCGroup , printSteps ) ; 
memoryLimit = updateMemoryLimit ( memoryLimit , hardMemoryLimit ) ; 
if ( memoryLimit > 0 ) 
if ( memoryLimit <= 0 ) 
return new MemoryLimitResult ( memoryLimit , insideContainer ) ; 
} private long getPhysicalMemorySize ( ) { 
long osMemory = - 1 ; 
final MBeanServer mBeanServer = ManagementFactory . getPlatformMBeanServer ( ) ; 
final Object attribute = mBeanServer 
. getAttribute ( new ObjectName ( "java.lang" , "type" , "OperatingSystem" ) , "TotalPhysicalMemorySize" ) ; 
if ( attribute != null ) { 
if ( attribute instanceof Long ) { 
osMemory = ( Long ) attribute ; 
osMemory = Long . parseLong ( attribute . toString ( ) ) ; 
} catch ( final NumberFormatException e ) { 
if ( ! OLogManager . instance ( ) . isDebugEnabled ( ) ) 
} catch ( MalformedObjectNameException | AttributeNotFoundException | InstanceNotFoundException | MBeanException | ReflectionException e ) { 
} catch ( final RuntimeException e ) { 
return osMemory ; 
} public boolean allowsIndexedFunctionExecutionOnTarget ( OFromClause target , OCommandContext context , 
OBinaryCompareOperator operator , Object right ) { 
if ( this . childExpressions . size ( ) != 1 ) { 
return this . childExpressions . get ( 0 ) . allowsIndexedFunctionExecutionOnTarget ( target , context , operator , right ) ; 
return OGraphCommandExecutorSQLFactory . runWithAnyGraph ( new OGraphCommandExecutorSQLFactory . GraphCallBack < Object > ( ) { 
public Object call ( final OrientBaseGraph graph ) { 
final OrientVertex vertex = graph . addTemporaryVertex ( clazz . getName ( ) ) ; 
if ( f . getValue ( ) instanceof OSQLFunctionRuntime ) 
f . setValue ( ( ( OSQLFunctionRuntime ) f . getValue ( ) ) . getValue ( vertex . getRecord ( ) , null , context ) ) ; 
OSQLHelper . bindParameters ( vertex . getRecord ( ) , fields , new OCommandParameters ( iArgs ) , context ) ; 
if ( content != null ) 
vertex . getRecord ( ) . merge ( content , true , false ) ; 
if ( clusterName != null ) 
vertex . save ( clusterName ) ; 
vertex . save ( ) ; 
return vertex . getRecord ( ) ; 
} public static void writeOType ( BytesContainer bytes , int pos , OType type ) { 
bytes . bytes [ pos ] = ( byte ) type . getId ( ) ; 
} public void move ( final int iFrom , final int iPosition ) { 
if ( iPosition == 0 ) 
final int to = iFrom + iPosition ; 
final int size = iPosition > 0 ? buffer . length - to : buffer . length - iFrom ; 
System . arraycopy ( buffer , iFrom , buffer , to , size ) ; 
} public final byte [ ] toByteArray ( ) { 
if ( position == buffer . length - 1 ) 
final int pos = position ; 
final byte [ ] destinBuffer = new byte [ pos ] ; 
final byte [ ] sourceBuffer = buffer ; 
if ( pos < NATIVE_COPY_THRESHOLD ) 
for ( int i = 0 ; i < pos ; ++ i ) 
destinBuffer [ i ] = sourceBuffer [ i ] ; 
System . arraycopy ( sourceBuffer , 0 , destinBuffer , 0 , pos ) ; 
return destinBuffer ; 
} public int set ( final byte [ ] iContent ) { 
if ( iContent == null ) 
final int begin = position ; 
assureSpaceFor ( OBinaryProtocol . SIZE_INT + iContent . length ) ; 
OBinaryProtocol . int2bytes ( iContent . length , buffer , position ) ; 
position += OBinaryProtocol . SIZE_INT ; 
write ( iContent , 0 , iContent . length ) ; 
return begin ; 
} public void fill ( final int iLength , final byte iFiller ) { 
assureSpaceFor ( iLength ) ; 
Arrays . fill ( buffer , position , position + iLength , iFiller ) ; 
position += iLength ; 
} public OExecutionStepInternal executeUntilReturn ( ) { 
if ( steps . size ( ) > 0 ) { 
lastStep = steps . get ( steps . size ( ) - 1 ) ; 
for ( int i = 0 ; i < steps . size ( ) - 1 ; i ++ ) { 
ScriptLineStep step = steps . get ( i ) ; 
if ( step . containsReturn ( ) ) { 
OExecutionStepInternal returnStep = step . executeUntilReturn ( ctx ) ; 
if ( returnStep != null ) { 
lastStep = returnStep ; 
return lastStep ; 
OResultSet lastResult = step . syncPull ( ctx , 100 ) ; 
while ( lastResult . hasNext ( ) ) { 
lastResult . next ( ) ; 
lastResult = step . syncPull ( ctx , 100 ) ; 
this . lastStep = steps . get ( steps . size ( ) - 1 ) ; 
} public OExecutionStepInternal executeFull ( ) { 
for ( int i = 0 ; i < steps . size ( ) ; i ++ ) { 
return returnStep ; 
} public static ODocument toStream ( final Object iPojo , final ODocument iRecord , final OEntityManager iEntityManager , 
final OClass schemaClass , final OUserObject2RecordHandler iObj2RecHandler , final ODatabaseObject db , 
final boolean iSaveOnlyDirty ) { 
if ( iSaveOnlyDirty && ! iRecord . isDirty ( ) ) 
return iRecord ; 
final long timer = Orient . instance ( ) . getProfiler ( ) . startChrono ( ) ; 
final Integer identityRecord = System . identityHashCode ( iRecord ) ; 
if ( OSerializationThreadLocal . INSTANCE . get ( ) . contains ( identityRecord ) ) 
OSerializationThreadLocal . INSTANCE . get ( ) . add ( identityRecord ) ; 
OProperty schemaProperty ; 
final Class < ? > pojoClass = iPojo . getClass ( ) ; 
final List < Field > properties = getClassFields ( pojoClass ) ; 
final Field idField = fieldIds . get ( pojoClass ) ; 
if ( idField != null ) { 
Object id = getFieldValue ( iPojo , idField . getName ( ) ) ; 
if ( id != null ) { 
if ( id instanceof ORecordId ) { 
ORecordInternal . setIdentity ( iRecord , ( ORecordId ) id ) ; 
} else if ( id instanceof Number ) { 
( ( ORecordId ) iRecord . getIdentity ( ) ) . setClusterId ( schemaClass . getDefaultClusterId ( ) ) ; 
( ( ORecordId ) iRecord . getIdentity ( ) ) . setClusterPosition ( ( ( Number ) id ) . longValue ( ) ) ; 
} else if ( id instanceof String ) 
( ( ORecordId ) iRecord . getIdentity ( ) ) . fromString ( ( String ) id ) ; 
else if ( id . getClass ( ) . equals ( Object . class ) ) 
OLogManager . instance ( ) . warn ( OObjectSerializerHelper . class , 
final Field vField = fieldVersions . get ( pojoClass ) ; 
boolean versionConfigured = false ; 
if ( vField != null ) { 
versionConfigured = true ; 
Object ver = getFieldValue ( iPojo , vField . getName ( ) ) ; 
final int version = convertVersion ( ver ) ; 
ORecordInternal . setVersion ( iRecord , version ) ; 
if ( db . isMVCC ( ) && ! versionConfigured && db . getTransaction ( ) instanceof OTransactionOptimistic ) 
iRecord . setClassName ( schemaClass != null ? schemaClass . getName ( ) : null ) ; 
String fieldName ; 
Object fieldValue ; 
invokeCallback ( iPojo , iRecord , OBeforeSerialization . class ) ; 
for ( Field p : properties ) { 
fieldName = p . getName ( ) ; 
if ( idField != null && fieldName . equals ( idField . getName ( ) ) ) 
if ( vField != null && fieldName . equals ( vField . getName ( ) ) ) 
fieldValue = serializeFieldValue ( getFieldType ( iPojo , fieldName ) , getFieldValue ( iPojo , fieldName ) ) ; 
schemaProperty = schemaClass != null ? schemaClass . getProperty ( fieldName ) : null ; 
if ( fieldValue != null ) { 
if ( isEmbeddedObject ( iPojo . getClass ( ) , fieldValue . getClass ( ) , fieldName , iEntityManager ) ) { 
if ( schemaClass == null ) { 
db . getMetadata ( ) . getSchema ( ) . createClass ( iPojo . getClass ( ) ) ; 
iRecord . setClassNameIfExists ( iPojo . getClass ( ) . getSimpleName ( ) ) ; 
if ( schemaProperty == null ) { 
OType t = OType . getTypeByClass ( fieldValue . getClass ( ) ) ; 
if ( t == null ) 
t = OType . EMBEDDED ; 
schemaProperty = iRecord . getSchemaClass ( ) . createProperty ( fieldName , t ) ; 
fieldValue = typeToStream ( fieldValue , schemaProperty != null ? schemaProperty . getType ( ) : null , iEntityManager , 
iObj2RecHandler , db , iRecord , iSaveOnlyDirty ) ; 
iRecord . field ( fieldName , fieldValue ) ; 
iObj2RecHandler . registerUserObject ( iPojo , iRecord ) ; 
invokeCallback ( iPojo , iRecord , OAfterSerialization . class ) ; 
OSerializationThreadLocal . INSTANCE . get ( ) . remove ( identityRecord ) ; 
} public static Type [ ] getGenericTypes ( final Object iObject ) { 
if ( iObject instanceof OTrackedMultiValue ) { 
final Class < ? > cls = ( ( OTrackedMultiValue < ? , ? > ) iObject ) . getGenericClass ( ) ; 
if ( cls != null ) 
return new Type [ ] { cls } ; 
return OReflectionHelper . getGenericTypes ( iObject . getClass ( ) ) ; 
ODatabaseDocumentInternal db = getDatabase ( ) ; 
db . begin ( ) ; 
if ( className == null && clusterName == null ) 
OModifiableBoolean shutdownGraph = new OModifiableBoolean ( ) ; 
final boolean txAlreadyBegun = getDatabase ( ) . getTransaction ( ) . isActive ( ) ; 
final Set < OIdentifiable > sourceRIDs = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , source , context , iArgs ) ; 
final List < ODocument > result = new ArrayList < ODocument > ( sourceRIDs . size ( ) ) ; 
for ( OIdentifiable from : sourceRIDs ) { 
final OVertex fromVertex = toVertex ( from ) ; 
final ORID oldVertex = fromVertex . getIdentity ( ) . copy ( ) ; 
final ORID newVertex = fromVertex . moveTo ( className , clusterName ) ; 
final ODocument newVertexDoc = newVertex . getRecord ( ) ; 
if ( fields != null ) { 
f . setValue ( ( ( OSQLFunctionRuntime ) f . getValue ( ) ) . getValue ( newVertex . getRecord ( ) , null , context ) ) ; 
OSQLHelper . bindParameters ( newVertexDoc , fields , new OCommandParameters ( iArgs ) , context ) ; 
if ( merge != null ) 
newVertexDoc . merge ( merge , true , false ) ; 
newVertexDoc . save ( ) ; 
result 
. add ( new ODocument ( ) . setTrackingChanges ( false ) . field ( "old" , oldVertex , OType . LINK ) . field ( "new" , newVertex , OType . LINK ) ) ; 
if ( batch > 0 && result . size ( ) % batch == 0 ) { 
db . commit ( ) ; 
public void serializeInByteBufferObject ( String object , ByteBuffer buffer , Object ... hints ) { 
int length = object . length ( ) ; 
buffer . putInt ( length ) ; 
byte [ ] binaryData = new byte [ length * 2 ] ; 
char [ ] stringContent = new char [ length ] ; 
object . getChars ( 0 , length , stringContent , 0 ) ; 
int counter = 0 ; 
for ( char character : stringContent ) { 
binaryData [ counter ] = ( byte ) character ; 
counter ++ ; 
binaryData [ counter ] = ( byte ) ( character > > > 8 ) ; 
buffer . put ( binaryData ) ; 
public String deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
int len = buffer . getInt ( ) ; 
final char [ ] chars = new char [ len ] ; 
final byte [ ] binaryData = new byte [ 2 * len ] ; 
buffer . get ( binaryData ) ; 
for ( int i = 0 ; i < len ; i ++ ) 
chars [ i ] = ( char ) ( ( 0xFF & binaryData [ i << 1 ] ) | ( ( 0xFF & binaryData [ ( i << 1 ) + 1 ] ) << 8 ) ) ; 
return new String ( chars ) ; 
return buffer . getInt ( ) * 2 + OIntegerSerializer . INT_SIZE ; 
public String deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
int len = walChanges . getIntValue ( buffer , offset ) ; 
offset += OIntegerSerializer . INT_SIZE ; 
byte [ ] binaryData = walChanges . getBinaryValue ( buffer , offset , 2 * len ) ; 
return walChanges . getIntValue ( buffer , offset ) * 2 + OIntegerSerializer . INT_SIZE ; 
} public static void writeIdentifiable ( OChannelBinary channel , OClientConnection connection , final OIdentifiable o ) 
throws IOException { 
if ( o == null ) 
channel . writeShort ( OChannelBinaryProtocol . RECORD_NULL ) ; 
else if ( o instanceof ORecordId ) { 
channel . writeShort ( OChannelBinaryProtocol . RECORD_RID ) ; 
channel . writeRID ( ( ORID ) o ) ; 
writeRecord ( channel , connection , o . getRecord ( ) ) ; 
} public OStorageConfigurationImpl load ( final OContextConfiguration configuration ) throws OSerializationException { 
lock . acquireWriteLock ( ) ; 
initConfiguration ( configuration ) ; 
final byte [ ] record = storage . readRecord ( CONFIG_RID , null , false , false , null ) . getResult ( ) . buffer ; 
fromStream ( record , 0 , record . length , streamCharset ) ; 
lock . releaseWriteLock ( ) ; 
} public byte [ ] toStream ( final int iNetworkVersion , Charset charset ) throws OSerializationException { 
lock . acquireReadLock ( ) ; 
final StringBuilder buffer = new StringBuilder ( 8192 ) ; 
write ( buffer , CURRENT_VERSION ) ; 
write ( buffer , name ) ; 
write ( buffer , schemaRecordId ) ; 
write ( buffer , dictionaryRecordId ) ; 
write ( buffer , indexMgrRecordId ) ; 
write ( buffer , localeLanguage ) ; 
write ( buffer , localeCountry ) ; 
write ( buffer , dateFormat ) ; 
write ( buffer , dateTimeFormat ) ; 
write ( buffer , timeZone . getID ( ) ) ; 
write ( buffer , charset ) ; 
if ( iNetworkVersion > 24 ) 
write ( buffer , conflictStrategy ) ; 
phySegmentToStream ( buffer , fileTemplate ) ; 
write ( buffer , clusters . size ( ) ) ; 
for ( OStorageClusterConfiguration c : clusters ) { 
if ( c == null ) { 
write ( buffer , - 1 ) ; 
write ( buffer , c . getId ( ) ) ; 
write ( buffer , c . getName ( ) ) ; 
write ( buffer , c . getDataSegmentId ( ) ) ; 
if ( c instanceof OStoragePaginatedClusterConfiguration ) { 
write ( buffer , "d" ) ; 
final OStoragePaginatedClusterConfiguration paginatedClusterConfiguration = ( OStoragePaginatedClusterConfiguration ) c ; 
write ( buffer , paginatedClusterConfiguration . useWal ) ; 
write ( buffer , paginatedClusterConfiguration . recordOverflowGrowFactor ) ; 
write ( buffer , paginatedClusterConfiguration . recordGrowFactor ) ; 
write ( buffer , paginatedClusterConfiguration . compression ) ; 
if ( iNetworkVersion >= 31 ) 
write ( buffer , paginatedClusterConfiguration . encryption ) ; 
write ( buffer , paginatedClusterConfiguration . conflictStrategy ) ; 
if ( iNetworkVersion > 25 ) 
write ( buffer , paginatedClusterConfiguration . getStatus ( ) . name ( ) ) ; 
if ( iNetworkVersion >= Integer . MAX_VALUE ) { 
write ( buffer , paginatedClusterConfiguration . getBinaryVersion ( ) ) ; 
if ( iNetworkVersion <= 25 ) { 
write ( buffer , 0 ) ; 
write ( buffer , "" ) ; 
write ( buffer , false ) ; 
synchronized ( properties ) { 
write ( buffer , properties . size ( ) ) ; 
for ( OStorageEntryConfiguration e : properties ) 
entryToStream ( buffer , e ) ; 
write ( buffer , binaryFormatVersion ) ; 
write ( buffer , clusterSelection ) ; 
write ( buffer , getMinimumClusters ( ) ) ; 
if ( iNetworkVersion > 24 ) { 
write ( buffer , recordSerializer ) ; 
write ( buffer , recordSerializerVersion ) ; 
write ( buffer , configuration . getContextSize ( ) ) ; 
for ( String k : configuration . getContextKeys ( ) ) { 
final OGlobalConfiguration cfg = OGlobalConfiguration . findByKey ( k ) ; 
write ( buffer , k ) ; 
if ( cfg != null ) { 
write ( buffer , cfg . isHidden ( ) ? null : configuration . getValueAsString ( cfg ) ) ; 
write ( buffer , null ) ; 
write ( buffer , indexEngines . size ( ) ) ; 
for ( IndexEngineData engineData : indexEngines . values ( ) ) { 
write ( buffer , engineData . getName ( ) ) ; 
write ( buffer , engineData . getAlgorithm ( ) ) ; 
write ( buffer , engineData . getIndexType ( ) == null ? "" : engineData . getIndexType ( ) ) ; 
write ( buffer , engineData . getValueSerializerId ( ) ) ; 
write ( buffer , engineData . getKeySerializedId ( ) ) ; 
write ( buffer , engineData . isAutomatic ( ) ) ; 
write ( buffer , engineData . getDurableInNonTxMode ( ) ) ; 
write ( buffer , engineData . getVersion ( ) ) ; 
write ( buffer , engineData . isNullValuesSupport ( ) ) ; 
write ( buffer , engineData . getKeySize ( ) ) ; 
write ( buffer , engineData . getEncryption ( ) ) ; 
write ( buffer , engineData . getEncryptionOptions ( ) ) ; 
if ( engineData . getKeyTypes ( ) != null ) { 
write ( buffer , engineData . getKeyTypes ( ) . length ) ; 
for ( OType type : engineData . getKeyTypes ( ) ) { 
write ( buffer , type . name ( ) ) ; 
if ( engineData . getEngineProperties ( ) == null ) { 
write ( buffer , engineData . getEngineProperties ( ) . size ( ) ) ; 
for ( Map . Entry < String , String > property : engineData . getEngineProperties ( ) . entrySet ( ) ) { 
write ( buffer , property . getKey ( ) ) ; 
write ( buffer , property . getValue ( ) ) ; 
write ( buffer , engineData . getApiVersion ( ) ) ; 
write ( buffer , engineData . isMultivalue ( ) ) ; 
write ( buffer , createdAtVersion ) ; 
write ( buffer , pageSize ) ; 
write ( buffer , freeListBoundary ) ; 
write ( buffer , maxKeySize ) ; 
buffer . append ( "|" ) ; 
return buffer . toString ( ) . getBytes ( charset ) ; 
lock . releaseReadLock ( ) ; 
public void create ( ) throws IOException { 
storage . createRecord ( CONFIG_RID , new byte [ ] { 0 , 0 , 0 , 0 } , 0 , OBlob . RECORD_TYPE , null ) ; 
} public static boolean contains ( final int [ ] iArray , final int iToFind ) { 
if ( iArray == null || iArray . length == 0 ) 
for ( int e : iArray ) 
if ( e == iToFind ) 
} public static < T > boolean contains ( final T [ ] iArray , final T iToFind ) { 
for ( T e : iArray ) 
if ( e != null && e . equals ( iToFind ) ) 
public < RET extends OCommandExecutor > RET parse ( OCommandRequest iRequest ) { 
final OCommandRequestText textRequest = ( OCommandRequestText ) iRequest ; 
if ( iRequest instanceof OSQLSynchQuery ) { 
request = ( OSQLSynchQuery < ODocument > ) iRequest ; 
} else if ( iRequest instanceof OSQLAsynchQuery ) { 
request = ( OSQLAsynchQuery < ODocument > ) iRequest ; 
request = new OSQLSynchQuery < ODocument > ( textRequest . getText ( ) ) ; 
if ( textRequest . getResultListener ( ) != null ) { 
request . setResultListener ( textRequest . getResultListener ( ) ) ; 
String queryText = textRequest . getText ( ) ; 
final InputStream is = new ByteArrayInputStream ( queryText . getBytes ( ) ) ; 
OrientSql osql = null ; 
if ( db == null ) { 
osql = new OrientSql ( is ) ; 
osql = new OrientSql ( is , db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; 
OLogManager . instance ( ) . warn ( this , 
OMatchStatement result = ( OMatchStatement ) osql . parse ( ) ; 
this . matchExpressions = result . matchExpressions ; 
this . notMatchExpressions = result . notMatchExpressions ; 
this . returnItems = result . returnItems ; 
this . returnAliases = result . returnAliases ; 
this . limit = result . limit ; 
} catch ( ParseException e ) { 
OCommandSQLParsingException ex = new OCommandSQLParsingException ( e , queryText ) ; 
OErrorCode . QUERY_PARSE_ERROR . throwException ( ex . getMessage ( ) , ex ) ; 
buildPatterns ( ) ; 
pattern . validate ( ) ; 
return ( RET ) this ; 
} private void rebindFilters ( Map < String , OWhereClause > aliasFilters ) { 
for ( OMatchExpression expression : matchExpressions ) { 
OWhereClause newFilter = aliasFilters . get ( expression . origin . getAlias ( ) ) ; 
expression . origin . setFilter ( newFilter ) ; 
for ( OMatchPathItem item : expression . items ) { 
newFilter = aliasFilters . get ( item . filter . getAlias ( ) ) ; 
item . filter . setFilter ( newFilter ) ; 
} private void assignDefaultAliases ( List < OMatchExpression > matchExpressions ) { 
if ( expression . origin . getAlias ( ) == null ) { 
expression . origin . setAlias ( DEFAULT_ALIAS_PREFIX + ( counter ++ ) ) ; 
if ( item . filter == null ) { 
item . filter = new OMatchFilter ( - 1 ) ; 
if ( item . filter . getAlias ( ) == null ) { 
item . filter . setAlias ( DEFAULT_ALIAS_PREFIX + ( counter ++ ) ) ; 
public Object execute ( Map < Object , Object > iArgs ) { 
this . context . setInputParameters ( iArgs ) ; 
return execute ( this . request , this . context , this . progressListener ) ; 
} public Object execute ( OSQLAsynchQuery < ODocument > request , OCommandContext context , OProgressListener progressListener ) { 
if ( orderBy != null ) { 
if ( groupBy != null ) { 
if ( unwind != null ) { 
if ( skip != null ) { 
Map < Object , Object > iArgs = context . getInputParameters ( ) ; 
Map < String , Long > estimatedRootEntries = estimateRootEntries ( aliasClasses , aliasFilters , context ) ; 
if ( estimatedRootEntries . values ( ) . contains ( 0l ) ) { 
return new OBasicLegacyResultSet ( ) ; 
List < EdgeTraversal > sortedEdges = getTopologicalSortedSchedule ( estimatedRootEntries , pattern ) ; 
MatchExecutionPlan executionPlan = new MatchExecutionPlan ( ) ; 
executionPlan . sortedEdges = sortedEdges ; 
calculateMatch ( pattern , estimatedRootEntries , new MatchContext ( ) , aliasClasses , aliasFilters , context , request , 
executionPlan ) ; 
return getResult ( request ) ; 
if ( request . getResultListener ( ) != null ) { 
request . getResultListener ( ) . end ( ) ; 
} private void updateScheduleStartingAt ( PatternNode startNode , Set < PatternNode > visitedNodes , Set < PatternEdge > visitedEdges , 
Map < String , Set < String > > remainingDependencies , List < EdgeTraversal > resultingSchedule ) { 
visitedNodes . add ( startNode ) ; 
for ( Set < String > dependencies : remainingDependencies . values ( ) ) { 
dependencies . remove ( startNode . alias ) ; 
Map < PatternEdge , Boolean > edges = new LinkedHashMap < PatternEdge , Boolean > ( ) ; 
for ( PatternEdge outEdge : startNode . out ) { 
edges . put ( outEdge , true ) ; 
for ( PatternEdge inEdge : startNode . in ) { 
edges . put ( inEdge , false ) ; 
for ( Map . Entry < PatternEdge , Boolean > edgeData : edges . entrySet ( ) ) { 
PatternEdge edge = edgeData . getKey ( ) ; 
boolean isOutbound = edgeData . getValue ( ) ; 
PatternNode neighboringNode = isOutbound ? edge . in : edge . out ; 
if ( ! remainingDependencies . get ( neighboringNode . alias ) . isEmpty ( ) ) { 
if ( visitedNodes . contains ( neighboringNode ) ) { 
if ( ! visitedEdges . contains ( edge ) ) { 
boolean traversalDirection ; 
if ( startNode . optional || edge . item . isBidirectional ( ) ) { 
traversalDirection = ! isOutbound ; 
traversalDirection = isOutbound ; 
visitedEdges . add ( edge ) ; 
resultingSchedule . add ( new EdgeTraversal ( edge , traversalDirection ) ) ; 
} else if ( ! startNode . optional ) { 
if ( visitedEdges . contains ( edge ) ) { 
resultingSchedule . add ( new EdgeTraversal ( edge , isOutbound ) ) ; 
updateScheduleStartingAt ( neighboringNode , visitedNodes , visitedEdges , remainingDependencies , resultingSchedule ) ; 
} private List < EdgeTraversal > getTopologicalSortedSchedule ( Map < String , Long > estimatedRootEntries , Pattern pattern ) { 
List < EdgeTraversal > resultingSchedule = new ArrayList < EdgeTraversal > ( ) ; 
Map < String , Set < String > > remainingDependencies = getDependencies ( pattern ) ; 
Set < PatternNode > visitedNodes = new HashSet < PatternNode > ( ) ; 
Set < PatternEdge > visitedEdges = new HashSet < PatternEdge > ( ) ; 
List < OPair < Long , String > > rootWeights = new ArrayList < OPair < Long , String > > ( ) ; 
for ( Map . Entry < String , Long > root : estimatedRootEntries . entrySet ( ) ) { 
rootWeights . add ( new OPair < Long , String > ( root . getValue ( ) , root . getKey ( ) ) ) ; 
Collections . sort ( rootWeights ) ; 
Set < String > remainingStarts = new LinkedHashSet < String > ( ) ; 
for ( OPair < Long , String > item : rootWeights ) { 
remainingStarts . add ( item . getValue ( ) ) ; 
for ( String alias : pattern . aliasToNode . keySet ( ) ) { 
if ( ! remainingStarts . contains ( alias ) ) { 
remainingStarts . add ( alias ) ; 
while ( resultingSchedule . size ( ) < pattern . numOfEdges ) { 
PatternNode startingNode = null ; 
List < String > startsToRemove = new ArrayList < String > ( ) ; 
for ( String currentAlias : remainingStarts ) { 
PatternNode currentNode = pattern . aliasToNode . get ( currentAlias ) ; 
if ( visitedNodes . contains ( currentNode ) ) { 
startsToRemove . add ( currentAlias ) ; 
} else if ( remainingDependencies . get ( currentAlias ) . isEmpty ( ) ) { 
startingNode = currentNode ; 
remainingStarts . removeAll ( startsToRemove ) ; 
if ( startingNode == null ) { 
updateScheduleStartingAt ( startingNode , visitedNodes , visitedEdges , remainingDependencies , resultingSchedule ) ; 
if ( resultingSchedule . size ( ) != pattern . numOfEdges ) { 
return resultingSchedule ; 
} private boolean addSingleResult ( OSQLAsynchQuery < ODocument > request , OBasicCommandContext ctx , ORecord record ) { 
if ( ( ( OBasicCommandContext ) context ) . addToUniqueResult ( record ) ) { 
request . getResultListener ( ) . result ( record ) ; 
long currentCount = ctx . getResultsProcessed ( ) . incrementAndGet ( ) ; 
long limitValue = limitFromProtocol ; 
if ( limit != null ) { 
limitValue = limit . num . getValue ( ) . longValue ( ) ; 
if ( limitValue > - 1 && limitValue <= currentCount ) { 
} private OSelectStatement buildSelectStatement ( String className , OWhereClause oWhereClause ) { 
OSelectStatement stm = new OSelectStatement ( - 1 ) ; 
stm . whereClause = oWhereClause ; 
stm . target = new OFromClause ( - 1 ) ; 
stm . target . item = new OFromItem ( - 1 ) ; 
stm . target . item . identifier = new OIdentifier ( className ) ; 
return stm ; 
public boolean isEqual ( final OBinaryField iField1 , final OBinaryField iField2 ) { 
final BytesContainer fieldValue1 = iField1 . bytes ; 
final int offset1 = fieldValue1 . offset ; 
final BytesContainer fieldValue2 = iField2 . bytes ; 
final int offset2 = fieldValue2 . offset ; 
switch ( iField1 . type ) { 
case INTEGER : { 
final int value1 = OVarIntSerializer . readAsInteger ( fieldValue1 ) ; 
switch ( iField2 . type ) { 
final int value2 = OVarIntSerializer . readAsInteger ( fieldValue2 ) ; 
return value1 == value2 ; 
case LONG : 
case DATETIME : { 
final long value2 = OVarIntSerializer . readAsLong ( fieldValue2 ) ; 
case DATE : { 
final long value2 = ( OVarIntSerializer . readAsLong ( fieldValue2 ) * MILLISEC_PER_DAY ) ; 
case SHORT : { 
final short value2 = OVarIntSerializer . readAsShort ( fieldValue2 ) ; 
case BYTE : { 
final byte value2 = readByte ( fieldValue2 ) ; 
case FLOAT : { 
final float value2 = Float . intBitsToFloat ( readInteger ( fieldValue2 ) ) ; 
case DOUBLE : { 
final double value2 = Double . longBitsToDouble ( readLong ( fieldValue2 ) ) ; 
case STRING : { 
return Integer . parseInt ( readString ( fieldValue2 ) ) == value1 ; 
case DECIMAL : { 
final BigDecimal value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) ; 
return value1 == value2 . intValue ( ) ; 
case LONG : { 
final long value1 = OVarIntSerializer . readAsLong ( fieldValue1 ) ; 
return Long . parseLong ( readString ( fieldValue2 ) ) == value1 ; 
return value1 == value2 . longValue ( ) ; 
final short value1 = OVarIntSerializer . readAsShort ( fieldValue1 ) ; 
return Short . parseShort ( readString ( fieldValue2 ) ) == value1 ; 
return value1 == value2 . shortValue ( ) ; 
return Integer . parseInt ( readString ( fieldValue1 ) ) == value2 ; 
return Long . parseLong ( readString ( fieldValue1 ) ) == value2 ; 
final long value2 = OVarIntSerializer . readAsLong ( fieldValue2 ) * MILLISEC_PER_DAY ; 
return Short . parseShort ( readString ( fieldValue1 ) ) == value2 ; 
return Byte . parseByte ( readString ( fieldValue1 ) ) == value2 ; 
return Float . parseFloat ( readString ( fieldValue1 ) ) == value2 ; 
return Double . parseDouble ( readString ( fieldValue1 ) ) == value2 ; 
final int len1 = OVarIntSerializer . readAsInteger ( fieldValue1 ) ; 
final int len2 = OVarIntSerializer . readAsInteger ( fieldValue2 ) ; 
if ( len1 != len2 ) 
final OCollate collate = ( iField1 . collate != null && ! ODefaultCollate . NAME . equals ( iField1 . collate . getName ( ) ) ) ? 
iField1 . collate : 
( iField2 . collate != null && ! ODefaultCollate . NAME . equals ( iField2 . collate . getName ( ) ) ? iField2 . collate : null ) ; 
if ( collate != null ) { 
final String str1 = ( String ) collate . transform ( stringFromBytes ( fieldValue1 . bytes , fieldValue1 . offset , len1 ) ) ; 
final String str2 = ( String ) collate . transform ( stringFromBytes ( fieldValue2 . bytes , fieldValue2 . offset , len2 ) ) ; 
return str1 . equals ( str2 ) ; 
for ( int i = 0 ; i < len1 ; ++ i ) { 
if ( fieldValue1 . bytes [ fieldValue1 . offset + i ] != fieldValue2 . bytes [ fieldValue2 . offset + i ] ) 
return new BigDecimal ( readString ( fieldValue1 ) ) . equals ( value2 ) ; 
case BOOLEAN : { 
final boolean value2 = readByte ( fieldValue2 ) == 1 ; 
return Boolean . parseBoolean ( readString ( fieldValue1 ) ) == value2 ; 
final long value1AsLong = readLong ( fieldValue1 ) ; 
final double value1 = Double . longBitsToDouble ( value1AsLong ) ; 
final double value2AsLong = readLong ( fieldValue2 ) ; 
return value1AsLong == value2AsLong ; 
return Double . parseDouble ( readString ( fieldValue2 ) ) == value1 ; 
return value1 == value2 . doubleValue ( ) ; 
final int value1AsInt = readInteger ( fieldValue1 ) ; 
final float value1 = Float . intBitsToFloat ( value1AsInt ) ; 
final float value2AsInt = readInteger ( fieldValue2 ) ; 
return value1AsInt == value2AsInt ; 
return Float . parseFloat ( readString ( fieldValue2 ) ) == value1 ; 
return value1 == value2 . floatValue ( ) ; 
final byte value1 = readByte ( fieldValue1 ) ; 
final byte value2 = Byte . parseByte ( ( readString ( fieldValue2 ) ) ) ; 
return value1 == value2 . byteValue ( ) ; 
final boolean value1 = readByte ( fieldValue1 ) == 1 ; 
final String str = readString ( fieldValue2 ) ; 
return Boolean . parseBoolean ( str ) == value1 ; 
final long value1 = OVarIntSerializer . readAsLong ( fieldValue1 ) * MILLISEC_PER_DAY ; 
long value2 = OVarIntSerializer . readAsLong ( fieldValue2 ) ; 
value2 = convertDayToTimezone ( ODateHelper . getDatabaseTimeZone ( ) , TimeZone . getTimeZone ( "GMT" ) , value2 ) ; 
final String value2AsString = readString ( fieldValue2 ) ; 
if ( OIOUtils . isLong ( value2AsString ) ) { 
final long value2 = Long . parseLong ( value2AsString ) ; 
final ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
final SimpleDateFormat dateFormat = db != null ? 
db . getStorage ( ) . getConfiguration ( ) . getDateTimeFormatInstance ( ) : 
new SimpleDateFormat ( OStorageConfiguration . DEFAULT_DATETIME_FORMAT ) ; 
final Date value2AsDate = dateFormat . parse ( value2AsString ) ; 
final long value2 = value2AsDate . getTime ( ) ; 
} catch ( ParseException ignore ) { 
db . getStorage ( ) . getConfiguration ( ) . getDateFormatInstance ( ) : 
new SimpleDateFormat ( OStorageConfiguration . DEFAULT_DATE_FORMAT ) ; 
} catch ( ParseException ignored ) { 
return new Date ( value1 ) . toString ( ) . equals ( value2AsString ) ; 
case BINARY : { 
final int length1 = OVarIntSerializer . readAsInteger ( fieldValue1 ) ; 
final int length2 = OVarIntSerializer . readAsInteger ( fieldValue2 ) ; 
if ( length1 != length2 ) 
for ( int i = 0 ; i < length1 ; ++ i ) { 
case LINK : { 
final int clusterId1 = OVarIntSerializer . readAsInteger ( fieldValue1 ) ; 
final int clusterId2 = OVarIntSerializer . readAsInteger ( fieldValue2 ) ; 
if ( clusterId1 != clusterId2 ) 
final long clusterPos1 = OVarIntSerializer . readAsLong ( fieldValue1 ) ; 
final long clusterPos2 = OVarIntSerializer . readAsLong ( fieldValue2 ) ; 
if ( clusterPos1 == clusterPos2 ) 
return readOptimizedLink ( fieldValue1 , false ) . toString ( ) . equals ( readString ( fieldValue2 ) ) ; 
final BigDecimal value1 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue1 . bytes , fieldValue1 . offset ) ; 
return value1 . equals ( new BigDecimal ( value2 ) ) ; 
return value1 . toString ( ) . equals ( readString ( fieldValue2 ) ) ; 
return value1 . equals ( value2 ) ; 
fieldValue1 . offset = offset1 ; 
fieldValue2 . offset = offset2 ; 
public int compare ( final OBinaryField iField1 , final OBinaryField iField2 ) { 
return ( value1 < value2 ) ? - 1 : ( ( value1 == value2 ) ? 0 : 1 ) ; 
final String value2 = readString ( fieldValue2 ) ; 
return Integer . toString ( value1 ) . compareTo ( value2 ) ; 
final int value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) . intValue ( ) ; 
return Long . toString ( value1 ) . compareTo ( value2 ) ; 
final long value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) . longValue ( ) ; 
return Short . toString ( value1 ) . compareTo ( value2 ) ; 
final short value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) . shortValue ( ) ; 
final String value1 = readString ( fieldValue1 ) ; 
return value1 . compareTo ( Integer . toString ( value2 ) ) ; 
return value1 . compareTo ( Long . toString ( value2 ) ) ; 
return value1 . compareTo ( Short . toString ( value2 ) ) ; 
return value1 . compareTo ( Byte . toString ( value2 ) ) ; 
return value1 . compareTo ( Float . toString ( value2 ) ) ; 
return value1 . compareTo ( Double . toString ( value2 ) ) ; 
final String str1 = ( String ) collate . transform ( value1 ) ; 
final String str2 = ( String ) collate . transform ( value2 ) ; 
return str1 . compareTo ( str2 ) ; 
return value1 . compareTo ( value2 ) ; 
return value1 . compareTo ( Boolean . toString ( value2 ) ) ; 
return new BigDecimal ( value1 ) . compareTo ( value2 ) ; 
final double value1 = Double . longBitsToDouble ( readLong ( fieldValue1 ) ) ; 
return Double . toString ( value1 ) . compareTo ( value2 ) ; 
final double value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) . doubleValue ( ) ; 
final float value1 = Float . intBitsToFloat ( readInteger ( fieldValue1 ) ) ; 
return Float . toString ( value1 ) . compareTo ( value2 ) ; 
return Byte . toString ( value1 ) . compareTo ( value2 ) ; 
final byte value2 = ODecimalSerializer . INSTANCE . deserialize ( fieldValue2 . bytes , fieldValue2 . offset ) . byteValue ( ) ; 
return ( value1 == value2 ) ? 0 : value1 ? 1 : - 1 ; 
final boolean value2 = Boolean . parseBoolean ( readString ( fieldValue2 ) ) ; 
return new Date ( value1 ) . toString ( ) . compareTo ( value2AsString ) ; 
long value2 = value2AsDate . getTime ( ) ; 
final int max = Math . min ( length1 , length2 ) ; 
for ( int i = 0 ; i < max ; ++ i ) { 
final byte b1 = fieldValue1 . bytes [ fieldValue1 . offset + i ] ; 
final byte b2 = fieldValue2 . bytes [ fieldValue2 . offset + i ] ; 
if ( b1 > b2 ) 
else if ( b2 > b1 ) 
if ( length1 > length2 ) 
else if ( length2 > length1 ) 
if ( clusterId1 > clusterId2 ) 
else if ( clusterId1 < clusterId2 ) 
if ( clusterPos1 > clusterPos2 ) 
else if ( clusterPos1 < clusterPos2 ) 
return readOptimizedLink ( fieldValue1 , false ) . compareTo ( new ORecordId ( readString ( fieldValue2 ) ) ) ; 
return value1 . compareTo ( new BigDecimal ( value2 ) ) ; 
return value1 . toString ( ) . compareTo ( value2 ) ; 
} public void addIndex ( final OIndexDefinition indexDefinition ) { 
indexDefinitions . add ( indexDefinition ) ; 
if ( indexDefinition instanceof OIndexDefinitionMultiValue ) { 
if ( multiValueDefinitionIndex == - 1 ) 
multiValueDefinitionIndex = indexDefinitions . size ( ) - 1 ; 
collate . addCollate ( indexDefinition . getCollate ( ) ) ; 
} public List < String > getFields ( ) { 
final List < String > fields = new LinkedList < String > ( ) ; 
for ( final OIndexDefinition indexDefinition : indexDefinitions ) { 
fields . addAll ( indexDefinition . getFields ( ) ) ; 
return Collections . unmodifiableList ( fields ) ; 
} public Object getDocumentValueToIndex ( final ODocument iDocument ) { 
final List < OCompositeKey > compositeKeys = new ArrayList < OCompositeKey > ( 10 ) ; 
final OCompositeKey firstKey = new OCompositeKey ( ) ; 
boolean containsCollection = false ; 
compositeKeys . add ( firstKey ) ; 
final Object result = indexDefinition . getDocumentValueToIndex ( iDocument ) ; 
if ( result == null && isNullValuesIgnored ( ) ) 
if ( result instanceof Collection && ( ( Collection ) result ) . isEmpty ( ) && isNullValuesIgnored ( ) ) 
containsCollection = addKey ( firstKey , compositeKeys , containsCollection , result ) ; 
if ( ! containsCollection ) 
return firstKey ; 
return compositeKeys ; 
} public Object createValue ( final Object ... params ) { 
if ( params . length == 1 && params [ 0 ] instanceof Collection ) 
return params [ 0 ] ; 
return createValue ( Arrays . asList ( params ) ) ; 
} public OType [ ] getTypes ( ) { 
final List < OType > types = new LinkedList < OType > ( ) ; 
for ( final OIndexDefinition indexDefinition : indexDefinitions ) 
Collections . addAll ( types , indexDefinition . getTypes ( ) ) ; 
return types . toArray ( new OType [ types . size ( ) ] ) ; 
public ODocument toStream ( ) { 
document . setInternalStatus ( ORecordElement . STATUS . UNMARSHALLING ) ; 
serializeToStream ( ) ; 
document . setInternalStatus ( ORecordElement . STATUS . LOADED ) ; 
return document ; 
} public String toCreateIndexDDL ( final String indexName , final String indexType , String engine ) { 
final Iterator < String > fieldIterator = getFieldsToIndex ( ) . iterator ( ) ; 
if ( fieldIterator . hasNext ( ) ) { 
ddl . append ( fieldIterator . next ( ) ) ; 
while ( fieldIterator . hasNext ( ) ) { 
if ( engine != null ) 
if ( multiValueDefinitionIndex == - 1 ) { 
boolean first = true ; 
for ( OType oType : getTypes ( ) ) { 
if ( first ) 
first = false ; 
ddl . append ( oType . name ( ) ) ; 
return ddl . toString ( ) ; 
if ( records . isEmpty ( ) ) 
int deleted = 0 ; 
final ODatabaseDocumentInternal database = getDatabase ( ) ; 
for ( String rec : records ) { 
final ORecordId rid = new ORecordId ( rec ) ; 
final OStorageOperationResult < Boolean > result = database . getStorage ( ) . deleteRecord ( rid , - 1 , 0 , null ) ; 
database . getLocalCache ( ) . deleteRecord ( rid ) ; 
if ( result . getResult ( ) ) 
deleted ++ ; 
return deleted ; 
} public OProjectionItem splitForAggregation ( AggregateProjectionSplit aggregateSplit , OCommandContext ctx ) { 
if ( isAggregate ( ) ) { 
OProjectionItem result = new OProjectionItem ( - 1 ) ; 
result . alias = getProjectionAlias ( ) ; 
result . expression = expression . splitForAggregation ( aggregateSplit , ctx ) ; 
result . nestedProjection = nestedProjection ; 
} public Object toObjectDetermineType ( OResult source , OCommandContext ctx ) { 
String className = getClassNameForDocument ( ctx ) ; 
String type = getTypeForDocument ( ctx ) ; 
if ( className != null || ( type != null && "d" . equalsIgnoreCase ( type ) ) ) { 
return toDocument ( source , ctx , className ) ; 
return toMap ( source , ctx ) ; 
} public boolean isFieldChain ( ) { 
if ( operationsChain == null ) { 
for ( OPair < OSQLMethodRuntime , Object [ ] > pair : operationsChain ) { 
if ( ! pair . getKey ( ) . getMethod ( ) . getName ( ) . equals ( OSQLMethodField . NAME ) ) { 
} public OCollate getCollate ( Object doc ) { 
if ( collate != null || operationsChain == null || ! isFieldChain ( ) ) { 
return collate ; 
if ( ! ( doc instanceof OIdentifiable ) ) { 
FieldChain chain = getFieldChain ( ) ; 
ODocument lastDoc = ( ( OIdentifiable ) doc ) . getRecord ( ) ; 
for ( int i = 0 ; i < chain . getItemCount ( ) - 1 ; i ++ ) { 
if ( lastDoc == null ) { 
Object nextDoc = lastDoc . field ( chain . getItemName ( i ) ) ; 
if ( nextDoc == null || ! ( nextDoc instanceof OIdentifiable ) ) { 
lastDoc = ( ( OIdentifiable ) nextDoc ) . getRecord ( ) ; 
OClass schemaClass = lastDoc . getSchemaClass ( ) ; 
OProperty property = schemaClass . getProperty ( chain . getItemName ( chain . getItemCount ( ) - 1 ) ) ; 
if ( property == null ) { 
return property . getCollate ( ) ; 
} public String getStringValue ( ) { 
if ( value == null ) { 
if ( value . contains ( "`" ) ) { 
return value . replaceAll ( "\\\\`" , "`" ) ; 
} private void setStringValue ( String s ) { 
if ( s == null ) { 
} else if ( s . contains ( "`" ) ) { 
value = s . replaceAll ( "`" , "\\\\`" ) ; 
value = s ; 
} private int advanceProbe ( int probe ) { 
probe ^= probe << 13 ; 
probe ^= probe > > > 17 ; 
probe ^= probe << 5 ; 
this . probe . get ( ) . set ( probe ) ; 
return probe ; 
public void commit ( final boolean force ) { 
checkTransaction ( ) ; 
if ( txStartCounter < 0 ) 
if ( force ) 
txStartCounter = 0 ; 
txStartCounter -- ; 
if ( txStartCounter == 0 ) { 
} else if ( txStartCounter > 0 ) 
if ( clusterName == null ) 
final int clusterId = database . getStorage ( ) . getClusterIdByName ( clusterName ) ; 
for ( OClass iClass : database . getMetadata ( ) . getSchema ( ) . getClasses ( ) ) { 
for ( int i : iClass . getClusterIds ( ) ) { 
if ( i == clusterId ) 
database . getMetadata ( ) . getCommandCache ( ) . invalidateResultsOfCluster ( clusterName ) ; 
database . dropCluster ( clusterId , true ) ; 
} public static ODocument buildJsonFromFile ( String filePath ) throws IOException { 
if ( filePath == null ) { 
File jsonFile = new File ( filePath ) ; 
if ( ! jsonFile . exists ( ) ) { 
FileInputStream is = new FileInputStream ( jsonFile ) ; 
BufferedReader rd = new BufferedReader ( new InputStreamReader ( is , Charset . forName ( "UTF-8" ) ) ) ; 
ODocument json = new ODocument ( ) ; 
String jsonText = OFileManager . readAllTextFile ( rd ) ; 
json . fromJSON ( jsonText , "noMap" ) ; 
return json ; 
if ( rid == null && query == null ) 
if ( ! returning . equalsIgnoreCase ( "COUNT" ) ) 
allDeletedRecords = new ArrayList < ORecord > ( ) ; 
txAlreadyBegun = getDatabase ( ) . getTransaction ( ) . isActive ( ) ; 
if ( rid != null ) { 
OGraphCommandExecutorSQLFactory . runInConfiguredTxMode ( new OGraphCommandExecutorSQLFactory . GraphCallBack < Object > ( ) { 
public Object call ( OrientBaseGraph graph ) { 
final OrientVertex v = graph . getVertex ( rid ) ; 
v . remove ( ) ; 
removed = 1 ; 
end ( ) ; 
} else if ( query != null ) { 
OGraphCommandExecutorSQLFactory . runInConfiguredTxMode ( new OGraphCommandExecutorSQLFactory . GraphCallBack < OrientGraph > ( ) { 
public OrientGraph call ( final OrientBaseGraph iGraph ) { 
currentGraph . set ( iGraph ) ; 
query . setContext ( getContext ( ) ) ; 
query . execute ( iArgs ) ; 
if ( returning . equalsIgnoreCase ( "COUNT" ) ) 
return removed ; 
return allDeletedRecords ; 
} public boolean result ( final Object iRecord ) { 
final OIdentifiable id = ( OIdentifiable ) iRecord ; 
if ( id . getIdentity ( ) . isValid ( ) ) { 
final ODocument record = id . getRecord ( ) ; 
final OrientBaseGraph g = currentGraph . get ( ) ; 
final OrientVertex v = g . getVertex ( record ) ; 
if ( ! txAlreadyBegun && batch > 0 && removed % batch == 0 ) { 
if ( g instanceof OrientGraph ) { 
g . commit ( ) ; 
( ( OrientGraph ) g ) . begin ( ) ; 
if ( returning . equalsIgnoreCase ( "BEFORE" ) ) 
allDeletedRecords . add ( record ) ; 
removed ++ ; 
} protected String parseReturn ( ) throws OCommandSQLParsingException { 
final String returning = parserNextWord ( true ) ; 
if ( ! returning . equalsIgnoreCase ( "COUNT" ) && ! returning . equalsIgnoreCase ( "BEFORE" ) ) 
return returning ; 
} public boolean checkPassword ( final String iPassword , final String iHash ) { 
if ( iHash . startsWith ( HASH_ALGORITHM_PREFIX ) ) { 
final String s = iHash . substring ( HASH_ALGORITHM_PREFIX . length ( ) ) ; 
return createSHA256 ( iPassword ) . equals ( s ) ; 
} else if ( iHash . startsWith ( PBKDF2_ALGORITHM_PREFIX ) ) { 
final String s = iHash . substring ( PBKDF2_ALGORITHM_PREFIX . length ( ) ) ; 
return checkPasswordWithSalt ( iPassword , s , PBKDF2_ALGORITHM ) ; 
} else if ( iHash . startsWith ( PBKDF2_SHA256_ALGORITHM_PREFIX ) ) { 
final String s = iHash . substring ( PBKDF2_SHA256_ALGORITHM_PREFIX . length ( ) ) ; 
return checkPasswordWithSalt ( iPassword , s , PBKDF2_SHA256_ALGORITHM ) ; 
return MessageDigest . isEqual ( digestSHA256 ( iPassword ) , digestSHA256 ( iHash ) ) ; 
} public String createHash ( final String iInput , final String iAlgorithm , final boolean iIncludeAlgorithm ) { 
if ( iInput == null ) 
if ( iAlgorithm == null ) 
final StringBuilder buffer = new StringBuilder ( 128 ) ; 
final String algorithm = validateAlgorithm ( iAlgorithm ) ; 
if ( iIncludeAlgorithm ) { 
buffer . append ( '{' ) ; 
buffer . append ( algorithm ) ; 
buffer . append ( '}' ) ; 
final String transformed ; 
if ( HASH_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { 
transformed = createSHA256 ( iInput ) ; 
} else if ( PBKDF2_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { 
transformed = createHashWithSalt ( iInput , OGlobalConfiguration . SECURITY_USER_PASSWORD_SALT_ITERATIONS . getValueAsInteger ( ) , 
algorithm ) ; 
} else if ( PBKDF2_SHA256_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { 
buffer . append ( transformed ) ; 
} private static boolean isAlgorithmSupported ( final String algorithm ) { 
if ( Runtime . class . getPackage ( ) != null && Runtime . class . getPackage ( ) . getImplementationVersion ( ) != null ) { 
if ( Runtime . class . getPackage ( ) . getImplementationVersion ( ) . startsWith ( "1.7" ) ) { 
if ( algorithm != null && algorithm . equals ( PBKDF2_SHA256_ALGORITHM ) ) { 
} public OIndexInternal < ? > create ( final OIndexDefinition indexDefinition , final String clusterIndexName , 
final Set < String > clustersToIndex , boolean rebuild , final OProgressListener progressListener , 
final OBinarySerializer valueSerializer ) { 
acquireExclusiveLock ( ) ; 
configuration = indexConfigurationInstance ( new ODocument ( ) . setTrackingChanges ( false ) ) ; 
this . indexDefinition = indexDefinition ; 
if ( clustersToIndex != null ) 
this . clustersToIndex = new HashSet < > ( clustersToIndex ) ; 
this . clustersToIndex = new HashSet < > ( ) ; 
removeValuesContainer ( ) ; 
indexId = storage . addIndexEngine ( name , algorithm , type , indexDefinition , valueSerializer , isAutomatic ( ) , true , version , 1 , 
this instanceof OIndexMultiValues , getEngineProperties ( ) , clustersToIndex , metadata ) ; 
apiVersion = OAbstractPaginatedStorage . extractEngineAPIVersion ( indexId ) ; 
assert indexId >= 0 ; 
assert apiVersion >= 0 ; 
onIndexEngineChange ( indexId ) ; 
if ( rebuild ) 
fillIndex ( progressListener , false ) ; 
updateConfiguration ( ) ; 
if ( indexId >= 0 ) 
storage . deleteIndexEngine ( indexId ) ; 
} catch ( OInvalidIndexEngineIdException ignore ) { 
doReloadIndexEngine ( ) ; 
} catch ( Exception ex ) { 
if ( e instanceof OIndexException ) 
throw ( OIndexException ) e ; 
releaseExclusiveLock ( ) ; 
} public long rebuild ( final OProgressListener iProgressListener ) { 
long documentIndexed ; 
final boolean intentInstalled = getDatabase ( ) . declareIntent ( new OIntentMassiveInsert ( ) ) ; 
rebuilding = true ; 
rebuildVersion . incrementAndGet ( ) ; 
if ( indexId >= 0 ) { 
indexId = storage 
. addIndexEngine ( name , algorithm , type , indexDefinition , determineValueSerializer ( ) , isAutomatic ( ) , true , version , 1 , 
storage . clearIndex ( indexId ) ; 
rebuilding = false ; 
documentIndexed = fillIndex ( iProgressListener , true ) ; 
} catch ( final Exception e ) { 
if ( intentInstalled ) 
getDatabase ( ) . declareIntent ( null ) ; 
return documentIndexed ; 
} public Query order ( final String props , final String dir ) { 
this . orderBy = props ; 
this . orderByDir = dir ; 
public Iterable < Vertex > vertices ( ) { 
if ( limit == 0 ) 
return Collections . emptyList ( ) ; 
OTransaction transaction = ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . getTransaction ( ) ; 
if ( transaction . isActive ( ) && transaction . getEntryCount ( ) > 0 || hasCustomPredicate ( ) ) { 
String [ ] classes = allSubClassesLabels ( ) ; 
return new OrientGraphQueryIterable < Vertex > ( true , classes ) ; 
final StringBuilder text = new StringBuilder ( 512 ) ; 
text . append ( QUERY_SELECT_FROM ) ; 
if ( ( ( OrientBaseGraph ) graph ) . isUseClassForVertexLabel ( ) && labels != null && labels . length > 0 ) { 
if ( labels . length == 1 ) 
text . append ( OrientBaseGraph . encodeClassName ( labels [ 0 ] ) ) ; 
text . append ( OrientVertexType . CLASS_NAME ) ; 
final List < Object > queryParams = manageFilters ( text ) ; 
if ( ! ( ( OrientBaseGraph ) graph ) . isUseClassForVertexLabel ( ) ) 
manageLabels ( queryParams . size ( ) > 0 , text ) ; 
if ( orderBy . length ( ) > 1 ) { 
text . append ( ORDERBY ) ; 
text . append ( orderBy ) ; 
if ( skip > 0 && skip < Integer . MAX_VALUE ) { 
text . append ( SKIP ) ; 
text . append ( skip ) ; 
if ( limit > 0 && limit < Integer . MAX_VALUE ) { 
text . append ( LIMIT ) ; 
text . append ( limit ) ; 
final OSQLSynchQuery < OIdentifiable > query = new OSQLSynchQuery < OIdentifiable > ( text . toString ( ) ) ; 
if ( fetchPlan != null ) 
query . setFetchPlan ( fetchPlan ) ; 
return new OrientElementIterable < Vertex > ( ( ( OrientBaseGraph ) graph ) , 
( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . query ( query , queryParams . toArray ( ) ) ) ; 
public Iterable < Edge > edges ( ) { 
if ( ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . getTransaction ( ) . isActive ( ) || hasCustomPredicate ( ) ) 
return new OrientGraphQueryIterable < Edge > ( false , labels ) ; 
if ( ( ( OrientBaseGraph ) graph ) . isUseLightweightEdges ( ) ) 
if ( ( ( OrientBaseGraph ) graph ) . isUseClassForEdgeLabel ( ) && labels != null && labels . length > 0 ) { 
text . append ( OrientEdgeType . CLASS_NAME ) ; 
List < Object > queryParams = manageFilters ( text ) ; 
if ( ! ( ( OrientBaseGraph ) graph ) . isUseClassForEdgeLabel ( ) ) 
if ( limit > 0 && limit < Integer . MAX_VALUE ) 
query . setLimit ( limit ) ; 
return new OrientElementIterable < Edge > ( ( ( OrientBaseGraph ) graph ) , 
public int [ ] getPartitionKey ( ) { 
if ( tasks . size ( ) == 1 ) 
return tasks . get ( 0 ) . getPartitionKey ( ) ; 
final int [ ] partitions = new int [ tasks . size ( ) ] ; 
for ( int i = 0 ; i < tasks . size ( ) ; ++ i ) { 
final OAbstractRecordReplicatedTask task = tasks . get ( i ) ; 
partitions [ i ] = task . getPartitionKey ( ) [ 0 ] ; 
return partitions ; 
public long getDistributedTimeout ( ) { 
final long to = OGlobalConfiguration . DISTRIBUTED_CRUD_TASK_SYNCH_TIMEOUT . getValueAsLong ( ) ; 
return to + ( ( to / 2 ) * tasks . size ( ) ) ; 
if ( keyTypes != null && keyTypes . length > 0 ) { 
ddl . append ( keyTypes [ 0 ] . toString ( ) ) ; 
for ( int i = 1 ; i < keyTypes . length ; i ++ ) { 
} public byte [ ] toStream ( final int iNetworkVersion , final Charset charset ) throws OSerializationException { 
write ( buffer , getSchemaRecordId ( ) ) ; 
write ( buffer , getIndexMgrRecordId ( ) ) ; 
write ( buffer , getLocaleLanguage ( ) ) ; 
write ( buffer , getLocaleCountry ( ) ) ; 
write ( buffer , getDateFormat ( ) ) ; 
final TimeZone timeZone = getTimeZone ( ) ; 
assert timeZone != null ; 
write ( buffer , timeZone ) ; 
write ( buffer , getConflictStrategy ( ) ) ; 
phySegmentToStream ( buffer , new OStorageSegmentConfiguration ( ) ) ; 
final List < OStorageClusterConfiguration > clusters = getClusters ( ) ; 
for ( final OStorageClusterConfiguration c : clusters ) { 
if ( iNetworkVersion >= 31 ) { 
if ( iNetworkVersion > 25 ) { 
final List < OStorageEntryConfiguration > properties = getProperties ( ) ; 
for ( final OStorageEntryConfiguration e : properties ) { 
write ( buffer , getBinaryFormatVersion ( ) ) ; 
write ( buffer , getClusterSelection ( ) ) ; 
write ( buffer , getRecordSerializer ( ) ) ; 
write ( buffer , getRecordSerializerVersion ( ) ) ; 
for ( final String k : configuration . getContextKeys ( ) ) { 
final List < IndexEngineData > engines = loadIndexEngines ( ) ; 
write ( buffer , engines . size ( ) ) ; 
for ( final IndexEngineData engineData : engines ) { 
for ( final OType type : engineData . getKeyTypes ( ) ) { 
for ( final Map . Entry < String , String > property : engineData . getEngineProperties ( ) . entrySet ( ) ) { 
write ( buffer , getCreatedAtVersion ( ) ) ; 
write ( buffer , getPageSize ( ) ) ; 
write ( buffer , getFreeListBoundary ( ) ) ; 
write ( buffer , getMaxKeySize ( ) ) ; 
} public Features getFeatures ( ) { 
makeActive ( ) ; 
if ( ! featuresInitialized ) { 
FEATURES . supportsDuplicateEdges = true ; 
FEATURES . supportsSelfLoops = true ; 
FEATURES . isPersistent = true ; 
FEATURES . supportsVertexIteration = true ; 
FEATURES . supportsVertexIndex = true ; 
FEATURES . ignoresSuppliedIds = true ; 
FEATURES . supportsTransactions = true ; 
FEATURES . supportsVertexKeyIndex = true ; 
FEATURES . supportsKeyIndices = true ; 
FEATURES . isWrapper = false ; 
FEATURES . supportsIndices = true ; 
FEATURES . supportsVertexProperties = true ; 
FEATURES . supportsEdgeProperties = true ; 
FEATURES . supportsSerializableObjectProperty = true ; 
FEATURES . supportsBooleanProperty = true ; 
FEATURES . supportsDoubleProperty = true ; 
FEATURES . supportsFloatProperty = true ; 
FEATURES . supportsIntegerProperty = true ; 
FEATURES . supportsPrimitiveArrayProperty = true ; 
FEATURES . supportsUniformListProperty = true ; 
FEATURES . supportsMixedListProperty = true ; 
FEATURES . supportsLongProperty = true ; 
FEATURES . supportsMapProperty = true ; 
FEATURES . supportsStringProperty = true ; 
FEATURES . supportsThreadedTransactions = false ; 
FEATURES . supportsThreadIsolatedTransactions = false ; 
FEATURES . supportsEdgeIndex = ! isUseLightweightEdges ( ) ; 
FEATURES . supportsEdgeKeyIndex = ! isUseLightweightEdges ( ) ; 
FEATURES . supportsEdgeIteration = ! isUseLightweightEdges ( ) ; 
FEATURES . supportsEdgeRetrieval = ! isUseLightweightEdges ( ) ; 
featuresInitialized = true ; 
return FEATURES ; 
} public void removeEdgeInternal ( final OrientEdge edge ) { 
final OIdentifiable inVertexEdge = edge . vIn != null ? edge . vIn : edge . rawElement ; 
final String edgeClassName = OrientBaseGraph . encodeClassName ( edge . getLabel ( ) ) ; 
final boolean useVertexFieldsForEdgeLabels = settings . isUseVertexFieldsForEdgeLabels ( ) ; 
final OIdentifiable outVertex = edge . getOutVertex ( ) ; 
ODocument outVertexRecord = null ; 
boolean outVertexChanged = false ; 
if ( outVertex != null ) { 
outVertexRecord = outVertex . getRecord ( ) ; 
if ( outVertexRecord != null ) { 
final String outFieldName = OrientVertex . getConnectionFieldName ( Direction . OUT , edgeClassName , useVertexFieldsForEdgeLabels ) ; 
outVertexChanged = edge . dropEdgeFromVertex ( inVertexEdge , outVertexRecord , outFieldName , 
outVertexRecord . field ( outFieldName ) ) ; 
final OIdentifiable outVertexEdge = edge . vOut != null ? edge . vOut : edge . rawElement ; 
final OIdentifiable inVertex = edge . getInVertex ( ) ; 
ODocument inVertexRecord = null ; 
boolean inVertexChanged = false ; 
if ( inVertex != null ) { 
inVertexRecord = inVertex . getRecord ( ) ; 
if ( inVertexRecord != null ) { 
final String inFieldName = OrientVertex . getConnectionFieldName ( Direction . IN , edgeClassName , useVertexFieldsForEdgeLabels ) ; 
inVertexChanged = edge . dropEdgeFromVertex ( outVertexEdge , inVertexRecord , inFieldName , inVertexRecord . field ( inFieldName ) ) ; 
if ( outVertexChanged ) 
outVertexRecord . save ( ) ; 
if ( inVertexChanged ) 
inVertexRecord . save ( ) ; 
if ( edge . rawElement != null ) 
edge . removeRecord ( ) ; 
} private Object execute ( OCommandContext ctx ) { 
if ( destField == null ) 
if ( ! ( database . getDatabaseOwner ( ) instanceof ODatabaseDocument ) ) 
throw new OCommandSQLParsingException ( 
final ODatabaseDocument db = ( ODatabaseDocument ) database . getDatabaseOwner ( ) ; 
final OClass sourceClass = database . getMetadata ( ) . getSchema ( ) . getClass ( getSourceClass ( ) . getStringValue ( ) ) ; 
final OClass destClass = database . getMetadata ( ) . getSchema ( ) . getClass ( getDestClass ( ) . getStringValue ( ) ) ; 
if ( destClass == null ) 
Object value ; 
if ( ! ODocumentHelper . ATTRIBUTE_RID . equals ( destField ) ) { 
List < ODocument > result ; 
ODocument target ; 
Object oldValue ; 
long total = 0 ; 
String linkName = name == null ? sourceField . getStringValue ( ) : name . getStringValue ( ) ; 
boolean multipleRelationship ; 
OType linkType = OType . valueOf ( type . getStringValue ( ) . toUpperCase ( Locale . ENGLISH ) ) ; 
if ( linkType != null ) 
multipleRelationship = linkType == OType . LINKSET || linkType == OType . LINKLIST ; 
multipleRelationship = false ; 
long totRecords = db . countClass ( sourceClass . getName ( ) ) ; 
long currRecord = 0 ; 
database . declareIntent ( new OIntentMassiveInsert ( ) ) ; 
for ( ODocument doc : db . browseClass ( sourceClass . getName ( ) ) ) { 
if ( breakExec ) { 
value = doc . getProperty ( sourceField . getStringValue ( ) ) ; 
if ( value != null ) { 
if ( value instanceof ODocument || value instanceof ORID ) { 
} else if ( value instanceof Collection < ? > ) { 
target = null ; 
if ( ! ODocumentHelper . ATTRIBUTE_RID . equals ( destField ) && value instanceof String ) 
if ( ( ( String ) value ) . length ( ) == 0 ) 
value = "'" + value + "'" ; 
OResultSet rs = database . query ( cmd + value ) ; 
result = toList ( rs ) ; 
rs . close ( ) ; 
if ( result == null || result . size ( ) == 0 ) 
else if ( result . size ( ) > 1 ) 
target = result . get ( 0 ) ; 
value = target ; 
if ( target != null && inverse ) { 
oldValue = target . getProperty ( linkName ) ; 
if ( oldValue != null ) { 
if ( ! multipleRelationship ) 
multipleRelationship = true ; 
Collection < ODocument > coll ; 
if ( oldValue instanceof Collection ) { 
coll = ( Collection < ODocument > ) oldValue ; 
target . setDirty ( ) ; 
coll = new ArrayList < ODocument > ( 2 ) ; 
target . setProperty ( linkName , coll ) ; 
coll . add ( ( ODocument ) oldValue ) ; 
coll . add ( doc ) ; 
if ( linkType == OType . LINKSET ) { 
value = new ORecordLazySet ( target ) ; 
( ( Set < OIdentifiable > ) value ) . add ( doc ) ; 
} else if ( linkType == OType . LINKLIST ) { 
value = new ORecordLazyList ( target ) ; 
( ( ORecordLazyList ) value ) . add ( doc ) ; 
value = doc ; 
target . setProperty ( linkName , value ) ; 
target . save ( ) ; 
doc . setProperty ( linkName , value ) ; 
doc . save ( ) ; 
total ++ ; 
if ( total > 0 ) { 
if ( inverse ) { 
OProperty prop = destClass . getProperty ( linkName ) ; 
if ( prop != null ) 
destClass . dropProperty ( linkName ) ; 
if ( linkType == null ) 
linkType = multipleRelationship ? OType . LINKSET : OType . LINK ; 
destClass . createProperty ( linkName , linkType , sourceClass ) ; 
OProperty prop = sourceClass . getProperty ( linkName ) ; 
sourceClass . dropProperty ( linkName ) ; 
sourceClass . createProperty ( linkName , OType . LINK , destClass ) ; 
database . declareIntent ( null ) ; 
return total ; 
} private static boolean checkChangesFilledUpTo ( final FileChanges changesContainer , final long pageIndex ) { 
if ( changesContainer == null ) { 
} else if ( changesContainer . isNew || changesContainer . maxNewPageIndex > - 2 ) { 
return pageIndex < changesContainer . maxNewPageIndex + 1 ; 
return ! changesContainer . truncate ; 
public OClass truncateCluster ( String clusterName ) { 
database . checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_DELETE , name ) ; 
acquireSchemaReadLock ( ) ; 
database . command ( cmd ) . close ( ) ; 
releaseSchemaReadLock ( ) ; 
} protected boolean parseTimeout ( final String w ) throws OCommandSQLParsingException { 
if ( ! w . equals ( KEYWORD_TIMEOUT ) ) 
String word = parserNextWord ( true ) ; 
timeoutMs = Long . parseLong ( word ) ; 
} catch ( NumberFormatException ignore ) { 
if ( timeoutMs < 0 ) 
word = parserNextWord ( true ) ; 
if ( word != null ) 
if ( word . equals ( TIMEOUT_STRATEGY . EXCEPTION . toString ( ) ) ) 
timeoutStrategy = TIMEOUT_STRATEGY . EXCEPTION ; 
else if ( word . equals ( TIMEOUT_STRATEGY . RETURN . toString ( ) ) ) 
timeoutStrategy = TIMEOUT_STRATEGY . RETURN ; 
parserGoBack ( ) ; 
} protected String parseLock ( ) throws OCommandSQLParsingException { 
final String lockStrategy = parserNextWord ( true ) ; 
if ( ! lockStrategy . equalsIgnoreCase ( "DEFAULT" ) && ! lockStrategy . equalsIgnoreCase ( "NONE" ) 
&& ! lockStrategy . equalsIgnoreCase ( "RECORD" ) ) 
return lockStrategy ; 
public OSpatialQueryContext build ( Map < String , Object > query ) throws Exception { 
Shape shape = parseShape ( query ) ; 
SpatialStrategy strategy = manager . strategy ( ) ; 
SpatialArgs args = new SpatialArgs ( SpatialOperation . Intersects , shape . getBoundingBox ( ) ) ; 
Query filterQuery = strategy . makeQuery ( args ) ; 
BooleanQuery q = new BooleanQuery . Builder ( ) . add ( filterQuery , BooleanClause . Occur . MUST ) 
. add ( new MatchAllDocsQuery ( ) , BooleanClause . Occur . SHOULD ) . build ( ) ; 
return new OSpatialQueryContext ( null , manager . searcher ( ) , q ) ; 
final StringBuilder result = new StringBuilder ( ) ; 
if ( optimizeEdges ) 
result . append ( optimizeEdges ( ) ) ; 
if ( fromExpr == null && toExpr == null && rids == null && query == null && compiledFilter == null ) 
if ( rids != null ) { 
for ( ORecordId rid : rids ) { 
final OrientEdge e = graph . getEdge ( rid ) ; 
e . remove ( ) ; 
final Set < OrientEdge > edges = new HashSet < OrientEdge > ( ) ; 
if ( query == null ) { 
Set < OIdentifiable > fromIds = null ; 
if ( fromExpr != null ) 
fromIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( graph . getRawGraph ( ) , fromExpr , context , iArgs ) ; 
Set < OIdentifiable > toIds = null ; 
if ( toExpr != null ) 
toIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( graph . getRawGraph ( ) , toExpr , context , iArgs ) ; 
if ( label == null ) 
label = OrientEdgeType . CLASS_NAME ; 
if ( fromIds != null && toIds != null ) { 
int fromCount = 0 ; 
int toCount = 0 ; 
for ( OIdentifiable fromId : fromIds ) { 
final OrientVertex v = graph . getVertex ( fromId ) ; 
if ( v != null ) 
fromCount += v . countEdges ( Direction . OUT , label ) ; 
for ( OIdentifiable toId : toIds ) { 
final OrientVertex v = graph . getVertex ( toId ) ; 
toCount += v . countEdges ( Direction . IN , label ) ; 
if ( fromCount <= toCount ) { 
for ( Edge e : v . getEdges ( Direction . OUT , label ) ) { 
final OIdentifiable inV = ( ( OrientEdge ) e ) . getInVertex ( ) ; 
if ( inV != null && toIds . contains ( inV . getIdentity ( ) ) ) 
edges . add ( ( OrientEdge ) e ) ; 
for ( Edge e : v . getEdges ( Direction . IN , label ) ) { 
final OIdentifiable outV = ( ( OrientEdge ) e ) . getOutVertex ( ) ; 
if ( outV != null && fromIds . contains ( outV . getIdentity ( ) ) ) 
} else if ( fromIds != null ) { 
} else if ( toIds != null ) { 
if ( compiledFilter != null ) { 
for ( Iterator < OrientEdge > it = edges . iterator ( ) ; it . hasNext ( ) ; ) { 
final OrientEdge edge = it . next ( ) ; 
if ( ! ( Boolean ) compiledFilter . evaluate ( edge . getRecord ( ) , null , context ) ) 
it . remove ( ) ; 
removed = edges . size ( ) ; 
for ( OrientEdge edge : edges ) 
edge . remove ( ) ; 
if ( ! ( Boolean ) compiledFilter . evaluate ( id . getRecord ( ) , null , context ) ) 
final OrientEdge e = g . getEdge ( id ) ; 
if ( ! txAlreadyBegun && batch > 0 && ( removed + 1 ) % batch == 0 ) { 
} public OIndexSearchResult merge ( final OIndexSearchResult searchResult ) { 
if ( searchResult . lastOperator instanceof OQueryOperatorEquals ) { 
return mergeFields ( this , searchResult ) ; 
if ( lastOperator instanceof OQueryOperatorEquals ) { 
return mergeFields ( searchResult , this ) ; 
if ( isIndexEqualityOperator ( searchResult . lastOperator ) ) { 
if ( schemaClass == null ) 
final long recs = schemaClass . count ( deep ) ; 
if ( recs > 0 && ! unsafe ) { 
if ( schemaClass . isSubClassOf ( "V" ) ) { 
} else if ( schemaClass . isSubClassOf ( "E" ) ) { 
Collection < OClass > subclasses = schemaClass . getAllSubclasses ( ) ; 
if ( deep && ! unsafe ) { 
for ( OClass subclass : subclasses ) { 
long subclassRecs = schemaClass . count ( ) ; 
if ( subclassRecs > 0 ) { 
if ( subclass . isSubClassOf ( "V" ) ) { 
} else if ( subclass . isSubClassOf ( "E" ) ) { 
schemaClass . truncate ( ) ; 
invalidateCommandCache ( schemaClass ) ; 
if ( deep ) { 
subclass . truncate ( ) ; 
invalidateCommandCache ( subclass ) ; 
return recs ; 
} List < ORID > getValues ( final int entryIndex ) { 
int entryPosition = getIntValue ( entryIndex * OIntegerSerializer . INT_SIZE + POSITIONS_ARRAY_OFFSET ) ; 
int nextItem = getIntValue ( entryPosition ) ; 
entryPosition += OIntegerSerializer . INT_SIZE ; 
int clusterId = getShortValue ( entryPosition ) ; 
long clusterPosition = getLongValue ( entryPosition + OShortSerializer . SHORT_SIZE ) ; 
final List < ORID > results = new ArrayList < > ( 8 ) ; 
results . add ( new ORecordId ( clusterId , clusterPosition ) ) ; 
while ( nextItem > 0 ) { 
final int nextNextItem = getIntValue ( nextItem ) ; 
final int nextItemSize = 0xFF & getByteValue ( nextItem + OIntegerSerializer . INT_SIZE ) ; 
for ( int i = 0 ; i < nextItemSize ; i ++ ) { 
clusterId = getShortValue ( nextItem + OIntegerSerializer . INT_SIZE + OByteSerializer . BYTE_SIZE + i * RID_SIZE ) ; 
clusterPosition = getLongValue ( 
nextItem + OIntegerSerializer . INT_SIZE + OShortSerializer . SHORT_SIZE + OByteSerializer . BYTE_SIZE + i * RID_SIZE ) ; 
nextItem = nextNextItem ; 
return results ; 
} public void createCluster ( final String className , final String clusterName ) { 
final ODatabaseDocumentInternal currentDB = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
final ODatabaseDocumentInternal sysdb = openSystemDatabase ( ) ; 
if ( ! sysdb . existsCluster ( clusterName ) ) { 
OSchema schema = sysdb . getMetadata ( ) . getSchema ( ) ; 
OClass cls = schema . getClass ( className ) ; 
if ( cls != null ) { 
cls . addCluster ( clusterName ) ; 
sysdb . close ( ) ; 
if ( currentDB != null ) 
ODatabaseRecordThreadLocal . instance ( ) . set ( currentDB ) ; 
ODatabaseRecordThreadLocal . instance ( ) . remove ( ) ; 
} public void freeCluster ( final int cid ) { 
final Set < ORID > toRemove = new HashSet < ORID > ( underlying . size ( ) / 2 ) ; 
final Set < ORID > keys = new HashSet < ORID > ( underlying . keys ( ) ) ; 
for ( final ORID id : keys ) 
if ( id . getClusterId ( ) == cid ) 
toRemove . add ( id ) ; 
for ( final ORID ridToRemove : toRemove ) 
underlying . remove ( ridToRemove ) ; 
} public void startup ( ) { 
underlying . startup ( ) ; 
Orient . instance ( ) . getProfiler ( ) 
public Object getValue ( ) { 
return getSize ( ) ; 
} , profilerMetadataPrefix + "current" ) ; 
underlying . shutdown ( ) ; 
if ( Orient . instance ( ) . getProfiler ( ) != null ) { 
Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + "enabled" ) ; 
Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + "current" ) ; 
Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + "max" ) ; 
} public static OScriptResultSet singleton ( Object entity , OScriptTransformer transformer ) { 
return new OScriptResultSet ( Collections . singletonList ( entity ) . iterator ( ) , transformer ) ; 
} public ORole grant ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { 
ORule rule = rules . get ( resourceGeneric ) ; 
if ( rule == null ) { 
rule = new ORule ( resourceGeneric , null , null ) ; 
rules . put ( resourceGeneric , rule ) ; 
rule . grantAccess ( resourceSpecific , iOperation ) ; 
updateRolesDocumentContent ( ) ; 
} public ORole revoke ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { 
if ( iOperation == PERMISSION_NONE ) 
rule . revokeAccess ( resourceSpecific , iOperation ) ; 
public void serializeInByteBufferObject ( Float object , ByteBuffer buffer , Object ... hints ) { 
buffer . putInt ( Float . floatToIntBits ( object ) ) ; 
public Float deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return Float . intBitsToFloat ( walChanges . getIntValue ( buffer , offset ) ) ; 
final ORecordAbstract record = ( ( OIdentifiable ) iRecord ) . getRecord ( ) ; 
if ( record instanceof ODocument && compiledFilter != null 
&& ! Boolean . TRUE . equals ( this . compiledFilter . evaluate ( record , ( ODocument ) record , getContext ( ) ) ) ) { 
if ( record . getIdentity ( ) . isValid ( ) ) { 
if ( ! unsafe && record instanceof ODocument ) { 
final OClass cls = ( ( ODocument ) record ) . getSchemaClass ( ) ; 
if ( cls . isSubClassOf ( "V" ) ) 
else if ( cls . isSubClassOf ( "E" ) ) 
record . delete ( ) ; 
recordCount ++ ; 
if ( lockStrategy . equalsIgnoreCase ( "RECORD" ) ) 
( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) ) . releaseWriteLock ( record . getIdentity ( ) ) ; 
} private void convertToModifiableResult ( OUpdateExecutionPlan plan , OCommandContext ctx , boolean profilingEnabled ) { 
plan . chain ( new ConvertToUpdatableResultStep ( ctx , profilingEnabled ) ) ; 
public void serializeInByteBufferObject ( Integer object , ByteBuffer buffer , Object ... hints ) { 
buffer . putInt ( object ) ; 
public Integer deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return walChanges . getIntValue ( buffer , offset ) ; 
} public void bindParameters ( final Map < Object , Object > iArgs ) { 
if ( parameterItems == null || iArgs == null || iArgs . size ( ) == 0 ) 
for ( int i = 0 ; i < parameterItems . size ( ) ; i ++ ) { 
OSQLFilterItemParameter value = parameterItems . get ( i ) ; 
if ( "?" . equals ( value . getName ( ) ) ) { 
value . setValue ( iArgs . get ( i ) ) ; 
value . setValue ( iArgs . get ( value . getName ( ) ) ) ; 
} private void convert ( final int iIndex ) { 
if ( converted ) 
Object o = list . get ( iIndex ) ; 
o = serializedList . get ( iIndex ) ; 
list . set ( iIndex , OObjectEntitySerializer . deserializeFieldValue ( deserializeClass , o ) ) ; 
} protected Iterable < OResultInternal > traversePatternEdge ( OIdentifiable startingPoint , OCommandContext iCommandContext ) { 
Iterable possibleResults = null ; 
if ( this . item . getFilter ( ) != null ) { 
String alias = getEndpointAlias ( ) ; 
Object matchedNodes = iCommandContext . getVariable ( MatchPrefetchStep . PREFETCHED_MATCH_ALIAS_PREFIX + alias ) ; 
if ( matchedNodes != null ) { 
if ( matchedNodes instanceof Iterable ) { 
possibleResults = ( Iterable ) matchedNodes ; 
possibleResults = Collections . singleton ( matchedNodes ) ; 
Object prevCurrent = iCommandContext . getVariable ( "$current" ) ; 
iCommandContext . setVariable ( "$current" , startingPoint ) ; 
Object qR ; 
qR = this . item . getMethod ( ) . execute ( startingPoint , possibleResults , iCommandContext ) ; 
iCommandContext . setVariable ( "$current" , prevCurrent ) ; 
if ( qR == null ) { 
return Collections . EMPTY_LIST ; 
if ( qR instanceof OIdentifiable ) { 
return Collections . singleton ( new OResultInternal ( ( OIdentifiable ) qR ) ) ; 
if ( qR instanceof Iterable ) { 
final Iterator < Object > iter = ( ( Iterable ) qR ) . iterator ( ) ; 
Iterable < OResultInternal > result = ( ) -> new Iterator < OResultInternal > ( ) { 
private OResultInternal nextElement ; 
public boolean hasNext ( ) { 
if ( nextElement == null ) { 
fetchNext ( ) ; 
return nextElement != null ; 
public OResultInternal next ( ) { 
throw new IllegalStateException ( ) ; 
OResultInternal res = nextElement ; 
nextElement = null ; 
public void fetchNext ( ) { 
Object o = iter . next ( ) ; 
if ( o instanceof OIdentifiable ) { 
nextElement = new OResultInternal ( ( OIdentifiable ) o ) ; 
} else if ( o instanceof OResultInternal ) { 
nextElement = ( OResultInternal ) o ; 
} else if ( o == null ) { 
throw new UnsupportedOperationException ( ) ; 
if ( o instanceof Number ) 
o = enumClass . getEnumConstants ( ) [ ( ( Number ) o ) . intValue ( ) ] ; 
o = Enum . valueOf ( enumClass , o . toString ( ) ) ; 
list . set ( iIndex , ( TYPE ) o ) ; 
} public static OType getType ( final String iValue ) { 
if ( iValue . length ( ) == 0 ) 
final char firstChar = iValue . charAt ( 0 ) ; 
if ( firstChar == ORID . PREFIX ) 
return OType . LINK ; 
else if ( firstChar == '\'' || firstChar == '"' ) 
return OType . STRING ; 
else if ( firstChar == OStringSerializerHelper . BINARY_BEGINEND ) 
return OType . BINARY ; 
else if ( firstChar == OStringSerializerHelper . EMBEDDED_BEGIN ) 
return OType . EMBEDDED ; 
else if ( firstChar == OStringSerializerHelper . LIST_BEGIN ) 
return OType . EMBEDDEDLIST ; 
else if ( firstChar == OStringSerializerHelper . SET_BEGIN ) 
return OType . EMBEDDEDSET ; 
else if ( firstChar == OStringSerializerHelper . MAP_BEGIN ) 
return OType . EMBEDDEDMAP ; 
else if ( firstChar == OStringSerializerHelper . CUSTOM_TYPE ) 
return OType . CUSTOM ; 
if ( iValue . equalsIgnoreCase ( "true" ) || iValue . equalsIgnoreCase ( "false" ) ) 
return OType . BOOLEAN ; 
boolean integer = true ; 
for ( int index = 0 ; index < iValue . length ( ) ; ++ index ) { 
final char c = iValue . charAt ( index ) ; 
if ( c < '0' || c > '9' ) 
if ( ( index == 0 && ( c == '+' || c == '-' ) ) ) 
else if ( c == DECIMAL_SEPARATOR ) 
integer = false ; 
if ( index > 0 ) 
if ( ! integer && c == 'E' ) { 
if ( index < iValue . length ( ) ) { 
if ( iValue . charAt ( index + 1 ) == '-' ) 
} else if ( c == 'f' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . FLOAT ; 
else if ( c == 'c' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . DECIMAL ; 
else if ( c == 'l' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . LONG ; 
else if ( c == 'd' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . DOUBLE ; 
else if ( c == 'b' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . BYTE ; 
else if ( c == 'a' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . DATE ; 
else if ( c == 't' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . DATETIME ; 
else if ( c == 's' ) 
return index != ( iValue . length ( ) - 1 ) ? OType . STRING : OType . SHORT ; 
else if ( c == 'e' ) { 
Double . parseDouble ( iValue ) ; 
return OType . DOUBLE ; 
} catch ( Exception ignore ) { 
if ( integer ) { 
final int numberLength = iValue . length ( ) ; 
if ( numberLength > MAX_INTEGER_DIGITS || ( numberLength == MAX_INTEGER_DIGITS && iValue . compareTo ( MAX_INTEGER_AS_STRING ) > 0 ) ) 
return OType . LONG ; 
return OType . INTEGER ; 
final double dou = Double . parseDouble ( iValue ) ; 
if ( dou <= Float . MAX_VALUE && dou >= Float . MIN_VALUE && Double . toString ( dou ) . equals ( Float . toString ( ( float ) dou ) ) 
&& new Double ( new Double ( dou ) . floatValue ( ) ) . doubleValue ( ) == dou ) { 
return OType . FLOAT ; 
} else if ( ! new Double ( dou ) . toString ( ) . equals ( iValue ) ) { 
return OType . DECIMAL ; 
} public static OType getType ( final String iValue , final char iCharType ) { 
if ( iCharType == 'f' ) 
else if ( iCharType == 'c' ) 
else if ( iCharType == 'l' ) 
else if ( iCharType == 'd' ) 
else if ( iCharType == 'b' ) { 
if ( iValue . length ( ) >= 1 && iValue . length ( ) <= 3 ) 
return OType . BYTE ; 
} else if ( iCharType == 'a' ) 
return OType . DATE ; 
else if ( iCharType == 't' ) 
return OType . DATETIME ; 
else if ( iCharType == 's' ) 
return OType . SHORT ; 
else if ( iCharType == 'e' ) 
else if ( iCharType == 'g' ) 
return OType . LINKBAG ; 
else if ( iCharType == 'z' ) 
return OType . LINKLIST ; 
else if ( iCharType == 'm' ) 
return OType . LINKMAP ; 
else if ( iCharType == 'x' ) 
else if ( iCharType == 'n' ) 
return OType . LINKSET ; 
else if ( iCharType == 'u' ) 
} public static Object getTypeValue ( final String iValue ) { 
if ( iValue == null || iValue . equalsIgnoreCase ( "NULL" ) ) 
if ( iValue . length ( ) > 1 ) 
if ( iValue . charAt ( 0 ) == '"' && iValue . charAt ( iValue . length ( ) - 1 ) == '"' ) 
return OStringSerializerHelper . decode ( iValue . substring ( 1 , iValue . length ( ) - 1 ) ) ; 
else if ( iValue . charAt ( 0 ) == OStringSerializerHelper . BINARY_BEGINEND 
&& iValue . charAt ( iValue . length ( ) - 1 ) == OStringSerializerHelper . BINARY_BEGINEND ) 
return OStringSerializerHelper . getBinaryContent ( iValue ) ; 
else if ( iValue . charAt ( 0 ) == OStringSerializerHelper . LIST_BEGIN 
&& iValue . charAt ( iValue . length ( ) - 1 ) == OStringSerializerHelper . LIST_END ) { 
final ArrayList < String > coll = new ArrayList < String > ( ) ; 
OStringSerializerHelper . getCollection ( iValue , 0 , coll , OStringSerializerHelper . LIST_BEGIN , 
OStringSerializerHelper . LIST_END , OStringSerializerHelper . COLLECTION_SEPARATOR ) ; 
return coll ; 
} else if ( iValue . charAt ( 0 ) == OStringSerializerHelper . SET_BEGIN 
&& iValue . charAt ( iValue . length ( ) - 1 ) == OStringSerializerHelper . SET_END ) { 
final Set < String > coll = new HashSet < String > ( ) ; 
OStringSerializerHelper . getCollection ( iValue , 0 , coll , OStringSerializerHelper . SET_BEGIN , OStringSerializerHelper . SET_END , 
OStringSerializerHelper . COLLECTION_SEPARATOR ) ; 
} else if ( iValue . charAt ( 0 ) == OStringSerializerHelper . MAP_BEGIN 
&& iValue . charAt ( iValue . length ( ) - 1 ) == OStringSerializerHelper . MAP_END ) { 
return OStringSerializerHelper . getMap ( iValue ) ; 
if ( iValue . charAt ( 0 ) == ORID . PREFIX ) 
return new ORecordId ( iValue ) ; 
char c ; 
boolean stringStarBySign = false ; 
c = iValue . charAt ( index ) ; 
if ( c < '0' || c > '9' ) { 
if ( ( index == 0 && ( c == '+' || c == '-' ) ) ) { 
stringStarBySign = true ; 
} else if ( c == DECIMAL_SEPARATOR ) 
if ( index > 0 ) { 
if ( index < iValue . length ( ) ) 
if ( iValue . charAt ( index ) == '-' ) 
final String v = iValue . substring ( 0 , index ) ; 
if ( c == 'f' ) 
return new Float ( v ) ; 
return new BigDecimal ( v ) ; 
return new Long ( v ) ; 
return new Double ( v ) ; 
return new Byte ( v ) ; 
else if ( c == 'a' || c == 't' ) 
return new Date ( Long . parseLong ( v ) ) ; 
return new Short ( v ) ; 
return iValue ; 
} else if ( stringStarBySign ) { 
stringStarBySign = false ; 
if ( stringStarBySign ) 
return new Integer ( iValue ) ; 
return new Long ( iValue ) ; 
} else if ( "NaN" . equals ( iValue ) || "Infinity" . equals ( iValue ) ) 
return new Double ( iValue ) ; 
return new BigDecimal ( iValue ) ; 
public void increment ( int hash ) { 
hash = spread ( hash ) ; 
final int start = ( hash & 3 ) << 2 ; 
final int index0 = indexOf ( hash , 0 ) ; 
final int index1 = indexOf ( hash , 1 ) ; 
final int index2 = indexOf ( hash , 2 ) ; 
final int index3 = indexOf ( hash , 3 ) ; 
boolean added = incrementAt ( index0 , start ) ; 
added |= incrementAt ( index1 , start + 1 ) ; 
added |= incrementAt ( index2 , start + 2 ) ; 
added |= incrementAt ( index3 , start + 3 ) ; 
if ( added && ( ++ size == sampleSize ) ) { 
reset ( ) ; 
} private boolean incrementAt ( final int i , final int j ) { 
final int offset = j << 2 ; 
final long mask = ( 0xfL << offset ) ; 
if ( ( table [ i ] & mask ) != mask ) { 
table [ i ] += ( 1L << offset ) ; 
} private void reset ( ) { 
for ( int i = 0 ; i < table . length ; i ++ ) { 
count += Long . bitCount ( table [ i ] & ONE_MASK ) ; 
table [ i ] = ( table [ i ] > > > 1 ) & RESET_MASK ; 
size = ( size > > > 1 ) - ( count > > > 2 ) ; 
} private int indexOf ( final int item , final int i ) { 
long hash = SEED [ i ] * item ; 
hash += hash > > 32 ; 
return ( ( int ) hash ) & tableMask ; 
} private int spread ( int x ) { 
x = ( ( x > > > 16 ) ^ x ) * 0x45d9f3b ; 
x = ( ( x > > > 16 ) ^ x ) * randomSeed ; 
return ( x > > > 16 ) ^ x ; 
} public OIndex < ? > createIndex ( final String iType ) { 
return owner . createIndex ( getFullName ( ) , iType , globalRef . getName ( ) ) ; 
public OPropertyImpl dropIndexes ( ) { 
getDatabase ( ) . checkSecurity ( ORule . ResourceGeneric . SCHEMA , ORole . PERMISSION_DELETE ) ; 
final ArrayList < OIndex < ? > > relatedIndexes = new ArrayList < OIndex < ? > > ( ) ; 
for ( final OIndex < ? > index : indexManager . getClassIndexes ( owner . getName ( ) ) ) { 
final OIndexDefinition definition = index . getDefinition ( ) ; 
if ( OCollections . indexOf ( definition . getFields ( ) , globalRef . getName ( ) , new OCaseInsentiveComparator ( ) ) > - 1 ) { 
if ( definition instanceof OPropertyIndexDefinition ) { 
relatedIndexes . add ( index ) ; 
for ( final OIndex < ? > index : relatedIndexes ) 
getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( index . getName ( ) ) ; 
public OIndex < ? > getIndex ( ) { 
Set < OIndex < ? > > indexes = owner . getInvolvedIndexes ( globalRef . getName ( ) ) ; 
if ( indexes != null && ! indexes . isEmpty ( ) ) 
return indexes . iterator ( ) . next ( ) ; 
} public OClass getLinkedClass ( ) { 
if ( linkedClass == null && linkedClassName != null ) 
linkedClass = owner . owner . getClass ( linkedClassName ) ; 
return linkedClass ; 
final OVertex vertex = getDatabase ( ) . newVertex ( clazz ) ; 
( ( ODocument ) vertex . getRecord ( ) ) . merge ( content , true , false ) ; 
} public void addKey ( final Object key ) { 
if ( key instanceof OCompositeKey ) { 
final OCompositeKey compositeKey = ( OCompositeKey ) key ; 
for ( final Object inKey : compositeKey . keys ) { 
addKey ( inKey ) ; 
keys . add ( key ) ; 
} public OIndex < ? > createIndex ( ODatabaseDocumentInternal database , final String iName , String type , 
final OIndexDefinition indexDefinition , final int [ ] clusterIdsToIndex , OProgressListener progressListener , ODocument metadata , 
String algorithm ) { 
if ( database . getTransaction ( ) . isActive ( ) ) 
final Character c = OSchemaShared . checkFieldNameIfValid ( iName ) ; 
if ( c != null ) 
if ( indexDefinition == null ) { 
final Locale locale = getServerLocale ( ) ; 
type = type . toUpperCase ( locale ) ; 
if ( algorithm == null ) { 
algorithm = OIndexes . chooseDefaultIndexAlgorithm ( type ) ; 
final String valueContainerAlgorithm = chooseContainerAlgorithm ( type ) ; 
final OIndexInternal < ? > index ; 
if ( indexes . containsKey ( iName ) ) 
if ( clusterIdsToIndex == null || clusterIdsToIndex . length == 0 ) { 
if ( metadata == null ) 
metadata = new ODocument ( ) . setTrackingChanges ( false ) ; 
final Object durable = metadata . field ( "durableInNonTxMode" ) ; 
if ( ! ( durable instanceof Boolean ) ) 
metadata . field ( "durableInNonTxMode" , true ) ; 
if ( metadata . field ( "trackMode" ) == null ) 
metadata . field ( "trackMode" , "FULL" ) ; 
index = OIndexes . createIndex ( getStorage ( ) , iName , type , algorithm , valueContainerAlgorithm , metadata , - 1 ) ; 
if ( progressListener == null ) 
progressListener = new OIndexRebuildOutputListener ( index ) ; 
final Set < String > clustersToIndex = findClustersByIds ( clusterIdsToIndex , database ) ; 
Object ignoreNullValues = metadata == null ? null : metadata . field ( "ignoreNullValues" ) ; 
if ( Boolean . TRUE . equals ( ignoreNullValues ) ) { 
indexDefinition . setNullValuesIgnored ( true ) ; 
} else if ( Boolean . FALSE . equals ( ignoreNullValues ) ) { 
indexDefinition . setNullValuesIgnored ( false ) ; 
indexDefinition . setNullValuesIgnored ( 
database . getConfiguration ( ) . getValueAsBoolean ( OGlobalConfiguration . INDEX_IGNORE_NULL_VALUES_DEFAULT ) ) ; 
final String clusterName = indexDefinition . getClassName ( ) != null ? defaultClusterName : manualClusterName ; 
index . create ( iName , indexDefinition , clusterName , clustersToIndex , true , progressListener ) ; 
addIndexInternal ( index ) ; 
if ( metadata != null ) { 
final ODocument config = index . getConfiguration ( ) ; 
config . field ( "metadata" , metadata , OType . EMBEDDED ) ; 
setDirty ( ) ; 
save ( ) ; 
notifyInvolvedClasses ( database , clusterIdsToIndex ) ; 
return preProcessBeforeReturn ( database , index ) ; 
internalAcquireExclusiveLock ( ) ; 
final OTrackedSet < ODocument > indexes = new OTrackedSet < > ( document ) ; 
for ( final OIndex < ? > i : this . indexes . values ( ) ) { 
indexes . add ( ( ( OIndexInternal < ? > ) i ) . updateConfiguration ( ) ) ; 
document . field ( CONFIG_INDEXES , indexes , OType . EMBEDDEDSET ) ; 
document . setDirty ( ) ; 
internalReleaseExclusiveLock ( ) ; 
} public void setServerRole ( final String iServerName , final ROLES role ) { 
synchronized ( configuration ) { 
ODocument servers = configuration . field ( SERVERS ) ; 
if ( servers == null ) { 
servers = new ODocument ( ) ; 
configuration . field ( SERVERS , servers , OType . EMBEDDED ) ; 
servers . field ( iServerName , role ) ; 
incrementVersion ( ) ; 
} public List < String > addNewNodeInServerList ( final String iNode ) { 
final List < String > changedPartitions = new ArrayList < String > ( ) ; 
for ( String clusterName : getClusterNames ( ) ) { 
final List < String > partitions = getClusterConfiguration ( clusterName ) . field ( SERVERS ) ; 
if ( partitions != null ) { 
final int newNodePos = partitions . indexOf ( OModifiableDistributedConfiguration . NEW_NODE_TAG ) ; 
if ( newNodePos > - 1 && ! partitions . contains ( iNode ) ) { 
partitions . add ( newNodePos , iNode ) ; 
changedPartitions . add ( clusterName ) ; 
if ( ! changedPartitions . isEmpty ( ) ) { 
if ( ! getRegisteredServers ( ) . contains ( iNode ) ) { 
if ( getNewNodeStrategy ( ) == NEW_NODE_STRATEGIES . STATIC ) { 
setServerRole ( iNode , getServerRole ( "*" ) ) ; 
return changedPartitions ; 
} public void setServerOwner ( final String iClusterName , final String iServerName ) { 
if ( iClusterName == null ) 
final ODocument clusters = configuration . field ( CLUSTERS ) ; 
ODocument cluster = clusters . field ( iClusterName ) ; 
if ( cluster == null ) 
cluster = createCluster ( iClusterName ) ; 
final String owner = cluster . field ( OWNER ) ; 
if ( owner != null && ! iServerName . equalsIgnoreCase ( owner ) ) 
List < String > serverList = getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; 
if ( serverList == null ) { 
serverList = initClusterServers ( cluster ) ; 
if ( ! serverList . isEmpty ( ) && serverList . get ( 0 ) . equals ( iServerName ) ) 
boolean removed = false ; 
for ( Iterator < String > it = serverList . iterator ( ) ; it . hasNext ( ) ; ) { 
if ( it . next ( ) . equals ( iServerName ) ) { 
removed = true ; 
if ( ! removed ) 
serverList . add ( 0 , iServerName ) ; 
} public List < String > removeServer ( final String iNode ) { 
final Collection < String > nodes = getClusterConfiguration ( clusterName ) . field ( SERVERS ) ; 
if ( nodes != null ) { 
for ( String node : nodes ) { 
if ( node . equals ( iNode ) ) { 
nodes . remove ( node ) ; 
} public List < String > setServerOffline ( final String iNode , final String newLockManagerServer ) { 
final String [ ] clusters = getClusterNames ( ) ; 
for ( String clusterName : clusters ) { 
final List < String > nodes = getClusterConfiguration ( clusterName ) . field ( SERVERS ) ; 
if ( nodes != null && nodes . size ( ) > 1 ) { 
final boolean newNodeRemoved = nodes . remove ( NEW_NODE_TAG ) ; 
nodes . add ( node ) ; 
if ( newNodeRemoved ) 
nodes . add ( NEW_NODE_TAG ) ; 
if ( newLockManagerServer != null ) { 
if ( nodes . remove ( newLockManagerServer ) ) 
nodes . add ( 0 , newLockManagerServer ) ; 
} public void configure ( OStorage iStorage , int iId , String iClusterName , Object ... iParameters ) { 
id = iId ; 
name = iClusterName ; 
} public void configure ( OStorage iStorage , OStorageClusterConfiguration iConfig ) throws IOException { 
id = iConfig . getId ( ) ; 
name = iConfig . getName ( ) ; 
} protected void removeListener ( final ORecordListener listener ) { 
if ( _listeners != null ) { 
_listeners . remove ( listener ) ; 
if ( _listeners . isEmpty ( ) ) 
_listeners = null ; 
} public ODistributedDatabaseImpl registerDatabase ( final String iDatabaseName , ODistributedConfiguration cfg ) { 
final ODistributedDatabaseImpl ddb = databases . get ( iDatabaseName ) ; 
if ( ddb != null ) 
return ddb ; 
return new ODistributedDatabaseImpl ( manager , this , iDatabaseName , cfg , manager . getServerInstance ( ) ) ; 
} public void dispatchResponseToThread ( final ODistributedResponse response ) { 
final long msgId = response . getRequestId ( ) . getMessageId ( ) ; 
final ODistributedResponseManager asynchMgr = responsesByRequestIds . get ( msgId ) ; 
if ( asynchMgr == null ) { 
if ( ODistributedServerLog . isDebugEnabled ( ) ) 
ODistributedServerLog . debug ( this , manager . getLocalNodeName ( ) , response . getExecutorNodeName ( ) , DIRECTION . IN , 
OGlobalConfiguration . DISTRIBUTED_ASYNCH_RESPONSES_TIMEOUT . getValueAsLong ( ) ) ; 
} else if ( asynchMgr . collectResponse ( response ) ) { 
responsesByRequestIds . remove ( msgId ) ; 
"distributed.node.msgReceived" ) ; 
Orient . instance ( ) . getProfiler ( ) . updateCounter ( "distributed.node." + response . getExecutorNodeName ( ) + ".msgReceived" , 
} public void timeoutRequest ( final long msgId ) { 
final ODistributedResponseManager asynchMgr = responsesByRequestIds . remove ( msgId ) ; 
if ( asynchMgr != null ) 
asynchMgr . timeout ( ) ; 
} public void internalCreate ( OrientDBConfig config , OSharedContext ctx ) { 
this . sharedContext = ctx ; 
this . status = STATUS . OPEN ; 
applyAttributes ( config ) ; 
applyListeners ( config ) ; 
metadata = new OMetadataDefault ( this ) ; 
installHooksEmbedded ( ) ; 
createMetadata ( ctx ) ; 
if ( this . getMetadata ( ) . getCommandCache ( ) . isEnabled ( ) ) 
registerHook ( new OCommandCacheHook ( this ) , ORecordHook . HOOK_POSITION . REGULAR ) ; 
} public ODatabaseDocumentInternal copy ( ) { 
ODatabaseDocumentEmbedded database = new ODatabaseDocumentEmbedded ( getSharedContext ( ) . getStorage ( ) ) ; 
database . init ( config , this . sharedContext ) ; 
String user ; 
if ( getUser ( ) != null ) { 
user = getUser ( ) . getName ( ) ; 
user = null ; 
database . internalOpen ( user , null , false ) ; 
database . callOnOpenListeners ( ) ; 
this . activateOnCurrentThread ( ) ; 
return database ; 
} public void executeDeleteRecord ( OIdentifiable record , final int iVersion , final boolean iRequired , final OPERATION_MODE iMode , 
boolean prohibitTombstones ) { 
checkOpenness ( ) ; 
checkIfActive ( ) ; 
final ORecordId rid = ( ORecordId ) record . getIdentity ( ) ; 
if ( rid == null ) 
throw new ODatabaseException ( 
if ( ! rid . isValid ( ) ) 
record = record . getRecord ( ) ; 
final OMicroTransaction microTx = beginMicroTransaction ( ) ; 
microTx . deleteRecord ( record . getRecord ( ) , iMode ) ; 
endMicroTransaction ( false ) ; 
endMicroTransaction ( true ) ; 
} public < RET extends ORecord > RET executeReadRecord ( final ORecordId rid , ORecord iRecord , final int recordVersion , 
final String fetchPlan , final boolean ignoreCache , final boolean iUpdateCache , final boolean loadTombstones , 
final OStorage . LOCKING_STRATEGY lockingStrategy , RecordReader recordReader ) { 
getMetadata ( ) . makeThreadLocalSchemaSnapshot ( ) ; 
ORecordSerializationContext . pushContext ( ) ; 
checkSecurity ( ORule . ResourceGeneric . CLUSTER , ORole . PERMISSION_READ , getClusterNameById ( rid . getClusterId ( ) ) ) ; 
assert ! ( getTransaction ( ) . isActive ( ) && ( microTransaction != null && microTransaction . isActive ( ) ) ) ; 
ORecord record = getTransaction ( ) . getRecord ( rid ) ; 
if ( record == OBasicTransaction . DELETED_RECORD ) 
if ( record == null ) { 
if ( microTransaction != null && microTransaction . isActive ( ) ) { 
record = microTransaction . getRecord ( rid ) ; 
if ( record == null && ! ignoreCache ) 
record = getLocalCache ( ) . findRecord ( rid ) ; 
if ( record != null ) { 
if ( iRecord != null ) { 
iRecord . fromStream ( record . toStream ( ) ) ; 
ORecordInternal . setVersion ( iRecord , record . getVersion ( ) ) ; 
record = iRecord ; 
OFetchHelper . checkFetchPlanValid ( fetchPlan ) ; 
if ( beforeReadOperations ( record ) ) 
if ( record . getInternalStatus ( ) == ORecordElement . STATUS . NOT_LOADED ) 
record . reload ( ) ; 
if ( lockingStrategy == OStorage . LOCKING_STRATEGY . KEEP_SHARED_LOCK ) { 
record . lock ( false ) ; 
} else if ( lockingStrategy == OStorage . LOCKING_STRATEGY . KEEP_EXCLUSIVE_LOCK ) { 
record . lock ( true ) ; 
afterReadOperations ( record ) ; 
if ( record instanceof ODocument ) 
ODocumentInternal . checkClass ( ( ODocument ) record , this ) ; 
return ( RET ) record ; 
final ORawBuffer recordBuffer ; 
recordBuffer = null ; 
int version ; 
if ( iRecord != null ) 
version = iRecord . getVersion ( ) ; 
version = recordVersion ; 
recordBuffer = recordReader . readRecord ( getStorage ( ) , rid , fetchPlan , ignoreCache , version ) ; 
if ( recordBuffer == null ) 
if ( iRecord == null || ORecordInternal . getRecordType ( iRecord ) != recordBuffer . recordType ) 
iRecord = Orient . instance ( ) . getRecordFactoryManager ( ) . newInstance ( recordBuffer . recordType , rid . getClusterId ( ) , this ) ; 
ORecordInternal . setRecordSerializer ( iRecord , getSerializer ( ) ) ; 
ORecordInternal . fill ( iRecord , rid , recordBuffer . version , recordBuffer . buffer , false , this ) ; 
if ( iRecord instanceof ODocument ) 
ODocumentInternal . checkClass ( ( ODocument ) iRecord , this ) ; 
if ( ORecordVersionHelper . isTombstone ( iRecord . getVersion ( ) ) ) 
return ( RET ) iRecord ; 
if ( beforeReadOperations ( iRecord ) ) 
iRecord . fromStream ( recordBuffer . buffer ) ; 
afterReadOperations ( iRecord ) ; 
if ( iUpdateCache ) 
getLocalCache ( ) . updateRecord ( iRecord ) ; 
} catch ( OOfflineClusterException t ) { 
throw t ; 
} catch ( ORecordNotFoundException t ) { 
} catch ( Exception t ) { 
if ( rid . isTemporary ( ) ) 
throw OException . wrapException ( new ODatabaseException ( 
+ ")" ) , t ) ; 
ORecordSerializationContext . pullContext ( ) ; 
getMetadata ( ) . clearThreadLocalSchemaSnapshot ( ) ; 
public void serializeInByteBufferObject ( Byte object , ByteBuffer buffer , Object ... hints ) { 
buffer . put ( object ) ; 
} public void notifySaved ( OBonsaiCollectionPointer newPointer ) { 
if ( newPointer . isValid ( ) ) { 
if ( isEmbedded ( ) ) { 
replaceWithSBTree ( newPointer ) ; 
( ( OSBTreeRidBag ) delegate ) . setCollectionPointer ( newPointer ) ; 
( ( OSBTreeRidBag ) delegate ) . clearChanges ( ) ; 
} public boolean tryMerge ( final ORidBag otherValue , boolean iMergeSingleItemsOfMultiValueFields ) { 
if ( ! isEmbedded ( ) && ! otherValue . isEmbedded ( ) ) { 
final OSBTreeRidBag thisTree = ( OSBTreeRidBag ) delegate ; 
final OSBTreeRidBag otherTree = ( OSBTreeRidBag ) otherValue . delegate ; 
if ( thisTree . getCollectionPointer ( ) . equals ( otherTree . getCollectionPointer ( ) ) ) { 
thisTree . mergeChanges ( otherTree ) ; 
uuid = otherValue . uuid ; 
} else if ( iMergeSingleItemsOfMultiValueFields ) { 
final Iterator < OIdentifiable > iter = otherValue . rawIterator ( ) ; 
final OIdentifiable value = iter . next ( ) ; 
final Iterator < OIdentifiable > localIter = rawIterator ( ) ; 
while ( localIter . hasNext ( ) ) { 
final OIdentifiable v = localIter . next ( ) ; 
if ( value . equals ( v ) ) { 
if ( ! found ) 
add ( value ) ; 
} private void replaceWithSBTree ( OBonsaiCollectionPointer pointer ) { 
delegate . requestDelete ( ) ; 
final OSBTreeRidBag treeBag = new OSBTreeRidBag ( ) ; 
treeBag . setCollectionPointer ( pointer ) ; 
treeBag . setOwner ( delegate . getOwner ( ) ) ; 
for ( OMultiValueChangeListener < OIdentifiable , OIdentifiable > listener : delegate . getChangeListeners ( ) ) 
treeBag . addChangeListener ( listener ) ; 
delegate = treeBag ; 
} public static Object transformResult ( Object result ) { 
if ( java8MethodIsArray == null || ! ( result instanceof Map ) ) { 
if ( ( Boolean ) java8MethodIsArray . invoke ( result ) ) { 
List < ? > partial = new ArrayList ( ( ( Map ) result ) . values ( ) ) ; 
List < Object > finalResult = new ArrayList < Object > ( ) ; 
for ( Object o : partial ) { 
finalResult . add ( transformResult ( o ) ) ; 
return finalResult ; 
Map < Object , Object > mapResult = ( Map ) result ; 
List < Object > keys = new ArrayList < Object > ( mapResult . keySet ( ) ) ; 
for ( Object key : keys ) { 
mapResult . put ( key , transformResult ( mapResult . get ( key ) ) ) ; 
return mapResult ; 
OLogManager . instance ( ) . error ( OCommandExecutorUtility . class , "" , e ) ; 
final int clusterId = database . getClusterIdByName ( clusterName ) ; 
if ( clusterId > - 1 ) 
if ( blob ) { 
if ( requestedId == - 1 ) { 
return database . addBlobCluster ( clusterName ) ; 
return database . addCluster ( clusterName ) ; 
return database . addCluster ( clusterName , requestedId , null ) ; 
lock ( ) ; 
if ( this . evictionTask != null ) { 
this . evictionTask . cancel ( ) ; 
for ( Entry < String , OReentrantResourcePool < String , DB > > pool : pools . entrySet ( ) ) { 
for ( DB db : pool . getValue ( ) . getResources ( ) ) { 
pool . getValue ( ) . close ( ) ; 
( ( ODatabasePooled ) db ) . forceClose ( ) ; 
OLogManager . instance ( ) . debug ( this , "OK" , db . getName ( ) ) ; 
unlock ( ) ; 
} public void onStorageUnregistered ( final OStorage iStorage ) { 
final String storageURL = iStorage . getURL ( ) ; 
Set < String > poolToClose = null ; 
for ( Entry < String , OReentrantResourcePool < String , DB > > e : pools . entrySet ( ) ) { 
final int pos = e . getKey ( ) . indexOf ( "@" ) ; 
final String dbName = e . getKey ( ) . substring ( pos + 1 ) ; 
if ( storageURL . equals ( dbName ) ) { 
if ( poolToClose == null ) 
poolToClose = new HashSet < String > ( ) ; 
poolToClose . add ( e . getKey ( ) ) ; 
if ( poolToClose != null ) 
for ( String pool : poolToClose ) 
remove ( pool ) ; 
} public static Set < String > getFunctionNames ( ) { 
final Set < String > types = new HashSet < String > ( ) ; 
final Iterator < OSQLFunctionFactory > ite = getFunctionFactories ( ) ; 
while ( ite . hasNext ( ) ) { 
types . addAll ( ite . next ( ) . getFunctionNames ( ) ) ; 
return types ; 
} public static Set < String > getCollateNames ( ) { 
final Iterator < OCollateFactory > ite = getCollateFactories ( ) ; 
types . addAll ( ite . next ( ) . getNames ( ) ) ; 
} public static Set < String > getCommandNames ( ) { 
final Iterator < OCommandExecutorSQLFactory > ite = getCommandFactories ( ) ; 
types . addAll ( ite . next ( ) . getCommandNames ( ) ) ; 
} private Tuple < Integer , OType > getFieldSizeAndTypeFromCurrentPosition ( BytesContainer bytes ) { 
int fieldSize = OVarIntSerializer . readAsInteger ( bytes ) ; 
OType type = readOType ( bytes , false ) ; 
return new Tuple < > ( fieldSize , type ) ; 
} public OHttpResponseWrapper writeStatus ( final int iHttpCode , final String iReason ) throws IOException { 
response . writeStatus ( iHttpCode , iReason ) ; 
} public OHttpResponseWrapper writeHeaders ( final String iContentType , final boolean iKeepAlive ) throws IOException { 
response . writeHeaders ( iContentType , iKeepAlive ) ; 
} public OHttpResponseWrapper writeRecords ( final Object iRecords , final String iFetchPlan ) throws IOException { 
response . writeRecords ( iRecords , iFetchPlan ) ; 
} public OHttpResponseWrapper writeRecord ( final ORecord iRecord , final String iFetchPlan ) throws IOException { 
response . writeRecord ( iRecord , iFetchPlan , null ) ; 
} public OHttpResponseWrapper send ( final int iCode , final String iReason , final String iContentType , final Object iContent ) 
response . send ( iCode , iReason , iContentType , iContent , null ) ; 
} public OHttpResponseWrapper sendStream ( final int iCode , final String iReason , final String iContentType , 
final InputStream iContent , final long iSize ) throws IOException { 
response . sendStream ( iCode , iReason , iContentType , iContent , iSize ) ; 
if ( currentRecord != null ) { 
public ORecordIteratorCluster < REC > begin ( ) { 
updateRangesOnLiveUpdate ( ) ; 
currentRecord = readCurrentRecord ( getRecord ( ) , + 1 ) ; 
public ORecordIteratorCluster < REC > setLiveUpdated ( boolean iLiveUpdated ) { 
firstClusterEntry = 0L ; 
final long [ ] range = database . getStorage ( ) . getClusterDataRange ( current . getClusterId ( ) ) ; 
firstClusterEntry = range [ 0 ] ; 
lastClusterEntry = range [ 1 ] ; 
totalAvailableRecords = database . countClusterElements ( current . getClusterId ( ) ) ; 
} public ODatabaseObject open ( String name , String user , String password ) { 
return new OObjectDatabaseTx ( ( ODatabaseDocumentInternal ) orientDB . open ( name , user , password ) ) ; 
} public void create ( String name , ODatabaseType type , OrientDBConfig config ) { 
orientDB . create ( name , type , config ) ; 
} public void setValue ( Object target , Object value , OCommandContext ctx ) { 
if ( target == null ) { 
if ( target . getClass ( ) . isArray ( ) ) { 
setArrayValue ( target , value , ctx ) ; 
} else if ( target instanceof List ) { 
setValue ( ( List ) target , value , ctx ) ; 
} else if ( OMultiValue . isMultiValue ( value ) ) { 
if ( isClosed ( ) ) 
if ( ownerPool != null && ownerPool . getConnectionsInCurrentThread ( getURL ( ) , userName ) > 1 ) { 
ownerPool . release ( this ) ; 
commit ( true ) ; 
callOnCloseListeners ( ) ; 
getLocalCache ( ) . clear ( ) ; 
if ( ownerPool != null ) { 
final ODatabaseDocumentPool localCopy = ownerPool ; 
ownerPool = null ; 
localCopy . release ( this ) ; 
public UUID listenForChanges ( ORidBag collection ) { 
UUID ownerUUID = collection . getTemporaryId ( ) ; 
if ( ownerUUID != null ) { 
final OBonsaiCollectionPointer pointer = collection . getPointer ( ) ; 
Map < UUID , OBonsaiCollectionPointer > changedPointers = collectionPointerChanges . get ( ) ; 
if ( pointer != null && pointer . isValid ( ) ) { 
changedPointers . put ( ownerUUID , pointer ) ; 
} public synchronized void processRequest ( final ODistributedRequest request , final boolean waitForAcceptingRequests ) { 
if ( ! running ) { 
final ORemoteTask task = request . getTask ( ) ; 
if ( waitForAcceptingRequests ) { 
waitIsReady ( task ) ; 
totalReceivedRequests . incrementAndGet ( ) ; 
final int [ ] partitionKeys = task . getPartitionKey ( ) ; 
request , databaseName , Arrays . toString ( partitionKeys ) , task ) ; 
if ( partitionKeys . length > 1 || partitionKeys [ 0 ] == - 1 ) { 
final Set < Integer > involvedWorkerQueues ; 
if ( partitionKeys . length > 1 ) 
involvedWorkerQueues = getInvolvedQueuesByPartitionKeys ( partitionKeys ) ; 
involvedWorkerQueues = ALL_QUEUES ; 
involvedWorkerQueues ) ; 
if ( involvedWorkerQueues . size ( ) == 1 ) 
processRequest ( involvedWorkerQueues . iterator ( ) . next ( ) , request ) ; 
ODistributedServerLog . debug ( this , localNodeName , null , DIRECTION . NONE , 
CyclicBarrier started = new CyclicBarrier ( involvedWorkerQueues . size ( ) ) ; 
CyclicBarrier finished = new CyclicBarrier ( involvedWorkerQueues . size ( ) ) ; 
for ( int queue : involvedWorkerQueues ) { 
ODistributedWorker worker = workerThreads . get ( queue ) ; 
OWaitPartitionsReadyTask waitRequest = new OWaitPartitionsReadyTask ( started , task , finished ) ; 
final ODistributedRequest syncRequest = new ODistributedRequest ( null , request . getId ( ) . getNodeId ( ) , 
request . getId ( ) . getMessageId ( ) , databaseName , waitRequest ) ; 
worker . processRequest ( syncRequest ) ; 
} else if ( partitionKeys . length == 1 && partitionKeys [ 0 ] == - 2 ) { 
for ( ODistributedWorker q : workerThreads ) { 
if ( q . isWaitingForNextRequest ( ) && q . localQueue . isEmpty ( ) ) { 
q . processRequest ( request ) ; 
if ( q . localQueue . isEmpty ( ) ) { 
workerThreads . get ( 0 ) . processRequest ( request ) ; 
} else if ( partitionKeys . length == 1 && partitionKeys [ 0 ] == - 3 ) { 
ODistributedServerLog . debug ( this , localNodeName , request . getTask ( ) . getNodeSource ( ) , DIRECTION . IN , 
lockThread . processRequest ( request ) ; 
} else if ( partitionKeys . length == 1 && partitionKeys [ 0 ] == - 4 ) { 
nowaitThread . processRequest ( request ) ; 
processRequest ( partitionKeys [ 0 ] , request ) ; 
} public void startComponentOperation ( String componentName , ComponentType type ) { 
final Component currentComponent = componentsStack . peek ( ) ; 
if ( currentComponent != null && componentName . equals ( currentComponent . name ) ) { 
currentComponent . operationCount ++ ; 
componentsStack . push ( new Component ( componentName , type ) ) ; 
} public void completeComponentOperation ( ) { 
if ( currentComponent == null ) 
currentComponent . operationCount -- ; 
if ( currentComponent . operationCount == 0 ) { 
final String componentName = currentComponent . name ; 
PerformanceCountersHolder cHolder = countersByComponent 
. computeIfAbsent ( componentName , k -> currentComponent . type . newCountersHolder ( ) ) ; 
cHolder . operationsCount ++ ; 
componentsStack . pop ( ) ; 
makeSnapshotIfNeeded ( - 1 ) ; 
} public long getReadSpeedFromCacheInPages ( String componentName ) { 
if ( componentName == null ) 
return performanceCountersHolder . getReadSpeedFromCacheInPages ( ) ; 
final PerformanceCountersHolder cHolder = countersByComponent . get ( componentName ) ; 
if ( cHolder != null ) 
return cHolder . getReadSpeedFromCacheInPages ( ) ; 
} public long getReadSpeedFromFileInPages ( String componentName ) { 
return performanceCountersHolder . getReadSpeedFromFileInPages ( ) ; 
return cHolder . getReadSpeedFromFileInPages ( ) ; 
} public long getAmountOfPagesReadFromCache ( String componentName ) { 
return performanceCountersHolder . getAmountOfPagesReadFromCache ( ) ; 
return cHolder . getAmountOfPagesReadFromCache ( ) ; 
} public long getAmountOfPagesReadFromFile ( String componentName ) { 
return performanceCountersHolder . getAmountOfPagesReadFromFile ( ) ; 
return cHolder . getAmountOfPagesReadFromFile ( ) ; 
} public long getWriteSpeedInCacheInPages ( String componentName ) { 
return performanceCountersHolder . getWriteSpeedInCacheInPages ( ) ; 
return cHolder . getWriteSpeedInCacheInPages ( ) ; 
} public long getAmountOfPagesWrittenInCache ( String componentName ) { 
return performanceCountersHolder . getAmountOfPagesWrittenInCache ( ) ; 
return cHolder . getAmountOfPagesWrittenInCache ( ) ; 
} public int getCacheHits ( String componentName ) { 
return performanceCountersHolder . getCacheHits ( ) ; 
return cHolder . getCacheHits ( ) ; 
} public long getAmountOfPagesPerOperation ( String componentName ) { 
if ( componentName == null ) { 
return cHolder . getAmountOfPagesPerOperation ( ) ; 
} public void pushComponentCounters ( Map < String , PerformanceCountersHolder > counters ) { 
if ( snapshot == null ) 
for ( Map . Entry < String , PerformanceCountersHolder > entry : snapshot . countersByComponent . entrySet ( ) ) { 
final String componentName = entry . getKey ( ) ; 
PerformanceCountersHolder holder = counters . computeIfAbsent ( componentName , k -> entry . getValue ( ) . newInstance ( ) ) ; 
entry . getValue ( ) . pushData ( holder ) ; 
} public WritCacheCountersHolder pushWriteCacheCounters ( WritCacheCountersHolder holder ) { 
return holder ; 
if ( snapshot . writCacheCountersHolder == null ) 
if ( holder == null ) 
holder = new WritCacheCountersHolder ( ) ; 
snapshot . writCacheCountersHolder . pushData ( holder ) ; 
} public StorageCountersHolder pushStorageCounters ( StorageCountersHolder holder ) { 
if ( snapshot . storageCountersHolder == null ) 
holder = new StorageCountersHolder ( ) ; 
snapshot . storageCountersHolder . pushData ( holder ) ; 
} public WALCountersHolder pushWALCounters ( WALCountersHolder holder ) { 
if ( snapshot . walCountersHolder == null ) 
holder = new WALCountersHolder ( ) ; 
snapshot . walCountersHolder . pushData ( holder ) ; 
} public void pushComponentCounters ( String name , PerformanceCountersHolder holder ) { 
final PerformanceCountersHolder countersHolder = snapshot . countersByComponent . get ( name ) ; 
if ( countersHolder != null ) { 
countersHolder . pushData ( holder ) ; 
} public ODocument toDocument ( ) { 
final ODocument document = performanceCountersHolder . toDocument ( ) ; 
document . field ( "commitTime" , getCommitTime ( ) , OType . LONG ) ; 
final Map < String , ODocument > countersMap = new HashMap < > ( ) ; 
for ( Map . Entry < String , PerformanceCountersHolder > entry : countersByComponent . entrySet ( ) ) { 
countersMap . put ( entry . getKey ( ) , entry . getValue ( ) . toDocument ( ) ) ; 
document . field ( "dataByComponent" , countersMap , OType . EMBEDDEDMAP ) ; 
if ( walCountersHolder != null ) { 
final ODocument wal = walCountersHolder . toDocument ( ) ; 
document . field ( "walData" , wal , OType . EMBEDDED ) ; 
} public void incrementPageAccessOnCacheLevel ( boolean cacheHit ) { 
performanceCountersHolder . cacheAccessCount ++ ; 
if ( cacheHit ) 
performanceCountersHolder . cacheHit ++ ; 
for ( Component component : componentsStack ) { 
final String componentName = component . name ; 
. computeIfAbsent ( componentName , k -> component . type . newCountersHolder ( ) ) ; 
cHolder . cacheAccessCount ++ ; 
cHolder . cacheHit ++ ; 
} public void stopWriteCacheFlushTimer ( int pagesFlushed ) { 
if ( writCacheCountersHolder == null ) 
writCacheCountersHolder = new WritCacheCountersHolder ( ) ; 
final long endTs = nanoTimer . getNano ( ) ; 
final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; 
writCacheCountersHolder . flushOperationsCount ++ ; 
writCacheCountersHolder . amountOfPagesFlushed += pagesFlushed ; 
writCacheCountersHolder . flushOperationsTime += timeDiff ; 
makeSnapshotIfNeeded ( endTs ) ; 
} public void stopFuzzyCheckpointTimer ( ) { 
writCacheCountersHolder . fuzzyCheckpointCount ++ ; 
writCacheCountersHolder . fuzzyCheckpointTime += timeDiff ; 
} public void stopPageReadFromCacheTimer ( ) { 
performanceCountersHolder . pageReadFromCacheTime += timeDiff ; 
performanceCountersHolder . pageReadFromCacheCount ++ ; 
cHolder . pageReadFromCacheTime += timeDiff ; 
cHolder . pageReadFromCacheCount ++ ; 
if ( currentComponent != null ) { 
PerformanceCountersHolder currentHolder = countersByComponent . get ( currentComponent . name ) ; 
if ( currentHolder . currentOperation != null ) { 
currentHolder . currentOperation . incrementOperationsCounter ( 1 , 0 ) ; 
} public void stopFullCheckpointTimer ( ) { 
if ( storageCountersHolder == null ) 
storageCountersHolder = new StorageCountersHolder ( ) ; 
storageCountersHolder . fullCheckpointOperationsCount ++ ; 
storageCountersHolder . fullCheckpointOperationsTime += timeDiff ; 
} public void stopPageWriteInCacheTimer ( ) { 
performanceCountersHolder . pageWriteToCacheTime += timeDiff ; 
performanceCountersHolder . pageWriteToCacheCount ++ ; 
cHolder . pageWriteToCacheTime += timeDiff ; 
cHolder . pageWriteToCacheCount ++ ; 
} public void stopCommitTimer ( ) { 
performanceCountersHolder . commitTime += timeDiff ; 
performanceCountersHolder . commitCount ++ ; 
} public void stopWALRecordTimer ( boolean isStartRecord , boolean isStopRecord ) { 
if ( walCountersHolder == null ) 
walCountersHolder = new WALCountersHolder ( ) ; 
walCountersHolder . logRecordCount ++ ; 
walCountersHolder . logRecordTime += timeDiff ; 
if ( isStartRecord ) { 
walCountersHolder . startRecordCount ++ ; 
walCountersHolder . startRecordTime += timeDiff ; 
} else if ( isStopRecord ) { 
walCountersHolder . stopRecordCount ++ ; 
walCountersHolder . stopRecordTime += timeDiff ; 
} public void stopWALFlushTimer ( ) { 
walCountersHolder . flushCount ++ ; 
walCountersHolder . flushTime += timeDiff ; 
} private void makeSnapshotIfNeeded ( long currentTime ) { 
if ( currentTime < 0 ) { 
currentTime = nanoTimer . getNano ( ) ; 
if ( lastSnapshotTimestamp == - 1 ) 
lastSnapshotTimestamp = 0 ; 
if ( lastSnapshotTimestamp < 0 || currentTime - lastSnapshotTimestamp >= intervalBetweenSnapshots ) { 
snapshot = new PerformanceSnapshot ( performanceCountersHolder , countersByComponent , writCacheCountersHolder , 
storageCountersHolder , walCountersHolder ) ; 
lastSnapshotTimestamp = currentTime ; 
if ( cleanUpInterval > 0 ) { 
if ( currentTime - lastCleanUpTimeStamp >= cleanUpInterval ) { 
performanceCountersHolder . clean ( ) ; 
for ( PerformanceCountersHolder pch : countersByComponent . values ( ) ) { 
pch . clean ( ) ; 
if ( writCacheCountersHolder != null ) 
writCacheCountersHolder . clean ( ) ; 
if ( storageCountersHolder != null ) 
storageCountersHolder . clean ( ) ; 
walCountersHolder . clean ( ) ; 
lastCleanUpTimeStamp = currentTime ; 
public void shutdown ( ) { 
MBeanServer mBeanServer = ManagementFactory . getPlatformMBeanServer ( ) ; 
if ( onProfiler != null ) 
if ( mBeanServer . isRegistered ( onProfiler ) ) 
mBeanServer . unregisterMBean ( onProfiler ) ; 
} public static OStatement get ( String statement , ODatabaseDocumentInternal db ) { 
return parse ( statement ) ; 
OStatementCache resource = db . getSharedContext ( ) . getStatementCache ( ) ; 
return resource . get ( statement ) ; 
} public OStatement get ( String statement ) { 
OStatement result ; 
synchronized ( map ) { 
result = map . remove ( statement ) ; 
if ( result != null ) { 
map . put ( statement , result ) ; 
result = parse ( statement ) ; 
} protected static OStatement parse ( String statement ) throws OCommandSQLParsingException { 
ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
InputStream is ; 
is = new ByteArrayInputStream ( statement . getBytes ( ) ) ; 
is = new ByteArrayInputStream ( statement . getBytes ( db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ) ; 
} catch ( UnsupportedEncodingException e2 ) { 
OStatement result = osql . parse ( ) ; 
result . originalStatement = statement ; 
throwParsingException ( e , statement ) ; 
} catch ( TokenMgrError e2 ) { 
throwParsingException ( e2 , statement ) ; 
} protected void start ( ) { 
initNetwork ( ) ; 
initReceiveMessages ( ) ; 
initDiscoveryPing ( ) ; 
initCheckLeader ( ) ; 
initCheckDisconnect ( ) ; 
} protected void initReceiveMessages ( ) throws IOException { 
messageThread = new Thread ( ( ) -> { 
while ( ! Thread . interrupted ( ) ) { 
receiveMessages ( ) ; 
messageThread . setName ( "OrientDB_DistributedDiscoveryThread" ) ; 
messageThread . setDaemon ( true ) ; 
messageThread . start ( ) ; 
} protected void initDiscoveryPing ( ) { 
discoveryTimer = new TimerTask ( ) { 
sendPing ( ) ; 
if ( running ) { 
taskScheduler . scheduleOnce ( discoveryTimer , discoveryPingIntervalMillis ) ; 
} protected void initCheckDisconnect ( ) { 
disconnectTimer = new TimerTask ( ) { 
checkIfKnownServersAreAlive ( ) ; 
taskScheduler . scheduleOnce ( disconnectTimer , discoveryPingIntervalMillis ) ; 
} private void initCheckLeader ( ) { 
checkerTimer = new TimerTask ( ) { 
checkLeader ( ) ; 
taskScheduler . scheduleOnce ( checkerTimer , checkLeaderIntervalMillis ) ; 
} protected byte [ ] serializeMessage ( OBroadcastMessage message ) throws Exception { 
ByteArrayOutputStream buffer = new ByteArrayOutputStream ( ) ; 
message . write ( new DataOutputStream ( buffer ) ) ; 
return encrypt ( buffer . toByteArray ( ) ) ; 
} private byte [ ] encrypt ( byte [ ] data ) throws Exception { 
if ( config . getGroupPassword ( ) == null ) { 
return data ; 
Cipher cipher = Cipher . getInstance ( "AES/CBC/PKCS5Padding" ) ; 
byte [ ] iv = cipher . getParameters ( ) . getParameterSpec ( IvParameterSpec . class ) . getIV ( ) ; 
IvParameterSpec ivSpec = new IvParameterSpec ( iv ) ; 
SecretKeySpec keySpec = new SecretKeySpec ( paddedPassword ( config . getGroupPassword ( ) ) , "AES" ) ; 
cipher . init ( Cipher . ENCRYPT_MODE , keySpec , ivSpec ) ; 
ByteArrayOutputStream stream = new ByteArrayOutputStream ( ) ; 
DataOutput output = new DataOutputStream ( stream ) ; 
output . writeInt ( iv . length ) ; 
output . write ( iv ) ; 
byte [ ] cypher = cipher . doFinal ( data ) ; 
output . writeInt ( cypher . length ) ; 
output . write ( cypher ) ; 
return stream . toByteArray ( ) ; 
} void removeRecord ( ) { 
checkIfAttached ( ) ; 
final OrientBaseGraph graph = getGraph ( ) ; 
graph . setCurrentGraphInThreadLocal ( ) ; 
graph . autoStartTransaction ( ) ; 
if ( checkDeletedInTx ( ) ) 
getRecord ( ) . load ( ) ; 
} catch ( ORecordNotFoundException e ) { 
graph . throwRecordNotFoundException ( getIdentity ( ) , e . getMessage ( ) ) ; 
getRecord ( ) . delete ( ) ; 
} public < T extends OrientElement > T setProperties ( final Object ... fields ) { 
setPropertiesInternal ( fields ) ; 
return ( T ) this ; 
} @ Override public void setProperty ( final String key , final Object value ) { 
validateProperty ( this , key , value ) ; 
if ( graph != null ) 
getRecord ( ) . field ( key , value ) ; 
} @ Override public < T > T removeProperty ( final String key ) { 
final Object oldValue = getRecord ( ) . removeField ( key ) ; 
return ( T ) oldValue ; 
} @ Override public < T > T getProperty ( final String key ) { 
if ( key == null ) 
if ( key . equals ( "_class" ) ) 
return ( T ) ODocumentInternal . getImmutableSchemaClass ( getRecord ( ) ) . getName ( ) ; 
else if ( key . equals ( "_version" ) ) 
return ( T ) new Integer ( getRecord ( ) . getVersion ( ) ) ; 
else if ( key . equals ( "_rid" ) ) 
return ( T ) rawElement . getIdentity ( ) . toString ( ) ; 
final ODocument record = getRecord ( ) ; 
final Object fieldValue = record . field ( key ) ; 
if ( graph != null && fieldValue instanceof OIdentifiable && ! ( ( ( OIdentifiable ) fieldValue ) . getRecord ( ) instanceof OBlob ) ) { 
ODocument fieldRecord = ( ( OIdentifiable ) fieldValue ) . getRecord ( ) ; 
if ( fieldRecord != null ) { 
final OClass schemaClass = fieldRecord . getSchemaClass ( ) ; 
if ( schemaClass != null && ( schemaClass . isVertexType ( ) || schemaClass . isEdgeType ( ) ) ) { 
return ( T ) graph . getElement ( fieldValue ) ; 
return ( T ) fieldValue ; 
} else if ( ! ( fieldValue instanceof Map ) && OMultiValue . isMultiValue ( fieldValue ) && OMultiValue 
. getFirstValue ( fieldValue ) instanceof OIdentifiable ) { 
final OIdentifiable firstValue = ( OIdentifiable ) OMultiValue . getFirstValue ( fieldValue ) ; 
if ( firstValue instanceof ODocument ) { 
final ODocument document = ( ODocument ) firstValue ; 
if ( document . getIdentity ( ) . getClusterId ( ) != - 2 && ( document . isEmbedded ( ) 
|| ODocumentInternal . getImmutableSchemaClass ( document ) == null ) ) 
return ( T ) new OrientElementIterable < OrientElement > ( graph , OMultiValue . getMultiValueIterable ( fieldValue ) ) ; 
} public void save ( final String iClusterName ) { 
final OrientBaseGraph graph = checkIfAttached ( ) ; 
if ( rawElement instanceof ODocument ) 
if ( iClusterName != null ) 
rawElement = ( ( ODocument ) rawElement ) . save ( iClusterName ) ; 
rawElement = ( ( ODocument ) rawElement ) . save ( ) ; 
} @ Override public OSerializableStream fromStream ( final byte [ ] stream ) throws OSerializationException { 
( ( ORecordId ) record . getIdentity ( ) ) . fromString ( new String ( stream ) ) ; 
} @ Override public ORID getIdentity ( ) { 
if ( rawElement == null ) 
return ORecordId . EMPTY_RECORD_ID ; 
final ORID rid = rawElement . getIdentity ( ) ; 
if ( ! rid . isValid ( ) ) { 
if ( graph != null ) { 
return rid ; 
} @ Override public ODocument getRecord ( ) { 
return ( ODocument ) rawElement ; 
final ODocument doc = rawElement . getRecord ( ) ; 
if ( doc == null ) 
rawElement = doc ; 
return doc ; 
} public OrientElement detach ( ) { 
getRecord ( ) . setLazyLoad ( false ) ; 
getRecord ( ) . fieldNames ( ) ; 
settings = graph . settings . copy ( ) ; 
graph = null ; 
classicDetachMode = true ; 
} public OrientElement attach ( final OrientBaseGraph iNewGraph ) { 
if ( iNewGraph == null ) 
graph = iNewGraph ; 
settings = graph . settings ; 
} public OrientBaseGraph getGraph ( ) { 
if ( classicDetachMode ) 
return graph ; 
OrientBaseGraph result = OrientBaseGraph . getActiveGraph ( ) ; 
if ( result == null && this . graph != null && ! graph . isClosed ( ) ) { 
result = graph ; 
} public final void validateProperty ( final Element element , final String key , final Object value ) throws IllegalArgumentException { 
if ( settings . isStandardElementConstraints ( ) && null == value ) 
throw ExceptionFactory . propertyValueCanNotBeNull ( ) ; 
if ( null == key ) 
throw ExceptionFactory . propertyKeyCanNotBeNull ( ) ; 
if ( settings . isStandardElementConstraints ( ) && key . equals ( StringFactory . ID ) ) 
throw ExceptionFactory . propertyKeyIdIsReserved ( ) ; 
if ( element instanceof Edge && key . equals ( StringFactory . LABEL ) ) 
throw ExceptionFactory . propertyKeyLabelIsReservedForEdges ( ) ; 
if ( key . isEmpty ( ) ) 
throw ExceptionFactory . propertyKeyCanNotBeEmpty ( ) ; 
} protected String checkForClassInSchema ( final String className ) { 
if ( className == null ) 
OrientBaseGraph graph = getGraph ( ) ; 
if ( graph == null ) 
return className ; 
final OSchema schema = graph . getRawGraph ( ) . getMetadata ( ) . getSchema ( ) ; 
if ( ! schema . existsClass ( className ) ) { 
graph . executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { 
@ Override public OClass call ( final OrientBaseGraph g ) { 
return schema . createClass ( className , schema . getClass ( getBaseClassName ( ) ) ) ; 
} catch ( OSchemaException e ) { 
if ( ! schema . existsClass ( className ) ) 
final OClass cls = schema . getClass ( className ) ; 
if ( ! cls . isSubClassOf ( getBaseClassName ( ) ) ) 
} protected < T extends OrientElement > T setPropertiesInternal ( final Object ... fields ) { 
if ( fields != null && fields . length > 0 && fields [ 0 ] != null ) { 
if ( fields . length == 1 ) { 
Object f = fields [ 0 ] ; 
if ( f instanceof Map < ? , ? > ) { 
for ( Map . Entry < Object , Object > entry : ( ( Map < Object , Object > ) f ) . entrySet ( ) ) 
setPropertyInternal ( this , ( ODocument ) rawElement . getRecord ( ) , entry . getKey ( ) . toString ( ) , entry . getValue ( ) ) ; 
} else if ( f instanceof Collection ) { 
for ( Object o : ( Collection ) f ) { 
if ( ! ( o instanceof OPair ) ) 
final OPair entry = ( OPair ) o ; 
if ( fields . length % 2 != 0 ) 
. toString ( fields ) ) ; 
for ( int i = 0 ; i < fields . length ; i += 2 ) 
setPropertyInternal ( this , ( ODocument ) rawElement . getRecord ( ) , fields [ i ] . toString ( ) , fields [ i + 1 ] ) ; 
} public < T extends Enum < T > > T getValueAsEnum ( final OGlobalConfiguration config , Class < T > enumType ) { 
final Object value ; 
if ( this . config != null && this . config . containsKey ( config . getKey ( ) ) ) { 
value = this . config . get ( config . getKey ( ) ) ; 
value = config . getValue ( ) ; 
if ( value == null ) 
if ( enumType . isAssignableFrom ( value . getClass ( ) ) ) { 
return enumType . cast ( value ) ; 
} else if ( value instanceof String ) { 
final String presentation = value . toString ( ) ; 
return Enum . valueOf ( enumType , presentation ) ; 
} public static OIndexCursor wrap ( OIndex < ? > source , OIndexCursor cursor , long indexRebuildVersion ) { 
if ( cursor instanceof OIndexChangesWrapper ) 
return cursor ; 
if ( cursor instanceof OSizeable ) { 
return new OIndexChangesSizeable ( source , cursor , indexRebuildVersion ) ; 
return new OIndexChangesWrapper ( source , cursor , indexRebuildVersion ) ; 
public Map . Entry < Object , OIdentifiable > nextEntry ( ) { 
if ( source . isRebuilding ( ) ) 
throwRebuildException ( ) ; 
final Map . Entry < Object , OIdentifiable > entry = delegate . nextEntry ( ) ; 
if ( source . getRebuildVersion ( ) != indexRebuildVersion ) 
public Set < OIdentifiable > toValues ( ) { 
final Set < OIdentifiable > values = delegate . toValues ( ) ; 
return values ; 
public Set < Map . Entry < Object , OIdentifiable > > toEntries ( ) { 
final Set < Map . Entry < Object , OIdentifiable > > entries = delegate . toEntries ( ) ; 
return entries ; 
public Set < Object > toKeys ( ) { 
final Set < Object > keys = delegate . toKeys ( ) ; 
return keys ; 
final boolean isNext = delegate . hasNext ( ) ; 
return isNext ; 
public OIdentifiable next ( ) { 
final OIdentifiable next = delegate . next ( ) ; 
return next ; 
} public OGraphMLReader defineVertexAttributeStrategy ( final String iAttributeName , final OGraphMLImportStrategy iStrategy ) { 
vertexPropsStrategy . put ( iAttributeName , iStrategy ) ; 
} public OGraphMLReader defineEdgeAttributeStrategy ( final String iAttributeName , final OGraphMLImportStrategy iStrategy ) { 
edgePropsStrategy . put ( iAttributeName , iStrategy ) ; 
} public void inputGraph ( final Graph inputGraph , final InputStream graphMLInputStream ) throws IOException { 
inputGraph ( inputGraph , graphMLInputStream , batchSize , vertexIdKey , edgeIdKey , edgeLabelKey ) ; 
} public void inputGraph ( final Graph inputGraph , final String filename ) throws IOException { 
inputGraph ( inputGraph , filename , batchSize , vertexIdKey , edgeIdKey , edgeLabelKey ) ; 
} public OGraphMLReader inputGraph ( final Graph inputGraph , final String filename , int bufferSize , String vertexIdKey , 
String edgeIdKey , String edgeLabelKey ) throws IOException { 
FileInputStream fis = new FileInputStream ( filename ) ; 
return inputGraph ( inputGraph , fis , bufferSize , vertexIdKey , edgeIdKey , edgeLabelKey ) ; 
} public OGraphMLReader inputGraph ( final Graph inputGraph , final InputStream graphMLInputStream , int bufferSize , String vertexIdKey , 
XMLInputFactory inputFactory = XMLInputFactory . newInstance ( ) ; 
XMLStreamReader reader = inputFactory . createXMLStreamReader ( graphMLInputStream ) ; 
final OrientBaseGraph graph = ( OrientBaseGraph ) inputGraph ; 
if ( storeVertexIds ) 
graph . setSaveOriginalIds ( storeVertexIds ) ; 
Map < String , String > keyIdMap = new HashMap < String , String > ( ) ; 
Map < String , String > keyTypesMaps = new HashMap < String , String > ( ) ; 
Map < String , ORID > vertexMappedIdMap = new HashMap < String , ORID > ( ) ; 
String vertexId = null ; 
Map < String , Object > vertexProps = null ; 
boolean inVertex = false ; 
String edgeId = null ; 
String edgeLabel = null ; 
String vertexLabel = null ; 
Vertex [ ] edgeEndVertices = null ; 
Map < String , Object > edgeProps = null ; 
boolean inEdge = false ; 
int bufferCounter = 0 ; 
while ( reader . hasNext ( ) ) { 
Integer eventType = reader . next ( ) ; 
if ( eventType . equals ( XMLEvent . START_ELEMENT ) ) { 
String elementName = reader . getName ( ) . getLocalPart ( ) ; 
if ( elementName . equals ( GraphMLTokens . KEY ) ) { 
String id = reader . getAttributeValue ( null , GraphMLTokens . ID ) ; 
String attributeName = reader . getAttributeValue ( null , GraphMLTokens . ATTR_NAME ) ; 
String attributeType = reader . getAttributeValue ( null , GraphMLTokens . ATTR_TYPE ) ; 
keyIdMap . put ( id , attributeName ) ; 
keyTypesMaps . put ( id , attributeType ) ; 
} else if ( elementName . equals ( GraphMLTokens . NODE ) ) { 
vertexId = reader . getAttributeValue ( null , GraphMLTokens . ID ) ; 
vertexLabel = reader . getAttributeValue ( null , LABELS ) ; 
if ( vertexLabel != null ) { 
if ( vertexLabel . startsWith ( ":" ) ) 
vertexLabel = vertexLabel . substring ( 1 ) ; 
final String [ ] vertexLabels = vertexLabel . split ( ":" ) ; 
vertexLabel = vertexId + ",class:" + vertexLabels [ vertexLabelIndex ] ; 
vertexLabel = vertexId ; 
inVertex = true ; 
vertexProps = new HashMap < String , Object > ( ) ; 
} else if ( elementName . equals ( GraphMLTokens . EDGE ) ) { 
edgeId = reader . getAttributeValue ( null , GraphMLTokens . ID ) ; 
edgeLabel = reader . getAttributeValue ( null , GraphMLTokens . LABEL ) ; 
edgeLabel = edgeLabel == null ? GraphMLTokens . _DEFAULT : edgeLabel ; 
String [ ] vertexIds = new String [ 2 ] ; 
vertexIds [ 0 ] = reader . getAttributeValue ( null , GraphMLTokens . SOURCE ) ; 
vertexIds [ 1 ] = reader . getAttributeValue ( null , GraphMLTokens . TARGET ) ; 
edgeEndVertices = new Vertex [ 2 ] ; 
for ( int i = 0 ; i < 2 ; i ++ ) { 
if ( vertexIdKey == null ) { 
edgeEndVertices [ i ] = null ; 
final Object vId = vertexMappedIdMap . get ( vertexIds [ i ] ) ; 
edgeEndVertices [ i ] = vId != null ? graph . getVertex ( vId ) : null ; 
if ( null == edgeEndVertices [ i ] ) { 
edgeEndVertices [ i ] = graph . addVertex ( vertexLabel ) ; 
if ( vertexIdKey != null ) { 
mapId ( vertexMappedIdMap , vertexIds [ i ] , ( ORID ) edgeEndVertices [ i ] . getId ( ) ) ; 
bufferCounter ++ ; 
printStatus ( reader , importedVertices , importedEdges ) ; 
inEdge = true ; 
vertexLabel = null ; 
edgeProps = new HashMap < String , Object > ( ) ; 
} else if ( elementName . equals ( GraphMLTokens . DATA ) ) { 
String key = reader . getAttributeValue ( null , GraphMLTokens . KEY ) ; 
String attributeName = keyIdMap . get ( key ) ; 
if ( attributeName == null ) 
attributeName = key ; 
String value = reader . getElementText ( ) ; 
if ( inVertex ) { 
if ( ( vertexIdKey != null ) && ( key . equals ( vertexIdKey ) ) ) { 
vertexId = value ; 
} else if ( attributeName . equalsIgnoreCase ( LABELS ) ) { 
final Object attrValue = typeCastValue ( key , value , keyTypesMaps ) ; 
final OGraphMLImportStrategy strategy = vertexPropsStrategy . get ( attributeName ) ; 
if ( strategy != null ) { 
attributeName = strategy . transformAttribute ( attributeName , attrValue ) ; 
if ( attributeName != null ) 
vertexProps . put ( attributeName , attrValue ) ; 
} else if ( inEdge ) { 
if ( ( edgeLabelKey != null ) && ( key . equals ( edgeLabelKey ) ) ) 
edgeLabel = value ; 
else if ( ( edgeIdKey != null ) && ( key . equals ( edgeIdKey ) ) ) 
edgeId = value ; 
final OGraphMLImportStrategy strategy = edgePropsStrategy . get ( attributeName ) ; 
edgeProps . put ( attributeName , attrValue ) ; 
} else if ( eventType . equals ( XMLEvent . END_ELEMENT ) ) { 
if ( elementName . equals ( GraphMLTokens . NODE ) ) { 
ORID currentVertex = null ; 
if ( vertexIdKey != null ) 
currentVertex = vertexMappedIdMap . get ( vertexId ) ; 
if ( currentVertex == null ) { 
final OrientVertex v = graph . addVertex ( vertexLabel , vertexProps ) ; 
mapId ( vertexMappedIdMap , vertexId , v . getIdentity ( ) ) ; 
final OrientVertex v = graph . getVertex ( currentVertex ) ; 
v . setProperties ( vertexProps ) ; 
vertexId = null ; 
vertexProps = null ; 
inVertex = false ; 
Edge currentEdge = ( ( OrientVertex ) edgeEndVertices [ 0 ] ) . addEdge ( null , ( OrientVertex ) edgeEndVertices [ 1 ] , edgeLabel , null , 
edgeProps ) ; 
edgeId = null ; 
edgeLabel = null ; 
edgeEndVertices = null ; 
edgeProps = null ; 
inEdge = false ; 
if ( bufferCounter > bufferSize ) { 
bufferCounter = 0 ; 
reader . close ( ) ; 
} catch ( Exception xse ) { 
} public OGraphMLReader inputGraph ( final InputStream graphMLInputStream ) throws IOException { 
return inputGraph ( this . graph , graphMLInputStream , batchSize , this . vertexIdKey , this . edgeIdKey , this . edgeLabelKey ) ; 
} public OGraphMLReader inputGraph ( final String filename ) throws IOException { 
return inputGraph ( this . graph , filename , batchSize , this . vertexIdKey , this . edgeIdKey , this . edgeLabelKey ) ; 
public void serializeInByteBufferObject ( Date object , ByteBuffer buffer , Object ... hints ) { 
final Calendar calendar = Calendar . getInstance ( ) ; 
calendar . setTime ( object ) ; 
calendar . set ( Calendar . HOUR_OF_DAY , 0 ) ; 
calendar . set ( Calendar . MINUTE , 0 ) ; 
calendar . set ( Calendar . SECOND , 0 ) ; 
calendar . set ( Calendar . MILLISECOND , 0 ) ; 
final ODateTimeSerializer dateTimeSerializer = ODateTimeSerializer . INSTANCE ; 
dateTimeSerializer . serializeInByteBufferObject ( calendar . getTime ( ) , buffer ) ; 
public Date deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
return dateTimeSerializer . deserializeFromByteBufferObject ( buffer ) ; 
public Date deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return dateTimeSerializer . deserializeFromByteBufferObject ( buffer , walChanges , offset ) ; 
} public List < ORecordOperation > getNewRecordEntriesByClass ( final OClass iClass , final boolean iPolymorphic ) { 
final List < ORecordOperation > result = new ArrayList < ORecordOperation > ( ) ; 
if ( iClass == null ) 
for ( ORecordOperation entry : allEntries . values ( ) ) { 
if ( entry . type == ORecordOperation . CREATED ) 
result . add ( entry ) ; 
if ( entry . getRecord ( ) != null && entry . getRecord ( ) instanceof ODocument ) { 
if ( iPolymorphic ) { 
if ( iClass . isSuperClassOf ( ( ( ODocument ) entry . getRecord ( ) ) . getSchemaClass ( ) ) ) 
} else if ( iClass . getName ( ) . equals ( ( ( ODocument ) entry . getRecord ( ) ) . getClassName ( ) ) ) 
} public List < ORecordOperation > getNewRecordEntriesByClusterIds ( final int [ ] iIds ) { 
if ( iIds == null ) 
for ( int id : iIds ) { 
if ( entry . getRecord ( ) != null && entry . getRecord ( ) . getIdentity ( ) . getClusterId ( ) == id 
&& entry . type == ORecordOperation . CREATED ) { 
} public void addIndexEntry ( final OIndex < ? > delegate , final String iIndexName , final OTransactionIndexChanges . OPERATION iOperation , 
final Object key , final OIdentifiable iValue , boolean clientTrackOnly ) { 
OTransactionIndexChanges indexEntry = indexEntries . get ( iIndexName ) ; 
if ( indexEntry == null ) { 
indexEntry = new OTransactionIndexChanges ( ) ; 
indexEntries . put ( iIndexName , indexEntry ) ; 
if ( iOperation == OPERATION . CLEAR ) 
indexEntry . setCleared ( ) ; 
OTransactionIndexChangesPerKey changes = indexEntry . getChangesPerKey ( key ) ; 
changes . clientTrackOnly = clientTrackOnly ; 
changes . add ( iValue , iOperation ) ; 
if ( iValue == null ) 
List < OTransactionRecordIndexOperation > transactionIndexOperations = recordIndexOperations . get ( iValue . getIdentity ( ) ) ; 
if ( transactionIndexOperations == null ) { 
transactionIndexOperations = new ArrayList < OTransactionRecordIndexOperation > ( ) ; 
recordIndexOperations . put ( iValue . getIdentity ( ) . copy ( ) , transactionIndexOperations ) ; 
transactionIndexOperations . add ( new OTransactionRecordIndexOperation ( iIndexName , key , iOperation ) ) ; 
} private static Set < ORecord > mergeSet ( Set < ORecord > target , Set < ORecord > source ) { 
if ( source != null ) { 
if ( target . size ( ) > source . size ( ) ) { 
target . addAll ( source ) ; 
return target ; 
source . addAll ( target ) ; 
} public String authenticate ( final String username , final String password ) { 
String principal = null ; 
if ( getServerConfig ( ) != null ) { 
OServerUserConfiguration userCfg = null ; 
if ( username != null && ! username . isEmpty ( ) ) 
userCfg = getServerConfig ( ) . getUser ( username ) ; 
if ( userCfg != null && userCfg . password != null ) { 
if ( OSecurityManager . instance ( ) . checkPassword ( password , userCfg . password ) ) { 
principal = userCfg . name ; 
OLogManager . instance ( ) . error ( this , "OServerConfigAuthenticator.authenticate()" , ex ) ; 
return principal ; 
} public void config ( final OServer oServer , final OServerConfigurationManager serverCfg , final ODocument jsonConfig ) { 
super . config ( oServer , serverCfg , jsonConfig ) ; 
} public OServerUserConfiguration getUser ( final String username ) { 
return userCfg ; 
} public boolean isAuthorized ( final String username , final String resource ) { 
if ( username == null || resource == null ) 
if ( ! username . isEmpty ( ) ) { 
OServerUserConfiguration userCfg = getServerConfig ( ) . getUser ( username ) ; 
if ( userCfg != null ) { 
if ( userCfg . resources . equals ( "*" ) ) 
String [ ] resourceParts = userCfg . resources . split ( "," ) ; 
for ( String r : resourceParts ) { 
if ( r . equalsIgnoreCase ( resource ) ) 
} @ SuppressWarnings ( "unchecked" ) public boolean result ( final Object iRecord ) { 
final ODocument record = ( ( OIdentifiable ) iRecord ) . getRecord ( ) ; 
if ( isUpdateEdge ( ) && ! isRecordInstanceOf ( iRecord , "E" ) ) { 
if ( ! ( Boolean ) compiledFilter . evaluate ( record , null , context ) ) 
parameters . reset ( ) ; 
returnHandler . beforeUpdate ( record ) ; 
boolean updated = handleContent ( record ) ; 
updated |= handleMerge ( record ) ; 
updated |= handleSetEntries ( record ) ; 
updated |= handleIncrementEntries ( record ) ; 
updated |= handleAddEntries ( record ) ; 
updated |= handlePutEntries ( record ) ; 
updated |= handleRemoveEntries ( record ) ; 
if ( updated ) { 
handleUpdateEdge ( record ) ; 
record . setDirty ( ) ; 
record . save ( ) ; 
returnHandler . afterUpdate ( record ) ; 
this . updated = true ; 
if ( ! updateEdge ) { 
} protected void parseReturn ( ) throws OCommandSQLParsingException { 
String mode = parserGetLastWord ( ) . trim ( ) ; 
if ( mode . equalsIgnoreCase ( "COUNT" ) ) { 
returnHandler = new ORecordCountHandler ( ) ; 
} else if ( mode . equalsIgnoreCase ( "BEFORE" ) || mode . equalsIgnoreCase ( "AFTER" ) ) { 
String returning = parserGetLastWord ( ) . trim ( ) ; 
Object returnExpression = null ; 
if ( returning . equalsIgnoreCase ( KEYWORD_WHERE ) || returning . equalsIgnoreCase ( KEYWORD_TIMEOUT ) || returning 
. equalsIgnoreCase ( KEYWORD_LIMIT ) || returning . equalsIgnoreCase ( KEYWORD_UPSERT ) || returning . equalsIgnoreCase ( KEYWORD_LOCK ) 
|| returning . length ( ) == 0 ) { 
if ( returning . startsWith ( "$" ) || returning . startsWith ( "@" ) ) 
returnExpression = ( returning . length ( ) > 0 ) ? OSQLHelper . parseValue ( this , returning , this . getContext ( ) ) : null ; 
if ( mode . equalsIgnoreCase ( "BEFORE" ) ) 
returnHandler = new OOriginalRecordsReturnHandler ( returnExpression , getContext ( ) ) ; 
returnHandler = new OUpdatedRecordsReturnHandler ( returnExpression , getContext ( ) ) ; 
} public Iterable < OIdentifiable > executeIndexedFunction ( OFromClause target , OCommandContext ctx , OBinaryCompareOperator operator , 
Object rightValue ) { 
OSQLFunction function = OSQLEngine . getInstance ( ) . getFunction ( name . getStringValue ( ) ) ; 
if ( function instanceof OIndexableSQLFunction ) { 
return ( ( OIndexableSQLFunction ) function ) 
. searchFromTarget ( target , operator , rightValue , ctx , this . getParams ( ) . toArray ( new OExpression [ ] { } ) ) ; 
} public long estimateIndexedFunction ( OFromClause target , OCommandContext ctx , OBinaryCompareOperator operator , Object rightValue ) { 
. estimate ( target , operator , rightValue , ctx , this . getParams ( ) . toArray ( new OExpression [ ] { } ) ) ; 
. canExecuteInline ( target , operator , right , context , this . getParams ( ) . toArray ( new OExpression [ ] { } ) ) ; 
public void serializeInByteBufferObject ( OIndexRIDContainer object , ByteBuffer buffer , Object ... hints ) { 
buffer . putLong ( object . getFileId ( ) ) ; 
final boolean embedded = object . isEmbedded ( ) ; 
final boolean durable = object . isDurableNonTxMode ( ) ; 
buffer . put ( ( byte ) ( embedded ? 1 : 0 ) ) ; 
buffer . put ( ( byte ) ( durable ? 1 : 0 ) ) ; 
if ( embedded ) { 
buffer . putInt ( object . size ( ) ) ; 
for ( OIdentifiable ids : object ) { 
LINK_SERIALIZER . serializeInByteBufferObject ( ids , buffer ) ; 
final OIndexRIDContainerSBTree underlying = ( OIndexRIDContainerSBTree ) object . getUnderlying ( ) ; 
final OBonsaiBucketPointer rootPointer = underlying . getRootPointer ( ) ; 
buffer . putLong ( rootPointer . getPageIndex ( ) ) ; 
buffer . putInt ( rootPointer . getPageOffset ( ) ) ; 
public OIndexRIDContainer deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final long fileId = buffer . getLong ( ) ; 
final boolean embedded = buffer . get ( ) > 0 ; 
final boolean durable = buffer . get ( ) > 0 ; 
final int size = buffer . getInt ( ) ; 
final Set < OIdentifiable > underlying = new HashSet < OIdentifiable > ( Math . max ( ( int ) ( size / .75f ) + 1 , 16 ) ) ; 
underlying . add ( LINK_SERIALIZER . deserializeFromByteBufferObject ( buffer ) ) ; 
return new OIndexRIDContainer ( fileId , underlying , durable ) ; 
final long pageIndex = buffer . getLong ( ) ; 
final int pageOffset = buffer . getInt ( ) ; 
final OBonsaiBucketPointer rootPointer = new OBonsaiBucketPointer ( pageIndex , pageOffset ) ; 
final ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; 
final OIndexRIDContainerSBTree underlying = new OIndexRIDContainerSBTree ( fileId , rootPointer , 
( OAbstractPaginatedStorage ) db . getStorage ( ) . getUnderlying ( ) ) ; 
final int offset = buffer . position ( ) ; 
buffer . position ( ) ; 
if ( buffer . get ( offset + EMBEDDED_OFFSET ) > 0 ) { 
return embeddedObjectSerializedSize ( buffer . getInt ( offset + EMBEDDED_SIZE_OFFSET ) ) ; 
return SBTREE_CONTAINER_SIZE ; 
public OIndexRIDContainer deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final long fileId = walChanges . getLongValue ( buffer , offset + FILE_ID_OFFSET ) ; 
final boolean durable = walChanges . getByteValue ( buffer , offset + DURABLE_OFFSET ) > 0 ; 
if ( walChanges . getByteValue ( buffer , offset + EMBEDDED_OFFSET ) > 0 ) { 
final int size = walChanges . getIntValue ( buffer , offset + EMBEDDED_SIZE_OFFSET ) ; 
int p = offset + EMBEDDED_VALUES_OFFSET ; 
underlying . add ( LINK_SERIALIZER . deserializeFromByteBufferObject ( buffer , walChanges , p ) ) ; 
p += RID_SIZE ; 
final long pageIndex = walChanges . getLongValue ( buffer , offset + SBTREE_ROOTINDEX_OFFSET ) ; 
final int pageOffset = walChanges . getIntValue ( buffer , offset + SBTREE_ROOTOFFSET_OFFSET ) ; 
return embeddedObjectSerializedSize ( walChanges . getIntValue ( buffer , offset + EMBEDDED_SIZE_OFFSET ) ) ; 
} public ODatabaseSession open ( String database , String user , String password ) { 
return open ( database , user , password , OrientDBConfig . defaultConfig ( ) ) ; 
} public ODatabaseSession open ( String database , String user , String password , OrientDBConfig config ) { 
return internal . open ( database , user , password , config ) ; 
} public void create ( String database , ODatabaseType type ) { 
create ( database , type , OrientDBConfig . defaultConfig ( ) ) ; 
} public void create ( String database , ODatabaseType type , OrientDBConfig config ) { 
this . internal . create ( database , serverUser , serverPassword , type , config ) ; 
} public boolean createIfNotExists ( String database , ODatabaseType type ) { 
return createIfNotExists ( database , type , OrientDBConfig . defaultConfig ( ) ) ; 
} public boolean createIfNotExists ( String database , ODatabaseType type , OrientDBConfig config ) { 
if ( ! this . internal . exists ( database , serverUser , serverPassword ) ) { 
} public static < T > Collection < OChainedIndexProxy < T > > createProxies ( OClass iSchemaClass , OSQLFilterItemField . FieldChain longChain ) { 
List < OChainedIndexProxy < T > > proxies = new ArrayList < OChainedIndexProxy < T > > ( ) ; 
for ( List < OIndex < ? > > indexChain : getIndexesForChain ( iSchemaClass , longChain ) ) { 
proxies . add ( new OChainedIndexProxy < T > ( indexChain ) ) ; 
return proxies ; 
} protected static OIndex < ? > findBestIndex ( Iterable < OIndex < ? > > indexes ) { 
OIndex < ? > bestIndex = null ; 
for ( OIndex < ? > index : indexes ) { 
if ( priorityOfUsage ( index ) > priorityOfUsage ( bestIndex ) ) 
bestIndex = index ; 
return bestIndex ; 
public long getRebuildVersion ( ) { 
long rebuildVersion = 0 ; 
for ( OIndex < ? > index : indexChain ) { 
rebuildVersion += index . getRebuildVersion ( ) ; 
return rebuildVersion ; 
public T get ( Object iKey ) { 
final Object lastIndexResult = lastIndex . get ( iKey ) ; 
final Set < OIdentifiable > result = new HashSet < OIdentifiable > ( ) ; 
if ( lastIndexResult != null ) 
result . addAll ( applyTailIndexes ( lastIndexResult ) ) ; 
return ( T ) result ; 
} private Set < Comparable > prepareKeys ( OIndex < ? > index , Object keys ) { 
final OIndexDefinition indexDefinition = index . getDefinition ( ) ; 
if ( keys instanceof Collection ) { 
final Set < Comparable > newKeys = new TreeSet < Comparable > ( ) ; 
for ( Object o : ( ( Collection ) keys ) ) { 
newKeys . add ( ( Comparable ) indexDefinition . createValue ( o ) ) ; 
return newKeys ; 
return Collections . singleton ( ( Comparable ) indexDefinition . createValue ( keys ) ) ; 
} private void updateStatistic ( OIndex < ? > index ) { 
final OProfiler profiler = Orient . instance ( ) . getProfiler ( ) ; 
if ( profiler . isRecording ( ) ) { 
final int paramCount = index . getDefinition ( ) . getParamCount ( ) ; 
if ( paramCount > 1 ) { 
final String profiler_prefix = profiler . getDatabaseMetric ( index . getDatabaseName ( ) , "query.compositeIndexUsed" ) ; 
profiler 
} void writePage ( ByteBuffer page , long pageIndex ) throws IOException { 
synchronized ( lockObject ) { 
lastAccessTime = System . nanoTime ( ) ; 
if ( pageIndex >= firstCachedPage && pageIndex <= firstCachedPage + pageCache . size ( ) ) { 
if ( pageIndex < firstCachedPage + pageCache . size ( ) ) { 
pageCache . set ( ( int ) ( pageIndex - firstCachedPage ) , page ) ; 
pageCache . add ( page ) ; 
} else if ( pageCache . isEmpty ( ) ) { 
firstCachedPage = pageIndex ; 
lastWrittenPage = page ; 
lastWrittenPageIndex = pageIndex ; 
if ( pageCache . size ( ) * OWALPage . PAGE_SIZE >= bufferSize + OWALPage . PAGE_SIZE ) { 
flushAllBufferPagesExceptLastOne ( ) ; 
} byte [ ] readPage ( long pageIndex ) throws IOException { 
if ( pageIndex == lastWrittenPageIndex ) { 
return lastWrittenPage . array ( ) ; 
if ( pageIndex >= firstCachedPage && pageIndex < firstCachedPage + pageCache . size ( ) ) { 
final ByteBuffer buffer = pageCache . get ( ( int ) ( pageIndex - firstCachedPage ) ) ; 
return buffer . array ( ) ; 
final ByteBuffer buffer = ByteBuffer . allocate ( OWALPage . PAGE_SIZE ) . order ( ByteOrder . nativeOrder ( ) ) ; 
initFile ( ) ; 
segChannel . position ( pageIndex * OWALPage . PAGE_SIZE ) ; 
readByteBuffer ( buffer , segChannel ) ; 
} void truncate ( long pageIndex ) throws IOException { 
flushBuffer ( ) ; 
lastWrittenPageIndex = - 1 ; 
lastWrittenPage = null ; 
segChannel . truncate ( pageIndex * OWALPage . PAGE_SIZE ) ; 
} ByteBuffer readPageBuffer ( long pageIndex ) throws IOException { 
final ByteBuffer copy = ByteBuffer . allocate ( OWALPage . PAGE_SIZE ) . order ( ByteOrder . nativeOrder ( ) ) ; 
lastWrittenPage . position ( 0 ) ; 
copy . put ( lastWrittenPage ) ; 
return copy ; 
copy . put ( buffer ) ; 
} public void sync ( ) throws IOException { 
if ( segChannel != null ) { 
segChannel . force ( false ) ; 
} public void close ( boolean flush ) { 
closer . shutdown ( ) ; 
if ( ! closer . awaitTermination ( CLOSER_TIMEOUT_MIN , TimeUnit . MINUTES ) ) { 
closeFile ( flush ) ; 
} catch ( InterruptedException ie ) { 
} public void open ( ) throws IOException { 
long pagesCount = segChannel . size ( ) / OWALPage . PAGE_SIZE ; 
if ( segChannel . size ( ) % OWALPage . PAGE_SIZE > 0 ) { 
segChannel . truncate ( OWALPage . PAGE_SIZE * pagesCount ) ; 
firstCachedPage = - 1 ; 
pageCache . clear ( ) ; 
public byte [ ] getRecord ( int position ) { 
buffer . position ( position + 2 ) ; 
final int recordSize = buffer . getInt ( ) ; 
final byte [ ] record = new byte [ recordSize ] ; 
buffer . get ( record ) ; 
} public boolean isReplicationActive ( final String iClusterName , final String iLocalNode ) { 
final Collection < String > servers = getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; 
if ( servers != null && ! servers . isEmpty ( ) ) { 
} public NEW_NODE_STRATEGIES getNewNodeStrategy ( ) { 
final String value = configuration . field ( NEW_NODE_STRATEGY ) ; 
if ( value != null ) 
return NEW_NODE_STRATEGIES . valueOf ( value . toUpperCase ( Locale . ENGLISH ) ) ; 
return NEW_NODE_STRATEGIES . STATIC ; 
} public Boolean isExecutionModeSynchronous ( final String iClusterName ) { 
Object value = getClusterConfiguration ( iClusterName ) . field ( EXECUTION_MODE ) ; 
value = configuration . field ( EXECUTION_MODE ) ; 
if ( value . toString ( ) . equalsIgnoreCase ( "undefined" ) ) 
return value . toString ( ) . equalsIgnoreCase ( EXECUTION_MODE_SYNCHRONOUS ) ; 
} public Boolean isReadYourWrites ( final String iClusterName ) { 
Object value = getClusterConfiguration ( iClusterName ) . field ( READ_YOUR_WRITES ) ; 
value = configuration . field ( READ_YOUR_WRITES ) ; 
return ( Boolean ) value ; 
} public Map < String , Collection < String > > getServerClusterMap ( Collection < String > iClusterNames , final String iLocalNode , 
final boolean optimizeForLocalOnly ) { 
if ( iClusterNames == null || iClusterNames . isEmpty ( ) ) 
iClusterNames = DEFAULT_CLUSTER_NAME ; 
final Map < String , Collection < String > > servers = new HashMap < String , Collection < String > > ( iClusterNames . size ( ) ) ; 
boolean canUseLocalNode = true ; 
for ( String p : iClusterNames ) { 
final List < String > serverList = getClusterConfiguration ( p ) . field ( SERVERS ) ; 
if ( serverList != null && ! serverList . contains ( iLocalNode ) ) { 
canUseLocalNode = false ; 
if ( optimizeForLocalOnly && canUseLocalNode ) { 
servers . put ( iLocalNode , iClusterNames ) ; 
return servers ; 
final Map < String , Collection < String > > serverMap = new HashMap < String , Collection < String > > ( ) ; 
for ( String s : serverList ) { 
if ( NEW_NODE_TAG . equalsIgnoreCase ( s ) ) 
Collection < String > clustersInServer = serverMap . get ( s ) ; 
if ( clustersInServer == null ) { 
clustersInServer = new HashSet < String > ( ) ; 
serverMap . put ( s , clustersInServer ) ; 
clustersInServer . add ( p ) ; 
if ( serverMap . size ( ) == 1 ) 
return serverMap ; 
if ( ! optimizeForLocalOnly ) 
final List < String > orderedServers = new ArrayList < String > ( serverMap . keySet ( ) ) ; 
Collections . sort ( orderedServers , new Comparator < String > ( ) { 
public int compare ( final String o1 , final String o2 ) { 
return ( ( Integer ) serverMap . get ( o2 ) . size ( ) ) . compareTo ( ( Integer ) serverMap . get ( o1 ) . size ( ) ) ; 
final Set < String > remainingClusters = new HashSet < String > ( iClusterNames ) ; 
final Set < String > includedClusters = new HashSet < String > ( iClusterNames . size ( ) ) ; 
for ( String s : orderedServers ) { 
final Collection < String > clusters = serverMap . get ( s ) ; 
if ( ! servers . isEmpty ( ) ) { 
clusters . removeAll ( includedClusters ) ; 
servers . put ( s , clusters ) ; 
remainingClusters . removeAll ( clusters ) ; 
includedClusters . addAll ( clusters ) ; 
if ( remainingClusters . isEmpty ( ) ) 
} public List < String > getOwnedClustersByServer ( Collection < String > iClusterNames , final String iNode ) { 
final List < String > notDefinedClusters = new ArrayList < String > ( 5 ) ; 
final List < String > candidates = new ArrayList < String > ( 5 ) ; 
if ( p == null ) 
final String ownerServer = getClusterOwner ( p ) ; 
if ( ownerServer == null ) 
notDefinedClusters . add ( p ) ; 
else if ( iNode . equals ( ownerServer ) ) { 
candidates . add ( p ) ; 
if ( ! candidates . isEmpty ( ) ) 
return candidates ; 
final String owner = getClusterOwner ( ALL_WILDCARD ) ; 
if ( iNode . equals ( owner ) ) 
return notDefinedClusters ; 
} public Set < String > getServers ( Collection < String > iClusterNames ) { 
return getAllConfiguredServers ( ) ; 
final Set < String > partitions = new HashSet < String > ( iClusterNames . size ( ) ) ; 
if ( serverList != null ) { 
for ( String s : serverList ) 
if ( ! s . equals ( NEW_NODE_TAG ) ) 
partitions . add ( s ) ; 
} public boolean isServerContainingAllClusters ( final String server , Collection < String > clusters ) { 
if ( clusters == null || clusters . isEmpty ( ) ) 
clusters = DEFAULT_CLUSTER_NAME ; 
for ( String cluster : clusters ) { 
final List < String > serverList = getClusterConfiguration ( cluster ) . field ( SERVERS ) ; 
if ( ! serverList . contains ( server ) ) 
} public boolean isServerContainingCluster ( final String server , String cluster ) { 
cluster = ALL_WILDCARD ; 
return serverList . contains ( server ) ; 
} public List < String > getServers ( final String iClusterName , final String iExclude ) { 
final List < String > serverList = getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; 
List < String > filteredServerList = new ArrayList < String > ( serverList . size ( ) ) ; 
if ( ! s . equals ( NEW_NODE_TAG ) && ( iExclude == null || ! iExclude . equals ( s ) ) ) 
filteredServerList . add ( s ) ; 
return filteredServerList ; 
} public List < String > getMasterServers ( ) { 
final List < String > serverList = getClusterConfiguration ( null ) . field ( SERVERS ) ; 
List < String > masters = new ArrayList < String > ( serverList . size ( ) ) ; 
masters . add ( s ) ; 
final ROLES defRole = getDefaultServerRole ( ) ; 
final ODocument servers = configuration . field ( SERVERS ) ; 
if ( servers != null ) { 
for ( Iterator < String > it = masters . iterator ( ) ; it . hasNext ( ) ; ) { 
final String server = it . next ( ) ; 
final String roleAsString = servers . field ( server ) ; 
final ROLES role = roleAsString != null ? ROLES . valueOf ( roleAsString . toUpperCase ( Locale . ENGLISH ) ) : defRole ; 
if ( role != ROLES . MASTER ) 
return masters ; 
} public Set < String > getAllConfiguredServers ( ) { 
final Set < String > servers = new HashSet < String > ( ) ; 
for ( String p : getClusterNames ( ) ) { 
servers . add ( s ) ; 
} public Set < String > getClustersOnServer ( final String iNodeName ) { 
final Set < String > clusters = new HashSet < String > ( ) ; 
for ( String cl : getClusterNames ( ) ) { 
final List < String > servers = getServers ( cl , null ) ; 
if ( servers . contains ( iNodeName ) ) 
clusters . add ( cl ) ; 
return clusters ; 
} public Set < String > getClustersOwnedByServer ( final String iNodeName ) { 
if ( iNodeName . equals ( getClusterOwner ( cl ) ) ) 
} public String getClusterOwner ( final String iClusterName ) { 
String owner ; 
final ODocument clusters = getConfiguredClusters ( ) ; 
final ODocument cfg = iClusterName != null ? ( ODocument ) clusters . field ( iClusterName ) : null ; 
owner = cfg . field ( OWNER ) ; 
if ( owner != null ) 
return owner ; 
final List < String > serverList = cfg . field ( SERVERS ) ; 
if ( serverList != null && ! serverList . isEmpty ( ) ) { 
owner = serverList . get ( 0 ) ; 
if ( NEW_NODE_TAG . equals ( owner ) && serverList . size ( ) > 1 ) 
owner = serverList . get ( 1 ) ; 
return getClusterOwner ( ALL_WILDCARD ) ; 
} public String getConfiguredClusterOwner ( final String iClusterName ) { 
String owner = null ; 
final ODocument cfg = clusters . field ( iClusterName ) ; 
if ( cfg != null ) 
} public List < String > getConfiguredServers ( final String iClusterName ) { 
final Collection < ? extends String > list = ( Collection < ? extends String > ) getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; 
return list != null ? new ArrayList < String > ( list ) : null ; 
} public ROLES getServerRole ( final String iServerName ) { 
if ( servers == null ) 
return ROLES . MASTER ; 
String role = servers . field ( iServerName ) ; 
if ( role == null ) { 
role = servers . field ( ALL_WILDCARD ) ; 
return ROLES . valueOf ( role . toUpperCase ( Locale . ENGLISH ) ) ; 
} public Set < String > getRegisteredServers ( ) { 
final Set < String > result = new HashSet < String > ( ) ; 
if ( servers != null ) 
for ( String s : servers . fieldNames ( ) ) 
result . add ( s ) ; 
} public Set < String > getDataCenters ( ) { 
final ODocument dcs = configuration . field ( DCS ) ; 
if ( dcs == null ) 
for ( String dc : dcs . fieldNames ( ) ) { 
result . add ( dc ) ; 
} public int getDataCenterWriteQuorum ( final String dataCenter ) { 
final ODocument dc = getDataCenterConfiguration ( dataCenter ) ; 
Object wq = dc . field ( WRITE_QUORUM ) ; 
if ( wq instanceof String ) { 
if ( wq . toString ( ) . equalsIgnoreCase ( ODistributedConfiguration . QUORUM_MAJORITY ) ) { 
final List < String > servers = dc . field ( SERVERS ) ; 
wq = servers . size ( ) / 2 + 1 ; 
} else if ( wq . toString ( ) . equalsIgnoreCase ( ODistributedConfiguration . QUORUM_ALL ) ) { 
wq = servers . size ( ) ; 
return ( Integer ) wq ; 
} public boolean isSharded ( ) { 
final ODocument allCluster = getClusterConfiguration ( ALL_WILDCARD ) ; 
if ( allCluster != null ) { 
final List < String > allServers = allCluster . field ( SERVERS ) ; 
if ( allServers != null && ! allServers . isEmpty ( ) ) { 
if ( servers != null && ! servers . isEmpty ( ) && ! allServers . containsAll ( servers ) ) 
} public List < String > getDataCenterServers ( final String dataCenter ) { 
if ( servers == null || servers . isEmpty ( ) ) 
throw new OConfigurationException ( 
return new ArrayList < String > ( servers ) ; 
} public String getDataCenterOfServer ( final String server ) { 
if ( dcs != null ) { 
final ODocument dcConfig = dcs . field ( dc ) ; 
if ( dcConfig != null ) { 
final List < String > dcServers = dcConfig . field ( "servers" ) ; 
if ( dcServers != null && ! dcServers . isEmpty ( ) ) { 
if ( dcServers . contains ( server ) ) 
return dc ; 
} public Object getGlobalReadQuorum ( final String iClusterName ) { 
Object value = getClusterConfiguration ( iClusterName ) . field ( READ_QUORUM ) ; 
value = configuration . field ( READ_QUORUM ) ; 
} public int getReadQuorum ( final String clusterName , final int totalConfiguredServers , final String server ) { 
return getQuorum ( "readQuorum" , clusterName , totalConfiguredServers , DEFAULT_READ_QUORUM , server ) ; 
} public int getWriteQuorum ( final String clusterName , final int totalConfiguredMasterServers , final String server ) { 
Integer overWrite = overwriteWriteQuorum . get ( ) ; 
if ( overWrite != null ) 
return overWrite . intValue ( ) ; 
return getQuorum ( "writeQuorum" , clusterName , totalConfiguredMasterServers , DEFAULT_WRITE_QUORUM , server ) ; 
} protected ODocument getClusterConfiguration ( String iClusterName ) { 
iClusterName = ALL_WILDCARD ; 
final ODocument cfg ; 
if ( ! clusters . containsField ( iClusterName ) ) 
cfg = clusters . field ( ALL_WILDCARD ) ; 
cfg = clusters . field ( iClusterName ) ; 
if ( cfg == null ) 
return new ODocument ( ) ; 
return cfg ; 
} private ODocument getDataCenterConfiguration ( final String dataCenter ) { 
if ( dcs != null ) 
return dcs . field ( dataCenter ) ; 
} private int getQuorum ( final String quorumSetting , final String iClusterName , final int totalServers , final Object defaultValue , 
final String server ) { 
Object value = getClusterConfiguration ( iClusterName ) . field ( quorumSetting ) ; 
value = configuration . field ( quorumSetting ) ; 
value = defaultValue ; 
if ( value instanceof String ) { 
if ( value . toString ( ) . equalsIgnoreCase ( QUORUM_MAJORITY ) ) 
value = totalServers / 2 + 1 ; 
else if ( value . toString ( ) . equalsIgnoreCase ( QUORUM_ALL ) ) 
value = totalServers ; 
else if ( value . toString ( ) . equalsIgnoreCase ( QUORUM_LOCAL_DC ) ) { 
final String dc = getDataCenterOfServer ( server ) ; 
if ( dc == null ) 
value = getDataCenterWriteQuorum ( dc ) ; 
return ( Integer ) value ; 
} public static void clearInitStack ( ) { 
final ThreadLocal < Deque < OrientBaseGraph > > is = initializationStack ; 
if ( is != null ) 
is . get ( ) . clear ( ) ; 
final ThreadLocal < OrientBaseGraph > ag = activeGraph ; 
if ( ag != null ) 
ag . remove ( ) ; 
} public static void encodeClassNames ( final String ... iLabels ) { 
if ( iLabels != null ) 
for ( int i = 0 ; i < iLabels . length ; ++ i ) 
iLabels [ i ] = encodeClassName ( iLabels [ i ] ) ; 
} public static void getEdgeClassNames ( final OrientBaseGraph graph , final String ... iLabels ) { 
if ( iLabels != null && graph != null && graph . isUseClassForEdgeLabel ( ) ) { 
for ( int i = 0 ; i < iLabels . length ; ++ i ) { 
final OrientEdgeType edgeType = graph . getEdgeType ( iLabels [ i ] ) ; 
if ( edgeType != null ) 
iLabels [ i ] = edgeType . getName ( ) ; 
} public static String encodeClassName ( String iClassName ) { 
if ( iClassName == null ) 
if ( Character . isDigit ( iClassName . charAt ( 0 ) ) ) 
iClassName = "-" + iClassName ; 
return URLEncoder . encode ( iClassName , "UTF-8" ) . replaceAll ( "\\." , "%2E" ) ; 
return iClassName ; 
} public static String decodeClassName ( String iClassName ) { 
if ( iClassName . charAt ( 0 ) == '-' ) 
iClassName = iClassName . substring ( 1 ) ; 
return URLDecoder . decode ( iClassName , "UTF-8" ) ; 
} public OrientBaseGraph configure ( final Settings iSetting ) { 
if ( iSetting != null ) { 
if ( settings == null ) { 
settings = iSetting ; 
settings . copyFrom ( iSetting ) ; 
public < T extends Element > Index < T > getIndex ( final String indexName , final Class < T > indexClass ) { 
final OIndex idx = indexManager . getIndex ( indexName ) ; 
if ( idx == null || ! hasIndexClass ( idx ) ) 
final Index < ? extends Element > index = new OrientIndex ( this , idx ) ; 
if ( indexClass . isAssignableFrom ( index . getIndexClass ( ) ) ) 
return ( Index < T > ) index ; 
throw ExceptionFactory . indexDoesNotSupportClass ( indexName , indexClass ) ; 
} public void dropIndex ( final String indexName ) { 
executeOutsideTx ( new OCallable < Object , OrientBaseGraph > ( ) { 
public Object call ( OrientBaseGraph g ) { 
final OIndexManager indexManager = getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) ; 
final OIndex index = indexManager . getIndex ( indexName ) ; 
ODocument metadata = index . getConfiguration ( ) . field ( "metadata" ) ; 
String recordMapIndexName = null ; 
recordMapIndexName = metadata . field ( OrientIndex . CONFIG_RECORD_MAP_NAME ) ; 
indexManager . dropIndex ( indexName ) ; 
if ( recordMapIndexName != null ) 
getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( recordMapIndexName ) ; 
saveIndexConfiguration ( ) ; 
g . rollback ( ) ; 
throw new RuntimeException ( e . getMessage ( ) , e ) ; 
public OrientVertex addVertex ( final Object id ) { 
return addVertex ( id , ( Object [ ] ) null ) ; 
} public OrientVertex addVertex ( Object id , final Object ... prop ) { 
String className = null ; 
String clusterName = null ; 
Object [ ] fields = null ; 
if ( id instanceof String ) { 
final String [ ] args = ( ( String ) id ) . split ( "," ) ; 
for ( String s : args ) { 
if ( s . startsWith ( CLASS_PREFIX ) ) 
className = s . substring ( CLASS_PREFIX . length ( ) ) ; 
else if ( s . startsWith ( CLUSTER_PREFIX ) ) 
clusterName = s . substring ( CLUSTER_PREFIX . length ( ) ) ; 
id = s ; 
if ( isSaveOriginalIds ( ) ) 
fields = new Object [ ] { OrientElement . DEF_ORIGINAL_ID_FIELDNAME , id } ; 
setCurrentGraphInThreadLocal ( ) ; 
autoStartTransaction ( ) ; 
final OrientVertex vertex = getVertexInstance ( className , fields ) ; 
vertex . setPropertiesInternal ( prop ) ; 
return vertex ; 
} public OrientVertex addVertex ( final String iClassName , final String iClusterName ) { 
final OrientVertex vertex = getVertexInstance ( iClassName ) ; 
vertex . save ( iClusterName ) ; 
} public OrientVertex addTemporaryVertex ( final String iClassName , final Object ... prop ) { 
public OrientEdge addEdge ( final Object id , Vertex outVertex , Vertex inVertex , final String label ) { 
final Object [ ] fields = isSaveOriginalIds ( ) && id != null ? new Object [ ] { OrientElement . DEF_ORIGINAL_ID_FIELDNAME , id } : null ; 
if ( outVertex instanceof PartitionVertex ) 
outVertex = ( ( PartitionVertex ) outVertex ) . getBaseVertex ( ) ; 
if ( inVertex instanceof PartitionVertex ) 
inVertex = ( ( PartitionVertex ) inVertex ) . getBaseVertex ( ) ; 
return ( ( OrientVertex ) outVertex ) . addEdge ( label , ( OrientVertex ) inVertex , className , clusterName , fields ) ; 
} public OrientVertex getVertex ( final Object id ) { 
if ( null == id ) 
throw ExceptionFactory . vertexIdCanNotBeNull ( ) ; 
if ( id instanceof OrientVertex ) 
return ( OrientVertex ) id ; 
else if ( id instanceof ODocument ) 
return getVertexInstance ( ( OIdentifiable ) id ) ; 
ORID rid ; 
if ( id instanceof OIdentifiable ) 
rid = ( ( OIdentifiable ) id ) . getIdentity ( ) ; 
rid = new ORecordId ( id . toString ( ) ) ; 
} catch ( IllegalArgumentException iae ) { 
final ORecord rec = rid . getRecord ( ) ; 
if ( rec == null || ! ( rec instanceof ODocument ) ) 
final OClass cls = ( ( ODocument ) rec ) . getSchemaClass ( ) ; 
if ( cls != null && cls . isEdgeType ( ) ) 
return getVertexInstance ( rec ) ; 
} public Iterable < Vertex > getVerticesOfClass ( final String iClassName , final boolean iPolymorphic ) { 
final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iClassName ) ; 
if ( cls == null ) 
if ( ! cls . isSubClassOf ( OrientVertexType . CLASS_NAME ) ) 
return new OrientElementScanIterable < Vertex > ( this , iClassName , iPolymorphic ) ; 
} public Iterable < Vertex > getVertices ( final String iKey , Object iValue ) { 
if ( iKey . equals ( "@class" ) ) 
return getVerticesOfClass ( iValue . toString ( ) ) ; 
int pos = iKey . indexOf ( '.' ) ; 
final String className = pos > - 1 ? iKey . substring ( 0 , pos ) : OrientVertexType . CLASS_NAME ; 
final String key = pos > - 1 ? iKey . substring ( pos + 1 ) : iKey ; 
OClass clazz = getDatabase ( ) . getMetadata ( ) . getImmutableSchemaSnapshot ( ) . getClass ( className ) ; 
OIndex < ? > idx = null ; 
final Collection < ? extends OIndex < ? > > indexes = clazz . getIndexes ( ) ; 
OIndexDefinition indexDef = index . getDefinition ( ) ; 
if ( "lucene" . equalsIgnoreCase ( index . getAlgorithm ( ) ) ) { 
List < String > indexedFields = indexDef . getFields ( ) ; 
if ( indexedFields != null && indexedFields . size ( ) > 0 && indexedFields . get ( 0 ) . equals ( key ) ) { 
idx = index ; 
idx = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . getIndex ( iKey ) ; 
if ( idx != null ) { 
iValue = convertKey ( idx , iValue ) ; 
Object indexValue = idx . get ( iValue ) ; 
if ( indexValue != null && ! ( indexValue instanceof Iterable < ? > ) ) 
indexValue = Arrays . asList ( indexValue ) ; 
return new OrientElementIterable < Vertex > ( this , ( Iterable < ? > ) indexValue ) ; 
OrientGraphQuery query = ( OrientGraphQuery ) query ( ) ; 
query . labels ( clazz . getName ( ) ) ; 
return query . has ( key , iValue ) . vertices ( ) ; 
public Vertex getVertexByKey ( final String iKey , Object iValue ) { 
String indexName ; 
if ( iKey . indexOf ( '.' ) > - 1 ) 
indexName = iKey ; 
indexName = OrientVertexType . CLASS_NAME + "." + iKey ; 
final OIndex < ? > idx = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . getIndex ( indexName ) ; 
Object v = idx . get ( iValue ) ; 
return getVertex ( v ) ; 
} public Iterable < Vertex > getVertices ( final String label , final String [ ] iKey , Object [ ] iValue ) { 
if ( iKey . length != iValue . length ) { 
final OClass clazz = getDatabase ( ) . getMetadata ( ) . getImmutableSchemaSnapshot ( ) . getClass ( label ) ; 
if ( clazz != null ) { 
Set < OIndex < ? > > indexes = clazz . getInvolvedIndexes ( Arrays . asList ( iKey ) ) ; 
Iterator < OIndex < ? > > iterator = indexes . iterator ( ) ; 
final OIndex < ? > idx = iterator . next ( ) ; 
if ( "lucene" . equalsIgnoreCase ( idx . getAlgorithm ( ) ) ) { 
Object [ ] sortedParams = new Object [ iValue . length ] ; 
for ( int i = 0 ; i < iKey . length ; i ++ ) { 
sortedParams [ indexFields . indexOf ( iKey [ i ] ) ] = iValue [ i ] ; 
List < Object > keys = Arrays . asList ( convertKeys ( idx , sortedParams ) ) ; 
Object key ; 
if ( indexFields . size ( ) == 1 ) { 
key = keys . get ( 0 ) ; 
key = new OCompositeKey ( keys ) ; 
Object indexValue = idx . get ( key ) ; 
return new OrientClassVertexIterable ( this , ( Iterable < ? > ) indexValue , label ) ; 
query . labels ( label ) ; 
query . has ( iKey [ i ] , iValue [ i ] ) ; 
return query . vertices ( ) ; 
} public Iterable < Edge > getEdgesOfClass ( final String iClassName , final boolean iPolymorphic ) { 
if ( ! cls . isSubClassOf ( OrientEdgeType . CLASS_NAME ) ) 
return new OrientElementScanIterable < Edge > ( this , iClassName , iPolymorphic ) ; 
} public Iterable < Edge > getEdges ( final String iKey , Object iValue ) { 
return getEdgesOfClass ( iValue . toString ( ) ) ; 
final String indexName ; 
final String key ; 
if ( pos > - 1 ) { 
key = iKey . substring ( iKey . indexOf ( '.' ) + 1 ) ; 
indexName = OrientEdgeType . CLASS_NAME + "." + iKey ; 
key = iKey ; 
return new OrientElementIterable < Edge > ( this , ( Iterable < ? > ) indexValue ) ; 
return query ( ) . has ( key , iValue ) . edges ( ) ; 
} public OrientEdge getEdge ( final Object id ) { 
throw ExceptionFactory . edgeIdCanNotBeNull ( ) ; 
if ( id instanceof OrientEdge ) 
return ( OrientEdge ) id ; 
return new OrientEdge ( this , ( OIdentifiable ) id ) ; 
final OIdentifiable rec ; 
rec = ( OIdentifiable ) id ; 
final String str = id . toString ( ) ; 
int pos = str . indexOf ( "->" ) ; 
final String from = str . substring ( 0 , pos ) ; 
final String to = str . substring ( pos + 2 ) ; 
return getEdgeInstance ( new ORecordId ( from ) , new ORecordId ( to ) , null ) ; 
rec = new ORecordId ( str ) ; 
final ODocument doc = rec . getRecord ( ) ; 
final OClass cls = doc . getSchemaClass ( ) ; 
if ( cls . isVertexType ( ) ) 
if ( ! cls . isEdgeType ( ) ) 
return new OrientEdge ( this , rec ) ; 
} public OrientBaseGraph reuse ( final ODatabaseDocumentInternal iDatabase ) { 
ODatabaseRecordThreadLocal . instance ( ) . set ( iDatabase ) ; 
this . url = iDatabase . getURL ( ) ; 
database = iDatabase ; 
} public void shutdown ( boolean closeDb , boolean commitTx ) { 
if ( ! isClosed ( ) ) { 
if ( commitTx ) { 
final OStorage storage = getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ; 
if ( storage instanceof OAbstractPaginatedStorage ) { 
if ( ( ( OAbstractPaginatedStorage ) storage ) . getWALInstance ( ) != null ) 
getDatabase ( ) . commit ( ) ; 
} else if ( closeDb ) { 
getDatabase ( ) . rollback ( ) ; 
} catch ( RuntimeException e ) { 
if ( closeDb ) { 
getDatabase ( ) . close ( ) ; 
if ( getDatabase ( ) . isPooled ( ) ) { 
database = null ; 
pollGraphFromStack ( closeDb ) ; 
url = null ; 
username = null ; 
password = null ; 
if ( ! closeDb ) 
getDatabase ( ) . activateOnCurrentThread ( ) ; 
} public OrientVertexType getVertexBaseType ( ) { 
return new OrientVertexType ( this , getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( OrientVertexType . CLASS_NAME ) ) ; 
} public OrientVertexType getVertexType ( final String iTypeName ) { 
final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iTypeName ) ; 
OrientVertexType . checkType ( cls ) ; 
return new OrientVertexType ( this , cls ) ; 
} public OrientVertexType createVertexType ( final String iClassName , final int clusters ) { 
return createVertexType ( iClassName , ( String ) null , clusters ) ; 
} public OrientVertexType createVertexType ( final String iClassName , final String iSuperClassName ) { 
return createVertexType ( iClassName , iSuperClassName == null ? getVertexBaseType ( ) : getVertexType ( iSuperClassName ) ) ; 
} public OrientVertexType createVertexType ( final String iClassName , final OClass iSuperClass , final int clusters ) { 
OrientVertexType . checkType ( iSuperClass ) ; 
return executeOutsideTx ( new OCallable < OrientVertexType , OrientBaseGraph > ( ) { 
public OrientVertexType call ( final OrientBaseGraph g ) { 
return new OrientVertexType ( g , getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . createClass ( iClassName , clusters , iSuperClass ) ) ; 
} public void dropVertexType ( final String iTypeName ) { 
if ( getDatabase ( ) . countClass ( iTypeName ) > 0 ) 
executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { 
public OClass call ( final OrientBaseGraph g ) { 
ODatabaseDocument rawGraph = getRawGraph ( ) ; 
rawGraph . getMetadata ( ) . getSchema ( ) . dropClass ( iTypeName ) ; 
} public OrientEdgeType getEdgeType ( final String iTypeName ) { 
OrientEdgeType . checkType ( cls ) ; 
return new OrientEdgeType ( this , cls ) ; 
} public OrientEdgeType createEdgeType ( final String iClassName , final int clusters ) { 
return createEdgeType ( iClassName , ( String ) null , clusters ) ; 
} public OrientEdgeType createEdgeType ( final String iClassName , final String iSuperClassName ) { 
return createEdgeType ( iClassName , iSuperClassName == null ? getEdgeBaseType ( ) : getEdgeType ( iSuperClassName ) ) ; 
} public OrientEdgeType createEdgeType ( final String iClassName , final OClass iSuperClass , final int clusters ) { 
OrientEdgeType . checkType ( iSuperClass ) ; 
return executeOutsideTx ( new OCallable < OrientEdgeType , OrientBaseGraph > ( ) { 
public OrientEdgeType call ( final OrientBaseGraph g ) { 
return new OrientEdgeType ( g , getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . createClass ( iClassName , clusters , iSuperClass ) ) ; 
} public OrientElement getElement ( final Object id ) { 
if ( id instanceof OrientElement ) 
return ( OrientElement ) id ; 
OIdentifiable rec ; 
rec = new ORecordId ( id . toString ( ) ) ; 
if ( doc != null ) { 
final OImmutableClass schemaClass = ODocumentInternal . getImmutableSchemaClass ( doc ) ; 
if ( schemaClass != null && schemaClass . isEdgeType ( ) ) 
return getEdge ( doc ) ; 
return getVertexInstance ( doc ) ; 
} public < T extends Element > void dropKeyIndex ( final String key , final Class < T > elementClass ) { 
if ( elementClass == null ) 
throw ExceptionFactory . classForElementCannotBeNull ( ) ; 
final String className = getClassName ( elementClass ) ; 
getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( className + "." + key ) ; 
} @ SuppressWarnings ( { "rawtypes" } ) 
public < T extends Element > void createKeyIndex ( final String key , final Class < T > elementClass , 
final Parameter ... indexParameters ) { 
String indexType = OClass . INDEX_TYPE . NOTUNIQUE . name ( ) ; 
OType keyType = OType . STRING ; 
String collate = null ; 
ODocument metadata = null ; 
final String ancestorClassName = getClassName ( elementClass ) ; 
for ( Parameter < ? , ? > p : indexParameters ) { 
if ( p . getKey ( ) . equals ( "type" ) ) 
indexType = p . getValue ( ) . toString ( ) . toUpperCase ( Locale . ENGLISH ) ; 
else if ( p . getKey ( ) . equals ( "keytype" ) ) 
keyType = OType . valueOf ( p . getValue ( ) . toString ( ) . toUpperCase ( Locale . ENGLISH ) ) ; 
else if ( p . getKey ( ) . equals ( "class" ) ) 
className = p . getValue ( ) . toString ( ) ; 
else if ( p . getKey ( ) . equals ( "collate" ) ) 
collate = p . getValue ( ) . toString ( ) ; 
else if ( p . getKey ( ) . toString ( ) . startsWith ( "metadata." ) ) { 
metadata = new ODocument ( ) ; 
metadata . field ( p . getKey ( ) . toString ( ) . substring ( "metadata." . length ( ) ) , p . getValue ( ) ) ; 
className = ancestorClassName ; 
final ODatabaseDocument db = getRawGraph ( ) ; 
final OSchema schema = db . getMetadata ( ) . getSchema ( ) ; 
final OClass cls = schema . getOrCreateClass ( className , schema . getClass ( ancestorClassName ) ) ; 
final OProperty property = cls . getProperty ( key ) ; 
if ( property != null ) 
keyType = property . getType ( ) ; 
OPropertyIndexDefinition indexDefinition = new OPropertyIndexDefinition ( className , key , keyType ) ; 
if ( collate != null ) 
indexDefinition . setCollate ( collate ) ; 
db . getMetadata ( ) . getIndexManager ( ) 
. createIndex ( className + "." + key , indexType , indexDefinition , cls . getPolymorphicClusterIds ( ) , null , metadata ) ; 
public < T extends Element > Set < String > getIndexedKeys ( final Class < T > elementClass ) { 
return getIndexedKeys ( elementClass , false ) ; 
} public < T extends Element > Set < String > getIndexedKeys ( final Class < T > elementClass , final boolean includeClassNames ) { 
final OSchema schema = getRawGraph ( ) . getMetadata ( ) . getImmutableSchemaSnapshot ( ) ; 
final String elementOClassName = getClassName ( elementClass ) ; 
Set < String > result = new HashSet < String > ( ) ; 
final Collection < ? extends OIndex < ? > > indexes = getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) . getIndexes ( ) ; 
String indexName = index . getName ( ) ; 
int point = indexName . indexOf ( "." ) ; 
if ( point > 0 ) { 
String oClassName = indexName . substring ( 0 , point ) ; 
OClass oClass = schema . getClass ( oClassName ) ; 
if ( oClass != null ) { 
if ( oClass . isSubClassOf ( elementOClassName ) ) { 
if ( includeClassNames ) 
result . add ( index . getName ( ) ) ; 
result . add ( index . getDefinition ( ) . getFields ( ) . get ( 0 ) ) ; 
} protected static void removeEdges ( final OrientBaseGraph graph , final ODocument iVertex , final String iFieldName , 
final OIdentifiable iVertexToRemove , final boolean iAlsoInverse , final boolean useVertexFieldsForEdgeLabels , 
final boolean autoScaleEdgeType , final boolean forceReload ) { 
if ( iVertex == null ) 
final Object fieldValue = iVertexToRemove != null ? iVertex . field ( iFieldName ) : iVertex . removeField ( iFieldName ) ; 
if ( fieldValue == null ) 
if ( fieldValue instanceof OIdentifiable ) { 
if ( iVertexToRemove != null ) { 
if ( ! fieldValue . equals ( iVertexToRemove ) ) 
iVertex . removeField ( iFieldName ) ; 
deleteEdgeIfAny ( iVertexToRemove , forceReload ) ; 
if ( iAlsoInverse ) 
removeInverseEdge ( graph , iVertex , iFieldName , iVertexToRemove , ( OIdentifiable ) fieldValue , useVertexFieldsForEdgeLabels , 
autoScaleEdgeType , forceReload ) ; 
} else if ( fieldValue instanceof ORidBag ) { 
final ORidBag bag = ( ORidBag ) fieldValue ; 
for ( Iterator < OIdentifiable > it = bag . rawIterator ( ) ; it . hasNext ( ) ; ) { 
final ODocument curr = getDocument ( it . next ( ) , forceReload ) ; 
if ( curr == null ) { 
iVertex . save ( ) ; 
if ( iVertexToRemove . equals ( curr ) ) { 
removeInverseEdge ( graph , iVertex , iFieldName , iVertexToRemove , curr , useVertexFieldsForEdgeLabels , autoScaleEdgeType , 
forceReload ) ; 
} else if ( ODocumentInternal . getImmutableSchemaClass ( curr ) . isEdgeType ( ) ) { 
final Direction direction = OrientVertex . getConnectionDirection ( iFieldName , useVertexFieldsForEdgeLabels ) ; 
if ( iVertexToRemove . equals ( OrientEdge . getConnection ( curr , direction . opposite ( ) ) ) ) { 
removeInverseEdge ( graph , iVertex , iFieldName , iVertexToRemove , curr , useVertexFieldsForEdgeLabels , 
OIdentifiable edge = it . next ( ) ; 
removeInverseEdge ( graph , iVertex , iFieldName , null , edge , useVertexFieldsForEdgeLabels , autoScaleEdgeType , forceReload ) ; 
deleteEdgeIfAny ( edge , forceReload ) ; 
if ( autoScaleEdgeType && bag . isEmpty ( ) ) 
} else if ( fieldValue instanceof Collection ) { 
final Collection col = ( Collection ) fieldValue ; 
for ( Iterator < OIdentifiable > it = col . iterator ( ) ; it . hasNext ( ) ; ) { 
if ( curr == null ) 
} else if ( ODocumentInternal . getImmutableSchemaClass ( curr ) . isVertexType ( ) ) { 
for ( OIdentifiable edge : ( Iterable < OIdentifiable > ) col ) { 
if ( autoScaleEdgeType && col . isEmpty ( ) ) 
} private static void removeInverseEdge ( final OrientBaseGraph graph , final ODocument iVertex , final String iFieldName , 
final OIdentifiable iVertexToRemove , final OIdentifiable currentRecord , final boolean useVertexFieldsForEdgeLabels , 
final boolean autoScaleEdgeType , boolean forceReload ) { 
final ODocument r = getDocument ( currentRecord , forceReload ) ; 
final String inverseFieldName = OrientVertex . getInverseConnectionFieldName ( iFieldName , useVertexFieldsForEdgeLabels ) ; 
OImmutableClass immutableClass = ODocumentInternal . getImmutableSchemaClass ( r ) ; 
OClass klass = ODocumentInternal . getImmutableSchemaClass ( r ) ; 
if ( klass == null ) { 
graph . getDatabase ( ) . getMetadata ( ) . reload ( ) ; 
klass = graph . getDatabase ( ) . getMetadata ( ) . getSchema ( ) . getClass ( inverseFieldName ) ; 
if ( klass . isVertexType ( ) ) { 
removeEdges ( graph , r , inverseFieldName , iVertex , false , useVertexFieldsForEdgeLabels , autoScaleEdgeType , forceReload ) ; 
r . save ( ) ; 
} else if ( klass . isEdgeType ( ) ) { 
final OIdentifiable otherVertex = OrientEdge 
. getConnection ( r , OrientVertex . getConnectionDirection ( inverseFieldName , useVertexFieldsForEdgeLabels ) ) ; 
if ( otherVertex != null ) { 
if ( iVertexToRemove == null || otherVertex . equals ( iVertexToRemove ) ) { 
final int maxRetries = graph . getMaxRetries ( ) ; 
for ( int retry = 0 ; retry < maxRetries ; ++ retry ) { 
final ODocument otherVertexRecord = getDocument ( otherVertex , forceReload ) ; 
removeEdges ( graph , otherVertexRecord , inverseFieldName , ( OIdentifiable ) currentRecord , false , 
useVertexFieldsForEdgeLabels , autoScaleEdgeType , forceReload ) ; 
if ( otherVertexRecord != null ) 
otherVertexRecord . save ( ) ; 
} protected static void deleteEdgeIfAny ( final OIdentifiable iRecord , boolean forceReload ) { 
final ODocument doc = getDocument ( iRecord , forceReload ) ; 
final OImmutableClass clazz = ODocumentInternal . getImmutableSchemaClass ( doc ) ; 
if ( clazz != null && clazz . isEdgeType ( ) ) 
doc . delete ( ) ; 
public void removeBackgroundExceptionListener ( final OBackgroundExceptionListener listener ) { 
final List < WeakReference < OBackgroundExceptionListener > > itemsToRemove = new ArrayList < > ( 1 ) ; 
for ( final WeakReference < OBackgroundExceptionListener > ref : backgroundExceptionListeners ) { 
final OBackgroundExceptionListener l = ref . get ( ) ; 
if ( l != null && l . equals ( listener ) ) { 
itemsToRemove . add ( ref ) ; 
backgroundExceptionListeners . removeAll ( itemsToRemove ) ; 
} private void fireBackgroundDataFlushExceptionEvent ( final Throwable e ) { 
final OBackgroundExceptionListener listener = ref . get ( ) ; 
listener . onException ( e ) ; 
} private void freeSpaceCheckAfterNewPageAdd ( ) throws IOException { 
final long newPagesAdded = amountOfNewPagesAdded . addAndGet ( 1 ) ; 
final long lastSpaceCheck = lastDiskSpaceCheck . get ( ) ; 
if ( newPagesAdded - lastSpaceCheck > diskSizeCheckInterval || lastSpaceCheck == 0 ) { 
final long freeSpace = Files . getFileStore ( storagePath ) . getUsableSpace ( ) ; 
if ( freeSpace < freeSpaceLimit ) { 
callLowSpaceListeners ( new OLowDiskSpaceInformation ( freeSpace , freeSpaceLimit ) ) ; 
lastDiskSpaceCheck . lazySet ( newPagesAdded ) ; 
} private void readNameIdMapV2 ( ) throws IOException , InterruptedException { 
nameIdMap . clear ( ) ; 
long localFileCounter = - 1 ; 
nameIdMapHolder . position ( 0 ) ; 
NameFileIdEntry nameFileIdEntry ; 
final Map < Integer , String > idFileNameMap = new HashMap < > ( 1_000 ) ; 
while ( ( nameFileIdEntry = readNextNameIdEntryV2 ( ) ) != null ) { 
final long absFileId = Math . abs ( nameFileIdEntry . fileId ) ; 
if ( localFileCounter < absFileId ) { 
localFileCounter = absFileId ; 
nameIdMap . put ( nameFileIdEntry . name , nameFileIdEntry . fileId ) ; 
if ( nameFileIdEntry . fileId >= 0 ) { 
idNameMap . put ( nameFileIdEntry . fileId , nameFileIdEntry . name ) ; 
idFileNameMap . put ( nameFileIdEntry . fileId , nameFileIdEntry . fileSystemName ) ; 
if ( localFileCounter > 0 && nextInternalId < localFileCounter ) { 
nextInternalId = ( int ) localFileCounter ; 
for ( final Map . Entry < String , Integer > nameIdEntry : nameIdMap . entrySet ( ) ) { 
final int fileId = nameIdEntry . getValue ( ) ; 
if ( fileId >= 0 ) { 
final long externalId = composeFileId ( id , nameIdEntry . getValue ( ) ) ; 
if ( files . get ( externalId ) == null ) { 
final Path path = storagePath . resolve ( idFileNameMap . get ( ( nameIdEntry . getValue ( ) ) ) ) ; 
final OFileClassic fileClassic = new OFileClassic ( path ) ; 
if ( fileClassic . exists ( ) ) { 
fileClassic . open ( ) ; 
files . add ( externalId , fileClassic ) ; 
nameIdMap . put ( nameIdEntry . getKey ( ) , - fileId ) ; 
idNameMap . remove ( fileId ) ; 
} public boolean matches ( String propertyName ) { 
if ( star ) { 
if ( expression != null ) { 
String fieldString = expression . getDefaultAlias ( ) . getStringValue ( ) ; 
if ( fieldString . equals ( propertyName ) ) { 
if ( rightWildcard && propertyName . startsWith ( fieldString ) ) { 
if ( clusterId < 0 ) { 
final OSchema schema = database . getMetadata ( ) . getSchema ( ) ; 
final OClass clazz = schema . getClassByClusterId ( clusterId ) ; 
final OStorage storage = database . getStorage ( ) ; 
final OCluster cluster = storage . getClusterById ( clusterId ) ; 
if ( cluster == null ) { 
database . checkForClusterPermissions ( cluster . getName ( ) ) ; 
cluster . truncate ( ) ; 
clazz . truncateCluster ( clusterName ) ; 
} public void startThreadMonitoring ( ) { 
switchLock . acquireWriteLock ( ) ; 
if ( enabled ) 
enabledForCurrentThread . set ( true ) ; 
statistics . put ( Thread . currentThread ( ) , new OSessionStoragePerformanceStatistic ( intervalBetweenSnapshots , Long . MAX_VALUE ) ) ; 
switchLock . releaseWriteLock ( ) ; 
} public void startMonitoring ( ) { 
if ( ! statistics . isEmpty ( ) && ! enabled ) 
deadThreadsStatistic = null ; 
postMeasurementStatistic = null ; 
enabled = true ; 
} public void stopMonitoring ( ) { 
enabled = false ; 
final PerformanceCountersHolder countersHolder = ComponentType . GENERAL . newCountersHolder ( ) ; 
final Map < String , PerformanceCountersHolder > componentCountersHolder = new HashMap < > ( ) ; 
WritCacheCountersHolder writCacheCountersHolder = deadThreadsStatistic . writCacheCountersHolder ; 
StorageCountersHolder storageCountersHolder = deadThreadsStatistic . storageCountersHolder ; 
WALCountersHolder walCountersHolder = deadThreadsStatistic . walCountersHolder ; 
deadThreadsStatistic . countersHolder . pushData ( countersHolder ) ; 
componentCountersHolder . putAll ( deadThreadsStatistic . countersByComponents ) ; 
for ( OSessionStoragePerformanceStatistic statistic : statistics . values ( ) ) { 
statistic . pushSystemCounters ( countersHolder ) ; 
statistic . pushComponentCounters ( componentCountersHolder ) ; 
writCacheCountersHolder = statistic . pushWriteCacheCounters ( writCacheCountersHolder ) ; 
storageCountersHolder = statistic . pushStorageCounters ( storageCountersHolder ) ; 
walCountersHolder = statistic . pushWALCounters ( walCountersHolder ) ; 
statistics . clear ( ) ; 
postMeasurementStatistic = new ImmutableStatistic ( countersHolder , componentCountersHolder , writCacheCountersHolder , 
} public void registerMBean ( String storageName , int storageId ) { 
if ( mbeanIsRegistered . compareAndSet ( false , true ) ) { 
final MBeanServer server = ManagementFactory . getPlatformMBeanServer ( ) ; 
final ObjectName mbeanName = new ObjectName ( getMBeanName ( storageName , storageId ) ) ; 
if ( ! server . isRegistered ( mbeanName ) ) { 
server . registerMBean ( new OPerformanceStatisticManagerMBean ( this ) , mbeanName ) ; 
mbeanIsRegistered . set ( false ) ; 
} catch ( MalformedObjectNameException | InstanceAlreadyExistsException | NotCompliantMBeanException | MBeanRegistrationException e ) { 
} public void unregisterMBean ( String storageName , int storageId ) { 
if ( storageName == null ) { 
if ( mbeanIsRegistered . compareAndSet ( true , false ) ) { 
server . unregisterMBean ( mbeanName ) ; 
} catch ( MalformedObjectNameException | InstanceNotFoundException | MBeanRegistrationException e ) { 
switchLock . acquireReadLock ( ) ; 
if ( enabled ) { 
final PerformanceCountersHolder componentCountersHolder = ComponentType . GENERAL . newCountersHolder ( ) ; 
fetchComponentCounters ( componentName , componentCountersHolder ) ; 
return componentCountersHolder . getAmountOfPagesPerOperation ( ) ; 
final ImmutableStatistic post = postMeasurementStatistic ; 
if ( post == null ) 
final PerformanceCountersHolder holder = post . countersByComponents . get ( componentName ) ; 
return holder . getAmountOfPagesPerOperation ( ) ; 
switchLock . releaseReadLock ( ) ; 
fetchComponentCounters ( componentName , countersHolder ) ; 
return countersHolder . getCacheHits ( ) ; 
if ( holder != null ) 
return holder . getCacheHits ( ) ; 
} private WritCacheCountersHolder fetchWriteCacheCounters ( ) { 
final Collection < ORawPair < Thread , PerformanceSnapshot > > snapshots = new ArrayList < > ( statistics . size ( ) ) ; 
final Collection < Thread > threadsToRemove = new ArrayList < > ( ) ; 
for ( Map . Entry < Thread , OSessionStoragePerformanceStatistic > entry : statistics . entrySet ( ) ) { 
final Thread thread = entry . getKey ( ) ; 
final OSessionStoragePerformanceStatistic statistic = entry . getValue ( ) ; 
snapshots . add ( new ORawPair < > ( thread , statistic . getSnapshot ( ) ) ) ; 
WritCacheCountersHolder holder = null ; 
for ( ORawPair < Thread , PerformanceSnapshot > pair : snapshots ) { 
final Thread thread = pair . getFirst ( ) ; 
if ( thread . isAlive ( ) ) { 
final PerformanceSnapshot snapshot = pair . getSecond ( ) ; 
if ( snapshot . writCacheCountersHolder != null ) { 
threadsToRemove . add ( thread ) ; 
if ( ! threadsToRemove . isEmpty ( ) ) { 
updateDeadThreadsStatistic ( threadsToRemove ) ; 
final ImmutableStatistic ds = deadThreadsStatistic ; 
if ( ds != null ) { 
final WritCacheCountersHolder wch = ds . writCacheCountersHolder ; 
if ( wch != null ) { 
wch . pushData ( holder ) ; 
} private void fetchSystemCounters ( PerformanceCountersHolder countersHolder ) { 
snapshot . performanceCountersHolder . pushData ( countersHolder ) ; 
final PerformanceCountersHolder dch = ds . countersHolder ; 
dch . pushData ( countersHolder ) ; 
} private void fetchComponentCounters ( String componentName , PerformanceCountersHolder componentCountersHolder ) { 
final List < Thread > threadsToRemove = new ArrayList < > ( ) ; 
final PerformanceCountersHolder holder = snapshot . countersByComponent . get ( componentName ) ; 
holder . pushData ( componentCountersHolder ) ; 
final PerformanceCountersHolder dch = ds . countersByComponents . get ( componentName ) ; 
if ( dch != null ) { 
dch . pushData ( componentCountersHolder ) ; 
} private void updateDeadThreadsStatistic ( Collection < Thread > threadsToRemove ) { 
deadThreadsUpdateLock . lock ( ) ; 
final ImmutableStatistic oldDS = deadThreadsStatistic ; 
final Map < String , PerformanceCountersHolder > countersByComponents = new HashMap < > ( ) ; 
WritCacheCountersHolder writeCacheCountersHolder = null ; 
StorageCountersHolder storageCountersHolder = null ; 
WALCountersHolder walCountersHolder = null ; 
if ( oldDS != null ) { 
oldDS . countersHolder . pushData ( countersHolder ) ; 
for ( Map . Entry < String , PerformanceCountersHolder > oldEntry : oldDS . countersByComponents . entrySet ( ) ) { 
final PerformanceCountersHolder holder = oldEntry . getValue ( ) . newInstance ( ) ; 
oldEntry . getValue ( ) . pushData ( holder ) ; 
countersByComponents . put ( oldEntry . getKey ( ) , holder ) ; 
if ( oldDS . writCacheCountersHolder != null ) { 
writeCacheCountersHolder = new WritCacheCountersHolder ( ) ; 
oldDS . writCacheCountersHolder . pushData ( writeCacheCountersHolder ) ; 
if ( oldDS . storageCountersHolder != null ) { 
oldDS . storageCountersHolder . pushData ( storageCountersHolder ) ; 
if ( oldDS . walCountersHolder != null ) { 
oldDS . walCountersHolder . pushData ( walCountersHolder ) ; 
for ( Thread deadThread : threadsToRemove ) { 
final OSessionStoragePerformanceStatistic sessionStoragePerformanceStatistic = statistics . remove ( deadThread ) ; 
if ( sessionStoragePerformanceStatistic != null ) { 
sessionStoragePerformanceStatistic . pushSystemCounters ( countersHolder ) ; 
sessionStoragePerformanceStatistic . pushComponentCounters ( countersByComponents ) ; 
writeCacheCountersHolder = sessionStoragePerformanceStatistic . pushWriteCacheCounters ( writeCacheCountersHolder ) ; 
storageCountersHolder = sessionStoragePerformanceStatistic . pushStorageCounters ( storageCountersHolder ) ; 
walCountersHolder = sessionStoragePerformanceStatistic . pushWALCounters ( walCountersHolder ) ; 
deadThreadsStatistic = new ImmutableStatistic ( countersHolder , countersByComponents , writeCacheCountersHolder , 
deadThreadsUpdateLock . unlock ( ) ; 
} public ORID getValue ( final int entryIndex ) { 
final int clusterId = getShortValue ( entryPosition ) ; 
final long clusterPosition = getLongValue ( entryPosition + OShortSerializer . SHORT_SIZE ) ; 
return new ORecordId ( clusterId , clusterPosition ) ; 
} public byte [ ] compress ( String jsonStr ) { 
if ( jsonStr == null || jsonStr . length ( ) == 0 ) { 
GZIPOutputStream gout = null ; 
ByteArrayOutputStream baos = null ; 
byte [ ] incoming = jsonStr . getBytes ( "UTF-8" ) ; 
baos = new ByteArrayOutputStream ( ) ; 
gout = new GZIPOutputStream ( baos , 16384 ) ; 
gout . write ( incoming ) ; 
gout . finish ( ) ; 
return baos . toByteArray ( ) ; 
if ( gout != null ) { 
gout . close ( ) ; 
if ( baos != null ) { 
baos . close ( ) ; 
} public String getProperty ( final String iName , final String iDefaultValue ) { 
if ( properties == null ) 
for ( OServerEntryConfiguration p : properties ) { 
if ( p . name . equals ( iName ) ) 
return p . value ; 
} public < RET extends Object > RET newInstance ( final String iClassName , final Object iEnclosingClass , Object ... iArgs ) { 
underlying . checkIfActive ( ) ; 
checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_CREATE , iClassName ) ; 
Class < ? > entityClass = entityManager . getEntityClass ( iClassName ) ; 
if ( entityClass != null ) { 
RET enhanced = ( RET ) OObjectEntityEnhancer . getInstance ( ) 
. getProxiedInstance ( entityManager . getEntityClass ( iClassName ) , iEnclosingClass , underlying . newInstance ( iClassName ) , null , 
iArgs ) ; 
return ( RET ) enhanced ; 
throw OException . wrapException ( new ODatabaseException ( message ) , e ) ; 
} public < RET > RET detach ( final Object iPojo , boolean returnNonProxiedInstance ) { 
return ( RET ) OObjectEntitySerializer . detach ( iPojo , this , returnNonProxiedInstance ) ; 
} public < RET > RET detachAll ( final Object iPojo , boolean returnNonProxiedInstance ) { 
return detachAll ( iPojo , returnNonProxiedInstance , new HashMap < Object , Object > ( ) , new HashMap < Object , Object > ( ) ) ; 
} public < RET > RET save ( final Object iContent , OPERATION_MODE iMode , boolean iForceCreate , 
final ORecordCallback < ? extends Number > iRecordCreatedCallback , ORecordCallback < Integer > iRecordUpdatedCallback ) { 
return ( RET ) save ( iContent , null , iMode , false , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
} public < RET > RET save ( final Object iPojo , final String iClusterName ) { 
return ( RET ) save ( iPojo , iClusterName , OPERATION_MODE . SYNCHRONOUS , false , null , null ) ; 
} public < RET > RET save ( final Object iPojo , final String iClusterName , OPERATION_MODE iMode , boolean iForceCreate , 
if ( iPojo == null ) 
return ( RET ) iPojo ; 
else if ( OMultiValue . isMultiValue ( iPojo ) ) { 
for ( Object pojo : OMultiValue . getMultiValueIterable ( iPojo ) ) { 
save ( pojo , iClusterName ) ; 
OSerializationThreadLocal . INSTANCE . get ( ) . clear ( ) ; 
final Object proxiedObject = OObjectEntitySerializer . serializeObject ( iPojo , this ) ; 
final ODocument record = getRecordByUserObject ( proxiedObject , true ) ; 
record . setInternalStatus ( ORecordElement . STATUS . MARSHALLING ) ; 
if ( ! saveOnlyDirty || record . isDirty ( ) ) { 
deleteOrphans ( ( ( ( OObjectProxyMethodHandler ) ( ( ProxyObject ) proxiedObject ) . getHandler ( ) ) ) ) ; 
ODocument savedRecord = underlying 
. save ( record , iClusterName , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
( ( OObjectProxyMethodHandler ) ( ( ProxyObject ) proxiedObject ) . getHandler ( ) ) . setDoc ( savedRecord ) ; 
( ( OObjectProxyMethodHandler ) ( ( ProxyObject ) proxiedObject ) . getHandler ( ) ) . updateLoadedFieldMap ( proxiedObject , false ) ; 
registerUserObject ( proxiedObject , record ) ; 
record . setInternalStatus ( ORecordElement . STATUS . LOADED ) ; 
return ( RET ) proxiedObject ; 
} public int getVersion ( final Object iPojo ) { 
final ODocument record = getRecordByUserObject ( iPojo , false ) ; 
return record . getVersion ( ) ; 
return OObjectSerializerHelper . getObjectVersion ( iPojo ) ; 
} private void registerFieldMappingStrategy ( ) { 
if ( ! this . getConfiguration ( ) . getContextKeys ( ) . contains ( OGlobalConfiguration . DOCUMENT_BINARY_MAPPING . getKey ( ) ) ) { 
this . getConfiguration ( ) 
. setValue ( OGlobalConfiguration . DOCUMENT_BINARY_MAPPING , OGlobalConfiguration . DOCUMENT_BINARY_MAPPING . getValueAsInteger ( ) ) ; 
} public < RET extends OCommandRequest > RET command ( final OCommandRequest iCommand ) { 
return ( RET ) new OCommandSQLPojoWrapper ( this , underlying . command ( iCommand ) ) ; 
} protected void convertParameters ( final Object ... iArgs ) { 
if ( iArgs == null ) 
for ( int i = 0 ; i < iArgs . length ; ++ i ) 
iArgs [ i ] = convertParameter ( iArgs [ i ] ) ; 
} public void setDirty ( final Object iPojo ) { 
} public void unsetDirty ( final Object iPojo ) { 
ORecordInternal . unsetDirty ( record ) ; 
} protected Object convertParameter ( final Object iParameter ) { 
if ( iParameter != null ) 
if ( iParameter instanceof Map < ? , ? > ) { 
Map < String , Object > map = ( Map < String , Object > ) iParameter ; 
for ( Map . Entry < String , Object > e : map . entrySet ( ) ) { 
map . put ( e . getKey ( ) , convertParameter ( e . getValue ( ) ) ) ; 
return map ; 
} else if ( iParameter instanceof Collection < ? > ) { 
List < Object > result = new ArrayList < Object > ( ) ; 
for ( Object object : ( Collection < Object > ) iParameter ) { 
result . add ( convertParameter ( object ) ) ; 
} else if ( iParameter . getClass ( ) . isEnum ( ) ) { 
return ( ( Enum < ? > ) iParameter ) . name ( ) ; 
} else if ( ! OType . isSimpleType ( iParameter ) ) { 
final ORID rid = getIdentity ( iParameter ) ; 
if ( rid != null && rid . isValid ( ) ) 
return iParameter ; 
} private static Set < String > getIndexTypes ( ) { 
final Set < String > types = new HashSet < > ( ) ; 
final Iterator < OIndexFactory > ite = getAllFactories ( ) ; 
types . addAll ( ite . next ( ) . getTypes ( ) ) ; 
} public static Set < String > getIndexEngines ( ) { 
final Set < String > engines = new HashSet < > ( ) ; 
engines . addAll ( ite . next ( ) . getAlgorithms ( ) ) ; 
return engines ; 
} public static OIndexInternal < ? > createIndex ( OStorage storage , String name , String indexType , String algorithm , 
String valueContainerAlgorithm , ODocument metadata , int version ) throws OConfigurationException , OIndexException { 
if ( indexType . equalsIgnoreCase ( OClass . INDEX_TYPE . UNIQUE_HASH_INDEX . name ( ) ) || indexType 
. equalsIgnoreCase ( OClass . INDEX_TYPE . NOTUNIQUE_HASH_INDEX . name ( ) ) || indexType 
. equalsIgnoreCase ( OClass . INDEX_TYPE . DICTIONARY_HASH_INDEX . name ( ) ) ) { 
if ( ! algorithm . equalsIgnoreCase ( "autosharding" ) ) { 
algorithm = OHashIndexFactory . HASH_INDEX_ALGORITHM ; 
return findFactoryByAlgorithmAndType ( algorithm , indexType ) 
. createIndex ( name , storage , indexType , algorithm , valueContainerAlgorithm , metadata , version ) ; 
} public boolean collectResponse ( final ODistributedResponse response ) { 
final String executorNode = response . getExecutorNodeName ( ) ; 
final String senderNode = response . getSenderNodeName ( ) ; 
response . setDistributedResponseManager ( this ) ; 
synchronousResponsesLock . lock ( ) ; 
if ( ! executorNode . equals ( dManager . getLocalNodeName ( ) ) && ! responses . containsKey ( executorNode ) ) { 
ODistributedServerLog . warn ( this , senderNode , executorNode , DIRECTION . IN , 
dManager . getMessageService ( ) . updateLatency ( executorNode , sentOn ) ; 
responses . put ( executorNode , response ) ; 
receivedResponses ++ ; 
if ( waitForLocalNode && executorNode . equals ( senderNode ) ) 
receivedCurrentNode = true ; 
ODistributedServerLog . debug ( this , senderNode , executorNode , DIRECTION . IN , 
response , request , receivedCurrentNode , receivedResponses , totalExpectedResponses , quorum ) ; 
if ( groupResponsesByResult ) { 
final Object responsePayload = response . getPayload ( ) ; 
boolean foundBucket = false ; 
for ( int i = 0 ; i < responseGroups . size ( ) ; ++ i ) { 
final List < ODistributedResponse > responseGroup = responseGroups . get ( i ) ; 
if ( responseGroup . isEmpty ( ) ) 
foundBucket = true ; 
final Object rgPayload = responseGroup . get ( 0 ) . getPayload ( ) ; 
if ( rgPayload == null && responsePayload == null ) 
else if ( rgPayload != null ) { 
if ( rgPayload instanceof ODocument && responsePayload instanceof ODocument && ! ( ( ODocument ) rgPayload ) . getIdentity ( ) 
. isValid ( ) && ( ( ODocument ) rgPayload ) . hasSameContentOf ( ( ODocument ) responsePayload ) ) 
else if ( rgPayload . equals ( responsePayload ) ) 
else if ( rgPayload instanceof Collection && responsePayload instanceof Collection ) { 
if ( OMultiValue . equals ( ( Collection ) rgPayload , ( Collection ) responsePayload ) ) 
if ( foundBucket ) { 
responseGroup . add ( response ) ; 
if ( ! foundBucket ) { 
final ArrayList < ODistributedResponse > newBucket = new ArrayList < ODistributedResponse > ( ) ; 
responseGroups . add ( newBucket ) ; 
newBucket . add ( response ) ; 
computeQuorumResponse ( false ) ; 
return checkForCompletion ( ) ; 
synchronousResponsesLock . unlock ( ) ; 
} public boolean setLocalResult ( final String localNodeName , final Object localResult ) { 
localResponse = new ODistributedResponse ( this , request . getId ( ) , localNodeName , localNodeName , localResult ) ; 
return collectResponse ( localResponse ) ; 
} public boolean waitForSynchronousResponses ( ) throws InterruptedException { 
final long beginTime = System . currentTimeMillis ( ) ; 
boolean reachedTimeout = false ; 
long currentTimeout = synchTimeout ; 
while ( currentTimeout > 0 ) { 
if ( currentTimeout > 10000 ) 
currentTimeout = 10000 ; 
ODistributedServerLog . debug ( this , dManager . getLocalNodeName ( ) , null , DIRECTION . NONE , 
synchTimeout , request . getId ( ) , Thread . currentThread ( ) . getId ( ) ) ; 
if ( synchronousResponsesArrived . await ( currentTimeout , TimeUnit . MILLISECONDS ) ) { 
if ( canceled . get ( ) ) 
request . getId ( ) , Thread . currentThread ( ) . getId ( ) ) ; 
( System . currentTimeMillis ( ) - beginTime ) , request . getId ( ) , Thread . currentThread ( ) . getId ( ) ) ; 
if ( Thread . currentThread ( ) . isInterrupted ( ) ) { 
request ) ; 
Thread . currentThread ( ) . interrupt ( ) ; 
final long elapsed = now - beginTime ; 
if ( elapsed > synchTimeout ) 
reachedTimeout = true ; 
currentTimeout = synchTimeout - elapsed ; 
int synchronizingNodes = 0 ; 
int missingActiveNodes = 0 ; 
Map < String , ODistributedServerManager . DB_STATUS > missingResponseNodeStatuses = new HashMap < String , ODistributedServerManager . DB_STATUS > ( 
responses . size ( ) ) ; 
int missingResponses = 0 ; 
for ( Iterator < Map . Entry < String , Object > > iter = responses . entrySet ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { 
final Map . Entry < String , Object > curr = iter . next ( ) ; 
if ( curr . getValue ( ) == NO_RESPONSE ) { 
missingResponses ++ ; 
final ODistributedServerManager . DB_STATUS dbStatus = dManager . getDatabaseStatus ( curr . getKey ( ) , getDatabaseName ( ) ) ; 
missingResponseNodeStatuses . put ( curr . getKey ( ) , dbStatus ) ; 
switch ( dbStatus ) { 
case BACKUP : 
case SYNCHRONIZING : 
synchronizingNodes ++ ; 
missingActiveNodes ++ ; 
case ONLINE : 
if ( missingResponses == 0 ) { 
request . getTask ( ) . checkIsValid ( dManager ) ; 
if ( missingActiveNodes == 0 ) { 
currentTimeout , missingResponseNodeStatuses ) ; 
final long lastClusterChange = dManager . getLastClusterChangeOn ( ) ; 
if ( lastClusterChange > 0 && now - lastClusterChange < ( synchTimeout + ADDITIONAL_TIMEOUT_CLUSTER_SHAPE ) ) { 
currentTimeout = synchTimeout ; 
currentTimeout ) ; 
} else if ( synchronizingNodes > 0 ) { 
return isMinimumQuorumReached ( reachedTimeout ) ; 
beginTime ) ; 
} public List < String > getMissingNodes ( ) { 
final List < String > missingNodes = new ArrayList < String > ( ) ; 
for ( Map . Entry < String , Object > entry : responses . entrySet ( ) ) 
if ( entry . getValue ( ) == NO_RESPONSE ) 
missingNodes . add ( entry . getKey ( ) ) ; 
return missingNodes ; 
} protected List < ODistributedResponse > getConflictResponses ( ) { 
final List < ODistributedResponse > servers = new ArrayList < ODistributedResponse > ( ) ; 
int bestGroupSoFar = getBestResponsesGroup ( ) ; 
if ( i != bestGroupSoFar ) { 
for ( ODistributedResponse r : responseGroups . get ( i ) ) 
servers . add ( r ) ; 
} protected int getBestResponsesGroup ( ) { 
int maxCoherentResponses = 0 ; 
int bestGroupSoFar = 0 ; 
final int currentGroupSize = responseGroups . get ( i ) . size ( ) ; 
if ( currentGroupSize > maxCoherentResponses ) { 
maxCoherentResponses = currentGroupSize ; 
bestGroupSoFar = i ; 
return bestGroupSoFar ; 
} private boolean computeQuorumResponse ( boolean reachedTimeout ) { 
if ( quorumResponse != null ) 
for ( List < ODistributedResponse > group : responseGroups ) { 
if ( group . size ( ) >= quorum ) { 
int responsesForQuorum = 0 ; 
for ( ODistributedResponse r : group ) { 
if ( nodesConcurInQuorum . contains ( r . getExecutorNodeName ( ) ) ) { 
final Object payload = r . getPayload ( ) ; 
if ( payload instanceof Throwable ) { 
if ( payload instanceof ODistributedRecordLockedException ) 
if ( payload instanceof OConcurrentCreateException ) 
} else if ( ++ responsesForQuorum >= quorum ) { 
setQuorumResponse ( r ) ; 
if ( receivedResponses >= quorum ) { 
for ( Map . Entry < String , Object > response : responses . entrySet ( ) ) { 
if ( response . getValue ( ) != NO_RESPONSE && nodesConcurInQuorum . contains ( response . getKey ( ) ) 
&& ++ responsesForQuorum >= quorum ) { 
ODistributedResponse resp = ( ODistributedResponse ) response . getValue ( ) ; 
if ( resp != null && ! ( resp . getPayload ( ) instanceof Throwable ) ) 
setQuorumResponse ( resp ) ; 
} protected List < ODistributedResponse > getReceivedResponses ( ) { 
final List < ODistributedResponse > parsed = new ArrayList < ODistributedResponse > ( ) ; 
for ( Object r : responses . values ( ) ) 
if ( r != NO_RESPONSE ) 
parsed . add ( ( ODistributedResponse ) r ) ; 
return parsed ; 
} public static OExecutionPlan get ( String statement , OCommandContext ctx , ODatabaseDocumentInternal db ) { 
if ( statement == null ) { 
OExecutionPlanCache resource = db . getSharedContext ( ) . getExecutionPlanCache ( ) ; 
OExecutionPlan result = resource . getInternal ( statement , ctx , db ) ; 
} public OExecutionPlan getInternal ( String statement , OCommandContext ctx , ODatabaseDocumentInternal db ) { 
OInternalExecutionPlan result ; 
result = result . copy ( ctx ) ; 
} List < String > getMatchPatternInvolvedAliases ( ) { 
if ( mathExpression != null ) 
return mathExpression . getMatchPatternInvolvedAliases ( ) ; 
if ( arrayConcatExpression != null ) 
return arrayConcatExpression . getMatchPatternInvolvedAliases ( ) ; 
} public boolean allowsIndexedFunctionExecutionOnTarget ( OFromClause target , OCommandContext context ) { 
return left . allowsIndexedFunctionExecutionOnTarget ( target , context , operator , right . execute ( ( OResult ) null , context ) ) ; 
} public String getLibrary ( final ODatabase < ? > db , final String iLanguage ) { 
if ( db == null ) 
final StringBuilder code = new StringBuilder ( ) ; 
final Set < String > functions = db . getMetadata ( ) . getFunctionLibrary ( ) . getFunctionNames ( ) ; 
for ( String fName : functions ) { 
final OFunction f = db . getMetadata ( ) . getFunctionLibrary ( ) . getFunction ( fName ) ; 
if ( f . getLanguage ( ) == null ) 
if ( f . getLanguage ( ) . equalsIgnoreCase ( iLanguage ) ) { 
final String def = getFunctionDefinition ( f ) ; 
if ( def != null ) { 
code . append ( def ) ; 
code . append ( "\n" ) ; 
return code . length ( ) == 0 ? null : code . toString ( ) ; 
} public OPartitionedObjectPool . PoolEntry < ScriptEngine > acquireDatabaseEngine ( final String databaseName , final String language ) { 
ODatabaseScriptManager dbManager = dbManagers . get ( databaseName ) ; 
if ( dbManager == null ) { 
dbManager = new ODatabaseScriptManager ( this , databaseName ) ; 
final ODatabaseScriptManager prev = dbManagers . putIfAbsent ( databaseName , dbManager ) ; 
if ( prev != null ) { 
dbManager . close ( ) ; 
dbManager = prev ; 
return dbManager . acquireEngine ( language ) ; 
} public void releaseDatabaseEngine ( final String iLanguage , final String iDatabaseName , 
final OPartitionedObjectPool . PoolEntry < ScriptEngine > poolEntry ) { 
final ODatabaseScriptManager dbManager = dbManagers . get ( iDatabaseName ) ; 
if ( dbManager != null ) { 
dbManager . releaseEngine ( iLanguage , poolEntry ) ; 
} public void unbind ( ScriptEngine scriptEngine , final Bindings binding , final OCommandContext iContext , 
final Map < Object , Object > iArgs ) { 
for ( OScriptInjection i : injections ) 
i . unbind ( scriptEngine , binding ) ; 
binding . put ( "db" , null ) ; 
binding . put ( "orient" , null ) ; 
binding . put ( "util" , null ) ; 
binding . put ( "ctx" , null ) ; 
if ( iContext != null ) { 
for ( Entry < String , Object > a : iContext . getVariables ( ) . entrySet ( ) ) 
binding . put ( a . getKey ( ) , null ) ; 
if ( iArgs != null ) { 
for ( Entry < Object , Object > a : iArgs . entrySet ( ) ) 
binding . put ( a . getKey ( ) . toString ( ) , null ) ; 
binding . put ( "params" , null ) ; 
public void registerInjection ( final OScriptInjection iInj ) { 
if ( ! injections . contains ( iInj ) ) 
injections . add ( iInj ) ; 
public void unregisterInjection ( final OScriptInjection iInj ) { 
injections . remove ( iInj ) ; 
public List < OScriptInjection > getInjections ( ) { 
return injections ; 
public OScriptManager registerEngine ( final String iLanguage , final ScriptEngineFactory iEngine ) { 
engines . put ( iLanguage , iEngine ) ; 
public OScriptManager registerFormatter ( final String iLanguage , final OScriptFormatter iFormatterImpl ) { 
formatters . put ( iLanguage . toLowerCase ( Locale . ENGLISH ) , iFormatterImpl ) ; 
public OScriptManager registerResultHandler ( final String iLanguage , final OScriptResultHandler resultHandler ) { 
handlers . put ( iLanguage . toLowerCase ( Locale . ENGLISH ) , resultHandler ) ; 
public Object handleResult ( String language , Object result , ScriptEngine engine , Bindings binding , ODatabaseDocument database ) { 
OScriptResultHandler handler = handlers . get ( language ) ; 
if ( handler != null ) { 
return handler . handle ( result , engine , binding , database ) ; 
public Map < String , OScriptFormatter > getFormatters ( ) { 
return formatters ; 
public void close ( final String iDatabaseName ) { 
final ODatabaseScriptManager dbPool = dbManagers . remove ( iDatabaseName ) ; 
if ( dbPool != null ) 
dbPool . close ( ) ; 
} long getNextPosition ( final OAtomicOperation atomicOperation ) throws IOException { 
final long filledUpTo = getFilledUpTo ( atomicOperation , fileId ) ; 
final long pageIndex = filledUpTo - 1 ; 
final OCacheEntry cacheEntry = loadPageForRead ( atomicOperation , fileId , pageIndex , false , 1 ) ; 
final OClusterPositionMapBucket bucket = new OClusterPositionMapBucket ( cacheEntry , false ) ; 
final int bucketSize = bucket . getSize ( ) ; 
return pageIndex * OClusterPositionMapBucket . MAX_ENTRIES + bucketSize ; 
releasePageFromRead ( atomicOperation , cacheEntry ) ; 
} private int updateSize ( ) { 
int size = 0 ; 
if ( collectionPointer != null ) { 
final OSBTreeBonsai < OIdentifiable , Integer > tree = loadTree ( ) ; 
if ( tree == null ) { 
size = tree . getRealBagSize ( changes ) ; 
releaseTree ( ) ; 
for ( Change change : changes . values ( ) ) { 
size += change . applyTo ( 0 ) ; 
for ( OModifiableInteger diff : newEntries . values ( ) ) { 
size += diff . getValue ( ) ; 
return size ; 
} private boolean removeFromNewEntries ( final OIdentifiable identifiable ) { 
OModifiableInteger counter = newEntries . get ( identifiable ) ; 
if ( counter == null ) { 
if ( counter . getValue ( ) == 1 ) { 
newEntries . remove ( identifiable ) ; 
counter . decrement ( ) ; 
} private void processAndBlock ( ) { 
OCollection fromKey = indexKeyFrom ( ( OAndBlock ) condition , additionalRangeCondition ) ; 
OCollection toKey = indexKeyTo ( ( OAndBlock ) condition , additionalRangeCondition ) ; 
boolean fromKeyIncluded = indexKeyFromIncluded ( ( OAndBlock ) condition , additionalRangeCondition ) ; 
boolean toKeyIncluded = indexKeyToIncluded ( ( OAndBlock ) condition , additionalRangeCondition ) ; 
init ( fromKey , fromKeyIncluded , toKey , toKeyIncluded ) ; 
} private Object unboxOResult ( Object value ) { 
if ( value instanceof List ) { 
return ( ( List ) value ) . stream ( ) . map ( x -> unboxOResult ( x ) ) . collect ( Collectors . toList ( ) ) ; 
if ( value instanceof OResult ) { 
if ( ( ( OResult ) value ) . isElement ( ) ) { 
return ( ( OResult ) value ) . getIdentity ( ) . orElse ( null ) ; 
Set < String > props = ( ( OResult ) value ) . getPropertyNames ( ) ; 
if ( props . size ( ) == 1 ) { 
return ( ( OResult ) value ) . getProperty ( props . iterator ( ) . next ( ) ) ; 
} public V getValue ( int index ) { 
int entryPosition = getIntValue ( POSITIONS_ARRAY_OFFSET + index * OIntegerSerializer . INT_SIZE ) ; 
entryPosition += OLongSerializer . LONG_SIZE ; 
final int encryptedLength = getIntValue ( entryPosition ) ; 
entryPosition += encryptedLength + OIntegerSerializer . INT_SIZE ; 
return deserializeFromDirectMemory ( valueSerializer , entryPosition ) ; 
} boolean canBeUsedByOrderByAfterFilter ( OIndex < ? > index , List < String > equalsFilterFields , 
List < OPair < String , String > > orderedFields ) { 
if ( orderedFields . isEmpty ( ) ) 
if ( ! index . supportsOrderedIterations ( ) ) 
final List < String > indexFields = definition . getFields ( ) ; 
int endIndex = Math . min ( indexFields . size ( ) , equalsFilterFields . size ( ) ) ; 
final String firstOrder = orderedFields . get ( 0 ) . getValue ( ) ; 
for ( int i = 0 ; i < endIndex ; i ++ ) { 
final String equalsFieldName = equalsFilterFields . get ( i ) ; 
final String indexFieldName = indexFields . get ( i ) ; 
if ( ! equalsFieldName . equals ( indexFieldName ) ) 
endIndex = Math . min ( indexFields . size ( ) , orderedFields . size ( ) + equalsFilterFields . size ( ) ) ; 
if ( endIndex == equalsFilterFields . size ( ) ) { 
for ( int i = equalsFilterFields . size ( ) ; i < endIndex ; i ++ ) { 
int fieldOrderInOrderByClause = i - equalsFilterFields . size ( ) ; 
final OPair < String , String > pair = orderedFields . get ( fieldOrderInOrderByClause ) ; 
if ( ! firstOrder . equals ( pair . getValue ( ) ) ) 
final String orderFieldName = pair . getKey ( ) ; 
if ( ! orderFieldName . equals ( indexFieldName ) ) 
} public static int indexOfOutsideStrings ( final String iText , final char iToFind , int iFrom , int iTo ) { 
if ( iTo == - 1 ) 
iTo = iText . length ( ) - 1 ; 
if ( iFrom == - 1 ) 
iFrom = iText . length ( ) - 1 ; 
boolean escape = false ; 
final StringBuilder buffer = new StringBuilder ( 1024 ) ; 
int i = iFrom ; 
c = iText . charAt ( i ) ; 
if ( ! escape && c == '\\' && ( ( i + 1 ) < iText . length ( ) ) ) { 
if ( iText . charAt ( i + 1 ) == 'u' ) { 
i = readUnicode ( iText , i + 2 , buffer ) ; 
escape = true ; 
if ( c == '\'' || c == '"' ) { 
stringChar = c ; 
if ( ! escape && c == stringChar ) 
if ( escape ) 
escape = false ; 
if ( iFrom < iTo ) { 
if ( ++ i > iTo ) 
if ( -- i < iFrom ) 
} public static int jumpWhiteSpaces ( final CharSequence iText , final int iCurrentPosition , final int iMaxPosition ) { 
return jump ( iText , iCurrentPosition , iMaxPosition , COMMON_JUMP ) ; 
} public static int jump ( final CharSequence iText , int iCurrentPosition , final int iMaxPosition , final String iJumpChars ) { 
if ( iCurrentPosition < 0 ) 
final int size = iMaxPosition > - 1 ? Math . min ( iMaxPosition , iText . length ( ) ) : iText . length ( ) ; 
final int jumpCharSize = iJumpChars . length ( ) ; 
boolean found = true ; 
for ( ; iCurrentPosition < size ; ++ iCurrentPosition ) { 
found = false ; 
c = iText . charAt ( iCurrentPosition ) ; 
for ( int jumpIndex = 0 ; jumpIndex < jumpCharSize ; ++ jumpIndex ) { 
if ( iJumpChars . charAt ( jumpIndex ) == c ) { 
return iCurrentPosition >= size ? - 1 : iCurrentPosition ; 
} public static boolean startsWithIgnoreCase ( final String iText , final String iToFind ) { 
if ( iText . length ( ) < iToFind . length ( ) ) 
return iText . substring ( 0 , iToFind . length ( ) ) . equalsIgnoreCase ( iToFind ) ; 
} public OQueryAbstract setFetchPlan ( final String fetchPlan ) { 
if ( fetchPlan != null && fetchPlan . length ( ) == 0 ) 
this . fetchPlan = null ; 
this . fetchPlan = fetchPlan ; 
public void enqueueRepairRecord ( final ORecordId rid ) { 
if ( rid == null || ! rid . isPersistent ( ) ) 
if ( rid . getClusterPosition ( ) < - 1 ) 
recordProcessed . incrementAndGet ( ) ; 
records . put ( rid , Boolean . TRUE ) ; 
public void cancelRepairRecord ( final ORecordId rid ) { 
if ( records . remove ( rid ) != null ) 
recordCanceled . incrementAndGet ( ) ; 
public void enqueueRepairCluster ( final int clusterId ) { 
if ( clusterId < - 1 ) 
clusters . put ( clusterId , Boolean . TRUE ) ; 
database . checkSecurity ( ORule . ResourceGeneric . SERVER , "status" , ORole . PERMISSION_READ ) ; 
if ( ! ( database instanceof ODatabaseDocumentDistributed ) ) { 
final OHazelcastPlugin dManager = ( OHazelcastPlugin ) ( ( ODatabaseDocumentDistributed ) database ) . getDistributedManager ( ) ; 
if ( dManager == null || ! dManager . isEnabled ( ) ) 
final String databaseName = database . getName ( ) ; 
final ODistributedConfiguration cfg = dManager . getDatabaseConfiguration ( databaseName ) ; 
if ( parsedStatement . outputText ) { 
final StringBuilder output = new StringBuilder ( ) ; 
if ( parsedStatement . servers ) 
output . append ( ODistributedOutput . formatServerStatus ( dManager , dManager . getClusterConfiguration ( ) ) ) ; 
if ( parsedStatement . db ) 
output . append ( ODistributedOutput . formatClusterTable ( dManager , databaseName , cfg , dManager . getTotalNodes ( databaseName ) ) ) ; 
if ( parsedStatement . latency ) 
output . append ( ODistributedOutput . formatLatency ( dManager , dManager . getClusterConfiguration ( ) ) ) ; 
if ( parsedStatement . messages ) 
output . append ( ODistributedOutput . formatMessages ( dManager , dManager . getClusterConfiguration ( ) ) ) ; 
return output . toString ( ) ; 
final ODocument output = new ODocument ( ) ; 
output . field ( "servers" , dManager . getClusterConfiguration ( ) , OType . EMBEDDED ) ; 
output . field ( "database" , cfg . getDocument ( ) , OType . EMBEDDED ) ; 
return output ; 
} private Map < String , Set < String > > getDependencies ( Pattern pattern ) { 
Map < String , Set < String > > result = new HashMap < String , Set < String > > ( ) ; 
for ( PatternNode node : pattern . aliasToNode . values ( ) ) { 
Set < String > currentDependencies = new HashSet < String > ( ) ; 
OWhereClause filter = aliasFilters . get ( node . alias ) ; 
if ( filter != null && filter . getBaseExpression ( ) != null ) { 
List < String > involvedAliases = filter . getBaseExpression ( ) . getMatchPatternInvolvedAliases ( ) ; 
if ( involvedAliases != null ) { 
currentDependencies . addAll ( involvedAliases ) ; 
result . put ( node . alias , currentDependencies ) ; 
} private List < EdgeTraversal > sortEdges ( Map < String , Long > estimatedRootEntries , Pattern pattern , OCommandContext ctx ) { 
OQueryStats stats = null ; 
if ( ctx != null && ctx . getDatabase ( ) != null ) { 
stats = OQueryStats . get ( ( ODatabaseDocumentInternal ) ctx . getDatabase ( ) ) ; 
List < EdgeTraversal > result = new ArrayList < EdgeTraversal > ( ) ; 
Set < PatternEdge > traversedEdges = new HashSet < PatternEdge > ( ) ; 
Set < PatternNode > traversedNodes = new HashSet < PatternNode > ( ) ; 
List < PatternNode > nextNodes = new ArrayList < PatternNode > ( ) ; 
while ( result . size ( ) < pattern . getNumOfEdges ( ) ) { 
for ( OPair < Long , String > rootPair : rootWeights ) { 
PatternNode root = pattern . get ( rootPair . getValue ( ) ) ; 
if ( root . isOptionalNode ( ) ) { 
if ( ! traversedNodes . contains ( root ) ) { 
nextNodes . add ( root ) ; 
if ( nextNodes . isEmpty ( ) ) { 
while ( ! nextNodes . isEmpty ( ) ) { 
PatternNode node = nextNodes . remove ( 0 ) ; 
traversedNodes . add ( node ) ; 
for ( PatternEdge edge : node . out ) { 
if ( ! traversedEdges . contains ( edge ) ) { 
result . add ( new EdgeTraversal ( edge , true ) ) ; 
traversedEdges . add ( edge ) ; 
if ( ! traversedNodes . contains ( edge . in ) && ! nextNodes . contains ( edge . in ) ) { 
nextNodes . add ( edge . in ) ; 
for ( PatternEdge edge : node . in ) { 
if ( ! traversedEdges . contains ( edge ) && edge . item . isBidirectional ( ) ) { 
result . add ( new EdgeTraversal ( edge , false ) ) ; 
if ( ! traversedNodes . contains ( edge . out ) && ! nextNodes . contains ( edge . out ) ) { 
nextNodes . add ( edge . out ) ; 
if ( expression . getOrigin ( ) . getAlias ( ) == null ) { 
expression . getOrigin ( ) . setAlias ( DEFAULT_ALIAS_PREFIX + ( counter ++ ) ) ; 
for ( OMatchPathItem item : expression . getItems ( ) ) { 
if ( item . getFilter ( ) == null ) { 
item . setFilter ( new OMatchFilter ( - 1 ) ) ; 
if ( item . getFilter ( ) . getAlias ( ) == null ) { 
item . getFilter ( ) . setAlias ( DEFAULT_ALIAS_PREFIX + ( counter ++ ) ) ; 
} public synchronized Object createPojo ( final String iClassName ) throws OConfigurationException { 
final Class < ? > entityClass = classHandler . getEntityClass ( iClassName ) ; 
if ( entityClass != null ) 
return createInstance ( entityClass ) ; 
return createInstance ( Class . forName ( iClassName ) ) ; 
} public synchronized void deregisterEntityClasses ( final String iPackageName , final ClassLoader iClassLoader ) { 
deregisterEntityClass ( c ) ; 
if ( OLogManager . instance ( ) . isDebugEnabled ( ) ) { 
for ( Entry < String , Class < ? > > entry : classHandler . getClassesEntrySet ( ) ) { 
} public synchronized void registerEntityClasses ( final Collection < String > iClassNames , final ClassLoader iClassLoader ) { 
registerEntityClasses ( OReflectionHelper . getClassesFor ( iClassNames , iClassLoader ) ) ; 
} public synchronized void registerEntityClasses ( Class < ? > aClass , boolean recursive ) { 
if ( recursive ) { 
classHandler . registerEntityClass ( aClass ) ; 
Field [ ] declaredFields = aClass . getDeclaredFields ( ) ; 
for ( Field declaredField : declaredFields ) { 
Class < ? > declaredFieldType = declaredField . getType ( ) ; 
if ( ! classHandler . containsEntityClass ( declaredFieldType ) ) { 
registerEntityClasses ( declaredFieldType , recursive ) ; 
} public synchronized void setClassHandler ( final OEntityManagerClassHandler iClassHandler ) { 
Iterator < Entry < String , Class < ? > > > iterator = classHandler . getClassesEntrySet ( ) . iterator ( ) ; 
Entry < String , Class < ? > > entry = iterator . next ( ) ; 
boolean forceSchemaReload = ! iterator . hasNext ( ) ; 
iClassHandler . registerEntityClass ( entry . getValue ( ) , forceSchemaReload ) ; 
this . classHandler = iClassHandler ; 
} public DB acquire ( final String iName , final String iUserName , final String iUserPassword ) { 
setup ( ) ; 
return dbPool . acquire ( iName , iUserName , iUserPassword ) ; 
} public int getAvailableConnections ( final String name , final String userName ) { 
return dbPool . getAvailableConnections ( name , userName ) ; 
} public DB acquire ( final String iName , final String iUserName , final String iUserPassword , 
final Map < String , Object > iOptionalParams ) { 
return dbPool . acquire ( iName , iUserName , iUserPassword , iOptionalParams ) ; 
database . checkSecurity ( ORule . ResourceGeneric . CLUSTER , "sync" , ORole . PERMISSION_UPDATE ) ; 
if ( this . parsedStatement . modeFull ) { 
return replaceCluster ( dManager , database , dManager . getServerInstance ( ) , databaseName , this . parsedStatement . clusterName . getStringValue ( ) ) ; 
} public void dumpToLog ( ) { 
final StringBuilder text = new StringBuilder ( ) ; 
text . append ( "Magic:\t\t\t" ) . append ( String . format ( "%016X" , getLongValue ( MAGIC_NUMBER_OFFSET ) ) ) . append ( '\n' ) ; 
text . append ( "CRC32:\t\t\t" ) . append ( String . format ( "%08X" , getIntValue ( CRC32_OFFSET ) ) ) . append ( '\n' ) ; 
final int indexCount = getIntValue ( PAGE_INDEXES_LENGTH_OFFSET ) ; 
int foundEntries = 0 ; 
for ( int i = 0 ; i < indexCount ; ++ i ) { 
final int offset = getIntValue ( PAGE_INDEXES_OFFSET + i * INDEX_ITEM_SIZE ) ; 
text . append ( "\tVersion:\t" ) 
. append ( String . format ( "%08X" , getIntValue ( PAGE_INDEXES_OFFSET + i * INDEX_ITEM_SIZE + OIntegerSerializer . INT_SIZE ) ) ) 
. append ( '\n' ) ; 
if ( ( offset & MARKED_AS_DELETED_FLAG ) != 0 ) { 
final int cleanOffset = offset & POSITION_MASK ; 
if ( cleanOffset + OIntegerSerializer . INT_SIZE <= MAX_PAGE_SIZE_BYTES ) { 
text . append ( "?\n" ) ; 
if ( cleanOffset + OIntegerSerializer . INT_SIZE * 2 <= MAX_PAGE_SIZE_BYTES ) { 
text . append ( "\t\tIndex:\t\t" ) . append ( String . format ( "%08X" , getIntValue ( cleanOffset + OIntegerSerializer . INT_SIZE ) ) ) 
if ( cleanOffset + OIntegerSerializer . INT_SIZE * 3 <= MAX_PAGE_SIZE_BYTES ) { 
++ foundEntries ; 
OLogManager . instance ( ) . error ( this , "%s" , null , text ) ; 
} public static synchronized < T extends Object > Iterator < T > lookupProviderWithOrientClassLoader ( Class < T > clazz ) { 
return lookupProviderWithOrientClassLoader ( clazz , OClassLoaderHelper . class . getClassLoader ( ) ) ; 
} public static long getCappedRuntimeMaxMemory ( long unlimitedCap ) { 
final long jvmMaxMemory = Runtime . getRuntime ( ) . maxMemory ( ) ; 
return jvmMaxMemory == Long . MAX_VALUE ? unlimitedCap : jvmMaxMemory ; 
} public static void checkCacheMemoryConfiguration ( ) { 
final long maxHeapSize = Runtime . getRuntime ( ) . maxMemory ( ) ; 
final long maxCacheSize = getMaxCacheMemorySize ( ) ; 
final ONative . MemoryLimitResult physicalMemory = ONative . instance ( ) . getMemoryLimit ( false ) ; 
if ( maxHeapSize != Long . MAX_VALUE && physicalMemory != null && maxHeapSize + maxCacheSize > physicalMemory . memoryLimit ) 
OLogManager . instance ( ) . warnNoDb ( OMemory . class , 
} public static void fixCommonConfigurationProblems ( ) { 
long diskCacheSize = OGlobalConfiguration . DISK_CACHE_SIZE . getValueAsLong ( ) ; 
final int max32BitCacheSize = 512 ; 
if ( getJavaBitWidth ( ) == 32 && diskCacheSize > max32BitCacheSize ) { 
diskCacheSize , max32BitCacheSize ) ; 
OGlobalConfiguration . DISK_CACHE_SIZE . setValue ( max32BitCacheSize ) ; 
} public Vertex vertexFromJson ( final InputStream json ) throws IOException { 
final JsonParser jp = jsonFactory . createParser ( json ) ; 
return this . vertexFromJson ( node ) ; 
} public Vertex vertexFromJson ( final JsonNode json ) throws IOException { 
final Map < String , Object > props = readProperties ( json , true , this . hasEmbeddedTypes ) ; 
final Object vertexId = getTypedValueFromJsonNode ( json . get ( GraphSONTokens . _ID ) ) ; 
final Vertex v = factory . createVertex ( vertexId ) ; 
for ( Map . Entry < String , Object > entry : props . entrySet ( ) ) { 
if ( includeKey ( entry . getKey ( ) , vertexPropertyKeys , this . vertexPropertiesRule ) ) { 
v . setProperty ( entry . getKey ( ) , entry . getValue ( ) ) ; 
} public Edge edgeFromJson ( final JSONObject json , final Vertex out , final Vertex in ) throws IOException { 
return this . edgeFromJson ( json . toString ( ) , out , in ) ; 
} public Edge edgeFromJson ( final String json , final Vertex out , final Vertex in ) throws IOException { 
return this . edgeFromJson ( node , out , in ) ; 
} public Edge edgeFromJson ( final JsonNode json , final Vertex out , final Vertex in ) throws IOException { 
final Map < String , Object > props = OGraphSONUtility . readProperties ( json , true , this . hasEmbeddedTypes ) ; 
final Object edgeId = getTypedValueFromJsonNode ( json . get ( GraphSONTokens . _ID ) ) ; 
final JsonNode nodeLabel = json . get ( GraphSONTokens . _LABEL ) ; 
final String label = nodeLabel == null ? EMPTY_STRING : nodeLabel . textValue ( ) ; 
final Edge e = factory . createEdge ( edgeId , out , in , label ) ; 
if ( includeKey ( entry . getKey ( ) , edgePropertyKeys , this . edgePropertiesRule ) ) { 
e . setProperty ( entry . getKey ( ) , entry . getValue ( ) ) ; 
} public JSONObject jsonFromElement ( final Element element ) throws JSONException { 
final ObjectNode objectNode = this . objectNodeFromElement ( element ) ; 
return new JSONObject ( new JSONTokener ( mapper . writeValueAsString ( objectNode ) ) ) ; 
throw new JSONException ( ioe ) ; 
} public ObjectNode objectNodeFromElement ( final Element element ) { 
final boolean isEdge = element instanceof Edge ; 
final boolean showTypes = mode == GraphSONMode . EXTENDED ; 
final List < String > propertyKeys = isEdge ? this . edgePropertyKeys : this . vertexPropertyKeys ; 
final ElementPropertiesRule elementPropertyConfig = isEdge ? this . edgePropertiesRule : this . vertexPropertiesRule ; 
final ObjectNode jsonElement = createJSONMap ( createPropertyMap ( element , propertyKeys , elementPropertyConfig , normalized ) , 
propertyKeys , showTypes ) ; 
if ( ( isEdge && this . includeReservedEdgeId ) || ( ! isEdge && this . includeReservedVertexId ) ) { 
putObject ( jsonElement , GraphSONTokens . _ID , element . getId ( ) ) ; 
if ( element instanceof Edge ) { 
final Edge edge = ( Edge ) element ; 
if ( this . includeReservedEdgeId ) { 
if ( this . includeReservedEdgeType ) { 
jsonElement . put ( GraphSONTokens . _TYPE , GraphSONTokens . EDGE ) ; 
if ( this . includeReservedEdgeOutV ) { 
putObject ( jsonElement , GraphSONTokens . _OUT_V , edge . getVertex ( Direction . OUT ) . getId ( ) ) ; 
if ( this . includeReservedEdgeInV ) { 
putObject ( jsonElement , GraphSONTokens . _IN_V , edge . getVertex ( Direction . IN ) . getId ( ) ) ; 
if ( this . includeReservedEdgeLabel ) { 
jsonElement . put ( GraphSONTokens . _LABEL , edge . getLabel ( ) ) ; 
} else if ( element instanceof Vertex ) { 
if ( this . includeReservedVertexId ) { 
if ( this . includeReservedVertexType ) { 
jsonElement . put ( GraphSONTokens . _TYPE , GraphSONTokens . VERTEX ) ; 
return jsonElement ; 
} public static Vertex vertexFromJson ( final JSONObject json , final ElementFactory factory , final GraphSONMode mode , 
final Set < String > propertyKeys ) throws IOException { 
final OGraphSONUtility graphson = new OGraphSONUtility ( mode , factory , propertyKeys , null ) ; 
return graphson . vertexFromJson ( json ) ; 
} public static Edge edgeFromJson ( final JSONObject json , final Vertex out , final Vertex in , final ElementFactory factory , 
final GraphSONMode mode , final Set < String > propertyKeys ) throws IOException { 
final OGraphSONUtility graphson = new OGraphSONUtility ( mode , factory , null , propertyKeys ) ; 
return graphson . edgeFromJson ( json , out , in ) ; 
} public static JSONObject jsonFromElement ( final Element element , final Set < String > propertyKeys , final GraphSONMode mode ) 
throws JSONException { 
final OGraphSONUtility graphson = element instanceof Edge ? new OGraphSONUtility ( mode , null , null , propertyKeys ) 
: new OGraphSONUtility ( mode , null , propertyKeys , null ) ; 
return graphson . jsonFromElement ( element ) ; 
} public static ObjectNode objectNodeFromElement ( final Element element , final Set < String > propertyKeys , final GraphSONMode mode ) { 
return graphson . objectNodeFromElement ( element ) ; 
} public void executeImport ( ODocument cfg , OServer server ) { 
OETLJob job = new OETLJob ( cfg , server , new OETLListener ( ) { 
public void onEnd ( OETLJob etlJob ) { 
currentJob = null ; 
job . validate ( ) ; 
currentJob = job ; 
pool . execute ( job ) ; 
} public ODocument status ( ) { 
ODocument status = new ODocument ( ) ; 
Collection < ODocument > jobs = new ArrayList < ODocument > ( ) ; 
if ( currentJob != null ) { 
jobs . add ( currentJob . status ( ) ) ; 
status . field ( "jobs" , jobs ) ; 
final ORID r = object . getIdentity ( ) ; 
buffer . putShort ( ( short ) r . getClusterId ( ) ) ; 
byte [ ] stream = new byte [ OLongSerializer . LONG_SIZE ] ; 
OLongSerializer . INSTANCE . serialize ( r . getClusterPosition ( ) , stream , 0 ) ; 
buffer . put ( stream ) ; 
public OIdentifiable deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final int clusterId = buffer . getShort ( ) ; 
final byte [ ] stream = new byte [ OLongSerializer . LONG_SIZE ] ; 
buffer . get ( stream ) ; 
final long clusterPosition = OLongSerializer . INSTANCE . deserialize ( stream , 0 ) ; 
final int clusterId = walChanges . getShortValue ( buffer , offset ) ; 
final long clusterPosition = OLongSerializer . INSTANCE 
. deserialize ( walChanges . getBinaryValue ( buffer , offset + OShortSerializer . SHORT_SIZE , OLongSerializer . LONG_SIZE ) , 0 ) ; 
public < T > Comparator < T > getComparator ( Class < T > clazz ) { 
boolean useUnsafe = OGlobalConfiguration . MEMORY_USE_UNSAFE . getValueAsBoolean ( ) ; 
if ( clazz . equals ( byte [ ] . class ) ) { 
if ( useUnsafe && unsafeWasDetected ) 
return ( Comparator < T > ) OUnsafeByteArrayComparator . INSTANCE ; 
return ( Comparator < T > ) OByteArrayComparator . INSTANCE ; 
} public Map < String , Set < String > > getActiveClusterMap ( ) { 
if ( distributedManager . isOffline ( ) || ! distributedManager . isNodeOnline ( distributedManager . getLocalNodeName ( ) , getName ( ) ) 
|| OScenarioThreadLocal . INSTANCE . isRunModeDistributed ( ) ) { 
return super . getActiveClusterMap ( ) ; 
Map < String , Set < String > > result = new HashMap < > ( ) ; 
ODistributedConfiguration cfg = getDistributedConfiguration ( ) ; 
for ( String server : distributedManager . getActiveServers ( ) ) { 
if ( getClustersOnServer ( cfg , server ) . contains ( "*" ) ) { 
result . put ( server , getStorage ( ) . getClusterNames ( ) ) ; 
result . put ( server , getClustersOnServer ( cfg , server ) ) ; 
} public Map < String , Set < String > > getActiveDataCenterMap ( ) { 
Set < String > servers = cfg . getRegisteredServers ( ) ; 
for ( String server : servers ) { 
String dc = cfg . getDataCenterOfServer ( server ) ; 
Set < String > dcConfig = result . get ( dc ) ; 
if ( dcConfig == null ) { 
dcConfig = new HashSet < > ( ) ; 
result . put ( dc , dcConfig ) ; 
dcConfig . add ( server ) ; 
} public boolean commit2pc ( ODistributedRequestId transactionId , boolean local ) { 
getStorageDistributed ( ) . resetLastValidBackup ( ) ; 
ODistributedDatabase localDistributedDatabase = getStorageDistributed ( ) . getLocalDistributedDatabase ( ) ; 
ONewDistributedTxContextImpl txContext = ( ONewDistributedTxContextImpl ) localDistributedDatabase . getTxContext ( transactionId ) ; 
if ( txContext != null ) { 
if ( SUCCESS . equals ( txContext . getStatus ( ) ) ) { 
txContext . commit ( this ) ; 
localDistributedDatabase . popTxContext ( transactionId ) ; 
OLiveQueryHook . notifyForTxChanges ( this ) ; 
OLiveQueryHookV2 . notifyForTxChanges ( this ) ; 
OLiveQueryHook . removePendingDatabaseOps ( this ) ; 
OLiveQueryHookV2 . removePendingDatabaseOps ( this ) ; 
} else if ( TIMEDOUT . equals ( txContext . getStatus ( ) ) ) { 
int nretry = getConfiguration ( ) . getValueAsInteger ( DISTRIBUTED_CONCURRENT_TX_MAX_AUTORETRY ) ; 
int delay = getConfiguration ( ) . getValueAsInteger ( DISTRIBUTED_CONCURRENT_TX_AUTORETRY_DELAY ) ; 
for ( int i = 0 ; i < nretry ; i ++ ) { 
if ( i > 0 ) { 
Thread . sleep ( new Random ( ) . nextInt ( delay ) ) ; 
OException . wrapException ( new OInterruptedException ( e . getMessage ( ) ) , e ) ; 
internalBegin2pc ( txContext , local ) ; 
txContext . setStatus ( SUCCESS ) ; 
} catch ( ODistributedRecordLockedException | ODistributedKeyLockedException ex ) { 
if ( ! SUCCESS . equals ( txContext . getStatus ( ) ) ) { 
txContext . destroy ( ) ; 
Orient . instance ( ) . submit ( ( ) -> { 
transactionId ) ; 
distributedManager . installDatabase ( false , ODatabaseDocumentDistributed . this . getName ( ) , true , true ) ; 
} protected static String separateAlgorithm ( final String cipherTransform ) { 
String [ ] array = cipherTransform . split ( "/" ) ; 
if ( array . length > 1 ) 
return array [ 0 ] ; 
} public static OSymmetricKey fromConfig ( final OSymmetricKeyConfig keyConfig ) { 
if ( keyConfig . usesKeyString ( ) ) { 
return fromString ( keyConfig . getKeyAlgorithm ( ) , keyConfig . getKeyString ( ) ) ; 
} else if ( keyConfig . usesKeyFile ( ) ) { 
return fromFile ( keyConfig . getKeyAlgorithm ( ) , keyConfig . getKeyFile ( ) ) ; 
} else if ( keyConfig . usesKeystore ( ) ) { 
return fromKeystore ( keyConfig . getKeystoreFile ( ) , keyConfig . getKeystorePassword ( ) , keyConfig . getKeystoreKeyAlias ( ) , 
keyConfig . getKeystoreKeyPassword ( ) ) ; 
} public static OSymmetricKey fromFile ( final String algorithm , final String path ) { 
String base64Key = null ; 
java . io . FileInputStream fis = null ; 
fis = new java . io . FileInputStream ( OSystemVariableResolver . resolveSystemVariables ( path ) ) ; 
return fromStream ( algorithm , fis ) ; 
if ( fis != null ) 
} public static OSymmetricKey fromStream ( final String algorithm , final InputStream is ) { 
base64Key = OIOUtils . readStreamAsString ( is ) ; 
return new OSymmetricKey ( algorithm , base64Key ) ; 
} public static OSymmetricKey fromKeystore ( final String path , final String password , final String keyAlias , 
final String keyPassword ) { 
OSymmetricKey sk = null ; 
KeyStore ks = KeyStore . getInstance ( "JCEKS" ) ; 
return fromKeystore ( fis , password , keyAlias , keyPassword ) ; 
} public static OSymmetricKey fromKeystore ( final InputStream is , final String password , final String keyAlias , 
char [ ] ksPasswdChars = null ; 
if ( password != null ) 
ksPasswdChars = password . toCharArray ( ) ; 
ks . load ( is , ksPasswdChars ) ; 
char [ ] ksKeyPasswdChars = null ; 
if ( keyPassword != null ) 
ksKeyPasswdChars = keyPassword . toCharArray ( ) ; 
KeyStore . ProtectionParameter protParam = new KeyStore . PasswordProtection ( ksKeyPasswdChars ) ; 
KeyStore . SecretKeyEntry skEntry = ( KeyStore . SecretKeyEntry ) ks . getEntry ( keyAlias , protParam ) ; 
if ( skEntry == null ) 
SecretKey secretKey = skEntry . getSecretKey ( ) ; 
sk = new OSymmetricKey ( secretKey ) ; 
return sk ; 
} public String encrypt ( final String value ) { 
return encrypt ( value . getBytes ( "UTF8" ) ) ; 
} public String encrypt ( final String transform , final byte [ ] bytes ) { 
String encodedJSON = null ; 
if ( secretKey == null ) 
if ( transform == null ) 
Cipher cipher = Cipher . getInstance ( transform ) ; 
cipher . init ( Cipher . ENCRYPT_MODE , secretKey ) ; 
byte [ ] initVector = cipher . getIV ( ) ; 
byte [ ] encrypted = cipher . doFinal ( bytes ) ; 
encodedJSON = encodeJSON ( encrypted , initVector ) ; 
return encodedJSON ; 
} public String decryptAsString ( final String encodedJSON ) { 
byte [ ] decrypted = decrypt ( encodedJSON ) ; 
return new String ( decrypted , "UTF8" ) ; 
} public byte [ ] decrypt ( final String encodedJSON ) { 
byte [ ] result = null ; 
if ( encodedJSON == null ) 
byte [ ] decoded = convertFromBase64 ( encodedJSON ) ; 
if ( decoded == null ) 
String json = new String ( decoded , "UTF8" ) ; 
final ODocument doc = new ODocument ( ) . fromJSON ( json , "noMap" ) ; 
String algorithm = secretKeyAlgorithm ; 
if ( doc . containsField ( "algorithm" ) ) 
algorithm = doc . field ( "algorithm" ) ; 
String transform = defaultCipherTransformation ; 
if ( doc . containsField ( "transform" ) ) 
transform = doc . field ( "transform" ) ; 
String payloadBase64 = doc . field ( "payload" ) ; 
String ivBase64 = doc . field ( "iv" ) ; 
byte [ ] payload = null ; 
byte [ ] iv = null ; 
if ( payloadBase64 != null ) 
payload = convertFromBase64 ( payloadBase64 ) ; 
if ( ivBase64 != null ) 
iv = convertFromBase64 ( ivBase64 ) ; 
if ( iv != null ) 
cipher . init ( Cipher . DECRYPT_MODE , secretKey , new IvParameterSpec ( iv ) ) ; 
cipher . init ( Cipher . DECRYPT_MODE , secretKey ) ; 
result = cipher . doFinal ( payload ) ; 
} public void saveToStream ( final OutputStream os ) { 
if ( os == null ) 
final OutputStreamWriter osw = new OutputStreamWriter ( os ) ; 
final BufferedWriter writer = new BufferedWriter ( osw ) ; 
writer . write ( getBase64Key ( ) ) ; 
writer . close ( ) ; 
os . close ( ) ; 
} public void saveToKeystore ( final OutputStream os , final String ksPasswd , final String keyAlias , final String keyPasswd ) { 
if ( ksPasswd == null ) 
if ( keyAlias == null ) 
if ( keyPasswd == null ) 
char [ ] ksPasswdCA = ksPasswd . toCharArray ( ) ; 
char [ ] keyPasswdCA = keyPasswd . toCharArray ( ) ; 
ks . load ( null , ksPasswdCA ) ; 
KeyStore . ProtectionParameter protParam = new KeyStore . PasswordProtection ( keyPasswdCA ) ; 
KeyStore . SecretKeyEntry skEntry = new KeyStore . SecretKeyEntry ( secretKey ) ; 
ks . setEntry ( keyAlias , skEntry , protParam ) ; 
ks . store ( os , ksPasswdCA ) ; 
public void serializeInByteBufferObject ( UUID object , ByteBuffer buffer , Object ... hints ) { 
buffer . putLong ( object . getMostSignificantBits ( ) ) ; 
buffer . putLong ( object . getLeastSignificantBits ( ) ) ; 
public UUID deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final long mostSignificantBits = buffer . getLong ( ) ; 
final long leastSignificantBits = buffer . getLong ( ) ; 
return new UUID ( mostSignificantBits , leastSignificantBits ) ; 
public UUID deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final long mostSignificantBits = walChanges . getLongValue ( buffer , offset ) ; 
final long leastSignificantBits = walChanges . getLongValue ( buffer , offset + OLongSerializer . LONG_SIZE ) ; 
} public OCommandContext setChild ( final OCommandContext iContext ) { 
if ( iContext == null ) { 
if ( child != null ) { 
child . setParent ( null ) ; 
child = null ; 
} else if ( child != iContext ) { 
child = iContext ; 
iContext . setParent ( this ) ; 
} public synchronized boolean addToUniqueResult ( Object o ) { 
Object toAdd = o ; 
if ( o instanceof ODocument && ( ( ODocument ) o ) . getIdentity ( ) . isNew ( ) ) { 
toAdd = new ODocumentEqualityWrapper ( ( ODocument ) o ) ; 
return this . uniqueResult . add ( toAdd ) ; 
public void serializeInByteBufferObject ( BigDecimal object , ByteBuffer buffer , Object ... hints ) { 
buffer . putInt ( object . scale ( ) ) ; 
OBinaryTypeSerializer . INSTANCE . serializeInByteBufferObject ( object . unscaledValue ( ) . toByteArray ( ) , buffer ) ; 
public BigDecimal deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final int scale = buffer . getInt ( ) ; 
final byte [ ] unscaledValue = OBinaryTypeSerializer . INSTANCE . deserializeFromByteBufferObject ( buffer ) ; 
return new BigDecimal ( new BigInteger ( unscaledValue ) , scale ) ; 
buffer . position ( buffer . position ( ) + OIntegerSerializer . INT_SIZE ) ; 
return OIntegerSerializer . INT_SIZE + OBinaryTypeSerializer . INSTANCE . getObjectSizeInByteBuffer ( buffer ) ; 
public BigDecimal deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final int scale = walChanges . getIntValue ( buffer , offset ) ; 
final byte [ ] unscaledValue = OBinaryTypeSerializer . INSTANCE . deserializeFromByteBufferObject ( buffer , walChanges , offset ) ; 
return OIntegerSerializer . INT_SIZE + OBinaryTypeSerializer . INSTANCE 
. getObjectSizeInByteBuffer ( buffer , walChanges , offset + OIntegerSerializer . INT_SIZE ) ; 
} private Object getValueAsObjectOrMap ( ODocument iRecord , String iFieldValue , OType iType , OType iLinkedType , 
Map < String , Character > iFieldTypes , boolean iNoMap , String iOptions ) { 
final String [ ] fields = OStringParser . getWords ( iFieldValue . substring ( 1 , iFieldValue . length ( ) - 1 ) , ":," , true ) ; 
if ( fields == null || fields . length == 0 ) 
if ( iNoMap ) { 
ODocument res = new ODocument ( ) ; 
ODocumentInternal . addOwner ( res , iRecord ) ; 
return new HashMap < String , Object > ( ) ; 
if ( iNoMap || hasTypeField ( fields ) ) { 
return getValueAsRecord ( iRecord , iFieldValue , iType , iOptions , fields ) ; 
return getValueAsMap ( iRecord , iFieldValue , iLinkedType , iFieldTypes , false , iOptions , fields ) ; 
} protected String authenticate ( final String username , final String password , final String iDatabaseName ) throws IOException { 
ODatabaseDocument db = null ; 
String userRid = null ; 
db = ( ODatabaseDocument ) server . openDatabase ( iDatabaseName , username , password ) ; 
} catch ( OSecurityAccessException e ) { 
} catch ( OLockException e ) { 
if ( db != null ) { 
db . close ( ) ; 
return userRid ; 
public static Object getMapEntry ( final Map < String , ? > iMap , final Object iKey ) { 
if ( iMap == null || iKey == null ) 
if ( iKey instanceof String ) { 
String iName = ( String ) iKey ; 
int pos = iName . indexOf ( '.' ) ; 
if ( pos > - 1 ) 
iName = iName . substring ( 0 , pos ) ; 
final Object value = iMap . get ( iName ) ; 
final String restFieldName = iName . substring ( pos + 1 ) ; 
if ( value instanceof ODocument ) 
return getFieldValue ( value , restFieldName ) ; 
else if ( value instanceof Map < ? , ? > ) 
return getMapEntry ( ( Map < String , ? > ) value , restFieldName ) ; 
return iMap . get ( iKey ) ; 
public static boolean hasSameContentOf ( final ODocument iCurrent , final ODatabaseDocumentInternal iMyDb , final ODocument iOther , 
final ODatabaseDocumentInternal iOtherDb , RIDMapper ridMapper ) { 
return hasSameContentOf ( iCurrent , iMyDb , iOther , iOtherDb , ridMapper , true ) ; 
final ODatabaseDocumentInternal iOtherDb , RIDMapper ridMapper , final boolean iCheckAlsoIdentity ) { 
if ( iOther == null ) 
if ( iCheckAlsoIdentity && iCurrent . getIdentity ( ) . isValid ( ) && ! iCurrent . getIdentity ( ) . equals ( iOther . getIdentity ( ) ) ) 
if ( iMyDb != null ) 
makeDbCall ( iMyDb , new ODbRelatedCall < Object > ( ) { 
public Object call ( ODatabaseDocumentInternal database ) { 
if ( iCurrent . getInternalStatus ( ) == STATUS . NOT_LOADED ) 
iCurrent . reload ( ) ; 
if ( iOtherDb != null ) 
makeDbCall ( iOtherDb , new ODbRelatedCall < Object > ( ) { 
if ( iOther . getInternalStatus ( ) == STATUS . NOT_LOADED ) 
iOther . reload ( ) ; 
iCurrent . checkForFields ( ) ; 
iOther . checkForFields ( ) ; 
if ( iCurrent . fields ( ) != iOther . fields ( ) ) 
Object myFieldValue ; 
Object otherFieldValue ; 
for ( Entry < String , Object > f : iCurrent ) { 
myFieldValue = f . getValue ( ) ; 
otherFieldValue = iOther . _fields . get ( f . getKey ( ) ) . value ; 
if ( myFieldValue == otherFieldValue ) 
if ( myFieldValue == null ) { 
if ( otherFieldValue != null ) 
} else if ( otherFieldValue == null ) 
if ( myFieldValue != null ) 
if ( myFieldValue instanceof Set && otherFieldValue instanceof Set ) { 
if ( ! compareSets ( iMyDb , ( Set < ? > ) myFieldValue , iOtherDb , ( Set < ? > ) otherFieldValue , ridMapper ) ) 
} else if ( myFieldValue instanceof Collection && otherFieldValue instanceof Collection ) { 
if ( ! compareCollections ( iMyDb , ( Collection < ? > ) myFieldValue , iOtherDb , ( Collection < ? > ) otherFieldValue , ridMapper ) ) 
} else if ( myFieldValue instanceof ORidBag && otherFieldValue instanceof ORidBag ) { 
if ( ! compareBags ( iMyDb , ( ORidBag ) myFieldValue , iOtherDb , ( ORidBag ) otherFieldValue , ridMapper ) ) 
} else if ( myFieldValue instanceof Map && otherFieldValue instanceof Map ) { 
if ( ! compareMaps ( iMyDb , ( Map < Object , Object > ) myFieldValue , iOtherDb , ( Map < Object , Object > ) otherFieldValue , ridMapper ) ) 
} else if ( myFieldValue instanceof ODocument && otherFieldValue instanceof ODocument ) { 
if ( ! hasSameContentOf ( ( ODocument ) myFieldValue , iMyDb , ( ODocument ) otherFieldValue , iOtherDb , ridMapper ) ) 
if ( ! compareScalarValues ( myFieldValue , iMyDb , otherFieldValue , iOtherDb , ridMapper ) ) 
} public String getRemoteAddress ( ) { 
Socket socket = null ; 
if ( getProtocol ( ) != null ) { 
socket = getProtocol ( ) . getChannel ( ) . socket ; 
for ( ONetworkProtocol protocol : this . protocols ) { 
socket = protocol . getChannel ( ) . socket ; 
if ( socket != null ) 
if ( socket != null ) { 
final InetSocketAddress remoteAddress = ( InetSocketAddress ) socket . getRemoteSocketAddress ( ) ; 
return remoteAddress . getAddress ( ) . getHostAddress ( ) + ":" + remoteAddress . getPort ( ) ; 
} protected ORecord getRecord ( ) { 
final ORecord record ; 
if ( reusedRecord != null ) { 
record = reusedRecord ; 
record . reset ( ) ; 
record = null ; 
} protected ORecord readCurrentRecord ( ORecord iRecord , final int iMovement ) { 
if ( limit > - 1 && browsedRecords >= limit ) 
final boolean moveResult ; 
switch ( iMovement ) { 
moveResult = nextPosition ( ) ; 
case - 1 : 
moveResult = prevPosition ( ) ; 
case 0 : 
moveResult = checkCurrentPosition ( ) ; 
if ( ! moveResult ) 
ORecordInternal . setIdentity ( iRecord , new ORecordId ( current . getClusterId ( ) , current . getClusterPosition ( ) ) ) ; 
iRecord = database . load ( iRecord , fetchPlan , false ) ; 
iRecord = database . load ( current , fetchPlan , false ) ; 
} catch ( ODatabaseException e ) { 
if ( Thread . interrupted ( ) || database . isClosed ( ) ) 
if ( e . getCause ( ) instanceof OSecurityException ) 
brokenRIDs . add ( current . copy ( ) ) ; 
browsedRecords ++ ; 
} while ( iMovement != 0 ) ; 
} public void importDelta ( final OServer serverInstance , final String databaseName , final FileInputStream in , final String iNode ) 
final String nodeName = serverInstance . getDistributedManager ( ) . getLocalNodeName ( ) ; 
final ODatabaseDocumentInternal db = serverInstance . openDatabase ( databaseName ) ; 
OScenarioThreadLocal . executeAsDistributed ( new Callable < Object > ( ) { 
db . activateOnCurrentThread ( ) ; 
long totalRecords = 0 ; 
long totalCreated = 0 ; 
long totalUpdated = 0 ; 
long totalDeleted = 0 ; 
long totalHoles = 0 ; 
long totalSkipped = 0 ; 
long lastLap = System . currentTimeMillis ( ) ; 
final DataInputStream input = new DataInputStream ( in ) ; 
final long records = input . readLong ( ) ; 
for ( long i = 0 ; i < records ; ++ i ) { 
final int clusterId = input . readInt ( ) ; 
final long clusterPos = input . readLong ( ) ; 
final boolean deleted = input . readBoolean ( ) ; 
final ORecordId rid = new ORecordId ( clusterId , clusterPos ) ; 
totalRecords ++ ; 
final OPaginatedCluster cluster = ( OPaginatedCluster ) db . getStorage ( ) . getUnderlying ( ) 
. getClusterById ( rid . getClusterId ( ) ) ; 
final OPaginatedCluster . RECORD_STATUS recordStatus = cluster . getRecordStatus ( rid . getClusterPosition ( ) ) ; 
ORecord newRecord = null ; 
if ( deleted ) { 
switch ( recordStatus ) { 
case REMOVED : 
totalSkipped ++ ; 
case ALLOCATED : 
case PRESENT : 
db . delete ( rid ) ; 
case NOT_EXISTENT : 
totalDeleted ++ ; 
final int recordVersion = input . readInt ( ) ; 
final int recordType = input . readByte ( ) ; 
final int recordSize = input . readInt ( ) ; 
final byte [ ] recordContent = new byte [ recordSize ] ; 
input . read ( recordContent ) ; 
newRecord = Orient . instance ( ) . getRecordFactoryManager ( ) 
. newInstance ( ( byte ) recordType , rid . getClusterId ( ) , null ) ; 
ORecordInternal . fill ( newRecord , rid , ORecordVersionHelper . setRollbackMode ( recordVersion ) , recordContent , true ) ; 
final ORecord loadedRecord = rid . getRecord ( ) ; 
if ( loadedRecord instanceof ODocument ) { 
ODocument loadedDocument = ( ODocument ) loadedRecord ; 
loadedDocument . merge ( ( ODocument ) newRecord , false , false ) ; 
ORecordInternal . setVersion ( loadedRecord , ORecordVersionHelper . setRollbackMode ( recordVersion ) ) ; 
loadedDocument . setDirty ( ) ; 
newRecord = loadedDocument ; 
newRecord . save ( ) ; 
recordType , recordSize , recordVersion , newRecord ) ; 
totalUpdated ++ ; 
ORecordInternal . fill ( newRecord , new ORecordId ( rid . getClusterId ( ) , - 1 ) , recordVersion , recordContent , true ) ; 
ODistributedServerLog . info ( this , nodeName , iNode , DIRECTION . IN , 
recordSize , recordVersion , newRecord ) ; 
} catch ( ORecordDuplicatedException e ) { 
rid , recordType , recordSize , recordVersion , newRecord ) ; 
final ORecord duplicatedRecord = db . load ( e . getRid ( ) , null , true ) ; 
if ( duplicatedRecord == null ) { 
final ODocument doc = ( ODocument ) newRecord ; 
final OIndex < ? > index = db . getMetadata ( ) . getIndexManager ( ) . getIndex ( e . getIndexName ( ) ) ; 
final List < String > fields = index . getDefinition ( ) . getFields ( ) ; 
final List < Object > values = new ArrayList < Object > ( fields . size ( ) ) ; 
for ( String f : fields ) { 
values . add ( doc . field ( f ) ) ; 
final Object keyValue = index . getDefinition ( ) . createValue ( values ) ; 
index . remove ( keyValue , e . getRid ( ) ) ; 
if ( newRecord . getIdentity ( ) . getClusterPosition ( ) < clusterPos ) { 
newRecord . delete ( ) ; 
totalHoles ++ ; 
} while ( newRecord . getIdentity ( ) . getClusterPosition ( ) < clusterPos ) ; 
totalCreated ++ ; 
if ( newRecord . getIdentity ( ) . isPersistent ( ) && ! newRecord . getIdentity ( ) . equals ( rid ) ) 
throw new ODistributedDatabaseDeltaSyncException ( 
if ( now - lastLap > 2000 ) { 
totalCreated , totalUpdated , totalDeleted , totalHoles , totalSkipped ) ; 
lastLap = now ; 
db . getMetadata ( ) . reload ( ) ; 
input . close ( ) ; 
db . getName ( ) ) ; 
throw OException . wrapException ( 
db . getName ( ) , totalRecords , totalCreated , totalUpdated , totalDeleted , totalHoles , totalSkipped ) ; 
ODistributedServerLog . error ( this , nodeName , iNode , DIRECTION . IN , 
throw OException . wrapException ( new ODistributedDatabaseDeltaSyncException ( 
} public double gcdist ( double lata , double longa , double latb , double longb ) { 
double midlat , psi , dist ; 
midlat = 0.5 * ( lata + latb ) ; 
psi = 0.0174532925 
* Math . sqrt ( Math . pow ( lata - latb , 2 ) 
+ Math . pow ( ( longa - longb ) 
* Math . cos ( 0.0174532925 * midlat ) , 2 ) ) ; 
dist = 6372.640112 * psi ; 
return dist ; 
} protected double getSimpleHeuristicCost ( double x , double g , double dFactor ) { 
double dx = Math . abs ( x - g ) ; 
return dFactor * ( dx ) ; 
} protected double getManhatanHeuristicCost ( double x , double y , double gx , double gy , double dFactor ) { 
double dx = Math . abs ( x - gx ) ; 
double dy = Math . abs ( y - gy ) ; 
return dFactor * ( dx + dy ) ; 
} protected double getDiagonalHeuristicCost ( double x , double y , double gx , double gy , double dFactor ) { 
double h_diagonal = Math . min ( dx , dy ) ; 
double h_straight = dx + dy ; 
return ( dFactor * 2 ) * h_diagonal + dFactor * ( h_straight - 2 * h_diagonal ) ; 
} protected double getEuclideanHeuristicCost ( double x , double y , double gx , double gy , double dFactor ) { 
return ( dFactor * Math . sqrt ( Math . pow ( dx , 2 ) + Math . pow ( dy , 2 ) ) ) ; 
} protected double getTieBreakingHeuristicCost ( double x , double y , double sx , double sy , double gx , double gy , double heuristic ) { 
double dx1 = x - gx ; 
double dy1 = y - gy ; 
double dx2 = sx - gx ; 
double dy2 = sy - gy ; 
double cross = Math . abs ( dx1 * dy2 - dx2 * dy1 ) ; 
heuristic += ( cross * 0.0001 ) ; 
return heuristic ; 
} public OrientGraph getTx ( ) { 
final OrientGraph g ; 
if ( pool == null ) { 
g = ( OrientGraph ) getTxGraphImplFactory ( ) . getGraph ( getDatabase ( ) , user , password , settings ) ; 
g = ( OrientGraph ) getTxGraphImplFactory ( ) . getGraph ( pool , settings ) ; 
initGraph ( g ) ; 
return g ; 
} public OrientGraphNoTx getNoTx ( ) { 
final OrientGraphNoTx g ; 
g = ( OrientGraphNoTx ) getNoTxGraphImplFactory ( ) . getGraph ( getDatabase ( ) , user , password , settings ) ; 
g = ( OrientGraphNoTx ) getNoTxGraphImplFactory ( ) . getGraph ( pool , settings ) ; 
} public ODatabaseDocumentTx getDatabase ( final boolean iCreate , final boolean iOpen ) { 
if ( pool != null ) 
return pool . acquire ( ) ; 
final ODatabaseDocument db = new ODatabaseDocumentTx ( url ) ; 
if ( properties != null ) { 
properties . entrySet ( ) . forEach ( e -> db . setProperty ( e . getKey ( ) , e . getValue ( ) ) ) ; 
if ( ! db . getURL ( ) . startsWith ( "remote:" ) && ! db . exists ( ) ) { 
if ( iCreate ) 
else if ( iOpen ) 
} else if ( iOpen ) 
db . open ( user , password ) ; 
return ( ODatabaseDocumentTx ) db ; 
} public boolean exists ( ) { 
final ODatabaseDocument db = getDatabase ( false , false ) ; 
return db . exists ( ) ; 
} public OrientGraphFactory setupPool ( final int iMin , final int iMax ) { 
if ( pool != null ) { 
pool . close ( ) ; 
pool = new OPartitionedDatabasePool ( url , user , password , 8 , iMax ) . setAutoCreate ( true ) ; 
properties . entrySet ( ) . forEach ( p -> pool . setProperty ( p . getKey ( ) , p . getValue ( ) ) ) ; 
} public Object getProperty ( final String iName ) { 
return properties . get ( iName . toLowerCase ( Locale . ENGLISH ) ) ; 
} @ SuppressWarnings ( "deprecation" ) 
public void stopTransaction ( final Conclusion conclusion ) { 
if ( getDatabase ( ) . isClosed ( ) || getDatabase ( ) . getTransaction ( ) instanceof OTransactionNoTx 
|| getDatabase ( ) . getTransaction ( ) . getStatus ( ) != TXSTATUS . BEGUN ) 
if ( Conclusion . SUCCESS == conclusion ) 
commit ( ) ; 
rollback ( ) ; 
} final public OStatement parse ( ) throws ParseException { 
Oparse jjtn000 = new Oparse ( JJTPARSE ) ; 
boolean jjtc000 = true ; 
jjtree . openNodeScope ( jjtn000 ) ; 
jjtn000 . jjtSetFirstToken ( getToken ( 1 ) ) ; OStatement result ; 
result = Statement ( ) ; 
jj_consume_token ( 0 ) ; 
jjtree . closeNodeScope ( jjtn000 , true ) ; 
jjtc000 = false ; 
jjtn000 . jjtSetLastToken ( getToken ( 0 ) ) ; 
{ if ( true ) return result ; } 
} catch ( Throwable jjte000 ) { 
if ( jjtc000 ) { 
jjtree . clearNodeScope ( jjtn000 ) ; 
jjtree . popNode ( ) ; 
if ( jjte000 instanceof RuntimeException ) { 
{ if ( true ) throw ( RuntimeException ) jjte000 ; } 
if ( jjte000 instanceof ParseException ) { 
{ if ( true ) throw ( ParseException ) jjte000 ; } 
{ if ( true ) throw ( Error ) jjte000 ; } 
} final public Token getNextToken ( ) { 
if ( token . next != null ) token = token . next ; 
else token = token . next = token_source . getNextToken ( ) ; 
jj_ntk = - 1 ; 
jj_gen ++ ; 
return token ; 
} final public Token getToken ( int index ) { 
Token t = token ; 
for ( int i = 0 ; i < index ; i ++ ) { 
if ( t . next != null ) t = t . next ; 
else t = t . next = token_source . getNextToken ( ) ; 
} public ParseException generateParseException ( ) { 
jj_expentries . clear ( ) ; 
boolean [ ] la1tokens = new boolean [ 279 ] ; 
if ( jj_kind >= 0 ) { 
la1tokens [ jj_kind ] = true ; 
jj_kind = - 1 ; 
for ( int i = 0 ; i < 424 ; i ++ ) { 
if ( jj_la1 [ i ] == jj_gen ) { 
for ( int j = 0 ; j < 32 ; j ++ ) { 
if ( ( jj_la1_0 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ j ] = true ; 
if ( ( jj_la1_1 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 32 + j ] = true ; 
if ( ( jj_la1_2 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 64 + j ] = true ; 
if ( ( jj_la1_3 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 96 + j ] = true ; 
if ( ( jj_la1_4 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 128 + j ] = true ; 
if ( ( jj_la1_5 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 160 + j ] = true ; 
if ( ( jj_la1_6 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 192 + j ] = true ; 
if ( ( jj_la1_7 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 224 + j ] = true ; 
if ( ( jj_la1_8 [ i ] & ( 1 << j ) ) != 0 ) { 
la1tokens [ 256 + j ] = true ; 
for ( int i = 0 ; i < 279 ; i ++ ) { 
if ( la1tokens [ i ] ) { 
jj_expentry = new int [ 1 ] ; 
jj_expentry [ 0 ] = i ; 
jj_expentries . add ( jj_expentry ) ; 
jj_endpos = 0 ; 
jj_rescan_token ( ) ; 
jj_add_error_token ( 0 , 0 ) ; 
int [ ] [ ] exptokseq = new int [ jj_expentries . size ( ) ] [ ] ; 
for ( int i = 0 ; i < jj_expentries . size ( ) ; i ++ ) { 
exptokseq [ i ] = jj_expentries . get ( i ) ; 
return new ParseException ( token , exptokseq , tokenImage ) ; 
} public static String getConnectionFieldName ( final Direction iDirection , final String iClassName , 
final boolean useVertexFieldsForEdgeLabels ) { 
if ( iDirection == null || iDirection == Direction . BOTH ) 
if ( useVertexFieldsForEdgeLabels ) { 
final String prefix = iDirection == Direction . OUT ? CONNECTION_OUT_PREFIX : CONNECTION_IN_PREFIX ; 
if ( iClassName == null || iClassName . isEmpty ( ) || iClassName . equals ( OrientEdgeType . CLASS_NAME ) ) 
return prefix ; 
return prefix + iClassName ; 
return iDirection == Direction . OUT ? OrientBaseGraph . CONNECTION_OUT : OrientBaseGraph . CONNECTION_IN ; 
} public static String getInverseConnectionFieldName ( final String iFieldName , final boolean useVertexFieldsForEdgeLabels ) { 
if ( iFieldName . startsWith ( CONNECTION_OUT_PREFIX ) ) { 
if ( iFieldName . length ( ) == CONNECTION_OUT_PREFIX . length ( ) ) 
return CONNECTION_IN_PREFIX ; 
return CONNECTION_IN_PREFIX + iFieldName . substring ( CONNECTION_OUT_PREFIX . length ( ) ) ; 
} else if ( iFieldName . startsWith ( CONNECTION_IN_PREFIX ) ) { 
if ( iFieldName . length ( ) == CONNECTION_IN_PREFIX . length ( ) ) 
return CONNECTION_OUT_PREFIX ; 
return CONNECTION_OUT_PREFIX + iFieldName . substring ( CONNECTION_IN_PREFIX . length ( ) ) ; 
if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_OUT ) ) 
return OrientBaseGraph . CONNECTION_IN ; 
else if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_IN ) ) 
return OrientBaseGraph . CONNECTION_OUT ; 
} public static void replaceLinks ( final ODocument iVertex , final String iFieldName , final OIdentifiable iVertexToRemove , 
final OIdentifiable iNewVertex ) { 
if ( ! fieldValue . equals ( iVertexToRemove ) ) { 
iVertex . field ( iFieldName , iNewVertex ) ; 
final Iterator < OIdentifiable > it = bag . rawIterator ( ) ; 
if ( it . next ( ) . equals ( iVertexToRemove ) ) { 
if ( found ) 
bag . add ( iNewVertex ) ; 
if ( col . remove ( iVertexToRemove ) ) 
col . add ( iNewVertex ) ; 
} protected static OrientEdge getEdge ( final OrientBaseGraph graph , final ODocument doc , String fieldName , 
final OPair < Direction , String > connection , final Object fieldValue , final OIdentifiable iTargetVertex , 
final String [ ] iLabels ) { 
final OrientEdge toAdd ; 
final ODocument fieldRecord = ( ( OIdentifiable ) fieldValue ) . getRecord ( ) ; 
if ( fieldRecord == null ) 
OClass klass = ODocumentInternal . getImmutableSchemaClass ( fieldRecord ) ; 
if ( klass == null && ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) != null ) { 
ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) . getMetadata ( ) . reload ( ) ; 
klass = fieldRecord . getSchemaClass ( ) ; 
if ( iTargetVertex != null && ! iTargetVertex . equals ( fieldValue ) ) 
if ( connection . getKey ( ) == Direction . OUT ) 
toAdd = graph . getEdgeInstance ( doc , fieldRecord , connection . getValue ( ) ) ; 
toAdd = graph . getEdgeInstance ( fieldRecord , doc , connection . getValue ( ) ) ; 
if ( iTargetVertex != null ) { 
Object targetVertex = OrientEdge . getConnection ( fieldRecord , connection . getKey ( ) . opposite ( ) ) ; 
if ( ! iTargetVertex . equals ( targetVertex ) ) 
toAdd = graph . getEdge ( fieldRecord ) ; 
return toAdd ; 
} public Object execute ( final OCommandPredicate iPredicate ) { 
final Object result = iPredicate . evaluate ( rawElement . getRecord ( ) , null , null ) ; 
if ( result instanceof OAutoConvertToRecord ) 
( ( OAutoConvertToRecord ) result ) . setAutoConvertToRecord ( true ) ; 
public Set < String > getPropertyKeys ( ) { 
final OrientBaseGraph graph = setCurrentGraphInThreadLocal ( ) ; 
final ODocument doc = getRecord ( ) ; 
for ( String field : doc . fieldNames ( ) ) 
if ( graph != null && settings . isUseVertexFieldsForEdgeLabels ( ) ) { 
if ( ! field . startsWith ( CONNECTION_OUT_PREFIX ) && ! field . startsWith ( CONNECTION_IN_PREFIX ) ) 
result . add ( field ) ; 
} else if ( ! field . equals ( OrientBaseGraph . CONNECTION_OUT ) && ! field . equals ( OrientBaseGraph . CONNECTION_IN ) ) 
public Iterable < Vertex > getVertices ( final Direction iDirection , final String ... iLabels ) { 
OrientBaseGraph . getEdgeClassNames ( getGraph ( ) , iLabels ) ; 
OrientBaseGraph . encodeClassNames ( iLabels ) ; 
final OMultiCollectionIterator < Vertex > iterable = new OMultiCollectionIterator < Vertex > ( ) ; 
for ( OTriple < String , Direction , String > connectionField : getConnectionFields ( iDirection , iLabels ) ) { 
String fieldName = connectionField . getKey ( ) ; 
OPair < Direction , String > connection = connectionField . getValue ( ) ; 
final Object fieldValue = doc . rawField ( fieldName ) ; 
if ( fieldValue != null ) 
addSingleVertex ( doc , iterable , fieldName , connection , fieldValue , iLabels ) ; 
} else if ( fieldValue instanceof Collection < ? > ) { 
Collection < ? > coll = ( Collection < ? > ) fieldValue ; 
if ( coll . size ( ) == 1 ) { 
if ( coll instanceof ORecordLazyMultiValue ) 
addSingleVertex ( doc , iterable , fieldName , connection , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) . next ( ) , iLabels ) ; 
else if ( coll instanceof List < ? > ) 
addSingleVertex ( doc , iterable , fieldName , connection , ( ( List < ? > ) coll ) . get ( 0 ) , iLabels ) ; 
addSingleVertex ( doc , iterable , fieldName , connection , coll . iterator ( ) . next ( ) , iLabels ) ; 
iterable . add ( new OrientVertexIterator ( this , coll , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) , connection , iLabels , 
coll . size ( ) ) ) ; 
iterable . add ( new OrientVertexIterator ( this , coll , coll . iterator ( ) , connection , iLabels , - 1 ) ) ; 
iterable . add ( new OrientVertexIterator ( this , fieldValue , ( ( ORidBag ) fieldValue ) . rawIterator ( ) , connection , iLabels , - 1 ) ) ; 
return iterable ; 
public void remove ( ) { 
checkClass ( ) ; 
throw ExceptionFactory . vertexWithIdDoesNotExist ( this . getId ( ) ) ; 
Map < String , List < ODocument > > treeRidbagEdgesToRemove = new HashMap < String , List < ODocument > > ( ) ; 
if ( ! graph . getRawGraph ( ) . getTransaction ( ) . isActive ( ) ) { 
for ( String fieldName : doc . fieldNames ( ) ) { 
final OPair < Direction , String > connection = getConnection ( Direction . BOTH , fieldName ) ; 
if ( connection == null ) 
Object fv = doc . field ( fieldName ) ; 
if ( fv instanceof ORidBag && ! ( ( ORidBag ) fv ) . isEmbedded ( ) ) { 
List < ODocument > docs = new ArrayList < ODocument > ( ) ; 
for ( OIdentifiable id : ( ORidBag ) fv ) 
docs . add ( OrientBaseGraph . getDocument ( id , true ) ) ; 
treeRidbagEdgesToRemove . put ( fieldName , docs ) ; 
super . removeRecord ( ) ; 
final Iterator < Index < ? extends Element > > it = graph . getIndices ( ) . iterator ( ) ; 
if ( it . hasNext ( ) ) { 
final Set < Edge > allEdges = new HashSet < Edge > ( ) ; 
for ( Edge e : getEdges ( Direction . BOTH ) ) 
allEdges . add ( e ) ; 
final Index < ? extends Element > index = it . next ( ) ; 
if ( Vertex . class . isAssignableFrom ( index . getIndexClass ( ) ) ) { 
OrientIndex < OrientVertex > idx = ( OrientIndex < OrientVertex > ) index ; 
idx . removeElement ( this ) ; 
if ( Edge . class . isAssignableFrom ( index . getIndexClass ( ) ) ) { 
OrientIndex < OrientEdge > idx = ( OrientIndex < OrientEdge > ) index ; 
for ( Edge e : allEdges ) 
idx . removeElement ( ( OrientEdge ) e ) ; 
for ( Map . Entry < String , List < ODocument > > entry : treeRidbagEdgesToRemove . entrySet ( ) ) { 
doc . removeField ( entry . getKey ( ) ) ; 
Iterator < ODocument > iter = entry . getValue ( ) . iterator ( ) ; 
ODocument docEdge = iter . next ( ) ; 
OrientBaseGraph . deleteEdgeIfAny ( docEdge , false ) ; 
graph . removeEdgesInternal ( this , doc , null , true , settings . isUseVertexFieldsForEdgeLabels ( ) , settings . isAutoScaleEdgeType ( ) ) ; 
} public ORID moveTo ( final String iClassName , final String iClusterName ) { 
final ORID oldIdentity = getIdentity ( ) . copy ( ) ; 
final ORecord oldRecord = oldIdentity . getRecord ( ) ; 
if ( oldRecord == null ) 
final ODocument doc = ( ( ODocument ) rawElement . getRecord ( ) ) . copy ( ) ; 
final Iterable < Edge > outEdges = getEdges ( Direction . OUT ) ; 
final Iterable < Edge > inEdges = getEdges ( Direction . IN ) ; 
copyRidBags ( oldRecord , doc ) ; 
removeEdgeLinks ( oldRecord ) ; 
oldRecord . delete ( ) ; 
if ( iClassName != null ) 
doc . setClassName ( iClassName ) ; 
doc . setDirty ( ) ; 
ORecordInternal . setIdentity ( doc , new ORecordId ( ) ) ; 
doc . save ( iClusterName ) ; 
final ORID newIdentity = doc . getIdentity ( ) ; 
for ( Edge e : outEdges ) { 
final OrientEdge oe = ( OrientEdge ) e ; 
if ( oe . isLightweight ( ) ) { 
final OrientVertex inV = oe . getVertex ( Direction . IN ) ; 
final String inFieldName = OrientVertex 
. getConnectionFieldName ( Direction . IN , oe . getLabel ( ) , graph . isUseVertexFieldsForEdgeLabels ( ) ) ; 
replaceLinks ( inV . getRecord ( ) , inFieldName , oldIdentity , newIdentity ) ; 
oe . vOut = newIdentity ; 
oe . getRecord ( ) . field ( OrientBaseGraph . CONNECTION_OUT , newIdentity ) ; 
oe . save ( ) ; 
for ( Edge e : inEdges ) { 
final OrientVertex outV = oe . getVertex ( Direction . OUT ) ; 
final String outFieldName = OrientVertex 
. getConnectionFieldName ( Direction . OUT , oe . getLabel ( ) , graph . isUseVertexFieldsForEdgeLabels ( ) ) ; 
replaceLinks ( outV . getRecord ( ) , outFieldName , oldIdentity , newIdentity ) ; 
oe . vIn = newIdentity ; 
oe . getRecord ( ) . field ( OrientBaseGraph . CONNECTION_IN , newIdentity ) ; 
return newIdentity ; 
public Edge addEdge ( final String label , Vertex inVertex ) { 
return addEdge ( label , ( OrientVertex ) inVertex , null , null , ( Object [ ] ) null ) ; 
} public OrientEdge addEdge ( final String label , final OrientVertex inVertex , final String iClassName ) { 
return addEdge ( label , inVertex , iClassName , null , ( Object [ ] ) null ) ; 
} public OrientEdge addEdge ( String label , final OrientVertex inVertex , final String iClassName , final String iClusterName , 
final Object ... fields ) { 
if ( inVertex == null ) 
return graph . addEdgeInternal ( this , label , inVertex , iClassName , iClusterName , fields ) ; 
return OrientGraphNoTx . addEdgeInternal ( null , this , label , inVertex , iClassName , iClusterName , fields ) ; 
} public long countEdges ( final Direction iDirection , final String ... iLabels ) { 
long counter = 0 ; 
if ( settings . isUseVertexFieldsForEdgeLabels ( ) || iLabels == null || iLabels . length == 0 ) { 
final OPair < Direction , String > connection = getConnection ( iDirection , fieldName , iLabels ) ; 
final Object fieldValue = doc . field ( fieldName ) ; 
if ( fieldValue instanceof Collection < ? > ) 
counter += ( ( Collection < ? > ) fieldValue ) . size ( ) ; 
else if ( fieldValue instanceof Map < ? , ? > ) 
counter += ( ( Map < ? , ? > ) fieldValue ) . size ( ) ; 
else if ( fieldValue instanceof ORidBag ) { 
counter += ( ( ORidBag ) fieldValue ) . size ( ) ; 
for ( Edge e : getEdges ( iDirection , iLabels ) ) 
if ( e != null ) 
return counter ; 
public Iterable < Edge > getEdges ( final Direction iDirection , final String ... iLabels ) { 
return getEdges ( null , iDirection , iLabels ) ; 
} public Iterable < Edge > getEdges ( final OrientVertex iDestination , final Direction iDirection , final String ... iLabels ) { 
final OMultiCollectionIterator < Edge > iterable = new OMultiCollectionIterator < Edge > ( ) . setEmbedded ( true ) ; 
final OIdentifiable destinationVId = iDestination != null ? ( OIdentifiable ) iDestination . getId ( ) : null ; 
addSingleEdge ( doc , iterable , fieldName , connection , fieldValue , destinationVId , iLabels ) ; 
addSingleEdge ( doc , iterable , fieldName , connection , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) . next ( ) , 
destinationVId , iLabels ) ; 
addSingleEdge ( doc , iterable , fieldName , connection , ( ( List < ? > ) coll ) . get ( 0 ) , destinationVId , iLabels ) ; 
addSingleEdge ( doc , iterable , fieldName , connection , coll . iterator ( ) . next ( ) , destinationVId , iLabels ) ; 
if ( coll instanceof ORecordLazyMultiValue ) { 
iterable . add ( 
new OrientEdgeIterator ( this , iDestination , coll , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) , connection , 
iLabels , coll . size ( ) ) ) ; 
iterable . add ( new OrientEdgeIterator ( this , iDestination , coll , coll . iterator ( ) , connection , iLabels , - 1 ) ) ; 
new OrientEdgeIterator ( this , iDestination , fieldValue , ( ( ORidBag ) fieldValue ) . rawIterator ( ) , connection , iLabels , 
( ( ORidBag ) fieldValue ) . size ( ) ) ) ; 
public String getLabel ( ) { 
if ( settings . isUseClassForVertexLabel ( ) ) { 
final String clsName = getRecord ( ) . getClassName ( ) ; 
if ( ! OrientVertexType . CLASS_NAME . equals ( clsName ) ) 
return clsName ; 
return getRecord ( ) . field ( OrientElement . LABEL_FIELD_NAME ) ; 
public OrientVertexType getType ( ) { 
return new OrientVertexType ( graph , getRecord ( ) . getSchemaClass ( ) ) ; 
} public String getConnectionClass ( final Direction iDirection , final String iFieldName ) { 
if ( iDirection == Direction . OUT ) { 
if ( iFieldName . length ( ) > CONNECTION_OUT_PREFIX . length ( ) ) 
return iFieldName . substring ( CONNECTION_OUT_PREFIX . length ( ) ) ; 
} else if ( iDirection == Direction . IN ) { 
if ( iFieldName . length ( ) > CONNECTION_IN_PREFIX . length ( ) ) 
return iFieldName . substring ( CONNECTION_IN_PREFIX . length ( ) ) ; 
return OrientEdgeType . CLASS_NAME ; 
} protected OPair < Direction , String > getConnection ( final Direction iDirection , final String iFieldName , String ... iClassNames ) { 
if ( iClassNames != null && iClassNames . length == 1 && iClassNames [ 0 ] . equalsIgnoreCase ( "E" ) ) 
iClassNames = null ; 
if ( iDirection == Direction . OUT || iDirection == Direction . BOTH ) { 
if ( settings . isUseVertexFieldsForEdgeLabels ( ) ) { 
String connClass = getConnectionClass ( Direction . OUT , iFieldName ) ; 
if ( iClassNames == null || iClassNames . length == 0 ) 
return new OPair < Direction , String > ( Direction . OUT , connClass ) ; 
OrientEdgeType edgeType = graph . getEdgeType ( connClass ) ; 
if ( edgeType != null ) { 
for ( String clsName : iClassNames ) { 
if ( edgeType . isSubClassOf ( clsName ) ) 
} else if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_OUT ) ) 
return new OPair < Direction , String > ( Direction . OUT , null ) ; 
if ( iDirection == Direction . IN || iDirection == Direction . BOTH ) { 
if ( iFieldName . startsWith ( CONNECTION_IN_PREFIX ) ) { 
String connClass = getConnectionClass ( Direction . IN , iFieldName ) ; 
return new OPair < Direction , String > ( Direction . IN , connClass ) ; 
} else if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_IN ) ) 
return new OPair < Direction , String > ( Direction . IN , null ) ; 
} private List < OTriple < String , Direction , String > > getConnectionFields ( final Direction iDirection , String ... iClassNames ) { 
List < OTriple < String , Direction , String > > result = new ArrayList < > ( ) ; 
if ( iClassNames == null || iClassNames . length == 0 || ( iClassNames . length == 1 && iClassNames [ 0 ] . equalsIgnoreCase ( "E" ) ) ) { 
final OPair < Direction , String > connection = getConnection ( iDirection , fieldName , iClassNames ) ; 
result . add ( new OTriple < String , Direction , String > ( fieldName , connection . getKey ( ) , connection . getValue ( ) ) ) ; 
OSchema schema = getGraph ( ) . getRawGraph ( ) . getMetadata ( ) . getSchema ( ) ; 
Set < String > allClassNames = new HashSet < String > ( ) ; 
for ( String className : iClassNames ) { 
allClassNames . add ( className ) ; 
OClass clazz = schema . getClass ( className ) ; 
Collection < OClass > subClasses = clazz . getAllSubclasses ( ) ; 
for ( OClass subClass : subClasses ) { 
allClassNames . add ( subClass . getName ( ) ) ; 
for ( String className : allClassNames ) { 
switch ( iDirection ) { 
case OUT : 
result . add ( new OTriple < String , Direction , String > ( CONNECTION_OUT_PREFIX + className , Direction . OUT , className ) ) ; 
case IN : 
result . add ( new OTriple < String , Direction , String > ( CONNECTION_IN_PREFIX + className , Direction . IN , className ) ) ; 
case BOTH : 
if ( iDirection == Direction . OUT ) 
result . add ( new OTriple < String , Direction , String > ( OrientBaseGraph . CONNECTION_OUT , Direction . OUT , null ) ) ; 
else if ( iDirection == Direction . IN ) 
result . add ( new OTriple < String , Direction , String > ( OrientBaseGraph . CONNECTION_IN , Direction . IN , null ) ) ; 
String [ ] fieldNames = new String [ result . size ( ) ] ; 
for ( OTriple < String , Direction , String > connectionField : result ) 
fieldNames [ i ++ ] = connectionField . getKey ( ) ; 
doc . deserializeFields ( fieldNames ) ; 
} private void processBrokenRids ( Set < ORID > brokenRids ) throws IOException , ParseException { 
if ( exporterVersion >= 12 ) { 
jsonReader . readNext ( OJSONReader . BEGIN_COLLECTION ) ; 
jsonReader . readNext ( OJSONReader . NEXT_IN_ARRAY ) ; 
final ORecordId recordId = new ORecordId ( jsonReader . getValue ( ) ) ; 
brokenRids . add ( recordId ) ; 
if ( jsonReader . lastChar ( ) == ']' ) 
if ( migrateLinks ) { 
if ( exporterVersion >= 12 ) 
listener . onMessage ( 
migrateLinksInImportedDocuments ( brokenRids ) ; 
fromIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , from , context , iArgs ) ; 
toIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , to , context , iArgs ) ; 
final OVertex toVertex ; 
toVertex = toVertex ( to ) ; 
if ( toVertex == null ) { 
OEdge edge = null ; 
edge = fromVertex . addEdge ( toVertex , edgeLabel ) ; 
fromVertex . save ( ) ; 
toVertex . save ( ) ; 
} protected Map < Method , Object > getConsoleMethods ( ) { 
if ( methods != null ) 
return methods ; 
final Iterator < OConsoleCommandCollection > ite = ServiceLoader . load ( OConsoleCommandCollection . class ) . iterator ( ) ; 
final Collection < Object > candidates = new ArrayList < Object > ( ) ; 
candidates . add ( this ) ; 
final OConsoleCommandCollection cc = ite . next ( ) . getClass ( ) . newInstance ( ) ; 
cc . setContext ( this ) ; 
candidates . add ( cc ) ; 
} catch ( InstantiationException ex ) { 
Logger . getLogger ( OConsoleApplication . class . getName ( ) ) . log ( Level . WARNING , ex . getMessage ( ) ) ; 
} catch ( IllegalAccessException ex ) { 
methods = new TreeMap < Method , Object > ( new Comparator < Method > ( ) { 
public int compare ( Method o1 , Method o2 ) { 
final ConsoleCommand ann1 = o1 . getAnnotation ( ConsoleCommand . class ) ; 
final ConsoleCommand ann2 = o2 . getAnnotation ( ConsoleCommand . class ) ; 
if ( ann1 != null && ann2 != null ) { 
if ( ann1 . priority ( ) != ann2 . priority ( ) ) 
return ann1 . priority ( ) - ann2 . priority ( ) ; 
int res = o1 . getName ( ) . compareTo ( o2 . getName ( ) ) ; 
if ( res == 0 ) 
res = o1 . toString ( ) . compareTo ( o2 . toString ( ) ) ; 
for ( final Object candidate : candidates ) { 
final Method [ ] classMethods = candidate . getClass ( ) . getMethods ( ) ; 
for ( Method m : classMethods ) { 
if ( Modifier . isAbstract ( m . getModifiers ( ) ) || Modifier . isStatic ( m . getModifiers ( ) ) || ! Modifier . isPublic ( m . getModifiers ( ) ) ) { 
if ( m . getReturnType ( ) != Void . TYPE ) { 
methods . put ( m , candidate ) ; 
public Object executeOnLocalNode ( final ODistributedRequestId reqId , final ORemoteTask task , 
final ODatabaseDocumentInternal database ) { 
if ( database != null && ! ( database . getStorage ( ) instanceof ODistributedStorage ) ) 
throw new ODistributedException ( 
. getStorage ( ) . getClass ( ) . getName ( ) ) ; 
final ODistributedAbstractPlugin manager = this ; 
return OScenarioThreadLocal . executeAsDistributed ( new Callable < Object > ( ) { 
final Object result = task . execute ( reqId , serverInstance , manager , database ) ; 
if ( result instanceof Throwable && ! ( result instanceof OException ) ) 
ODistributedServerLog . debug ( this , nodeName , getNodeNameById ( reqId . getNodeId ( ) ) , DIRECTION . IN , 
final String sourceNodeName = task . getNodeSource ( ) ; 
if ( database != null ) { 
final ODistributedDatabaseImpl ddb = getMessageService ( ) . getDatabase ( database . getName ( ) ) ; 
if ( ddb != null && ! ( result instanceof Throwable ) && task instanceof OAbstractReplicatedTask && ! task 
. isIdempotent ( ) ) { 
ddb . setLSN ( sourceNodeName , ( ( OAbstractReplicatedTask ) task ) . getLastLSN ( ) , true ) ; 
ddb . setLSN ( getLocalNodeName ( ) , ( ( OAbstractPaginatedStorage ) database . getStorage ( ) . getUnderlying ( ) ) . getLSN ( ) , true ) ; 
if ( ! ( e instanceof OException ) ) 
ODistributedServerLog . error ( this , nodeName , getNodeNameById ( reqId . getNodeId ( ) ) , DIRECTION . IN , 
public int getAvailableNodes ( final Collection < String > iNodes , final String databaseName ) { 
for ( Iterator < String > it = iNodes . iterator ( ) ; it . hasNext ( ) ; ) { 
final String node = it . next ( ) ; 
if ( ! isNodeAvailable ( node , databaseName ) ) 
return iNodes . size ( ) ; 
public int getNodesWithStatus ( final Collection < String > iNodes , final String databaseName , final DB_STATUS ... statuses ) { 
if ( ! isNodeStatusEqualsTo ( node , databaseName , statuses ) ) 
} protected void installDatabaseFromNetwork ( final String dbPath , final String databaseName , 
final ODistributedDatabaseImpl distrDatabase , final String iNode , final ODistributedDatabaseChunk firstChunk , 
final boolean delta , final File uniqueClustersBackupDirectory , final OModifiableDistributedConfiguration cfg ) { 
final String fileName = Orient . getTempPath ( ) + "install_" + databaseName + "_server" + getLocalNodeId ( ) + ".zip" ; 
final String localNodeName = nodeName ; 
final File file = new File ( fileName ) ; 
if ( file . exists ( ) ) 
file . delete ( ) ; 
file . getParentFile ( ) . mkdirs ( ) ; 
file . createNewFile ( ) ; 
final File completedFile = new File ( file . getAbsolutePath ( ) + ".completed" ) ; 
if ( completedFile . exists ( ) ) 
completedFile . delete ( ) ; 
final AtomicReference < ODistributedMomentum > momentum = new AtomicReference < ODistributedMomentum > ( ) ; 
OSyncReceiver receiver = new OSyncReceiver ( this , databaseName , firstChunk , momentum , fileName , iNode , dbPath , file ) ; 
Thread t = new Thread ( receiver ) ; 
t . setUncaughtExceptionHandler ( new OUncaughtExceptionHandler ( ) ) ; 
t . start ( ) ; 
final ODatabaseDocumentInternal db = installDatabaseOnLocalNode ( databaseName , dbPath , iNode , fileName , delta , 
uniqueClustersBackupDirectory , cfg , firstChunk . incremental , firstChunk . walSegment , firstChunk . walPosition , receiver ) ; 
distrDatabase . getSyncConfiguration ( ) . load ( ) ; 
distrDatabase . getSyncConfiguration ( ) 
. setLastLSN ( localNodeName , ( ( OLocalPaginatedStorage ) db . getStorage ( ) . getUnderlying ( ) ) . getLSN ( ) , false ) ; 
DISTRIBUTED_SYNC_JSON_FILENAME , databaseName ) ; 
distrDatabase . setOnline ( ) ; 
rebalanceClusterOwnership ( nodeName , db , cfg , false ) ; 
public List < String > backup ( OutputStream out , Map < String , Object > options , Callable < Object > callable , 
final OCommandOutputListener iListener , int compressionLevel , int bufferSize ) throws IOException { 
return underlying . backup ( out , options , callable , iListener , compressionLevel , bufferSize ) ; 
} protected ORole createRole ( final ODocument roleDoc ) { 
ORole role = null ; 
if ( databaseName != null && ! databaseName . isEmpty ( ) ) { 
if ( roleDoc != null && roleDoc . containsField ( OSystemRole . DB_FILTER ) && roleDoc . fieldType ( OSystemRole . DB_FILTER ) == OType . EMBEDDEDLIST ) { 
List < String > dbNames = roleDoc . field ( OSystemRole . DB_FILTER , OType . EMBEDDEDLIST ) ; 
for ( String dbName : dbNames ) { 
if ( dbName != null && ! dbName . isEmpty ( ) && ( dbName . equalsIgnoreCase ( databaseName ) || dbName . equals ( "*" ) ) ) { 
role = new OSystemRole ( roleDoc ) ; 
if ( roleDoc != null ) { 
if ( ! roleDoc . containsField ( OSystemRole . DB_FILTER ) ) { 
if ( roleDoc . fieldType ( OSystemRole . DB_FILTER ) == OType . EMBEDDEDLIST ) { 
if ( dbName != null && ! dbName . isEmpty ( ) && dbName . equals ( "*" ) ) { 
final OClassImpl cls = ( OClassImpl ) database . getMetadata ( ) . getSchema ( ) . getClass ( className ) ; 
if ( ! unsafe && attribute == ATTRIBUTES . NAME && cls . isSubClassOf ( "E" ) ) 
for ( int clId : cls . getPolymorphicClusterIds ( ) ) 
getDatabase ( ) . getMetadata ( ) . getCommandCache ( ) . invalidateResultsOfCluster ( getDatabase ( ) . getClusterNameById ( clId ) ) ; 
if ( value != null && attribute == ATTRIBUTES . SUPERCLASS ) { 
checkClassExists ( database , className , decodeClassName ( value ) ) ; 
if ( value != null && attribute == ATTRIBUTES . SUPERCLASSES ) { 
List < String > classes = Arrays . asList ( value . split ( ",\\s*" ) ) ; 
for ( String cName : classes ) { 
checkClassExists ( database , className , decodeClassName ( cName ) ) ; 
if ( ! unsafe && value != null && attribute == ATTRIBUTES . NAME ) { 
if ( ! cls . getIndexes ( ) . isEmpty ( ) ) { 
cls . set ( attribute , value ) ; 
return Boolean . TRUE ; 
} protected Object executeSQL ( ) { 
ODatabaseDocument db = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
return executeSQLScript ( parserText , db ) ; 
} protected void waitForNextRetry ( ) { 
Thread . sleep ( new Random ( ) . nextInt ( MAX_DELAY - 1 ) + 1 ) ; 
} public String getArgument ( final int iPosition ) { 
return args != null && args . length > iPosition ? args [ iPosition ] : null ; 
} public int hasParameters ( final String ... iNames ) { 
int found = 0 ; 
if ( iNames != null && request . parameters != null ) 
for ( String name : iNames ) 
found += request . parameters . containsKey ( name ) ? 1 : 0 ; 
return found ; 
public synchronized OServerAdmin connect ( final String iUserName , final String iUserPassword ) throws IOException { 
final String username ; 
final String password ; 
OCredentialInterceptor ci = OSecurityManager . instance ( ) . newCredentialInterceptor ( ) ; 
if ( ci != null ) { 
ci . intercept ( storage . getURL ( ) , iUserName , iUserPassword ) ; 
username = ci . getUsername ( ) ; 
password = ci . getPassword ( ) ; 
username = iUserName ; 
password = iUserPassword ; 
OConnect37Request request = new OConnect37Request ( username , password ) ; 
networkAdminOperation ( ( network , session ) -> { 
OStorageRemoteNodeSession nodeSession = session . getOrCreateServerSession ( network . getServerURL ( ) ) ; 
network . beginRequest ( request . getCommand ( ) , session ) ; 
request . write ( network , session ) ; 
network . endRequest ( ) ; 
OConnectResponse response = request . createResponse ( ) ; 
network . beginResponse ( nodeSession . getSessionId ( ) , true ) ; 
response . read ( network , session ) ; 
storage . endResponse ( network ) ; 
public synchronized Map < String , String > listDatabases ( ) throws IOException { 
OListDatabasesRequest request = new OListDatabasesRequest ( ) ; 
return response . getDatabases ( ) ; 
public synchronized ODocument getServerInfo ( ) throws IOException { 
OServerInfoRequest request = new OServerInfoRequest ( ) ; 
res . fromJSON ( response . getResult ( ) ) ; 
public synchronized OServerAdmin createDatabase ( final String iDatabaseType , String iStorageMode ) throws IOException { 
return createDatabase ( storage . getName ( ) , iDatabaseType , iStorageMode ) ; 
} public synchronized OServerAdmin createDatabase ( final String iDatabaseName , final String iDatabaseType , final String iStorageMode , 
final String backupPath ) throws IOException { 
if ( iDatabaseName == null || iDatabaseName . length ( ) <= 0 ) { 
OLogManager . instance ( ) . error ( this , message , null ) ; 
throw new OStorageException ( message ) ; 
String storageMode ; 
if ( iStorageMode == null ) 
storageMode = "plocal" ; 
storageMode = iStorageMode ; 
OCreateDatabaseRequest request = new OCreateDatabaseRequest ( iDatabaseName , iDatabaseName , storageMode , backupPath ) ; 
} public synchronized boolean existsDatabase ( final String iDatabaseName , final String storageType ) throws IOException { 
OExistsDatabaseRequest request = new OExistsDatabaseRequest ( iDatabaseName , storageType ) ; 
OExistsDatabaseResponse response = networkAdminOperation ( request , 
return response . isExists ( ) ; 
} public synchronized OServerAdmin dropDatabase ( final String iDatabaseName , final String storageType ) throws IOException { 
ODropDatabaseRequest request = new ODropDatabaseRequest ( iDatabaseName , storageType ) ; 
OURLConnection connection = OURLHelper . parse ( getURL ( ) ) ; 
OrientDBRemote remote = ( OrientDBRemote ) ODatabaseDocumentTxInternal . getOrCreateRemoteFactory ( connection . getPath ( ) ) ; 
remote . forceDatabaseClose ( iDatabaseName ) ; 
} public synchronized OServerAdmin freezeDatabase ( final String storageType ) throws IOException { 
OFreezeDatabaseRequest request = new OFreezeDatabaseRequest ( storage . getName ( ) , storageType ) ; 
} public synchronized OServerAdmin releaseDatabase ( final String storageType ) throws IOException { 
OReleaseDatabaseRequest request = new OReleaseDatabaseRequest ( storage . getName ( ) , storageType ) ; 
} public ODocument clusterStatus ( ) { 
ODistributedStatusRequest request = new ODistributedStatusRequest ( ) ; 
return response . getClusterConfig ( ) ; 
public Object execute ( final Map < Object , Object > iArgs ) { 
if ( indexName == null ) 
final OIndex < ? > idx ; 
List < OCollate > collatesList = null ; 
if ( collates != null ) { 
collatesList = new ArrayList < OCollate > ( ) ; 
for ( String collate : collates ) { 
final OCollate col = OSQLEngine . getCollate ( collate ) ; 
collatesList . add ( col ) ; 
collatesList . add ( null ) ; 
if ( fields == null || fields . length == 0 ) { 
OIndexFactory factory = OIndexes . getFactory ( indexType . toString ( ) , null ) ; 
if ( keyTypes != null ) 
idx = database . getMetadata ( ) . getIndexManager ( ) 
. createIndex ( indexName , indexType . toString ( ) , new OSimpleKeyIndexDefinition ( keyTypes , collatesList ) , null , null , 
metadataDoc , engine ) ; 
else if ( serializerKeyId != 0 ) { 
. createIndex ( indexName , indexType . toString ( ) , new ORuntimeKeyIndexDefinition ( serializerKeyId ) , null , null , metadataDoc , 
engine ) ; 
if ( ( keyTypes == null || keyTypes . length == 0 ) && collates == null ) { 
idx = oClass . createIndex ( indexName , indexType . toString ( ) , null , metadataDoc , engine , fields ) ; 
final List < OType > fieldTypeList ; 
if ( keyTypes == null ) { 
for ( final String fieldName : fields ) { 
if ( ! fieldName . equals ( "@rid" ) && ! oClass . existsProperty ( fieldName ) ) 
throw new OIndexException ( 
fieldTypeList = ( ( OClassImpl ) oClass ) . extractFieldTypes ( fields ) ; 
fieldTypeList = Arrays . asList ( keyTypes ) ; 
final OIndexDefinition idxDef = OIndexDefinitionFactory 
. createIndexDefinition ( oClass , Arrays . asList ( fields ) , fieldTypeList , collatesList , indexType . toString ( ) , null ) ; 
. createIndex ( indexName , indexType . name ( ) , idxDef , oClass . getPolymorphicClusterIds ( ) , null , metadataDoc , engine ) ; 
if ( idx != null ) 
return idx . getSize ( ) ; 
} public static OrientGraph getGraph ( final boolean autoStartTx , OModifiableBoolean shouldBeShutDown ) { 
final OrientBaseGraph result = OrientBaseGraph . getActiveGraph ( ) ; 
if ( result != null && ( result instanceof OrientGraph ) ) { 
final ODatabaseDocumentInternal graphDb = result . getRawGraph ( ) ; 
if ( canReuseActiveGraph ( graphDb , database ) ) { 
if ( ! graphDb . isClosed ( ) ) { 
ODatabaseRecordThreadLocal . instance ( ) . set ( graphDb ) ; 
if ( autoStartTx && autoTxStartRequired ( graphDb ) ) 
( ( OrientGraph ) result ) . begin ( ) ; 
shouldBeShutDown . setValue ( false ) ; 
return ( OrientGraph ) result ; 
ODatabaseRecordThreadLocal . instance ( ) . set ( database ) ; 
shouldBeShutDown . setValue ( true ) ; 
final OrientGraph g = ( OrientGraph ) OrientGraphFactory . getTxGraphImplFactory ( ) . getGraph ( database , false ) ; 
if ( autoStartTx && autoTxStartRequired ( database ) ) 
g . begin ( ) ; 
} protected void parseRetry ( ) throws OCommandSQLParsingException { 
retry = Integer . parseInt ( parserNextWord ( true ) ) ; 
String temp = parseOptionalWord ( true ) ; 
if ( temp . equals ( "WAIT" ) ) { 
wait = Integer . parseInt ( parserNextWord ( true ) ) ; 
} long reset ( boolean executeViaDistributed ) throws ODatabaseException { 
long retVal ; 
if ( executeViaDistributed ) { 
retVal = sendSequenceActionOverCluster ( OSequenceAction . RESET , null ) ; 
} catch ( InterruptedException | ExecutionException exc ) { 
OLogManager . instance ( ) . error ( this , exc . getMessage ( ) , exc , ( Object [ ] ) null ) ; 
throw new ODatabaseException ( exc . getMessage ( ) ) ; 
retVal = resetWork ( ) ; 
return retVal ; 
} public ORecord saveRecord ( final ORecord iRecord , final String iClusterName , final OPERATION_MODE iMode , boolean iForceCreate , 
return database . saveAll ( iRecord , iClusterName , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
final ORecordId rid = ( ORecordId ) iRecord . getIdentity ( ) ; 
if ( rid . isValid ( ) ) 
database . getLocalCache ( ) . freeRecord ( rid ) ; 
if ( e instanceof ONeedRetryException ) 
throw ( ONeedRetryException ) e ; 
} public void deleteRecord ( final ORecord iRecord , final OPERATION_MODE iMode ) { 
if ( ! iRecord . getIdentity ( ) . isPersistent ( ) ) 
database . executeDeleteRecord ( iRecord , iRecord . getVersion ( ) , true , iMode , false ) ; 
if ( e instanceof RuntimeException ) 
throw ( RuntimeException ) e ; 
server = oServer ; 
serverConfig = serverCfg ; 
if ( jsonConfig . containsField ( "name" ) ) { 
name = jsonConfig . field ( "name" ) ; 
if ( jsonConfig . containsField ( "debug" ) ) { 
debug = jsonConfig . field ( "debug" ) ; 
if ( jsonConfig . containsField ( "enabled" ) ) { 
enabled = jsonConfig . field ( "enabled" ) ; 
if ( jsonConfig . containsField ( "caseSensitive" ) ) { 
caseSensitive = jsonConfig . field ( "caseSensitive" ) ; 
} public String getAuthenticationHeader ( String databaseName ) { 
String header ; 
if ( databaseName != null ) 
return header ; 
OLogManager . instance ( ) . error ( this , "config()" , ex ) ; 
if ( getServer ( ) != null ) { 
OUser user = getServer ( ) . getSecurity ( ) . getSystemUser ( username , null ) ; 
if ( user != null && user . getAccountStatus ( ) == OSecurityUser . STATUSES . ACTIVE ) { 
if ( user . checkPassword ( password ) ) 
principal = username ; 
OLogManager . instance ( ) . error ( this , "authenticate()" , ex ) ; 
ORule . ResourceGeneric rg = ORule . mapLegacyResourceToGenericResource ( resource ) ; 
if ( rg != null ) { 
String specificResource = ORule . mapLegacyResourceToSpecificResource ( resource ) ; 
if ( specificResource == null || specificResource . equals ( "*" ) ) { 
specificResource = null ; 
role = user . checkIfAllowed ( rg , specificResource , ORole . PERMISSION_EXECUTE ) ; 
return role != null ; 
OLogManager . instance ( ) . error ( this , "isAuthorized()" , ex ) ; 
userCfg = new OServerUserConfiguration ( user . getName ( ) , "" , "" ) ; 
OLogManager . instance ( ) . error ( this , "getUser()" , ex ) ; 
if ( server != null ) 
if ( ! server . shutdown ( ) ) { 
Thread . sleep ( 5000 ) ; 
} public void ReInit ( java . io . Reader dstream , 
int startline , int startcolumn , int buffersize ) 
inputStream = dstream ; 
line = startline ; 
column = startcolumn - 1 ; 
if ( buffer == null || buffersize != buffer . length ) 
available = bufsize = buffersize ; 
buffer = new char [ buffersize ] ; 
bufline = new int [ buffersize ] ; 
bufcolumn = new int [ buffersize ] ; 
nextCharBuf = new char [ 4096 ] ; 
prevCharIsLF = prevCharIsCR = false ; 
tokenBegin = inBuf = maxNextCharInd = 0 ; 
nextCharInd = bufpos = - 1 ; 
int startline , int startcolumn ) 
ReInit ( dstream , startline , startcolumn , 4096 ) ; 
} public void ReInit ( java . io . InputStream dstream , String encoding , int startline , 
int startcolumn , int buffersize ) throws java . io . UnsupportedEncodingException 
ReInit ( encoding == null ? new java . io . InputStreamReader ( dstream ) : new java . io . InputStreamReader ( dstream , encoding ) , startline , startcolumn , buffersize ) ; 
} public void ReInit ( java . io . InputStream dstream , int startline , 
int startcolumn , int buffersize ) 
ReInit ( new java . io . InputStreamReader ( dstream ) , startline , startcolumn , buffersize ) ; 
int startcolumn ) throws java . io . UnsupportedEncodingException 
ReInit ( dstream , encoding , startline , startcolumn , 4096 ) ; 
int startcolumn ) 
} public void adjustBeginLineColumn ( int newLine , int newCol ) 
int start = tokenBegin ; 
int len ; 
if ( bufpos >= tokenBegin ) 
len = bufpos - tokenBegin + inBuf + 1 ; 
len = bufsize - tokenBegin + bufpos + 1 + inBuf ; 
int i = 0 , j = 0 , k = 0 ; 
int nextColDiff = 0 , columnDiff = 0 ; 
while ( i < len && bufline [ j = start % bufsize ] == bufline [ k = ++ start % bufsize ] ) 
bufline [ j ] = newLine ; 
nextColDiff = columnDiff + bufcolumn [ k ] - bufcolumn [ j ] ; 
bufcolumn [ j ] = newCol + columnDiff ; 
columnDiff = nextColDiff ; 
if ( i < len ) 
bufline [ j ] = newLine ++ ; 
while ( i ++ < len ) 
if ( bufline [ j = start % bufsize ] != bufline [ ++ start % bufsize ] ) 
line = bufline [ j ] ; 
column = bufcolumn [ j ] ; 
public void serializeInByteBufferObject ( OCompositeKey object , ByteBuffer buffer , Object ... hints ) { 
final OType [ ] types = getKeyTypes ( hints ) ; 
final List < Object > keys = object . getKeys ( ) ; 
final int keysSize = keys . size ( ) ; 
final int oldStartOffset = buffer . position ( ) ; 
buffer . position ( oldStartOffset + OIntegerSerializer . INT_SIZE ) ; 
buffer . putInt ( keysSize ) ; 
final OBinarySerializerFactory factory = OBinarySerializerFactory . getInstance ( ) ; 
for ( int i = 0 ; i < keys . size ( ) ; i ++ ) { 
final Object key = keys . get ( i ) ; 
OBinarySerializer < Object > binarySerializer ; 
if ( key != null ) { 
final OType type ; 
if ( types . length > i ) 
type = types [ i ] ; 
type = OType . getTypeByClass ( key . getClass ( ) ) ; 
binarySerializer = factory . getObjectSerializer ( type ) ; 
binarySerializer = ONullSerializer . INSTANCE ; 
binarySerializer . serializeInByteBufferObject ( key , buffer ) ; 
final int finalPosition = buffer . position ( ) ; 
final int serializedSize = buffer . position ( ) - oldStartOffset ; 
buffer . position ( oldStartOffset ) ; 
buffer . putInt ( serializedSize ) ; 
buffer . position ( finalPosition ) ; 
public OCompositeKey deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final OCompositeKey compositeKey = new OCompositeKey ( ) ; 
final int keysSize = buffer . getInt ( ) ; 
for ( int i = 0 ; i < keysSize ; i ++ ) { 
OBinarySerializer < Object > binarySerializer = ( OBinarySerializer < Object > ) factory . getObjectSerializer ( serializerId ) ; 
final Object key = binarySerializer . deserializeFromByteBufferObject ( buffer ) ; 
compositeKey . addKey ( key ) ; 
return compositeKey ; 
public OCompositeKey deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final int keysSize = walChanges . getIntValue ( buffer , offset ) ; 
final byte serializerId = walChanges . getByteValue ( buffer , offset ) ; 
offset += OBinarySerializerFactory . TYPE_IDENTIFIER_SIZE ; 
final Object key = binarySerializer . deserializeFromByteBufferObject ( buffer , walChanges , offset ) ; 
offset += binarySerializer . getObjectSize ( key ) ; 
} protected void setBucketPointer ( int pageOffset , OBonsaiBucketPointer value ) throws IOException { 
setLongValue ( pageOffset , value . getPageIndex ( ) ) ; 
setIntValue ( pageOffset + OLongSerializer . LONG_SIZE , value . getPageOffset ( ) ) ; 
} protected OBonsaiBucketPointer getBucketPointer ( int offset ) { 
final long pageIndex = getLongValue ( offset ) ; 
final int pageOffset = getIntValue ( offset + OLongSerializer . LONG_SIZE ) ; 
return new OBonsaiBucketPointer ( pageIndex , pageOffset ) ; 
getDatabase ( ) . checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_DELETE , name ) ; 
truncateClusterInternal ( clusterName , database ) ; 
} public OAtomicOperation startAtomicOperation ( String lockName , boolean trackNonTxOperations ) throws IOException { 
OAtomicOperation operation = currentOperation . get ( ) ; 
if ( operation != null ) { 
operation . incrementCounter ( ) ; 
if ( lockName != null ) { 
acquireExclusiveLockTillOperationComplete ( operation , lockName ) ; 
return operation ; 
atomicOperationsCount . increment ( ) ; 
while ( freezeRequests . get ( ) > 0 ) { 
assert freezeRequests . get ( ) >= 0 ; 
atomicOperationsCount . decrement ( ) ; 
throwFreezeExceptionIfNeeded ( ) ; 
final Thread thread = Thread . currentThread ( ) ; 
addThreadInWaitingList ( thread ) ; 
if ( freezeRequests . get ( ) > 0 ) { 
LockSupport . park ( this ) ; 
final boolean useWal = useWal ( ) ; 
final OOperationUnitId unitId = OOperationUnitId . generateId ( ) ; 
final OLogSequenceNumber lsn = useWal ? writeAheadLog . logAtomicOperationStartRecord ( true , unitId ) : null ; 
operation = new OAtomicOperation ( lsn , unitId , readCache , writeCache , storage . getId ( ) ) ; 
currentOperation . set ( operation ) ; 
if ( trackAtomicOperations ) { 
activeAtomicOperations . put ( unitId , new OPair < > ( thread . getName ( ) , thread . getStackTrace ( ) ) ) ; 
if ( useWal && trackNonTxOperations && storage . getStorageTransaction ( ) == null ) { 
writeAheadLog . log ( new ONonTxOperationPerformedWALRecord ( ) ) ; 
storage . checkReadOnlyConditions ( ) ; 
} catch ( RuntimeException | Error e ) { 
final Iterator < String > lockedObjectIterator = operation . lockedObjects ( ) . iterator ( ) ; 
while ( lockedObjectIterator . hasNext ( ) ) { 
final String lockedObject = lockedObjectIterator . next ( ) ; 
lockedObjectIterator . remove ( ) ; 
lockManager . releaseLock ( this , lockedObject , OOneEntryPerKeyLockManager . LOCK . EXCLUSIVE ) ; 
} public OLogSequenceNumber endAtomicOperation ( boolean rollback ) throws IOException { 
final OAtomicOperation operation = currentOperation . get ( ) ; 
if ( operation == null ) { 
int counter = operation . getCounter ( ) ; 
operation . decrementCounter ( ) ; 
assert counter > 0 ; 
final OLogSequenceNumber lsn ; 
if ( rollback ) { 
operation . rollback ( ) ; 
if ( counter == 1 ) { 
if ( ! operation . isRollback ( ) ) { 
lsn = operation . commitChanges ( useWal ? writeAheadLog : null ) ; 
lsn = null ; 
activeAtomicOperations . remove ( operation . getOperationUnitId ( ) ) ; 
currentOperation . set ( null ) ; 
} catch ( Error e ) { 
final OAbstractPaginatedStorage st = storage ; 
if ( st != null ) { 
st . handleJVMError ( e ) ; 
counter = 1 ; 
return lsn ; 
} public void acquireExclusiveLockTillOperationComplete ( OAtomicOperation operation , String lockName ) { 
if ( operation . containsInLockedObjects ( lockName ) ) { 
lockManager . acquireLock ( lockName , OOneEntryPerKeyLockManager . LOCK . EXCLUSIVE ) ; 
operation . addLockedObject ( lockName ) ; 
} public void acquireExclusiveLockTillOperationComplete ( ODurableComponent durableComponent ) { 
assert operation != null ; 
acquireExclusiveLockTillOperationComplete ( operation , durableComponent . getLockName ( ) ) ; 
} public void changeMaximumAmountOfMemory ( final long readCacheMaxMemory ) throws IllegalStateException { 
MemoryData memoryData ; 
MemoryData newMemoryData ; 
final int newMemorySize = normalizeMemory ( readCacheMaxMemory , pageSize ) ; 
memoryData = memoryDataContainer . get ( ) ; 
if ( memoryData . maxSize == newMemorySize ) { 
if ( ( 100 * memoryData . pinnedPages / newMemorySize ) > percentOfPinnedPages ) { 
newMemoryData = new MemoryData ( newMemorySize , memoryData . pinnedPages ) ; 
} while ( ! memoryDataContainer . compareAndSet ( memoryData , newMemoryData ) ) ; 
public final void closeStorage ( final OWriteCache writeCache ) throws IOException { 
if ( writeCache == null ) { 
cacheLock . acquireWriteLock ( ) ; 
final long [ ] filesToClear = writeCache . close ( ) ; 
clearFiles ( writeCache , filesToClear ) ; 
cacheLock . releaseWriteLock ( ) ; 
public final void storeCacheState ( final OWriteCache writeCache ) { 
if ( ! OGlobalConfiguration . STORAGE_KEEP_DISK_CACHE_STATE . getValueAsBoolean ( ) ) { 
final Path rootDirectory = writeCache . getRootDirectory ( ) ; 
final Path stateFile = rootDirectory . resolve ( CACHE_STATE_FILE ) ; 
if ( Files . exists ( stateFile ) ) { 
Files . delete ( stateFile ) ; 
final Set < Long > filesToStore = new HashSet < > ( writeCache . files ( ) . values ( ) ) ; 
try ( final FileChannel channel = FileChannel . open ( stateFile , StandardOpenOption . WRITE , StandardOpenOption . CREATE ) ) { 
final OutputStream channelStream = Channels . newOutputStream ( channel ) ; 
final BufferedOutputStream bufferedOutputStream = new BufferedOutputStream ( channelStream , 64 * 1024 ) ; 
try ( final DataOutputStream dataOutputStream = new DataOutputStream ( bufferedOutputStream ) ) { 
dataOutputStream . writeLong ( memoryDataContainer . get ( ) . maxSize ) ; 
storeQueueState ( writeCache , filesToStore , dataOutputStream , am ) ; 
dataOutputStream . writeInt ( - 1 ) ; 
storeQueueState ( writeCache , filesToStore , dataOutputStream , a1in ) ; 
storeQueueState ( writeCache , filesToStore , dataOutputStream , a1out ) ; 
} private static void storeQueueState ( final OWriteCache writeCache , final Set < Long > filesToStore , 
final DataOutputStream dataOutputStream , final LRUList queue ) throws IOException { 
final Iterator < OCacheEntry > queueIterator = queue . reverseIterator ( ) ; 
while ( queueIterator . hasNext ( ) ) { 
final OCacheEntry cacheEntry = queueIterator . next ( ) ; 
final long fileId = cacheEntry . getFileId ( ) ; 
if ( filesToStore . contains ( fileId ) ) { 
final int internalId = writeCache . internalFileId ( fileId ) ; 
dataOutputStream . writeInt ( internalId ) ; 
dataOutputStream . writeLong ( cacheEntry . getPageIndex ( ) ) ; 
} private void listen ( final String iHostName , final String iHostPortRange , final String iProtocolName , 
Class < ? extends ONetworkProtocol > protocolClass ) { 
for ( int port : getPorts ( iHostPortRange ) ) { 
inboundAddr = new InetSocketAddress ( iHostName , port ) ; 
serverSocket = socketFactory . createServerSocket ( port , 0 , InetAddress . getByName ( iHostName ) ) ; 
if ( serverSocket . isBound ( ) ) { 
OLogManager . instance ( ) . info ( this , 
} catch ( BindException be ) { 
} catch ( SocketException se ) { 
throw new RuntimeException ( se ) ; 
throw new RuntimeException ( ioe ) ; 
iHostName ) ; 
} private void readParameters ( final OContextConfiguration iServerConfig , final OServerParameterConfiguration [ ] iParameters ) { 
configuration = new OContextConfiguration ( iServerConfig ) ; 
if ( iParameters != null && iParameters . length > 0 ) { 
for ( OServerParameterConfiguration param : iParameters ) 
configuration . setValue ( param . name , param . value ) ; 
socketBufferSize = configuration . getValueAsInteger ( OGlobalConfiguration . NETWORK_SOCKET_BUFFER_SIZE ) ; 
} public void applyStorageFilter ( ) { 
final StorageFilter filter = new StorageFilter ( ) ; 
if ( storageFilterHolder . compareAndSet ( null , filter ) ) { 
for ( Logger logger : loggersCache . values ( ) ) { 
logger . setFilter ( filter ) ; 
if ( shutdownFlag . compareAndSet ( false , true ) ) { 
if ( LogManager . getLogManager ( ) instanceof ShutdownLogManager ) 
( ( ShutdownLogManager ) LogManager . getLogManager ( ) ) . shutdown ( ) ; 
} catch ( NoClassDefFoundError ignore ) { 
} public void add ( K key , V item ) throws InterruptedException { 
if ( ! item . isOpen ( ) ) 
checkOpenFilesLimit ( ) ; 
final OClosableEntry < K , V > closableEntry = new OClosableEntry < K , V > ( item ) ; 
final OClosableEntry < K , V > oldEntry = data . putIfAbsent ( key , closableEntry ) ; 
if ( oldEntry != null ) { 
logAdd ( closableEntry ) ; 
} public V remove ( K key ) { 
final OClosableEntry < K , V > removed = data . remove ( key ) ; 
if ( removed != null ) { 
long preStatus = removed . makeRetired ( ) ; 
if ( OClosableEntry . isOpen ( preStatus ) ) { 
countClosedFiles ( ) ; 
logRemoved ( removed ) ; 
return removed . get ( ) ; 
} public OClosableEntry < K , V > acquire ( K key ) throws InterruptedException { 
final OClosableEntry < K , V > entry = data . get ( key ) ; 
if ( entry == null ) 
boolean logOpen = false ; 
entry . acquireStateLock ( ) ; 
if ( entry . isRetired ( ) || entry . isDead ( ) ) { 
} else if ( entry . isClosed ( ) ) { 
entry . makeAcquiredFromClosed ( entry . get ( ) ) ; 
logOpen = true ; 
} else if ( entry . isOpen ( ) ) { 
entry . makeAcquiredFromOpen ( ) ; 
entry . incrementAcquired ( ) ; 
entry . releaseStateLock ( ) ; 
if ( logOpen ) { 
logOpen ( entry ) ; 
logAcquire ( entry ) ; 
assert entry . get ( ) . isOpen ( ) ; 
} private void checkOpenFilesLimit ( ) throws InterruptedException { 
CountDownLatch ol = openLatch . get ( ) ; 
if ( ol != null ) 
ol . await ( ) ; 
while ( openFiles . get ( ) > openLimit ) { 
final CountDownLatch latch = new CountDownLatch ( 1 ) ; 
if ( openLatch . compareAndSet ( null , latch ) ) { 
emptyBuffers ( ) ; 
latch . countDown ( ) ; 
openLatch . set ( null ) ; 
ol = openLatch . get ( ) ; 
} public V get ( K key ) { 
if ( entry != null ) 
return entry . get ( ) ; 
lruLock . lock ( ) ; 
data . clear ( ) ; 
openFiles . set ( 0 ) ; 
for ( int n = 0 ; n < NUMBER_OF_READ_BUFFERS ; n ++ ) { 
final AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ n ] ; 
for ( int i = 0 ; i < READ_BUFFER_SIZE ; i ++ ) { 
buffer [ i ] . set ( null ) ; 
readBufferReadCount [ n ] = 0 ; 
readBufferWriteCount [ n ] . set ( 0 ) ; 
readBufferDrainAtWriteCount [ n ] . set ( 0 ) ; 
stateBuffer . clear ( ) ; 
while ( lruList . poll ( ) != null ) 
; 
lruLock . unlock ( ) ; 
} public boolean close ( K key ) { 
if ( entry . makeClosed ( ) ) { 
} private void emptyWriteBuffer ( ) { 
Runnable task = stateBuffer . poll ( ) ; 
while ( task != null ) { 
task = stateBuffer . poll ( ) ; 
} private void emptyReadBuffers ( ) { 
AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ n ] ; 
long writeCount = readBufferDrainAtWriteCount [ n ] . get ( ) ; 
long counter = readBufferReadCount [ n ] ; 
final int bufferIndex = ( int ) ( counter & READ_BUFFER_INDEX_MASK ) ; 
final AtomicReference < OClosableEntry < K , V > > eref = buffer [ bufferIndex ] ; 
final OClosableEntry < K , V > entry = eref . get ( ) ; 
applyRead ( entry ) ; 
eref . lazySet ( null ) ; 
readBufferReadCount [ n ] = counter ; 
readBufferDrainAtWriteCount [ n ] . lazySet ( writeCount ) ; 
} private void afterWrite ( Runnable task ) { 
stateBuffer . add ( task ) ; 
drainStatus . lazySet ( DrainStatus . REQUIRED ) ; 
tryToDrainBuffers ( ) ; 
} private void afterRead ( OClosableEntry < K , V > entry ) { 
final int bufferIndex = readBufferIndex ( ) ; 
final long writeCount = putEntryInReadBuffer ( entry , bufferIndex ) ; 
drainReadBuffersIfNeeded ( bufferIndex , writeCount ) ; 
} private long putEntryInReadBuffer ( OClosableEntry < K , V > entry , int bufferIndex ) { 
AtomicLong writeCounter = readBufferWriteCount [ bufferIndex ] ; 
final long counter = writeCounter . get ( ) ; 
writeCounter . lazySet ( counter + 1 ) ; 
final AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ bufferIndex ] ; 
AtomicReference < OClosableEntry < K , V > > bufferEntry = buffer [ ( int ) ( counter & READ_BUFFER_INDEX_MASK ) ] ; 
bufferEntry . lazySet ( entry ) ; 
return counter + 1 ; 
} private static int closestPowerOfTwo ( int value ) { 
int n = value - 1 ; 
n |= n > > > 1 ; 
n |= n > > > 2 ; 
n |= n > > > 4 ; 
n |= n > > > 8 ; 
n |= n > > > 16 ; 
return ( n < 0 ) ? 1 : ( n >= ( 1 << 30 ) ) ? 1 << 30 : n + 1 ; 
public void serializeInByteBufferObject ( Long object , ByteBuffer buffer , Object ... hints ) { 
buffer . putLong ( object ) ; 
public Long deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return walChanges . getLongValue ( buffer , offset ) ; 
} public boolean onEvent ( OLiveQueryPushRequest pushRequest ) { 
ODatabaseDocumentInternal old = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
database . activateOnCurrentThread ( ) ; 
if ( pushRequest . getStatus ( ) == OLiveQueryPushRequest . ERROR ) { 
onError ( pushRequest . getErrorCode ( ) . newException ( pushRequest . getErrorMessage ( ) , null ) ) ; 
for ( OLiveQueryResult result : pushRequest . getEvents ( ) ) { 
switch ( result . getEventType ( ) ) { 
case OLiveQueryResult . CREATE_EVENT : 
listener . onCreate ( database , result . getCurrentValue ( ) ) ; 
case OLiveQueryResult . UPDATE_EVENT : 
listener . onUpdate ( database , result . getOldValue ( ) , result . getCurrentValue ( ) ) ; 
case OLiveQueryResult . DELETE_EVENT : 
listener . onDelete ( database , result . getCurrentValue ( ) ) ; 
if ( pushRequest . getStatus ( ) == OLiveQueryPushRequest . END ) { 
onEnd ( ) ; 
ODatabaseRecordThreadLocal . instance ( ) . set ( old ) ; 
} public OCommandRequestText fromStream ( final byte [ ] iStream , ORecordSerializer serializer ) throws IOException { 
if ( iStream == null || iStream . length == 0 ) 
final int classNameSize = OBinaryProtocol . bytes2int ( iStream ) ; 
if ( classNameSize <= 0 ) { 
throw new OSerializationException ( message ) ; 
final String className = new String ( iStream , 4 , classNameSize , "UTF-8" ) ; 
final OCommandRequestText stream ; 
if ( className . equalsIgnoreCase ( "q" ) ) 
stream = new OSQLSynchQuery < Object > ( ) ; 
else if ( className . equalsIgnoreCase ( "c" ) ) 
stream = new OCommandSQL ( ) ; 
else if ( className . equalsIgnoreCase ( "s" ) ) 
stream = new OCommandScript ( ) ; 
stream = ( OCommandRequestText ) Class . forName ( className ) . newInstance ( ) ; 
return stream . fromStream ( OArrays . copyOfRange ( iStream , 4 + classNameSize , iStream . length ) , serializer ) ; 
} public byte [ ] toStream ( final OCommandRequestText iObject ) throws IOException { 
if ( iObject == null ) 
final byte [ ] className ; 
if ( iObject instanceof OLiveQuery < ? > ) 
className = iObject . getClass ( ) . getName ( ) . getBytes ( "UTF-8" ) ; 
else if ( iObject instanceof OSQLSynchQuery < ? > ) 
className = QUERY_COMMAND_CLASS_ASBYTES ; 
else if ( iObject instanceof OCommandSQL ) 
className = SQL_COMMAND_CLASS_ASBYTES ; 
else if ( iObject instanceof OCommandScript ) 
className = SCRIPT_COMMAND_CLASS_ASBYTES ; 
className = null ; 
byte [ ] objectContent = iObject . toStream ( ) ; 
byte [ ] result = new byte [ 4 + className . length + objectContent . length ] ; 
System . arraycopy ( OBinaryProtocol . int2bytes ( className . length ) , 0 , result , 0 , 4 ) ; 
System . arraycopy ( className , 0 , result , 4 , className . length ) ; 
System . arraycopy ( objectContent , 0 , result , 4 + className . length , objectContent . length ) ; 
final ODocument instance = new ODocument ( ) ; 
ORecordSerializerSchemaAware2CSV . INSTANCE . fromStream ( iStream . getBytes ( "UTF-8" ) , instance , null ) ; 
final String className = instance . field ( ODocumentSerializable . CLASS_NAME ) ; 
Class < ? > clazz = null ; 
clazz = Class . forName ( className ) ; 
if ( ODocumentSerializable . class . isAssignableFrom ( clazz ) ) { 
final ODocumentSerializable documentSerializable = ( ODocumentSerializable ) clazz . newInstance ( ) ; 
final ODocument docClone = new ODocument ( ) ; 
instance . copyTo ( docClone ) ; 
docClone . removeField ( ODocumentSerializable . CLASS_NAME ) ; 
documentSerializable . fromDocument ( docClone ) ; 
return documentSerializable ; 
} catch ( InstantiationException e ) { 
} catch ( IllegalAccessException e ) { 
if ( iValue instanceof ODocumentSerializable ) 
iValue = ( ( ODocumentSerializable ) iValue ) . toDocument ( ) ; 
throw new OSerializationException ( 
iOutput . append ( SEPARATOR ) ; 
iOutput . append ( new String ( stream . toStream ( ) , "UTF-8" ) ) ; 
} private void convert ( final Object iKey ) { 
if ( super . containsKey ( iKey ) ) 
Object o = underlying . get ( String . valueOf ( iKey ) ) ; 
super . put ( iKey , enumClass . getEnumConstants ( ) [ ( ( Number ) o ) . intValue ( ) ] ) ; 
super . put ( iKey , Enum . valueOf ( enumClass , o . toString ( ) ) ) ; 
} protected void convertAll ( ) { 
for ( java . util . Map . Entry < Object , Object > e : underlying . entrySet ( ) ) { 
if ( e . getValue ( ) instanceof Number ) 
super . put ( e . getKey ( ) , enumClass . getEnumConstants ( ) [ ( ( Number ) e . getValue ( ) ) . intValue ( ) ] ) ; 
super . put ( e . getKey ( ) , Enum . valueOf ( enumClass , e . getValue ( ) . toString ( ) ) ) ; 
converted = true ; 
public < T > OBinarySerializer < T > getObjectSerializer ( final OType type ) { 
return ( OBinarySerializer < T > ) serializerTypeMap . get ( type ) ; 
} public void processRequest ( final ODistributedRequest request , final boolean waitForAcceptingRequests ) { 
final CountDownLatch syncLatch = new CountDownLatch ( involvedWorkerQueues . size ( ) ) ; 
final ODistributedRequest syncRequest = new ODistributedRequest ( null , request . getId ( ) . getNodeId ( ) , - 1 , databaseName , 
new OSynchronizedTaskWrapper ( syncLatch ) ) ; 
long taskTimeout = 0 ; 
if ( taskTimeout <= 0 ) 
syncLatch . await ( ) ; 
final long start = System . currentTimeMillis ( ) ; 
final long cycleTimeout = Math . min ( taskTimeout , 2000 ) ; 
boolean locked = false ; 
if ( syncLatch . await ( cycleTimeout , TimeUnit . MILLISECONDS ) ) { 
locked = true ; 
if ( this . workerThreads . size ( ) == 0 ) 
} while ( System . currentTimeMillis ( ) - start < taskTimeout ) ; 
if ( ! locked ) { 
final String msg = String . format ( 
request , workerThreads . size ( ) , syncLatch . getCount ( ) , taskTimeout ) ; 
ODistributedWorker . sendResponseBack ( this , manager , request , new ODistributedOperationException ( msg ) ) ; 
final String msg = String 
workerThreads . size ( ) ) ; 
final CountDownLatch queueLatch = new CountDownLatch ( 1 ) ; 
final ODistributedRequest req ; 
if ( i ++ == 0 ) { 
final String senderNodeName = manager . getNodeNameById ( request . getId ( ) . getNodeId ( ) ) ; 
request . setTask ( new OSynchronizedTaskWrapper ( queueLatch , senderNodeName , task ) ) ; 
req = request ; 
req = new ODistributedRequest ( manager , request . getId ( ) . getNodeId ( ) , - 1 , databaseName , new OWaitForTask ( queueLatch ) ) ; 
workerThreads . get ( queue ) . processRequest ( req ) ; 
} public void addShutdownHandler ( OShutdownHandler shutdownHandler ) { 
engineLock . writeLock ( ) . lock ( ) ; 
shutdownHandlers . add ( shutdownHandler ) ; 
engineLock . writeLock ( ) . unlock ( ) ; 
} private void initShutdownQueue ( ) { 
addShutdownHandler ( new OShutdownWorkersHandler ( ) ) ; 
addShutdownHandler ( new OShutdownOrientDBInstancesHandler ( ) ) ; 
addShutdownHandler ( new OShutdownPendingThreadsHandler ( ) ) ; 
addShutdownHandler ( new OShutdownProfilerHandler ( ) ) ; 
addShutdownHandler ( new OShutdownCallListenersHandler ( ) ) ; 
} private void registerEngines ( ) { 
ClassLoader classLoader = Orient . class . getClassLoader ( ) ; 
Iterator < OEngine > engines = OClassLoaderHelper . lookupProviderWithOrientClassLoader ( OEngine . class , classLoader ) ; 
OEngine engine = null ; 
while ( engines . hasNext ( ) ) { 
engine = engines . next ( ) ; 
registerEngine ( engine ) ; 
} catch ( IllegalArgumentException e ) { 
} public OEngine getEngine ( final String engineName ) { 
engineLock . readLock ( ) . lock ( ) ; 
return engines . get ( engineName ) ; 
engineLock . readLock ( ) . unlock ( ) ; 
} public OEngine getEngineIfRunning ( final String engineName ) { 
final OEngine engine = engines . get ( engineName ) ; 
return engine == null || ! engine . isRunning ( ) ? null : engine ; 
} public OEngine getRunningEngine ( final String engineName ) { 
OEngine engine = engines . get ( engineName ) ; 
if ( engine == null ) 
if ( ! engine . isRunning ( ) && ! startEngine ( engine ) ) 
return engine ; 
} @ Override public OResultSet executeSimple ( OCommandContext ctx ) { 
OResultInternal result = new OResultInternal ( ) ; 
OStorage storage = ( ( ODatabaseInternal ) ctx . getDatabase ( ) ) . getStorage ( ) ; 
if ( on ) { 
( ( OAbstractPaginatedStorage ) storage ) . startGatheringPerformanceStatisticForCurrentThread ( ) ; 
result . setProperty ( "value" , "on" ) ; 
final OSessionStoragePerformanceStatistic performanceStatistic = ( ( OAbstractPaginatedStorage ) storage ) 
. completeGatheringPerformanceStatisticForCurrentThread ( ) ; 
result . setProperty ( "value" , "off" ) ; 
if ( performanceStatistic != null ) { 
result . setProperty ( "result" , performanceStatistic . toDocument ( ) ) ; 
result . setProperty ( "result" , "error" ) ; 
OInternalResultSet rs = new OInternalResultSet ( ) ; 
rs . add ( result ) ; 
return rs ; 
} @ Override public Object execute ( OSQLAsynchQuery < ODocument > request , OCommandContext context , OProgressListener progressListener ) { 
final OStorage storage = db . getStorage ( ) ; 
ODocument result = new ODocument ( ) ; 
result . field ( "result" , "OK" ) ; 
request . getResultListener ( ) . result ( result ) ; 
if ( performanceStatistic != null ) 
request . getResultListener ( ) . result ( performanceStatistic . toDocument ( ) ) ; 
} protected void removeState ( AtomicInteger state ) { 
readersStateList . remove ( state ) ; 
readersStateArrayRef . set ( null ) ; 
state . set ( SRWL_STATE_NOT_READING ) ; 
} private ReadersEntry addState ( ) { 
final AtomicInteger state = new AtomicInteger ( SRWL_STATE_NOT_READING ) ; 
final ReadersEntry newEntry = new ReadersEntry ( state ) ; 
entry . set ( newEntry ) ; 
readersStateList . add ( state ) ; 
return newEntry ; 
} public void sharedLock ( ) { 
ReadersEntry localEntry = entry . get ( ) ; 
if ( localEntry == null ) { 
localEntry = addState ( ) ; 
final AtomicInteger currentReadersState = localEntry . state ; 
currentReadersState . set ( SRWL_STATE_READING ) ; 
if ( ! stampedLock . isWriteLocked ( ) ) { 
currentReadersState . set ( SRWL_STATE_NOT_READING ) ; 
while ( stampedLock . isWriteLocked ( ) ) { 
Thread . yield ( ) ; 
} public void sharedUnlock ( ) { 
final ReadersEntry localEntry = entry . get ( ) ; 
throw new IllegalMonitorStateException ( ) ; 
localEntry . state . set ( SRWL_STATE_NOT_READING ) ; 
} public void exclusiveLock ( ) { 
stampedLock . writeLock ( ) ; 
AtomicInteger [ ] localReadersStateArray = readersStateArrayRef . get ( ) ; 
if ( localReadersStateArray == null ) { 
readersStateArrayRef . set ( dummyArray ) ; 
localReadersStateArray = readersStateList . toArray ( new AtomicInteger [ readersStateList . size ( ) ] ) ; 
readersStateArrayRef . compareAndSet ( dummyArray , localReadersStateArray ) ; 
for ( AtomicInteger readerState : localReadersStateArray ) { 
while ( readerState != null && readerState . get ( ) == SRWL_STATE_READING ) { 
} public boolean sharedTryLock ( ) { 
} public boolean sharedTryLockNanos ( long nanosTimeout ) { 
final long lastTime = System . nanoTime ( ) ; 
if ( nanosTimeout <= 0 ) 
if ( System . nanoTime ( ) - lastTime < nanosTimeout ) { 
} public boolean exclusiveTryLock ( ) { 
if ( stampedLock . tryWriteLock ( ) == 0 ) { 
if ( readerState != null && readerState . get ( ) == SRWL_STATE_READING ) { 
stampedLock . asWriteLock ( ) . unlock ( ) ; 
} public boolean exclusiveTryLockNanos ( long nanosTimeout ) throws InterruptedException { 
if ( stampedLock . tryWriteLock ( nanosTimeout , TimeUnit . NANOSECONDS ) == 0 ) { 
} public OUser authenticate ( final OToken authToken ) { 
final String dbName = getDatabase ( ) . getName ( ) ; 
if ( authToken . getIsValid ( ) != true ) { 
OUser user = authToken . getUser ( getDatabase ( ) ) ; 
if ( user == null && authToken . getUserName ( ) != null ) { 
user = getUser ( authToken . getUserName ( ) ) ; 
if ( user . getAccountStatus ( ) != STATUSES . ACTIVE ) 
return user ; 
} public OUser createMetadata ( ) { 
OClass identityClass = database . getMetadata ( ) . getSchema ( ) . getClass ( OIdentity . CLASS_NAME ) ; 
if ( identityClass == null ) 
identityClass = database . getMetadata ( ) . getSchema ( ) . createAbstractClass ( OIdentity . CLASS_NAME ) ; 
OClass roleClass = createOrUpdateORoleClass ( database , identityClass ) ; 
createOrUpdateOUserClass ( database , identityClass , roleClass ) ; 
ORole adminRole = getRole ( ORole . ADMIN ) ; 
if ( adminRole == null ) { 
adminRole = createRole ( ORole . ADMIN , ORole . ALLOW_MODES . ALLOW_ALL_BUT ) ; 
adminRole . addRule ( ORule . ResourceGeneric . BYPASS_RESTRICTED , null , ORole . PERMISSION_ALL ) . save ( ) ; 
OUser adminUser = getUser ( OUser . ADMIN ) ; 
if ( adminUser == null ) { 
boolean createDefUsers = getDatabase ( ) . getStorage ( ) . getConfiguration ( ) . getContextConfiguration ( ) 
. getValueAsBoolean ( OGlobalConfiguration . CREATE_DEFAULT_USERS ) ; 
if ( createDefUsers ) { 
adminUser = createUser ( OUser . ADMIN , OUser . ADMIN , adminRole ) ; 
createOrUpdateORestrictedClass ( database ) ; 
return adminUser ; 
} public List < OIdentifiable > execute ( ) { 
final List < OIdentifiable > result = new ArrayList < OIdentifiable > ( ) ; 
while ( hasNext ( ) ) 
result . add ( next ( ) ) ; 
} public static void dumpHeap ( String fileName , boolean live ) { 
MBeanServer server = ManagementFactory . getPlatformMBeanServer ( ) ; 
server . invoke ( new ObjectName ( HOTSPOT_BEAN_NAME ) , 
"dumpHeap" , 
new Object [ ] { fileName , live } , 
new String [ ] { String . class . getName ( ) , Boolean . TYPE . getName ( ) } 
} catch ( RuntimeException re ) { 
} catch ( Exception exp ) { 
throw new RuntimeException ( exp ) ; 
} public boolean tryAcquireReadLock ( long timeout ) { 
final OModifiableInteger lHolds = lockHolds . get ( ) ; 
final int holds = lHolds . intValue ( ) ; 
if ( holds > 0 ) { 
lHolds . increment ( ) ; 
} else if ( holds < 0 ) { 
distributedCounter . increment ( ) ; 
WNode wNode = tail . get ( ) ; 
final long start = System . nanoTime ( ) ; 
while ( wNode . locked ) { 
distributedCounter . decrement ( ) ; 
while ( wNode . locked && wNode == tail . get ( ) ) { 
wNode . waitingReaders . put ( Thread . currentThread ( ) , Boolean . TRUE ) ; 
if ( wNode . locked && wNode == tail . get ( ) ) { 
final long parkTimeout = timeout - ( System . nanoTime ( ) - start ) ; 
if ( parkTimeout > 0 ) { 
LockSupport . parkNanos ( this , parkTimeout ) ; 
wNode = tail . get ( ) ; 
if ( System . nanoTime ( ) - start > timeout ) { 
assert lHolds . intValue ( ) == 1 ; 
} public static boolean isLabeled ( final String iEdgeLabel , final String [ ] iLabels ) { 
if ( iLabels != null && iLabels . length > 0 ) { 
if ( iEdgeLabel != null ) 
for ( String l : iLabels ) 
if ( l . equals ( iEdgeLabel ) ) 
} public static String getRecordLabel ( final OIdentifiable iEdge ) { 
if ( iEdge == null ) 
final ODocument edge = iEdge . getRecord ( ) ; 
if ( edge == null ) 
return edge . field ( OrientElement . LABEL_FIELD_NAME ) ; 
} private static void removeLightweightConnection ( final ODocument iVertex , final String iFieldName , 
final OIdentifiable iVertexToRemove ) { 
if ( iVertex == null || iVertexToRemove == null ) 
final Object fieldValue = iVertex . field ( iFieldName ) ; 
if ( fieldValue . equals ( iVertexToRemove ) ) { 
( ( ORidBag ) fieldValue ) . remove ( iVertexToRemove ) ; 
public OrientVertex getVertex ( final Direction direction ) { 
if ( direction . equals ( Direction . OUT ) ) 
return graph . getVertex ( getOutVertex ( ) ) ; 
else if ( direction . equals ( Direction . IN ) ) 
return graph . getVertex ( getInVertex ( ) ) ; 
throw ExceptionFactory . bothIsNotSupported ( ) ; 
} public OIdentifiable getOutVertex ( ) { 
if ( vOut != null ) 
return vOut ; 
if ( settings != null && settings . isKeepInMemoryReferences ( ) ) 
return doc . rawField ( OrientBaseGraph . CONNECTION_OUT ) ; 
return doc . field ( OrientBaseGraph . CONNECTION_OUT ) ; 
} public OIdentifiable getInVertex ( ) { 
if ( vIn != null ) 
return vIn ; 
return doc . rawField ( OrientBaseGraph . CONNECTION_IN ) ; 
return doc . field ( OrientBaseGraph . CONNECTION_IN ) ; 
if ( label != null ) 
return label ; 
else if ( rawElement != null ) { 
if ( settings != null && settings . isUseClassForEdgeLabel ( ) ) { 
if ( ! OrientEdgeType . CLASS_NAME . equals ( clsName ) ) 
return OrientBaseGraph . decodeClassName ( clsName ) ; 
final String label = doc . field ( OrientElement . LABEL_FIELD_NAME ) ; 
return OrientBaseGraph . decodeClassName ( label ) ; 
public Object getId ( ) { 
return vOut . getIdentity ( ) + "->" + vIn . getIdentity ( ) ; 
return super . getId ( ) ; 
public < T > T getProperty ( final String key ) { 
return super . getProperty ( key ) ; 
return Collections . emptySet ( ) ; 
for ( String field : getRecord ( ) . fieldNames ( ) ) 
if ( ! field . equals ( OrientBaseGraph . CONNECTION_OUT ) && ! field . equals ( OrientBaseGraph . CONNECTION_IN ) && ( 
settings . isUseClassForEdgeLabel ( ) || ! field . equals ( OrientElement . LABEL_FIELD_NAME ) ) ) 
public void setProperty ( final String key , final Object value ) { 
convertToDocument ( ) ; 
super . setProperty ( key , value ) ; 
public < T > T removeProperty ( String key ) { 
if ( rawElement != null ) 
return super . removeProperty ( key ) ; 
if ( ! isLightweight ( ) ) 
for ( final Index < ? extends Element > index : graph . getIndices ( ) ) { 
graph . removeEdgeInternal ( this ) ; 
OrientGraphNoTx . removeEdgeInternal ( null , this ) ; 
public ODocument getRecord ( ) { 
if ( rawElement == null ) { 
final ODocument tmp = new ODocument ( getClassName ( label ) ) . setTrackingChanges ( false ) ; 
tmp . field ( OrientBaseGraph . CONNECTION_IN , vIn . getIdentity ( ) ) ; 
tmp . field ( OrientBaseGraph . CONNECTION_OUT , vOut . getIdentity ( ) ) ; 
if ( label != null && settings != null && ! settings . isUseClassForEdgeLabel ( ) ) 
tmp . field ( OrientEdge . LABEL_FIELD_NAME , label ) ; 
return tmp ; 
return super . getRecord ( ) ; 
} public void convertToDocument ( ) { 
final ODocument vOutRecord = vOut . getRecord ( ) ; 
final ODocument vInRecord = vIn . getRecord ( ) ; 
final ODocument doc = createDocument ( label ) ; 
doc . field ( OrientBaseGraph . CONNECTION_OUT , settings . isKeepInMemoryReferences ( ) ? vOutRecord . getIdentity ( ) : vOutRecord ) ; 
doc . field ( OrientBaseGraph . CONNECTION_IN , settings . isKeepInMemoryReferences ( ) ? vInRecord . getIdentity ( ) : vInRecord ) ; 
final String outFieldName = OrientVertex . getConnectionFieldName ( Direction . OUT , label , useVertexFieldsForEdgeLabels ) ; 
removeLightweightConnection ( vOutRecord , outFieldName , vInRecord ) ; 
OrientVertex . createLink ( graph , vOutRecord , doc , outFieldName ) ; 
vOutRecord . save ( ) ; 
final String inFieldName = OrientVertex . getConnectionFieldName ( Direction . IN , label , useVertexFieldsForEdgeLabels ) ; 
removeLightweightConnection ( vInRecord , inFieldName , vOutRecord ) ; 
OrientVertex . createLink ( graph , vInRecord , doc , inFieldName ) ; 
vInRecord . save ( ) ; 
vOut = null ; 
vIn = null ; 
label = null ; 
} public String getClassName ( final String iLabel ) { 
if ( iLabel != null && ( settings == null || settings . isUseClassForEdgeLabel ( ) ) ) 
return checkForClassInSchema ( iLabel ) ; 
database . checkSecurity ( ORule . ResourceGeneric . DATABASE , ORole . PERMISSION_UPDATE ) ; 
database . setInternal ( attribute , value ) ; 
buffer . putLong ( calendar . getTimeInMillis ( ) ) ; 
calendar . setTimeInMillis ( buffer . getLong ( ) ) ; 
return calendar . getTime ( ) ; 
calendar . setTimeInMillis ( walChanges . getLongValue ( buffer , offset ) ) ; 
database . checkSecurity ( ORule . ResourceGeneric . SERVER , "remove" , ORole . PERMISSION_EXECUTE ) ; 
return dManager . removeNodeFromConfiguration ( parsedStatement . serverName . getStringValue ( ) , databaseName , false , true ) ; 
public void clear ( ) throws IOException { 
boolean rollback = false ; 
final OAtomicOperation atomicOperation = startAtomicOperation ( true ) ; 
final Lock lock = FILE_LOCK_MANAGER . acquireExclusiveLock ( fileId ) ; 
final Queue < OBonsaiBucketPointer > subTreesToDelete = new LinkedList < > ( ) ; 
final OCacheEntry cacheEntry = loadPageForWrite ( atomicOperation , fileId , rootBucketPointer . getPageIndex ( ) , false , true ) ; 
OSBTreeBonsaiBucket < K , V > rootBucket = new OSBTreeBonsaiBucket < > ( cacheEntry , rootBucketPointer . getPageOffset ( ) , 
keySerializer , valueSerializer , this ) ; 
addChildrenToQueue ( subTreesToDelete , rootBucket ) ; 
rootBucket . shrink ( 0 ) ; 
rootBucket = new OSBTreeBonsaiBucket < > ( cacheEntry , rootBucketPointer . getPageOffset ( ) , true , keySerializer , 
valueSerializer , this ) ; 
rootBucket . setTreeSize ( 0 ) ; 
releasePageFromWrite ( atomicOperation , cacheEntry ) ; 
recycleSubTrees ( subTreesToDelete , atomicOperation ) ; 
rollback = true ; 
endAtomicOperation ( rollback ) ; 
public void delete ( ) throws IOException { 
final OAtomicOperation atomicOperation = startAtomicOperation ( false ) ; 
subTreesToDelete . add ( rootBucketPointer ) ; 
out = estimatedEntries > 0 ? new HashMap < Long , List < Long > > ( estimatedEntries ) : new HashMap < Long , List < Long > > ( ) ; 
in = estimatedEntries > 0 ? new HashMap < Long , List < Long > > ( estimatedEntries ) : new HashMap < Long , List < Long > > ( ) ; 
lastClusterPositions [ i ] = db . getStorage ( ) . getClusterById ( clusterId ) . getLastPosition ( ) ; 
} public void end ( ) { 
final OClass vClass = db . getMetadata ( ) . getSchema ( ) . getClass ( vertexClass ) ; 
runningThreads = new AtomicInteger ( parallel ) ; 
for ( int i = 0 ; i < parallel - 1 ; i ++ ) { 
Thread t = new BatchImporterJob ( i , vClass ) ; 
Thread t = new BatchImporterJob ( parallel - 1 , vClass ) ; 
t . run ( ) ; 
if ( runningThreads . get ( ) > 0 ) { 
synchronized ( runningThreads ) { 
while ( runningThreads . get ( ) > 0 ) { 
runningThreads . wait ( ) ; 
db . declareIntent ( null ) ; 
OGlobalConfiguration . USE_WAL . setValue ( true ) ; 
} public void createVertex ( final Long v ) { 
last = last < v ? v : last ; 
final List < Long > outList = out . get ( v ) ; 
if ( outList == null ) { 
out . put ( v , new ArrayList < Long > ( averageEdgeNumberPerNode <= 0 ? 4 : averageEdgeNumberPerNode ) ) ; 
} public void createEdge ( final Long from , final Long to ) { 
final OVertex v = toVertex ( rid ) ; 
v . delete ( ) ; 
final OVertex v = toVertex ( record ) ; 
} public OCommandExecutorSQLTraverse parse ( final OCommandRequest iRequest ) { 
String originalQuery = queryText ; 
queryText = preParse ( queryText , iRequest ) ; 
textRequest . setText ( queryText ) ; 
super . parse ( iRequest ) ; 
final int pos = parseFields ( ) ; 
if ( pos == - 1 ) 
parserSetCurrentPosition ( pos ) ; 
int endPosition = parserText . length ( ) ; 
parsedTarget = OSQLEngine . getInstance ( ) . parseTarget ( parserText . substring ( pos , endPosition ) , getContext ( ) ) ; 
if ( parsedTarget . parserIsEnded ( ) ) 
parserSetCurrentPosition ( endPosition ) ; 
parserMoveCurrentPosition ( parsedTarget . parserGetCurrentPosition ( ) ) ; 
if ( ! parserIsEnded ( ) ) { 
parserNextWord ( true ) ; 
if ( parserGetLastWord ( ) . equalsIgnoreCase ( KEYWORD_WHERE ) ) 
warnDeprecatedWhere ( ) ; 
if ( parserGetLastWord ( ) . equalsIgnoreCase ( KEYWORD_WHERE ) || parserGetLastWord ( ) . equalsIgnoreCase ( KEYWORD_WHILE ) ) { 
compiledFilter = OSQLEngine . getInstance ( ) . parseCondition ( parserText . substring ( parserGetCurrentPosition ( ) , endPosition ) , 
getContext ( ) , KEYWORD_WHILE ) ; 
traverse . predicate ( compiledFilter ) ; 
optimize ( ) ; 
parserSetCurrentPosition ( compiledFilter . parserIsEnded ( ) ? endPosition 
: compiledFilter . parserGetCurrentPosition ( ) + parserGetCurrentPosition ( ) ) ; 
parserSkipWhiteSpaces ( ) ; 
while ( ! parserIsEnded ( ) ) { 
if ( parserOptionalKeyword ( KEYWORD_LIMIT , KEYWORD_SKIP , KEYWORD_OFFSET , KEYWORD_TIMEOUT , KEYWORD_MAXDEPTH , 
KEYWORD_STRATEGY ) ) { 
final String w = parserGetLastWord ( ) ; 
if ( w . equals ( KEYWORD_LIMIT ) ) 
parseLimit ( w ) ; 
else if ( w . equals ( KEYWORD_SKIP ) || w . equals ( KEYWORD_OFFSET ) ) 
parseSkip ( w ) ; 
else if ( w . equals ( KEYWORD_TIMEOUT ) ) 
parseTimeout ( w ) ; 
else if ( w . equals ( KEYWORD_MAXDEPTH ) ) 
parseMaxDepth ( w ) ; 
else if ( w . equals ( KEYWORD_STRATEGY ) ) 
parseStrategy ( w ) ; 
if ( limit == 0 || limit < - 1 ) 
traverse . limit ( limit ) ; 
traverse . getContext ( ) . setParent ( iRequest . getContext ( ) ) ; 
textRequest . setText ( originalQuery ) ; 
} protected boolean parseStrategy ( final String w ) throws OCommandSQLParsingException { 
if ( ! w . equals ( KEYWORD_STRATEGY ) ) 
final String strategyWord = parserNextWord ( true ) ; 
traverse . setStrategy ( OTraverse . STRATEGY . valueOf ( strategyWord . toUpperCase ( Locale . ENGLISH ) ) ) ; 
} catch ( IllegalArgumentException ignore ) { 
public void serializeInByteBufferObject ( byte [ ] object , ByteBuffer buffer , Object ... hints ) { 
final int len = object . length ; 
buffer . putInt ( len ) ; 
public byte [ ] deserializeFromByteBufferObject ( ByteBuffer buffer ) { 
final int len = buffer . getInt ( ) ; 
final byte [ ] result = new byte [ len ] ; 
buffer . get ( result ) ; 
public byte [ ] deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
final int len = walChanges . getIntValue ( buffer , offset ) ; 
return walChanges . getBinaryValue ( buffer , offset , len ) ; 
return walChanges . getIntValue ( buffer , offset ) + OIntegerSerializer . INT_SIZE ; 
} private List < RecordInfo > getPositionsFromEmbeddedCollection ( final BytesContainer bytes , int serializerVersion ) { 
List < RecordInfo > retList = new ArrayList < > ( ) ; 
int numberOfElements = OVarIntSerializer . readAsInteger ( bytes ) ; 
readByte ( bytes ) ; 
for ( int i = 0 ; i < numberOfElements ; i ++ ) { 
OType dataType = readOType ( bytes , false ) ; 
int fieldStart = bytes . offset ; 
RecordInfo fieldInfo = new RecordInfo ( ) ; 
fieldInfo . fieldStartOffset = fieldStart ; 
fieldInfo . fieldType = dataType ; 
deserializeValue ( bytes , dataType , null , true , - 1 , serializerVersion , true ) ; 
fieldInfo . fieldLength = bytes . offset - fieldStart ; 
retList . add ( fieldInfo ) ; 
return retList ; 
if ( newRecords == null && content == null && subQuery == null ) 
final OCommandParameters commandParameters = new OCommandParameters ( iArgs ) ; 
if ( indexName != null ) { 
if ( newRecords == null ) 
final OIndex < ? > index = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . getIndex ( indexName ) ; 
Map < String , Object > result = new HashMap < String , Object > ( ) ; 
for ( Map < String , Object > candidate : newRecords ) { 
Object indexKey = getIndexKeyValue ( commandParameters , candidate ) ; 
OIdentifiable indexValue = getIndexValue ( commandParameters , candidate ) ; 
if ( index instanceof OIndexMultiValues ) { 
final Collection < ORID > rids = ( ( OIndexMultiValues ) index ) . get ( indexKey ) ; 
if ( ! rids . contains ( indexValue . getIdentity ( ) ) ) { 
index . put ( indexKey , indexValue ) ; 
result . put ( KEYWORD_KEY , indexKey ) ; 
result . put ( KEYWORD_RID , indexValue ) ; 
return prepareReturnItem ( new ODocument ( result ) ) ; 
final List < ODocument > docs = new ArrayList < ODocument > ( ) ; 
if ( newRecords != null ) { 
final ODocument doc = className != null ? new ODocument ( className ) : new ODocument ( ) ; 
OSQLHelper . bindParameters ( doc , candidate , commandParameters , context ) ; 
saveRecord ( doc ) ; 
docs . add ( doc ) ; 
if ( docs . size ( ) == 1 ) 
return prepareReturnItem ( docs . get ( 0 ) ) ; 
return prepareReturnResult ( docs ) ; 
} else if ( content != null ) { 
doc . merge ( content , true , false ) ; 
return prepareReturnItem ( doc ) ; 
} else if ( subQuery != null ) { 
subQuery . execute ( ) ; 
if ( queryResult != null ) 
return prepareReturnResult ( queryResult ) ; 
return saved . longValue ( ) ; 
} protected boolean fixLink ( final Object fieldValue ) { 
final ORID id = ( ( OIdentifiable ) fieldValue ) . getIdentity ( ) ; 
if ( id . getClusterId ( ) == 0 && id . getClusterPosition ( ) == 0 ) 
if ( id . isValid ( ) ) 
if ( id . isPersistent ( ) ) { 
final ORecord connected = ( ( OIdentifiable ) fieldValue ) . getRecord ( ) ; 
if ( connected == null ) 
} public static PersistenceUnitTransactionType initTransactionType ( String elementContent ) { 
if ( elementContent == null || elementContent . isEmpty ( ) ) { 
return PersistenceUnitTransactionType . valueOf ( elementContent . toUpperCase ( Locale . ENGLISH ) ) ; 
} catch ( IllegalArgumentException ex ) { 
for ( OIndex < ? > idx : database . getMetadata ( ) . getIndexManager ( ) . getIndexes ( ) ) { 
if ( idx . isAutomatic ( ) ) 
totalIndexed += idx . rebuild ( ) ; 
final OIndex < ? > idx = database . getMetadata ( ) . getIndexManager ( ) . getIndex ( name ) ; 
if ( idx == null ) 
if ( ! idx . isAutomatic ( ) ) 
return idx . rebuild ( ) ; 
} public void intercept ( final String url , final String username , final String password ) throws OSecurityException { 
if ( username == null || username . isEmpty ( ) ) 
if ( password == null || password . isEmpty ( ) ) 
this . username = username ; 
String algorithm = OGlobalConfiguration . CLIENT_CI_KEYALGORITHM . getValueAsString ( ) ; 
String transform = OGlobalConfiguration . CLIENT_CI_CIPHERTRANSFORM . getValueAsString ( ) ; 
String keystoreFile = OGlobalConfiguration . CLIENT_CI_KEYSTORE_FILE . getValueAsString ( ) ; 
String keystorePassword = OGlobalConfiguration . CLIENT_CI_KEYSTORE_PASSWORD . getValueAsString ( ) ; 
ODocument jsonDoc = null ; 
jsonDoc = new ODocument ( ) . fromJSON ( password , "noMap" ) ; 
if ( jsonDoc . containsField ( "algorithm" ) ) 
algorithm = jsonDoc . field ( "algorithm" ) ; 
if ( jsonDoc . containsField ( "transform" ) ) 
transform = jsonDoc . field ( "transform" ) ; 
if ( transform == null || transform . isEmpty ( ) ) 
if ( algorithm == null ) 
algorithm = OSymmetricKey . separateAlgorithm ( transform ) ; 
OSymmetricKey key = null ; 
if ( jsonDoc . containsField ( "key" ) ) { 
final String base64Key = jsonDoc . field ( "key" ) ; 
key = OSymmetricKey . fromString ( algorithm , base64Key ) ; 
key . setDefaultCipherTransform ( transform ) ; 
if ( jsonDoc . containsField ( "keyFile" ) ) { 
key = OSymmetricKey . fromFile ( algorithm , ( String ) jsonDoc . field ( "keyFile" ) ) ; 
} else if ( jsonDoc . containsField ( "keyStore" ) ) { 
ODocument ksDoc = jsonDoc . field ( "keyStore" ) ; 
if ( ksDoc . containsField ( "file" ) ) 
keystoreFile = ksDoc . field ( "file" ) ; 
if ( keystoreFile == null || keystoreFile . isEmpty ( ) ) 
if ( ksDoc . containsField ( "password" ) ) 
keystorePassword = ksDoc . field ( "password" ) ; 
String keyAlias = ksDoc . field ( "keyAlias" ) ; 
if ( keyAlias == null || keyAlias . isEmpty ( ) ) 
String keyPassword = ksDoc . field ( "keyPassword" ) ; 
key = OSymmetricKey . fromKeystore ( keystoreFile , keystorePassword , keyAlias , keyPassword ) ; 
encodedJSON = key . encrypt ( transform , username ) ; 
} public static ORecordAbstract fill ( final ORecord record , final ORID iRid , final int iVersion , final byte [ ] iBuffer , 
final boolean iDirty ) { 
final ORecordAbstract rec = ( ORecordAbstract ) record ; 
rec . fill ( iRid , iVersion , iBuffer , iDirty ) ; 
return rec ; 
} public static ORecordAbstract setIdentity ( final ORecord record , final int iClusterId , final long iClusterPosition ) { 
rec . setIdentity ( iClusterId , iClusterPosition ) ; 
} public static ORecordAbstract setIdentity ( final ORecord record , final ORecordId iIdentity ) { 
rec . setIdentity ( iIdentity ) ; 
} public static void setVersion ( final ORecord record , final int iVersion ) { 
rec . setVersion ( iVersion ) ; 
} public static byte getRecordType ( final ORecord record ) { 
if ( record instanceof ORecordAbstract ) { 
return ( ( ORecordAbstract ) record ) . getRecordType ( ) ; 
final ORecordAbstract rec = ( ORecordAbstract ) record . getRecord ( ) ; 
return rec . getRecordType ( ) ; 
} public void initDatabaseInstance ( ) { 
if ( database == null ) { 
for ( int retry = 0 ; retry < 100 ; ++ retry ) { 
database = distributed . getDatabaseInstance ( ) ; 
} catch ( OStorageException e ) { 
if ( ! dbNotAvailable ( retry ) ) 
} catch ( OConfigurationException e ) { 
ODistributedServerLog . info ( this , manager . getLocalNodeName ( ) , null , DIRECTION . NONE , 
distributed . shutdown ( ) ; 
} else if ( database . isClosed ( ) ) { 
database . close ( ) ; 
} protected void onMessage ( final ODistributedRequest iRequest ) { 
String senderNodeName = null ; 
for ( int retry = 0 ; retry < 10 ; retry ++ ) { 
senderNodeName = manager . getNodeNameById ( iRequest . getId ( ) . getNodeId ( ) ) ; 
if ( senderNodeName != null ) 
Thread . sleep ( 200 ) ; 
if ( senderNodeName == null ) { 
ODistributedServerLog . warn ( this , localNodeName , senderNodeName , DIRECTION . IN , 
iRequest . getId ( ) . getNodeId ( ) , iRequest , id ) ; 
final ORemoteTask task = iRequest . getTask ( ) ; 
Object responsePayload = null ; 
OSecurityUser origin = null ; 
waitNodeIsOnline ( ) ; 
distributed . waitIsReady ( task ) ; 
for ( int retry = 1 ; running ; ++ retry ) { 
if ( task . isUsingDatabase ( ) ) { 
initDatabaseInstance ( ) ; 
throw new ODistributedOperationException ( 
origin = database . getUser ( ) ; 
if ( iRequest . getUserRID ( ) != null && iRequest . getUserRID ( ) . isValid ( ) && ( lastUser == null || ! ( lastUser . getIdentity ( ) ) 
. equals ( iRequest . getUserRID ( ) ) ) ) { 
lastUser = database . getMetadata ( ) . getSecurity ( ) . getUser ( iRequest . getUserRID ( ) ) ; 
database . setUser ( lastUser ) ; 
origin = null ; 
responsePayload = manager . executeOnLocalNode ( iRequest . getId ( ) , iRequest . getTask ( ) , database ) ; 
if ( responsePayload instanceof OModificationOperationProhibitedException ) { 
ODistributedServerLog . info ( this , localNodeName , senderNodeName , DIRECTION . IN , 
Thread . sleep ( 1000 ) ; 
if ( retry > 1 ) 
if ( task . hasResponse ( ) ) 
sendResponseBack ( iRequest , e ) ; 
if ( database != null && ! database . isClosed ( ) ) { 
if ( ! database . isClosed ( ) ) { 
database . rollback ( ) ; 
database . getLocalCache ( ) . clear ( ) ; 
if ( origin != null ) 
database . setUser ( origin ) ; 
if ( task . hasResponse ( ) ) { 
if ( ! sendResponseBack ( iRequest , responsePayload ) ) { 
handleError ( iRequest , responsePayload ) ; 
} public String printExceptionMessage ( Exception e , String message , String level ) { 
if ( e . getMessage ( ) != null ) 
message += "\n" + e . getClass ( ) . getName ( ) ; 
switch ( level ) { 
case "debug" : 
this . messageHandler . debug ( this , message ) ; 
case "info" : 
this . messageHandler . info ( this , message ) ; 
case "warn" : 
this . messageHandler . warn ( this , message ) ; 
case "error" : 
this . messageHandler . error ( this , message ) ; 
return message ; 
} public String printExceptionStackTrace ( Exception e , String level ) { 
Writer writer = new StringWriter ( ) ; 
e . printStackTrace ( new PrintWriter ( writer ) ) ; 
String s = writer . toString ( ) ; 
this . messageHandler . debug ( this , "\n" + s + "\n" ) ; 
this . messageHandler . info ( this , "\n" + s + "\n" ) ; 
this . messageHandler . warn ( this , "\n" + s + "\n" ) ; 
this . messageHandler . error ( this , "\n" + s + "\n" ) ; 
} public OIndexCursor executeIndexQuery ( OCommandContext iContext , OIndex < ? > index , final List < Object > keyParams , 
boolean ascSortOrder ) { 
} private void convertLink2Record ( final Object iKey ) { 
if ( status == MULTIVALUE_CONTENT_TYPE . ALL_RECORDS ) 
if ( iKey instanceof ORID ) 
value = iKey ; 
value = super . get ( iKey ) ; 
if ( value != null && value instanceof ORID ) { 
final ORID rid = ( ORID ) value ; 
marshalling = true ; 
ORecord record = rid . getRecord ( ) ; 
ORecordInternal . unTrack ( sourceRecord , rid ) ; 
ORecordInternal . track ( sourceRecord , record ) ; 
super . put ( iKey , record ) ; 
} catch ( ORecordNotFoundException ignore ) { 
marshalling = false ; 
public void serializeInByteBufferObject ( Boolean object , ByteBuffer buffer , Object ... hints ) { 
buffer . put ( object . booleanValue ( ) ? ( byte ) 1 : ( byte ) 0 ) ; 
public Boolean deserializeFromByteBufferObject ( ByteBuffer buffer , OWALChanges walChanges , int offset ) { 
return walChanges . getByteValue ( buffer , offset ) > 0 ; 
} public void registerCommand ( final OServerCommand iServerCommandInstance ) { 
for ( String name : iServerCommandInstance . getNames ( ) ) 
if ( OStringSerializerHelper . contains ( name , '{' ) ) { 
restCommands . put ( name , iServerCommandInstance ) ; 
} else if ( OStringSerializerHelper . contains ( name , '*' ) ) 
wildcardCommands . put ( name , iServerCommandInstance ) ; 
exactCommands . put ( name , iServerCommandInstance ) ; 
iServerCommandInstance . configure ( server ) ; 
if ( jsonConfig . containsField ( "users" ) ) { 
List < ODocument > usersList = jsonConfig . field ( "users" ) ; 
for ( ODocument userDoc : usersList ) { 
OServerUserConfiguration userCfg = createServerUser ( userDoc ) ; 
String checkName = userCfg . name ; 
if ( ! isCaseSensitive ( ) ) checkName = checkName . toLowerCase ( Locale . ENGLISH ) ; 
usersMap . put ( checkName , userCfg ) ; 
} protected OServerUserConfiguration createServerUser ( final ODocument userDoc ) { 
if ( userDoc . containsField ( "username" ) && userDoc . containsField ( "resources" ) ) { 
final String user = userDoc . field ( "username" ) ; 
final String resources = userDoc . field ( "resources" ) ; 
String password = userDoc . field ( "password" ) ; 
if ( password == null ) password = "" ; 
userCfg = new OServerUserConfiguration ( user , password , resources ) ; 
OServerUserConfiguration user = getUser ( username ) ; 
if ( isPasswordValid ( user ) ) { 
if ( OSecurityManager . instance ( ) . checkPassword ( password , user . password ) ) { 
principal = user . name ; 
OLogManager . instance ( ) . error ( this , "ODefaultPasswordAuthenticator.authenticate()" , ex ) ; 
OServerUserConfiguration userCfg = getUser ( username ) ; 
synchronized ( usersMap ) { 
if ( username != null ) { 
String checkName = username ; 
if ( ! isCaseSensitive ( ) ) 
checkName = username . toLowerCase ( Locale . ENGLISH ) ; 
if ( usersMap . containsKey ( checkName ) ) { 
userCfg = usersMap . get ( checkName ) ; 
} public List < OIndexSearchResult > analyzeCondition ( OSQLFilterCondition condition , final OClass schemaClass , 
OCommandContext context ) { 
final List < OIndexSearchResult > indexSearchResults = new ArrayList < OIndexSearchResult > ( ) ; 
OIndexSearchResult lastCondition = analyzeFilterBranch ( schemaClass , condition , indexSearchResults , context ) ; 
if ( indexSearchResults . isEmpty ( ) && lastCondition != null ) { 
indexSearchResults . add ( lastCondition ) ; 
Collections . sort ( indexSearchResults , new Comparator < OIndexSearchResult > ( ) { 
public int compare ( final OIndexSearchResult searchResultOne , final OIndexSearchResult searchResultTwo ) { 
return searchResultTwo . getFieldCount ( ) - searchResultOne . getFieldCount ( ) ; 
return indexSearchResults ; 
} private OIndexSearchResult createIndexedProperty ( final OSQLFilterCondition iCondition , final Object iItem , OCommandContext ctx ) { 
if ( iItem == null || ! ( iItem instanceof OSQLFilterItemField ) ) { 
if ( iCondition . getLeft ( ) instanceof OSQLFilterItemField && iCondition . getRight ( ) instanceof OSQLFilterItemField ) { 
final OSQLFilterItemField item = ( OSQLFilterItemField ) iItem ; 
if ( item . hasChainOperators ( ) && ! item . isFieldChain ( ) ) { 
boolean inverted = iCondition . getRight ( ) == iItem ; 
final Object origValue = inverted ? iCondition . getLeft ( ) : iCondition . getRight ( ) ; 
OQueryOperator operator = iCondition . getOperator ( ) ; 
if ( inverted ) { 
if ( operator instanceof OQueryOperatorIn ) { 
operator = new OQueryOperatorContains ( ) ; 
} else if ( operator instanceof OQueryOperatorContains ) { 
operator = new OQueryOperatorIn ( ) ; 
} else if ( operator instanceof OQueryOperatorMajor ) { 
operator = new OQueryOperatorMinor ( ) ; 
} else if ( operator instanceof OQueryOperatorMinor ) { 
operator = new OQueryOperatorMajor ( ) ; 
} else if ( operator instanceof OQueryOperatorMajorEquals ) { 
operator = new OQueryOperatorMinorEquals ( ) ; 
} else if ( operator instanceof OQueryOperatorMinorEquals ) { 
operator = new OQueryOperatorMajorEquals ( ) ; 
if ( iCondition . getOperator ( ) instanceof OQueryOperatorBetween || operator instanceof OQueryOperatorIn ) { 
return new OIndexSearchResult ( operator , item . getFieldChain ( ) , origValue ) ; 
final Object value = OSQLHelper . getValue ( origValue , null , ctx ) ; 
return new OIndexSearchResult ( operator , item . getFieldChain ( ) , value ) ; 
} public void detach ( final Object self , final boolean nonProxiedInstance ) 
throws NoSuchMethodException , IllegalAccessException , InvocationTargetException { 
final Class < ? > selfClass = self . getClass ( ) ; 
Object value = getValue ( self , fieldName , false , null , true ) ; 
if ( value instanceof OObjectLazyMultivalueElement ) { 
( ( OObjectLazyMultivalueElement < ? > ) value ) . detach ( nonProxiedInstance ) ; 
if ( nonProxiedInstance ) 
value = ( ( OObjectLazyMultivalueElement < ? > ) value ) . getNonOrientInstance ( ) ; 
OObjectEntitySerializer . setFieldValue ( OObjectEntitySerializer . getField ( fieldName , selfClass ) , self , value ) ; 
OObjectEntitySerializer . setIdField ( selfClass , self , doc . getIdentity ( ) ) ; 
OObjectEntitySerializer . setVersionField ( selfClass , self , doc . getVersion ( ) ) ; 
} public void detachAll ( final Object self , final boolean nonProxiedInstance , final Map < Object , Object > alreadyDetached , 
final Map < Object , Object > lazyObjects ) throws NoSuchMethodException , IllegalAccessException , InvocationTargetException { 
final Field field = OObjectEntitySerializer . getField ( fieldName , selfClass ) ; 
if ( field != null ) { 
( ( OObjectLazyMultivalueElement < ? > ) value ) . detachAll ( nonProxiedInstance , alreadyDetached , lazyObjects ) ; 
} else if ( value instanceof Proxy ) { 
OObjectProxyMethodHandler handler = ( OObjectProxyMethodHandler ) ( ( ProxyObject ) value ) . getHandler ( ) ; 
if ( nonProxiedInstance ) { 
value = OObjectEntitySerializer . getNonProxiedInstance ( value ) ; 
if ( OObjectEntitySerializer . isFetchLazyField ( self . getClass ( ) , fieldName ) ) { 
Object lazyValue = lazyObjects . get ( handler . doc . getIdentity ( ) ) ; 
if ( lazyValue != null ) { 
value = lazyValue ; 
OObjectEntitySerializer . setIdField ( field . getType ( ) , value , handler . doc . getIdentity ( ) ) ; 
lazyObjects . put ( handler . doc . getIdentity ( ) , value ) ; 
Object detachedValue = alreadyDetached . get ( handler . doc . getIdentity ( ) ) ; 
if ( detachedValue != null ) { 
value = detachedValue ; 
ORID identity = handler . doc . getIdentity ( ) ; 
if ( identity . isValid ( ) ) 
alreadyDetached . put ( identity , value ) ; 
handler . detachAll ( value , nonProxiedInstance , alreadyDetached , lazyObjects ) ; 
} else if ( value instanceof OTrackedMap && nonProxiedInstance ) { 
Map newValue = new LinkedHashMap < > ( ) ; 
newValue . putAll ( ( Map ) value ) ; 
value = newValue ; 
} else if ( value instanceof OTrackedList && nonProxiedInstance ) { 
List newValue = new ArrayList ( ) ; 
newValue . addAll ( ( Collection ) value ) ; 
} else if ( value instanceof OTrackedSet && nonProxiedInstance ) { 
Set newValue = new LinkedHashSet ( ) ; 
OObjectEntitySerializer . setFieldValue ( field , self , value ) ; 
} public void attach ( final Object self ) 
throws IllegalArgumentException , IllegalAccessException , NoSuchMethodException , InvocationTargetException { 
for ( Class < ? > currentClass = self . getClass ( ) ; currentClass != Object . class ; ) { 
if ( Proxy . class . isAssignableFrom ( currentClass ) ) { 
for ( Field f : currentClass . getDeclaredFields ( ) ) { 
final String fieldName = f . getName ( ) ; 
final Class < ? > declaringClass = f . getDeclaringClass ( ) ; 
if ( OObjectEntitySerializer . isTransientField ( declaringClass , fieldName ) || OObjectEntitySerializer 
. isVersionField ( declaringClass , fieldName ) || OObjectEntitySerializer . isIdField ( declaringClass , fieldName ) ) 
Object value = OObjectEntitySerializer . getFieldValue ( f , self ) ; 
value = setValue ( self , fieldName , value ) ; 
OObjectEntitySerializer . setFieldValue ( f , self , value ) ; 
} private String [ ] calculateProperties ( OCommandContext ctx ) { 
if ( propertyList == null ) { 
return propertyList . stream ( ) . map ( x -> x . getCompleteKey ( ) ) . collect ( Collectors . toList ( ) ) . toArray ( new String [ ] { } ) ; 
} private OClass getIndexClass ( OCommandContext ctx ) { 
if ( className == null ) { 
OClass result = ctx . getDatabase ( ) . getMetadata ( ) . getSchema ( ) . getClass ( className . getStringValue ( ) ) ; 
} private ODocument calculateMetadata ( OCommandContext ctx ) { 
if ( metadata == null ) { 
return metadata . toDocument ( null , ctx ) ; 
} protected long nextWithNewCurrentValue ( long currentValue , boolean executeViaDistributed ) 
throws OSequenceLimitReachedException , ODatabaseException { 
if ( ! executeViaDistributed ) { 
cacheStart = currentValue ; 
return nextWork ( ) ; 
return sendSequenceActionSetAndNext ( currentValue ) ; 
catch ( InterruptedException | ExecutionException exc ) { 
} public Iterable < OTransactionIndexEntry > interpret ( Interpretation interpretation ) { 
switch ( interpretation ) { 
case Unique : 
return interpretAsUnique ( ) ; 
case Dictionary : 
return interpretAsDictionary ( ) ; 
case NonUnique : 
return interpretAsNonUnique ( ) ; 
txAlreadyBegun = db . getTransaction ( ) . isActive ( ) ; 
final OEdge e = toEdge ( rid ) ; 
e . delete ( ) ; 
final Set < OEdge > edges = new HashSet < OEdge > ( ) ; 
fromIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , fromExpr , context , iArgs ) ; 
toIds = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , toExpr , context , iArgs ) ; 
label = "E" ; 
final OVertex v = toVertex ( fromId ) ; 
fromCount += count ( v . getEdges ( ODirection . OUT , label ) ) ; 
final OVertex v = toVertex ( toId ) ; 
toCount += count ( v . getEdges ( ODirection . IN , label ) ) ; 
for ( OEdge e : v . getEdges ( ODirection . OUT , label ) ) { 
final OIdentifiable inV = ( ( OEdge ) e ) . getTo ( ) ; 
edges . add ( e ) ; 
for ( OEdge e : v . getEdges ( ODirection . IN , label ) ) { 
final OIdentifiable outV = ( ( OEdge ) e ) . getFrom ( ) ; 
for ( Iterator < OEdge > it = edges . iterator ( ) ; it . hasNext ( ) ; ) { 
final OEdge edge = it . next ( ) ; 
for ( OEdge edge : edges ) 
edge . delete ( ) ; 
final OEdge e = toEdge ( id ) ; 
getDatabase ( ) . begin ( ) ; 
} public void truncate ( ) throws IOException { 
db . checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_UPDATE ) ; 
if ( isSubClassOf ( OSecurityShared . RESTRICTED_CLASSNAME ) ) { 
throw new OSecurityException ( 
+ OSecurityShared . RESTRICTED_CLASSNAME + "')" ) ; 
for ( int id : clusterIds ) { 
OCluster cl = storage . getClusterById ( id ) ; 
db . checkForClusterPermissions ( cl . getName ( ) ) ; 
cl . truncate ( ) ; 
for ( OIndex < ? > index : getClassIndexes ( ) ) 
index . clear ( ) ; 
Set < OIndex < ? > > superclassIndexes = new HashSet < OIndex < ? > > ( ) ; 
superclassIndexes . addAll ( getIndexes ( ) ) ; 
superclassIndexes . removeAll ( getClassIndexes ( ) ) ; 
for ( OIndex index : superclassIndexes ) { 
index . rebuild ( ) ; 
} public boolean isSubClassOf ( final String iClassName ) { 
if ( iClassName . equalsIgnoreCase ( getName ( ) ) || iClassName . equalsIgnoreCase ( getShortName ( ) ) ) 
for ( OClassImpl superClass : superClasses ) { 
if ( superClass . isSubClassOf ( iClassName ) ) 
} public boolean isSubClassOf ( final OClass clazz ) { 
if ( equals ( clazz ) ) 
if ( superClass . isSubClassOf ( clazz ) ) 
} protected OClass addBaseClass ( final OClassImpl iBaseClass ) { 
checkRecursion ( iBaseClass ) ; 
if ( subclasses == null ) 
subclasses = new ArrayList < OClass > ( ) ; 
if ( subclasses . contains ( iBaseClass ) ) 
subclasses . add ( iBaseClass ) ; 
addPolymorphicClusterIdsWithInheritance ( iBaseClass ) ; 
} protected void addPolymorphicClusterIds ( final OClassImpl iBaseClass ) { 
Set < Integer > clusters = new TreeSet < Integer > ( ) ; 
for ( int clusterId : polymorphicClusterIds ) { 
clusters . add ( clusterId ) ; 
for ( int clusterId : iBaseClass . polymorphicClusterIds ) { 
if ( clusters . add ( clusterId ) ) { 
addClusterIdToIndexes ( clusterId ) ; 
clusters . remove ( clusterId ) ; 
polymorphicClusterIds = new int [ clusters . size ( ) ] ; 
for ( Integer cluster : clusters ) { 
polymorphicClusterIds [ i ] = cluster ; 
public Object evaluateRecord ( OIdentifiable iRecord , ODocument iCurrentResult , OSQLFilterCondition iCondition , Object iLeft , 
Object iRight , OCommandContext iContext , final ODocumentSerializer serializer ) { 
OSQLFunction function = OSQLEngine . getInstance ( ) . getFunction ( keyword ) ; 
return function . execute ( this , iRecord , iCurrentResult , new Object [ ] { iLeft , iCondition . getRight ( ) } , iContext ) ; 
} private static OIdentifiable linkToStream ( final StringBuilder buffer , final ODocument iParentRecord , Object iLinked ) { 
if ( iLinked == null ) 
OIdentifiable resultRid = null ; 
if ( iLinked instanceof ORID ) { 
rid = ( ORID ) iLinked ; 
assert rid . getIdentity ( ) . isValid ( ) || ( ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getStorage ( ) instanceof OStorageProxy ) : 
resultRid = rid ; 
if ( iLinked instanceof String ) 
iLinked = new ORecordId ( ( String ) iLinked ) ; 
if ( ! ( iLinked instanceof OIdentifiable ) ) 
+ iLinked ) ; 
ORecord iLinkedRecord = ( ( OIdentifiable ) iLinked ) . getRecord ( ) ; 
rid = iLinkedRecord . getIdentity ( ) ; 
final ODatabaseDocument database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; 
if ( iParentRecord != null ) { 
if ( ! database . isRetainRecords ( ) ) 
resultRid = iLinkedRecord . getIdentity ( ) ; 
rid . toString ( buffer ) ; 
return resultRid ; 
} public static SortField buildSortField ( Map < String , Object > conf ) { 
final String field = Optional . ofNullable ( ( String ) conf . get ( "field" ) ) . orElse ( null ) ; 
final String type = Optional . ofNullable ( ( ( String ) conf . get ( "type" ) ) . toUpperCase ( ) ) . orElse ( SortField . Type . STRING . name ( ) ) ; 
final Boolean reverse = Optional . ofNullable ( ( Boolean ) conf . get ( "reverse" ) ) . orElse ( false ) ; 
SortField sortField = new SortField ( field , SortField . Type . valueOf ( type ) , reverse ) ; 
return sortField ; 
} public int fromInputStream ( final InputStream in ) throws IOException { 
final OMemoryStream out = new OMemoryStream ( ) ; 
final byte [ ] buffer = new byte [ OMemoryStream . DEF_SIZE ] ; 
int readBytesCount ; 
readBytesCount = in . read ( buffer , 0 , buffer . length ) ; 
if ( readBytesCount == - 1 ) { 
out . write ( buffer , 0 , readBytesCount ) ; 
_source = out . toByteArray ( ) ; 
_size = _source . length ; 
return _size ; 
} public int fromInputStream ( final InputStream in , final int maxSize ) throws IOException { 
final byte [ ] buffer = new byte [ maxSize ] ; 
int totalBytesCount = 0 ; 
while ( totalBytesCount < maxSize ) { 
readBytesCount = in . read ( buffer , totalBytesCount , buffer . length - totalBytesCount ) ; 
totalBytesCount += readBytesCount ; 
if ( totalBytesCount == 0 ) { 
_source = EMPTY_SOURCE ; 
_size = 0 ; 
} else if ( totalBytesCount == maxSize ) { 
_source = buffer ; 
_size = maxSize ; 
_source = Arrays . copyOf ( buffer , totalBytesCount ) ; 
_size = totalBytesCount ; 
} public final OPointer acquireDirect ( boolean clear ) { 
OPointer pointer ; 
pointer = pointersPool . poll ( ) ; 
if ( pointer != null ) { 
pointersPoolSize . decrementAndGet ( ) ; 
pointer = allocator . allocate ( pageSize , - 1 ) ; 
if ( clear ) { 
pointer . clear ( ) ; 
final ByteBuffer buffer = pointer . getNativeByteBuffer ( ) ; 
if ( TRACK ) { 
pointerMapping . put ( pointer , generatePointer ( ) ) ; 
return pointer ; 
} public final void release ( OPointer pointer ) { 
pointerMapping . remove ( pointer ) ; 
long poolSize = pointersPoolSize . incrementAndGet ( ) ; 
if ( poolSize > this . poolSize ) { 
allocator . deallocate ( pointer ) ; 
pointersPool . add ( pointer ) ; 
} public void checkMemoryLeaks ( ) { 
boolean detected = false ; 
for ( Map . Entry < OPointer , PointerTracker > entry : pointerMapping . entrySet ( ) ) { 
System . identityHashCode ( entry . getKey ( ) ) ) ; 
detected = true ; 
assert ! detected ; 
for ( OPointer pointer : pointersPool ) { 
pointersPool . clear ( ) ; 
pointersPoolSize . set ( 0 ) ; 
for ( OPointer pointer : pointerMapping . keySet ( ) ) { 
pointerMapping . clear ( ) ; 
} public static int bytes2int ( final byte [ ] b , final int offset ) { 
return ( b [ offset ] ) << 24 | ( 0xff & b [ offset + 1 ] ) << 16 | ( 0xff & b [ offset + 2 ] ) << 8 | ( ( 0xff & b [ offset + 3 ] ) ) ; 
} public static PersistenceUnitInfo findPersistenceUnit ( String unitName , Collection < ? extends PersistenceUnitInfo > units ) { 
if ( units == null || unitName == null ) { 
for ( PersistenceUnitInfo unit : units ) { 
if ( unitName . equals ( unit . getPersistenceUnitName ( ) ) ) { 
return unit ; 
} public static Collection < ? extends PersistenceUnitInfo > parse ( URL persistenceXml ) { 
InputStream is = null ; 
is = new BufferedInputStream ( persistenceXml . openStream ( ) ) ; 
JPAVersion jpaVersion = getSchemaVersion ( is ) ; 
Schema schema = getSchema ( jpaVersion ) ; 
parserFactory . setNamespaceAware ( true ) ; 
int endIndex = persistenceXml . getPath ( ) . length ( ) - PERSISTENCE_XML_BASE_NAME . length ( ) ; 
URL persistenceXmlRoot = new URL ( "file://" + persistenceXml . getFile ( ) . substring ( 0 , endIndex ) ) ; 
return getPersistenceUnits ( is , persistenceXmlRoot , jpaVersion ) ; 
is . close ( ) ; 
public void startElement ( String uri , String localName , String name , Attributes attributes ) throws SAXException { 
PersistenceXml element = PersistenceXml . parse ( ( localName == null || localName . isEmpty ( ) ) ? name : localName ) ; 
schemaVersion = PersistenceXmlUtil . parseSchemaVersion ( uri , element , attributes ) ; 
if ( schemaVersion != null ) { 
throw new StopSAXParser ( ) ; 
if ( TAG_PERSISTENCE != element && EnumSet . allOf ( PersistenceXml . class ) . contains ( element ) ) { 
} public static void writeUnsignedVarLong ( long value , final BytesContainer bos ) { 
int pos ; 
while ( ( value & 0xFFFFFFFFFFFFFF80L ) != 0L ) { 
pos = bos . alloc ( ( short ) 1 ) ; 
bos . bytes [ pos ] = ( byte ) ( value & 0x7F | 0x80 ) ; 
value >>>= 7 ; 
bos . bytes [ pos ] = ( byte ) ( value & 0x7F ) ; 
} public static long readSignedVarLong ( final BytesContainer bytes ) { 
final long raw = readUnsignedVarLong ( bytes ) ; 
final long temp = ( ( ( raw << 63 ) > > 63 ) ^ raw ) > > 1 ; 
return temp ^ ( raw & ( 1L << 63 ) ) ; 
} public static long readUnsignedVarLong ( final BytesContainer bytes ) { 
long value = 0L ; 
long b ; 
while ( ( ( b = bytes . bytes [ bytes . offset ++ ] ) & 0x80L ) != 0 ) { 
value |= ( b & 0x7F ) << i ; 
i += 7 ; 
if ( i > 63 ) 
return value | ( b << i ) ; 
public void onOpen ( final ODatabaseInternal iDatabase ) { 
if ( ! isRelatedToLocalServer ( iDatabase ) ) 
if ( isOffline ( ) && status != NODE_STATUS . STARTING ) 
final ODatabaseDocumentInternal currDb = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; 
final String dbName = iDatabase . getName ( ) ; 
final ODistributedConfiguration cfg = getDatabaseConfiguration ( dbName ) ; 
} catch ( HazelcastException e ) { 
} catch ( HazelcastInstanceNotActiveException e ) { 
ODatabaseRecordThreadLocal . instance ( ) . set ( currDb ) ; 
OSyncReceiver receiver = new OSyncReceiver ( this , databaseName , firstChunk , momentum , iNode , dbPath ) ; 
final ODatabaseDocumentInternal db = installDatabaseOnLocalNode ( databaseName , dbPath , iNode , delta , 
uniqueClustersBackupDirectory , cfg , firstChunk . incremental , receiver ) ; 
final Set < String > localManagedClusters = cfg . getClustersOnServer ( localNodeName ) ; 
final Set < String > sourceNodeClusters = cfg . getClustersOnServer ( iNode ) ; 
localManagedClusters . removeAll ( sourceNodeClusters ) ; 
final HashSet < String > toSynchClusters = new HashSet < String > ( ) ; 
for ( String cl : localManagedClusters ) { 
final List < String > servers = cfg . getServers ( cl , localNodeName ) ; 
getAvailableNodes ( servers , databaseName ) ; 
if ( ! servers . isEmpty ( ) ) 
toSynchClusters . add ( cl ) ; 
for ( String cl : toSynchClusters ) { 
OCommandExecutorSQLHASyncCluster . replaceCluster ( this , serverInstance , databaseName , cl ) ; 
} public boolean installClustersOfClass ( final ODatabaseInternal iDatabase , final OClass iClass , 
OModifiableDistributedConfiguration cfg ) { 
final String databaseName = iDatabase . getName ( ) ; 
if ( iClass . isAbstract ( ) ) 
getMessageService ( ) . registerDatabase ( databaseName , cfg ) ; 
return executeInDistributedDatabaseLock ( databaseName , 20000 , cfg , 
new OCallable < Boolean , OModifiableDistributedConfiguration > ( ) { 
public Boolean call ( final OModifiableDistributedConfiguration lastCfg ) { 
final Set < String > availableNodes = getAvailableNodeNames ( iDatabase . getName ( ) ) ; 
final List < String > cluster2Create = clusterAssignmentStrategy 
. assignClusterOwnershipOfClass ( iDatabase , lastCfg , iClass , availableNodes , true ) ; 
final Map < OClass , List < String > > cluster2CreateMap = new HashMap < OClass , List < String > > ( 1 ) ; 
cluster2CreateMap . put ( iClass , cluster2Create ) ; 
createClusters ( iDatabase , cluster2CreateMap , lastCfg ) ; 
} public < T > T executeInDistributedDatabaseLock ( final String databaseName , final long timeoutLocking , 
OModifiableDistributedConfiguration lastCfg , final OCallable < T , OModifiableDistributedConfiguration > iCallback ) { 
boolean updated ; 
T result ; 
lockManagerRequester . acquireExclusiveLock ( databaseName , nodeName , timeoutLocking ) ; 
if ( lastCfg == null ) 
lastCfg = getDatabaseConfiguration ( databaseName ) . modify ( ) ; 
lastCfg . getDocument ( ) . toJSON ( ) ) ; 
result = iCallback . call ( lastCfg ) ; 
updated = updateCachedDatabaseConfiguration ( databaseName , lastCfg , true ) ; 
lockManagerRequester . releaseExclusiveLock ( databaseName , nodeName ) ; 
notifyClients ( databaseName ) ; 
serverInstance . getClientConnectionManager ( ) . pushDistribCfg2Clients ( getClusterConfiguration ( ) ) ; 
} protected void dumpServersStatus ( ) { 
final ODocument cfg = getClusterConfiguration ( ) ; 
final String compactStatus = ODistributedOutput . getCompactServerStatus ( this , cfg ) ; 
if ( ! lastServerDump . equals ( compactStatus ) ) { 
lastServerDump = compactStatus ; 
getLockManagerServer ( ) , ODistributedOutput . formatServerStatus ( this , cfg ) ) ; 
} public static < T > int indexOf ( final List < T > list , final T object , final Comparator < T > comparator ) { 
for ( final T item : list ) { 
if ( comparator . compare ( item , object ) == 0 ) 
} public static int indexOf ( final Object [ ] array , final Comparable object ) { 
for ( int i = 0 ; i < array . length ; ++ i ) { 
if ( object . compareTo ( array [ i ] ) == 0 ) 
} public static int indexOf ( final int [ ] array , final int object ) { 
if ( array [ i ] == object ) 
} public OCommandExecutorSQLSelect parse ( final OCommandRequest iRequest ) { 
initContext ( ) ; 
final int pos = parseProjections ( ) ; 
if ( pos == - 1 ) { 
final int endPosition = parserText . length ( ) ; 
if ( parserGetLastWord ( ) . equalsIgnoreCase ( KEYWORD_FROM ) ) { 
parsedTarget = OSQLEngine . getInstance ( ) 
. parseTarget ( parserText . substring ( parserGetCurrentPosition ( ) , endPosition ) , getContext ( ) ) ; 
parserSetCurrentPosition ( 
parsedTarget . parserIsEnded ( ) ? endPosition : parsedTarget . parserGetCurrentPosition ( ) + parserGetCurrentPosition ( ) ) ; 
final String w = parserNextWord ( true ) ; 
if ( ! w . isEmpty ( ) ) { 
if ( w . equals ( KEYWORD_WHERE ) ) { 
compiledFilter = OSQLEngine . getInstance ( ) 
. parseCondition ( parserText . substring ( parserGetCurrentPosition ( ) , endPosition ) , getContext ( ) , KEYWORD_WHERE ) ; 
parserSetCurrentPosition ( compiledFilter . parserIsEnded ( ) ? 
endPosition : 
compiledFilter . parserGetCurrentPosition ( ) + parserGetCurrentPosition ( ) ) ; 
} else if ( w . equals ( KEYWORD_LET ) ) { 
parseLet ( ) ; 
} else if ( w . equals ( KEYWORD_GROUP ) ) { 
parseGroupBy ( ) ; 
} else if ( w . equals ( KEYWORD_ORDER ) ) { 
parseOrderBy ( ) ; 
} else if ( w . equals ( KEYWORD_UNWIND ) ) { 
parseUnwind ( ) ; 
} else if ( w . equals ( KEYWORD_LIMIT ) ) { 
} else if ( w . equals ( KEYWORD_SKIP ) || w . equals ( KEYWORD_OFFSET ) ) { 
} else if ( w . equals ( KEYWORD_FETCHPLAN ) ) { 
parseFetchplan ( w ) ; 
} else if ( w . equals ( KEYWORD_NOCACHE ) ) { 
parseNoCache ( w ) ; 
} else if ( w . equals ( KEYWORD_TIMEOUT ) ) { 
} else if ( w . equals ( KEYWORD_LOCK ) ) { 
final String lock = parseLock ( ) ; 
if ( lock . equalsIgnoreCase ( "DEFAULT" ) ) { 
lockingStrategy = LOCKING_STRATEGY . DEFAULT ; 
} else if ( lock . equals ( "NONE" ) ) { 
lockingStrategy = LOCKING_STRATEGY . NONE ; 
} else if ( lock . equals ( "RECORD" ) ) { 
lockingStrategy = LOCKING_STRATEGY . EXCLUSIVE_LOCK ; 
} else if ( lock . equals ( "SHARED" ) ) { 
lockingStrategy = LOCKING_STRATEGY . SHARED_LOCK ; 
} else if ( w . equals ( KEYWORD_PARALLEL ) ) { 
parallel = parseParallel ( w ) ; 
if ( preParsedStatement == null ) { 
if ( limit == 0 || limit < - 1 ) { 
validateQuery ( ) ; 
public Set < String > getInvolvedClusters ( ) { 
if ( parsedTarget != null ) { 
final ODatabaseDocument db = getDatabase ( ) ; 
if ( parsedTarget . getTargetQuery ( ) != null && parsedTarget 
. getTargetRecords ( ) instanceof OCommandExecutorSQLResultsetDelegate ) { 
final Set < String > clIds = ( ( OCommandExecutorSQLResultsetDelegate ) parsedTarget . getTargetRecords ( ) ) . getInvolvedClusters ( ) ; 
for ( String c : clIds ) { 
if ( checkClusterAccess ( db , c ) ) { 
clusters . add ( c ) ; 
} else if ( parsedTarget . getTargetRecords ( ) != null ) { 
for ( OIdentifiable identifiable : parsedTarget . getTargetRecords ( ) ) { 
final String c = db . getClusterNameById ( identifiable . getIdentity ( ) . getClusterId ( ) ) . toLowerCase ( Locale . ENGLISH ) ; 
if ( parsedTarget . getTargetClasses ( ) != null ) { 
return getInvolvedClustersOfClasses ( parsedTarget . getTargetClasses ( ) . values ( ) ) ; 
if ( parsedTarget . getTargetClusters ( ) != null ) { 
return getInvolvedClustersOfClusters ( parsedTarget . getTargetClusters ( ) . keySet ( ) ) ; 
if ( parsedTarget . getTargetIndex ( ) != null ) { 
return getInvolvedClustersOfIndex ( parsedTarget . getTargetIndex ( ) ) ; 
protected boolean handleResult ( final OIdentifiable iRecord , final OCommandContext iContext ) { 
lastRecord = iRecord ; 
if ( ( orderedFields . isEmpty ( ) || fullySortedByIndex || isRidOnlySort ( ) ) && skip > 0 && this . unwindFields == null 
&& this . expandTarget == null ) { 
lastRecord = null ; 
skip -- ; 
if ( ! addResult ( lastRecord , iContext ) ) { 
return continueSearching ( ) ; 
} public int getTemporaryRIDCounter ( final OCommandContext iContext ) { 
final OTemporaryRidGenerator parentQuery = ( OTemporaryRidGenerator ) iContext . getVariable ( "parentQuery" ) ; 
return parentQuery != null && parentQuery != this ? 
parentQuery . getTemporaryRIDCounter ( iContext ) : 
serialTempRID . getAndIncrement ( ) ; 
} private void applyPartialOrderBy ( ) { 
if ( expandTarget != null || ( unwindFields != null && unwindFields . size ( ) > 0 ) || orderedFields . isEmpty ( ) || fullySortedByIndex 
|| isRidOnlySort ( ) ) { 
if ( limit > 0 ) { 
int sortBufferSize = limit + 1 ; 
if ( skip > 0 ) { 
sortBufferSize += skip ; 
if ( tempResult instanceof List && ( ( List ) tempResult ) . size ( ) >= sortBufferSize + PARTIAL_SORT_BUFFER_THRESHOLD ) { 
applyOrderBy ( false ) ; 
tempResult = new ArrayList ( ( ( List ) tempResult ) . subList ( 0 , sortBufferSize ) ) ; 
} protected void reportTip ( final String iMessage ) { 
Orient . instance ( ) . getProfiler ( ) . reportTip ( iMessage ) ; 
List < String > tips = ( List < String > ) context . getVariable ( "tips" ) ; 
if ( tips == null ) { 
tips = new ArrayList < String > ( 3 ) ; 
context . setVariable ( "tips" , tips ) ; 
tips . add ( iMessage ) ; 
} protected boolean parseFetchplan ( final String w ) throws OCommandSQLParsingException { 
if ( ! w . equals ( KEYWORD_FETCHPLAN ) ) { 
int start = parserGetCurrentPosition ( ) ; 
int end = parserGetCurrentPosition ( ) ; 
int position = parserGetCurrentPosition ( ) ; 
final String word = OIOUtils . getStringContent ( parserNextWord ( true ) ) ; 
if ( ! OPatternConst . PATTERN_FETCH_PLAN . matcher ( word ) . matches ( ) ) { 
end = parserGetCurrentPosition ( ) ; 
position = parserGetCurrentPosition ( ) ; 
parserSetCurrentPosition ( position ) ; 
if ( end < 0 ) { 
fetchPlan = OIOUtils . getStringContent ( parserText . substring ( start ) ) ; 
fetchPlan = OIOUtils . getStringContent ( parserText . substring ( start , end ) ) ; 
request . setFetchPlan ( fetchPlan ) ; 
} protected boolean parseNoCache ( final String w ) throws OCommandSQLParsingException { 
if ( ! w . equals ( KEYWORD_NOCACHE ) ) 
noCache = true ; 
} private boolean optimizeSort ( OClass iSchemaClass ) { 
OIndexCursor cursor = getOptimizedSortCursor ( iSchemaClass ) ; 
if ( cursor != null ) { 
fetchValuesFromIndexCursor ( cursor ) ; 
} private void applyExpand ( ) { 
if ( expandTarget == null ) { 
final long startExpand = System . currentTimeMillis ( ) ; 
if ( tempResult == null ) { 
tempResult = new ArrayList < OIdentifiable > ( ) ; 
if ( expandTarget instanceof OSQLFilterItemVariable ) { 
Object r = ( ( OSQLFilterItemVariable ) expandTarget ) . getValue ( null , null , context ) ; 
if ( r != null ) { 
if ( r instanceof OIdentifiable ) { 
( ( Collection < OIdentifiable > ) tempResult ) . add ( ( OIdentifiable ) r ) ; 
} else if ( r instanceof Iterator || OMultiValue . isMultiValue ( r ) ) { 
for ( Object o : OMultiValue . getMultiValueIterable ( r ) ) { 
( ( Collection < OIdentifiable > ) tempResult ) . add ( ( OIdentifiable ) o ) ; 
} else if ( expandTarget instanceof OSQLFunctionRuntime && ! hasFieldItemParams ( ( OSQLFunctionRuntime ) expandTarget ) ) { 
if ( ( ( OSQLFunctionRuntime ) expandTarget ) . aggregateResults ( ) ) { 
Object r = ( ( OSQLFunctionRuntime ) expandTarget ) . execute ( null , null , null , context ) ; 
final OMultiCollectionIterator < OIdentifiable > finalResult = new OMultiCollectionIterator < OIdentifiable > ( ) ; 
if ( orderedFields == null || orderedFields . size ( ) == 0 ) { 
int iteratorLimit = 0 ; 
if ( limit < 0 ) { 
iteratorLimit = - 1 ; 
iteratorLimit += limit ; 
finalResult . setLimit ( iteratorLimit ) ; 
finalResult . setSkip ( skip ) ; 
for ( OIdentifiable id : tempResult ) { 
if ( expandTarget instanceof OSQLFilterItem ) { 
fieldValue = ( ( OSQLFilterItem ) expandTarget ) . getValue ( id . getRecord ( ) , null , context ) ; 
} else if ( expandTarget instanceof OSQLFunctionRuntime ) { 
fieldValue = ( ( OSQLFunctionRuntime ) expandTarget ) . getResult ( ) ; 
fieldValue = expandTarget . toString ( ) ; 
if ( fieldValue instanceof Iterable && ! ( fieldValue instanceof OIdentifiable ) ) { 
fieldValue = ( ( Iterable ) fieldValue ) . iterator ( ) ; 
if ( fieldValue instanceof ODocument ) { 
ArrayList < ODocument > partial = new ArrayList < ODocument > ( ) ; 
partial . add ( ( ODocument ) fieldValue ) ; 
finalResult . add ( partial ) ; 
} else if ( fieldValue instanceof Collection < ? > || fieldValue . getClass ( ) . isArray ( ) || fieldValue instanceof Iterator < ? > 
|| fieldValue instanceof OIdentifiable || fieldValue instanceof ORidBag ) { 
finalResult . add ( fieldValue ) ; 
} else if ( fieldValue instanceof Map < ? , ? > ) { 
finalResult . add ( ( ( Map < ? , OIdentifiable > ) fieldValue ) . values ( ) ) ; 
tempResult = finalResult ; 
context . setVariable ( "expandElapsed" , ( System . currentTimeMillis ( ) - startExpand ) ) ; 
synchronized ( listener ) { 
status . field ( "cfg" , cfg ) ; 
status . field ( "status" , this . status ) ; 
String lastBatchLog = "" ; 
if ( this . messageHandler != null ) { 
lastBatchLog = extractBatchLog ( ) ; 
status . field ( "log" , lastBatchLog ) ; 
if ( this . status == Status . FINISHED ) { 
listener . notifyAll ( ) ; 
public < RET > RET execute ( final Object ... iArgs ) { 
OExecutionThreadLocal . INSTANCE . get ( ) . onAsyncReplicationOk = onAsyncReplicationOk ; 
OExecutionThreadLocal . INSTANCE . get ( ) . onAsyncReplicationError = onAsyncReplicationError ; 
return ( RET ) ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getStorage ( ) . command ( this ) ; 
} public static Object createLink ( final ODocument iFromVertex , final OIdentifiable iTo , final String iFieldName ) { 
final Object out ; 
OType outType = iFromVertex . fieldType ( iFieldName ) ; 
Object found = iFromVertex . field ( iFieldName ) ; 
final OClass linkClass = ODocumentInternal . getImmutableSchemaClass ( iFromVertex ) ; 
if ( linkClass == null ) 
final OProperty prop = linkClass . getProperty ( iFieldName ) ; 
final OType propType = prop != null && prop . getType ( ) != OType . ANY ? prop . getType ( ) : null ; 
if ( found == null ) { 
if ( propType == OType . LINKLIST || ( prop != null && "true" . equalsIgnoreCase ( prop . getCustom ( "ordered" ) ) ) ) { 
final Collection coll = new ORecordLazyList ( iFromVertex ) ; 
coll . add ( iTo ) ; 
out = coll ; 
outType = OType . LINKLIST ; 
} else if ( propType == null || propType == OType . LINKBAG ) { 
final ORidBag bag = new ORidBag ( ) ; 
bag . add ( iTo ) ; 
out = bag ; 
outType = OType . LINKBAG ; 
} else if ( propType == OType . LINK ) { 
out = iTo ; 
outType = OType . LINK ; 
} else if ( found instanceof OIdentifiable ) { 
if ( prop != null && propType == OType . LINK ) 
if ( prop != null && "true" . equalsIgnoreCase ( prop . getCustom ( "ordered" ) ) ) { 
coll . add ( found ) ; 
bag . add ( ( OIdentifiable ) found ) ; 
} else if ( found instanceof ORidBag ) { 
out = null ; 
( ( ORidBag ) found ) . add ( iTo . getRecord ( ) ) ; 
} else if ( found instanceof Collection < ? > ) { 
( ( Collection < Object > ) found ) . add ( iTo ) ; 
if ( out != null ) 
iFromVertex . field ( iFieldName , out , outType ) ; 
return out ; 
} public final void handleJVMError ( final Error e ) { 
if ( jvmError . compareAndSet ( null , e ) ) { 
} public OBackgroundDelta recordsChangedAfterLSN ( final OLogSequenceNumber lsn , final OCommandOutputListener outputListener ) { 
final OLogSequenceNumber endLsn ; 
final SortedSet < ORID > sortedRids = new TreeSet < > ( ) ; 
if ( ! configuration . getContextConfiguration ( ) . getValueAsBoolean ( OGlobalConfiguration . STORAGE_TRACK_CHANGED_RECORDS_IN_WAL ) ) { 
stateLock . acquireReadLock ( ) ; 
if ( writeAheadLog == null ) { 
endLsn = writeAheadLog . end ( ) ; 
if ( endLsn == null || lsn . compareTo ( endLsn ) > 0 ) { 
if ( lsn . equals ( endLsn ) ) { 
return new OBackgroundDelta ( endLsn ) ; 
List < OWriteableWALRecord > records = writeAheadLog . next ( lsn , 1 ) ; 
if ( records . isEmpty ( ) ) { 
final OLogSequenceNumber freezeLsn = records . get ( 0 ) . getLsn ( ) ; 
writeAheadLog . addCutTillLimit ( freezeLsn ) ; 
records = writeAheadLog . next ( lsn , 1_000 ) ; 
long read = 0 ; 
readLoop : 
while ( ! records . isEmpty ( ) ) { 
for ( final OWALRecord record : records ) { 
final OLogSequenceNumber recordLSN = record . getLsn ( ) ; 
if ( endLsn . compareTo ( recordLSN ) >= 0 ) { 
if ( record instanceof OFileCreatedWALRecord ) { 
if ( record instanceof OFileDeletedWALRecord ) { 
. getFileId ( ) ) ; 
if ( record instanceof OAtomicUnitEndRecord ) { 
final OAtomicUnitEndRecord atomicUnitEndRecord = ( OAtomicUnitEndRecord ) record ; 
if ( atomicUnitEndRecord . getAtomicOperationMetadata ( ) . containsKey ( ORecordOperationMetadata . RID_METADATA_KEY ) ) { 
final ORecordOperationMetadata recordOperationMetadata = ( ORecordOperationMetadata ) atomicUnitEndRecord 
. getAtomicOperationMetadata ( ) . get ( ORecordOperationMetadata . RID_METADATA_KEY ) ; 
final Set < ORID > rids = recordOperationMetadata . getValue ( ) ; 
sortedRids . addAll ( rids ) ; 
read ++ ; 
if ( outputListener != null ) { 
break readLoop ; 
records = writeAheadLog . next ( records . get ( records . size ( ) - 1 ) . getLsn ( ) , 1_000 ) ; 
writeAheadLog . removeCutTillLimit ( freezeLsn ) ; 
stateLock . releaseReadLock ( ) ; 
OBackgroundDelta b = new OBackgroundDelta ( this , outputListener , sortedRids , lsn , endLsn ) ; 
throw logAndPrepareForRethrow ( e ) ; 
} catch ( final Error e ) { 
throw logAndPrepareForRethrow ( t ) ; 
} public Set < ORecordId > recordsChangedRecently ( final int maxEntries ) { 
final SortedSet < ORecordId > result = new TreeSet < > ( ) ; 
if ( ! OGlobalConfiguration . STORAGE_TRACK_CHANGED_RECORDS_IN_WAL . getValueAsBoolean ( ) ) { 
OLogSequenceNumber startLsn = writeAheadLog . begin ( ) ; 
if ( startLsn == null ) { 
final OLogSequenceNumber freezeLSN = startLsn ; 
writeAheadLog . addCutTillLimit ( freezeLSN ) ; 
startLsn = writeAheadLog . begin ( ) ; 
final OLogSequenceNumber endLsn = writeAheadLog . end ( ) ; 
if ( endLsn == null ) { 
List < OWriteableWALRecord > walRecords = writeAheadLog . read ( startLsn , 1_000 ) ; 
if ( walRecords . isEmpty ( ) ) { 
final List < OAtomicUnitEndRecord > lastTx = new ArrayList < > ( 1024 ) ; 
while ( ! walRecords . isEmpty ( ) ) { 
for ( final OWriteableWALRecord walRecord : walRecords ) { 
final OLogSequenceNumber recordLSN = walRecord . getLsn ( ) ; 
if ( walRecord instanceof OAtomicUnitEndRecord ) { 
if ( lastTx . size ( ) >= maxEntries ) { 
lastTx . remove ( 0 ) ; 
lastTx . add ( ( OAtomicUnitEndRecord ) walRecord ) ; 
walRecords = writeAheadLog . next ( walRecords . get ( walRecords . size ( ) - 1 ) . getLsn ( ) , 1_000 ) ; 
for ( final OAtomicUnitEndRecord atomicUnitEndRecord : lastTx ) { 
for ( final ORID rid : rids ) { 
result . add ( ( ORecordId ) rid ) ; 
writeAheadLog . removeCutTillLimit ( freezeLSN ) ; 
} public void startGatheringPerformanceStatisticForCurrentThread ( ) { 
performanceStatisticManager . startThreadMonitoring ( ) ; 
} catch ( final RuntimeException ee ) { 
throw logAndPrepareForRethrow ( ee ) ; 
} catch ( final Error ee ) { 
} public OSessionStoragePerformanceStatistic completeGatheringPerformanceStatisticForCurrentThread ( ) { 
return performanceStatisticManager . stopThreadMonitoring ( ) ; 
} public void preallocateRids ( final OTransactionInternal clientTx ) { 
checkLowDiskSpaceRequestsAndReadOnlyConditions ( ) ; 
final Iterable < ORecordOperation > entries = clientTx . getRecordOperations ( ) ; 
final TreeMap < Integer , OCluster > clustersToLock = new TreeMap < > ( ) ; 
final Set < ORecordOperation > newRecords = new TreeSet < > ( COMMIT_RECORD_OPERATION_COMPARATOR ) ; 
for ( final ORecordOperation txEntry : entries ) { 
if ( txEntry . type == ORecordOperation . CREATED ) { 
newRecords . add ( txEntry ) ; 
final int clusterId = txEntry . getRID ( ) . getClusterId ( ) ; 
clustersToLock . put ( clusterId , getClusterById ( clusterId ) ) ; 
makeStorageDirty ( ) ; 
atomicOperationsManager . startAtomicOperation ( ( String ) null , true ) ; 
lockClusters ( clustersToLock ) ; 
for ( final ORecordOperation txEntry : newRecords ) { 
final ORecord rec = txEntry . getRecord ( ) ; 
if ( ! rec . getIdentity ( ) . isPersistent ( ) ) { 
if ( rec . isDirty ( ) ) { 
final ORecordId rid = ( ORecordId ) rec . getIdentity ( ) . copy ( ) ; 
final ORecordId oldRID = rid . copy ( ) ; 
final OCluster cluster = getClusterById ( rid . getClusterId ( ) ) ; 
final OPhysicalPosition ppos = cluster . allocatePosition ( ORecordInternal . getRecordType ( rec ) ) ; 
rid . setClusterPosition ( ppos . clusterPosition ) ; 
clientTx . updateIdentityAfterCommit ( oldRID , rid ) ; 
final ORecordId rid = ( ORecordId ) rec . getIdentity ( ) ; 
final OPaginatedCluster cluster = ( OPaginatedCluster ) getClusterById ( rid . getClusterId ( ) ) ; 
OPaginatedCluster . RECORD_STATUS recordStatus = cluster . getRecordStatus ( rid . getClusterPosition ( ) ) ; 
if ( recordStatus == OPaginatedCluster . RECORD_STATUS . NOT_EXISTENT ) { 
OPhysicalPosition ppos = cluster . allocatePosition ( ORecordInternal . getRecordType ( rec ) ) ; 
while ( ppos . clusterPosition < rid . getClusterPosition ( ) ) { 
ppos = cluster . allocatePosition ( ORecordInternal . getRecordType ( rec ) ) ; 
if ( ppos . clusterPosition != rid . getClusterPosition ( ) ) { 
throw new OConcurrentCreateException ( rid , new ORecordId ( rid . getClusterId ( ) , ppos . clusterPosition ) ) ; 
} else if ( recordStatus == OPaginatedCluster . RECORD_STATUS . PRESENT 
|| recordStatus == OPaginatedCluster . RECORD_STATUS . REMOVED ) { 
atomicOperationsManager . endAtomicOperation ( rollback ) ; 
} catch ( final IOException | RuntimeException ioe ) { 
} private List < ORecordOperation > commit ( final OTransactionInternal transaction , final boolean allocated ) { 
txBegun . incrementAndGet ( ) ; 
final ODatabaseDocumentInternal database = transaction . getDatabase ( ) ; 
final OIndexManager indexManager = database . getMetadata ( ) . getIndexManager ( ) ; 
final TreeMap < String , OTransactionIndexChanges > indexOperations = getSortedIndexOperations ( transaction ) ; 
database . getMetadata ( ) . makeThreadLocalSchemaSnapshot ( ) ; 
final Collection < ORecordOperation > recordOperations = transaction . getRecordOperations ( ) ; 
final Map < ORecordOperation , Integer > clusterOverrides = new IdentityHashMap < > ( 8 ) ; 
for ( final ORecordOperation recordOperation : recordOperations ) { 
if ( recordOperation . type == ORecordOperation . CREATED || recordOperation . type == ORecordOperation . UPDATED ) { 
final ORecord record = recordOperation . getRecord ( ) ; 
if ( record instanceof ODocument ) { 
( ( ODocument ) record ) . validate ( ) ; 
if ( recordOperation . type == ORecordOperation . UPDATED || recordOperation . type == ORecordOperation . DELETED ) { 
final int clusterId = recordOperation . getRecord ( ) . getIdentity ( ) . getClusterId ( ) ; 
} else if ( recordOperation . type == ORecordOperation . CREATED ) { 
newRecords . add ( recordOperation ) ; 
final ORID rid = record . getIdentity ( ) ; 
int clusterId = rid . getClusterId ( ) ; 
if ( record . isDirty ( ) && clusterId == ORID . CLUSTER_ID_INVALID && record instanceof ODocument ) { 
final OImmutableClass class_ = ODocumentInternal . getImmutableSchemaClass ( ( ( ODocument ) record ) ) ; 
if ( class_ != null ) { 
clusterId = class_ . getClusterForNewInstance ( ( ODocument ) record ) ; 
clusterOverrides . put ( recordOperation , clusterId ) ; 
final List < ORecordOperation > result = new ArrayList < > ( 8 ) ; 
if ( modificationLock ) { 
final List < ORID > recordLocks = new ArrayList < > ( ) ; 
recordLocks . add ( recordOperation . getRID ( ) ) ; 
final Set < ORID > locked = transaction . getLockedRecords ( ) ; 
if ( locked != null ) { 
recordLocks . removeAll ( locked ) ; 
Collections . sort ( recordLocks ) ; 
for ( final ORID rid : recordLocks ) { 
acquireWriteLock ( rid ) ; 
startStorageTx ( transaction ) ; 
final OAtomicOperation atomicOperation = OAtomicOperationsManager . getCurrentOperation ( ) ; 
checkReadOnlyConditions ( ) ; 
final Map < ORecordOperation , OPhysicalPosition > positions = new IdentityHashMap < > ( 8 ) ; 
for ( final ORecordOperation recordOperation : newRecords ) { 
final ORecord rec = recordOperation . getRecord ( ) ; 
if ( allocated ) { 
if ( rec . getIdentity ( ) . isPersistent ( ) ) { 
positions . put ( recordOperation , new OPhysicalPosition ( rec . getIdentity ( ) . getClusterPosition ( ) ) ) ; 
} else if ( rec . isDirty ( ) && ! rec . getIdentity ( ) . isPersistent ( ) ) { 
final Integer clusterOverride = clusterOverrides . get ( recordOperation ) ; 
final int clusterId = clusterOverride == null ? rid . getClusterId ( ) : clusterOverride ; 
final OCluster cluster = getClusterById ( clusterId ) ; 
assert atomicOperation . getCounter ( ) == 1 ; 
OPhysicalPosition physicalPosition = cluster . allocatePosition ( ORecordInternal . getRecordType ( rec ) ) ; 
rid . setClusterId ( cluster . getId ( ) ) ; 
if ( rid . getClusterPosition ( ) > - 1 ) { 
while ( rid . getClusterPosition ( ) > physicalPosition . clusterPosition ) { 
physicalPosition = cluster . allocatePosition ( ORecordInternal . getRecordType ( rec ) ) ; 
if ( rid . getClusterPosition ( ) != physicalPosition . clusterPosition ) { 
throw new OConcurrentCreateException ( rid , new ORecordId ( rid . getClusterId ( ) , physicalPosition . clusterPosition ) ) ; 
positions . put ( recordOperation , physicalPosition ) ; 
rid . setClusterPosition ( physicalPosition . clusterPosition ) ; 
transaction . updateIdentityAfterCommit ( oldRID , rid ) ; 
lockRidBags ( clustersToLock , indexOperations , indexManager ) ; 
commitEntry ( recordOperation , positions . get ( recordOperation ) , database . getSerializer ( ) ) ; 
result . add ( recordOperation ) ; 
lockIndexes ( indexOperations ) ; 
commitIndexes ( indexOperations , atomicOperation ) ; 
} catch ( final IOException | RuntimeException e ) { 
if ( e instanceof RuntimeException ) { 
throw ( ( RuntimeException ) e ) ; 
rollback ( transaction ) ; 
endStorageTx ( transaction , recordOperations ) ; 
this . transaction . set ( null ) ; 
atomicOperationsManager . ensureThatComponentsUnlocked ( ) ; 
database . getMetadata ( ) . clearThreadLocalSchemaSnapshot ( ) ; 
releaseWriteLock ( rid ) ; 
transaction . getId ( ) , database . getName ( ) , result ) ; 
handleJVMError ( ee ) ; 
OAtomicOperationsManager . alarmClearOfAtomicOperation ( ) ; 
} @ SuppressWarnings ( "UnusedReturnValue" ) 
public boolean validatedPutIndexValue ( int indexId , final Object key , final ORID value , 
final OBaseIndexEngine . Validator < Object , ORID > validator ) throws OInvalidIndexEngineIdException { 
indexId = extractInternalId ( indexId ) ; 
if ( transaction . get ( ) != null ) { 
return doValidatedPutIndexValue ( indexId , key , value , validator ) ; 
} catch ( final OInvalidIndexEngineIdException ie ) { 
throw logAndPrepareForRethrow ( ie ) ; 
} public void rollback ( final OMicroTransaction microTransaction ) { 
if ( transaction . get ( ) == null ) { 
if ( transaction . get ( ) . getMicroTransaction ( ) . getId ( ) != microTransaction . getId ( ) ) { 
throw new OStorageException ( 
rollbackStorageTx ( ) ; 
microTransaction . updateRecordCacheAfterRollback ( ) ; 
txRollback . incrementAndGet ( ) ; 
transaction . set ( null ) ; 
} public final void renameCluster ( final String oldName , final String newName ) { 
clusterMap . put ( newName . toLowerCase ( configuration . getLocaleInstance ( ) ) , 
clusterMap . remove ( oldName . toLowerCase ( configuration . getLocaleInstance ( ) ) ) ) ; 
public final Object command ( final OCommandRequestText iCommand ) { 
final OCommandExecutor executor = OCommandManager . instance ( ) . getExecutor ( iCommand ) ; 
executor . setContext ( iCommand . getContext ( ) ) ; 
executor . setProgressListener ( iCommand . getProgressListener ( ) ) ; 
executor . parse ( iCommand ) ; 
return executeCommand ( iCommand , executor ) ; 
} catch ( final ORetryQueryException ignore ) { 
if ( iCommand instanceof OQueryAbstract ) { 
final OQueryAbstract query = ( OQueryAbstract ) iCommand ; 
query . reset ( ) ; 
throw logAndPrepareForRethrow ( ee , false ) ; 
} private int registerCluster ( final OCluster cluster ) { 
final int id ; 
if ( cluster != null ) { 
if ( clusterMap . containsKey ( cluster . getName ( ) . toLowerCase ( configuration . getLocaleInstance ( ) ) ) ) { 
clusterMap . put ( cluster . getName ( ) . toLowerCase ( configuration . getLocaleInstance ( ) ) , cluster ) ; 
id = cluster . getId ( ) ; 
id = clusters . size ( ) ; 
setCluster ( id , cluster ) ; 
return id ; 
} private void checkLowDiskSpaceRequestsAndReadOnlyConditions ( ) { 
if ( lowDiskSpace != null ) { 
if ( checkpointInProgress . compareAndSet ( false , true ) ) { 
if ( writeCache . checkLowDiskSpace ( ) ) { 
synch ( ) ; 
. getValueAsInteger ( OGlobalConfiguration . DISK_CACHE_FREE_SPACE_LIMIT ) 
lowDiskSpace = null ; 
checkpointInProgress . set ( false ) ; 
} public Object setProperty ( final String iName , final Object iValue ) { 
return properties . put ( iName . toLowerCase ( Locale . ENGLISH ) , iValue ) ; 
return properties . remove ( iName . toLowerCase ( Locale . ENGLISH ) ) ; 
boolean alreadyExists = database . getMetadata ( ) . getSchema ( ) . existsClass ( className ) ; 
if ( ! alreadyExists || ! ifNotExists ) { 
if ( clusters != null ) 
database . getMetadata ( ) . getSchema ( ) . createClass ( className , clusters , superClasses . toArray ( new OClass [ 0 ] ) ) ; 
database . getMetadata ( ) . getSchema ( ) . createClass ( className , clusterIds , superClasses . toArray ( new OClass [ 0 ] ) ) ; 
return database . getMetadata ( ) . getSchema ( ) . getClasses ( ) . size ( ) ; 
public long count ( ) { 
if ( hasContainers . isEmpty ( ) ) { 
long counter = ( ( OrientVertex ) vertex ) . countEdges ( direction , labels ) ; 
if ( limit != Integer . MAX_VALUE && counter > limit ) 
return limit ; 
return super . count ( ) ; 
database . checkSecurity ( ORule . ResourceGeneric . DATABASE , "sync" , ORole . PERMISSION_UPDATE ) ; 
final OStorage stg = database . getStorage ( ) ; 
if ( ! ( stg instanceof ODistributedStorage ) ) 
final ODistributedStorage dStg = ( ODistributedStorage ) stg ; 
final OHazelcastPlugin dManager = ( OHazelcastPlugin ) dStg . getDistributedManager ( ) ; 
return dManager . installDatabase ( true , databaseName , parsedStatement . isForce ( ) , ! parsedStatement . isFull ( ) ) ; 
} public OCommandExecutorSQLAbstract createCommand ( final String name ) throws OCommandExecutionException { 
final Class < ? extends OCommandExecutorSQLAbstract > clazz = COMMANDS . get ( name ) ; 
return clazz . newInstance ( ) ; 
} public < RET extends ORecord > RET load ( final ORID iRecordId , final String iFetchPlan , final boolean iIgnoreCache ) { 
return ( RET ) executeReadRecord ( ( ORecordId ) iRecordId , null , - 1 , iFetchPlan , iIgnoreCache , ! iIgnoreCache , false , 
OStorage . LOCKING_STRATEGY . DEFAULT , new SimpleRecordReader ( prefetchRecords ) ) ; 
} public ODatabase < ORecord > delete ( final ORID iRecord , final int iVersion ) { 
ORecord record = load ( iRecord ) ; 
ORecordInternal . setVersion ( record , iVersion ) ; 
delete ( record ) ; 
public < REC extends ORecord > ORecordIteratorCluster < REC > browseCluster ( final String iClusterName , final Class < REC > iRecordClass , 
final long startClusterPosition , final long endClusterPosition , final boolean loadTombstones ) { 
checkSecurity ( ORule . ResourceGeneric . CLUSTER , ORole . PERMISSION_READ , iClusterName ) ; 
final int clusterId = getClusterIdByName ( iClusterName ) ; 
return new ORecordIteratorCluster < REC > ( this , clusterId , startClusterPosition , endClusterPosition , 
OStorage . LOCKING_STRATEGY . DEFAULT ) ; 
} public OCommandRequest command ( final OCommandRequest iCommand ) { 
checkSecurity ( ORule . ResourceGeneric . COMMAND , ORole . PERMISSION_READ ) ; 
final OCommandRequestInternal command = ( OCommandRequestInternal ) iCommand ; 
command . reset ( ) ; 
} public < RET extends List < ? > > RET query ( final OQuery < ? > iCommand , final Object ... iArgs ) { 
iCommand . reset ( ) ; 
return ( RET ) iCommand . execute ( iArgs ) ; 
public long countClusterElements ( int [ ] iClusterIds , boolean countTombstones ) { 
String name ; 
for ( int iClusterId : iClusterIds ) { 
name = getClusterNameById ( iClusterId ) ; 
checkSecurity ( ORule . ResourceGeneric . CLUSTER , ORole . PERMISSION_READ , name ) ; 
return getStorage ( ) . count ( iClusterIds , countTombstones ) ; 
public long countClusterElements ( final String iClusterName ) { 
if ( clusterId < 0 ) 
return getStorage ( ) . count ( clusterId ) ; 
} public < DB extends ODatabaseDocument > DB checkSecurity ( final ORule . ResourceGeneric resourceGeneric , final String resourceSpecific , 
final int iOperation ) { 
if ( user != null ) { 
user . allow ( resourceGeneric , resourceSpecific , iOperation ) ; 
if ( OLogManager . instance ( ) . isDebugEnabled ( ) ) 
resourceSpecific , iOperation ) ; 
return ( DB ) this ; 
} public < DB extends ODatabaseDocument > DB checkSecurity ( final ORule . ResourceGeneric iResourceGeneric , final int iOperation , 
final Object ... iResourcesSpecific ) { 
if ( iResourcesSpecific . length != 0 ) { 
for ( Object target : iResourcesSpecific ) { 
if ( target != null ) { 
user . allow ( iResourceGeneric , target . toString ( ) , iOperation ) ; 
user . allow ( iResourceGeneric , null , iOperation ) ; 
getUser ( ) , iResourceGeneric , Arrays . toString ( iResourcesSpecific ) , iOperation ) ; 
final Object iResourceSpecific ) { 
if ( iResourceSpecific != null ) 
user . allow ( iResourceGeneric , iResourceSpecific . toString ( ) , iOperation ) ; 
getUser ( ) , iResourceGeneric , iResourceSpecific , iOperation ) ; 
} public < DB extends ODatabase > DB setStatus ( final STATUS status ) { 
setStatusInternal ( status ) ; 
} public void setUser ( final OSecurityUser user ) { 
if ( user instanceof OUser ) { 
OMetadata metadata = getMetadata ( ) ; 
final OSecurity security = metadata . getSecurity ( ) ; 
this . user = new OImmutableUser ( security . getVersion ( ) , ( OUser ) user ) ; 
this . user = new OImmutableUser ( - 1 , ( OUser ) user ) ; 
this . user = ( OImmutableUser ) user ; 
} public < DB extends ODatabase < ? > > DB registerHook ( final ORecordHook iHookImpl , final ORecordHook . HOOK_POSITION iPosition ) { 
final Map < ORecordHook , ORecordHook . HOOK_POSITION > tmp = new LinkedHashMap < ORecordHook , ORecordHook . HOOK_POSITION > ( hooks ) ; 
tmp . put ( iHookImpl , iPosition ) ; 
hooks . clear ( ) ; 
for ( ORecordHook . HOOK_POSITION p : ORecordHook . HOOK_POSITION . values ( ) ) { 
for ( Map . Entry < ORecordHook , ORecordHook . HOOK_POSITION > e : tmp . entrySet ( ) ) { 
if ( e . getValue ( ) == p ) 
hooks . put ( e . getKey ( ) , e . getValue ( ) ) ; 
compileHooks ( ) ; 
} public < DB extends ODatabase < ? > > DB registerHook ( final ORecordHook iHookImpl ) { 
return ( DB ) registerHook ( iHookImpl , ORecordHook . HOOK_POSITION . REGULAR ) ; 
} public < DB extends ODatabase < ? > > DB unregisterHook ( final ORecordHook iHookImpl ) { 
if ( iHookImpl != null ) { 
iHookImpl . onUnregister ( ) ; 
hooks . remove ( iHookImpl ) ; 
} public ORecordHook . RESULT callbackHooks ( final ORecordHook . TYPE type , final OIdentifiable id ) { 
if ( id == null || hooks . isEmpty ( ) || id . getIdentity ( ) . getClusterId ( ) == 0 ) 
return ORecordHook . RESULT . RECORD_NOT_CHANGED ; 
final ORecordHook . SCOPE scope = ORecordHook . SCOPE . typeToScope ( type ) ; 
final int scopeOrdinal = scope . ordinal ( ) ; 
final ORID identity = id . getIdentity ( ) . copy ( ) ; 
if ( ! pushInHook ( identity ) ) 
final ORecord rec = id . getRecord ( ) ; 
if ( rec == null ) 
final OScenarioThreadLocal . RUN_MODE runMode = OScenarioThreadLocal . INSTANCE . getRunMode ( ) ; 
boolean recordChanged = false ; 
for ( ORecordHook hook : hooksByScope [ scopeOrdinal ] ) { 
switch ( runMode ) { 
case DEFAULT : 
if ( getStorage ( ) . isDistributed ( ) 
&& hook . getDistributedExecutionMode ( ) == ORecordHook . DISTRIBUTED_EXECUTION_MODE . TARGET_NODE ) 
case RUNNING_DISTRIBUTED : 
if ( hook . getDistributedExecutionMode ( ) == ORecordHook . DISTRIBUTED_EXECUTION_MODE . SOURCE_NODE ) 
final ORecordHook . RESULT res = hook . onTrigger ( type , rec ) ; 
if ( res == ORecordHook . RESULT . RECORD_CHANGED ) 
recordChanged = true ; 
else if ( res == ORecordHook . RESULT . SKIP_IO ) 
else if ( res == ORecordHook . RESULT . SKIP ) 
else if ( res == ORecordHook . RESULT . RECORD_REPLACED ) 
return recordChanged ? ORecordHook . RESULT . RECORD_CHANGED : ORecordHook . RESULT . RECORD_NOT_CHANGED ; 
popInHook ( identity ) ; 
} public < DB extends ODatabaseDocument > DB setValidationEnabled ( final boolean iEnabled ) { 
set ( ATTRIBUTES . VALIDATION , iEnabled ) ; 
} public ODatabaseDocument delete ( final ORID iRecord ) { 
final ORecord rec = load ( iRecord ) ; 
if ( rec != null ) 
delete ( rec ) ; 
} public < RET extends ORecord > RET load ( final ORecord iRecord , final String iFetchPlan , final boolean iIgnoreCache ) { 
return ( RET ) executeReadRecord ( ( ORecordId ) iRecord . getIdentity ( ) , iRecord , - 1 , iFetchPlan , iIgnoreCache , ! iIgnoreCache , false , 
OStorage . LOCKING_STRATEGY . NONE , new SimpleRecordReader ( prefetchRecords ) ) ; 
} public boolean executeHideRecord ( OIdentifiable record , final OPERATION_MODE iMode ) { 
checkSecurity ( ORule . ResourceGeneric . CLUSTER , ORole . PERMISSION_DELETE , getClusterNameById ( rid . getClusterId ( ) ) ) ; 
final OStorageOperationResult < Boolean > operationResult ; 
operationResult = getStorage ( ) . hideRecord ( rid , iMode . ordinal ( ) , null ) ; 
if ( ! operationResult . isMoved ( ) ) 
getLocalCache ( ) . deleteRecord ( rid ) ; 
return operationResult . getResult ( ) ; 
public void freeze ( final boolean throwException ) { 
if ( ! ( getStorage ( ) instanceof OFreezableStorageComponent ) ) { 
OLogManager . instance ( ) . error ( this , 
final long startTime = Orient . instance ( ) . getProfiler ( ) . startChrono ( ) ; 
final OFreezableStorageComponent storage = getFreezableStorage ( ) ; 
if ( storage != null ) { 
storage . freeze ( throwException ) ; 
} public ORecordIteratorClass < ODocument > browseClass ( final String iClassName , final boolean iPolymorphic ) { 
if ( getMetadata ( ) . getImmutableSchemaSnapshot ( ) . getClass ( iClassName ) == null ) 
checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_READ , iClassName ) ; 
return new ORecordIteratorClass < ODocument > ( this , iClassName , iPolymorphic , false ) ; 
public ORecordIteratorCluster < ODocument > browseCluster ( final String iClusterName ) { 
return new ORecordIteratorCluster < ODocument > ( this , getClusterIdByName ( iClusterName ) ) ; 
public ORecordIteratorCluster < ODocument > browseCluster ( String iClusterName , long startClusterPosition , long endClusterPosition , 
boolean loadTombstones ) { 
return new ORecordIteratorCluster < ODocument > ( this , getClusterIdByName ( iClusterName ) , startClusterPosition , endClusterPosition , 
public < RET extends ORecord > RET save ( final ORecord iRecord ) { 
return ( RET ) save ( iRecord , null , OPERATION_MODE . SYNCHRONOUS , false , null , null ) ; 
public < RET extends ORecord > RET save ( final ORecord iRecord , final OPERATION_MODE iMode , boolean iForceCreate , 
return save ( iRecord , null , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
public < RET extends ORecord > RET save ( ORecord iRecord , String iClusterName , final OPERATION_MODE iMode , boolean iForceCreate , 
if ( iRecord instanceof OVertex ) { 
iRecord = iRecord . getRecord ( ) ; 
if ( iRecord instanceof OEdge ) { 
if ( ( ( OEdge ) iRecord ) . isLightweight ( ) ) { 
iRecord = ( ( OEdge ) iRecord ) . getFrom ( ) ; 
ODirtyManager dirtyManager = ORecordInternal . getDirtyManager ( iRecord ) ; 
if ( iRecord instanceof OElement && dirtyManager != null && dirtyManager . getReferences ( ) != null && ! dirtyManager . getReferences ( ) 
. isEmpty ( ) ) { 
if ( ( ( ( OElement ) iRecord ) . isVertex ( ) || ( ( OElement ) iRecord ) . isEdge ( ) ) && ! getTransaction ( ) . isActive ( ) && inHook . isEmpty ( ) ) { 
return saveGraph ( iRecord , iClusterName , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
return saveInternal ( iRecord , iClusterName , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; 
} public long countView ( final String viewName ) { 
final OView cls = getMetadata ( ) . getImmutableSchemaSnapshot ( ) . getView ( viewName ) ; 
return countClass ( cls , false ) ; 
} public long countClass ( final String iClassName , final boolean iPolymorphic ) { 
final OClass cls = getMetadata ( ) . getImmutableSchemaSnapshot ( ) . getClass ( iClassName ) ; 
return countClass ( cls , iPolymorphic ) ; 
public ODatabaseDocumentAbstract activateOnCurrentThread ( ) { 
final ODatabaseRecordThreadLocal tl = ODatabaseRecordThreadLocal . instance ( ) ; 
if ( tl != null ) 
tl . set ( this ) ; 
} public void register ( final OEncryption iEncryption ) { 
final String name = iEncryption . name ( ) ; 
if ( instances . containsKey ( name ) ) 
if ( classes . containsKey ( name ) ) 
instances . put ( name , iEncryption ) ; 
} public byte [ ] getBytes ( long pos , int length ) throws SQLException { 
if ( pos < 1 ) 
if ( length < 0 ) 
throw new SQLException ( 
int relativeIndex = this . getRelativeIndex ( pos ) ; 
ByteBuffer buffer = ByteBuffer . allocate ( length ) ; 
int j ; 
for ( j = 0 ; j < length ; j ++ ) { 
if ( relativeIndex == currentChunk . length ) { 
currentChunkIndex ++ ; 
if ( currentChunkIndex < binaryDataChunks . size ( ) ) { 
relativeIndex = 0 ; 
currentChunk = binaryDataChunks . get ( currentChunkIndex ) ; 
buffer . put ( currentChunk [ relativeIndex ] ) ; 
relativeIndex ++ ; 
} private int getRelativeIndex ( long pos ) { 
int currentSize = 0 ; 
currentChunkIndex = 0 ; 
while ( pos >= ( currentSize += binaryDataChunks . get ( currentChunkIndex ) . length ) ) 
currentSize -= currentChunk . length ; 
int relativePosition = ( int ) ( pos - currentSize ) ; 
return relativePosition - 1 ; 
} protected String parserOptionalWord ( final boolean iUpperCase ) { 
parserPreviousPos = parserCurrentPos ; 
parserNextWord ( iUpperCase ) ; 
if ( parserLastWord . length ( ) == 0 ) 
return parserLastWord . toString ( ) ; 
} protected String parserRequiredWord ( final boolean iUpperCase , final String iCustomMessage , String iSeparators ) { 
if ( iSeparators == null ) 
parserNextWord ( iUpperCase , iSeparators ) ; 
throwSyntaxErrorException ( iCustomMessage ) ; 
if ( parserLastWord . charAt ( 0 ) == '`' && parserLastWord . charAt ( parserLastWord . length ( ) - 1 ) == '`' ) { 
return parserLastWord . substring ( 1 , parserLastWord . length ( ) - 1 ) ; 
} protected int parserNextChars ( final boolean iUpperCase , final boolean iMandatory , final String ... iCandidateWords ) { 
parserEscapeSequenceCount = 0 ; 
parserLastWord . setLength ( 0 ) ; 
final String [ ] processedWords = Arrays . copyOf ( iCandidateWords , iCandidateWords . length ) ; 
final String text2Use = iUpperCase ? parserTextUpperCase : parserText ; 
final int max = text2Use . length ( ) ; 
parserCurrentPos = parserCurrentPos + parserTextUpperCase . length ( ) - parserText . length ( ) ; 
for ( int i = 0 ; parserCurrentPos <= max ; ++ i ) { 
final char ch = parserCurrentPos < max ? text2Use . charAt ( parserCurrentPos ) : '\n' ; 
if ( ! separator ) 
parserLastWord . append ( ch ) ; 
int candidatesWordsCount = 0 ; 
int candidatesWordsPos = - 1 ; 
for ( int c = 0 ; c < processedWords . length ; ++ c ) { 
final String w = processedWords [ c ] ; 
if ( w != null ) { 
final int wordSize = w . length ( ) ; 
if ( ( separator && wordSize > i ) || ( ! separator && ( i > wordSize - 1 || w . charAt ( i ) != ch ) ) ) 
processedWords [ c ] = null ; 
candidatesWordsCount ++ ; 
if ( candidatesWordsCount == 1 ) 
candidatesWordsPos = c ; 
if ( candidatesWordsCount == 1 ) { 
final String w = processedWords [ candidatesWordsPos ] ; 
if ( w . length ( ) == i + ( separator ? 0 : 1 ) && ! Character . isLetter ( ch ) ) 
return candidatesWordsPos ; 
if ( candidatesWordsCount == 0 || separator ) 
parserCurrentPos ++ ; 
if ( iMandatory ) 
+ Arrays . toString ( iCandidateWords ) + "'" ) ; 
} protected boolean parserOptionalKeyword ( final String ... iWords ) { 
boolean found = iWords . length == 0 ; 
for ( String w : iWords ) { 
if ( parserLastWord . toString ( ) . equals ( w ) ) { 
+ Arrays . toString ( iWords ) + "'" ) ; 
} private boolean parserCheckSeparator ( final char c , final String iSeparatorChars ) { 
for ( int sepIndex = 0 ; sepIndex < iSeparatorChars . length ( ) ; ++ sepIndex ) { 
if ( iSeparatorChars . charAt ( sepIndex ) == c ) { 
parserLastSeparator = c ; 
} public LinkedList < OrientVertex > getPath ( ) { 
final LinkedList < OrientVertex > path = new LinkedList < OrientVertex > ( ) ; 
OrientVertex step = paramDestinationVertex ; 
if ( predecessors . get ( step . getIdentity ( ) ) == null ) 
path . add ( step ) ; 
while ( predecessors . get ( step . getIdentity ( ) ) != null ) { 
step = predecessors . get ( step . getIdentity ( ) ) ; 
Collections . reverse ( path ) ; 
if ( ifExists && ! database . getMetadata ( ) . getSchema ( ) . existsClass ( className ) ) { 
final OClass cls = database . getMetadata ( ) . getSchema ( ) . getClass ( className ) ; 
if ( cls == null ) { 
final long records = cls . count ( true ) ; 
if ( records > 0 && ! unsafe ) { 
if ( cls . isSubClassOf ( "V" ) ) { 
} else if ( cls . isSubClassOf ( "E" ) ) { 
database . getMetadata ( ) . getSchema ( ) . dropClass ( className ) ; 
if ( records > 0 && unsafe ) { 
if ( unsafe ) 
records ) ; 
} private void clearConfigurationFiles ( ) throws IOException { 
final Path file = storagePath . resolve ( NAME ) ; 
Files . deleteIfExists ( file ) ; 
final Path backupFile = storagePath . resolve ( BACKUP_NAME ) ; 
Files . deleteIfExists ( backupFile ) ; 
if ( converted || ! convertToRecord ) 
Object o = super . get ( iIndex ) ; 
final ODatabaseDocument database = getDatabase ( ) . getUnderlying ( ) ; 
o = recordList . get ( iIndex ) ; 
ODocument doc ; 
if ( o instanceof ORID ) { 
doc = database . load ( ( ORID ) o , fetchPlan ) ; 
doc = ( ODocument ) o ; 
OLogManager . instance ( ) . warn ( 
this , 
super . set ( 
iIndex , 
( TYPE ) OObjectEntityEnhancer . getInstance ( ) . getProxiedInstance ( doc . getClassName ( ) , getDatabase ( ) . getEntityManager ( ) , doc , 
sourceRecord ) ) ; 
} public int getAsByteArrayOffset ( ) { 
if ( position >= length ) 
final int size = OBinaryProtocol . bytes2int ( buffer , position ) ; 
position += OBinaryProtocol . SIZE_INT + size ; 
} public WhenRuleBuilder < T , U > when ( Predicate < NameValueReferableTypeConvertibleMap < T > > condition ) { 
return new WhenRuleBuilder < > ( _rule , condition ) ; 
public void handleRequest ( Object obj ) { 
boolean actionResult = _rule . invoke ( ( NameValueReferableMap ) obj ) ; 
if ( ! actionResult || _rule . getRuleState ( ) == RuleState . NEXT ) { 
getSuccessor ( ) . ifPresent ( handler -> { 
_rule . getResult ( ) . ifPresent ( result -> handler . getDelegate ( ) . setResult ( ( Result ) result ) ) ; 
handler . handleRequest ( obj ) ; 
public T getOne ( ) { 
if ( _facts . size ( ) == 1 ) { 
return _facts . values ( ) . iterator ( ) . next ( ) . getValue ( ) ; 
public T getValue ( String name ) { 
return Optional . ofNullable ( _facts . get ( name ) ) . map ( NameValueReferable :: getValue ) . orElse ( null ) ; 
public String getStrVal ( String name ) { 
if ( getValue ( name ) instanceof String ) { 
return ( String ) getValue ( name ) ; 
return String . valueOf ( getValue ( name ) ) ; 
public Integer getIntVal ( String name ) { 
Object value = getValue ( name ) ; 
if ( Integer . class == value . getClass ( ) ) { 
if ( value . getClass ( ) == String . class ) { 
return Integer . valueOf ( ( String ) value ) ; 
public Double getDblVal ( String name ) { 
if ( Float . class == value . getClass ( ) ) { 
return Double . valueOf ( ( Float ) value ) ; 
if ( Double . class == value . getClass ( ) ) { 
return ( Double ) value ; 
return Double . valueOf ( ( Integer ) value ) ; 
if ( Long . class == value . getClass ( ) ) { 
return Double . valueOf ( ( Long ) value ) ; 
if ( String . class == value . getClass ( ) ) { 
return Double . parseDouble ( ( String ) value ) ; 
} public void setValue ( String name , T value ) { 
NameValueReferable < T > fact = _facts . get ( name ) ; 
if ( fact == null ) { 
fact = new Fact < > ( name , value ) ; 
_facts . put ( name , fact ) ; 
fact . setValue ( value ) ; 
public Fact < T > put ( NameValueReferable < T > fact ) { 
return put ( fact . getName ( ) , fact ) ; 
} GivenRuleBuilder < T , U > given ( String name , T value ) { 
return given ( new Fact < T > ( name , value ) ) ; 
} @ SafeVarargs 
public final GivenRuleBuilder < T , U > given ( NameValueReferable ... facts ) { 
_rule . addFacts ( facts ) ; 
} public UsingRuleBuilder < T , U > using ( String ... factNames ) { 
return new UsingRuleBuilder < T , U > ( _rule , factNames ) ; 
} public static RuleBuilder < Object , Object > create ( Class < ? extends Rule > ruleClass , 
RuleChainActionType actionType ) { 
return new RuleBuilder < > ( ruleClass , actionType ) ; 
} public static RuleBuilder < Object , Object > create ( ) { 
RuleBuilder < Object , Object > rule = new RuleBuilder < > ( GoldenRule . class ) ; 
rule . _factType = Object . class ; 
return rule ; 
} public < S > RuleBuilder < S , U > withFactType ( Class < S > factType ) { 
RuleBuilder < S , U > builder = new RuleBuilder < > ( _ruleClass ) ; 
builder . _factType = factType ; 
builder . _resultType = _resultType ; 
builder . _actionType = _actionType ; 
return builder ; 
} public < S > RuleBuilder < T , S > withResultType ( Class < S > resultType ) { 
RuleBuilder < T , S > builder = new RuleBuilder < > ( _ruleClass ) ; 
builder . _factType = _factType ; 
builder . _resultType = resultType ; 
builder . _name = _name ; 
public GivenRuleBuilder < T , U > given ( String name , T value ) { 
Rule < T , U > rule = _name . map ( ruleName -> ( Rule < T , U > ) new AuditableRule < T , U > ( newRule ( ) , ruleName ) ) . orElse ( newRule ( ) ) ; 
return new GivenRuleBuilder < T , U > ( rule , new Fact < T > ( name , value ) ) ; 
@ SafeVarargs 
Rule < T , U > rule = _name . map ( name -> ( Rule < T , U > ) new AuditableRule < T , U > ( newRule ( ) , name ) ) . orElse ( newRule ( ) ) ; 
return new GivenRuleBuilder < T , U > ( rule , facts ) ; 
public WhenRuleBuilder < T , U > when ( Predicate < NameValueReferableTypeConvertibleMap < T > > condition ) { 
return new WhenRuleBuilder < T , U > ( rule , condition ) ; 
public UsingRuleBuilder < T , U > using ( String ... factNames ) { 
return new UsingRuleBuilder < T , U > ( rule , factNames ) ; 
public ThenRuleBuilder < T , U > then ( Consumer < NameValueReferableTypeConvertibleMap < T > > action ) { 
return new ThenRuleBuilder < T , U > ( rule , action ) ; 
private void mapFactsToProperties ( NameValueReferableMap facts ) { 
for ( Field field : getAnnotatedFields ( Given . class , _pojoRule . getClass ( ) ) ) { 
Given given = field . getAnnotation ( Given . class ) ; 
field . setAccessible ( true ) ; 
if ( NameValueReferable . class . isAssignableFrom ( field . getType ( ) ) ) { 
field . set ( _pojoRule , facts . get ( given . value ( ) ) ) ; 
Object value = facts . getValue ( given . value ( ) ) ; 
field . set ( _pojoRule , value ) ; 
} else if ( NameValueReferableMap . class . isAssignableFrom ( field . getType ( ) ) ) { 
field . set ( _pojoRule , facts ) ; 
} else if ( Collection . class . isAssignableFrom ( field . getType ( ) ) ) { 
Stream stream = facts . values ( ) . stream ( ) 
. filter ( fact -> { 
ParameterizedType paramType = ( ParameterizedType ) field . getGenericType ( ) ; 
Class < ? > genericType = ( Class < ? > ) paramType . getActualTypeArguments ( ) [ 0 ] ; 
return genericType . equals ( ( ( NameValueReferable ) fact ) . getValue ( ) . getClass ( ) ) ; 
} ) 
. map ( fact -> { 
return genericType . cast ( ( ( NameValueReferable ) fact ) . getValue ( ) ) ; 
if ( List . class == field . getType ( ) ) { 
field . set ( _pojoRule , stream . collect ( Collectors . toList ( ) ) ) ; 
} else if ( Set . class == field . getType ( ) ) { 
field . set ( _pojoRule , stream . collect ( Collectors . toSet ( ) ) ) ; 
} else if ( Map . class == field . getType ( ) ) { 
Map map = ( Map ) facts . keySet ( ) . stream ( ) 
. filter ( key -> { 
Class < ? > genericType = ( Class < ? > ) paramType . getActualTypeArguments ( ) [ 1 ] ; 
return genericType . equals ( facts . getValue ( ( String ) key ) . getClass ( ) ) ; 
. collect ( Collectors . toMap ( key -> key , key -> facts . getValue ( ( String ) key ) ) ) ; 
field . set ( _pojoRule , map ) ; 
+ _pojoRule . getClass ( ) + "'" , ex ) ; 
} protected Object getRuleInstance ( Class < ? > rule ) { 
return rule . newInstance ( ) ; 
} catch ( InstantiationException | IllegalAccessException ex ) { 
} public final void run ( ) { 
if ( _headRule . isPresent ( ) == false ) { 
defineRules ( ) ; 
_headRule . ifPresent ( rule -> rule . given ( _facts ) ) ; 
_headRule . ifPresent ( Rule :: run ) ; 
public final RuleBook < T > given ( Fact < T > ... facts ) { 
Arrays . stream ( facts ) . forEach ( _facts :: add ) ; 
} public RuleBook < T > given ( String name , T value ) { 
_facts . add ( new Fact < T > ( name , value ) ) ; 
} public void addRule ( Rule < T > rule ) { 
if ( ! _headRule . isPresent ( ) ) { 
_headRule = Optional . of ( rule ) ; 
_tailRule = rule ; 
_tailRule . setNextRule ( rule ) ; 
public static List < Field > getAnnotatedFields ( Class annotation , Class clazz ) { 
if ( clazz == Object . class ) { 
return new ArrayList < > ( ) ; 
List < Field > fields = ( List < Field > ) Arrays . stream ( clazz . getDeclaredFields ( ) ) 
. filter ( field -> field . getAnnotation ( annotation ) != null ) 
if ( clazz . getSuperclass ( ) != null ) { 
fields . addAll ( getAnnotatedFields ( annotation , clazz . getSuperclass ( ) ) ) ; 
return fields ; 
} public static Optional < Field > getAnnotatedField ( Class annotation , Class clazz ) { 
List < Field > fields = getAnnotatedFields ( annotation , clazz ) ; 
return Optional . ofNullable ( fields . size ( ) > 0 ? fields . get ( 0 ) : null ) ; 
public static List < Method > getAnnotatedMethods ( Class annotation , Class clazz ) { 
List < Method > methods = new ArrayList < > ( ) ; 
methods . addAll ( ( List < Method > ) 
Arrays . stream ( clazz . getDeclaredMethods ( ) ) 
. collect ( Collectors . toList ( ) ) ) ; 
methods . addAll ( getAnnotatedMethods ( annotation , clazz . getSuperclass ( ) ) ) ; 
} public static Optional < Method > getAnnotatedMethod ( Class annotation , Class clazz ) { 
List < Method > methods = getAnnotatedMethods ( annotation , clazz ) ; 
return Optional . ofNullable ( methods . size ( ) > 0 ? methods . get ( 0 ) : null ) ; 
public static < A extends Annotation > A getAnnotation ( Class < A > annotation , Class < ? > clazz ) { 
return Optional . ofNullable ( clazz . getAnnotation ( annotation ) ) . orElse ( ( A ) 
Arrays . stream ( clazz . getDeclaredAnnotations ( ) ) 
. flatMap ( anno -> Arrays . stream ( anno . getClass ( ) . getInterfaces ( ) ) 
. flatMap ( iface -> Arrays . stream ( iface . getDeclaredAnnotations ( ) ) ) ) 
. filter ( annotation :: isInstance ) 
. findFirst ( ) . orElse ( null ) 
} public static < T , U > StandardDecision < T , U > create ( Class < T > factType , Class < U > resultType ) { 
return new StandardDecision < T , U > ( factType , resultType ) ; 
public Decision < T , U > given ( String name , T value ) { 
_rule . given ( name , value ) ; 
public Decision < T , U > given ( Fact < T > ... facts ) { 
_rule . given ( facts ) ; 
public Decision < T , U > given ( FactMap < T > facts ) { 
public Decision < T , U > when ( Predicate < FactMap < T > > test ) { 
_rule . when ( test ) ; 
public Decision < T , U > then ( BiConsumer < FactMap < T > , Result < U > > action ) { 
_rule . getThen ( ) . add ( action ) ; 
public Decision < T , U > then ( Consumer < FactMap < T > > action ) { 
_rule . then ( action ) ; 
public Decision < T , U > using ( String ... factNames ) { 
_rule . using ( factNames ) ; 
} public void registerRule ( Auditable rule ) { 
_lock . writeLock ( ) . lock ( ) ; 
_auditMap . put ( rule . getName ( ) , new HashMap < > ( ) ) ; 
_lock . writeLock ( ) . unlock ( ) ; 
} public void updateRuleStatus ( Auditable rule , RuleStatus status ) { 
_lock . readLock ( ) . lock ( ) ; 
if ( _auditMap . containsKey ( rule . getName ( ) ) ) { 
_lock . readLock ( ) . unlock ( ) ; 
_auditMap . get ( rule . getName ( ) ) . put ( Thread . currentThread ( ) . getId ( ) , status ) ; 
} public Map < String , RuleStatus > getRuleStatusMap ( ) { 
return _auditMap . keySet ( ) . stream ( ) 
. collect ( 
Collectors . toMap ( key -> key , 
key -> _auditMap . get ( key ) . getOrDefault ( Thread . currentThread ( ) . getId ( ) , RuleStatus . PENDING ) ) ) ; 
} public < U > RuleBookWithResultTypeBuilder < U > withResultType ( Class < U > resultType ) { 
_resultType = resultType ; 
return new RuleBookWithResultTypeBuilder < U > ( ( new RuleBookBuilder < U > ( this ) ) . newRuleBook ( ) ) ; 
} public RuleBookAddRuleBuilder < T > addRule ( Consumer < RuleBookRuleBuilder < T > > consumer ) { 
return new RuleBookAddRuleBuilder < > ( newRuleBook ( ) , consumer ) ; 
} public < U > RuleBookAddRuleBuilder < T > addRule ( Rule < U , T > rule ) { 
return new RuleBookAddRuleBuilder < > ( newRuleBook ( ) , rule ) ; 
public void run ( Object ... otherArgs ) { 
FactMap < T > typeFilteredFacts = new FactMap < T > ( ( Map < String , NameValueReferable < T > > ) _facts . values ( ) . stream ( ) 
. filter ( ( Object fact ) -> _factType . isAssignableFrom ( ( ( Fact ) fact ) . getValue ( ) . getClass ( ) ) ) 
. collect ( Collectors . toMap ( fact -> ( ( Fact ) fact ) . getName ( ) , fact -> ( Fact < T > ) fact ) ) ) ; 
if ( getWhen ( ) == null || getWhen ( ) . test ( typeFilteredFacts ) ) { 
List < Object > actionList = getThen ( ) ; 
for ( int i = 0 ; i < ( getThen ( ) ) . size ( ) ; i ++ ) { 
Object action = actionList . get ( i ) ; 
List < String > factNames = _factNameMap . get ( i ) ; 
FactMap < T > usingFacts ; 
if ( factNames != null ) { 
usingFacts = new FactMap < T > ( factNames . stream ( ) 
. filter ( typeFilteredFacts :: containsKey ) 
. collect ( Collectors . toMap ( name -> name , name -> _facts . get ( name ) ) ) ) ; 
usingFacts = typeFilteredFacts ; 
Stream . of ( action . getClass ( ) . getMethods ( ) ) 
. filter ( method -> method . getName ( ) . equals ( "accept" ) ) 
. findFirst ( ) 
. ifPresent ( method -> { 
method . setAccessible ( true ) ; 
method . invoke ( action , 
ArrayUtils . combine ( new Object [ ] { usingFacts } , otherArgs , method . getParameterCount ( ) ) ) ; 
} catch ( IllegalAccessException | InvocationTargetException err ) { 
if ( _ruleState == BREAK ) { 
_nextRule . ifPresent ( rule -> rule . given ( _facts ) ) ; 
_nextRule . ifPresent ( Rule :: run ) ; 
public Rule < T > given ( String name , T value ) { 
_facts . put ( name , new Fact < T > ( name , value ) ) ; 
public Rule < T > given ( Fact < T > ... facts ) { 
for ( Fact f : facts ) { 
_facts . put ( f . getName ( ) , f ) ; 
public Rule < T > when ( Predicate < FactMap < T > > test ) { 
_test = test ; 
public Rule < T > then ( Consumer < FactMap < T > > action ) { 
_actionChain . add ( action ) ; 
public StandardRule < T > using ( String ... factNames ) { 
List < String > factNameList = Stream . of ( factNames ) 
. filter ( name -> _factType . isInstance ( _facts . getValue ( name ) ) ) 
if ( _factNameMap . containsKey ( ( getThen ( ) ) . size ( ) ) ) { 
List < String > existingFactNames = _factNameMap . get ( ( getThen ( ) ) . size ( ) ) ; 
existingFactNames . addAll ( factNameList ) ; 
_factNameMap . put ( ( getThen ( ) ) . size ( ) , factNameList ) ; 
} public void addRule ( Decision < T , U > rule ) { 
super . addRule ( rule ) ; 
rule . setResult ( _result ) ; 
} public ThenRuleBuilder < T , U > then ( Consumer < NameValueReferableTypeConvertibleMap < T > > action ) { 
_rule . addAction ( action ) ; 
} public ThenRuleBuilder < T , U > then ( BiConsumer < NameValueReferableTypeConvertibleMap < T > , Result < U > > action ) { 
} public RuleBookDefaultResultBuilder < T > withDefaultResult ( T result ) { 
_ruleBook . setDefaultResult ( result ) ; 
return new RuleBookDefaultResultBuilder < > ( _ruleBook ) ; 
} public void reset ( ) { 
if ( _defaultValue == null ) { 
setValue ( _defaultValue ) ; 
long key = Thread . currentThread ( ) . getId ( ) ; 
if ( _valueMap . containsKey ( key ) ) { 
return _valueMap . get ( Thread . currentThread ( ) . getId ( ) ) ; 
return _defaultValue ; 
public void setValue ( T value ) { 
_valueMap . put ( Thread . currentThread ( ) . getId ( ) , value ) ; 
return new RuleBookAddRuleBuilder < > ( _ruleBook , consumer ) ; 
return new RuleBookAddRuleBuilder < > ( _ruleBook , rule ) ; 
public < T > RuleBookRuleWithFactTypeBuilder < T , U > withFactType ( Class < T > factType ) { 
Rule < T , U > rule = ( Rule < T , U > ) RuleBuilder . create ( _ruleClass ) . withFactType ( factType ) . build ( ) ; 
_ruleBook . addRule ( rule ) ; 
return new RuleBookRuleWithFactTypeBuilder < > ( rule ) ; 
} protected List < Class < ? > > getPojoRules ( ) { 
Reflections reflections = new Reflections ( _package ) ; 
List < Class < ? > > rules = reflections 
. getTypesAnnotatedWith ( com . deliveredtechnologies . rulebook . annotation . Rule . class ) . stream ( ) 
. filter ( rule -> rule . getAnnotatedSuperclass ( ) != null ) 
. filter ( rule -> _subPkgMatch . test ( rule . getPackage ( ) . getName ( ) ) ) 
rules . sort ( comparingInt ( aClass -> 
getAnnotation ( com . deliveredtechnologies . rulebook . annotation . Rule . class , aClass ) . order ( ) ) ) ; 
return rules ; 
public static < T > T [ ] combine ( T [ ] array1 , T [ ] array2 ) { 
return combine ( array1 , array2 , array1 . length + array2 . length ) ; 
public static < T > T [ ] combine ( T [ ] array1 , T [ ] array2 , int maxElements ) { 
if ( array1 . length == maxElements ) { 
return array1 ; 
} else if ( array1 . length > maxElements ) { 
T [ ] combinedArray = ( T [ ] ) Array . newInstance ( array1 . getClass ( ) . getComponentType ( ) , maxElements ) ; 
System . arraycopy ( array1 , 0 , combinedArray , 0 , maxElements ) ; 
return combinedArray ; 
maxElements = array1 . length + array2 . length >= maxElements ? maxElements : array1 . length + array2 . length ; 
System . arraycopy ( array1 , 0 , combinedArray , 0 , array1 . length ) ; 
System . arraycopy ( array2 , 0 , combinedArray , array1 . length , maxElements - array1 . length ) ; 
} private String readEmptyLineOrEndTable ( final BufferedReader tableContent ) throws IOException { 
final String column = tableContent . readLine ( ) ; 
if ( column != null && column . startsWith ( END_TABLE ) ) { 
return END_TABLE ; 
if ( column == null || ! column . isEmpty ( ) ) { 
} private void skipUntilColumns ( final BufferedReader tableContent ) throws IOException { 
String line ; 
while ( ( line = tableContent . readLine ( ) ) != null ) { 
if ( line . trim ( ) . isEmpty ( ) ) { 
} private ObjectMeta createDeploymentConfigMetaData ( ResourceConfig config ) { 
return new ObjectMetaBuilder ( ) 
. build ( ) ; 
} private void addServices ( KubernetesListBuilder builder ) { 
ResourceConfig resources = new ResourceConfig ( ) ; 
if ( resources != null && resources . getServices ( ) != null ) { 
List < ServiceConfig > serviceConfig = resources . getServices ( ) ; 
ServiceHandler serviceHandler = new ServiceHandler ( ) ; 
builder . addToServiceItems ( toArray ( serviceHandler . getServices ( serviceConfig ) ) ) ; 
} private Service [ ] toArray ( List < Service > services ) { 
if ( services == null ) { 
return new Service [ 0 ] ; 
if ( services instanceof ArrayList ) { 
return ( ( ArrayList < Service > ) services ) . toArray ( new Service [ services . size ( ) ] ) ; 
Service [ ] ret = new Service [ services . size ( ) ] ; 
for ( int i = 0 ; i < services . size ( ) ; i ++ ) { 
ret [ i ] = services . get ( i ) ; 
} private Map < String , String > extractLabels ( ) { 
Map < String , String > labels = new HashMap < > ( ) ; 
if ( Configs . asBoolean ( getConfig ( Config . expose ) ) ) { 
labels . put ( "expose" , "true" ) ; 
return labels ; 
} private List < ServicePort > extractPorts ( List < ImageConfiguration > images ) { 
List < ServicePort > ret = new ArrayList < > ( ) ; 
boolean isMultiPort = Boolean . parseBoolean ( getConfig ( Config . multiPort ) ) ; 
List < ServicePort > configuredPorts = extractPortsFromConfig ( ) ; 
for ( ImageConfiguration image : images ) { 
Map < String , String > labels = extractLabelsFromConfig ( image ) ; 
List < String > podPorts = getPortsFromBuildConfiguration ( image ) ; 
List < String > portsFromImageLabels = getLabelWithService ( labels ) ; 
if ( podPorts . isEmpty ( ) ) { 
if ( portsFromImageLabels == null || portsFromImageLabels . isEmpty ( ) ) { 
addPortIfNotNull ( ret , extractPortsFromImageSpec ( image . getName ( ) , podPorts . remove ( 0 ) , shiftOrNull ( configuredPorts ) , null ) ) ; 
for ( String imageLabelPort : portsFromImageLabels ) { 
addPortIfNotNull ( ret , extractPortsFromImageSpec ( image . getName ( ) , podPorts . remove ( 0 ) , shiftOrNull ( configuredPorts ) , imageLabelPort ) ) ; 
if ( isMultiPort ) { 
for ( String port : podPorts ) { 
addPortIfNotNull ( ret , extractPortsFromImageSpec ( image . getName ( ) , port , shiftOrNull ( configuredPorts ) , null ) ) ; 
ret . addAll ( mirrorMissingTargetPorts ( configuredPorts ) ) ; 
} else if ( ret . isEmpty ( ) && ! configuredPorts . isEmpty ( ) ) { 
ret . addAll ( mirrorMissingTargetPorts ( Collections . singletonList ( configuredPorts . get ( 0 ) ) ) ) ; 
} private List < String > getPortsFromBuildConfiguration ( ImageConfiguration image ) { 
BuildImageConfiguration buildConfig = image . getBuildConfiguration ( ) ; 
if ( buildConfig == null ) { 
return buildConfig . getPorts ( ) ; 
} private List < ServicePort > extractPortsFromConfig ( ) { 
List < ServicePort > ret = new LinkedList < > ( ) ; 
String ports = getConfig ( Config . port ) ; 
if ( ports != null ) { 
for ( String port : StringUtils . split ( ports , "," ) ) { 
ret . add ( parsePortMapping ( port ) ) ; 
} private ServicePort parsePortMapping ( String port ) { 
Matcher matcher = PORT_MAPPING_PATTERN . matcher ( port ) ; 
if ( ! matcher . matches ( ) ) { 
int servicePort = Integer . parseInt ( matcher . group ( "port" ) ) ; 
String optionalTargetPort = matcher . group ( "targetPort" ) ; 
String protocol = getProtocol ( matcher . group ( "protocol" ) ) ; 
ServicePortBuilder builder = new ServicePortBuilder ( ) 
. withPort ( servicePort ) 
. withProtocol ( protocol ) 
. withName ( getDefaultPortName ( servicePort , protocol ) ) ; 
if ( optionalTargetPort != null ) { 
builder . withNewTargetPort ( Integer . parseInt ( optionalTargetPort ) ) ; 
return builder . build ( ) ; 
} private void addPortIfNotNull ( List < ServicePort > ret , ServicePort port ) { 
if ( port != null ) { 
ret . add ( port ) ; 
} private ServicePort shiftOrNull ( List < ServicePort > ports ) { 
if ( ! ports . isEmpty ( ) ) { 
return ports . remove ( 0 ) ; 
} private String getDefaultServiceName ( Service defaultService ) { 
String defaultServiceName = KubernetesHelper . getName ( defaultService ) ; 
if ( StringUtils . isBlank ( defaultServiceName ) ) { 
defaultServiceName = getContext ( ) . getGav ( ) . getSanitizedArtifactId ( ) ; 
return defaultServiceName ; 
} private void addMissingServiceParts ( ServiceBuilder service , Service defaultService ) { 
if ( ! service . hasSpec ( ) ) { 
service . withNewSpecLike ( defaultService . getSpec ( ) ) . endSpec ( ) ; 
List < ServicePort > ports = service . buildSpec ( ) . getPorts ( ) ; 
if ( ports == null || ports . isEmpty ( ) ) { 
service . editSpec ( ) . withPorts ( defaultService . getSpec ( ) . getPorts ( ) ) . endSpec ( ) ; 
service . editSpec ( ) 
. withPorts ( addMissingDefaultPorts ( ports , defaultService ) ) 
. endSpec ( ) ; 
} public void appendImageStreamResource ( ImageName imageName , File target ) throws MojoExecutionException { 
String tag = StringUtils . isBlank ( imageName . getTag ( ) ) ? "latest" : imageName . getTag ( ) ; 
ImageStream is = new ImageStreamBuilder ( ) 
. withNewMetadata ( ) 
. withName ( imageName . getSimpleName ( ) ) 
. endMetadata ( ) 
. withNewSpec ( ) 
. addNewTag ( ) 
. withName ( tag ) 
. withNewFrom ( ) . withKind ( "ImageStreamImage" ) . endFrom ( ) 
. endTag ( ) 
. endSpec ( ) 
createOrUpdateImageStreamTag ( client , imageName , is ) ; 
appendImageStreamToFile ( is , target ) ; 
} catch ( KubernetesClientException e ) { 
KubernetesResourceUtil . handleKubernetesClientException ( e , this . log ) ; 
imageName . getFullName ( ) , target . getAbsoluteFile ( ) , e . getMessage ( ) ) , e ) ; 
} public static String getServiceURL ( KubernetesClient client , String serviceName , String serviceNamespace , String serviceProtocol , boolean serviceExternal ) { 
Service srv = null ; 
String serviceHost = serviceToHostOrBlank ( serviceName ) ; 
String servicePort = serviceToPortOrBlank ( serviceName ) ; 
String serviceProto = serviceProtocol != null ? serviceProtocol : serviceToProtocol ( serviceName , servicePort ) ; 
String actualNamespace = StringUtils . isNotBlank ( serviceNamespace ) ? serviceNamespace : client . getNamespace ( ) ; 
if ( ! serviceExternal && StringUtils . isNotBlank ( serviceHost ) && StringUtils . isNotBlank ( servicePort ) && StringUtils . isNotBlank ( serviceProtocol ) ) { 
return serviceProtocol + "://" + serviceHost + ":" + servicePort ; 
} else if ( StringUtils . isNotBlank ( actualNamespace ) ) { 
srv = client . services ( ) . inNamespace ( actualNamespace ) . withName ( serviceName ) . get ( ) ; 
if ( srv == null ) { 
String hostAndPort = getServiceHostAndPort ( serviceName , "" , "" ) ; 
if ( ! hostAndPort . startsWith ( ":" ) ) { 
return serviceProto + "://" + hostAndPort ; 
String answer = KubernetesHelper . getOrCreateAnnotations ( srv ) . get ( Fabric8Annotations . SERVICE_EXPOSE_URL . toString ( ) ) ; 
if ( StringUtils . isNotBlank ( answer ) ) { 
return answer ; 
if ( OpenshiftHelper . isOpenShift ( client ) ) { 
OpenShiftClient openShiftClient = client . adapt ( OpenShiftClient . class ) ; 
Route route = openShiftClient . routes ( ) . inNamespace ( actualNamespace ) . withName ( serviceName ) . get ( ) ; 
if ( route != null ) { 
return ( serviceProto + "://" + route . getSpec ( ) . getHost ( ) ) . toLowerCase ( ) ; 
ServicePort port = findServicePortByName ( srv , null ) ; 
if ( port == null ) { 
String clusterIP = srv . getSpec ( ) . getClusterIP ( ) ; 
if ( "None" . equals ( clusterIP ) ) { 
Integer portNumber = port . getPort ( ) ; 
if ( StringUtils . isBlank ( clusterIP ) ) { 
IngressList ingresses = client . extensions ( ) . ingresses ( ) . inNamespace ( serviceNamespace ) . list ( ) ; 
if ( ingresses != null ) { 
List < Ingress > items = ingresses . getItems ( ) ; 
if ( items != null ) { 
for ( Ingress item : items ) { 
String ns = KubernetesHelper . getNamespace ( item ) ; 
if ( Objects . equal ( serviceNamespace , ns ) ) { 
IngressSpec spec = item . getSpec ( ) ; 
if ( spec != null ) { 
List < IngressRule > rules = spec . getRules ( ) ; 
List < IngressTLS > tls = spec . getTls ( ) ; 
if ( rules != null ) { 
for ( IngressRule rule : rules ) { 
HTTPIngressRuleValue http = rule . getHttp ( ) ; 
if ( http != null ) { 
List < HTTPIngressPath > paths = http . getPaths ( ) ; 
if ( paths != null ) { 
for ( HTTPIngressPath path : paths ) { 
IngressBackend backend = path . getBackend ( ) ; 
if ( backend != null ) { 
String backendServiceName = backend . getServiceName ( ) ; 
if ( serviceName . equals ( backendServiceName ) && portsMatch ( port , backend . getServicePort ( ) ) ) { 
String pathPostfix = path . getPath ( ) ; 
if ( tls != null ) { 
for ( IngressTLS tlsHost : tls ) { 
List < String > hosts = tlsHost . getHosts ( ) ; 
if ( hosts != null ) { 
for ( String host : hosts ) { 
if ( StringUtils . isNotBlank ( host ) ) { 
return String . format ( "https://%s/%s" , host , preparePath ( pathPostfix ) ) ; 
answer = rule . getHost ( ) ; 
return String . format ( "http://%s/%s" , answer , preparePath ( pathPostfix ) ) ; 
ServiceStatus status = srv . getStatus ( ) ; 
if ( status != null ) { 
LoadBalancerStatus loadBalancerStatus = status . getLoadBalancer ( ) ; 
if ( loadBalancerStatus != null ) { 
List < LoadBalancerIngress > loadBalancerIngresses = loadBalancerStatus . getIngress ( ) ; 
if ( loadBalancerIngresses != null ) { 
for ( LoadBalancerIngress loadBalancerIngress : loadBalancerIngresses ) { 
String ip = loadBalancerIngress . getIp ( ) ; 
if ( StringUtils . isNotBlank ( ip ) ) { 
clusterIP = ip ; 
Integer nodePort = port . getNodePort ( ) ; 
if ( nodePort != null ) { 
NodeList nodeList = client . nodes ( ) . list ( ) ; 
if ( nodeList != null ) { 
List < Node > items = nodeList . getItems ( ) ; 
for ( Node item : items ) { 
NodeStatus status = item . getStatus ( ) ; 
if ( ! found && status != null ) { 
List < NodeAddress > addresses = status . getAddresses ( ) ; 
if ( addresses != null ) { 
for ( NodeAddress address : addresses ) { 
String ip = address . getAddress ( ) ; 
portNumber = nodePort ; 
NodeSpec spec = item . getSpec ( ) ; 
clusterIP = spec . getExternalID ( ) ; 
if ( StringUtils . isNotBlank ( clusterIP ) ) { 
return ( serviceProto + "://" + clusterIP + ":" + portNumber ) . toLowerCase ( ) ; 
} private static boolean portsMatch ( ServicePort servicePort , IntOrString intOrString ) { 
if ( intOrString != null ) { 
Integer port = servicePort . getPort ( ) ; 
Integer intVal = intOrString . getIntVal ( ) ; 
String strVal = intOrString . getStrVal ( ) ; 
if ( intVal != null ) { 
return port . intValue ( ) == intVal . intValue ( ) ; 
} else if ( strVal != null ) { 
return Objects . equal ( strVal , servicePort . getName ( ) ) ; 
} private static String serviceToPortOrBlank ( String serviceName ) { 
String envVarName = toServicePortEnvironmentVariable ( serviceName ) ; 
return getEnvVarOrSystemProperty ( envVarName , "" ) ; 
} private static String getServiceHostAndPort ( String serviceName , String defaultHost , String defaultPort ) { 
String serviceEnvVarPrefix = getServiceEnvVarPrefix ( serviceName ) ; 
String hostEnvVar = serviceEnvVarPrefix + "_HOST" ; 
String portEnvVar = serviceEnvVarPrefix + "_PORT" ; 
String host = getEnvVarOrSystemProperty ( hostEnvVar , hostEnvVar , defaultHost ) ; 
String port = getEnvVarOrSystemProperty ( portEnvVar , portEnvVar , defaultPort ) ; 
String answer = host + ":" + port ; 
} public static void putIfAbsent ( Map < String , String > map , String name , String value ) { 
if ( ! map . containsKey ( name ) ) { 
map . put ( name , value ) ; 
} public static void mergeIfAbsent ( Map < String , String > map , Map < String , String > toMerge ) { 
for ( Map . Entry < String , String > entry : toMerge . entrySet ( ) ) { 
putIfAbsent ( map , entry . getKey ( ) , entry . getValue ( ) ) ; ; 
} public static < K , V > Map < K , V > mergeMaps ( Map < K , V > map1 , Map < K , V > map2 ) { 
Map < K , V > answer = new HashMap < > ( ) ; 
if ( map2 != null ) { 
answer . putAll ( map2 ) ; 
if ( map1 != null ) { 
answer . putAll ( map1 ) ; 
} public static void putAllIfNotNull ( Map < String , String > ret , Map < String , String > toPut ) { 
if ( toPut != null ) { 
ret . putAll ( toPut ) ; 
} private void ensureTemplateSpecs ( KubernetesListBuilder builder ) { 
ensureTemplateSpecsInReplicationControllers ( builder ) ; 
ensureTemplateSpecsInRelicaSet ( builder ) ; 
ensureTemplateSpecsInDeployments ( builder ) ; 
ensureTemplateSpecsInDaemonSet ( builder ) ; 
ensureTemplateSpecsInStatefulSet ( builder ) ; 
ensureTemplateSpecsInDeploymentConfig ( builder ) ; 
} private void updateContainers ( KubernetesListBuilder builder ) { 
builder . accept ( new TypedVisitor < PodTemplateSpecBuilder > ( ) { 
public void visit ( PodTemplateSpecBuilder templateBuilder ) { 
PodTemplateSpecFluent . SpecNested < PodTemplateSpecBuilder > podSpec = 
templateBuilder . getSpec ( ) == null ? templateBuilder . withNewSpec ( ) : templateBuilder . editSpec ( ) ; 
List < Container > containers = podSpec . getContainers ( ) ; 
if ( containers == null ) { 
containers = new ArrayList < Container > ( ) ; 
mergeImageConfigurationWithContainerSpec ( containers ) ; 
podSpec . withContainers ( containers ) . endSpec ( ) ; 
} private void mergeImageConfigurationWithContainerSpec ( List < Container > containers ) { 
getImages ( ) . ifPresent ( images -> { 
int idx = 0 ; 
Container container = getContainer ( idx , containers ) ; 
mergeImagePullPolicy ( image , container ) ; 
mergeImage ( image , container ) ; 
mergeContainerName ( image , container ) ; 
mergeEnvVariables ( container ) ; 
idx ++ ; 
} private void waitUntilPodIsReady ( String podName , int nAwaitTimeout , final Logger log ) throws InterruptedException { 
final CountDownLatch readyLatch = new CountDownLatch ( 1 ) ; 
try ( Watch watch = client . pods ( ) . withName ( podName ) . watch ( new Watcher < Pod > ( ) { 
public void eventReceived ( Action action , Pod aPod ) { 
if ( KubernetesHelper . isPodReady ( aPod ) ) { 
readyLatch . countDown ( ) ; 
public void onClose ( KubernetesClientException e ) { 
} ) ) { 
readyLatch . await ( nAwaitTimeout , TimeUnit . SECONDS ) ; 
} catch ( KubernetesClientException | InterruptedException e ) { 
} private String getS2IBuildName ( BuildServiceConfig config , ImageName imageName ) { 
return imageName . getSimpleName ( ) + config . getS2iBuildNameSuffix ( ) ; 
} private static EntityPatcher < BuildConfig > bcPatcher ( ) { 
return ( KubernetesClient client , String namespace , BuildConfig newObj , BuildConfig oldObj ) -> { 
if ( UserConfigurationCompare . configEqual ( newObj , oldObj ) ) { 
return oldObj ; 
OpenShiftClient openShiftClient = OpenshiftHelper . asOpenShiftClient ( client ) ; 
if ( openShiftClient == null ) { 
DoneableBuildConfig entity = 
openShiftClient . buildConfigs ( ) 
. inNamespace ( namespace ) 
. withName ( oldObj . getMetadata ( ) . getName ( ) ) 
. edit ( ) ; 
if ( ! UserConfigurationCompare . configEqual ( newObj . getMetadata ( ) , oldObj . getMetadata ( ) ) ) { 
entity . withMetadata ( newObj . getMetadata ( ) ) ; 
if ( ! UserConfigurationCompare . configEqual ( newObj . getSpec ( ) , oldObj . getSpec ( ) ) ) { 
entity . withSpec ( newObj . getSpec ( ) ) ; 
return entity . done ( ) ; 
} public static String validateKubernetesId ( String currentValue , String description ) throws IllegalArgumentException { 
if ( StringUtils . isBlank ( currentValue ) ) { 
int size = currentValue . length ( ) ; 
char ch = currentValue . charAt ( i ) ; 
if ( Character . isUpperCase ( ch ) ) { 
return currentValue ; 
public static List < HasMetadata > toItemList ( Object entity ) throws IOException { 
if ( entity instanceof List ) { 
return ( List < HasMetadata > ) entity ; 
} else if ( entity instanceof HasMetadata [ ] ) { 
HasMetadata [ ] array = ( HasMetadata [ ] ) entity ; 
return Arrays . asList ( array ) ; 
} else if ( entity instanceof KubernetesList ) { 
KubernetesList config = ( KubernetesList ) entity ; 
return config . getItems ( ) ; 
} else if ( entity instanceof Template ) { 
Template objects = ( Template ) entity ; 
return objects . getObjects ( ) ; 
List < HasMetadata > answer = new ArrayList < > ( ) ; 
if ( entity instanceof HasMetadata ) { 
answer . add ( ( HasMetadata ) entity ) ; 
} public static String getResourceVersion ( HasMetadata entity ) { 
if ( entity != null ) { 
ObjectMeta metadata = entity . getMetadata ( ) ; 
String resourceVersion = metadata . getResourceVersion ( ) ; 
if ( StringUtils . isNotBlank ( resourceVersion ) ) { 
return resourceVersion ; 
} public static IntOrString createIntOrString ( int intVal ) { 
IntOrString answer = new IntOrString ( ) ; 
answer . setIntVal ( intVal ) ; 
answer . setKind ( 0 ) ; 
} public static IntOrString createIntOrString ( String nameOrNumber ) { 
if ( StringUtils . isBlank ( nameOrNumber ) ) { 
Integer intVal = null ; 
intVal = Integer . parseInt ( nameOrNumber ) ; 
answer . setStrVal ( nameOrNumber ) ; 
answer . setKind ( 1 ) ; 
} public static boolean isPodReady ( Pod pod ) { 
if ( ! isPodRunning ( pod ) ) { 
PodStatus podStatus = pod . getStatus ( ) ; 
if ( podStatus == null ) { 
List < PodCondition > conditions = podStatus . getConditions ( ) ; 
if ( conditions == null || conditions . isEmpty ( ) ) { 
for ( PodCondition condition : conditions ) { 
if ( "ready" . equalsIgnoreCase ( condition . getType ( ) ) ) { 
return Boolean . parseBoolean ( condition . getStatus ( ) ) ; 
} private static Context getCurrentContext ( Config config ) { 
String contextName = config . getCurrentContext ( ) ; 
if ( contextName != null ) { 
List < NamedContext > contexts = config . getContexts ( ) ; 
if ( contexts != null ) { 
for ( NamedContext context : contexts ) { 
if ( Objects . equals ( contextName , context . getName ( ) ) ) { 
return context . getContext ( ) ; 
} private boolean hasRoute ( final KubernetesListBuilder listBuilder , final String name ) { 
final AtomicBoolean answer = new AtomicBoolean ( false ) ; 
listBuilder . accept ( new TypedVisitor < RouteBuilder > ( ) { 
public void visit ( RouteBuilder builder ) { 
ObjectMeta metadata = builder . getMetadata ( ) ; 
if ( metadata != null && name . equals ( metadata . getName ( ) ) ) { 
answer . set ( true ) ; 
return answer . get ( ) ; 
} protected static String replaceProperties ( String text , Properties properties ) { 
Set < Map . Entry < Object , Object > > entries = properties . entrySet ( ) ; 
for ( Map . Entry < Object , Object > entry : entries ) { 
Object key = entry . getKey ( ) ; 
Object value = entry . getValue ( ) ; 
if ( key != null && value != null ) { 
String pattern = "${" + key + "}" ; 
text = StringUtils . replace ( text , pattern , value . toString ( ) ) ; 
return text ; 
} private static void addShutdownHook ( final Logger log , final Process process , final File command ) { 
Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( command . getName ( ) ) { 
if ( process != null ) { 
boolean alive = false ; 
process . exitValue ( ) ; 
} catch ( IllegalThreadStateException e ) { 
alive = true ; 
if ( alive ) { 
process . destroy ( ) ; 
} public Closeable forwardPortAsync ( final Logger externalProcessLogger , final LabelSelector podSelector , final int remotePort , final int localPort ) throws Fabric8ServiceException { 
final Lock monitor = new ReentrantLock ( true ) ; 
final Condition podChanged = monitor . newCondition ( ) ; 
final Pod [ ] nextForwardedPod = new Pod [ 1 ] ; 
final Thread forwarderThread = new Thread ( ) { 
Pod currentPod = null ; 
Closeable currentPortForward = null ; 
monitor . lock ( ) ; 
if ( podEquals ( currentPod , nextForwardedPod [ 0 ] ) ) { 
podChanged . await ( ) ; 
Pod nextPod = nextForwardedPod [ 0 ] ; 
monitor . unlock ( ) ; 
if ( currentPortForward != null ) { 
currentPortForward . close ( ) ; 
currentPortForward = null ; 
if ( nextPod != null ) { 
currentPortForward = forwardPortAsync ( externalProcessLogger , KubernetesHelper . getName ( nextPod ) , remotePort , localPort ) ; 
currentPod = nextPod ; 
} catch ( Exception e ) { } 
Pod newPod = getNewestPod ( podSelector ) ; 
nextForwardedPod [ 0 ] = newPod ; 
final Watch watch = KubernetesClientUtil . withSelector ( kubernetes . pods ( ) , podSelector , log ) . watch ( new Watcher < Pod > ( ) { 
public void eventReceived ( Action action , Pod pod ) { 
List < Pod > candidatePods ; 
if ( nextForwardedPod [ 0 ] != null ) { 
candidatePods = new LinkedList < > ( ) ; 
candidatePods . add ( nextForwardedPod [ 0 ] ) ; 
candidatePods . add ( pod ) ; 
candidatePods = Collections . singletonList ( pod ) ; 
Pod newPod = getNewestPod ( candidatePods ) ; 
if ( ! podEquals ( nextForwardedPod [ 0 ] , newPod ) ) { 
podChanged . signal ( ) ; 
forwarderThread . start ( ) ; 
final Closeable handle = ( ) -> { 
watch . close ( ) ; 
forwarderThread . interrupt ( ) ; 
forwarderThread . join ( 15000 ) ; 
Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ) { 
handle . close ( ) ; 
return handle ; 
} private static URLClassLoader createClassLoader ( List < String > classpathElements , String ... paths ) { 
List < URL > urls = new ArrayList < > ( ) ; 
for ( String path : paths ) { 
URL url = pathToUrl ( path ) ; 
urls . add ( url ) ; 
for ( Object object : classpathElements ) { 
if ( object != null ) { 
String path = object . toString ( ) ; 
return createURLClassLoader ( urls ) ; 
} public static boolean hasDependency ( MavenProject project , String groupId , String artifactId ) { 
return getDependencyVersion ( project , groupId , artifactId ) != null ; 
} public static String getDependencyVersion ( MavenProject project , String groupId , String artifactId ) { 
Set < Artifact > artifacts = project . getArtifacts ( ) ; 
if ( artifacts != null ) { 
for ( Artifact artifact : artifacts ) { 
String scope = artifact . getScope ( ) ; 
if ( Objects . equal ( "test" , scope ) ) { 
if ( artifactId != null && ! Objects . equal ( artifactId , artifact . getArtifactId ( ) ) ) { 
if ( Objects . equal ( groupId , artifact . getGroupId ( ) ) ) { 
return artifact . getVersion ( ) ; 
} public static Plugin getPlugin ( MavenProject project , String groupId , String artifactId ) { 
if ( artifactId == null ) { 
List < Plugin > plugins = project . getBuildPlugins ( ) ; 
if ( plugins != null ) { 
for ( Plugin plugin : plugins ) { 
boolean matchesArtifactId = artifactId . equals ( plugin . getArtifactId ( ) ) ; 
boolean matchesGroupId = groupId == null || groupId . equals ( plugin . getGroupId ( ) ) ; 
if ( matchesGroupId && matchesArtifactId ) { 
return plugin ; 
} public static boolean hasResource ( MavenProject project , String ... paths ) { 
URLClassLoader compileClassLoader = getCompileClassLoader ( project ) ; 
if ( compileClassLoader . getResource ( path ) != null ) { 
} public static String getVersion ( String groupId , String artifactId ) throws IOException { 
String path = "META-INF/maven/" + groupId + "/" + artifactId + "/pom.properties" ; 
InputStream in = MavenUtil . class . getClassLoader ( ) . getResourceAsStream ( path ) ; 
if ( in == null ) { 
Properties properties = new Properties ( ) ; 
properties . load ( in ) ; 
String version = properties . getProperty ( "version" ) ; 
if ( StringUtils . isBlank ( version ) ) { 
return version ; 
} public boolean isOpenShiftImageStream ( Logger log ) { 
if ( isOpenShift ( log ) ) { 
OpenShiftClient openShiftClient = null ; 
if ( this . client == null ) { 
openShiftClient = createOpenShiftClient ( ) ; 
} else if ( this . client instanceof OpenShiftClient ) { 
openShiftClient = ( OpenShiftClient ) this . client ; 
} else if ( this . client . isAdaptable ( OpenShiftClient . class ) ) { 
openShiftClient = client . adapt ( OpenShiftClient . class ) ; 
return openShiftClient . supportsOpenShiftAPIGroup ( OpenShiftAPIGroups . IMAGE ) ; 
} public static KubernetesListBuilder readResourceFragmentsFrom ( PlatformMode platformMode , ResourceVersioning apiVersions , 
String defaultName , 
File [ ] resourceFiles ) throws IOException { 
KubernetesListBuilder builder = new KubernetesListBuilder ( ) ; 
if ( resourceFiles != null ) { 
for ( File file : resourceFiles ) { 
HasMetadata resource = getResource ( platformMode , apiVersions , file , defaultName ) ; 
builder . addToItems ( resource ) ; 
} public static HasMetadata getResource ( PlatformMode platformMode , ResourceVersioning apiVersions , 
File file , String appName ) throws IOException { 
Map < String , Object > fragment = readAndEnrichFragment ( platformMode , apiVersions , file , appName ) ; 
return mapper . convertValue ( fragment , HasMetadata . class ) ; 
} catch ( ClassCastException exp ) { 
} private static Map < String , Object > readAndEnrichFragment ( PlatformMode platformMode , ResourceVersioning apiVersions , 
Pattern pattern = Pattern . compile ( FILENAME_PATTERN , Pattern . CASE_INSENSITIVE ) ; 
Matcher matcher = pattern . matcher ( file . getName ( ) ) ; 
String name = matcher . group ( "name" ) ; 
String type = matcher . group ( "type" ) ; 
String ext = matcher . group ( "ext" ) . toLowerCase ( ) ; 
String kind ; 
Map < String , Object > fragment = readFragment ( file , ext ) ; 
if ( type != null ) { 
kind = getAndValidateKindFromType ( file , type ) ; 
kind = FILENAME_TO_KIND_MAPPER . get ( name . toLowerCase ( ) ) ; 
if ( kind != null ) { 
name = null ; 
addKind ( fragment , kind , file . getName ( ) ) ; 
String apiVersion = apiVersions . getCoreVersion ( ) ; 
if ( Objects . equals ( kind , "Ingress" ) ) { 
apiVersion = apiVersions . getExtensionsVersion ( ) ; 
} else if ( Objects . equals ( kind , "StatefulSet" ) || Objects . equals ( kind , "Deployment" ) ) { 
apiVersion = apiVersions . getAppsVersion ( ) ; 
} else if ( Objects . equals ( kind , "Job" ) ) { 
apiVersion = apiVersions . getJobVersion ( ) ; 
} else if ( Objects . equals ( kind , "DeploymentConfig" ) && platformMode == PlatformMode . openshift ) { 
apiVersion = apiVersions . getOpenshiftV1version ( ) ; 
addIfNotExistent ( fragment , "apiVersion" , apiVersion ) ; 
Map < String , Object > metaMap = getMetadata ( fragment ) ; 
addIfNotExistent ( metaMap , "name" , StringUtils . isNotBlank ( name ) ? name : appName ) ; 
return fragment ; 
} private static Map < String , Object > getMetadata ( Map < String , Object > fragment ) { 
Object mo = fragment . get ( "metadata" ) ; 
Map < String , Object > meta ; 
if ( mo == null ) { 
meta = new HashMap < > ( ) ; 
fragment . put ( "metadata" , meta ) ; 
return meta ; 
} else if ( mo instanceof Map ) { 
return ( Map < String , Object > ) mo ; 
} public static List < EnvVar > convertToEnvVarList ( Map < String , String > envVars ) { 
List < EnvVar > envList = new LinkedList < > ( ) ; 
for ( Map . Entry < String , String > entry : envVars . entrySet ( ) ) { 
String name = entry . getKey ( ) ; 
String value = entry . getValue ( ) ; 
EnvVar env = new EnvVarBuilder ( ) . withName ( name ) . withValue ( value ) . build ( ) ; 
envList . add ( env ) ; 
return envList ; 
} public static void mergeSimpleFields ( Object targetValues , Object defaultValues ) { 
Class < ? > tc = targetValues . getClass ( ) ; 
Class < ? > sc = defaultValues . getClass ( ) ; 
for ( Method targetGetMethod : tc . getMethods ( ) ) { 
if ( ! targetGetMethod . getName ( ) . startsWith ( "get" ) ) { 
Class < ? > fieldType = targetGetMethod . getReturnType ( ) ; 
if ( ! SIMPLE_FIELD_TYPES . contains ( fieldType ) ) { 
String fieldName = targetGetMethod . getName ( ) . substring ( 3 ) ; 
Method withMethod = null ; 
withMethod = tc . getMethod ( "with" + fieldName , fieldType ) ; 
} catch ( NoSuchMethodException e ) { 
withMethod = tc . getMethod ( "set" + fieldName , fieldType ) ; 
} catch ( NoSuchMethodException e2 ) { 
Method sourceGetMethod = null ; 
sourceGetMethod = sc . getMethod ( "get" + fieldName ) ; 
if ( targetGetMethod . invoke ( targetValues ) == null ) { 
withMethod . invoke ( targetValues , sourceGetMethod . invoke ( defaultValues ) ) ; 
} catch ( InvocationTargetException e ) { 
throw new RuntimeException ( e . getCause ( ) ) ; 
} public static HasMetadata mergeResources ( HasMetadata item1 , HasMetadata item2 , Logger log , boolean switchOnLocalCustomisation ) { 
if ( item1 instanceof Deployment && item2 instanceof Deployment ) { 
return mergeDeployments ( ( Deployment ) item1 , ( Deployment ) item2 , log , switchOnLocalCustomisation ) ; 
if ( item1 instanceof ConfigMap && item2 instanceof ConfigMap ) { 
ConfigMap cm1 = ( ConfigMap ) item1 ; 
ConfigMap cm2 = ( ConfigMap ) item2 ; 
return mergeConfigMaps ( cm1 , cm2 , log , switchOnLocalCustomisation ) ; 
mergeMetadata ( item1 , item2 ) ; 
return item1 ; 
} private static Map < String , String > mergeMapsAndRemoveEmptyStrings ( Map < String , String > overrideMap , Map < String , String > originalMap ) { 
Map < String , String > answer = MapUtil . mergeMaps ( overrideMap , originalMap ) ; 
Set < Map . Entry < String , String > > entries = overrideMap . entrySet ( ) ; 
for ( Map . Entry < String , String > entry : entries ) { 
if ( value == null || value . isEmpty ( ) ) { 
String key = entry . getKey ( ) ; 
answer . remove ( key ) ; 
} private static boolean isLocalCustomisation ( PodSpec podSpec ) { 
List < Container > containers = podSpec . getContainers ( ) != null ? podSpec . getContainers ( ) : Collections . < Container > emptyList ( ) ; 
for ( Container container : containers ) { 
if ( StringUtils . isNotBlank ( container . getImage ( ) ) ) { 
} private Map < String , String > readConfig ( File f ) throws IOException { 
Map < String , String > map ; 
if ( f . getName ( ) . endsWith ( JSON_EXTENSION ) ) { 
map = flatten ( JSON_MAPPER . readValue ( f , Map . class ) ) ; 
} else if ( f . getName ( ) . endsWith ( YAML_EXTENSION ) || f . getName ( ) . endsWith ( YML_EXTENSION ) ) { 
map = flatten ( YAML_MAPPER . readValue ( f , Map . class ) ) ; 
} else if ( f . getName ( ) . endsWith ( PROPERTIES_EXTENSION ) ) { 
properties . load ( new FileInputStream ( f ) ) ; 
map = propertiesToMap ( properties ) ; 
} private Map < String , String > flatten ( Map map ) { 
Map < String , String > flat = new HashMap < > ( ) ; 
for ( Object key : map . keySet ( ) ) { 
String stringKey = String . valueOf ( key ) ; 
Object value = map . get ( key ) ; 
flat . put ( stringKey , ( String ) value ) ; 
} else if ( value instanceof Map ) { 
for ( Map . Entry < String , String > entry : flatten ( ( Map ) value ) . entrySet ( ) ) { 
flat . put ( 
new StringBuilder ( stringKey ) . append ( DOT ) . append ( entry . getKey ( ) ) . toString ( ) , 
entry . getValue ( ) ) ; 
flat . put ( stringKey , String . valueOf ( value ) ) ; 
return flat ; 
} private Map < String , String > propertiesToMap ( Properties properties ) { 
Map < String , String > map = new HashMap < > ( ) ; 
for ( Map . Entry < Object , Object > entry : properties . entrySet ( ) ) { 
map . put ( String . valueOf ( entry . getKey ( ) ) , String . valueOf ( entry . getValue ( ) ) ) ; 
} private void addPortIfValid ( Map < String , Integer > map , String key , String port ) { 
if ( StringUtils . isNotBlank ( port ) ) { 
String t = port . trim ( ) ; 
if ( t . matches ( NUMBER_REGEX ) ) { 
map . put ( key , Integer . parseInt ( t ) ) ; 
} private HTTPGetAction getHTTPGetAction ( String getUrl ) { 
if ( getUrl == null || ! getUrl . subSequence ( 0 , 4 ) . toString ( ) . equalsIgnoreCase ( "http" ) ) { 
URL url = new URL ( getUrl ) ; 
return new HTTPGetAction ( url . getHost ( ) , 
null , 
url . getPath ( ) , 
new IntOrString ( url . getPort ( ) ) , 
url . getProtocol ( ) . toUpperCase ( ) ) ; 
} catch ( MalformedURLException e ) { 
} public String getDockerJsonConfigString ( final Settings settings , final String serverId ) { 
Server server = getServer ( settings , serverId ) ; 
if ( server == null ) { 
JsonObject auth = new JsonObject ( ) ; 
auth . add ( "username" , new JsonPrimitive ( server . getUsername ( ) ) ) ; 
auth . add ( "password" , new JsonPrimitive ( server . getPassword ( ) ) ) ; 
String mail = getConfigurationValue ( server , "email" ) ; 
if ( ! StringUtils . isBlank ( mail ) ) { 
auth . add ( "email" , new JsonPrimitive ( mail ) ) ; 
JsonObject json = new JsonObject ( ) ; 
json . add ( serverId , auth ) ; 
return json . toString ( ) ; 
} public Optional < Map < String , Object > > getPluginConfiguration ( String system , String id ) { 
return pluginConfigLookup . apply ( system , id ) ; 
} public Optional < Map < String , Object > > getSecretConfiguration ( String id ) { 
return secretConfigLookup . apply ( id ) ; 
} public static void download ( Logger log , URL downloadUrl , File target ) throws MojoExecutionException { 
log . progressStart ( ) ; 
OkHttpClient client = 
new OkHttpClient . Builder ( ) 
. readTimeout ( 30 , TimeUnit . MINUTES ) . build ( ) ; 
Request request = new Request . Builder ( ) 
. url ( downloadUrl ) 
Response response = client . newCall ( request ) . execute ( ) ; 
try ( OutputStream out = new FileOutputStream ( target ) ; 
InputStream im = response . body ( ) . byteStream ( ) ) { 
long length = response . body ( ) . contentLength ( ) ; 
InputStream in = response . body ( ) . byteStream ( ) ; 
byte [ ] buffer = new byte [ 8192 ] ; 
long readBytes = 0 ; 
int len = in . read ( buffer ) ; 
readBytes += len ; 
log . progressUpdate ( target . getName ( ) , "Downloading" , getProgressBar ( readBytes , length ) ) ; 
if ( len <= 0 ) { 
out . write ( buffer , 0 , len ) ; 
log . progressFinished ( ) ; 
} public static int getFreeRandomPort ( int min , int max , int attempts ) { 
Random random = new Random ( ) ; 
for ( int i = 0 ; i < attempts ; i ++ ) { 
int port = min + random . nextInt ( max - min + 1 ) ; 
try ( Socket socket = new Socket ( "localhost" , port ) ) { 
} catch ( ConnectException e ) { 
return port ; 
} public static int compareVersions ( String v1 , String v2 ) { 
String [ ] components1 = split ( v1 ) ; 
String [ ] components2 = split ( v2 ) ; 
int diff ; 
int length = Math . min ( components1 . length , components2 . length ) ; 
for ( int i = 0 ; i < length ; i ++ ) { 
String s1 = components1 [ i ] ; 
String s2 = components2 [ i ] ; 
Integer i1 = tryParseInteger ( s1 ) ; 
Integer i2 = tryParseInteger ( s2 ) ; 
if ( i1 != null && i2 != null ) { 
diff = i1 . compareTo ( i2 ) ; 
diff = s1 . compareTo ( s2 ) ; 
if ( diff != 0 ) { 
return diff ; 
diff = Integer . compare ( components1 . length , components2 . length ) ; 
if ( diff == 0 ) { 
if ( v1 == v2 ) { 
return v1 != null ? v1 . compareTo ( v2 ) : - 1 ; 
} public static Profile findProfile ( String profileArg , File resourceDir ) throws IOException { 
String profile = profileArg == null ? DEFAULT_PROFILE : profileArg ; 
Profile profileFound = lookup ( profile , resourceDir ) ; 
if ( profileFound != null ) { 
if ( profileFound . getParentProfile ( ) != null ) { 
profileFound = inheritFromParentProfile ( profileFound , resourceDir ) ; 
return profileFound ; 
} public static ProcessorConfig blendProfileWithConfiguration ( ProcessorConfigurationExtractor configExtractor , 
String profile , 
File resourceDir , 
ProcessorConfig config ) throws IOException { 
ProcessorConfig profileConfig = extractProcesssorConfiguration ( configExtractor , profile , resourceDir ) ; 
return ProcessorConfig . mergeProcessorConfigs ( config , profileConfig ) ; 
} public static Profile lookup ( String name , File directory ) throws IOException { 
List < Profile > profiles = readProfileFromClasspath ( name ) ; 
File profileFile = findProfileYaml ( directory ) ; 
if ( profileFile != null ) { 
List < Profile > fileProfiles = fromYaml ( new FileInputStream ( profileFile ) ) ; 
for ( Profile profile : fileProfiles ) { 
if ( profile . getName ( ) . equals ( name ) ) { 
profiles . add ( profile ) ; 
Collections . sort ( profiles , Collections . < Profile > reverseOrder ( ) ) ; 
return mergeProfiles ( profiles ) ; 
} private static List < Profile > readProfileFromClasspath ( String name ) throws IOException { 
List < Profile > ret = new ArrayList < > ( ) ; 
ret . addAll ( readAllFromClasspath ( name , "default" ) ) ; 
ret . addAll ( readAllFromClasspath ( name , "" ) ) ; 
} public static List < Profile > readAllFromClasspath ( String name , String ext ) throws IOException { 
for ( String location : getMetaInfProfilePaths ( ext ) ) { 
for ( String url : ClassUtil . getResources ( location ) ) { 
for ( Profile profile : fromYaml ( new URL ( url ) . openStream ( ) ) ) { 
if ( name . equals ( profile . getName ( ) ) ) { 
ret . add ( profile ) ; 
} private static File findProfileYaml ( File directory ) { 
for ( String profileFile : PROFILE_FILENAMES ) { 
File ret = new File ( directory , String . format ( profileFile , "" ) ) ; 
if ( ret . exists ( ) ) { 
} private static List < String > getMetaInfProfilePaths ( String ext ) { 
List < String > ret = new ArrayList < > ( PROFILE_FILENAMES . length ) ; 
for ( String p : PROFILE_FILENAMES ) { 
ret . add ( "META-INF/fabric8/" + getProfileFileName ( p , ext ) ) ; 
} public static List < Profile > fromYaml ( InputStream is ) throws IOException { 
TypeReference < List < Profile > > typeRef = new TypeReference < List < Profile > > ( ) { } ; 
return mapper . readValue ( is , typeRef ) ; 
} public static List < String > findMainClasses ( File rootDir ) throws IOException { 
List < String > ret = new ArrayList < > ( ) ; 
if ( ! rootDir . exists ( ) ) { 
if ( ! rootDir . isDirectory ( ) ) { 
findClasses ( ret , rootDir , rootDir . getAbsolutePath ( ) + "/" ) ; 
} private void addGitServiceUrl ( Map < String , String > annotations , String repoName , String gitCommitId ) { 
String username = getGitUserName ( ) ; 
String gogsUrl = getExternalServiceURL ( getConfig ( Config . gitService ) , "http" ) ; 
String rootGitUrl = String . format ( "%s/%s/%s" , gogsUrl , username , repoName ) ; 
rootGitUrl = String . format ( "%s/%s/%s" , rootGitUrl , "commit" , gitCommitId ) ; 
if ( StringUtils . isNotBlank ( rootGitUrl ) ) { 
annotations . put ( Fabric8Annotations . GIT_URL . value ( ) , rootGitUrl ) ; 
} private String getImagePullPolicy ( ResourceConfig resourceConfig , String defaultValue ) { 
if ( resourceConfig != null ) { 
return resourceConfig . getImagePullPolicy ( ) != null ? resourceConfig . getImagePullPolicy ( ) : defaultValue ; 
return defaultValue ; 
} protected boolean isOpenShiftMode ( ) { 
Properties properties = getContext ( ) . getConfiguration ( ) . getProperties ( ) ; 
return RuntimeMode . isOpenShiftMode ( properties ) ; 
} protected int getReplicaCount ( KubernetesListBuilder builder , ResourceConfig xmlResourceConfig , int defaultValue ) { 
if ( xmlResourceConfig != null ) { 
List < HasMetadata > items = builder . buildItems ( ) ; 
for ( HasMetadata item : items ) { 
if ( item instanceof Deployment ) { 
if ( ( ( Deployment ) item ) . getSpec ( ) . getReplicas ( ) != null ) { 
return ( ( Deployment ) item ) . getSpec ( ) . getReplicas ( ) ; 
if ( item instanceof DeploymentConfig ) { 
if ( ( ( DeploymentConfig ) item ) . getSpec ( ) . getReplicas ( ) != null ) { 
return ( ( DeploymentConfig ) item ) . getSpec ( ) . getReplicas ( ) ; 
return xmlResourceConfig . getReplicas ( ) > 0 ? xmlResourceConfig . getReplicas ( ) : defaultValue ; 
} public static Element firstChild ( Element element , String name ) { 
NodeList nodes = element . getChildNodes ( ) ; 
for ( int i = 0 , size = nodes . getLength ( ) ; i < size ; i ++ ) { 
Node item = nodes . item ( i ) ; 
if ( item instanceof Element ) { 
Element childElement = ( Element ) item ; 
if ( name . equals ( childElement . getTagName ( ) ) ) { 
return childElement ; 
} private static String getTextContent ( final Node node ) { 
switch ( node . getNodeType ( ) ) { 
case Node . ELEMENT_NODE : 
case Node . ATTRIBUTE_NODE : 
case Node . ENTITY_NODE : 
case Node . ENTITY_REFERENCE_NODE : 
case Node . DOCUMENT_FRAGMENT_NODE : 
return mergeTextContent ( node . getChildNodes ( ) ) ; 
case Node . TEXT_NODE : 
case Node . CDATA_SECTION_NODE : 
case Node . COMMENT_NODE : 
case Node . PROCESSING_INSTRUCTION_NODE : 
return node . getNodeValue ( ) ; 
case Node . DOCUMENT_NODE : 
case Node . DOCUMENT_TYPE_NODE : 
case Node . NOTATION_NODE : 
} public void apply ( Object dto , String sourceName ) throws Exception { 
if ( dto instanceof List ) { 
List list = ( List ) dto ; 
for ( Object element : list ) { 
if ( dto == element ) { 
apply ( element , sourceName ) ; 
} else if ( dto instanceof KubernetesList ) { 
applyList ( ( KubernetesList ) dto , sourceName ) ; 
} else if ( dto != null ) { 
applyEntity ( dto , sourceName ) ; 
} private void applyEntity ( Object dto , String sourceName ) throws Exception { 
if ( dto instanceof Pod ) { 
applyPod ( ( Pod ) dto , sourceName ) ; 
} else if ( dto instanceof ReplicationController ) { 
applyReplicationController ( ( ReplicationController ) dto , sourceName ) ; 
} else if ( dto instanceof Service ) { 
applyService ( ( Service ) dto , sourceName ) ; 
} else if ( dto instanceof Route ) { 
applyRoute ( ( Route ) dto , sourceName ) ; 
} else if ( dto instanceof BuildConfig ) { 
applyBuildConfig ( ( BuildConfig ) dto , sourceName ) ; 
} else if ( dto instanceof DeploymentConfig ) { 
DeploymentConfig resource = ( DeploymentConfig ) dto ; 
OpenShiftClient openShiftClient = getOpenShiftClient ( ) ; 
if ( openShiftClient != null ) { 
applyResource ( resource , sourceName , openShiftClient . deploymentConfigs ( ) ) ; 
} else if ( dto instanceof RoleBinding ) { 
applyRoleBinding ( ( RoleBinding ) dto , sourceName ) ; 
} else if ( dto instanceof Role ) { 
Role resource = ( Role ) dto ; 
applyResource ( resource , sourceName , openShiftClient . rbac ( ) . roles ( ) ) ; 
} else if ( dto instanceof ImageStream ) { 
applyImageStream ( ( ImageStream ) dto , sourceName ) ; 
} else if ( dto instanceof OAuthClient ) { 
applyOAuthClient ( ( OAuthClient ) dto , sourceName ) ; 
} else if ( dto instanceof Template ) { 
applyTemplate ( ( Template ) dto , sourceName ) ; 
} else if ( dto instanceof ServiceAccount ) { 
applyServiceAccount ( ( ServiceAccount ) dto , sourceName ) ; 
} else if ( dto instanceof Secret ) { 
applySecret ( ( Secret ) dto , sourceName ) ; 
} else if ( dto instanceof ConfigMap ) { 
applyResource ( ( ConfigMap ) dto , sourceName , kubernetesClient . configMaps ( ) ) ; 
} else if ( dto instanceof DaemonSet ) { 
applyResource ( ( DaemonSet ) dto , sourceName , kubernetesClient . extensions ( ) . daemonSets ( ) ) ; 
} else if ( dto instanceof Deployment ) { 
applyResource ( ( Deployment ) dto , sourceName , kubernetesClient . extensions ( ) . deployments ( ) ) ; 
} else if ( dto instanceof ReplicaSet ) { 
applyResource ( ( ReplicaSet ) dto , sourceName , kubernetesClient . extensions ( ) . replicaSets ( ) ) ; 
} else if ( dto instanceof StatefulSet ) { 
applyResource ( ( StatefulSet ) dto , sourceName , kubernetesClient . apps ( ) . statefulSets ( ) ) ; 
} else if ( dto instanceof Ingress ) { 
applyResource ( ( Ingress ) dto , sourceName , kubernetesClient . extensions ( ) . ingresses ( ) ) ; 
} else if ( dto instanceof PersistentVolumeClaim ) { 
applyPersistentVolumeClaim ( ( PersistentVolumeClaim ) dto , sourceName ) ; 
} else if ( dto instanceof HasMetadata ) { 
HasMetadata entity = ( HasMetadata ) dto ; 
kubernetesClient . resource ( entity ) . inNamespace ( getNamespace ( ) ) . createOrReplace ( ) ; 
} public Object applyTemplate ( Template entity , String sourceName ) throws Exception { 
installTemplate ( entity , sourceName ) ; 
return processTemplate ( entity , sourceName ) ; 
} public void installTemplate ( Template entity , String sourceName ) { 
if ( ! isProcessTemplatesLocally ( ) ) { 
String namespace = getNamespace ( ) ; 
String id = getName ( entity ) ; 
Template old = openShiftClient . templates ( ) . inNamespace ( namespace ) . withName ( id ) . get ( ) ; 
if ( isRunning ( old ) ) { 
if ( UserConfigurationCompare . configEqual ( entity , old ) ) { 
boolean recreateMode = isRecreateMode ( ) ; 
recreateMode = true ; 
if ( recreateMode ) { 
openShiftClient . templates ( ) . inNamespace ( namespace ) . withName ( id ) . delete ( ) ; 
doCreateTemplate ( entity , namespace , sourceName ) ; 
Object answer = openShiftClient . templates ( ) . inNamespace ( namespace ) . withName ( id ) . replace ( entity ) ; 
if ( ! isAllowCreate ( ) ) { 
} public void applyServiceAccount ( ServiceAccount serviceAccount , String sourceName ) throws Exception { 
String id = getName ( serviceAccount ) ; 
if ( isServicesOnlyMode ( ) ) { 
ServiceAccount old = kubernetesClient . serviceAccounts ( ) . inNamespace ( namespace ) . withName ( id ) . get ( ) ; 
if ( UserConfigurationCompare . configEqual ( serviceAccount , old ) ) { 
if ( isRecreateMode ( ) ) { 
kubernetesClient . serviceAccounts ( ) . inNamespace ( namespace ) . withName ( id ) . delete ( ) ; 
doCreateServiceAccount ( serviceAccount , namespace , sourceName ) ; 
Object answer = kubernetesClient . serviceAccounts ( ) . inNamespace ( namespace ) . withName ( id ) . replace ( serviceAccount ) ; 
} private int removeTagByName ( List < TagReference > tags , String tagName ) { 
List < TagReference > removeTags = new ArrayList < > ( ) ; 
for ( TagReference tag : tags ) { 
if ( Objects . equals ( tagName , tag . getName ( ) ) ) { 
removeTags . add ( tag ) ; 
tags . removeAll ( removeTags ) ; 
return removeTags . size ( ) ; 
} public boolean applyNamespace ( Namespace entity ) { 
String namespace = getOrCreateMetadata ( entity ) . getName ( ) ; 
String name = getName ( entity ) ; 
Namespace old = kubernetesClient . namespaces ( ) . withName ( name ) . get ( ) ; 
if ( ! isRunning ( old ) ) { 
Object answer = kubernetesClient . namespaces ( ) . create ( entity ) ; 
} public boolean applyProject ( Project project ) { 
return applyProjectRequest ( new ProjectRequestBuilder ( ) 
. withDisplayName ( project . getMetadata ( ) . getName ( ) ) 
. withMetadata ( project . getMetadata ( ) ) . build ( ) ) ; 
} public boolean applyProjectRequest ( ProjectRequest entity ) { 
OpenShiftClient openshiftClient = getOpenShiftClient ( ) ; 
if ( openshiftClient == null ) { 
boolean exists = checkNamespace ( name ) ; 
if ( ! exists ) { 
Object answer = openshiftClient . projectrequests ( ) . create ( entity ) ; 
} protected String getNamespace ( HasMetadata entity ) { 
String answer = KubernetesHelper . getNamespace ( entity ) ; 
if ( StringUtils . isBlank ( answer ) ) { 
answer = getNamespace ( ) ; 
applyNamespace ( answer ) ; 
} protected void onApplyError ( String message , Exception e ) { 
log . error ( message , e ) ; 
throw new RuntimeException ( message , e ) ; 
} @ GET 
@ Produces ( "text/plain" ) 
public String peng ( @ PathParam ( "id" ) String id ) { 
Stroke stroke = Stroke . play ( strength ) ; 
} private void ensureSpringDevToolSecretToken ( ) throws MojoExecutionException { 
Properties properties = SpringBootUtil . getSpringBootApplicationProperties ( MavenUtil . getCompileClassLoader ( getProject ( ) ) ) ; 
String remoteSecret = properties . getProperty ( DEV_TOOLS_REMOTE_SECRET ) ; 
if ( Strings . isNullOrEmpty ( remoteSecret ) ) { 
addSecretTokenToApplicationProperties ( ) ; 
public void create ( PlatformMode platformMode , KubernetesListBuilder builder ) { 
final String name = config . getNamespace ( ) ; 
if ( name == null || name . isEmpty ( ) ) { 
if ( ! KubernetesResourceUtil . checkForKind ( builder , NAMESPACE_KINDS ) ) { 
String type = getConfig ( Config . type ) ; 
if ( "project" . equalsIgnoreCase ( type ) || "namespace" . equalsIgnoreCase ( type ) ) { 
if ( platformMode == PlatformMode . kubernetes ) { 
Namespace namespace = handlerHub . getNamespaceHandler ( ) . getNamespace ( config . getNamespace ( ) ) ; 
builder . addToNamespaceItems ( namespace ) ; 
Project project = handlerHub . getProjectHandler ( ) . getProject ( config . getNamespace ( ) ) ; 
builder . addToProjectItems ( project ) ; 
public void enrich ( PlatformMode platformMode , KubernetesListBuilder builder ) { 
builder . accept ( new TypedVisitor < ObjectMetaBuilder > ( ) { 
private String getNamespaceName ( ) { 
String name = null ; 
if ( config . getNamespace ( ) != null && ! config . getNamespace ( ) . isEmpty ( ) ) { 
name = config . getNamespace ( ) ; 
name = builder . getItems ( ) . stream ( ) 
. filter ( item -> Arrays . asList ( NAMESPACE_KINDS ) . contains ( item . getKind ( ) ) ) 
. findFirst ( ) . get ( ) . getMetadata ( ) . getName ( ) ; 
return name ; 
public void visit ( ObjectMetaBuilder metaBuilder ) { 
String name = getNamespaceName ( ) ; 
metaBuilder . withNamespace ( name ) . build ( ) ; 
builder . accept ( new TypedVisitor < NamespaceBuilder > ( ) { 
public void visit ( NamespaceBuilder builder ) { 
builder . withNewStatus ( "active" ) . editMetadata ( ) . withNamespace ( null ) . endMetadata ( ) . build ( ) ; 
builder . accept ( new TypedVisitor < ProjectBuilder > ( ) { 
public void visit ( ProjectBuilder builder ) { 
} public static Map < String , Object > extract ( Xpp3Dom root ) { 
if ( root == null ) { 
return new HashMap < > ( ) ; 
return getElement ( root ) ; 
} protected Map < String , String > getEnv ( boolean prePackagePhase ) throws MojoExecutionException { 
Map < String , String > ret = new HashMap < > ( ) ; 
if ( ! isFatJar ( ) ) { 
String mainClass = getConfig ( Config . mainClass ) ; 
if ( mainClass == null ) { 
mainClass = mainClassDetector . getMainClass ( ) ; 
if ( ! prePackagePhase ) { 
if ( mainClass != null ) { 
ret . put ( JAVA_MAIN_CLASS_ENV_VAR , mainClass ) ; 
List < String > javaOptions = getExtraJavaOptions ( ) ; 
if ( javaOptions . size ( ) > 0 ) { 
} public static Integer durationSeconds ( String duration ) { 
BigDecimal ns = durationNs ( duration ) ; 
if ( ns == null ) { 
BigDecimal sec = ns . divide ( new BigDecimal ( 1_000_000_000 ) ) ; 
if ( sec . compareTo ( new BigDecimal ( Integer . MAX_VALUE ) ) > 0 ) { 
return sec . intValue ( ) ; 
} public static BigDecimal durationNs ( String durationP ) { 
if ( durationP == null ) { 
String duration = durationP . trim ( ) ; 
if ( duration . length ( ) == 0 ) { 
int unitPos = 1 ; 
while ( unitPos < duration . length ( ) && ( Character . isDigit ( duration . charAt ( unitPos ) ) || duration . charAt ( unitPos ) == '.' ) ) { 
unitPos ++ ; 
if ( unitPos >= duration . length ( ) ) { 
String tail = duration . substring ( unitPos ) ; 
Long multiplier = null ; 
Integer unitEnd = null ; 
for ( int i = 0 ; i < TIME_UNITS . length ; i ++ ) { 
if ( tail . startsWith ( TIME_UNITS [ i ] ) ) { 
multiplier = UNIT_MULTIPLIERS [ i ] ; 
unitEnd = unitPos + TIME_UNITS [ i ] . length ( ) ; 
if ( multiplier == null ) { 
BigDecimal value = new BigDecimal ( duration . substring ( 0 , unitPos ) ) ; 
value = value . multiply ( BigDecimal . valueOf ( multiplier ) ) ; 
String remaining = duration . substring ( unitEnd ) ; 
BigDecimal remainingValue = durationNs ( remaining ) ; 
if ( remainingValue != null ) { 
value = value . add ( remainingValue ) ; 
} protected String [ ] scanFiles ( String ... patterns ) { 
String buildOutputDir = project . getBuild ( ) . getDirectory ( ) ; 
if ( buildOutputDir != null && new File ( buildOutputDir ) . exists ( ) ) { 
DirectoryScanner directoryScanner = new DirectoryScanner ( ) ; 
directoryScanner . setBasedir ( buildOutputDir ) ; 
directoryScanner . setIncludes ( patterns ) ; 
directoryScanner . scan ( ) ; 
return directoryScanner . getIncludedFiles ( ) ; 
return new String [ 0 ] ; 
} private boolean shouldCreateExternalURLForService ( Service service , String id ) { 
if ( "kubernetes" . equals ( id ) || "kubernetes-ro" . equals ( id ) ) { 
Set < Integer > ports = getPorts ( service ) ; 
if ( ports . size ( ) == 1 ) { 
String type = null ; 
ServiceSpec spec = service . getSpec ( ) ; 
type = spec . getType ( ) ; 
if ( Objects . equals ( type , "LoadBalancer" ) ) { 
} protected void disableOpenShiftFeatures ( ApplyService applyService ) { 
this . processTemplatesLocally = true ; 
applyService . setSupportOAuthClients ( false ) ; 
applyService . setProcessTemplatesLocally ( true ) ; 
} private boolean serviceHasIngressRule ( List < Ingress > ingresses , Service service ) { 
String serviceName = KubernetesHelper . getName ( service ) ; 
for ( Ingress ingress : ingresses ) { 
IngressSpec spec = ingress . getSpec ( ) ; 
if ( spec == null ) { 
if ( rules == null ) { 
if ( http == null ) { 
if ( paths == null ) { 
if ( backend == null ) { 
if ( Objects . equals ( serviceName , backend . getServiceName ( ) ) ) { 
} protected File getRootProjectFolder ( ) { 
File answer = null ; 
MavenProject project = getProject ( ) ; 
while ( project != null ) { 
File basedir = project . getBasedir ( ) ; 
if ( basedir != null ) { 
answer = basedir ; 
project = project . getParent ( ) ; 
} protected MavenProject getRootProject ( ) { 
MavenProject parent = project . getParent ( ) ; 
if ( parent == null ) { 
project = parent ; 
return project ; 
public List < ImageConfiguration > customizeConfig ( List < ImageConfiguration > configs ) { 
ProcessorConfig generatorConfig = 
ProfileUtil . blendProfileWithConfiguration ( ProfileUtil . GENERATOR_CONFIG , profile , ResourceDirCreator . getFinalResourceDir ( resourceDir , environment ) , generator ) ; 
GeneratorContext ctx = new GeneratorContext . Builder ( ) 
. config ( generatorConfig ) 
. project ( project ) 
. logger ( log ) 
. runtimeMode ( mode ) 
. strategy ( buildStrategy ) 
. useProjectClasspath ( false ) 
return GeneratorManager . generate ( configs , ctx , true ) ; 
} public Map < String , List < String > > parse ( final InputStream mapping ) { 
final Properties mappingProperties = new Properties ( ) ; 
mappingProperties . load ( mapping ) ; 
final Map < String , List < String > > serializedContent = new HashMap < > ( ) ; 
final Set < String > kinds = mappingProperties . stringPropertyNames ( ) ; 
for ( String kind : kinds ) { 
final String filenames = mappingProperties . getProperty ( kind ) ; 
final String [ ] filenameTypes = filenames . split ( "," ) ; 
final List < String > scannedFiletypes = new ArrayList < > ( ) ; 
for ( final String filenameType : filenameTypes ) { 
scannedFiletypes . add ( filenameType . trim ( ) ) ; 
serializedContent . put ( kind , scannedFiletypes ) ; 
return serializedContent ; 
throw new IllegalStateException ( e ) ; 
runtimeMode = clusterAccess . resolveRuntimeMode ( mode , log ) ; 
if ( runtimeMode == RuntimeMode . openshift ) { 
if ( runtimeMode . equals ( PlatformMode . openshift ) ) { 
Properties properties = project . getProperties ( ) ; 
if ( ! properties . contains ( RuntimeMode . FABRIC8_EFFECTIVE_PLATFORM_MODE ) ) { 
properties . setProperty ( RuntimeMode . FABRIC8_EFFECTIVE_PLATFORM_MODE , runtimeMode . toString ( ) ) ; 
return GeneratorManager . generate ( configs , getGeneratorContext ( ) , false ) ; 
} catch ( MojoExecutionException e ) { 
} private GeneratorContext getGeneratorContext ( ) { 
return new GeneratorContext . Builder ( ) 
. config ( extractGeneratorConfig ( ) ) 
. runtimeMode ( runtimeMode ) 
. useProjectClasspath ( useProjectClasspath ) 
. artifactResolver ( getFabric8ServiceHub ( ) . getArtifactResolverService ( ) ) 
} private ProcessorConfig extractGeneratorConfig ( ) { 
return ProfileUtil . blendProfileWithConfiguration ( ProfileUtil . GENERATOR_CONFIG , profile , ResourceDirCreator . getFinalResourceDir ( resourceDir , environment ) , generator ) ; 
} public EnricherContext getEnricherContext ( ) { 
return new MavenEnricherContext . Builder ( ) 
. properties ( project . getProperties ( ) ) 
. session ( session ) 
. config ( extractEnricherConfig ( ) ) 
. images ( getResolvedImages ( ) ) 
. resources ( resources ) 
. log ( log ) 
} private ProcessorConfig extractEnricherConfig ( ) { 
return ProfileUtil . blendProfileWithConfiguration ( ProfileUtil . ENRICHER_CONFIG , profile , ResourceDirCreator . getFinalResourceDir ( resourceDir , environment ) , enricher ) ; 
} private String extractIconRef ( ) { 
String iconRef = getConfig ( Config . ref ) ; 
if ( StringUtils . isBlank ( iconRef ) ) { 
iconRef = getDefaultIconRef ( ) ; 
return iconRef ; 
} private String getDefaultIconRef ( ) { 
ProjectClassLoaders cls = getContext ( ) . getProjectClassLoaders ( ) ; 
if ( cls . isClassInCompileClasspath ( false , "io.fabric8.funktion.runtime.Main" ) || 
getContext ( ) . hasDependency ( "io.fabric8.funktion" , null ) ) { 
return "funktion" ; 
if ( cls . isClassInCompileClasspath ( false , "org.apache.camel.CamelContext" ) ) { 
return "camel" ; 
if ( getContext ( ) . hasPlugin ( null , SpringBootConfigurationHelper . SPRING_BOOT_MAVEN_PLUGIN_ARTIFACT_ID ) || 
cls . isClassInCompileClasspath ( false , "org.springframework.boot.SpringApplication" ) ) { 
return "spring-boot" ; 
if ( cls . isClassInCompileClasspath ( false , "org.springframework.core.Constants" ) ) { 
return "spring" ; 
if ( cls . isClassInCompileClasspath ( false , "org.vertx.java.core.Handler" , "io.vertx.core.Handler" ) ) { 
return "vertx" ; 
if ( getContext ( ) . hasPlugin ( "org.wildfly.swarm" , "wildfly-swarm-plugin" ) || 
getContext ( ) . hasDependency ( "org.wildfly.swarm" , null ) ) { 
return "wildfly-swarm" ; 
if ( getContext ( ) . hasPlugin ( "io.thorntail" , "thorntail-maven-plugin" ) || 
getContext ( ) . hasDependency ( "io.thorntail" , null ) ) { 
} private void copyAppConfigFiles ( File appBuildDir , File appConfigDir ) throws IOException { 
File [ ] files = appConfigDir . listFiles ( ) ; 
if ( files != null ) { 
appBuildDir . mkdirs ( ) ; 
File outFile = new File ( appBuildDir , file . getName ( ) ) ; 
copyAppConfigFiles ( outFile , file ) ; 
Files . copy ( file , outFile ) ; 
} protected String embeddedIconsInConsole ( String iconRef , String prefix ) { 
if ( iconRef == null ) { 
if ( iconRef . startsWith ( "icons/" ) ) { 
iconRef = iconRef . substring ( 6 ) ; 
if ( iconRef . contains ( "META-INF/fabric8" ) ) { 
return "img/fabric8_icon.svg" ; 
if ( iconRef . contains ( "activemq" ) ) { 
return prefix + "activemq.svg" ; 
} else if ( iconRef . contains ( "apiman" ) ) { 
return prefix + "apiman.png" ; 
} else if ( iconRef . contains ( "api-registry" ) ) { 
return prefix + "api-registry.svg" ; 
} else if ( iconRef . contains ( "brackets" ) ) { 
return prefix + "brackets.svg" ; 
} else if ( iconRef . contains ( "camel" ) ) { 
return prefix + "camel.svg" ; 
} else if ( iconRef . contains ( "chaos-monkey" ) ) { 
return prefix + "chaos-monkey.png" ; 
} else if ( iconRef . contains ( "docker-registry" ) ) { 
return prefix + "docker-registry.png" ; 
} else if ( iconRef . contains ( "elasticsearch" ) ) { 
return prefix + "elasticsearch.png" ; 
} else if ( iconRef . contains ( "fluentd" ) ) { 
return prefix + "fluentd.png" ; 
} else if ( iconRef . contains ( "forge" ) ) { 
return prefix + "forge.svg" ; 
} else if ( iconRef . contains ( "funktion" ) ) { 
return prefix + "funktion.png" ; 
} else if ( iconRef . contains ( "gerrit" ) ) { 
return prefix + "gerrit.png" ; 
} else if ( iconRef . contains ( "gitlab" ) ) { 
return prefix + "gitlab.svg" ; 
} else if ( iconRef . contains ( "gogs" ) ) { 
return prefix + "gogs.png" ; 
} else if ( iconRef . contains ( "grafana" ) ) { 
return prefix + "grafana.png" ; 
} else if ( iconRef . contains ( "hubot-irc" ) ) { 
return prefix + "hubot-irc.png" ; 
} else if ( iconRef . contains ( "hubot-letschat" ) ) { 
return prefix + "hubot-letschat.png" ; 
} else if ( iconRef . contains ( "hubot-notifier" ) ) { 
return prefix + "hubot-notifier.png" ; 
} else if ( iconRef . contains ( "hubot-slack" ) ) { 
return prefix + "hubot-slack.png" ; 
} else if ( iconRef . contains ( "image-linker" ) ) { 
return prefix + "image-linker.svg" ; 
} else if ( iconRef . contains ( "javascript" ) ) { 
return prefix + "javascript.png" ; 
} else if ( iconRef . contains ( "java" ) ) { 
return prefix + "java.svg" ; 
} else if ( iconRef . contains ( "jenkins" ) ) { 
return prefix + "jenkins.svg" ; 
} else if ( iconRef . contains ( "jetty" ) ) { 
return prefix + "jetty.svg" ; 
} else if ( iconRef . contains ( "karaf" ) ) { 
return prefix + "karaf.svg" ; 
} else if ( iconRef . contains ( "keycloak" ) ) { 
return prefix + "keycloak.svg" ; 
} else if ( iconRef . contains ( "kibana" ) ) { 
return prefix + "kibana.svg" ; 
} else if ( iconRef . contains ( "kiwiirc" ) ) { 
return prefix + "kiwiirc.png" ; 
} else if ( iconRef . contains ( "letschat" ) ) { 
return prefix + "letschat.png" ; 
} else if ( iconRef . contains ( "mule" ) ) { 
return prefix + "mule.svg" ; 
} else if ( iconRef . contains ( "nexus" ) ) { 
return prefix + "nexus.png" ; 
} else if ( iconRef . contains ( "node" ) ) { 
return prefix + "node.svg" ; 
} else if ( iconRef . contains ( "orion" ) ) { 
return prefix + "orion.png" ; 
} else if ( iconRef . contains ( "prometheus" ) ) { 
return prefix + "prometheus.png" ; 
} else if ( iconRef . contains ( "django" ) || iconRef . contains ( "python" ) ) { 
return prefix + "python.png" ; 
} else if ( iconRef . contains ( "spring-boot" ) ) { 
return prefix + "spring-boot.svg" ; 
} else if ( iconRef . contains ( "taiga" ) ) { 
return prefix + "taiga.png" ; 
} else if ( iconRef . contains ( "tomcat" ) ) { 
return prefix + "tomcat.svg" ; 
} else if ( iconRef . contains ( "tomee" ) ) { 
return prefix + "tomee.svg" ; 
} else if ( iconRef . contains ( "vertx" ) ) { 
return prefix + "vertx.svg" ; 
} else if ( iconRef . contains ( "wildfly" ) ) { 
return prefix + "wildfly.svg" ; 
} else if ( iconRef . contains ( "wildfly-swarm" ) ) { 
return prefix + "wildfly-swarm.png" ; 
} else if ( iconRef . contains ( "weld" ) ) { 
return prefix + "weld.svg" ; 
} else if ( iconRef . contains ( "zipkin" ) ) { 
return prefix + "zipkin.png" ; 
} public static Properties getSpringBootApplicationProperties ( URLClassLoader compileClassLoader ) { 
URL ymlResource = compileClassLoader . findResource ( "application.yml" ) ; 
URL propertiesResource = compileClassLoader . findResource ( "application.properties" ) ; 
Properties props = YamlUtil . getPropertiesFromYamlResource ( ymlResource ) ; 
props . putAll ( getPropertiesResource ( propertiesResource ) ) ; 
return props ; 
} protected static Properties getPropertiesResource ( URL resource ) { 
Properties answer = new Properties ( ) ; 
try ( InputStream stream = resource . openStream ( ) ) { 
answer . load ( stream ) ; 
} public static Optional < String > getSpringBootVersion ( MavenProject mavenProject ) { 
return Optional . ofNullable ( MavenUtil . getDependencyVersion ( mavenProject , SpringBootConfigurationHelper . SPRING_BOOT_GROUP_ID , SpringBootConfigurationHelper . SPRING_BOOT_ARTIFACT_ID ) ) ; 
} public < T > List < T > createServiceObjects ( String ... descriptorPaths ) { 
ServiceEntry . initDefaultOrder ( ) ; 
TreeMap < ServiceEntry , T > serviceMap = new TreeMap < ServiceEntry , T > ( ) ; 
for ( String descriptor : descriptorPaths ) { 
readServiceDefinitions ( serviceMap , descriptor ) ; 
ArrayList < T > ret = new ArrayList < T > ( ) ; 
for ( T service : serviceMap . values ( ) ) { 
ret . add ( service ) ; 
ServiceEntry . removeDefaultOrder ( ) ; 
} private void enrich ( PlatformMode platformMode , final ProcessorConfig enricherConfig , final KubernetesListBuilder builder , final List < Enricher > enricherList ) { 
loop ( enricherConfig , enricher -> { 
enricher . enrich ( platformMode , builder ) ; 
} private void logEnrichers ( List < Enricher > enrichers ) { 
log . verbose ( "Enrichers:" ) ; 
for ( Enricher enricher : enrichers ) { 
} public static Properties getThorntailProperties ( URLClassLoader compileClassLoader ) { 
URL ymlResource = compileClassLoader . findResource ( "project-defaults.yml" ) ; 
} public Map < String , String > getRawConfig ( ) { 
return configuration . getProcessorConfig ( ) . orElse ( ProcessorConfig . EMPTY ) . getConfigMap ( name ) ; 
} public String get ( Configs . Key key , String defaultVal ) { 
String val = configuration . getProcessorConfig ( ) . orElse ( ProcessorConfig . EMPTY ) . getConfig ( name , key . name ( ) ) ; 
if ( val == null ) { 
String fullKey = ENRICHER_PROP_PREFIX + "." + name + "." + key ; 
val = configuration . getPropertyWithSystemOverride ( fullKey ) ; 
return val != null ? val : defaultVal ; 
} private void setupIgnoreRules ( ResourceClassifier target ) { 
ignoreValidationRules . add ( new IgnorePortValidationRule ( IgnorePortValidationRule . TYPE ) ) ; 
ignoreValidationRules . add ( new IgnoreResourceMemoryLimitRule ( IgnoreResourceMemoryLimitRule . TYPE ) ) ; 
} public int validate ( ) throws ConstraintViolationException , IOException { 
for ( File resource : resources ) { 
if ( resource . isFile ( ) && resource . exists ( ) ) { 
JsonNode inputSpecNode = geFileContent ( resource ) ; 
String kind = inputSpecNode . get ( "kind" ) . toString ( ) ; 
JsonSchema schema = getJsonSchema ( prepareSchemaUrl ( SCHEMA_JSON ) , kind ) ; 
Set < ValidationMessage > errors = schema . validate ( inputSpecNode ) ; 
processErrors ( errors , resource ) ; 
} catch ( URISyntaxException e ) { 
throw new IOException ( e ) ; 
return resources . length ; 
} private static Map < String , Object > getFlattenedMap ( Map < String , Object > source ) { 
Map < String , Object > result = new LinkedHashMap < > ( ) ; 
buildFlattenedMap ( result , source , null ) ; 
} public String getSanitizedArtifactId ( ) { 
if ( this . artifactId != null && ! this . artifactId . isEmpty ( ) && Character . isDigit ( this . artifactId . charAt ( 0 ) ) ) { 
return PREFIX + this . artifactId ; 
return this . artifactId ; 
} private ProcessorConfig extractWatcherConfig ( ) { 
return ProfileUtil . blendProfileWithConfiguration ( ProfileUtil . WATCHER_CONFIG , profile , ResourceDirCreator . getFinalResourceDir ( resourceDir , environment ) , watcher ) ; 
} protected static Template getSingletonTemplate ( KubernetesList resources ) { 
if ( resources != null ) { 
List < HasMetadata > items = resources . getItems ( ) ; 
if ( items != null && items . size ( ) == 1 ) { 
HasMetadata singleEntity = items . get ( 0 ) ; 
if ( singleEntity instanceof Template ) { 
return ( Template ) singleEntity ; 
} private List < ImageConfiguration > getResolvedImages ( List < ImageConfiguration > images , final Logger log ) 
throws MojoExecutionException { 
List < ImageConfiguration > ret ; 
ret = ConfigHelper . resolveImages ( 
log , 
images , 
( ImageConfiguration image ) -> imageConfigResolver . resolve ( image , project , session ) , 
( List < ImageConfiguration > configs ) -> { 
Date now = getBuildReferenceDate ( ) ; 
storeReferenceDateInPluginContext ( now ) ; 
String minimalApiVersion = ConfigHelper . initAndValidate ( ret , null , 
new ImageNameFormatter ( project , now ) , log ) ; 
} private Date getBuildReferenceDate ( ) throws MojoExecutionException { 
File tsFile = new File ( project . getBuild ( ) . getDirectory ( ) , AbstractDockerMojo . DOCKER_BUILD_TIMESTAMP ) ; 
if ( ! tsFile . exists ( ) ) { 
return new Date ( ) ; 
return EnvUtil . loadTimestamp ( tsFile ) ; 
} public static boolean configEqual ( Object entity1 , Object entity2 ) { 
if ( entity1 == entity2 ) { 
} else if ( entity1 == null || entity2 == null ) { 
} else if ( entity1 instanceof Map ) { 
return configEqualMap ( ( Map ) entity1 , castTo ( Map . class , entity2 ) ) ; 
} else if ( entity2 instanceof Map ) { 
} else if ( entity2 instanceof ObjectMeta ) { 
return configEqualObjectMeta ( ( ObjectMeta ) entity1 , castTo ( ObjectMeta . class , entity2 ) ) ; 
} else if ( entity1 instanceof Collection && entity2 instanceof Collection ) { 
return collectionsEqual ( ( Collection ) entity1 , ( Collection ) entity2 ) ; 
Class < ? > aClass = getCommonDenominator ( entity1 . getClass ( ) , entity2 . getClass ( ) ) ; 
if ( aClass != null ) { 
Object castEntity2 = castTo ( aClass , entity2 ) ; 
if ( castEntity2 == null ) { 
} else if ( aClass . getPackage ( ) . getName ( ) . startsWith ( "io.fabric8" ) ) { 
return configEqualKubernetesDTO ( entity1 , entity2 , aClass ) ; 
return java . util . Objects . equals ( entity1 , entity2 ) ; 
} protected static boolean configEqualKubernetesDTO ( @ NotNull Object entity1 , @ NotNull Object entity2 , @ NotNull Class < ? > clazz ) { 
BeanInfo beanInfo = null ; 
beanInfo = Introspector . getBeanInfo ( clazz ) ; 
} catch ( IntrospectionException e ) { 
PropertyDescriptor [ ] propertyDescriptors = beanInfo . getPropertyDescriptors ( ) ; 
for ( PropertyDescriptor propertyDescriptor : propertyDescriptors ) { 
String name = propertyDescriptor . getName ( ) ; 
if ( ignoredProperties . contains ( name ) ) { 
Method readMethod = propertyDescriptor . getReadMethod ( ) ; 
if ( readMethod != null ) { 
Object value1 = invokeMethod ( entity1 , readMethod ) ; 
Object value2 = invokeMethod ( entity2 , readMethod ) ; 
if ( value1 != null && value2 != null && ! configEqual ( value1 , value2 ) ) { 
} private static void combineParameters ( List < Parameter > parameters , List < Parameter > otherParameters ) { 
if ( otherParameters != null && otherParameters . size ( ) > 0 ) { 
Map < String , Parameter > map = new HashMap < > ( ) ; 
for ( Parameter parameter : parameters ) { 
map . put ( parameter . getName ( ) , parameter ) ; 
for ( Parameter otherParameter : otherParameters ) { 
String name = otherParameter . getName ( ) ; 
Parameter original = map . get ( name ) ; 
if ( original == null ) { 
parameters . add ( otherParameter ) ; 
if ( StringUtils . isNotBlank ( original . getValue ( ) ) ) { 
original . setValue ( otherParameter . getValue ( ) ) ; 
String keyVal = key != null ? key . name ( ) : "" ; 
String val = config != null ? config . getConfig ( name , key . name ( ) ) : null ; 
String fullKey = GENERATOR_PROP_PREFIX + "." + name + "." + key ; 
val = Configs . getSystemPropertyWithMavenPropertyAsFallback ( properties , fullKey ) ; 
String fullKey = WATCHER_PROP_PREFIX + "." + name + "." + key ; 
val = Configs . getSystemPropertyWithMavenPropertyAsFallback ( projectProperties , fullKey ) ; 
} public Map < String , String > getConfigMap ( String name ) { 
return config . containsKey ( name ) ? 
Collections . unmodifiableMap ( config . get ( name ) ) : 
Collections . < String , String > emptyMap ( ) ; 
} public < T extends Named > List < T > prepareProcessors ( List < T > namedList , String type ) { 
List < T > ret = new ArrayList < > ( ) ; 
Map < String , T > lookup = new HashMap < > ( ) ; 
for ( T named : namedList ) { 
lookup . put ( named . getName ( ) , named ) ; 
for ( String inc : includes ) { 
if ( use ( inc ) ) { 
T named = lookup . get ( inc ) ; 
if ( named == null ) { 
List < String > keys = new ArrayList < > ( lookup . keySet ( ) ) ; 
Collections . sort ( keys ) ; 
ret . add ( named ) ; 
} public static ProcessorConfig mergeProcessorConfigs ( ProcessorConfig ... processorConfigs ) { 
Map < String , TreeMap > configs = mergeConfig ( processorConfigs ) ; 
Set < String > excludes = mergeExcludes ( processorConfigs ) ; 
List < String > includes = mergeIncludes ( processorConfigs ) ; 
return new ProcessorConfig ( includes , excludes , configs ) ; 
} private static List < String > removeDups ( List < String > list ) { 
for ( String el : list ) { 
if ( ! ret . contains ( el ) ) { 
ret . add ( el ) ; 
} protected void addFrom ( BuildImageConfiguration . Builder builder ) { 
String fromMode = getConfigWithFallback ( Config . fromMode , "fabric8.generator.fromMode" , getFromModeDefault ( context . getRuntimeMode ( ) ) ) ; 
String from = getConfigWithFallback ( Config . from , "fabric8.generator.from" , null ) ; 
if ( "docker" . equalsIgnoreCase ( fromMode ) ) { 
String fromImage = from ; 
if ( fromImage == null ) { 
fromImage = fromSelector != null ? fromSelector . getFrom ( ) : null ; 
builder . from ( fromImage ) ; 
} else if ( "istag" . equalsIgnoreCase ( fromMode ) ) { 
Map < String , String > fromExt = new HashMap < > ( ) ; 
if ( from != null ) { 
ImageName iName = new ImageName ( from ) ; 
String tag = iName . getTag ( ) ; 
if ( StringUtils . isBlank ( tag ) ) { 
tag = "latest" ; 
fromExt . put ( OpenShiftBuildStrategy . SourceStrategy . name . key ( ) , iName . getSimpleName ( ) + ":" + tag ) ; 
if ( iName . getUser ( ) != null ) { 
fromExt . put ( OpenShiftBuildStrategy . SourceStrategy . namespace . key ( ) , iName . getUser ( ) ) ; 
fromExt . put ( OpenShiftBuildStrategy . SourceStrategy . kind . key ( ) , "ImageStreamTag" ) ; 
fromExt = fromSelector != null ? fromSelector . getImageStreamTagFromExt ( ) : null ; 
if ( fromExt != null ) { 
String namespace = fromExt . get ( OpenShiftBuildStrategy . SourceStrategy . namespace . key ( ) ) ; 
if ( namespace != null ) { 
fromExt . get ( OpenShiftBuildStrategy . SourceStrategy . name . key ( ) ) , namespace ) ; 
fromExt . get ( OpenShiftBuildStrategy . SourceStrategy . name . key ( ) ) ) ; 
builder . fromExt ( fromExt ) ; 
} private String getFromModeDefault ( RuntimeMode mode ) { 
if ( mode == RuntimeMode . openshift && fromSelector != null && fromSelector . isRedHat ( ) ) { 
return "istag" ; 
return "docker" ; 
} protected String getImageName ( ) { 
if ( RuntimeMode . isOpenShiftMode ( getProject ( ) . getProperties ( ) ) ) { 
return getConfigWithFallback ( Config . name , "fabric8.generator.name" , "%a:%l" ) ; 
return getConfigWithFallback ( Config . name , "fabric8.generator.name" , "%g/%a:%l" ) ; 
} protected String getRegistry ( ) { 
if ( ! RuntimeMode . isOpenShiftMode ( getProject ( ) . getProperties ( ) ) ) { 
return getConfigWithFallback ( Config . registry , "fabric8.generator.registry" , null ) ; 
} public static String getAbsolutePath ( URL url ) { 
return url != null ? Paths . get ( url . toURI ( ) ) . toAbsolutePath ( ) . toString ( ) : null ; 
} boolean isOnline ( ) { 
String isOnline = getConfig ( Config . online ) ; 
if ( isOnline != null ) { 
return Configs . asBoolean ( isOnline ) ; 
Boolean ret = asBooleanFromGlobalProp ( "fabric8.online" ) ; 
return ret != null ? ret : getDefaultOnline ( ) ; 
} protected String getExternalServiceURL ( String serviceName , String protocol ) { 
if ( ! isOnline ( ) ) { 
KubernetesClient kubernetes = getKubernetes ( ) ; 
String ns = kubernetes . getNamespace ( ) ; 
if ( StringUtils . isBlank ( ns ) ) { 
ns = getNamespace ( ) ; 
Service service = kubernetes . services ( ) . inNamespace ( ns ) . withName ( serviceName ) . get ( ) ; 
return service != null ? 
ServiceUrlUtil . getServiceURL ( kubernetes , serviceName , ns , protocol , true ) : 
null ; 
Throwable cause = e ; 
boolean notFound = false ; 
boolean connectError = false ; 
Stack < Throwable > stack = unfoldExceptions ( e ) ; 
Throwable t = stack . pop ( ) ; 
serviceName , cause . getMessage ( ) ) ; 
} else if ( t instanceof IllegalArgumentException || 
t . getMessage ( ) != null && t . getMessage ( ) . matches ( "^No.*found.*$" ) ) { 
getLog ( ) . warn ( "%s" , cause . getMessage ( ) ) ; 
} protected Stack < Throwable > unfoldExceptions ( Throwable exception ) { 
Stack < Throwable > throwables = new Stack < > ( ) ; 
Throwable current = exception ; 
while ( current != null ) { 
throwables . push ( current ) ; 
current = current . getCause ( ) ; 
return throwables ; 
} protected Boolean asBooleanFromGlobalProp ( String prop ) { 
String value = getContext ( ) . getConfiguration ( ) . getProperty ( prop ) ; 
value = System . getProperty ( prop ) ; 
return value != null ? Boolean . valueOf ( value ) : null ; 
} private String getNamespace ( ) { 
String namespace = getConfig ( Config . namespace ) ; 
if ( StringUtils . isNotBlank ( namespace ) ) { 
return namespace ; 
namespace = getContext ( ) . getConfiguration ( ) . getProperty ( "fabric8.namespace" ) ; 
namespace = System . getProperty ( "fabric8.namespace" ) ; 
return KubernetesHelper . getDefaultNamespace ( ) ; 
} private JestClient createJestClient ( String uri ) { 
HttpClientConfig . Builder builder = new HttpClientConfig . Builder ( uri ) 
. maxTotalConnection ( properties . getMaxTotalConnection ( ) ) 
. defaultMaxTotalConnectionPerRoute ( properties . getDefaultMaxTotalConnectionPerRoute ( ) ) 
. maxConnectionIdleTime ( properties . getMaxConnectionIdleTime ( ) , TimeUnit . MILLISECONDS ) 
. readTimeout ( properties . getReadTimeout ( ) ) 
. multiThreaded ( properties . getMultiThreaded ( ) ) ; 
if ( StringUtils . hasText ( this . properties . getUsername ( ) ) ) { 
builder . defaultCredentials ( this . properties . getUsername ( ) , this . properties . getPassword ( ) ) ; 
String proxyHost = this . properties . getProxy ( ) . getHost ( ) ; 
if ( StringUtils . hasText ( proxyHost ) ) { 
Integer proxyPort = this . properties . getProxy ( ) . getPort ( ) ; 
builder . proxy ( new HttpHost ( proxyHost , proxyPort ) ) ; 
List < HttpClientConfigBuilderCustomizer > configBuilderCustomizers = builderCustomizers != null ? builderCustomizers . getIfAvailable ( ) : new ArrayList < > ( ) ; 
if ( ! CollectionUtils . isEmpty ( configBuilderCustomizers ) ) { 
configBuilderCustomizers . stream ( ) . forEach ( customizer -> customizer . customize ( builder ) ) ; 
JestClientFactory factory = jestClientFactory != null ? jestClientFactory : new JestClientFactory ( ) ; 
factory . setHttpClientConfig ( builder . build ( ) ) ; 
return factory . getObject ( ) ; 
} private int createInternalNode ( ) throws NodeValidationException { 
int port = SocketUtils . findAvailableTcpPort ( ) ; 
String clusterName = INTERNAL_TEST_CLUSTER_NAME + UUID . randomUUID ( ) ; 
Settings . Builder settingsBuilder = Settings . builder ( ) 
. put ( "cluster.name" , clusterName ) 
. put ( "http.type" , "netty4" ) 
. put ( "http.port" , String . valueOf ( port ) ) ; 
if ( this . esNodeproperties != null ) { 
this . esNodeproperties . getProperties ( ) . forEach ( settingsBuilder :: put ) ; 
Collection < Class < ? extends Plugin > > plugins = scanPlugins ( ) ; 
plugins . add ( Netty4Plugin . class ) ; 
this . node = new InternalNode ( settingsBuilder . build ( ) , plugins ) . start ( ) ; 
return Integer . parseInt ( settingsBuilder . get ( "http.port" ) ) ; 
private static Collection < Class < ? extends Plugin > > scanPlugins ( ) { 
ClassPathScanningCandidateComponentProvider componentProvider = new ClassPathScanningCandidateComponentProvider ( false ) ; 
componentProvider . addIncludeFilter ( new AssignableTypeFilter ( Plugin . class ) ) ; 
return componentProvider . findCandidateComponents ( "org.elasticsearch.plugin" ) . stream ( ) 
. map ( BeanDefinition :: getBeanClassName ) 
. map ( name -> { 
return ( Class < ? extends Plugin > ) Class . forName ( name ) ; 
. collect ( Collectors . toSet ( ) ) ; 
} private void extractDistanceString ( Distance distance , StringBuilder sb ) { 
sb . append ( ( int ) distance . getValue ( ) ) ; 
Metrics metric = ( Metrics ) distance . getMetric ( ) ; 
switch ( metric ) { 
case KILOMETERS : 
sb . append ( "km" ) ; 
case MILES : 
sb . append ( "mi" ) ; 
} private static void addSingleFieldMapping ( XContentBuilder builder , java . lang . reflect . Field field , Field annotation , boolean nestedOrObjectField ) throws IOException { 
builder . startObject ( field . getName ( ) ) ; 
addFieldMappingParameters ( builder , annotation , nestedOrObjectField ) ; 
builder . endObject ( ) ; 
} private static void addMultiFieldMapping ( 
XContentBuilder builder , 
java . lang . reflect . Field field , 
MultiField annotation , 
boolean nestedOrObjectField ) throws IOException { 
addFieldMappingParameters ( builder , annotation . mainField ( ) , nestedOrObjectField ) ; 
builder . startObject ( "fields" ) ; 
for ( InnerField innerField : annotation . otherFields ( ) ) { 
builder . startObject ( innerField . suffix ( ) ) ; 
addFieldMappingParameters ( builder , innerField , false ) ; 
} public Property getPropertyMetaData ( int propertyNo ) { 
long cPtr = VideoJNI . Configurable_getPropertyMetaData__SWIG_0 ( swigCPtr , this , propertyNo ) ; 
return ( cPtr == 0 ) ? null : new Property ( cPtr , false ) ; 
} public Property getPropertyMetaData ( String name ) { 
long cPtr = VideoJNI . Configurable_getPropertyMetaData__SWIG_1 ( swigCPtr , this , name ) ; 
} public void setProperty ( String name , String value ) { 
VideoJNI . Configurable_setProperty__SWIG_0 ( swigCPtr , this , name , value ) ; 
} public void setProperty ( String name , Rational value ) { 
VideoJNI . Configurable_setProperty__SWIG_4 ( swigCPtr , this , name , Rational . getCPtr ( value ) , value ) ; 
} public Rational getPropertyAsRational ( String name ) { 
long cPtr = VideoJNI . Configurable_getPropertyAsRational ( swigCPtr , this , name ) ; 
return ( cPtr == 0 ) ? null : new Rational ( cPtr , false ) ; 
} public void setProperty ( KeyValueBag valuesToSet , KeyValueBag valuesNotFound ) { 
VideoJNI . Configurable_setProperty__SWIG_5 ( swigCPtr , this , KeyValueBag . getCPtr ( valuesToSet ) , valuesToSet , KeyValueBag . getCPtr ( valuesNotFound ) , valuesNotFound ) ; 
} public java . util . Collection < Codec . ID > getSupportedCodecs ( ) 
final java . util . List < Codec . ID > retval = 
new java . util . LinkedList < Codec . ID > ( ) ; 
final java . util . Set < Codec . ID > uniqueSet = 
new java . util . HashSet < Codec . ID > ( ) ; 
int numCodecs = getNumSupportedCodecs ( ) ; 
for ( int i = 0 ; i < numCodecs ; i ++ ) 
Codec . ID id = getSupportedCodecId ( i ) ; 
if ( id != Codec . ID . CODEC_ID_NONE && ! uniqueSet . contains ( id ) ) 
retval . add ( id ) ; 
uniqueSet . add ( id ) ; 
return retval ; 
} public java . util . Collection < Long > getSupportedTags ( ) 
final java . util . List < Long > retval = 
new java . util . LinkedList < Long > ( ) ; 
final java . util . Set < Long > uniqueSet = 
new java . util . HashSet < Long > ( ) ; 
long tag = getSupportedCodecTag ( i ) ; 
if ( id != Codec . ID . CODEC_ID_NONE && ! uniqueSet . contains ( tag ) ) 
retval . add ( tag ) ; 
uniqueSet . add ( tag ) ; 
} protected Codec . ID getSupportedCodecId ( int n ) { 
return Codec . ID . swigToEnum ( VideoJNI . ContainerFormat_getSupportedCodecId ( swigCPtr , this , n ) ) ; 
} public long getNumPinnedObjects ( ) 
long numPinnedObjects = 0 ; 
blockingLock ( ) ; 
int numItems = mNextAvailableReferenceSlot ; 
for ( int i = 0 ; i < numItems ; i ++ ) 
JNIReference ref = mValidReferences [ i ] ; 
if ( ref != null && ! ref . isDeleted ( ) ) 
++ numPinnedObjects ; 
blockingUnlock ( ) ; 
return numPinnedObjects ; 
} public void dumpMemoryLog ( ) 
if ( ref != null ) 
} final boolean addReference ( final JNIReference ref ) 
boolean gotNonblockingLock = false ; 
gotNonblockingLock = mSpinLock . compareAndSet ( false , true ) ; 
if ( gotNonblockingLock ) 
final int slot = mNextAvailableReferenceSlot ++ ; 
if ( slot < mMaxValidReference ) 
mValidReferences [ slot ] = ref ; 
final boolean result = mSpinLock . compareAndSet ( true , false ) ; 
if ( ! mLock . tryLock ( ) ) { 
gotNonblockingLock = false ; 
mSpinLock . compareAndSet ( true , false ) ; 
if ( ! gotNonblockingLock ) { 
mLock . lock ( ) ; 
while ( ! mSpinLock . compareAndSet ( false , true ) ) 
int slot = mNextAvailableReferenceSlot ++ ; 
if ( slot >= mMaxValidReference ) 
sweepAndCollect ( ) ; 
slot = mNextAvailableReferenceSlot ++ ; 
mLock . unlock ( ) ; 
} void gcInternal ( ) 
JNIReference ref = null ; 
while ( ( ref = ( JNIReference ) mRefQueue . poll ( ) ) != null ) 
ref . delete ( ) ; 
} public void startCollectionThread ( ) 
synchronized ( this ) 
if ( mCollectionThread != null ) 
mCollectionThread = new Thread ( new Runnable ( ) 
public void run ( ) 
ref = ( JNIReference ) mRefQueue . remove ( ) ; 
catch ( InterruptedException ex ) 
synchronized ( JNIMemoryManager . this ) 
mCollectionThread = null ; 
mCollectionThread . setDaemon ( true ) ; 
mCollectionThread . start ( ) ; 
} final public void flush ( ) 
int numSurvivors = sweepAndCollect ( ) ; 
for ( int i = 0 ; i < numSurvivors ; i ++ ) 
final JNIReference ref = mValidReferences [ i ] ; 
mValidReferences = new JNIReference [ mMinimumReferencesToCache ] ; 
mNextAvailableReferenceSlot = 0 ; 
mMaxValidReference = mMinimumReferencesToCache ; 
} public byte [ ] malloc ( int size ) 
byte [ ] retval = null ; 
JNIMemoryParachute . getParachute ( ) . packChute ( ) ; 
if ( SHOULD_RETRY_FAILED_ALLOCS ) 
int allocationAttempts = 0 ; 
int backoffTimeout = 10 ; 
retval = new byte [ size ] ; 
catch ( final OutOfMemoryError e ) 
++ allocationAttempts ; 
if ( allocationAttempts >= MAX_ALLOCATION_ATTEMPTS ) 
JNIMemoryParachute . getParachute ( ) . pullCord ( ) ; 
JNIReference . getMgr ( ) . gcInternal ( ) ; 
allocationAttempts , size ) ; 
if ( allocationAttempts <= 1 ) 
Thread . sleep ( backoffTimeout ) ; 
backoffTimeout = ( int ) ( backoffTimeout * FALLBACK_TIME_DECAY ) ; 
catch ( InterruptedException e1 ) 
addToBuffer ( retval ) ; 
retval [ retval . length - 1 ] = 0 ; 
catch ( Throwable t ) 
retval = null ; 
} public void addPicture ( MediaPicture picture ) { 
VideoJNI . FilterPictureSource_addPicture ( swigCPtr , this , MediaPicture . getCPtr ( picture ) , picture ) ; 
public static void load ( String appname , JNILibrary library ) { 
synchronized ( mLock ) { 
deleteTemporaryFiles ( ) ; 
library . load ( appname ) ; 
} catch ( UnsatisfiedLinkError e ) { 
JNILibraryLoader . loadLibrary ( library . getName ( ) , library . getVersion ( ) ) ; 
} private boolean unpackLibrary ( String path ) { 
boolean retval = false ; 
final Enumeration < URL > c = JNILibrary . class . getClassLoader ( ) 
. getResources ( path ) ; 
while ( c . hasMoreElements ( ) ) { 
final URL url = c . nextElement ( ) ; 
if ( url == null ) 
boolean unpacked = false ; 
File lib ; 
if ( url . getProtocol ( ) . toLowerCase ( ) . equals ( "file" ) ) { 
lib = new File ( new URI ( url . toString ( ) ) ) ; 
lib = new File ( url . getPath ( ) ) ; 
if ( ! lib . exists ( ) ) { 
url ) ; 
} else if ( url . getProtocol ( ) . toLowerCase ( ) . equals ( "jar" ) ) { 
InputStream stream = url . openStream ( ) ; 
if ( stream == null ) { 
FileOutputStream out = null ; 
File dir = getTmpDir ( ) ; 
lib = File 
. createTempFile ( 
"humble" , 
JNIEnv . getEnv ( ) . getOSFamily ( ) == JNIEnv . OSFamily . WINDOWS ? ".dll" 
: null , dir ) ; 
lib . deleteOnExit ( ) ; 
out = new FileOutputStream ( lib ) ; 
int bytesRead = 0 ; 
final byte [ ] buffer = new byte [ 2048 ] ; 
while ( ( bytesRead = stream . read ( buffer , 0 , buffer . length ) ) > 0 ) { 
out . write ( buffer , 0 , bytesRead ) ; 
unpacked = true ; 
stream . close ( ) ; 
doJNILoad ( lib . getAbsolutePath ( ) ) ; 
retval = true ; 
if ( unpacked ) { 
deleteUnpackedFile ( lib . getAbsolutePath ( ) ) ; 
} catch ( IOException e1 ) { 
retval = false ; 
} private static void deleteTemporaryFiles ( ) { 
final File dir = getTmpDir ( ) ; 
final FilenameFilter filter = new FilenameFilter ( ) { 
public boolean accept ( File dir , String name ) { 
return name . endsWith ( HUMBLE_TEMP_EXTENSION ) ; 
final File markers [ ] = dir . listFiles ( filter ) ; 
for ( File marker : markers ) { 
final String markerName = marker . getName ( ) ; 
final String libName = markerName . substring ( 0 , markerName . length ( ) 
- HUMBLE_TEMP_EXTENSION . length ( ) ) ; 
final File lib = new File ( marker . getParentFile ( ) , libName ) ; 
if ( ! lib . exists ( ) || lib . delete ( ) ) 
marker . delete ( ) ; 
} public static AudioChannel . Layout getDefaultLayout ( int numChannels ) { 
return AudioChannel . Layout . swigToEnum ( VideoJNI . AudioChannel_getDefaultLayout ( numChannels ) ) ; 
} public static int getIndexOfChannelInLayout ( AudioChannel . Layout layout , AudioChannel . Type channel ) { 
return VideoJNI . AudioChannel_getIndexOfChannelInLayout ( layout . swigValue ( ) , channel . swigValue ( ) ) ; 
} public static AudioChannel . Type getChannelFromLayoutAtIndex ( AudioChannel . Layout layout , int index ) { 
return AudioChannel . Type . swigToEnum ( VideoJNI . AudioChannel_getChannelFromLayoutAtIndex ( layout . swigValue ( ) , index ) ) ; 
} public static PixelFormat . Type getFormat ( String name ) { 
return PixelFormat . Type . swigToEnum ( VideoJNI . PixelFormat_getFormat ( name ) ) ; 
} public static PixelFormatDescriptor getInstalledFormatDescriptor ( int i ) { 
long cPtr = VideoJNI . PixelFormat_getInstalledFormatDescriptor ( i ) ; 
return ( cPtr == 0 ) ? null : new PixelFormatDescriptor ( cPtr , false ) ; 
} public static PixelFormat . Type swapEndianness ( PixelFormat . Type pix_fmt ) { 
return PixelFormat . Type . swigToEnum ( VideoJNI . PixelFormat_swapEndianness ( pix_fmt . swigValue ( ) ) ) ; 
} public static int getBufferSizeNeeded ( int width , int height , PixelFormat . Type pix_fmt ) { 
return VideoJNI . PixelFormat_getBufferSizeNeeded ( width , height , pix_fmt . swigValue ( ) ) ; 
} public static MediaPacket make ( ) { 
long cPtr = VideoJNI . MediaPacket_make__SWIG_0 ( ) ; 
return ( cPtr == 0 ) ? null : new MediaPacket ( cPtr , false ) ; 
} public static MediaPacket make ( Buffer buffer ) { 
long cPtr = VideoJNI . MediaPacket_make__SWIG_1 ( Buffer . getCPtr ( buffer ) , buffer ) ; 
} public static MediaPacket make ( MediaPacket packet , boolean copyData ) { 
long cPtr = VideoJNI . MediaPacket_make__SWIG_2 ( MediaPacket . getCPtr ( packet ) , packet , copyData ) ; 
} public static MediaPacket make ( int size ) { 
long cPtr = VideoJNI . MediaPacket_make__SWIG_3 ( size ) ; 
} public Buffer getData ( ) { 
long cPtr = VideoJNI . MediaPacket_getData ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new Buffer ( cPtr , false ) ; 
} public Buffer getSideData ( int n ) { 
long cPtr = VideoJNI . MediaPacket_getSideData ( swigCPtr , this , n ) ; 
} public MediaPacket . SideDataType getSideDataType ( int n ) { 
return MediaPacket . SideDataType . swigToEnum ( VideoJNI . MediaPacket_getSideDataType ( swigCPtr , this , n ) ) ; 
} public static FilterType findFilterType ( String name ) { 
long cPtr = VideoJNI . FilterType_findFilterType ( name ) ; 
return ( cPtr == 0 ) ? null : new FilterType ( cPtr , false ) ; 
} public int open ( String url , int flags ) 
if ( mOpenStream != null ) 
mOpenStream ) ; 
switch ( flags ) 
case URL_RDWR : 
if ( mDataInput != null && mDataOutput != null && 
mDataInput == mDataOutput && 
mDataInput instanceof RandomAccessFile ) { 
mOpenStream = mDataInput ; 
case URL_WRONLY_MODE : 
mOpenStream = mDataOutput ; 
if ( mOpenStream == null ) 
case URL_RDONLY_MODE : 
} public int read ( byte [ ] buf , int size ) 
int ret = - 1 ; 
if ( mOpenStream == null || ! ( mOpenStream instanceof DataInput ) ) 
if ( mOpenStream instanceof RandomAccessFile ) { 
RandomAccessFile file = ( RandomAccessFile ) mOpenStream ; 
return file . read ( buf , 0 , size ) ; 
} else if ( mOpenStream instanceof DataInputStream ) { 
DataInputStream stream = ( DataInputStream ) mOpenStream ; 
return stream . read ( buf , 0 , size ) ; 
DataInput input = ( DataInput ) mOpenStream ; 
input . readFully ( buf , 0 , size ) ; 
ret = size ; 
} catch ( EOFException e ) { 
ret = - 1 ; 
catch ( IOException e ) 
mOpenStream , e ) ; 
} public long seek ( long offset , int whence ) 
if ( ! ( mOpenStream instanceof RandomAccessFile ) ) 
final RandomAccessFile file = ( RandomAccessFile ) mOpenStream ; 
final long seek ; 
if ( whence == SEEK_SET ) 
seek = offset ; 
else if ( whence == SEEK_CUR ) 
seek = file . getFilePointer ( ) + offset ; 
else if ( whence == SEEK_END ) 
seek = file . length ( ) + offset ; 
else if ( whence == SEEK_SIZE ) 
return ( int ) file . length ( ) ; 
file . seek ( seek ) ; 
return seek ; 
. getMessage ( ) , file ) ; 
} public int write ( byte [ ] buf , int size ) 
if ( mOpenStream == null || 
! ( mOpenStream instanceof DataOutput ) ) 
DataOutput output = ( DataOutput ) mOpenStream ; 
output . write ( buf , 0 , size ) ; 
} public boolean isStreamed ( String url , int flags ) 
if ( mDataInput != null && mDataInput instanceof RandomAccessFile ) 
if ( mDataOutput != null && mDataOutput instanceof RandomAccessFile ) 
} public PixelComponentDescriptor getComponentDescriptor ( int component ) { 
long cPtr = VideoJNI . PixelFormatDescriptor_getComponentDescriptor ( swigCPtr , this , component ) ; 
return ( cPtr == 0 ) ? null : new PixelComponentDescriptor ( cPtr , false ) ; 
} public static String getVersionInfo ( ) { 
final Class < ? > c = Version . class ; 
final StringBuilder b = new StringBuilder ( ) ; 
final Package p = c . getPackage ( ) ; 
return b . toString ( ) ; 
} public static Rational getDefaultTimeBase ( ) { 
long cPtr = VideoJNI . Global_getDefaultTimeBase ( ) ; 
} public Property getFlagConstant ( int position ) { 
long cPtr = VideoJNI . Property_getFlagConstant__SWIG_0 ( swigCPtr , this , position ) ; 
} public Property getFlagConstant ( String name ) { 
long cPtr = VideoJNI . Property_getFlagConstant__SWIG_1 ( swigCPtr , this , name ) ; 
} public static Demuxer make ( ) { 
long cPtr = VideoJNI . Demuxer_make ( ) ; 
return ( cPtr == 0 ) ? null : new Demuxer ( cPtr , false ) ; 
} public DemuxerFormat getFormat ( ) { 
long cPtr = VideoJNI . Demuxer_getFormat ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new DemuxerFormat ( cPtr , false ) ; 
} public void open ( String url , DemuxerFormat format , boolean streamsCanBeAddedDynamically , boolean queryStreamMetaData , KeyValueBag options , KeyValueBag optionsNotSet ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Demuxer_open ( swigCPtr , this , url , DemuxerFormat . getCPtr ( format ) , format , streamsCanBeAddedDynamically , queryStreamMetaData , KeyValueBag . getCPtr ( options ) , options , KeyValueBag . getCPtr ( optionsNotSet ) , optionsNotSet ) ; 
} public void close ( ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Demuxer_close ( swigCPtr , this ) ; 
} public DemuxerStream getStream ( int streamIndex ) throws java . lang . InterruptedException , java . io . IOException { 
long cPtr = VideoJNI . Demuxer_getStream ( swigCPtr , this , streamIndex ) ; 
return ( cPtr == 0 ) ? null : new DemuxerStream ( cPtr , false ) ; 
} public int read ( MediaPacket packet ) throws java . lang . InterruptedException , java . io . IOException { 
return VideoJNI . Demuxer_read ( swigCPtr , this , MediaPacket . getCPtr ( packet ) , packet ) ; 
} public void queryStreamMetaData ( ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Demuxer_queryStreamMetaData ( swigCPtr , this ) ; 
} public void setFlag ( Container . Flag flag , boolean value ) { 
VideoJNI . Demuxer_setFlag ( swigCPtr , this , flag . swigValue ( ) , value ) ; 
} public KeyValueBag getMetaData ( ) { 
long cPtr = VideoJNI . Demuxer_getMetaData ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new KeyValueBag ( cPtr , false ) ; 
} public int seek ( int stream_index , long min_ts , long ts , long max_ts , int flags ) throws java . lang . InterruptedException , java . io . IOException { 
return VideoJNI . Demuxer_seek ( swigCPtr , this , stream_index , min_ts , ts , max_ts , flags ) ; 
} public void play ( ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Demuxer_play ( swigCPtr , this ) ; 
} public void pause ( ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Demuxer_pause ( swigCPtr , this ) ; 
} public Rational copy ( ) { 
long cPtr = VideoJNI . Rational_copy ( swigCPtr , this ) ; 
} public int compareTo ( Rational other ) { 
return VideoJNI . Rational_compareTo ( swigCPtr , this , Rational . getCPtr ( other ) , other ) ; 
} public static int sCompareTo ( Rational a , Rational b ) { 
return VideoJNI . Rational_sCompareTo ( Rational . getCPtr ( a ) , a , Rational . getCPtr ( b ) , b ) ; 
} public int reduce ( long num , long den , long max ) { 
return VideoJNI . Rational_reduce ( swigCPtr , this , num , den , max ) ; 
} public static int sReduce ( Rational dst , long num , long den , long max ) { 
return VideoJNI . Rational_sReduce ( Rational . getCPtr ( dst ) , dst , num , den , max ) ; 
} public Rational multiply ( Rational arg ) { 
long cPtr = VideoJNI . Rational_multiply ( swigCPtr , this , Rational . getCPtr ( arg ) , arg ) ; 
} public static Rational sMultiply ( Rational a , Rational b ) { 
long cPtr = VideoJNI . Rational_sMultiply ( Rational . getCPtr ( a ) , a , Rational . getCPtr ( b ) , b ) ; 
} public Rational divide ( Rational arg ) { 
long cPtr = VideoJNI . Rational_divide ( swigCPtr , this , Rational . getCPtr ( arg ) , arg ) ; 
} public static Rational sDivide ( Rational a , Rational b ) { 
long cPtr = VideoJNI . Rational_sDivide ( Rational . getCPtr ( a ) , a , Rational . getCPtr ( b ) , b ) ; 
} public Rational subtract ( Rational arg ) { 
long cPtr = VideoJNI . Rational_subtract ( swigCPtr , this , Rational . getCPtr ( arg ) , arg ) ; 
} public static Rational sSubtract ( Rational a , Rational b ) { 
long cPtr = VideoJNI . Rational_sSubtract ( Rational . getCPtr ( a ) , a , Rational . getCPtr ( b ) , b ) ; 
} public Rational add ( Rational arg ) { 
long cPtr = VideoJNI . Rational_add ( swigCPtr , this , Rational . getCPtr ( arg ) , arg ) ; 
} public static Rational sAdd ( Rational a , Rational b ) { 
long cPtr = VideoJNI . Rational_sAdd ( Rational . getCPtr ( a ) , a , Rational . getCPtr ( b ) , b ) ; 
} public long rescale ( long origValue , Rational origBase ) { 
return VideoJNI . Rational_rescale__SWIG_0 ( swigCPtr , this , origValue , Rational . getCPtr ( origBase ) , origBase ) ; 
} public static long sRescale ( long origValue , Rational origBase , Rational newBase ) { 
return VideoJNI . Rational_sRescale__SWIG_0 ( origValue , Rational . getCPtr ( origBase ) , origBase , Rational . getCPtr ( newBase ) , newBase ) ; 
} public static Rational make ( ) { 
long cPtr = VideoJNI . Rational_make__SWIG_0 ( ) ; 
} public static Rational make ( double d ) { 
long cPtr = VideoJNI . Rational_make__SWIG_1 ( d ) ; 
} public static Rational make ( Rational src ) { 
long cPtr = VideoJNI . Rational_make__SWIG_2 ( Rational . getCPtr ( src ) , src ) ; 
} public static Rational make ( int num , int den ) { 
long cPtr = VideoJNI . Rational_make__SWIG_3 ( num , den ) ; 
} public long rescale ( long origValue , Rational origBase , Rational . Rounding rounding ) { 
return VideoJNI . Rational_rescale__SWIG_1 ( swigCPtr , this , origValue , Rational . getCPtr ( origBase ) , origBase , rounding . swigValue ( ) ) ; 
} public static long sRescale ( long origValue , Rational origBase , Rational newBase , Rational . Rounding rounding ) { 
return VideoJNI . Rational_sRescale__SWIG_1 ( origValue , Rational . getCPtr ( origBase ) , origBase , Rational . getCPtr ( newBase ) , newBase , rounding . swigValue ( ) ) ; 
} public static long rescale ( long srcValue , int dstNumerator , int dstDenominator , int srcNumerator , int srcDenominator , Rational . Rounding rounding ) { 
return VideoJNI . Rational_rescale__SWIG_2 ( srcValue , dstNumerator , dstDenominator , srcNumerator , srcDenominator , rounding . swigValue ( ) ) ; 
} private static void playVideo ( String filename ) throws InterruptedException , IOException { 
Demuxer demuxer = Demuxer . make ( ) ; 
demuxer . open ( filename , null , false , true , null , null ) ; 
int numStreams = demuxer . getNumStreams ( ) ; 
int videoStreamId = - 1 ; 
long streamStartTime = Global . NO_PTS ; 
Decoder videoDecoder = null ; 
for ( int i = 0 ; i < numStreams ; i ++ ) 
final DemuxerStream stream = demuxer . getStream ( i ) ; 
streamStartTime = stream . getStartTime ( ) ; 
final Decoder decoder = stream . getDecoder ( ) ; 
if ( decoder != null && decoder . getCodecType ( ) == MediaDescriptor . Type . MEDIA_VIDEO ) { 
videoStreamId = i ; 
videoDecoder = decoder ; 
if ( videoStreamId == - 1 ) 
videoDecoder . open ( null , null ) ; 
final MediaPicture picture = MediaPicture . make ( 
videoDecoder . getWidth ( ) , 
videoDecoder . getHeight ( ) , 
videoDecoder . getPixelFormat ( ) ) ; 
final MediaPictureConverter converter = 
MediaPictureConverterFactory . createConverter ( 
MediaPictureConverterFactory . HUMBLE_BGR_24 , 
picture ) ; 
BufferedImage image = null ; 
final ImageFrame window = ImageFrame . make ( ) ; 
if ( window == null ) { 
long systemStartTime = System . nanoTime ( ) ; 
final Rational systemTimeBase = Rational . make ( 1 , 1000000000 ) ; 
final Rational streamTimebase = videoDecoder . getTimeBase ( ) ; 
final MediaPacket packet = MediaPacket . make ( ) ; 
while ( demuxer . read ( packet ) >= 0 ) { 
if ( packet . getStreamIndex ( ) == videoStreamId ) 
bytesRead += videoDecoder . decode ( picture , packet , offset ) ; 
if ( picture . isComplete ( ) ) { 
image = displayVideoAtCorrectTime ( streamStartTime , picture , 
converter , image , window , systemStartTime , systemTimeBase , 
streamTimebase ) ; 
offset += bytesRead ; 
} while ( offset < packet . getSize ( ) ) ; 
videoDecoder . decode ( picture , null , 0 ) ; 
image = displayVideoAtCorrectTime ( streamStartTime , picture , converter , 
image , window , systemStartTime , systemTimeBase , streamTimebase ) ; 
} while ( picture . isComplete ( ) ) ; 
demuxer . close ( ) ; 
window . dispose ( ) ; 
} private static BufferedImage displayVideoAtCorrectTime ( long streamStartTime , 
final MediaPicture picture , final MediaPictureConverter converter , 
BufferedImage image , final ImageFrame window , long systemStartTime , 
final Rational systemTimeBase , final Rational streamTimebase ) 
long streamTimestamp = picture . getTimeStamp ( ) ; 
streamTimestamp = systemTimeBase . rescale ( streamTimestamp - streamStartTime , streamTimebase ) ; 
long systemTimestamp = System . nanoTime ( ) ; 
while ( streamTimestamp > ( systemTimestamp - systemStartTime + 1000000 ) ) { 
Thread . sleep ( 1 ) ; 
systemTimestamp = System . nanoTime ( ) ; 
image = converter . toImage ( image , picture ) ; 
window . setImage ( image ) ; 
return image ; 
} public static java . util . Collection < BitStreamFilterType > 
getInstalledBitStreamFilterTypes ( ) 
java . util . Collection < BitStreamFilterType > retval = new java . util . HashSet < BitStreamFilterType > ( ) ; 
int count = getNumBitStreamFilterTypes ( ) ; 
for ( int i = 0 ; i < count ; i ++ ) 
BitStreamFilterType t = getBitStreamFilterType ( i ) ; 
if ( t != null ) 
retval . add ( t ) ; 
} public static MediaAudioConverter createConverter ( String description , MediaAudio protoAudio ) 
return createConverter ( description , 
protoAudio . getSampleRate ( ) , protoAudio . getChannelLayout ( ) , protoAudio . getFormat ( ) ) ; 
} public static MediaAudioConverter createConverter ( String description , 
int sampleRate , Layout layout , Type format ) { 
if ( description != DEFAULT_JAVA_AUDIO ) 
return new StereoS16AudioConverter ( sampleRate , layout , format ) ; 
} public static Encoder make ( Codec codec ) { 
long cPtr = VideoJNI . Encoder_make__SWIG_0 ( Codec . getCPtr ( codec ) , codec ) ; 
return ( cPtr == 0 ) ? null : new Encoder ( cPtr , false ) ; 
} public static Encoder make ( Coder src ) { 
long cPtr = VideoJNI . Encoder_make__SWIG_1 ( Coder . getCPtr ( src ) , src ) ; 
} public void open ( KeyValueBag inputOptions , KeyValueBag unsetOptions ) { 
VideoJNI . Encoder_open ( swigCPtr , this , KeyValueBag . getCPtr ( inputOptions ) , inputOptions , KeyValueBag . getCPtr ( unsetOptions ) , unsetOptions ) ; 
} public void encodeVideo ( MediaPacket output , MediaPicture picture ) { 
VideoJNI . Encoder_encodeVideo ( swigCPtr , this , MediaPacket . getCPtr ( output ) , output , MediaPicture . getCPtr ( picture ) , picture ) ; 
} public void encodeAudio ( MediaPacket output , MediaAudio samples ) { 
VideoJNI . Encoder_encodeAudio ( swigCPtr , this , MediaPacket . getCPtr ( output ) , output , MediaAudio . getCPtr ( samples ) , samples ) ; 
} public void encode ( MediaPacket output , MediaSampled media ) { 
VideoJNI . Encoder_encode ( swigCPtr , this , MediaPacket . getCPtr ( output ) , output , MediaSampled . getCPtr ( media ) , media ) ; 
public MediaPicture toPicture ( MediaPicture output , 
final BufferedImage input , long timestamp ) { 
validateImage ( input ) ; 
if ( output == null ) { 
output = MediaPicture . make ( mPictureWidth , 
mPictureHeight , getPictureType ( ) ) ; 
DataBuffer imageBuffer = input . getRaster ( ) . getDataBuffer ( ) ; 
byte [ ] imageBytes = null ; 
int [ ] imageInts = null ; 
if ( imageBuffer instanceof DataBufferByte ) { 
imageBytes = ( ( DataBufferByte ) imageBuffer ) . getData ( ) ; 
else if ( imageBuffer instanceof DataBufferInt ) { 
imageInts = ( ( DataBufferInt ) imageBuffer ) . getData ( ) ; 
+ imageBuffer . getDataType ( ) ) ; 
final AtomicReference < JNIReference > ref = new AtomicReference < JNIReference > ( 
null ) ; 
final MediaPicture picture = willResample ( ) ? mResampleMediaPicture : output ; 
Buffer buffer = picture . getData ( 0 ) ; 
int size = picture . getDataPlaneSize ( 0 ) ; 
ByteBuffer pictureByteBuffer = buffer . getByteBuffer ( 0 , 
size , ref ) ; 
buffer . delete ( ) ; 
buffer = null ; 
if ( imageInts != null ) { 
pictureByteBuffer . order ( ByteOrder . BIG_ENDIAN ) ; 
IntBuffer pictureIntBuffer = pictureByteBuffer . asIntBuffer ( ) ; 
pictureIntBuffer . put ( imageInts ) ; 
pictureByteBuffer . put ( imageBytes ) ; 
pictureByteBuffer = null ; 
picture . setTimeStamp ( timestamp ) ; 
picture . setComplete ( true ) ; 
if ( willResample ( ) ) { 
resample ( output , picture , mToPictureResampler ) ; 
if ( ref . get ( ) != null ) 
ref . get ( ) . delete ( ) ; 
public BufferedImage toImage ( BufferedImage output , final MediaPicture input ) { 
validatePicture ( input ) ; 
final byte [ ] bytes = new byte [ willResample ( ) ? mResampleMediaPicture . getDataPlaneSize ( 0 ) : input . getDataPlaneSize ( 0 ) ] ; 
final DataBufferByte db = new DataBufferByte ( bytes , bytes . length ) ; 
int w = mImageWidth ; 
int h = mImageHeight ; 
final SampleModel sm = new PixelInterleavedSampleModel ( 
db . getDataType ( ) , w , h , 3 , 3 * w , mBandOffsets ) ; 
final WritableRaster wr = Raster . createWritableRaster ( sm , db , null ) ; 
final ColorModel colorModel = new ComponentColorModel ( 
mColorSpace , false , false , ColorModel . OPAQUE , db . getDataType ( ) ) ; 
output = new BufferedImage ( colorModel , wr , false , null ) ; 
MediaPicture picture ; 
AtomicReference < JNIReference > ref = new AtomicReference < JNIReference > ( null ) ; 
picture = resample ( mResampleMediaPicture , input , mToImageResampler ) ; 
picture = input ; 
final Buffer buffer = picture . getData ( 0 ) ; 
final int size = picture . getDataPlaneSize ( 0 ) ; 
final ByteBuffer byteBuf = buffer . getByteBuffer ( 0 , 
final DataBufferByte db = ( DataBufferByte ) output . getRaster ( ) 
. getDataBuffer ( ) ; 
final byte [ ] bytes = db . getData ( ) ; 
byteBuf . get ( bytes , 0 , size ) ; 
} public static CodecDescriptor make ( Codec . ID id ) { 
long cPtr = VideoJNI . CodecDescriptor_make ( id . swigValue ( ) ) ; 
return ( cPtr == 0 ) ? null : new CodecDescriptor ( cPtr , false ) ; 
} public static void printConfigurable ( java . io . PrintStream stream , 
Configurable configObj ) 
stream . println ( "=======================================" ) ; 
int numOptions = configObj . getNumProperties ( ) ; 
for ( int i = 0 ; i < numOptions ; i ++ ) 
Property prop = configObj . getPropertyMetaData ( i ) ; 
printOption ( stream , configObj , prop ) ; 
} public static void printOption ( java . io . PrintStream stream , 
Configurable configObj , Property prop ) 
if ( prop . getType ( ) != Property . Type . PROPERTY_FLAGS ) 
prop . getName ( ) , 
configObj . getPropertyAsString ( prop . getName ( ) ) , 
prop . getType ( ) ) ; 
configObj . getPropertyAsLong ( prop . getName ( ) ) ) ; 
int numSettings = prop . getNumFlagSettings ( ) ; 
long value = configObj . getPropertyAsLong ( prop . getName ( ) ) ; 
for ( int i = 0 ; i < numSettings ; i ++ ) 
Property fprop = prop . getFlagConstant ( i ) ; 
long flagMask = fprop . getDefault ( ) ; 
boolean isSet = ( value & flagMask ) > 0 ; 
isSet ? "+" : "-" , 
fprop . getName ( ) ) ; 
public static void configure ( final Properties properties , final Configurable config ) 
for ( 
final Enumeration < String > names = ( Enumeration < String > ) properties . propertyNames ( ) ; 
names . hasMoreElements ( ) ; 
) 
final String name = names . nextElement ( ) ; 
final String value = properties . getProperty ( name ) ; 
config . setProperty ( name , value ) ; 
} catch ( PropertyNotFoundException e ) { 
new Object [ ] { 
config , 
name , 
value 
public static void configure ( final String file , final Configurable config ) throws FileNotFoundException , IOException 
Properties props = new Properties ( ) ; 
props . load ( new FileInputStream ( file ) ) ; 
Configuration . configure ( props , config ) ; 
} public void setTimeBase ( Rational aBase ) { 
VideoJNI . MediaEncoded_setTimeBase ( swigCPtr , this , Rational . getCPtr ( aBase ) , aBase ) ; 
} public static String findDescriptor ( BufferedImage image ) 
for ( Type converterType : getRegisteredConverters ( ) ) 
if ( converterType . getImageType ( ) == image . getType ( ) ) 
return converterType . getDescriptor ( ) ; 
} public static MediaPictureConverter createConverter ( 
String converterDescriptor , 
MediaPicture picture ) 
if ( picture == null ) 
return createConverter ( converterDescriptor , picture . getFormat ( ) , 
picture . getWidth ( ) , picture . getHeight ( ) ) ; 
BufferedImage image , 
if ( image == null ) 
return createConverter ( image , picture . getFormat ( ) ) ; 
PixelFormat . Type pictureType ) 
String converterDescriptor = findDescriptor ( image ) ; 
if ( converterDescriptor == null ) 
throw new UnsupportedOperationException ( 
image . getType ( ) ) ; 
return createConverter ( converterDescriptor , pictureType , 
image . getWidth ( ) , image . getHeight ( ) ) ; 
PixelFormat . Type pictureType , 
int width , int height ) 
width , height , width , height ) ; 
int pictureWidth , int pictureHeight , 
int imageWidth , int imageHeight ) 
MediaPictureConverter converter = null ; 
Type converterType = findRegisteredConverter ( converterDescriptor ) ; 
if ( null == converterType ) 
Constructor < ? extends MediaPictureConverter > converterConstructor = 
converterType . getConverterClass ( ) . getConstructor ( PixelFormat . Type . class , 
int . class , int . class , int . class , int . class ) ; 
converter = converterConstructor . newInstance ( 
pictureType , pictureWidth , pictureHeight , imageWidth , imageHeight ) ; 
catch ( NoSuchMethodException e ) 
catch ( InvocationTargetException e ) 
if ( cause != null && cause instanceof OutOfMemoryError ) 
throw ( OutOfMemoryError ) cause ; 
catch ( IllegalAccessException e ) 
catch ( InstantiationException e ) 
return converter ; 
} public static BufferedImage convertToType ( BufferedImage sourceImage , 
int targetType ) 
BufferedImage image ; 
if ( sourceImage . getType ( ) == targetType ) 
image = sourceImage ; 
image = new BufferedImage ( sourceImage . getWidth ( ) , sourceImage . getHeight ( ) , 
targetType ) ; 
image . getGraphics ( ) . drawImage ( sourceImage , 0 , 0 , null ) ; 
} boolean packChute ( ) throws OutOfMemoryError 
if ( mPayload != null ) 
mPayload = new byte [ PAYLOAD_BYTES ] ; 
mPayload [ 0 ] = 'P' ; 
mPayload [ 1 ] = 'A' ; 
mPayload [ 2 ] = 'R' ; 
mPayload [ 3 ] = 'A' ; 
mPayload [ 4 ] = 'C' ; 
mPayload [ 5 ] = 'H' ; 
mPayload [ 6 ] = 'U' ; 
mPayload [ 7 ] = 'T' ; 
mPayload [ 8 ] = 'E' ; 
mPayload [ 9 ] = '!' ; 
} catch ( OutOfMemoryError e ) { 
} public int close ( ) 
int retval = 0 ; 
if ( mOpenStream != null && mCloseStreamOnClose ) 
mOpenStream . close ( ) ; 
retval = - 1 ; 
mOpenStream = null ; 
mOpenStream = mWriteChannel ; 
mOpenStream = mReadChannel ; 
if ( mOpenStream == null || ! ( mOpenStream instanceof ReadableByteChannel ) ) 
ReadableByteChannel channel = ( ReadableByteChannel ) mOpenStream ; 
ByteBuffer buffer = ByteBuffer . allocate ( size ) ; 
ret = channel . read ( buffer ) ; 
if ( ret > 0 ) { 
buffer . flip ( ) ; 
buffer . get ( buf , 0 , ret ) ; 
! ( mOpenStream instanceof WritableByteChannel ) ) 
WritableByteChannel channel = ( WritableByteChannel ) mOpenStream ; 
buffer . put ( buf , 0 , size ) ; 
return channel . write ( buffer ) ; 
} static HumbleIO registerFactory ( String protocolPrefix ) 
URLProtocolManager manager = URLProtocolManager . getManager ( ) ; 
manager . registerFactory ( protocolPrefix , mFactory ) ; 
return mFactory ; 
} static public String generateUniqueName ( Object src , String extension ) 
StringBuilder builder = new StringBuilder ( ) ; 
builder . append ( UUID . randomUUID ( ) . toString ( ) ) ; 
if ( src != null ) 
builder . append ( "-" ) ; 
builder . append ( src . getClass ( ) . getName ( ) ) ; 
builder . append ( Integer . toHexString ( src . hashCode ( ) ) ) ; 
if ( extension != null ) 
builder . append ( extension ) ; 
} public static String map ( String url , IURLProtocolHandler handler ) 
return map ( url , handler , DEFAULT_UNMAP_URL_ON_OPEN ) ; 
} public static String map ( DataInput input ) 
return map ( generateUniqueName ( input ) , input , null , 
DEFAULT_UNMAP_URL_ON_OPEN , DEFAULT_CLOSE_STREAM_ON_CLOSE ) ; 
} public static String map ( String url , DataInput input ) 
return map ( url , input , null , DEFAULT_UNMAP_URL_ON_OPEN , 
DEFAULT_CLOSE_STREAM_ON_CLOSE ) ; 
} public static String map ( DataOutput output ) 
return map ( generateUniqueName ( output ) , null , output , 
} public static String map ( String url , DataOutput output ) 
return map ( url , null , output , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( RandomAccessFile file ) 
return map ( generateUniqueName ( file ) , file , file , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( String url , RandomAccessFile file ) 
return map ( url , file , file , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( ReadableByteChannel channel ) 
return map ( generateUniqueName ( channel ) , channel , null , 
} public static String map ( String url , ReadableByteChannel channel ) 
return map ( url , channel , null , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( WritableByteChannel channel ) 
return map ( generateUniqueName ( channel ) , null , channel , 
} public static String map ( String url , WritableByteChannel channel ) 
return map ( url , null , channel , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( ByteChannel channel ) 
return map ( generateUniqueName ( channel ) , channel , channel , 
} public static String map ( String url , ByteChannel channel ) 
return map ( url , channel , channel , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( InputStream in ) 
return map ( generateUniqueName ( in ) , in , null , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( String url , InputStream in ) 
return map ( url , in , null , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( OutputStream out ) 
return map ( generateUniqueName ( out ) , null , out , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( String url , OutputStream out ) 
return map ( url , null , out , DEFAULT_UNMAP_URL_ON_OPEN , 
} public static String map ( String url , DataInput in , DataOutput out , 
boolean unmapOnOpen , boolean closeOnClose ) 
return map ( url , new DataInputOutputHandler ( in , out , closeOnClose ) ) ; 
} public static String map ( String url , ReadableByteChannel in , 
WritableByteChannel out , boolean unmapOnOpen , boolean closeOnClose ) 
return map ( url , new ReadableWritableChannelHandler ( in , out , closeOnClose ) ) ; 
} public static String map ( String url , InputStream in , OutputStream out , 
return map ( url , new InputOutputStreamHandler ( in , out , closeOnClose ) ) ; 
} public static String map ( String url , IURLProtocolHandler handler , 
boolean unmapUrlOnOpen ) 
if ( mFactory . mapIO ( url , handler , unmapUrlOnOpen ) != null ) 
return DEFAULT_PROTOCOL + ":" + URLProtocolManager . getResourceFromURL ( url ) ; 
} public IURLProtocolHandler mapIO ( String url , IURLProtocolHandler handler , 
if ( url == null || url . length ( ) <= 0 ) 
if ( handler == null ) 
String streamName = URLProtocolManager . getResourceFromURL ( url ) ; 
RegistrationInformation tuple = new RegistrationInformation ( streamName , 
handler , unmapUrlOnOpen ) ; 
RegistrationInformation oldTuple = mURLs . putIfAbsent ( streamName , tuple ) ; 
return oldTuple == null ? null : oldTuple . getHandler ( ) ; 
} public IURLProtocolHandler unmapIO ( String url ) 
RegistrationInformation oldTuple = mURLs . remove ( streamName ) ; 
} public IURLProtocolHandler getHandler ( String protocol , String url , int flags ) 
RegistrationInformation tuple = mURLs . get ( streamName ) ; 
if ( tuple != null ) 
IURLProtocolHandler handler = tuple . getHandler ( ) ; 
if ( tuple . isUnmappingOnOpen ( ) ) 
IURLProtocolHandler oldHandler = unmapIO ( tuple . getName ( ) ) ; 
if ( handler != null && ! handler . equals ( oldHandler ) ) 
tuple . getName ( ) ) ; 
return handler ; 
} public static Logger getLogger ( String aLoggerName ) { 
long cPtr = FerryJNI . Logger_getLogger ( aLoggerName ) ; 
return ( cPtr == 0 ) ? null : new Logger ( cPtr , false ) ; 
} public static Logger getStaticLogger ( String aLoggerName ) { 
long cPtr = FerryJNI . Logger_getStaticLogger ( aLoggerName ) ; 
} public boolean log ( String filename , int lineNo , Logger . Level level , String format ) { 
return FerryJNI . Logger_log ( swigCPtr , this , filename , lineNo , level . swigValue ( ) , format ) ; 
} public static MediaAudioResampler make ( AudioChannel . Layout outLayout , int outSampleRate , AudioFormat . Type outFormat , AudioChannel . Layout inLayout , int inSampleRate , AudioFormat . Type inFormat ) { 
long cPtr = VideoJNI . MediaAudioResampler_make ( outLayout . swigValue ( ) , outSampleRate , outFormat . swigValue ( ) , inLayout . swigValue ( ) , inSampleRate , inFormat . swigValue ( ) ) ; 
return ( cPtr == 0 ) ? null : new MediaAudioResampler ( cPtr , false ) ; 
} public int resample ( MediaSampled out , MediaSampled in ) { 
return VideoJNI . MediaAudioResampler_resample ( swigCPtr , this , MediaSampled . getCPtr ( out ) , out , MediaSampled . getCPtr ( in ) , in ) ; 
} public Rational getTimeBase ( ) { 
long cPtr = VideoJNI . MediaAudioResampler_getTimeBase ( swigCPtr , this ) ; 
} public void setTimeBase ( Rational rational ) { 
VideoJNI . MediaAudioResampler_setTimeBase ( swigCPtr , this , Rational . getCPtr ( rational ) , rational ) ; 
} public java . util . List < IndexEntry > getIndexEntries ( ) 
final int numEntries = getNumIndexEntries ( ) ; 
java . util . List < IndexEntry > retval = new java . util . ArrayList < IndexEntry > ( Math . max ( numEntries , 10 ) ) ; 
for ( int i = 0 ; i < numEntries ; i ++ ) { 
final IndexEntry entry = getIndexEntry ( i ) ; 
if ( entry != null ) { 
retval . add ( entry ) ; 
} public Rational getFrameRate ( ) { 
long cPtr = VideoJNI . ContainerStream_getFrameRate ( swigCPtr , this ) ; 
long cPtr = VideoJNI . ContainerStream_getTimeBase ( swigCPtr , this ) ; 
} public Rational getSampleAspectRatio ( ) { 
long cPtr = VideoJNI . ContainerStream_getSampleAspectRatio ( swigCPtr , this ) ; 
} public Container getContainer ( ) { 
long cPtr = VideoJNI . ContainerStream_getContainer ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new Container ( cPtr , false ) ; 
long cPtr = VideoJNI . ContainerStream_getMetaData ( swigCPtr , this ) ; 
} public IndexEntry findTimeStampEntryInIndex ( long wantedTimeStamp , int flags ) { 
long cPtr = VideoJNI . ContainerStream_findTimeStampEntryInIndex ( swigCPtr , this , wantedTimeStamp , flags ) ; 
return ( cPtr == 0 ) ? null : new IndexEntry ( cPtr , false ) ; 
} public IndexEntry getIndexEntry ( int position ) { 
long cPtr = VideoJNI . ContainerStream_getIndexEntry ( swigCPtr , this , position ) ; 
} public MediaPacket getAttachedPic ( ) { 
long cPtr = VideoJNI . ContainerStream_getAttachedPic ( swigCPtr , this ) ; 
} public static java . util . Collection < Codec > 
getInstalledCodecs ( ) 
java . util . Collection < Codec > retval = new java . util . HashSet < Codec > ( ) ; 
int count = getNumInstalledCodecs ( ) ; 
Codec codec = getInstalledCodec ( i ) ; 
if ( codec != null ) 
retval . add ( codec ) ; 
} public java . util . Collection < Rational > 
getSupportedVideoFrameRates ( ) 
java . util . List < Rational > retval = 
new java . util . LinkedList < Rational > ( ) ; 
int count = getNumSupportedVideoFrameRates ( ) ; 
Rational rate = getSupportedVideoFrameRate ( i ) ; 
if ( rate != null ) 
retval . add ( rate ) ; 
} public java . util . Collection < PixelFormat . Type > 
getSupportedVideoPixelFormats ( ) 
java . util . List < PixelFormat . Type > retval = 
new java . util . LinkedList < PixelFormat . Type > ( ) ; 
int count = getNumSupportedVideoPixelFormats ( ) ; 
PixelFormat . Type type = getSupportedVideoPixelFormat ( i ) ; 
if ( type != null && type != PixelFormat . Type . PIX_FMT_NONE ) 
retval . add ( type ) ; 
} public java . util . Collection < Integer > 
getSupportedAudioSampleRates ( ) 
java . util . List < Integer > retval = 
new java . util . LinkedList < Integer > ( ) ; 
int count = getNumSupportedAudioSampleRates ( ) ; 
int rate = getSupportedAudioSampleRate ( i ) ; 
if ( rate != 0 ) 
} public java . util . Collection < AudioFormat . Type > 
getSupportedAudioFormats ( ) 
java . util . List < AudioFormat . Type > retval = 
new java . util . LinkedList < AudioFormat . Type > ( ) ; 
int count = getNumSupportedAudioFormats ( ) ; 
AudioFormat . Type fmt = getSupportedAudioFormat ( i ) ; 
if ( fmt != null && fmt != AudioFormat . Type . SAMPLE_FMT_NONE ) 
retval . add ( fmt ) ; 
} public java . util . Collection < AudioChannel . Layout > 
getSupportedAudioChannelLayouts ( ) 
java . util . List < AudioChannel . Layout > retval = 
new java . util . LinkedList < AudioChannel . Layout > ( ) ; 
int count = getNumSupportedAudioChannelLayouts ( ) ; 
AudioChannel . Layout layout = getSupportedAudioChannelLayout ( i ) ; 
if ( layout != AudioChannel . Layout . CH_LAYOUT_UNKNOWN ) 
retval . add ( layout ) ; 
} public static Codec findEncodingCodec ( Codec . ID id ) { 
long cPtr = VideoJNI . Codec_findEncodingCodec ( id . swigValue ( ) ) ; 
return ( cPtr == 0 ) ? null : new Codec ( cPtr , false ) ; 
} public static Codec findEncodingCodecByIntID ( int id ) { 
long cPtr = VideoJNI . Codec_findEncodingCodecByIntID ( id ) ; 
} public static Codec findEncodingCodecByName ( String id ) { 
long cPtr = VideoJNI . Codec_findEncodingCodecByName ( id ) ; 
} public static Codec findDecodingCodec ( Codec . ID id ) { 
long cPtr = VideoJNI . Codec_findDecodingCodec ( id . swigValue ( ) ) ; 
} public static Codec findDecodingCodecByIntID ( int id ) { 
long cPtr = VideoJNI . Codec_findDecodingCodecByIntID ( id ) ; 
} public static Codec findDecodingCodecByName ( String id ) { 
long cPtr = VideoJNI . Codec_findDecodingCodecByName ( id ) ; 
} public static Codec guessEncodingCodec ( MuxerFormat fmt , String shortName , String url , String mimeType , MediaDescriptor . Type type ) { 
long cPtr = VideoJNI . Codec_guessEncodingCodec ( MuxerFormat . getCPtr ( fmt ) , fmt , shortName , url , mimeType , type . swigValue ( ) ) ; 
} public static Codec getInstalledCodec ( int index ) { 
long cPtr = VideoJNI . Codec_getInstalledCodec ( index ) ; 
} public Rational getSupportedVideoFrameRate ( int index ) { 
long cPtr = VideoJNI . Codec_getSupportedVideoFrameRate ( swigCPtr , this , index ) ; 
} public PixelFormat . Type getSupportedVideoPixelFormat ( int index ) { 
return PixelFormat . Type . swigToEnum ( VideoJNI . Codec_getSupportedVideoPixelFormat ( swigCPtr , this , index ) ) ; 
} public AudioFormat . Type getSupportedAudioFormat ( int index ) { 
return AudioFormat . Type . swigToEnum ( VideoJNI . Codec_getSupportedAudioFormat ( swigCPtr , this , index ) ) ; 
} public AudioChannel . Layout getSupportedAudioChannelLayout ( int index ) { 
return AudioChannel . Layout . swigToEnum ( VideoJNI . Codec_getSupportedAudioChannelLayout ( swigCPtr , this , index ) ) ; 
} public CodecProfile getSupportedProfile ( int index ) { 
long cPtr = VideoJNI . Codec_getSupportedProfile ( swigCPtr , this , index ) ; 
return ( cPtr == 0 ) ? null : new CodecProfile ( cPtr , false ) ; 
return VideoJNI . MediaPictureResampler_resample ( swigCPtr , this , MediaSampled . getCPtr ( out ) , out , MediaSampled . getCPtr ( in ) , in ) ; 
} public int resamplePicture ( MediaPicture out , MediaPicture in ) { 
return VideoJNI . MediaPictureResampler_resamplePicture ( swigCPtr , this , MediaPicture . getCPtr ( out ) , out , MediaPicture . getCPtr ( in ) , in ) ; 
} public static MediaPictureResampler make ( int outputWidth , int outputHeight , PixelFormat . Type outputFmt , int inputWidth , int inputHeight , PixelFormat . Type inputFmt , int flags ) { 
long cPtr = VideoJNI . MediaPictureResampler_make ( outputWidth , outputHeight , outputFmt . swigValue ( ) , inputWidth , inputHeight , inputFmt . swigValue ( ) , flags ) ; 
return ( cPtr == 0 ) ? null : new MediaPictureResampler ( cPtr , false ) ; 
mOpenStream = mOutputStream ; 
mOpenStream = mInputStream ; 
if ( mOpenStream == null || ! ( mOpenStream instanceof InputStream ) ) 
InputStream stream = ( InputStream ) mOpenStream ; 
ret = stream . read ( buf , 0 , size ) ; 
! ( mOpenStream instanceof OutputStream ) ) 
OutputStream stream = ( OutputStream ) mOpenStream ; 
stream . write ( buf , 0 , size ) ; 
} public java . util . Collection < String > getKeys ( ) 
int numKeys = getNumKeys ( ) ; 
java . util . List < String > retval = new java . util . ArrayList < String > ( numKeys ) ; 
for ( int i = 0 ; i < getNumKeys ( ) ; i ++ ) 
String key = getKey ( i ) ; 
if ( key != null && key . length ( ) > 0 ) 
retval . add ( key ) ; 
} public String getValue ( String key , KeyValueBag . Flags flag ) { 
return VideoJNI . KeyValueBag_getValue ( swigCPtr , this , key , flag . swigValue ( ) ) ; 
} public int setValue ( String key , String value ) { 
return VideoJNI . KeyValueBag_setValue__SWIG_0 ( swigCPtr , this , key , value ) ; 
} public static KeyValueBag make ( ) { 
long cPtr = VideoJNI . KeyValueBag_make ( ) ; 
} public int setValue ( String key , String value , KeyValueBag . Flags flag ) { 
return VideoJNI . KeyValueBag_setValue__SWIG_1 ( swigCPtr , this , key , value , flag . swigValue ( ) ) ; 
VideoJNI . Coder_open ( swigCPtr , this , KeyValueBag . getCPtr ( inputOptions ) , inputOptions , KeyValueBag . getCPtr ( unsetOptions ) , unsetOptions ) ; 
} public Codec getCodec ( ) { 
long cPtr = VideoJNI . Coder_getCodec ( swigCPtr , this ) ; 
long cPtr = VideoJNI . Coder_getTimeBase ( swigCPtr , this ) ; 
} public void setTimeBase ( Rational newTimeBase ) { 
VideoJNI . Coder_setTimeBase ( swigCPtr , this , Rational . getCPtr ( newTimeBase ) , newTimeBase ) ; 
} public void setFlag ( Coder . Flag flag , boolean value ) { 
VideoJNI . Coder_setFlag ( swigCPtr , this , flag . swigValue ( ) , value ) ; 
} public void setFlag2 ( Coder . Flag2 flag , boolean value ) { 
VideoJNI . Coder_setFlag2 ( swigCPtr , this , flag . swigValue ( ) , value ) ; 
} public Decoder getDecoder ( ) { 
long cPtr = VideoJNI . DemuxerStream_getDecoder ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new Decoder ( cPtr , false ) ; 
} public Demuxer getDemuxer ( ) { 
long cPtr = VideoJNI . DemuxerStream_getDemuxer ( swigCPtr , this ) ; 
} public static java . util . Collection < MuxerFormat > 
getFormats ( ) 
java . util . Collection < MuxerFormat > retval = 
new java . util . HashSet < MuxerFormat > ( ) ; 
int count = getNumFormats ( ) ; 
for ( int i = 0 ; i < count ; ++ i ) 
MuxerFormat fmt = getFormat ( i ) ; 
if ( fmt != null ) 
} public static MuxerFormat guessFormat ( String shortName , String filename , String mimeType ) { 
long cPtr = VideoJNI . MuxerFormat_guessFormat ( shortName , filename , mimeType ) ; 
return ( cPtr == 0 ) ? null : new MuxerFormat ( cPtr , false ) ; 
return Codec . ID . swigToEnum ( VideoJNI . MuxerFormat_getSupportedCodecId ( swigCPtr , this , n ) ) ; 
} public static MuxerFormat getFormat ( int index ) { 
long cPtr = VideoJNI . MuxerFormat_getFormat ( index ) ; 
} public static FilterGraph make ( ) { 
long cPtr = VideoJNI . FilterGraph_make ( ) ; 
return ( cPtr == 0 ) ? null : new FilterGraph ( cPtr , false ) ; 
} public Filter addFilter ( FilterType type , String name ) { 
long cPtr = VideoJNI . FilterGraph_addFilter ( swigCPtr , this , FilterType . getCPtr ( type ) , type , name ) ; 
return ( cPtr == 0 ) ? null : new Filter ( cPtr , false ) ; 
} public FilterAudioSource addAudioSource ( String name , int sampleRate , AudioChannel . Layout channelLayout , AudioFormat . Type format , Rational timeBase ) { 
long cPtr = VideoJNI . FilterGraph_addAudioSource ( swigCPtr , this , name , sampleRate , channelLayout . swigValue ( ) , format . swigValue ( ) , Rational . getCPtr ( timeBase ) , timeBase ) ; 
return ( cPtr == 0 ) ? null : new FilterAudioSource ( cPtr , false ) ; 
} public FilterPictureSource addPictureSource ( String name , int width , int height , PixelFormat . Type format , Rational timeBase , Rational pixelAspectRatio ) { 
long cPtr = VideoJNI . FilterGraph_addPictureSource ( swigCPtr , this , name , width , height , format . swigValue ( ) , Rational . getCPtr ( timeBase ) , timeBase , Rational . getCPtr ( pixelAspectRatio ) , pixelAspectRatio ) ; 
return ( cPtr == 0 ) ? null : new FilterPictureSource ( cPtr , false ) ; 
} public FilterAudioSink addAudioSink ( String name , int sampleRate , AudioChannel . Layout channelLayout , AudioFormat . Type format ) { 
long cPtr = VideoJNI . FilterGraph_addAudioSink ( swigCPtr , this , name , sampleRate , channelLayout . swigValue ( ) , format . swigValue ( ) ) ; 
return ( cPtr == 0 ) ? null : new FilterAudioSink ( cPtr , false ) ; 
} public FilterPictureSink addPictureSink ( String name , PixelFormat . Type format ) { 
long cPtr = VideoJNI . FilterGraph_addPictureSink ( swigCPtr , this , name , format . swigValue ( ) ) ; 
return ( cPtr == 0 ) ? null : new FilterPictureSink ( cPtr , false ) ; 
} public void queueCommand ( String target , String command , String arguments , int flags , double ts ) { 
VideoJNI . FilterGraph_queueCommand ( swigCPtr , this , target , command , arguments , flags , ts ) ; 
} public static IndexEntry make ( long position , long timeStamp , int flags , int size , int minDistance ) { 
long cPtr = VideoJNI . IndexEntry_make ( position , timeStamp , flags , size , minDistance ) ; 
} public static BitStreamFilter make ( String filtername ) { 
long cPtr = VideoJNI . BitStreamFilter_make__SWIG_0 ( filtername ) ; 
return ( cPtr == 0 ) ? null : new BitStreamFilter ( cPtr , false ) ; 
} public static BitStreamFilter make ( BitStreamFilterType type ) { 
long cPtr = VideoJNI . BitStreamFilter_make__SWIG_1 ( BitStreamFilterType . getCPtr ( type ) , type ) ; 
} public BitStreamFilterType getType ( ) { 
long cPtr = VideoJNI . BitStreamFilter_getType ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new BitStreamFilterType ( cPtr , false ) ; 
} public int filter ( Buffer output , int outputOffset , Buffer input , int inputOffset , int inputSize , Coder coder , String args , boolean isKey ) { 
return VideoJNI . BitStreamFilter_filter__SWIG_0 ( swigCPtr , this , Buffer . getCPtr ( output ) , output , outputOffset , Buffer . getCPtr ( input ) , input , inputOffset , inputSize , Coder . getCPtr ( coder ) , coder , args , isKey ) ; 
} public void filter ( MediaPacket packet , String args ) { 
VideoJNI . BitStreamFilter_filter__SWIG_1 ( swigCPtr , this , MediaPacket . getCPtr ( packet ) , packet , args ) ; 
} public void put ( byte [ ] src , int srcPos , int destPos , int length ) 
java . util . concurrent . atomic . AtomicReference < JNIReference > ref = 
new java . util . concurrent . atomic . AtomicReference < JNIReference > ( ) ; 
java . nio . ByteBuffer buffer = this . getByteBuffer ( 0 , this . getBufferSize ( ) , 
ref ) ; 
if ( buffer == null ) 
validateArgs ( src , src . length , srcPos , buffer . limit ( ) , destPos , length ) ; 
buffer . position ( destPos ) ; 
buffer . put ( src , srcPos , length ) ; 
} public java . nio . ByteBuffer getByteBuffer ( int offset , int length ) 
return getByteBuffer ( offset , length , null ) ; 
} public java . nio . ByteBuffer getByteBuffer ( int offset , int length , 
java . util . concurrent . atomic . AtomicReference < JNIReference > referenceReturn ) 
java . nio . ByteBuffer retval = this . java_getByteBuffer ( offset , length ) ; 
if ( retval != null ) 
java . util . concurrent . atomic . AtomicLong refCount = 
this . getJavaRefCount ( ) ; 
refCount . incrementAndGet ( ) ; 
JNIReference ref = JNIReference . createNonFerryReference ( 
retval , swigCPtr , refCount ) ; 
if ( referenceReturn != null ) 
referenceReturn . set ( ref ) ; 
retval . order ( java . nio . ByteOrder . nativeOrder ( ) ) ; 
retval . position ( 0 ) ; 
retval . mark ( ) ; 
retval . limit ( this . getBufferSize ( ) ) ; 
} public static Buffer make ( RefCounted requestor , int bufferSize ) { 
long cPtr = FerryJNI . Buffer_make__SWIG_0 ( RefCounted . getCPtr ( requestor ) , requestor , bufferSize ) ; 
} public static Buffer make ( RefCounted requestor , Buffer . Type type , int numElements , boolean zero ) { 
long cPtr = FerryJNI . Buffer_make__SWIG_1 ( RefCounted . getCPtr ( requestor ) , requestor , type . swigValue ( ) , numElements , zero ) ; 
} public static Buffer make ( RefCounted requestor , byte [ ] buffer , int offset , int length ) { 
long cPtr = FerryJNI . Buffer_make__SWIG_2 ( RefCounted . getCPtr ( requestor ) , requestor , buffer , offset , length ) ; 
} public static Buffer make ( RefCounted requestor , java . nio . ByteBuffer directByteBuffer , int offset , int length ) { 
long cPtr = FerryJNI . Buffer_make__SWIG_3 ( RefCounted . getCPtr ( requestor ) , requestor , directByteBuffer , offset , length ) ; 
} public static AudioFrame make ( final AudioFormat audioFormat ) { 
return new AudioFrame ( audioFormat ) ; 
} catch ( LineUnavailableException e ) { 
} public void play ( ByteBuffer rawAudio ) 
byte [ ] data = rawAudio . array ( ) ; 
mLine . write ( data , rawAudio . position ( ) , rawAudio . limit ( ) ) ; 
} protected static MediaPicture resample ( MediaPicture input , 
MediaPictureResampler resampler ) 
MediaPicture output = MediaPicture . make ( 
resampler . getOutputWidth ( ) , 
resampler . getOutputHeight ( ) , 
resampler . getOutputFormat ( ) ) ; 
return resample ( output , input , resampler ) ; 
} protected void validateImage ( BufferedImage image ) 
if ( image . getType ( ) != getImageType ( ) ) 
getImageType ( ) + "." ) ; 
} protected void validatePicture ( MediaPicture picture ) 
if ( ! picture . isComplete ( ) ) 
PixelFormat . Type type = picture . getFormat ( ) ; 
if ( ( type != getPictureType ( ) ) && ( willResample ( ) && 
type != mToImageResampler . getOutputFormat ( ) ) ) 
getPictureType ( ) + ( willResample ( ) 
: "" ) + 
"." ) ; 
public boolean isInterrupted ( ) 
final Thread thread = mThreads . get ( ) . mThread ; 
final Interruptable handler = getGlobalInterruptHandler ( ) ; 
retval = handler . preInterruptCheck ( ) ; 
if ( ! retval ) 
retval = thread . isInterrupted ( ) ; 
retval = handler . postInterruptCheck ( retval ) ; 
public void interrupt ( ) 
thread . interrupt ( ) ; 
} public FilterGraph getFilterGraph ( ) { 
long cPtr = VideoJNI . FilterLink_getFilterGraph ( swigCPtr , this ) ; 
long cPtr = VideoJNI . FilterLink_getTimeBase ( swigCPtr , this ) ; 
} public void insertFilter ( Filter filter , int srcPadIndex , int dstPadIndex ) { 
VideoJNI . FilterLink_insertFilter ( swigCPtr , this , Filter . getCPtr ( filter ) , filter , srcPadIndex , dstPadIndex ) ; 
long cPtr = VideoJNI . MediaRaw_getTimeBase ( swigCPtr , this ) ; 
long cPtr = VideoJNI . MediaRaw_getMetaData ( swigCPtr , this ) ; 
} public void setTimeBase ( Rational timeBase ) { 
VideoJNI . MediaRaw_setTimeBase ( swigCPtr , this , Rational . getCPtr ( timeBase ) , timeBase ) ; 
} public IURLProtocolHandlerFactory registerFactory ( String protocol , 
IURLProtocolHandlerFactory factory ) 
if ( protocol == null ) 
IURLProtocolHandlerFactory oldFactory ; 
if ( factory == null ) 
oldFactory = mProtocols . remove ( protocol ) ; 
oldFactory = mProtocols . put ( protocol , factory ) ; 
if ( oldFactory == null ) 
protocol ) ; 
FfmpegIO . registerProtocolHandler ( protocol , this ) ; 
return oldFactory ; 
} public IURLProtocolHandler getHandler ( String url , int flags ) 
IURLProtocolHandler result = null ; 
if ( url == null || url . length ( ) == 0 ) 
int colonIndex = url . indexOf ( ":" ) ; 
String protocol = null ; 
if ( colonIndex > 0 ) 
protocol = url . substring ( 0 , colonIndex ) ; 
protocol = DEFAULT_PROTOCOL ; 
IURLProtocolHandlerFactory factory = mProtocols . get ( protocol ) ; 
if ( factory != null ) 
result = factory . getHandler ( protocol , url , flags ) ; 
} public static String getResourceFromURL ( String url ) 
String retval = url ; 
if ( url != null && url . length ( ) > 0 ) 
int colonIndex ; 
colonIndex = url . indexOf ( "://" ) ; 
retval = url . substring ( colonIndex + 3 ) ; 
colonIndex = url . indexOf ( ":" ) ; 
if ( colonIndex > 1 ) 
retval = url . substring ( colonIndex + 1 ) ; 
} public static String getProtocolFromURL ( String url ) 
String retval = null ; 
retval = url . substring ( 0 , colonIndex ) ; 
} public static CPUArch getCPUArch ( String javaCPU ) 
final CPUArch javaArch ; 
final String javaCPUArch = javaCPU != null ? javaCPU . toLowerCase ( ) : "" ; 
if ( javaCPUArch . startsWith ( "x86_64" ) || 
javaCPUArch . startsWith ( "amd64" ) || 
javaCPUArch . startsWith ( "ia64" ) ) { 
javaArch = CPUArch . X86_64 ; 
} else if ( 
javaCPUArch . startsWith ( "ppc64" ) || 
javaCPUArch . startsWith ( "powerpc64" ) 
javaArch = CPUArch . PPC64 ; 
javaCPUArch . startsWith ( "ppc" ) || 
javaCPUArch . startsWith ( "powerpc" ) 
javaArch = CPUArch . PPC ; 
javaCPUArch . contains ( "86" ) 
javaArch = CPUArch . X86 ; 
javaArch = CPUArch . UNKNOWN ; 
return javaArch ; 
} public static CPUArch getCPUArchFromGNUString ( String gnuString ) 
final String nativeCpu = gnuString . toLowerCase ( ) ; 
final CPUArch nativeArch ; 
if ( nativeCpu . startsWith ( "x86_64" ) || 
nativeCpu . startsWith ( "amd64" ) || 
nativeCpu . startsWith ( "ia64" ) ) 
nativeArch = CPUArch . X86_64 ; 
else if ( 
nativeCpu . startsWith ( "ppc64" ) || 
nativeCpu . startsWith ( "powerpc64" ) 
nativeArch = CPUArch . PPC64 ; 
nativeCpu . startsWith ( "ppc" ) || 
nativeCpu . startsWith ( "powerpc" ) 
nativeArch = CPUArch . PPC ; 
nativeCpu . contains ( "86" ) 
nativeArch = CPUArch . X86 ; 
nativeArch = CPUArch . UNKNOWN ; 
return nativeArch ; 
} public static OSFamily getOSFamily ( String osName ) 
final OSFamily retval ; 
if ( osName != null && osName . length ( ) > 0 ) 
if ( osName . startsWith ( "Windows" ) ) 
retval = OSFamily . WINDOWS ; 
else if ( osName . startsWith ( "Mac" ) ) 
retval = OSFamily . MAC ; 
else if ( osName . startsWith ( "Linux" ) ) 
retval = OSFamily . LINUX ; 
retval = OSFamily . UNKNOWN ; 
} public static OSFamily getOSFamilyFromGNUString ( String gnuString ) 
final String nativeOs = ( gnuString != null ? gnuString . toLowerCase ( ) : "" ) ; 
if ( nativeOs . startsWith ( "mingw" ) || nativeOs . startsWith ( "cygwin" ) ) 
else if ( nativeOs . startsWith ( "darwin" ) ) 
else if ( nativeOs . startsWith ( "linux" ) ) 
} public String getFormattedTimeStamp ( String format ) 
java . util . Formatter formatter = new java . util . Formatter ( ) ; 
Rational timeBase = getTimeBase ( ) ; 
if ( timeBase == null ) 
timeBase = Rational . make ( 1 , ( int ) Global . DEFAULT_PTS_PER_SECOND ) ; 
retval = formatter . format ( format , 
( long ) ( getTimeStamp ( ) * timeBase . getDouble ( ) * 1000 ) + 
TIME_OFFSET ) . toString ( ) ; 
timeBase . delete ( ) ; 
formatter . close ( ) ; 
long cPtr = VideoJNI . Media_getTimeBase ( swigCPtr , this ) ; 
} private static void playSound ( String filename ) throws InterruptedException , IOException , LineUnavailableException { 
int audioStreamId = - 1 ; 
Decoder audioDecoder = null ; 
if ( decoder != null && decoder . getCodecType ( ) == MediaDescriptor . Type . MEDIA_AUDIO ) { 
audioStreamId = i ; 
audioDecoder = decoder ; 
if ( audioStreamId == - 1 ) 
audioDecoder . open ( null , null ) ; 
final MediaAudio samples = MediaAudio . make ( 
audioDecoder . getFrameSize ( ) , 
audioDecoder . getSampleRate ( ) , 
audioDecoder . getChannels ( ) , 
audioDecoder . getChannelLayout ( ) , 
audioDecoder . getSampleFormat ( ) ) ; 
final MediaAudioConverter converter = 
MediaAudioConverterFactory . createConverter ( 
MediaAudioConverterFactory . DEFAULT_JAVA_AUDIO , 
samples ) ; 
final AudioFrame audioFrame = AudioFrame . make ( converter . getJavaFormat ( ) ) ; 
if ( audioFrame == null ) 
throw new LineUnavailableException ( ) ; 
ByteBuffer rawAudio = null ; 
if ( packet . getStreamIndex ( ) == audioStreamId ) 
bytesRead += audioDecoder . decode ( samples , packet , offset ) ; 
if ( samples . isComplete ( ) ) { 
rawAudio = converter . toJavaAudio ( rawAudio , samples ) ; 
audioFrame . play ( rawAudio ) ; 
audioDecoder . decode ( samples , null , 0 ) ; 
} while ( samples . isComplete ( ) ) ; 
audioFrame . dispose ( ) ; 
} public static void main ( String [ ] args ) throws InterruptedException , IOException , LineUnavailableException 
final Options options = new Options ( ) ; 
final CommandLineParser parser = new org . apache . commons . cli . BasicParser ( ) ; 
final CommandLine cmd = parser . parse ( options , args ) ; 
if ( cmd . hasOption ( "version" ) ) { 
final String version = io . humble . video_native . Version . getVersionInfo ( ) ; 
} else if ( cmd . hasOption ( "help" ) || args . length == 0 ) { 
final HelpFormatter formatter = new HelpFormatter ( ) ; 
final String [ ] parsedArgs = cmd . getArgs ( ) ; 
for ( String arg : parsedArgs ) 
playSound ( arg ) ; 
} public void delete ( ) 
if ( swigCPtr != 0 ) { 
Object object = this ; 
if ( object instanceof RefCounted && mRefCounter != null ) { 
mRefCounter . delete ( ) ; 
} else if ( swigCMemOwn ) { 
swigCMemOwn = false ; 
mJavaRefCount = null ; 
mRefCounter = null ; 
mObjectToForceFinalize = null ; 
mLifecycleReference = null ; 
swigCPtr = 0 ; 
public static void loadLibrary ( String aLibraryName , Long aMajorVersion ) 
getInstance ( ) . loadLibrary0 ( aLibraryName , aMajorVersion ) ; 
} synchronized void loadLibrary0 ( String aLibraryName , Long aMajorVersion ) 
if ( alreadyLoadedLibrary ( aLibraryName , aMajorVersion ) ) 
List < String > libCandidates = getLibraryCandidates ( aLibraryName , 
aMajorVersion ) ; 
if ( libCandidates != null && libCandidates . size ( ) > 0 
&& ! loadCandidateLibrary ( aLibraryName , aMajorVersion , libCandidates ) ) 
System . loadLibrary ( aLibraryName ) ; 
catch ( UnsatisfiedLinkError e ) 
log 
aLibraryName , aMajorVersion == null ? "" : aMajorVersion ) ; 
setLoadedLibrary ( aLibraryName , aMajorVersion ) ; 
} void setLoadedLibrary ( String aLibraryName , Long aMajorVersion ) 
Set < Long > foundVersions = mLoadedLibraries . get ( aLibraryName ) ; 
if ( foundVersions == null ) 
foundVersions = new HashSet < Long > ( ) ; 
mLoadedLibraries . put ( aLibraryName , foundVersions ) ; 
foundVersions . add ( aMajorVersion ) ; 
} boolean loadCandidateLibrary ( String aLibraryName , Long aMajorVersion , 
List < String > aLibCandidates ) 
for ( String candidate : aLibCandidates ) 
. trace ( 
new Object [ ] 
aLibraryName , 
aMajorVersion == null ? "<unspecified>" : aMajorVersion 
. longValue ( ) , candidate 
File candidateFile = new File ( candidate ) ; 
if ( candidateFile . exists ( ) ) 
String absPath = candidateFile . getAbsolutePath ( ) ; 
. longValue ( ) , absPath 
System . load ( absPath ) ; 
. longValue ( ) , absPath , e 
catch ( SecurityException e ) 
} List < String > getLibraryCandidates ( String aLibraryName , Long aMajorVersion ) 
final List < String > retval = new LinkedList < String > ( ) ; 
final String [ ] prefixes ; 
final String [ ] suffixes ; 
final String [ ] preSuffixVersions ; 
final String [ ] postSuffixVersions ; 
switch ( getOS ( ) ) 
case Unknown : 
case Linux : 
prefixes = new String [ ] 
"lib" , "" 
suffixes = new String [ ] 
".so" 
preSuffixVersions = new String [ ] 
"" 
postSuffixVersions = ( aMajorVersion == null ? new String [ ] 
} : new String [ ] 
"." + aMajorVersion . longValue ( ) 
case Windows : 
"lib" , "" , "cyg" 
".dll" 
preSuffixVersions = ( aMajorVersion == null ? new String [ ] 
"-" + aMajorVersion . longValue ( ) 
postSuffixVersions = new String [ ] 
case MacOSX : 
".dylib" 
prefixes = null ; 
suffixes = null ; 
preSuffixVersions = null ; 
postSuffixVersions = null ; 
initializeSearchPaths ( ) ; 
if ( aMajorVersion != null ) 
for ( String directory : mJavaPropPaths ) 
generateFileNames ( retval , directory , aLibraryName , prefixes , suffixes , 
preSuffixVersions , postSuffixVersions , true ) ; 
for ( String directory : mJavaEnvPaths ) 
preSuffixVersions , postSuffixVersions , false ) ; 
} private void initializeSearchPaths ( ) 
String pathVar = null ; 
if ( mJavaPropPaths == null ) 
pathVar = System . getProperty ( "java.library.path" , "" ) ; 
mJavaPropPaths = getEntitiesFromPath ( pathVar ) ; 
if ( mJavaEnvPaths == null ) 
String envVar = getSystemRuntimeLibraryPathVar ( ) ; 
pathVar = System . getenv ( envVar ) ; 
pathVar ) ; 
mJavaEnvPaths = getEntitiesFromPath ( pathVar ) ; 
} boolean alreadyLoadedLibrary ( String aLibraryName , Long aMajorVersion ) 
if ( foundVersions != null ) 
if ( aMajorVersion == null || foundVersions . contains ( aMajorVersion ) ) 
aLibraryName , aMajorVersion , foundVersions . toArray ( ) 
} public static Decoder make ( Codec codec ) { 
long cPtr = VideoJNI . Decoder_make__SWIG_0 ( Codec . getCPtr ( codec ) , codec ) ; 
} public static Decoder make ( Coder src ) { 
long cPtr = VideoJNI . Decoder_make__SWIG_1 ( Coder . getCPtr ( src ) , src ) ; 
} public int decodeAudio ( MediaAudio output , MediaPacket packet , int byteOffset ) { 
return VideoJNI . Decoder_decodeAudio ( swigCPtr , this , MediaAudio . getCPtr ( output ) , output , MediaPacket . getCPtr ( packet ) , packet , byteOffset ) ; 
} public int decodeVideo ( MediaPicture output , MediaPacket packet , int byteOffset ) { 
return VideoJNI . Decoder_decodeVideo ( swigCPtr , this , MediaPicture . getCPtr ( output ) , output , MediaPacket . getCPtr ( packet ) , packet , byteOffset ) ; 
} public int decode ( MediaSampled output , MediaPacket packet , int byteOffset ) { 
return VideoJNI . Decoder_decode ( swigCPtr , this , MediaSampled . getCPtr ( output ) , output , MediaPacket . getCPtr ( packet ) , packet , byteOffset ) ; 
} private static void recordScreen ( String filename , String formatname , 
String codecname , int duration , int snapsPerSecond ) throws AWTException , InterruptedException , IOException { 
final Robot robot = new Robot ( ) ; 
final Toolkit toolkit = Toolkit . getDefaultToolkit ( ) ; 
final Rectangle screenbounds = new Rectangle ( toolkit . getScreenSize ( ) ) ; 
final Rational framerate = Rational . make ( 1 , snapsPerSecond ) ; 
final Muxer muxer = Muxer . make ( filename , null , formatname ) ; 
final MuxerFormat format = muxer . getFormat ( ) ; 
final Codec codec ; 
if ( codecname != null ) { 
codec = Codec . findEncodingCodecByName ( codecname ) ; 
codec = Codec . findEncodingCodec ( format . getDefaultVideoCodecId ( ) ) ; 
Encoder encoder = Encoder . make ( codec ) ; 
encoder . setWidth ( screenbounds . width ) ; 
encoder . setHeight ( screenbounds . height ) ; 
final PixelFormat . Type pixelformat = PixelFormat . Type . PIX_FMT_YUV420P ; 
encoder . setPixelFormat ( pixelformat ) ; 
encoder . setTimeBase ( framerate ) ; 
if ( format . getFlag ( MuxerFormat . Flag . GLOBAL_HEADER ) ) 
encoder . setFlag ( Encoder . Flag . FLAG_GLOBAL_HEADER , true ) ; 
encoder . open ( null , null ) ; 
muxer . addNewStream ( encoder ) ; 
muxer . open ( null , null ) ; 
encoder . getWidth ( ) , 
encoder . getHeight ( ) , 
pixelformat ) ; 
picture . setTimeBase ( framerate ) ; 
for ( int i = 0 ; i < duration / framerate . getDouble ( ) ; i ++ ) { 
final BufferedImage screen = convertToType ( robot . createScreenCapture ( screenbounds ) , BufferedImage . TYPE_3BYTE_BGR ) ; 
if ( converter == null ) 
converter = MediaPictureConverterFactory . createConverter ( screen , picture ) ; 
converter . toPicture ( picture , screen , i ) ; 
encoder . encode ( packet , picture ) ; 
if ( packet . isComplete ( ) ) 
muxer . write ( packet , false ) ; 
} while ( packet . isComplete ( ) ) ; 
Thread . sleep ( ( long ) ( 1000 * framerate . getDouble ( ) ) ) ; 
encoder . encode ( packet , null ) ; 
muxer . close ( ) ; 
final long swigPtr = mSwigCPtr . getAndSet ( 0 ) ; 
if ( swigPtr != 0 ) 
if ( mJavaRefCount . decrementAndGet ( ) == 0 ) 
FerryJNI . RefCounted_release ( swigPtr , null ) ; 
mMemAllocator = null ; 
} public void addAudio ( MediaAudio audio ) { 
VideoJNI . FilterAudioSource_addAudio ( swigCPtr , this , MediaAudio . getCPtr ( audio ) , audio ) ; 
return VideoJNI . MediaResampler_resample ( swigCPtr , this , MediaSampled . getCPtr ( out ) , out , MediaSampled . getCPtr ( in ) , in ) ; 
} public static AudioFormat . Type getFormat ( String name ) { 
return AudioFormat . Type . swigToEnum ( VideoJNI . AudioFormat_getFormat ( name ) ) ; 
} public static AudioFormat . Type getAlternateSampleFormat ( AudioFormat . Type sample_fmt , boolean planar ) { 
return AudioFormat . Type . swigToEnum ( VideoJNI . AudioFormat_getAlternateSampleFormat ( sample_fmt . swigValue ( ) , planar ) ) ; 
} public static AudioFormat . Type getPackedSampleFormat ( AudioFormat . Type sample_fmt ) { 
return AudioFormat . Type . swigToEnum ( VideoJNI . AudioFormat_getPackedSampleFormat ( sample_fmt . swigValue ( ) ) ) ; 
} public static AudioFormat . Type getPlanarSampleFormat ( AudioFormat . Type sample_fmt ) { 
return AudioFormat . Type . swigToEnum ( VideoJNI . AudioFormat_getPlanarSampleFormat ( sample_fmt . swigValue ( ) ) ) ; 
} public static int getBufferSizeNeeded ( int numSamples , int numChannels , AudioFormat . Type format ) { 
return VideoJNI . AudioFormat_getBufferSizeNeeded ( numSamples , numChannels , format . swigValue ( ) ) ; 
} public static int getDataPlaneSizeNeeded ( int numSamples , int numChannels , AudioFormat . Type format ) { 
return VideoJNI . AudioFormat_getDataPlaneSizeNeeded ( numSamples , numChannels , format . swigValue ( ) ) ; 
} public static Muxer make ( String filename , MuxerFormat format , String formatName ) { 
long cPtr = VideoJNI . Muxer_make ( filename , MuxerFormat . getCPtr ( format ) , format , formatName ) ; 
return ( cPtr == 0 ) ? null : new Muxer ( cPtr , false ) ; 
} public MuxerFormat getFormat ( ) { 
long cPtr = VideoJNI . Muxer_getFormat ( swigCPtr , this ) ; 
} public void open ( KeyValueBag inputOptions , KeyValueBag outputOptions ) throws java . lang . InterruptedException , java . io . IOException { 
VideoJNI . Muxer_open ( swigCPtr , this , KeyValueBag . getCPtr ( inputOptions ) , inputOptions , KeyValueBag . getCPtr ( outputOptions ) , outputOptions ) ; 
} public MuxerStream addNewStream ( Coder coder ) { 
long cPtr = VideoJNI . Muxer_addNewStream ( swigCPtr , this , Coder . getCPtr ( coder ) , coder ) ; 
return ( cPtr == 0 ) ? null : new MuxerStream ( cPtr , false ) ; 
} public MuxerStream getStream ( int position ) throws java . lang . InterruptedException , java . io . IOException { 
long cPtr = VideoJNI . Muxer_getStream ( swigCPtr , this , position ) ; 
} public boolean write ( MediaPacket packet , boolean forceInterleave ) { 
return VideoJNI . Muxer_write ( swigCPtr , this , MediaPacket . getCPtr ( packet ) , packet , forceInterleave ) ; 
} public static Mutex make ( ) { 
long cPtr = FerryJNI . Mutex_make ( ) ; 
return ( cPtr == 0 ) ? null : new Mutex ( cPtr , false ) ; 
return Codec . ID . swigToEnum ( VideoJNI . DemuxerFormat_getSupportedCodecId ( swigCPtr , this , n ) ) ; 
} public static DemuxerFormat findFormat ( String shortName ) { 
long cPtr = VideoJNI . DemuxerFormat_findFormat ( shortName ) ; 
} protected static DemuxerFormat getFormat ( int index ) { 
long cPtr = VideoJNI . DemuxerFormat_getFormat ( index ) ; 
} public int getNumStreams ( ) throws java . lang . InterruptedException , java . io . IOException { 
return VideoJNI . Container_getNumStreams ( swigCPtr , this ) ; 
} public Coder getCoder ( ) { 
long cPtr = VideoJNI . MuxerStream_getCoder ( swigCPtr , this ) ; 
return ( cPtr == 0 ) ? null : new Coder ( cPtr , false ) ; 
} public Muxer getMuxer ( ) { 
long cPtr = VideoJNI . MuxerStream_getMuxer ( swigCPtr , this ) ; 
} public static SetScriptTransaction makeScriptTx ( PrivateKeyAccount sender , String script , byte chainId , long fee , long timestamp ) { 
return new SetScriptTransaction ( sender , script , chainId , fee , timestamp ) ; 
} public static byte [ ] decode ( String input ) throws IllegalArgumentException { 
if ( input . startsWith ( "base58:" ) ) input = input . substring ( 7 ) ; 
if ( input . length ( ) == 0 ) return new byte [ 0 ] ; 
byte [ ] input58 = new byte [ input . length ( ) ] ; 
for ( int i = 0 ; i < input . length ( ) ; ++ i ) { 
char c = input . charAt ( i ) ; 
int digit = c < 128 ? INDEXES [ c ] : - 1 ; 
if ( digit < 0 ) { 
input58 [ i ] = ( byte ) digit ; 
int zeros = 0 ; 
while ( zeros < input58 . length && input58 [ zeros ] == 0 ) { 
++ zeros ; 
byte [ ] decoded = new byte [ input . length ( ) ] ; 
int outputStart = decoded . length ; 
for ( int inputStart = zeros ; inputStart < input58 . length ; ) { 
decoded [ -- outputStart ] = divmod ( input58 , inputStart , 58 , 256 ) ; 
if ( input58 [ inputStart ] == 0 ) { 
++ inputStart ; 
while ( outputStart < decoded . length && decoded [ outputStart ] == 0 ) { 
++ outputStart ; 
return Arrays . copyOfRange ( decoded , outputStart - zeros , decoded . length ) ; 
} public static String generateSeed ( ) { 
byte [ ] bytes = new byte [ 21 ] ; 
new SecureRandom ( ) . nextBytes ( bytes ) ; 
byte [ ] rhash = hash ( bytes , 0 , 20 , SHA256 ) ; 
bytes [ 20 ] = rhash [ 0 ] ; 
BigInteger rand = new BigInteger ( bytes ) ; 
BigInteger mask = new BigInteger ( new byte [ ] { 0 , 0 , 7 , - 1 } ) ; 
for ( int i = 0 ; i < 15 ; i ++ ) { 
. append ( SEED_WORDS [ rand . and ( mask ) . intValue ( ) ] ) ; 
rand = rand . shiftRight ( 11 ) ; 
} public Transaction getTransaction ( String txId ) throws IOException { 
return wavesJsonMapper . convertValue ( send ( "/transactions/info/" + txId ) , Transaction . class ) ; 
} public List < Transaction > getAddressTransactions ( String address , int limit ) throws IOException { 
return getAddressTransactions ( address , limit , null ) ; 
} public List < Transaction > getAddressTransactions ( String address , int limit , String after ) throws IOException { 
String requestUrl = String . format ( "/transactions/address/%s/limit/%d" , address , limit ) ; 
if ( after != null ) { 
requestUrl += String . format ( "?after=%s" , after ) ; 
return wavesJsonMapper . < List < List < Transaction > > > convertValue ( send ( requestUrl ) , new TypeReference < List < List < Transaction > > > ( ) { } ) . get ( 0 ) ; 
} public List < BlockHeader > getBlockHeaderSeq ( int from , int to ) throws IOException { 
String path = String . format ( "/blocks/headers/seq/%s/%s" , from , to ) ; 
HttpResponse r = exec ( request ( path ) ) ; 
return parse ( r , BLOCK_HEADER_LIST ) ; 
} public Block getBlock ( String signature ) throws IOException { 
return wavesJsonMapper . convertValue ( send ( "/blocks/signature/" + signature ) , Block . class ) ; 
} public String send ( Transaction tx ) throws IOException { 
return parse ( exec ( request ( tx ) ) , "id" ) . asText ( ) ; 
} public String setScript ( PrivateKeyAccount from , String script , byte chainId , long fee ) throws IOException { 
return send ( Transactions . makeScriptTx ( from , compileScript ( script ) , chainId , fee ) ) ; 
} public String compileScript ( String script ) throws IOException { 
if ( script == null || script . isEmpty ( ) ) { 
HttpPost request = new HttpPost ( uri . resolve ( "/utils/script/compile" ) ) ; 
request . setEntity ( new StringEntity ( script ) ) ; 
return parse ( exec ( request ) , "script" ) . asText ( ) ; 
} static ArrayChar factory ( Index index , char [ ] storage ) { 
if ( index instanceof Index0D ) { 
return new ArrayChar . D0 ( index , storage ) ; 
} else if ( index instanceof Index1D ) { 
return new ArrayChar . D1 ( index , storage ) ; 
} else if ( index instanceof Index2D ) { 
return new ArrayChar . D2 ( index , storage ) ; 
} else if ( index instanceof Index3D ) { 
return new ArrayChar . D3 ( index , storage ) ; 
} else if ( index instanceof Index4D ) { 
return new ArrayChar . D4 ( index , storage ) ; 
} else if ( index instanceof Index5D ) { 
return new ArrayChar . D5 ( index , storage ) ; 
} else if ( index instanceof Index6D ) { 
return new ArrayChar . D6 ( index , storage ) ; 
} else if ( index instanceof Index7D ) { 
return new ArrayChar . D7 ( index , storage ) ; 
return new ArrayChar ( index , storage ) ; 
} protected void copyFrom1DJavaArray ( IndexIterator iter , Object javaArray ) { 
char [ ] ja = ( char [ ] ) javaArray ; 
for ( char aJa : ja ) iter . setCharNext ( aJa ) ; 
public ByteBuffer getDataAsByteBuffer ( ) { 
ByteBuffer bb = ByteBuffer . allocate ( ( int ) getSize ( ) ) ; 
resetLocalIterator ( ) ; 
bb . put ( nextByte ( ) ) ; 
return bb ; 
} public String getString ( ) { 
int rank = getRank ( ) ; 
if ( rank == 0 ) { 
return new String ( storage ) ; 
if ( rank != 1 ) 
int strLen = indexCalc . getShape ( 0 ) ; 
for ( int k = 0 ; k < strLen ; k ++ ) { 
if ( 0 == storage [ k ] ) 
return new String ( storage , 0 , count ) ; 
} public String getString ( int index ) { 
Index ima = getIndex ( ) ; 
return getString ( ima . set ( index ) ) ; 
} public String getString ( Index ima ) { 
if ( rank == 0 ) 
if ( rank == 1 ) 
return getString ( ) ; 
int strLen = indexCalc . getShape ( rank - 1 ) ; 
char [ ] carray = new char [ strLen ] ; 
ima . setDim ( rank - 1 , k ) ; 
carray [ k ] = getChar ( ima ) ; 
if ( 0 == carray [ k ] ) 
return new String ( carray , 0 , count ) ; 
} public void setString ( String val ) { 
int arrayLen = indexCalc . getShape ( 0 ) ; 
int strLen = Math . min ( val . length ( ) , arrayLen ) ; 
for ( int k = 0 ; k < strLen ; k ++ ) 
storage [ k ] = val . charAt ( k ) ; 
char c = 0 ; 
for ( int k = strLen ; k < arrayLen ; k ++ ) 
storage [ k ] = c ; 
} public void setString ( int index , String val ) { 
if ( rank != 2 ) 
setString ( ima . set ( index ) , val ) ; 
} public void setString ( Index ima , String val ) { 
int arrayLen = indexCalc . getShape ( rank - 1 ) ; 
setChar ( ima , val . charAt ( k ) ) ; 
for ( int k = count ; k < arrayLen ; k ++ ) { 
setChar ( ima , c ) ; 
} public ArrayObject make1DStringArray ( ) { 
int nelems = ( getRank ( ) == 0 ) ? 1 : ( int ) getSize ( ) / indexCalc . getShape ( getRank ( ) - 1 ) ; 
Array sarr = Array . factory ( DataType . STRING , new int [ ] { nelems } ) ; 
IndexIterator newsiter = sarr . getIndexIterator ( ) ; 
ArrayChar . StringIterator siter = getStringIterator ( ) ; 
while ( siter . hasNext ( ) ) { 
newsiter . setObjectNext ( siter . next ( ) ) ; 
return ( ArrayObject ) sarr ; 
} public static ArrayChar makeFromString ( String s , int max ) { 
ArrayChar result = new ArrayChar . D1 ( max ) ; 
for ( int i = 0 ; i < max && i < s . length ( ) ; i ++ ) 
result . setChar ( i , s . charAt ( i ) ) ; 
} public static ArrayChar makeFromStringArray ( ArrayObject values ) { 
IndexIterator ii = values . getIndexIterator ( ) ; 
int strlen = 0 ; 
while ( ii . hasNext ( ) ) { 
String s = ( String ) ii . next ( ) ; 
strlen = Math . max ( s . length ( ) , strlen ) ; 
return makeFromStringArray ( values , strlen ) ; 
} public static ArrayChar makeFromStringArray ( ArrayObject values , int strlen ) { 
Section section = new Section ( values . getShape ( ) ) ; 
section . appendRange ( strlen ) ; 
int [ ] shape = section . getShape ( ) ; 
long size = section . computeSize ( ) ; 
char [ ] cdata = new char [ ( int ) size ] ; 
int start = 0 ; 
for ( int k = 0 ; k < s . length ( ) && k < strlen ; k ++ ) 
cdata [ start + k ] = s . charAt ( k ) ; 
start += strlen ; 
Array carr = Array . factory ( DataType . CHAR , shape , cdata ) ; 
return ( ArrayChar ) carr ; 
} catch ( InvalidRangeException e ) { 
} public MAVector dot ( MAVector v ) { 
if ( ncols != v . getNelems ( ) ) 
ArrayDouble . D1 result = new ArrayDouble . D1 ( nrows ) ; 
Index imr = result . getIndex ( ) ; 
for ( int i = 0 ; i < nrows ; i ++ ) { 
double sum = 0.0 ; 
for ( int k = 0 ; k < ncols ; k ++ ) 
sum += getDouble ( i , k ) * v . getDouble ( k ) ; 
result . setDouble ( imr . set ( i ) , sum ) ; 
return new MAVector ( result ) ; 
} static public MAMatrix multiply ( MAMatrix m1 , MAMatrix m2 ) { 
if ( m1 . getNcols ( ) != m2 . getNrows ( ) ) 
int kdims = m1 . getNcols ( ) ; 
ArrayDouble . D2 result = new ArrayDouble . D2 ( m1 . getNrows ( ) , m2 . getNcols ( ) ) ; 
for ( int i = 0 ; i < m1 . getNrows ( ) ; i ++ ) { 
for ( int j = 0 ; j < m2 . getNcols ( ) ; j ++ ) { 
for ( int k = 0 ; k < kdims ; k ++ ) 
sum += m1 . getDouble ( i , k ) * m2 . getDouble ( k , j ) ; 
result . setDouble ( imr . set ( i , j ) , sum ) ; 
return new MAMatrix ( result ) ; 
} public void postMultiplyDiagonal ( MAVector diag ) { 
if ( ncols != diag . getNelems ( ) ) 
for ( int j = 0 ; j < ncols ; j ++ ) { 
double val = a . getDouble ( ima . set ( i , j ) ) * diag . getDouble ( j ) ; 
a . setDouble ( ima , val ) ; 
public int [ ] getForecastTimeIntervalOffset ( Grib2Record gr ) { 
Grib2Pds pds = gr . getPDS ( ) ; 
if ( ! pds . isTimeInterval ( ) ) { 
int statType = pds . getOctet ( 47 ) ; 
int n = pds . getInt4StartingAtOctet ( 50 ) ; 
int p2 = pds . getInt4StartingAtOctet ( 55 ) ; 
int p2mp1 = pds . getInt4StartingAtOctet ( 62 ) ; 
int p1 = p2 - p2mp1 ; 
int start , end ; 
switch ( statType ) { 
case 193 : 
start = p1 ; 
end = p1 + n * p2 ; 
case 194 : 
start = 0 ; 
end = n * p2 ; 
case 195 : 
case 204 : 
case 205 : 
end = p2 ; 
return new int [ ] { start , end } ; 
} private void initLocalTable ( ) { 
String tableName = config . getPath ( ) ; 
ClassLoader cl = this . getClass ( ) . getClassLoader ( ) ; 
try ( InputStream is = cl . getResourceAsStream ( tableName ) ) { 
if ( is == null ) { 
try ( BufferedReader br = new BufferedReader ( new InputStreamReader ( is , CDM . utf8Charset ) ) ) { 
String line = br . readLine ( ) ; 
if ( line == null ) { 
if ( ( line . length ( ) == 0 ) || line . startsWith ( "#" ) ) { 
String [ ] flds = StringUtil2 . splitString ( line ) ; 
int p1 = Integer . parseInt ( flds [ 0 ] . trim ( ) ) ; 
int p2 = Integer . parseInt ( flds [ 1 ] . trim ( ) ) ; 
int p3 = Integer . parseInt ( flds [ 2 ] . trim ( ) ) ; 
StringBuilder b = new StringBuilder ( ) ; 
int count = 3 ; 
while ( count < flds . length && ! flds [ count ] . equals ( "." ) ) { 
String abbrev = b . toString ( ) . trim ( ) ; 
b . setLength ( 0 ) ; 
String name = b . toString ( ) . trim ( ) ; 
String unit = b . toString ( ) . trim ( ) ; 
Grib2Parameter s = new Grib2Parameter ( p1 , p2 , p3 , name , unit , abbrev , null ) ; 
local . put ( makeParamId ( p1 , p2 , p3 ) , s ) ; 
} public void draw ( java . awt . Graphics2D g , AffineTransform deviceFromNormalAT ) { 
g . setColor ( Color . black ) ; 
g . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , 
RenderingHints . VALUE_ANTIALIAS_OFF ) ; 
g . setStroke ( new java . awt . BasicStroke ( 0.0f ) ) ; 
Rectangle2D clipRect = ( Rectangle2D ) g . getClip ( ) ; 
Iterator siter = getShapes ( g , deviceFromNormalAT ) ; 
Shape s = ( Shape ) siter . next ( ) ; 
Rectangle2D shapeBounds = s . getBounds2D ( ) ; 
if ( shapeBounds . intersects ( clipRect ) ) 
g . draw ( s ) ; 
if ( ShowLabels ) { 
Font f = FontUtil . getStandardFont ( 10 ) . getFont ( ) ; 
Font saveFont = g . getFont ( ) ; 
AffineTransform deviceFromWorldAT = g . getTransform ( ) ; 
AffineTransform normalFromWorldAT ; 
normalFromWorldAT = deviceFromNormalAT . createInverse ( ) ; 
normalFromWorldAT . concatenate ( deviceFromWorldAT ) ; 
} catch ( java . awt . geom . NoninvertibleTransformException e ) { 
g . setTransform ( deviceFromNormalAT ) ; 
g . setFont ( f ) ; 
siter = getShapes ( g , deviceFromNormalAT ) ; 
Iterator CViter = contourList . iterator ( ) ; 
Point2D worldPt = new Point2D . Double ( ) ; 
Point2D normalPt = new Point2D . Double ( ) ; 
float [ ] coords = new float [ 6 ] ; 
double contValue = ( ( ContourFeature ) CViter . next ( ) ) . getContourValue ( ) ; 
PathIterator piter = s . getPathIterator ( null ) ; 
int cs , count = 12 ; 
while ( ! piter . isDone ( ) ) { 
if ( count % 25 == 0 ) { 
cs = piter . currentSegment ( coords ) ; 
if ( cs == PathIterator . SEG_MOVETO || cs == PathIterator . SEG_LINETO ) { 
worldPt . setLocation ( coords [ 0 ] , coords [ 1 ] ) ; 
normalFromWorldAT . transform ( worldPt , normalPt ) ; 
g . drawString ( Format . d ( contValue , 4 ) , ( int ) normalPt . getX ( ) , ( int ) normalPt . getY ( ) ) ; 
piter . next ( ) ; 
g . setTransform ( deviceFromWorldAT ) ; 
g . setFont ( saveFont ) ; 
if ( Debug . isSet ( "contour/doLabels" ) ) { 
for ( Object aContourList : contourList ) { 
+ ( ( ContourFeature ) aContourList ) . getContourValue ( ) ) ; 
} public void show ( ) { 
setState ( Frame . NORMAL ) ; 
super . toFront ( ) ; 
SwingUtilities . invokeLater ( new Runnable ( ) { 
IndependentWindow . super . show ( ) ; 
} public void showIfNotIconified ( ) { 
if ( getState ( ) == Frame . ICONIFIED ) return ; 
} private Array readData ( ucar . nc2 . Variable v2 , long dataPos , List < Range > ranges , 
int [ ] levels ) throws IOException , InvalidRangeException { 
raf . seek ( dataPos ) ; 
int data_size = ( int ) ( raf . length ( ) - dataPos ) ; 
byte [ ] data = new byte [ data_size ] ; 
raf . readFully ( data ) ; 
Array array = makeArray ( data , levels , v2 . getShape ( ) ) ; 
return array . sectionNoReduce ( ranges ) ; 
} private Array readCompressedData ( ucar . nc2 . Variable v2 , long dataPos , List < Range > ranges , 
ByteArrayInputStream ios = new ByteArrayInputStream ( data ) ; 
BufferedImage image = javax . imageio . ImageIO . read ( ios ) ; 
DataBuffer db = image . getData ( ) . getDataBuffer ( ) ; 
if ( db instanceof DataBufferByte ) { 
DataBufferByte dbb = ( DataBufferByte ) db ; 
Array array = makeArray ( dbb . getData ( ) , levels , v2 . getShape ( ) ) ; 
if ( levels == null ) 
v2 . setCachedData ( array , false ) ; 
} static public long makeSizeEstimate ( ucar . nc2 . dt . GridDataset gds , List < String > gridList , 
LatLonRect llbb , ProjectionRect projRect , int horizStride , Range zRange , 
CalendarDateRange dateRange , int stride_time , boolean addLatLon ) throws IOException , InvalidRangeException { 
CFGridWriter2 writer2 = new CFGridWriter2 ( ) ; 
return writer2 . writeOrTestSize ( gds , gridList , llbb , projRect , horizStride , zRange , dateRange , stride_time , addLatLon , true , null ) ; 
} static public long writeFile ( ucar . nc2 . dt . GridDataset gds , List < String > gridList , 
CalendarDateRange dateRange , int stride_time , boolean addLatLon , NetcdfFileWriter writer ) throws IOException , InvalidRangeException { 
return writer2 . writeOrTestSize ( gds , gridList , llbb , projRect , horizStride , zRange , dateRange , stride_time , addLatLon , false , writer ) ; 
} private RandomAccessFile uncompress ( RandomAccessFile inputRaf , String ufilename ) throws IOException { 
RandomAccessFile outputRaf = new RandomAccessFile ( ufilename , "rw" ) ; 
FileLock lock ; 
lock = outputRaf . getRandomAccessFile ( ) . getChannel ( ) . lock ( 0 , 1 , false ) ; 
} catch ( OverlappingFileLockException oe ) { 
} catch ( InterruptedException e1 ) { 
outputRaf . close ( ) ; 
inputRaf . seek ( 0 ) ; 
byte [ ] header = new byte [ Level2Record . FILE_HEADER_SIZE ] ; 
int bytesRead = inputRaf . read ( header ) ; 
if ( bytesRead != header . length ) 
outputRaf . write ( header ) ; 
boolean eof = false ; 
int numCompBytes ; 
byte [ ] ubuff = new byte [ 40000 ] ; 
byte [ ] obuff = new byte [ 40000 ] ; 
CBZip2InputStream cbzip2 = new CBZip2InputStream ( ) ; 
while ( ! eof ) { 
numCompBytes = inputRaf . readInt ( ) ; 
if ( numCompBytes == - 1 ) { 
if ( log . isDebugEnabled ( ) ) 
} catch ( EOFException ee ) { 
if ( log . isDebugEnabled ( ) ) { 
if ( numCompBytes < 0 ) { 
numCompBytes = - numCompBytes ; 
eof = true ; 
byte [ ] buf = new byte [ numCompBytes ] ; 
inputRaf . readFully ( buf ) ; 
ByteArrayInputStream bis = new ByteArrayInputStream ( buf , 2 , 
numCompBytes - 2 ) ; 
cbzip2 . setStream ( bis ) ; 
int total = 0 ; 
int nread ; 
while ( ( nread = cbzip2 . read ( ubuff ) ) != - 1 ) { 
if ( total + nread > obuff . length ) { 
byte [ ] temp = obuff ; 
obuff = new byte [ temp . length * 2 ] ; 
System . arraycopy ( temp , 0 , obuff , 0 , temp . length ) ; 
System . arraycopy ( ubuff , 0 , obuff , total , nread ) ; 
total += nread ; 
if ( obuff . length >= 0 ) outputRaf . write ( obuff , 0 , total ) ; 
} catch ( BZip2ReadException ioe ) { 
float nrecords = ( float ) ( total / 2432.0 ) ; 
outputRaf . flush ( ) ; 
if ( outputRaf != null ) outputRaf . close ( ) ; 
File ufile = new File ( ufilename ) ; 
if ( ufile . exists ( ) ) { 
if ( ! ufile . delete ( ) ) 
if ( lock != null ) lock . release ( ) ; 
return outputRaf ; 
} public static void main ( String [ ] args ) throws IOException { 
String file = ( args . length > 0 ) ? args [ 0 ] : "Q:/cdmUnitTest/formats/grib1/ECMWF.hybrid.grib1" ; 
RandomAccessFile raf = new RandomAccessFile ( file , "r" ) ; 
Grib1RecordScanner scan = new Grib1RecordScanner ( raf ) ; 
while ( scan . hasNext ( ) ) { 
scan . next ( ) ; 
raf . close ( ) ; 
System . out . printf ( "count=%d%n" , count ) ; 
} public static UnitName newUnitName ( final String name , final String plural ) 
throws NameException { 
return newUnitName ( name , plural , null ) ; 
} public static UnitName newUnitName ( final String name , final String plural , 
final String symbol ) throws NameException { 
return new UnitName ( name , plural , symbol ) ; 
} protected String makePlural ( final String name ) { 
String plural ; 
final int length = name . length ( ) ; 
final char lastChar = name . charAt ( length - 1 ) ; 
if ( lastChar != 'y' ) { 
plural = name 
+ ( lastChar == 's' || lastChar == 'x' || lastChar == 'z' 
|| name . endsWith ( "ch" ) 
? "es" 
: "s" ) ; 
if ( length == 1 ) { 
plural = name + "s" ; 
final char penultimateChar = name . charAt ( length - 2 ) ; 
plural = ( penultimateChar == 'a' || penultimateChar == 'e' 
|| penultimateChar == 'i' || penultimateChar == 'o' || penultimateChar == 'u' ) 
? name + "s" 
: name . substring ( 0 , length - 1 ) + "ies" ; 
return plural ; 
} private String chooseResolution ( double time ) { 
if ( time < 180 ) 
return "secs" ; 
time /= 60 ; 
return "minutes" ; 
if ( time < 72 ) 
return "hours" ; 
time /= 24 ; 
if ( time < 90 ) 
return "days" ; 
time /= 30 ; 
if ( time < 36 ) 
return "months" ; 
return "years" ; 
} public boolean included ( Date d ) { 
if ( isEmpty ) return false ; 
if ( getStart ( ) . after ( d ) ) return false ; 
if ( getEnd ( ) . before ( d ) ) return false ; 
} public boolean intersects ( Date start_want , Date end_want ) { 
if ( getStart ( ) . after ( end_want ) ) return false ; 
if ( getEnd ( ) . before ( start_want ) ) return false ; 
} public boolean intersects ( DateRange other ) { 
return intersects ( other . getStart ( ) . getDate ( ) , other . getEnd ( ) . getDate ( ) ) ; 
} public DateRange intersect ( DateRange clip ) { 
if ( isEmpty ) return this ; 
if ( clip . isEmpty ) return clip ; 
DateType ss = getStart ( ) ; 
DateType s = ss . before ( clip . getStart ( ) ) ? clip . getStart ( ) : ss ; 
DateType ee = getEnd ( ) ; 
DateType e = ee . before ( clip . getEnd ( ) ) ? ee : clip . getEnd ( ) ; 
return new DateRange ( s , e , null , resolution ) ; 
} public void extend ( DateRange dr ) { 
boolean localEmpty = isEmpty ; 
if ( localEmpty || dr . getStart ( ) . before ( getStart ( ) ) ) 
setStart ( dr . getStart ( ) ) ; 
if ( localEmpty || getEnd ( ) . before ( dr . getEnd ( ) ) ) 
setEnd ( dr . getEnd ( ) ) ; 
} public void extend ( Date d ) { 
if ( d . before ( getStart ( ) . getDate ( ) ) ) 
setStart ( new DateType ( false , d ) ) ; 
if ( getEnd ( ) . before ( d ) ) 
setEnd ( new DateType ( false , d ) ) ; 
} public void setStart ( DateType start ) { 
this . start = start ; 
useStart = true ; 
if ( useEnd ) { 
this . isMoving = this . start . isPresent ( ) || this . end . isPresent ( ) ; 
useDuration = false ; 
recalcDuration ( ) ; 
this . isMoving = this . start . isPresent ( ) ; 
this . end = this . start . add ( duration ) ; 
checkIfEmpty ( ) ; 
} public void setEnd ( DateType end ) { 
this . end = end ; 
useEnd = true ; 
if ( useStart ) { 
this . isMoving = this . end . isPresent ( ) ; 
this . start = this . end . subtract ( duration ) ; 
} public void setDuration ( TimeDuration duration ) { 
this . duration = duration ; 
useDuration = true ; 
useEnd = false ; 
} private void recalcDuration ( ) { 
long min = getStart ( ) . getDate ( ) . getTime ( ) ; 
long max = getEnd ( ) . getDate ( ) . getTime ( ) ; 
double secs = .001 * ( max - min ) ; 
if ( secs < 0 ) 
secs = 0 ; 
if ( duration == null ) { 
duration = new TimeDuration ( chooseResolution ( secs ) ) ; 
if ( resolution == null ) { 
duration . setValueInSeconds ( secs ) ; 
double resSecs = resolution . getValueInSeconds ( ) ; 
double closest = Math . round ( secs / resSecs ) ; 
secs = closest * resSecs ; 
hashCode = 0 ; 
} public void storePersistentData ( ) { 
store . putInt ( "vertSplit" , splitDraw . getDividerLocation ( ) ) ; 
store . putBoolean ( "navToolbarAction" , ( ( Boolean ) navToolbarAction . getValue ( BAMutil . STATE ) ) . booleanValue ( ) ) ; 
store . putBoolean ( "moveToolbarAction" , ( ( Boolean ) moveToolbarAction . getValue ( BAMutil . STATE ) ) . booleanValue ( ) ) ; 
if ( projManager != null ) 
projManager . storePersistentData ( ) ; 
dsTable . save ( ) ; 
dsTable . getPrefs ( ) . putBeanObject ( "DialogBounds" , dsDialog . getBounds ( ) ) ; 
store . put ( GEOTIFF_FILECHOOSER_DEFAULTDIR , geotiffFileChooser . getCurrentDirectory ( ) ) ; 
controller . storePersistentData ( ) ; 
} public void addMapBean ( MapBean mb ) { 
mapBeanMenu . addAction ( mb . getActionDesc ( ) , mb . getIcon ( ) , mb . getAction ( ) ) ; 
if ( mapBeanCount == 0 ) { 
setMapRenderer ( mb . getRenderer ( ) ) ; 
mapBeanCount ++ ; 
mb . addPropertyChangeListener ( new PropertyChangeListener ( ) { 
public void propertyChange ( java . beans . PropertyChangeEvent e ) { 
if ( e . getPropertyName ( ) . equals ( "Renderer" ) ) { 
setMapRenderer ( ( Renderer ) e . getNewValue ( ) ) ; 
} private void makeActionsDataset ( ) { 
AbstractAction chooseLocalDatasetAction = new AbstractAction ( ) { 
public void actionPerformed ( ActionEvent e ) { 
String filename = fileChooser . chooseFilename ( ) ; 
if ( filename == null ) return ; 
Dataset invDs ; 
invDs = Dataset . makeStandalone ( filename , FeatureType . GRID . toString ( ) , "" , ServiceType . File . toString ( ) ) ; 
} catch ( Exception ue ) { 
ue . printStackTrace ( ) ; 
setDataset ( invDs ) ; 
chooseProjectionAction = new AbstractAction ( ) { 
getProjectionManager ( ) . setVisible ( ) ; 
saveCurrentProjectionAction = new AbstractAction ( ) { 
getProjectionManager ( ) ; 
ProjectionImpl proj = panz . getProjectionImpl ( ) . constructCopy ( ) ; 
proj . setDefaultMapArea ( panz . getMapArea ( ) ) ; 
redrawAction = new AbstractAction ( ) { 
repaint ( ) ; 
controller . start ( true ) ; 
controller . draw ( true ) ; 
BAMutil . setActionProperties ( redrawAction , "alien" , "RedRaw" , false , 'W' , 0 ) ; 
showDatasetInfoAction = new AbstractAction ( ) { 
if ( infoWindow == null ) { 
datasetInfoTA = new TextHistoryPane ( ) ; 
infoWindow . setSize ( 700 , 700 ) ; 
infoWindow . setLocation ( 100 , 100 ) ; 
datasetInfoTA . clear ( ) ; 
datasetInfoTA . appendLine ( controller . getDatasetInfo ( ) ) ; 
datasetInfoTA . gotoTop ( ) ; 
infoWindow . show ( ) ; 
showNcMLAction = new AbstractAction ( ) { 
if ( ncmlWindow == null ) { 
ncmlTA = new TextHistoryPane ( ) ; 
ncmlWindow . setSize ( 700 , 700 ) ; 
ncmlWindow . setLocation ( 200 , 70 ) ; 
ncmlTA . clear ( ) ; 
ncmlTA . appendLine ( controller . getNcML ( ) ) ; 
ncmlTA . gotoTop ( ) ; 
ncmlWindow . show ( ) ; 
showGridDatasetInfoAction = new AbstractAction ( ) { 
ncmlTA . appendLine ( controller . getDatasetXML ( ) ) ; 
showGridTableAction = new AbstractAction ( ) { 
gtWindow . show ( ) ; 
showNetcdfDatasetAction = new AbstractAction ( ) { 
NetcdfDataset netcdfDataset = controller . getNetcdfDataset ( ) ; 
if ( null != netcdfDataset ) { 
dsTable . setDataset ( netcdfDataset , null ) ; 
e1 . printStackTrace ( ) ; 
dsDialog . show ( ) ; 
minmaxHorizAction = new AbstractAction ( ) { 
csDataMinMax . setSelectedItem ( ColorScale . MinMaxType . horiz ) ; 
controller . setDataMinMaxType ( ColorScale . MinMaxType . horiz ) ; 
minmaxLogAction = new AbstractAction ( ) { 
csDataMinMax . setSelectedItem ( ColorScale . MinMaxType . log ) ; 
controller . setDataMinMaxType ( ColorScale . MinMaxType . log ) ; 
minmaxHoldAction = new AbstractAction ( ) { 
csDataMinMax . setSelectedItem ( ColorScale . MinMaxType . hold ) ; 
controller . setDataMinMaxType ( ColorScale . MinMaxType . hold ) ; 
fieldLoopAction = new LoopControlAction ( fieldChooser ) ; 
levelLoopAction = new LoopControlAction ( levelChooser ) ; 
timeLoopAction = new LoopControlAction ( timeChooser ) ; 
} public ArrayDouble . D3 getCoordinateArray ( int timeIndex ) 
throws IOException , InvalidRangeException { 
Array etaArray = readArray ( etaVar , timeIndex ) ; 
Array sArray = readArray ( sVar , timeIndex ) ; 
Array depthArray = readArray ( depthVar , timeIndex ) ; 
Array cArray = readArray ( cVar , timeIndex ) ; 
depth_c = depthCVar . readScalarDouble ( ) ; 
return makeHeight ( etaArray , sArray , depthArray , cArray , depth_c ) ; 
} public ArrayDouble . D1 getCoordinateArray1D ( int timeIndex , int xIndex , int yIndex ) 
return makeHeight1D ( etaArray , sArray , depthArray , cArray , depth_c , xIndex , yIndex ) ; 
} private long getFilePos ( long elem ) { 
long segno = elem / innerNelems ; 
long offset = elem % innerNelems ; 
return startPos + segno * recSize + offset * elemSize ; 
} public int 
yylex ( ) 
throws ParseException 
int token ; 
int c = 0 ; 
token = 0 ; 
yytext . setLength ( 0 ) ; 
text . mark ( ) ; 
token = - 1 ; 
while ( token < 0 && ( c = text . read ( ) ) != EOS ) { 
} else if ( c == '"' || c == '\'' ) { 
int delim = c ; 
boolean more = true ; 
while ( more && ( c = text . read ( ) ) > 0 ) { 
switch ( c ) { 
case EOS : 
case '"' : 
more = ( delim != c ) ; 
case '\'' : 
case ESCAPE : 
case 'r' : 
c = '\r' ; 
case 'n' : 
c = '\n' ; 
case 'f' : 
c = '\f' ; 
case 't' : 
c = '\t' ; 
if ( more ) yytext . append ( ( char ) c ) ; 
token = CEParserImpl . Lexer . STRING ; 
} else if ( DELIMS . indexOf ( c ) >= 0 ) { 
yytext . append ( ( char ) c ) ; 
token = c ; 
while ( ( c = text . read ( ) ) > 0 ) { 
if ( DELIMS . indexOf ( c ) >= 0 ) break ; 
if ( c == ESCAPE ) { 
c = text . read ( ) ; 
if ( c == EOS ) 
if ( c != EOS ) text . backup ( ) ; 
long num = Long . parseLong ( yytext . toString ( ) ) ; 
token = CEParserImpl . Lexer . LONG ; 
} catch ( NumberFormatException nfe ) { 
token = CEParserImpl . Lexer . NAME ; 
if ( c == EOS && token < 0 ) { 
lval = null ; 
lval = ( yytext . length ( ) == 0 ? ( String ) null : yytext . toString ( ) ) ; 
if ( parsestate . getDebugLevel ( ) > 0 ) 
dumptoken ( token , ( String ) lval ) ; 
} public void yyerror ( String s ) 
String context = getInput ( ) ; 
int show = ( context . length ( ) < CONTEXTLEN ? context . length ( ) : CONTEXTLEN ) ; 
System . err . println ( context . substring ( context . length ( ) - show ) + "^" ) ; 
new Exception ( ) . printStackTrace ( System . err ) ; 
} static public DtCoverageDataset open ( String location ) throws java . io . IOException { 
DatasetUrl durl = DatasetUrl . findDatasetUrl ( location ) ; 
return open ( durl , NetcdfDataset . getDefaultEnhanceMode ( ) ) ; 
} static public DtCoverageDataset open ( DatasetUrl durl , Set < NetcdfDataset . Enhance > enhanceMode ) throws java . io . IOException { 
NetcdfDataset ds = ucar . nc2 . dataset . NetcdfDataset . acquireDataset ( null , durl , enhanceMode , - 1 , null , null ) ; 
return new DtCoverageDataset ( ds , null ) ; 
} public String getName ( ) { 
String loc = ncd . getLocation ( ) ; 
int pos = loc . lastIndexOf ( '/' ) ; 
if ( pos < 0 ) 
pos = loc . lastIndexOf ( '\\' ) ; 
return ( pos < 0 ) ? loc : loc . substring ( pos + 1 ) ; 
} public DtCoverage findGridByName ( String fullName ) { 
for ( DtCoverage ggi : grids ) { 
if ( fullName . equals ( ggi . getFullName ( ) ) ) 
return ggi ; 
} public DtCoverage findGridByShortName ( String shortName ) { 
if ( shortName . equals ( ggi . getShortName ( ) ) ) 
} public String paramsToString ( ) { 
Formatter f = new Formatter ( ) ; 
return f . toString ( ) ; 
} public boolean crossSeam ( ProjectionPoint pt1 , ProjectionPoint pt2 ) { 
if ( ProjectionPointImpl . isInfinite ( pt1 ) || ProjectionPointImpl . isInfinite ( pt2 ) ) { 
} private double computeTheta ( double lon ) { 
double dlon = LatLonPointImpl . lonNormal ( lon - lon0deg ) ; 
return n * Math . toRadians ( dlon ) ; 
} public ProjectionPoint latLonToProj ( LatLonPoint latLon , ProjectionPointImpl result ) { 
double fromLat = Math . toRadians ( latLon . getLatitude ( ) ) ; 
double theta = computeTheta ( latLon . getLongitude ( ) ) ; 
double rho = 0.0 ; 
if ( Math . abs ( Math . abs ( fromLat ) - MapMath . HALFPI ) >= TOL ) { 
double term ; 
if ( isSpherical ) 
term = Math . pow ( Math . tan ( MapMath . QUARTERPI + .5 * fromLat ) , - n ) ; 
term = Math . pow ( MapMath . tsfn ( fromLat , Math . sin ( fromLat ) , e ) , n ) ; 
rho = c * term ; 
double toX = ( rho * Math . sin ( theta ) ) ; 
double toY = ( rho0 - rho * Math . cos ( theta ) ) ; 
result . setLocation ( totalScale * toX + falseEasting , totalScale * toY + falseNorthing ) ; 
} public LatLonPoint projToLatLon ( ProjectionPoint world , LatLonPointImpl result ) { 
double toLat , toLon ; 
double fromX = ( world . getX ( ) - falseEasting ) / totalScale ; 
double fromY = ( world . getY ( ) - falseNorthing ) / totalScale ; 
fromY = rho0 - fromY ; 
double rho = MapMath . distance ( fromX , fromY ) ; 
if ( rho != 0 ) { 
if ( n < 0.0 ) { 
rho = - rho ; 
fromX = - fromX ; 
fromY = - fromY ; 
toLat = 2.0 * Math . atan ( Math . pow ( c / rho , 1.0 / n ) ) - MapMath . HALFPI ; 
toLat = MapMath . phi2 ( Math . pow ( rho / c , 1.0 / n ) , e ) ; 
toLon = Math . atan2 ( fromX , fromY ) / n ; 
toLon = 0.0 ; 
toLat = n > 0.0 ? MapMath . HALFPI : - MapMath . HALFPI ; 
result . setLatitude ( Math . toDegrees ( toLat ) ) ; 
result . setLongitude ( Math . toDegrees ( toLon ) + lon0deg ) ; 
} private static void toProj ( ProjectionImpl p , double lat , double lon ) { 
ProjectionPoint pt = p . latLonToProj ( lat , lon ) ; 
LatLonPoint ll = p . projToLatLon ( pt ) ; 
} public boolean dspMatch ( String location , DapContext context ) 
XURI xuri = new XURI ( location ) ; 
if ( xuri . isFile ( ) ) { 
String path = xuri . getPath ( ) ; 
for ( String ext : EXTENSIONS ) { 
if ( path . endsWith ( ext ) ) 
} catch ( URISyntaxException use ) { 
} public FileDSP 
open ( byte [ ] rawdata ) 
throws DapException 
this . raw = rawdata ; 
ByteArrayInputStream stream = new ByteArrayInputStream ( this . raw ) ; 
ChunkInputStream rdr = new ChunkInputStream ( stream , RequestMode . DAP ) ; 
String document = rdr . readDMR ( ) ; 
byte [ ] serialdata = DapUtil . readbinaryfile ( rdr ) ; 
super . build ( document , serialdata , rdr . getRemoteByteOrder ( ) ) ; 
throw new DapException ( ioe ) . setCode ( DapCodes . SC_INTERNAL_SERVER_ERROR ) ; 
} public DAPNode cloneDAG ( CloneMap map ) 
throws CloneNotSupportedException 
Alias a = ( Alias ) super . cloneDAG ( map ) ; 
a . aliasedToAttributeNamed = this . aliasedToAttributeNamed ; 
a . targetAttribute = ( Attribute ) cloneDAG ( map , this . targetAttribute ) ; 
a . targetVariable = ( BaseType ) cloneDAG ( map , this . targetVariable ) ; 
return a ; 
public int getMaximumValue ( ReadablePartial partial ) { 
if ( partial . isSupported ( DateTimeFieldType . monthOfYear ( ) ) ) { 
int month = partial . get ( DateTimeFieldType . monthOfYear ( ) ) ; 
return this . daysInMonth [ month - 1 ] ; 
return this . getMaximumValue ( ) ; 
public int getMaximumValue ( ReadablePartial partial , int [ ] values ) { 
int size = partial . size ( ) ; 
if ( partial . getFieldType ( i ) == DateTimeFieldType . monthOfYear ( ) ) { 
int month = values [ i ] ; 
} private Optional < List < RangeIterator > > computeBounds ( LatLonRect llbb , int horizStride ) { 
if ( edges == null ) edges = new Edges ( ) ; 
return edges . computeBoundsExhaustive ( llbb , horizStride ) ; 
} public static CollectionType initCollection ( CollectionType collection , FeatureDatasetPoint fdPoint , 
List < VariableSimpleIF > dataVars ) throws IOException { 
String id = MarshallingUtil . createIdForType ( CollectionType . class ) ; 
collection . setId ( id ) ; 
NcDocumentMetadataPropertyType . initMetadata ( collection . addNewMetadata ( ) ) ; 
StationTimeSeriesFeatureCollection stationFeatColl = getStationFeatures ( fdPoint ) ; 
while ( stationFeatColl . hasNext ( ) ) { 
StationTimeSeriesFeature stationFeat = stationFeatColl . next ( ) ; 
for ( VariableSimpleIF dataVar : dataVars ) { 
if ( dataVar . getDataType ( ) . isNumeric ( ) ) { 
NcOMObservationPropertyType . initObservationMember ( 
collection . addNewObservationMember ( ) , stationFeat , dataVar ) ; 
stationFeatColl . finish ( ) ; 
return collection ; 
} public static OMObservationType initOmObservation ( OMObservationType omObservation , 
StationTimeSeriesFeature stationFeat , VariableSimpleIF dataVar ) throws IOException { 
String id = MarshallingUtil . createIdForType ( OMObservationType . class ) ; 
omObservation . setId ( id ) ; 
NcTimeObjectPropertyType . initPhenomenonTime ( omObservation . addNewPhenomenonTime ( ) , stationFeat ) ; 
NcTimeInstantPropertyType . initResultTime ( omObservation . addNewResultTime ( ) ) ; 
NcReferenceType . initObservedProperty ( omObservation . addNewObservedProperty ( ) , dataVar ) ; 
NcOMProcessPropertyType . initProcedure ( omObservation . addNewProcedure ( ) ) ; 
NcFeaturePropertyType . initFeatureOfInterest ( omObservation . addNewFeatureOfInterest ( ) , stationFeat ) ; 
MeasurementTimeseriesDocument measurementTimeseriesDoc = MeasurementTimeseriesDocument . Factory . newInstance ( ) ; 
NcMeasurementTimeseriesType . initMeasurementTimeseries ( 
measurementTimeseriesDoc . addNewMeasurementTimeseries ( ) , stationFeat , dataVar ) ; 
omObservation . setResult ( measurementTimeseriesDoc ) ; 
return omObservation ; 
} private void doCheckHash ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
int [ ] accum = new int [ 4 ] ; 
TrackMessageTypes all = new TrackMessageTypes ( ) ; 
for ( MFile mfile : dcm . getFilesSorted ( ) ) { 
String path = mfile . getPath ( ) ; 
if ( path . endsWith ( ".ncx" ) ) continue ; 
doCheckHash ( mfile , f , all , accum ) ; 
t . printStackTrace ( ) ; 
show ( all , f ) ; 
} private void doBufrSplitter ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
String dirName = dcm . getRoot ( ) + "/split" ; 
BufrSplitter2 splitter = new BufrSplitter2 ( dirName , f ) ; 
long start2 = System . currentTimeMillis ( ) ; 
splitter . execute ( path ) ; 
long took2 = System . currentTimeMillis ( ) - start2 ; 
splitter . exit ( ) ; 
long took = ( System . currentTimeMillis ( ) - start ) / 1000 ; 
} int readAllData ( RandomAccessFile raf ) throws IOException , NumberFormatException , ParseException { 
ArrayList records = new ArrayList ( ) ; 
java . text . SimpleDateFormat isoDateTimeFormat = new java . text . SimpleDateFormat ( "yyyy-MM-dd'T'HH:mm:ss" ) ; 
isoDateTimeFormat . setTimeZone ( java . util . TimeZone . getTimeZone ( "GMT" ) ) ; 
raf . seek ( 0 ) ; 
String line = raf . readLine ( ) ; 
if ( line == null ) break ; 
if ( line . startsWith ( MAGIC ) ) continue ; 
StringTokenizer stoker = new StringTokenizer ( line , ",\r\n" ) ; 
while ( stoker . hasMoreTokens ( ) ) { 
Date d = isoDateTimeFormat . parse ( stoker . nextToken ( ) ) ; 
double lat = Double . parseDouble ( stoker . nextToken ( ) ) ; 
double lon = Double . parseDouble ( stoker . nextToken ( ) ) ; 
double amp = Double . parseDouble ( stoker . nextToken ( ) ) ; 
String tok = stoker . nextToken ( ) ; 
int nstrikes = Integer . parseInt ( tok ) ; 
Strike s = new Strike ( d , lat , lon , amp , nstrikes ) ; 
records . add ( s ) ; 
if ( count < 10 ) 
int n = records . size ( ) ; 
int [ ] shape = new int [ ] { n } ; 
dateArray = ( ArrayInt . D1 ) Array . factory ( DataType . INT , shape ) ; 
latArray = ( ArrayDouble . D1 ) Array . factory ( DataType . DOUBLE , shape ) ; 
lonArray = ( ArrayDouble . D1 ) Array . factory ( DataType . DOUBLE , shape ) ; 
ampArray = ( ArrayDouble . D1 ) Array . factory ( DataType . DOUBLE , shape ) ; 
nstrokesArray = ( ArrayInt . D1 ) Array . factory ( DataType . INT , shape ) ; 
for ( int i = 0 ; i < records . size ( ) ; i ++ ) { 
Strike strike = ( Strike ) records . get ( i ) ; 
dateArray . set ( i , strike . d ) ; 
latArray . set ( i , strike . lat ) ; 
lonArray . set ( i , strike . lon ) ; 
ampArray . set ( i , strike . amp ) ; 
nstrokesArray . set ( i , strike . n ) ; 
return n ; 
} private void synchUI ( boolean slidersOK ) { 
eventOK = false ; 
if ( slidersOK ) minSlider . setValue ( scale . world2slider ( dateRange . getStart ( ) ) ) ; 
minField . setValue ( dateRange . getStart ( ) ) ; 
if ( maxField != null ) { 
if ( slidersOK ) maxSlider . setValue ( scale . world2slider ( dateRange . getEnd ( ) ) ) ; 
maxField . setValue ( dateRange . getEnd ( ) ) ; 
if ( durationField != null ) 
durationField . setValue ( dateRange . getDuration ( ) ) ; 
eventOK = true ; 
} public int [ ] computeUnlimitedChunking ( List < Dimension > dims , int elemSize ) { 
int maxElements = defaultChunkSize / elemSize ; 
int [ ] result = fillRightmost ( convertUnlimitedShape ( dims ) , maxElements ) ; 
long resultSize = new Section ( result ) . computeSize ( ) ; 
if ( resultSize < minChunksize ) { 
maxElements = minChunksize / elemSize ; 
result = incrUnlimitedShape ( dims , result , maxElements ) ; 
} public void register ( Path dir ) throws IOException { 
if ( ! enable ) return ; 
WatchKey key = dir . register ( watcher , ENTRY_CREATE , ENTRY_DELETE , ENTRY_MODIFY ) ; 
if ( trace ) { 
Path prev = keys . get ( key ) ; 
if ( prev == null ) { 
if ( ! dir . equals ( prev ) ) { 
keys . put ( key , dir ) ; 
} public void processEvents ( ) { 
WatchKey key ; 
key = watcher . take ( ) ; 
} catch ( InterruptedException x ) { 
Path dir = keys . get ( key ) ; 
if ( dir == null ) { 
for ( WatchEvent < ? > event : key . pollEvents ( ) ) { 
WatchEvent . Kind kind = event . kind ( ) ; 
if ( kind == OVERFLOW ) { 
WatchEvent < Path > ev = cast ( event ) ; 
Path name = ev . context ( ) ; 
Path child = dir . resolve ( name ) ; 
if ( recursive && ( kind == ENTRY_CREATE ) ) { 
if ( Files . isDirectory ( child , NOFOLLOW_LINKS ) ) { 
registerAll ( child ) ; 
} catch ( IOException x ) { 
boolean valid = key . reset ( ) ; 
if ( ! valid ) { 
keys . remove ( key ) ; 
if ( keys . isEmpty ( ) ) { 
} public TimeHelper setReferenceDate ( CalendarDate refDate ) { 
CalendarDateUnit cdUnit = CalendarDateUnit . of ( dateUnit . getCalendar ( ) , dateUnit . getCalendarField ( ) , refDate ) ; 
return new TimeHelper ( cdUnit ) ; 
} static public boolean registerFactory ( FeatureType datatype , String className ) { 
Class c = Class . forName ( className ) ; 
registerFactory ( datatype , c ) ; 
} static public void registerFactory ( String className ) throws ClassNotFoundException { 
registerFactory ( c ) ; 
} static public void registerFactory ( Class c ) { 
if ( ! ( FeatureDatasetFactory . class . isAssignableFrom ( c ) ) ) 
Object instance ; 
instance = c . newInstance ( ) ; 
Method m = c . getMethod ( "getFeatureTypes" , new Class [ 0 ] ) ; 
FeatureType [ ] result = ( FeatureType [ ] ) m . invoke ( instance , new Object [ 0 ] ) ; 
for ( FeatureType ft : result ) { 
if ( userMode ) 
factoryList . add ( 0 , new Factory ( ft , c , ( FeatureDatasetFactory ) instance ) ) ; 
factoryList . add ( new Factory ( ft , c , ( FeatureDatasetFactory ) instance ) ) ; 
} static public FeatureDataset open ( FeatureType wantFeatureType , String location , ucar . nc2 . util . CancelTask task , Formatter errlog ) throws IOException { 
if ( location . startsWith ( DataFactory . SCHEME ) ) { 
DataFactory . Result result = new DataFactory ( ) . openFeatureDataset ( wantFeatureType , location , task ) ; 
errlog . format ( "%s" , result . errLog ) ; 
if ( ! featureTypeOk ( wantFeatureType , result . featureType ) ) { 
result . close ( ) ; 
return result . featureDataset ; 
} else if ( location . startsWith ( CdmrFeatureDataset . SCHEME ) ) { 
Optional < FeatureDataset > opt = CdmrFeatureDataset . factory ( wantFeatureType , location ) ; 
if ( opt . isPresent ( ) ) return opt . get ( ) ; 
errlog . format ( "%s" , opt . getErrorMessage ( ) ) ; 
} else if ( location . startsWith ( ucar . nc2 . ft . point . collection . CompositeDatasetFactory . SCHEME ) ) { 
String spec = location . substring ( CompositeDatasetFactory . SCHEME . length ( ) ) ; 
MFileCollectionManager dcm = MFileCollectionManager . open ( spec , spec , null , errlog ) ; 
return CompositeDatasetFactory . factory ( location , wantFeatureType , dcm , errlog ) ; 
if ( durl . serviceType == null ) { 
Optional < FeatureDatasetCoverage > opt = CoverageDatasetFactory . openGrib ( location ) ; 
if ( opt . isPresent ( ) ) { 
return opt . get ( ) ; 
} else if ( ! opt . getErrorMessage ( ) . startsWith ( CoverageDatasetFactory . NOT_GRIB_FILE ) && 
! opt . getErrorMessage ( ) . startsWith ( CoverageDatasetFactory . NO_GRIB_CLASS ) ) { 
errlog . format ( "%s%n" , opt . getErrorMessage ( ) ) ; 
NetcdfDataset ncd = NetcdfDataset . acquireDataset ( durl , true , task ) ; 
FeatureDataset fd = wrap ( wantFeatureType , ncd , task , errlog ) ; 
if ( fd == null ) 
ncd . close ( ) ; 
return fd ; 
} static public FeatureDataset wrap ( FeatureType wantFeatureType , NetcdfDataset ncd , ucar . nc2 . util . CancelTask task , Formatter errlog ) throws IOException { 
if ( ( wantFeatureType == null ) || ( wantFeatureType == FeatureType . ANY ) ) { 
return wrapUnknown ( ncd , task , errlog ) ; 
Object analysis = null ; 
FeatureDatasetFactory useFactory = null ; 
for ( Factory fac : factoryList ) { 
if ( ! featureTypeOk ( wantFeatureType , fac . featureType ) ) continue ; 
analysis = fac . factory . isMine ( wantFeatureType , ncd , errlog ) ; 
if ( analysis != null ) { 
useFactory = fac . factory ; 
if ( null == useFactory ) { 
return useFactory . open ( wantFeatureType , ncd , analysis , task , errlog ) ; 
} static public boolean featureTypeOk ( FeatureType want , FeatureType facType ) { 
if ( want == null ) return true ; 
if ( want == facType ) return true ; 
if ( want == FeatureType . ANY_POINT ) { 
return facType . isPointFeatureType ( ) ; 
if ( facType == FeatureType . ANY_POINT ) { 
return want . isPointFeatureType ( ) ; 
if ( want == FeatureType . COVERAGE ) { 
return facType . isCoverageFeatureType ( ) ; 
if ( want == FeatureType . GRID ) { 
if ( want == FeatureType . SIMPLE_GEOMETRY ) { 
if ( want == FeatureType . UGRID ) { 
return facType . isUnstructuredGridFeatureType ( ) ; 
} static public FeatureType findFeatureType ( NetcdfFile ncd ) { 
String cdm_datatype = ncd . findAttValueIgnoreCase ( null , CF . FEATURE_TYPE , null ) ; 
if ( cdm_datatype == null ) 
cdm_datatype = ncd . findAttValueIgnoreCase ( null , "cdm_data_type" , null ) ; 
cdm_datatype = ncd . findAttValueIgnoreCase ( null , "cdm_datatype" , null ) ; 
cdm_datatype = ncd . findAttValueIgnoreCase ( null , "thredds_data_type" , null ) ; 
if ( cdm_datatype != null ) { 
for ( FeatureType ft : FeatureType . values ( ) ) 
if ( cdm_datatype . equalsIgnoreCase ( ft . name ( ) ) ) { 
return ft ; 
CF . FeatureType cff = CF . FeatureType . getFeatureTypeFromGlobalAttribute ( ncd ) ; 
if ( cff != null ) return CF . FeatureType . convert ( cff ) ; 
protected int read_ ( long pos , byte [ ] buff , int offset , int len ) throws IOException { 
long end = pos + len - 1 ; 
if ( end >= total_length ) 
end = total_length - 1 ; 
try ( HTTPMethod method = HTTPFactory . Get ( session , url ) ) { 
method . setFollowRedirects ( true ) ; 
method . setRange ( pos , end ) ; 
doConnect ( method ) ; 
int code = method . getStatusCode ( ) ; 
if ( code != 206 ) 
String s = method . getResponseHeader ( "Content-Length" ) . getValue ( ) ; 
if ( s == null ) 
int readLen = Integer . parseInt ( s ) ; 
readLen = Math . min ( len , readLen ) ; 
InputStream is = method . getResponseAsStream ( ) ; 
readLen = copy ( is , buff , offset , readLen ) ; 
return readLen ; 
} public int writeCatalog ( HttpServletRequest req , HttpServletResponse res , Catalog cat , boolean isLocalCatalog ) throws IOException { 
String catHtmlAsString = convertCatalogToHtml ( cat , isLocalCatalog ) ; 
res . setContentType ( ContentType . html . getContentHeader ( ) ) ; 
int len = ServletUtil . setResponseContentLength ( res , catHtmlAsString ) ; 
if ( ! req . getMethod ( ) . equals ( "HEAD" ) ) { 
PrintWriter writer = res . getWriter ( ) ; 
writer . write ( catHtmlAsString ) ; 
writer . flush ( ) ; 
return len ; 
} String convertCatalogToHtml ( Catalog cat , boolean isLocalCatalog ) { 
StringBuilder sb = new StringBuilder ( 10000 ) ; 
String uri = cat . getUriString ( ) ; 
if ( uri == null ) uri = cat . getName ( ) ; 
if ( uri == null ) uri = "unknown" ; 
String catname = Escape . html ( uri ) ; 
sb . append ( getHtmlDoctypeAndOpenTag ( ) ) ; 
sb . append ( "<head>\r\n" ) ; 
sb . append ( "<title>" ) ; 
sb . append ( "</title>\r\n" ) ; 
sb . append ( getTdsCatalogCssLink ( ) ) . append ( "\n" ) ; 
sb . append ( this . getGoogleTrackingContent ( ) ) ; 
sb . append ( "</head>\r\n" ) ; 
sb . append ( "<body>" ) ; 
sb . append ( "<h1>" ) ; 
String logoUrl = htmlConfig . prepareUrlStringForHtml ( htmlConfig . getInstallLogoUrl ( ) ) ; 
if ( logoUrl != null ) { 
String logoAlt = htmlConfig . getInstallLogoAlt ( ) ; 
sb . append ( "</h1>" ) ; 
sb . append ( "<tr>\r\n" ) ; 
sb . append ( "Dataset" ) ; 
sb . append ( "</font></th>\r\n" ) ; 
sb . append ( "Size" ) ; 
sb . append ( "</tr>" ) ; 
doDatasets ( cat , cat . getDatasetsLocal ( ) , sb , false , 0 , isLocalCatalog ) ; 
sb . append ( "</table>\r\n" ) ; 
appendSimpleFooter ( sb ) ; 
sb . append ( "</body>\r\n" ) ; 
sb . append ( "</html>\r\n" ) ; 
return ( sb . toString ( ) ) ; 
} public String getUserCSS ( ) { 
return new StringBuilder ( ) 
. append ( this . htmlConfig . prepareUrlStringForHtml ( this . htmlConfig . getPageCssUrl ( ) ) ) 
} public String getUserHead ( ) { 
. append ( "'\n" ) 
. append ( "</td></tr></table>\n" ) 
. toString ( ) ; 
} public Catalog getCatalog ( String path , URI baseURI ) throws IOException { 
if ( path == null ) 
String workPath = path ; 
if ( workPath . startsWith ( "/" ) ) 
workPath = workPath . substring ( 1 ) ; 
Object dyno = makeDynamicCatalog ( workPath , baseURI ) ; 
if ( dyno != null ) { 
CatalogBuilder catBuilder ; 
if ( dyno instanceof CatalogBuilder ) { 
catBuilder = ( CatalogBuilder ) dyno ; 
ConfigCatalog configCatalog = ( ConfigCatalog ) dyno ; 
catBuilder = configCatalog . makeCatalogBuilder ( ) ; 
addGlobalServices ( catBuilder ) ; 
return catBuilder . makeCatalog ( ) ; 
ConfigCatalog configCatalog = ccc . get ( workPath ) ; 
if ( configCatalog == null ) return null ; 
CatalogBuilder catBuilder = configCatalog . makeCatalogBuilder ( ) ; 
} private Object makeDynamicCatalog ( String path , URI baseURI ) throws IOException { 
boolean isLatest = path . endsWith ( "/latest.xml" ) ; 
int pos = path . lastIndexOf ( "/" ) ; 
String workPath = ( pos >= 0 ) ? path . substring ( 0 , pos ) : path ; 
String filename = ( pos > 0 ) ? path . substring ( pos + 1 ) : path ; 
DataRootManager . DataRootMatch match = dataRootManager . findDataRootMatch ( workPath ) ; 
if ( match == null ) 
if ( match . dataRoot . getFeatureCollection ( ) != null ) { 
InvDatasetFeatureCollection fc = featureCollectionCache . get ( match . dataRoot . getFeatureCollection ( ) ) ; 
if ( isLatest ) 
return fc . makeLatest ( match . remaining , path , baseURI ) ; 
return fc . makeCatalog ( match . remaining , path , baseURI ) ; 
DatasetScan dscan = match . dataRoot . getDatasetScan ( ) ; 
if ( dscan != null ) { 
CatalogBuilder cat ; 
cat = dscan . makeCatalogForLatest ( workPath , baseURI ) ; 
cat = dscan . makeCatalogForDirectory ( workPath , baseURI ) ; 
if ( null == cat ) 
return cat ; 
CatalogScan catScan = match . dataRoot . getCatalogScan ( ) ; 
if ( catScan != null ) { 
if ( ! filename . equalsIgnoreCase ( CatalogScan . CATSCAN ) ) { 
return catScan . getCatalog ( tdsContext . getThreddsDirectory ( ) , match . remaining , filename , ccc ) ; 
CatalogBuilder cat = catScan . makeCatalogFromDirectory ( tdsContext . getThreddsDirectory ( ) , match . remaining , baseURI ) ; 
} private void addGlobalServices ( CatalogBuilder cat ) { 
Set < String > allServiceNames = new HashSet < > ( ) ; 
findServices ( cat . getDatasets ( ) , allServiceNames ) ; 
if ( ! allServiceNames . isEmpty ( ) ) { 
List < Service > servicesMissing = new ArrayList < > ( ) ; 
for ( String name : allServiceNames ) { 
if ( cat . hasServiceInDataset ( name ) ) continue ; 
Service s = globalServices . findGlobalService ( name ) ; 
if ( s != null ) servicesMissing . add ( s ) ; 
servicesMissing . forEach ( cat :: addService ) ; 
for ( DatasetBuilder node : cat . getDatasets ( ) ) { 
String sname = ( String ) node . getFldOrInherited ( Dataset . ServiceName ) ; 
String urlPath = ( String ) node . get ( Dataset . UrlPath ) ; 
String ftypeS = ( String ) node . getFldOrInherited ( Dataset . FeatureType ) ; 
if ( sname == null && urlPath != null && ftypeS != null ) { 
Service s = globalServices . getStandardServices ( ftypeS ) ; 
node . put ( Dataset . ServiceName , s . getName ( ) ) ; 
cat . addService ( s ) ; 
} static public void init ( CredentialsProvider provider , String userAgent ) 
if ( provider != null ) 
HTTPSession . setGlobalCredentialsProvider ( provider ) ; 
} catch ( HTTPException e ) { 
throw new IllegalArgumentException ( e ) ; 
if ( userAgent != null ) 
HTTPSession . setGlobalUserAgent ( userAgent + "/NetcdfJava/HttpClient" ) ; 
HTTPSession . setGlobalUserAgent ( "NetcdfJava/HttpClient" ) ; 
} @ Urlencoded 
public static String getContentAsString ( HTTPSession session , String urlencoded ) throws IOException 
HTTPSession useSession = session ; 
if ( useSession == null ) 
useSession = HTTPFactory . newSession ( urlencoded ) ; 
try ( HTTPMethod m = HTTPFactory . Get ( useSession , urlencoded ) ) { 
m . execute ( ) ; 
return m . getResponseAsString ( ) ; 
if ( ( session == null ) && ( useSession != null ) ) 
useSession . close ( ) ; 
} public static int putContent ( String urlencoded , String content ) throws IOException 
try ( HTTPMethod m = HTTPFactory . Put ( urlencoded ) ) { 
m . setRequestContent ( new StringEntity ( content , "application/text" , "UTF-8" ) ) ; 
int resultCode = m . getStatusCode ( ) ; 
if ( resultCode == 302 ) { 
String redirectLocation ; 
Header locationHeader = m . getResponseHeader ( "location" ) ; 
if ( locationHeader != null ) { 
redirectLocation = locationHeader . getValue ( ) ; 
resultCode = putContent ( redirectLocation , content ) ; 
return resultCode ; 
} static public String getUrlContentsAsString ( String urlencoded , int maxKbytes ) throws IOException 
return getUrlContentsAsString ( null , urlencoded , maxKbytes ) ; 
} public static boolean op ( int oprtr , BaseType lop , BaseType rop ) throws InvalidOperatorException , 
RegExpException , 
SBHException { 
if ( lop instanceof DByte ) 
return ( op ( oprtr , ( DByte ) lop , rop ) ) ; 
else if ( lop instanceof DFloat32 ) 
return ( op ( oprtr , ( DFloat32 ) lop , rop ) ) ; 
else if ( lop instanceof DFloat64 ) 
return ( op ( oprtr , ( DFloat64 ) lop , rop ) ) ; 
else if ( lop instanceof DInt16 ) 
return ( op ( oprtr , ( DInt16 ) lop , rop ) ) ; 
else if ( lop instanceof DInt32 ) 
return ( op ( oprtr , ( DInt32 ) lop , rop ) ) ; 
else if ( lop instanceof DString ) 
return ( op ( oprtr , ( DString ) lop , rop ) ) ; 
else if ( lop instanceof DUInt16 ) 
return ( op ( oprtr , ( DUInt16 ) lop , rop ) ) ; 
else if ( lop instanceof DUInt32 ) 
return ( op ( oprtr , ( DUInt32 ) lop , rop ) ) ; 
else if ( lop instanceof DURL ) 
return ( op ( oprtr , ( DURL ) lop , rop ) ) ; 
} private static String opErrorMsg ( int oprtr , String lop , String rop ) { 
switch ( oprtr ) { 
case LESS : 
case LESS_EQL : 
case GREATER : 
case GREATER_EQL : 
case EQUAL : 
case NOT_EQUAL : 
case REGEXP : 
} private static boolean op ( int oprtr , DFloat32 lop , DByte rop ) throws InvalidOperatorException { 
return ( lop . getValue ( ) < rop . getValue ( ) ) ; 
return ( lop . getValue ( ) <= rop . getValue ( ) ) ; 
return ( lop . getValue ( ) > rop . getValue ( ) ) ; 
return ( lop . getValue ( ) >= rop . getValue ( ) ) ; 
return ( lop . getValue ( ) == rop . getValue ( ) ) ; 
return ( lop . getValue ( ) != rop . getValue ( ) ) ; 
throw new InvalidOperatorException ( opErrorMsg ( oprtr , lop . getTypeName ( ) , rop . getTypeName ( ) ) ) ; 
} private static boolean op ( int oprtr , DUInt16 lop , DByte rop ) throws InvalidOperatorException { 
int lval = ( ( int ) lop . getValue ( ) ) & 0xFFFF ; 
return ( lval < rop . getValue ( ) ) ; 
return ( lval <= rop . getValue ( ) ) ; 
return ( lval > rop . getValue ( ) ) ; 
return ( lval >= rop . getValue ( ) ) ; 
return ( lval == rop . getValue ( ) ) ; 
return ( lval != rop . getValue ( ) ) ; 
protected void 
doFavicon ( String icopath , DapContext cxt ) 
throws IOException 
DapRequest drq = ( DapRequest ) cxt . get ( DapRequest . class ) ; 
String favfile = getResourcePath ( drq , icopath ) ; 
if ( favfile != null ) { 
try ( FileInputStream fav = new FileInputStream ( favfile ) ; ) { 
byte [ ] content = DapUtil . readbinaryfile ( fav ) ; 
OutputStream out = drq . getOutputStream ( ) ; 
out . write ( content ) ; 
} protected FrontPage 
getFrontPage ( DapRequest drq , DapContext cxt ) 
if ( this . defaultroots == null ) { 
String pageroot ; 
pageroot = getResourcePath ( drq , "" ) ; 
if ( pageroot == null ) 
this . defaultroots = new ArrayList < > ( ) ; 
this . defaultroots . add ( 
new Root ( "testfiles" , pageroot ) ) ; 
return new FrontPage ( this . defaultroots , drq ) ; 
} private String makeCollectionShortName ( String collectionName ) { 
String topCollectionName = config . collectionName ; 
if ( collectionName . equals ( topCollectionName ) ) return topCollectionName ; 
if ( collectionName . startsWith ( topCollectionName ) ) { 
return name + collectionName . substring ( topCollectionName . length ( ) ) ; 
return collectionName ; 
} protected void addFileDatasets ( DatasetBuilder parent , String parentPath , GribCollectionImmutable fromGc ) throws IOException { 
DatasetBuilder filesParent = new DatasetBuilder ( parent ) ; 
filesParent . addServiceToCatalog ( downloadService ) ; 
ThreddsMetadata tmi = filesParent . getInheritableMetadata ( ) ; 
tmi . set ( Dataset . ServiceName , downloadService . getName ( ) ) ; 
parent . addDataset ( filesParent ) ; 
List < MFile > mfiles = new ArrayList < > ( fromGc . getFiles ( ) ) ; 
Collections . sort ( mfiles ) ; 
if ( ! this . config . getSortFilesAscending ( ) ) { 
Collections . reverse ( mfiles ) ; 
for ( MFile mfile : mfiles ) { 
DatasetBuilder ds = new DatasetBuilder ( parent ) ; 
ds . setName ( mfile . getName ( ) ) ; 
String lpath = parentPath + "/" + FILES + "/" + mfile . getName ( ) ; 
ds . put ( Dataset . UrlPath , lpath ) ; 
ds . put ( Dataset . Id , lpath ) ; 
ds . put ( Dataset . DataSize , mfile . getLength ( ) ) ; 
if ( mfile . getLastModified ( ) > 0 ) { 
CalendarDate cdate = CalendarDate . of ( mfile . getLastModified ( ) ) ; 
ds . put ( Dataset . Dates , new DateType ( cdate ) . setType ( "modified" ) ) ; 
filesParent . addDataset ( ds ) ; 
public CatalogBuilder makeCatalog ( String match , String reqPath , URI catURI ) throws IOException { 
StateGrib localState = ( StateGrib ) checkState ( ) ; 
if ( localState == null ) return null ; 
if ( localState . gribCollection == null ) return null ; 
if ( ( match == null ) || ( match . length ( ) == 0 ) ) { 
return makeCatalogTop ( catURI , localState ) ; 
if ( localState . gribCollection instanceof PartitionCollectionImmutable ) { 
String [ ] paths = match . split ( "/" ) ; 
PartitionCollectionImmutable pc = ( PartitionCollectionImmutable ) localState . gribCollection ; 
return makeCatalogFromPartition ( pc , paths , 0 , catURI ) ; 
protected DatasetBuilder makeDatasetTop ( URI catURI , State state ) throws IOException { 
StateGrib localState = ( StateGrib ) state ; 
return makeDatasetFromCollection ( catURI , true , null , null , localState . gribCollection ) ; 
} private ThreddsMetadata . GeospatialCoverage extractGeospatial ( GribCollectionImmutable . GroupGC group ) { 
GdsHorizCoordSys gdsCoordSys = group . getGdsHorizCoordSys ( ) ; 
LatLonRect llbb = GridCoordSys . getLatLonBoundingBox ( gdsCoordSys . proj , gdsCoordSys . getStartX ( ) , gdsCoordSys . getStartY ( ) , 
gdsCoordSys . getEndX ( ) , gdsCoordSys . getEndY ( ) ) ; 
double dx = 0.0 , dy = 0.0 ; 
if ( gdsCoordSys . isLatLon ( ) ) { 
dx = Math . abs ( gdsCoordSys . dx ) ; 
dy = Math . abs ( gdsCoordSys . dy ) ; 
return new ThreddsMetadata . GeospatialCoverage ( llbb , null , dx , dy ) ; 
} private Object findDataset ( String matchPath , GribCollectionImmutable topCollection , DatasetCreator visit ) throws IOException { 
String [ ] paths = matchPath . split ( "/" ) ; 
List < String > pathList = ( paths . length < 1 ) ? new ArrayList < > ( ) : Arrays . asList ( paths ) ; 
DatasetAndGroup dg = findDatasetAndGroup ( pathList , topCollection ) ; 
if ( dg != null ) 
return visit . obtain ( topCollection , dg . ds , dg . group ) ; 
if ( ! ( topCollection instanceof PartitionCollectionImmutable ) ) return null ; 
PartitionCollectionImmutable pc = ( PartitionCollectionImmutable ) topCollection ; 
return findDatasetPartition ( visit , pc , pathList ) ; 
} private DatasetAndGroup findDatasetAndGroup ( List < String > paths , GribCollectionImmutable gc ) { 
if ( paths . size ( ) < 1 || paths . get ( 0 ) . length ( ) == 0 ) { 
GribCollectionImmutable . Dataset ds = gc . getDataset ( 0 ) ; 
GribCollectionImmutable . GroupGC dg = ds . getGroup ( 0 ) ; 
return new DatasetAndGroup ( ds , dg ) ; 
GribCollectionImmutable . Dataset ds = getSingleDatasetOrByTypeName ( gc , paths . get ( 0 ) ) ; 
if ( ds == null ) return null ; 
boolean isSingleGroup = ds . getGroupsSize ( ) == 1 ; 
if ( isSingleGroup ) { 
GribCollectionImmutable . GroupGC g = ds . getGroup ( 0 ) ; 
return new DatasetAndGroup ( ds , g ) ; 
String groupName = ( paths . size ( ) == 1 ) ? paths . get ( 0 ) : paths . get ( 1 ) ; 
GribCollectionImmutable . GroupGC g = ds . findGroupById ( groupName ) ; 
if ( g != null ) 
} public GribCollectionImmutable . Dataset getSingleDatasetOrByTypeName ( GribCollectionImmutable gc , String typeName ) { 
if ( gc . getDatasets ( ) . size ( ) == 1 ) return gc . getDataset ( 0 ) ; 
for ( GribCollectionImmutable . Dataset ds : gc . getDatasets ( ) ) 
if ( ds . getType ( ) . toString ( ) . equalsIgnoreCase ( typeName ) ) return ds ; 
} public boolean nearlyEquals ( VertCoordValue other ) { 
return Misc . nearlyEquals ( value1 , other . value1 ) && Misc . nearlyEquals ( value2 , other . value2 ) ; 
} public static UnitID newUnitID ( final String name , final String plural , 
final String symbol ) { 
UnitID id ; 
id = name == null 
? new UnitSymbol ( symbol ) 
: UnitName . newUnitName ( name , plural , symbol ) ; 
catch ( final NameException e ) { 
id = null ; 
} public static GradsAttribute parseAttribute ( String attrSpec ) { 
String [ ] toks = attrSpec . split ( "\\s+" ) ; 
StringBuffer buf = new StringBuffer ( ) ; 
for ( int i = 4 ; i < toks . length ; i ++ ) { 
buf . append ( toks [ i ] ) ; 
return new GradsAttribute ( toks [ 1 ] , toks [ 2 ] , toks [ 3 ] , 
buf . toString ( ) . trim ( ) ) ; 
} int readTop ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { 
int pos = 0 ; 
raf . seek ( pos ) ; 
int readLen = 35 ; 
byte [ ] b = new byte [ readLen ] ; 
int rc = raf . read ( b ) ; 
if ( rc != readLen ) { 
if ( ( convertunsignedByte2Short ( b [ 0 ] ) != 0x00 ) || ( convertunsignedByte2Short ( b [ 1 ] ) != 0xF0 ) 
|| ( convertunsignedByte2Short ( b [ 2 ] ) != 0x09 ) ) { 
String pidd = new String ( b , 15 , 5 , CDM . utf8Charset ) ; 
if ( pidd . contains ( "NOWRA" ) || pidd . contains ( "USRAD" ) || pidd . contains ( "NEX" ) ) { 
} void read ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile ) throws Exception { 
this . raf = raf ; 
int rc ; 
int hoffset ; 
int readLen = 250 ; 
this . ncfile = ncfile ; 
rc = raf . read ( b ) ; 
int hsize = b [ 3 ] ; 
String product = new String ( b , 15 , 8 , CDM . utf8Charset ) ; 
int t1 = 0 ; 
int ii = 0 ; 
for ( int i = 0 ; i < readLen ; i ++ ) { 
if ( convertunsignedByte2Short ( b [ i + hsize ] ) == 0xF0 && 
convertunsignedByte2Short ( b [ i + 1 + hsize ] ) == 0x0A ) { 
t1 = i + hsize ; 
ii = i ; 
if ( t1 == 0 ) 
String lstr = trim ( new String ( b , t1 + 2 , 4 , CDM . utf8Charset ) ) ; 
numY = Integer . parseInt ( lstr ) ; 
String estr = trim ( new String ( b , t1 + 6 , 5 , CDM . utf8Charset ) ) ; 
numX = Integer . parseInt ( estr ) ; 
t1 = 0 ; 
for ( int i = ii ; i < readLen ; i ++ ) { 
convertunsignedByte2Short ( b [ i + 1 + hsize ] ) == 0x03 ) { 
int off = 0 ; 
if ( product . contains ( "USRADHF" ) ) { 
off = 3 ; 
String ts = new String ( b , t1 + 22 + off , 2 , CDM . utf8Charset ) ; 
int hr = Integer . parseInt ( ts ) ; 
ts = new String ( b , t1 + 25 + off , 2 , CDM . utf8Charset ) ; 
int min = Integer . parseInt ( ts ) ; 
ts = new String ( b , t1 + 28 + off , 2 , CDM . utf8Charset ) ; 
int dd = Integer . parseInt ( ts ) ; 
ts = new String ( b , t1 + 31 + off , 3 , CDM . utf8Charset ) ; 
String mon = ts ; 
int month = getMonth ( mon ) ; 
ts = new String ( b , t1 + 35 + off , 2 , CDM . utf8Charset ) ; 
int year = Integer . parseInt ( ts ) ; 
SimpleDateFormat sdf = new SimpleDateFormat ( ) ; 
sdf . setTimeZone ( TimeZone . getTimeZone ( "GMT" ) ) ; 
convertunsignedByte2Short ( b [ i + 1 + hsize ] ) == 0x0b ) { 
if ( product . contains ( "NOWRAD" ) ) { 
String ot = new String ( b , t1 + 2 , 68 , CDM . utf8Charset ) ; 
String [ ] toks = StringUtil2 . splitString ( ot ) ; 
double nav1 = Math . toDegrees ( Double . parseDouble ( toks [ 1 ] ) ) ; 
double nav2 = Math . toDegrees ( Double . parseDouble ( toks [ 2 ] ) ) ; 
double nav3 = Math . toDegrees ( Double . parseDouble ( toks [ 3 ] ) ) ; 
double nav4 = Math . toDegrees ( Double . parseDouble ( toks [ 4 ] ) ) ; 
double nav5 = Math . toDegrees ( Double . parseDouble ( toks [ 5 ] ) ) ; 
float rlat1 ; 
float rlon1 ; 
float rlat2 ; 
float rlon2 ; 
rlat1 = ( float ) ( nav2 - ( numY - 1 ) * nav4 ) ; 
rlon1 = ( float ) ( nav1 + nav3 ) ; 
rlat2 = ( float ) nav2 ; 
rlon2 = ( float ) ( nav1 - nav3 ) ; 
hoffset = t1 + 71 ; 
if ( ( convertunsignedByte2Short ( b [ 172 + hsize ] ) != 0xF0 ) 
|| ( convertunsignedByte2Short ( b [ 173 + hsize ] ) != 0x0c ) ) { 
setProductInfo ( product , date ) ; 
nowrad ( hoffset , rlat1 , rlon1 , rlat2 , rlon2 , ( float ) nav4 , ( float ) nav5 , date ) ; 
} else if ( product . contains ( "USRADHF" ) ) { 
String ot = new String ( b , t1 + 2 , 107 , CDM . utf8Charset ) ; 
double nav6 = Math . toDegrees ( Double . parseDouble ( toks [ 6 ] ) ) ; 
hoffset = t1 + 110 ; 
if ( ( convertunsignedByte2Short ( b [ t1 + 110 ] ) != 0xF0 ) || ( convertunsignedByte2Short ( b [ t1 + 111 ] ) != 0x0c ) ) { 
nowradL ( hoffset , ( float ) nav1 , ( float ) nav2 , ( float ) nav3 , ( float ) nav4 , ( float ) nav5 , ( float ) nav6 , date ) ; 
ncfile . finish ( ) ; 
} ProjectionImpl nowrad ( int hoff , float rlat1 , float rlon1 , float rlat2 , float rlon2 , float dlat , float dlon , Date dd ) { 
List < Dimension > dims = new ArrayList < > ( ) ; 
Dimension dimT = new Dimension ( "time" , 1 , true , false , false ) ; 
ncfile . addDimension ( null , dimT ) ; 
String timeCoordName = "time" ; 
Variable taxis = new Variable ( ncfile , null , null , timeCoordName ) ; 
taxis . setDataType ( DataType . DOUBLE ) ; 
taxis . setDimensions ( "time" ) ; 
taxis . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Time . toString ( ) ) ) ; 
double [ ] tdata = new double [ 1 ] ; 
tdata [ 0 ] = dd . getTime ( ) ; 
Array dataT = Array . factory ( DataType . DOUBLE , new int [ ] { 1 } , tdata ) ; 
taxis . setCachedData ( dataT , false ) ; 
DateFormatter formatter = new DateFormatter ( ) ; 
ncfile . addVariable ( null , taxis ) ; 
dims . add ( dimT ) ; 
Dimension jDim = new Dimension ( "lat" , numY , true , false , false ) ; 
Dimension iDim = new Dimension ( "lon" , numX , true , false , false ) ; 
dims . add ( jDim ) ; 
dims . add ( iDim ) ; 
ncfile . addDimension ( null , iDim ) ; 
ncfile . addDimension ( null , jDim ) ; 
ncfile . addAttribute ( null , new Attribute ( "cdm_data_type" , FeatureType . GRID . toString ( ) ) ) ; 
Variable v = new Variable ( ncfile , null , null , cname ) ; 
v . setDataType ( DataType . BYTE ) ; 
v . setDimensions ( dims ) ; 
ncfile . addVariable ( null , v ) ; 
v . addAttribute ( new Attribute ( CDM . LONG_NAME , ctitle ) ) ; 
v . addAttribute ( new Attribute ( CDM . SCALE_FACTOR , 5.0f ) ) ; 
v . addAttribute ( new Attribute ( CDM . MISSING_VALUE , 0 ) ) ; 
v . addAttribute ( new Attribute ( CDM . UNITS , cunit ) ) ; 
v . setSPobject ( new Vinfo ( numX , numY , hoff ) ) ; 
v . addAttribute ( new Attribute ( _Coordinate . Axes , coordinates ) ) ; 
Variable xaxis = new Variable ( ncfile , null , null , "lon" ) ; 
xaxis . setDataType ( DataType . DOUBLE ) ; 
xaxis . setDimensions ( "lon" ) ; 
xaxis . addAttribute ( new Attribute ( CDM . LONG_NAME , "longitude" ) ) ; 
xaxis . addAttribute ( new Attribute ( CDM . UNITS , "degree" ) ) ; 
xaxis . addAttribute ( new Attribute ( _Coordinate . AxisType , "Lon" ) ) ; 
double [ ] data1 = new double [ numX ] ; 
for ( int i = 0 ; i < numX ; i ++ ) { 
data1 [ i ] = ( double ) ( rlon1 + i * dlon ) ; 
Array dataA = Array . factory ( DataType . DOUBLE , new int [ ] { numX } , data1 ) ; 
xaxis . setCachedData ( dataA , false ) ; 
ncfile . addVariable ( null , xaxis ) ; 
Variable yaxis = new Variable ( ncfile , null , null , "lat" ) ; 
yaxis . setDataType ( DataType . DOUBLE ) ; 
yaxis . setDimensions ( "lat" ) ; 
yaxis . addAttribute ( new Attribute ( CDM . LONG_NAME , "latitude" ) ) ; 
yaxis . addAttribute ( new Attribute ( CDM . UNITS , "degree" ) ) ; 
yaxis . addAttribute ( new Attribute ( _Coordinate . AxisType , "Lat" ) ) ; 
data1 = new double [ numY ] ; 
for ( int i = 0 ; i < numY ; i ++ ) { 
data1 [ i ] = rlat1 + i * dlat ; 
dataA = Array . factory ( DataType . DOUBLE , new int [ ] { numY } , data1 ) ; 
yaxis . setCachedData ( dataA , false ) ; 
ncfile . addVariable ( null , yaxis ) ; 
} void setProductInfo ( String prod , Date dd ) { 
String summary = null ; 
if ( prod . contains ( "NOWRADHF" ) ) { 
cunit = "dBZ" ; 
cname = "Reflectivity" ; 
} else if ( prod . contains ( "USRADHF" ) ) { 
} else if ( prod . contains ( "NEXET" ) ) { 
cname = "EchoTopsComposite" ; 
} else if ( prod . contains ( "NEXLL" ) ) { 
ctitle = "LayerReflectivityLow" ; 
} else if ( prod . contains ( "NEXLM" ) ) { 
ctitle = "LayerReflectivityMid" ; 
} else if ( prod . contains ( "NEXLH" ) ) { 
ctitle = "LayerReflectivityHigh" ; 
cname = "ReflectivityHigh" ; 
} else if ( prod . contains ( "NEXVI" ) ) { 
cunit = "Knots" ; 
cname = "VILwater" ; 
ctilt = "error" ; 
ctitle = "error" ; 
cunit = "error" ; 
cname = "error" ; 
ncfile . addAttribute ( null , new Attribute ( "title" , "NOWRAD" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "keywords" , "NOWRAD" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "creator_name" , "NOAA/NWS" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "creator_url" , "http://www.ncdc.noaa.gov/oa/radar/radarproducts.html" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "naming_authority" , "NOAA/NCDC" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "base_date" , formatter . toDateOnlyString ( dd ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "conventions" , _Coordinate . Convention ) ) ; 
} public static int shortsToInt ( short s1 , short s2 , boolean swapBytes ) { 
byte [ ] b = new byte [ 4 ] ; 
b [ 0 ] = ( byte ) ( s1 > > > 8 ) ; 
b [ 1 ] = ( byte ) ( s1 > > > 0 ) ; 
b [ 2 ] = ( byte ) ( s2 > > > 8 ) ; 
b [ 3 ] = ( byte ) ( s2 > > > 0 ) ; 
return bytesToInt ( b , false ) ; 
} public static int bytesToInt ( byte [ ] bytes , boolean swapBytes ) { 
byte a = bytes [ 0 ] ; 
byte b = bytes [ 1 ] ; 
byte c = bytes [ 2 ] ; 
byte d = bytes [ 3 ] ; 
if ( swapBytes ) { 
return ( ( a & 0xff ) ) + ( ( b & 0xff ) << 8 ) + ( ( c & 0xff ) << 16 ) + ( ( d & 0xff ) << 24 ) ; 
return ( ( a & 0xff ) << 24 ) + ( ( b & 0xff ) << 16 ) + ( ( c & 0xff ) << 8 ) + ( ( d & 0xff ) ) ; 
} static public java . util . Date getDate ( int julianDays , int msecs ) { 
long total = ( ( long ) ( julianDays - 1 ) ) * 24 * 3600 * 1000 + msecs ; 
return new Date ( total ) ; 
} static public void setProperty ( String name , String value ) { 
if ( name . equalsIgnoreCase ( "syncExtendOnly" ) ) 
syncExtendOnly = value . equalsIgnoreCase ( "true" ) ; 
} public static boolean isValidNetcdfObjectName ( String name ) { 
int cp = name . codePointAt ( 0 ) ; 
if ( cp <= 0x7f ) { 
if ( ! ( 'A' <= cp && cp <= 'Z' ) 
&& ! ( 'a' <= cp && cp <= 'z' ) 
&& ! ( '0' <= cp && cp <= '9' ) 
&& cp != '_' ) { 
for ( int i = 1 ; i < name . length ( ) ; ++ i ) { 
cp = name . codePointAt ( i ) ; 
if ( cp <= 0x7f && Character . isWhitespace ( cp ) ) { 
} public static String makeValidNetcdfObjectName ( String name ) { 
StringBuilder sb = new StringBuilder ( name ) ; 
while ( sb . length ( ) > 0 ) { 
int cp = sb . codePointAt ( 0 ) ; 
sb . deleteCharAt ( 0 ) ; 
for ( int pos = 1 ; pos < sb . length ( ) ; ++ pos ) { 
int cp = sb . codePointAt ( pos ) ; 
if ( cp <= 0x7F ) { 
sb . deleteCharAt ( pos ) ; 
-- pos ; 
int cp = sb . codePointAt ( sb . length ( ) - 1 ) ; 
sb . deleteCharAt ( sb . length ( ) - 1 ) ; 
if ( sb . length ( ) == 0 ) { 
} static public boolean isValidNetcdf3ObjectName ( String name ) { 
Matcher m = objectNamePatternOld . matcher ( name ) ; 
return m . matches ( ) ; 
public void openForWriting ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile , 
ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
open ( raf , ncfile , cancelTask ) ; 
public Array readData ( ucar . nc2 . Variable v2 , Section section ) throws IOException , InvalidRangeException { 
if ( v2 instanceof Structure ) 
return readRecordData ( ( Structure ) v2 , section ) ; 
N3header . Vinfo vinfo = ( N3header . Vinfo ) v2 . getSPobject ( ) ; 
DataType dataType = v2 . getDataType ( ) ; 
Layout layout = ( ! v2 . isUnlimited ( ) ) ? new LayoutRegular ( vinfo . begin , v2 . getElementSize ( ) , v2 . getShape ( ) , section ) : 
new LayoutRegularSegmented ( vinfo . begin , v2 . getElementSize ( ) , header . recsize , v2 . getShape ( ) , section ) ; 
if ( layout . getTotalNelems ( ) == 0 ) { 
return Array . factory ( dataType , section . getShape ( ) ) ; 
Object data = readData ( layout , dataType ) ; 
return Array . factory ( dataType , section . getShape ( ) , data ) ; 
} private ucar . ma2 . Array readRecordData ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException { 
Range recordRange = section . getRange ( 0 ) ; 
StructureMembers members = s . makeStructureMembers ( ) ; 
for ( StructureMembers . Member m : members . getMembers ( ) ) { 
Variable v2 = s . findVariable ( m . getName ( ) ) ; 
m . setDataParam ( ( int ) ( vinfo . begin - header . recStart ) ) ; 
if ( header . recsize > Integer . MAX_VALUE ) 
long nrecs = section . computeSize ( ) ; 
if ( nrecs * header . recsize > Integer . MAX_VALUE ) 
members . setStructureSize ( ( int ) header . recsize ) ; 
ArrayStructureBB structureArray = new ArrayStructureBB ( members , new int [ ] { recordRange . length ( ) } ) ; 
byte [ ] result = structureArray . getByteBuffer ( ) . array ( ) ; 
for ( int recnum : recordRange ) { 
raf . seek ( header . recStart + recnum * header . recsize ) ; 
if ( recnum != header . numrecs - 1 ) 
raf . readFully ( result , ( int ) ( count * header . recsize ) , ( int ) header . recsize ) ; 
raf . read ( result , ( int ) ( count * header . recsize ) , ( int ) header . recsize ) ; 
return structureArray ; 
} private ucar . ma2 . Array readRecordDataSubset ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException { 
int nrecords = recordRange . length ( ) ; 
int rank = m . getShape ( ) . length ; 
int [ ] fullShape = new int [ rank + 1 ] ; 
fullShape [ 0 ] = nrecords ; 
System . arraycopy ( m . getShape ( ) , 0 , fullShape , 1 , rank ) ; 
Array data = Array . factory ( m . getDataType ( ) , fullShape ) ; 
m . setDataArray ( data ) ; 
m . setDataObject ( data . getIndexIterator ( ) ) ; 
public void create ( String filename , ucar . nc2 . NetcdfFile ncfile , int extra , long preallocateSize , boolean largeFile ) throws IOException { 
this . readonly = false ; 
raf = new ucar . unidata . io . RandomAccessFile ( filename , "rw" ) ; 
raf . order ( RandomAccessFile . BIG_ENDIAN ) ; 
if ( preallocateSize > 0 ) { 
java . io . RandomAccessFile myRaf = raf . getRandomAccessFile ( ) ; 
myRaf . setLength ( preallocateSize ) ; 
header = new N3header ( ) ; 
header . create ( raf , ncfile , extra , largeFile , null ) ; 
_create ( raf ) ; 
if ( fill ) 
fillNonRecordVariables ( ) ; 
public void writeData ( Variable v2 , Section section , Array values ) throws java . io . IOException , InvalidRangeException { 
if ( v2 . isUnlimited ( ) ) { 
Range firstRange = section . getRange ( 0 ) ; 
setNumrecs ( firstRange . last ( ) + 1 ) ; 
if ( v2 instanceof Structure ) { 
if ( ! ( values instanceof ArrayStructure ) ) 
if ( v2 . getRank ( ) == 0 ) 
Dimension d = v2 . getDimension ( 0 ) ; 
if ( ! d . isUnlimited ( ) ) 
writeRecordData ( ( Structure ) v2 , section , ( ArrayStructure ) values ) ; 
writeData ( values , layout , dataType ) ; 
public void updateAttribute ( ucar . nc2 . Variable v2 , Attribute att ) throws IOException { 
header . updateAttribute ( v2 , att ) ; 
} protected void fillNonRecordVariables ( ) throws IOException { 
for ( Variable v : ncfile . getVariables ( ) ) { 
if ( v . isUnlimited ( ) ) continue ; 
writeData ( v , v . getShapeAsSection ( ) , makeConstantArray ( v ) ) ; 
public boolean syncExtend ( ) throws IOException { 
boolean result = header . synchNumrecs ( ) ; 
if ( result && log . isDebugEnabled ( ) ) 
public void flush ( ) throws java . io . IOException { 
if ( raf != null ) { 
raf . flush ( ) ; 
header . writeNumrecs ( ) ; 
} public boolean read ( String datasetName , Object specialO ) throws IOException { 
long tstart = System . currentTimeMillis ( ) ; 
Array a ; 
log . debug ( getRequestedRange ( ) ) ; 
int n = numDimensions ( ) ; 
List < Range > ranges = new ArrayList < > ( n ) ; 
for ( int i = 0 ; i < n ; i ++ ) 
ranges . add ( new Range ( getStart ( i ) , getStop ( i ) , getStride ( i ) ) ) ; 
a = ncVar . read ( ranges ) ; 
} catch ( java . lang . ArrayIndexOutOfBoundsException t ) { 
log . error ( getRequestedRange ( ) , t ) ; 
if ( debug ) 
long tookTime = System . currentTimeMillis ( ) - tstart ; 
} catch ( InvalidDimensionException e ) { 
log . error ( getRequestedRange ( ) , e ) ; 
setData ( a ) ; 
return ( false ) ; 
} protected double [ ] makeLevelValues ( ) { 
List < String > levels = getLevels ( ) ; 
if ( levels == null ) { 
if ( levels . size ( ) != getSize ( ) ) { 
int inc = 0 ; 
double [ ] vals = new double [ getSize ( ) ] ; 
String tstart = levels . get ( 0 ) . trim ( ) . toLowerCase ( ) ; 
String pattern = null ; 
if ( tstart . indexOf ( ":" ) >= 0 ) { 
pattern = dateFormats [ 0 ] ; 
} else if ( tstart . indexOf ( "z" ) >= 0 ) { 
pattern = dateFormats [ 1 ] ; 
} else if ( Character . isLetter ( tstart . charAt ( 0 ) ) ) { 
pattern = dateFormats [ 3 ] ; 
pattern = dateFormats [ 2 ] ; 
SimpleDateFormat sdf = new SimpleDateFormat ( pattern ) ; 
ParsePosition p = new ParsePosition ( 0 ) ; 
Date d = sdf . parse ( tstart , p ) ; 
if ( d == null ) { 
d = new Date ( 0 ) ; 
+ sdf . format ( d , new StringBuffer ( ) , new FieldPosition ( 0 ) ) ) ; 
String tinc = levels . get ( 1 ) . toLowerCase ( ) ; 
int incIndex = 0 ; 
for ( int i = 0 ; i < incStr . length ; i ++ ) { 
int index = tinc . indexOf ( incStr [ i ] ) ; 
int numOf = Integer . parseInt ( tinc . substring ( 0 , index ) ) ; 
inc = numOf ; 
incIndex = i ; 
Calendar calendar = Calendar . getInstance ( TimeZone . getTimeZone ( "GMT" ) ) ; 
calendar . setTime ( d ) ; 
vals [ 0 ] = 0 ; 
initialTime = makeTimeStruct ( calendar ) ; 
int calInc = calIncs [ incIndex ] ; 
double hours = ( double ) 1000 * 60 * 60 ; 
for ( int i = 1 ; i < getSize ( ) ; i ++ ) { 
calendar . add ( calInc , inc ) ; 
double offset = ( calendar . getTime ( ) . getTime ( ) - d . getTime ( ) ) / hours ; 
vals [ i ] = offset ; 
return vals ; 
} public GradsTimeStruct makeTimeStruct ( int timeIndex ) { 
double tVal = getValues ( ) [ timeIndex ] ; 
Calendar calendar = Calendar . getInstance ( ) ; 
calendar . setTimeZone ( java . util . TimeZone . getTimeZone ( "GMT" ) ) ; 
return makeTimeStruct ( calendar ) ; 
} private GradsTimeStruct makeTimeStruct ( Calendar calendar ) { 
GradsTimeStruct ts = new GradsTimeStruct ( ) ; 
ts . year = calendar . get ( Calendar . YEAR ) ; 
ts . month = calendar . get ( Calendar . MONTH ) + 1 ; 
ts . day = calendar . get ( Calendar . DAY_OF_MONTH ) ; 
ts . hour = calendar . get ( Calendar . HOUR_OF_DAY ) ; 
ts . minute = calendar . get ( Calendar . MINUTE ) ; 
ts . jday = calendar . get ( Calendar . DAY_OF_YEAR ) ; 
return ts ; 
} public String replaceFileTemplate ( String filespec , int timeIndex ) { 
GradsTimeStruct ts = makeTimeStruct ( timeIndex ) ; 
String retString = filespec ; 
String format ; 
while ( hasTimeTemplate ( retString ) ) { 
if ( retString . indexOf ( "%ix1" ) >= 0 ) { 
retString = retString . replaceAll ( "%ix1" , 
String . format ( "%d" , initialTime . year / 10 ) ) ; 
if ( retString . indexOf ( "%ix3" ) >= 0 ) { 
retString = retString . replaceAll ( "%ix3" , 
String . format ( "%03d" , initialTime . year / 10 ) ) ; 
if ( retString . indexOf ( "%iy2" ) >= 0 ) { 
int cent = initialTime . year / 100 ; 
int val = initialTime . year - cent * 100 ; 
retString = retString . replaceAll ( "%iy2" , 
String . format ( "%02d" , val ) ) ; 
if ( retString . indexOf ( "%iy4" ) >= 0 ) { 
retString = retString . replaceAll ( "%iy4" , 
String . format ( "%d" , initialTime . year ) ) ; 
if ( retString . indexOf ( "%im1" ) >= 0 ) { 
retString = retString . replaceAll ( "%im1" , 
String . format ( "%d" , initialTime . month ) ) ; 
if ( retString . indexOf ( "%im2" ) >= 0 ) { 
retString = retString . replaceAll ( "%im2" , 
String . format ( "%02d" , initialTime . month ) ) ; 
if ( retString . indexOf ( "%imc" ) >= 0 ) { 
retString = retString . replaceAll ( "%imc" , 
GradsTimeStruct . months [ initialTime . month - 1 ] ) ; 
if ( retString . indexOf ( "%id1" ) >= 0 ) { 
retString = retString . replaceAll ( "%id1" , 
String . format ( "%d" , initialTime . day ) ) ; 
if ( retString . indexOf ( "%id2" ) >= 0 ) { 
retString = retString . replaceAll ( "%id2" , 
String . format ( "%02d" , initialTime . day ) ) ; 
if ( retString . indexOf ( "%ih1" ) >= 0 ) { 
retString = retString . replaceAll ( "%ih1" , 
String . format ( "%d" , initialTime . hour ) ) ; 
if ( retString . indexOf ( "%ih2" ) >= 0 ) { 
retString = retString . replaceAll ( "%ih2" , 
String . format ( "%02d" , initialTime . hour ) ) ; 
if ( retString . indexOf ( "%ih3" ) >= 0 ) { 
retString = retString . replaceAll ( "%ih3" , 
String . format ( "%03d" , initialTime . hour ) ) ; 
if ( retString . indexOf ( "%in2" ) >= 0 ) { 
retString = retString . replaceAll ( "%in2" , 
String . format ( "%02d" , initialTime . minute ) ) ; 
if ( retString . indexOf ( "%x1" ) >= 0 ) { 
retString = retString . replaceAll ( "%x1" , 
String . format ( "%d" , ts . year / 10 ) ) ; 
if ( retString . indexOf ( "%x3" ) >= 0 ) { 
retString = retString . replaceAll ( "%x3" , 
String . format ( "%03d" , ts . year / 10 ) ) ; 
if ( retString . indexOf ( "%y2" ) >= 0 ) { 
int cent = ts . year / 100 ; 
int val = ts . year - cent * 100 ; 
retString = retString . replaceAll ( "%y2" , 
if ( retString . indexOf ( "%y4" ) >= 0 ) { 
retString = retString . replaceAll ( "%y4" , 
String . format ( "%d" , ts . year ) ) ; 
if ( retString . indexOf ( "%m1" ) >= 0 ) { 
retString = retString . replaceAll ( "%m1" , 
String . format ( "%d" , ts . month ) ) ; 
if ( retString . indexOf ( "%m2" ) >= 0 ) { 
retString = retString . replaceAll ( "%m2" , 
String . format ( "%02d" , ts . month ) ) ; 
if ( retString . indexOf ( "%mc" ) >= 0 ) { 
retString = retString . replaceAll ( "%mc" , 
GradsTimeStruct . months [ ts . month - 1 ] ) ; 
if ( retString . indexOf ( "%d1" ) >= 0 ) { 
retString = retString . replaceAll ( "%d1" , 
String . format ( "%d" , ts . day ) ) ; 
if ( retString . indexOf ( "%d2" ) >= 0 ) { 
retString = retString . replaceAll ( "%d2" , 
String . format ( "%02d" , ts . day ) ) ; 
if ( retString . indexOf ( "%h1" ) >= 0 ) { 
retString = retString . replaceAll ( "%h1" , 
String . format ( "%d" , ts . hour ) ) ; 
if ( retString . indexOf ( "%h2" ) >= 0 ) { 
retString = retString . replaceAll ( "%h2" , 
String . format ( "%02d" , ts . hour ) ) ; 
if ( retString . indexOf ( "%h3" ) >= 0 ) { 
retString = retString . replaceAll ( "%h3" , 
String . format ( "%03d" , ts . hour ) ) ; 
if ( retString . indexOf ( "%n2" ) >= 0 ) { 
retString = retString . replaceAll ( "%n2" , 
String . format ( "%02d" , ts . minute ) ) ; 
if ( retString . indexOf ( "%j3" ) >= 0 ) { 
retString = retString . replaceAll ( "%j3" , 
String . format ( "%03d" , ts . jday ) ) ; 
if ( retString . indexOf ( "%t1" ) >= 0 ) { 
retString = retString . replaceAll ( "%t1" , 
String . format ( "%d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%t2" ) >= 0 ) { 
retString = retString . replaceAll ( "%t2" , 
String . format ( "%02d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%t3" ) >= 0 ) { 
retString = retString . replaceAll ( "%t3" , 
String . format ( "%03d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%t4" ) >= 0 ) { 
retString = retString . replaceAll ( "%t4" , 
String . format ( "%04d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%t5" ) >= 0 ) { 
retString = retString . replaceAll ( "%t5" , 
String . format ( "%05d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%t6" ) >= 0 ) { 
retString = retString . replaceAll ( "%t6" , 
String . format ( "%06d" , timeIndex + 1 ) ) ; 
if ( retString . indexOf ( "%tm1" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm1" , 
String . format ( "%d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%tm2" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm2" , 
String . format ( "%02d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%tm3" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm3" , 
String . format ( "%03d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%tm4" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm4" , 
String . format ( "%04d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%tm5" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm5" , 
String . format ( "%05d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%tm6" ) >= 0 ) { 
retString = retString . replaceAll ( "%tm6" , 
String . format ( "%06d" , timeIndex ) ) ; 
if ( retString . indexOf ( "%f" ) >= 0 ) { 
int mins = ( int ) getValues ( ) [ timeIndex ] * 60 ; 
int tdif ; 
if ( retString . indexOf ( "%f2" ) >= 0 ) { 
format = "%02d" ; 
tdif = mins / 60 ; 
if ( tdif > 99 ) { 
format = "%d" ; 
retString = retString . replaceAll ( "%f2" , 
String . format ( format , tdif ) ) ; 
if ( retString . indexOf ( "%f3" ) >= 0 ) { 
format = "%03d" ; 
if ( tdif > 999 ) { 
retString = retString . replaceAll ( "%f3" , 
if ( retString . indexOf ( "%fn2" ) >= 0 ) { 
if ( mins > 99 ) { 
retString = retString . replaceAll ( "%fn2" , 
String . format ( format , mins ) ) ; 
if ( retString . indexOf ( "%fhn2" ) >= 0 ) { 
tdif = mins ; 
int hrs = tdif / 60 ; 
int mns = tdif - ( hrs * 60 ) ; 
format = "%02d%02d" ; 
if ( hrs > 99 ) { 
format = "%d%02d" ; 
retString = retString . replaceAll ( "%fhn2" , 
String . format ( format , hrs , mns ) ) ; 
if ( retString . indexOf ( "%fdhn2" ) >= 0 ) { 
int dys = tdif / 1440 ; 
int hrs = ( tdif - ( dys * 1440 ) ) / 60 ; 
int mns = tdif - ( dys * 1440 ) - ( hrs * 60 ) ; 
format = "%02d%02d%02d" ; 
if ( dys > 99 ) { 
format = "%d%02d%02d" ; 
retString = retString . replaceAll ( "%fdhn2" , 
String . format ( format , dys , hrs , mns ) ) ; 
return retString ; 
} public static boolean hasTimeTemplate ( String template ) { 
for ( int i = 0 ; i < timeTemplates . length ; i ++ ) { 
if ( template . indexOf ( timeTemplates [ i ] ) >= 0 ) { 
if ( ProjectionPointImpl . isInfinite ( pt1 ) 
|| ProjectionPointImpl . isInfinite ( pt2 ) ) { 
double y1 = pt1 . getY ( ) - falseNorthing ; 
double y2 = pt2 . getY ( ) - falseNorthing ; 
return ( y1 * y2 < 0 ) && ( Math . abs ( y1 - y2 ) > 2 * earthRadius ) ; 
} public ProjectionPoint latLonToProj ( LatLonPoint latLon , 
ProjectionPointImpl result ) { 
double toX , toY ; 
double fromLat = latLon . getLatitude ( ) ; 
double fromLon = latLon . getLongitude ( ) ; 
double lon = Math . toRadians ( fromLon ) ; 
double lat = Math . toRadians ( fromLat ) ; 
double dlon = lon - lon0 ; 
double b = Math . cos ( lat ) * Math . sin ( dlon ) ; 
if ( ( Math . abs ( Math . abs ( b ) - 1.0 ) ) < TOLERANCE ) { 
toX = Double . POSITIVE_INFINITY ; 
toY = Double . POSITIVE_INFINITY ; 
toX = scale * SpecialMathFunction . atanh ( b ) ; 
toY = scale * ( Math . atan2 ( Math . tan ( lat ) , Math . cos ( dlon ) ) - lat0 ) ; 
result . setLocation ( toX + falseEasting , toY + falseNorthing ) ; 
} public LatLonPoint projToLatLon ( ProjectionPoint world , 
LatLonPointImpl result ) { 
double fromX = world . getX ( ) ; 
double fromY = world . getY ( ) ; 
double x = ( fromX - falseEasting ) / scale ; 
double d = ( fromY - falseNorthing ) / scale + lat0 ; 
toLon = Math . toDegrees ( lon0 + Math . atan2 ( Math . sinh ( x ) , Math . cos ( d ) ) ) ; 
toLat = Math . toDegrees ( Math . asin ( Math . sin ( d ) / Math . cosh ( x ) ) ) ; 
result . setLatitude ( toLat ) ; 
result . setLongitude ( toLon ) ; 
} public float [ ] [ ] latLonToProj ( float [ ] [ ] from , float [ ] [ ] to , int latIndex , 
int lonIndex ) { 
int cnt = from [ 0 ] . length ; 
float [ ] fromLatA = from [ latIndex ] ; 
float [ ] fromLonA = from [ lonIndex ] ; 
float [ ] resultXA = to [ INDEX_X ] ; 
float [ ] resultYA = to [ INDEX_Y ] ; 
for ( int i = 0 ; i < cnt ; i ++ ) { 
double fromLat = fromLatA [ i ] ; 
double fromLon = fromLonA [ i ] ; 
toX = 0.0 ; 
toY = 0.0 ; 
toX = scale * SpecialMathFunction . atanh ( b ) + falseEasting ; 
toY = scale * ( Math . atan2 ( Math . tan ( lat ) , Math . cos ( dlon ) ) - lat0 ) + falseNorthing ; 
resultXA [ i ] = ( float ) toX ; 
resultYA [ i ] = ( float ) toY ; 
return to ; 
} public double [ ] [ ] projToLatLon ( double [ ] [ ] from , double [ ] [ ] to ) { 
double [ ] fromXA = from [ INDEX_X ] ; 
double [ ] fromYA = from [ INDEX_Y ] ; 
double [ ] toLatA = to [ INDEX_LAT ] ; 
double [ ] toLonA = to [ INDEX_LON ] ; 
double fromX = fromXA [ i ] ; 
double fromY = fromYA [ i ] ; 
toLatA [ i ] = ( double ) toLat ; 
toLonA [ i ] = ( double ) toLon ; 
} public void add ( ServerSideFunction function ) { 
if ( function instanceof BoolFunction ) { 
boolFunctions . put ( function . getName ( ) , function ) ; 
if ( function instanceof BTFunction ) { 
btFunctions . put ( function . getName ( ) , function ) ; 
} public BoolFunction getBoolFunction ( String name ) 
throws NoSuchFunctionException { 
if ( ! boolFunctions . containsKey ( name ) ) { 
loadNewFunction ( name ) ; 
return ( BoolFunction ) boolFunctions . get ( name ) ; 
} public BTFunction getBTFunction ( String name ) 
if ( ! btFunctions . containsKey ( name ) ) { 
return ( BTFunction ) btFunctions . get ( name ) ; 
} protected void loadNewFunction ( String name ) { 
String fullName = prefix + name ; 
Class value = Class . forName ( fullName ) ; 
if ( ( ServerSideFunction . class ) . isAssignableFrom ( value ) ) { 
add ( ( ServerSideFunction ) value . newInstance ( ) ) ; 
} private String findCoordinateName ( NetcdfDataset ds , AxisType axisType ) { 
List < Variable > vlist = ds . getVariables ( ) ; 
for ( Variable aVlist : vlist ) { 
VariableEnhanced ve = ( VariableEnhanced ) aVlist ; 
if ( axisType == getAxisType ( ds , ve ) ) { 
return ve . getFullName ( ) ; 
public String getGeneratingProcessName ( int genProcess ) { 
if ( genProcessMap == null ) 
genProcessMap = readGenProcess ( fnmocTableA ) ; 
if ( genProcessMap == null ) return null ; 
return genProcessMap . get ( genProcess ) ; 
} protected VertCoordType getLevelType ( int code ) { 
if ( levelTypesMap == null ) 
levelTypesMap = readFnmocTable3 ( fnmocTable3 ) ; 
return super . getLevelType ( code ) ; 
VertCoordType levelType = levelTypesMap . get ( code ) ; 
if ( levelType != null ) return levelType ; 
private HashMap < Integer , VertCoordType > readFnmocTable3 ( String path ) { 
try ( InputStream is = GribResourceReader . getInputStream ( path ) ) { 
SAXBuilder builder = new SAXBuilder ( ) ; 
org . jdom2 . Document doc = builder . build ( is ) ; 
Element root = doc . getRootElement ( ) ; 
HashMap < Integer , VertCoordType > result = new HashMap < > ( 200 ) ; 
Element fnmocTable = root . getChild ( "fnmocTable" ) ; 
List < Element > params = fnmocTable . getChildren ( "entry" ) ; 
for ( Element elem1 : params ) { 
int code = Integer . parseInt ( elem1 . getChildText ( "grib1Id" ) ) ; 
if ( code < 129 ) continue ; 
String desc = elem1 . getChildText ( "description" ) ; 
String abbrev = elem1 . getChildText ( "name" ) ; 
String units = elem1 . getChildText ( "units" ) ; 
if ( units == null ) units = ( code == 219 ) ? "Pa" : "" ; 
String datum = elem1 . getChildText ( "datum" ) ; 
boolean isLayer = elem1 . getChild ( "isLayer" ) != null ; 
boolean isPositiveUp = elem1 . getChild ( "isPositiveUp" ) != null ; 
VertCoordType lt = new VertCoordType ( code , desc , abbrev , units , datum , isPositiveUp , isLayer ) ; 
result . put ( code , lt ) ; 
} catch ( IOException | JDOMException e ) { 
} protected InvCatalog createSkeletonCatalog ( String prefixUrlPath ) throws IOException 
this . checkAccessPoint ( ) ; 
InvCatalogImpl catalog = new InvCatalogImpl ( null , null , null ) ; 
InvService service = new InvService ( this . getResultService ( ) . getName ( ) , 
this . getResultService ( ) . getServiceType ( ) . toString ( ) , 
this . getResultService ( ) . getBase ( ) , 
this . getResultService ( ) . getSuffix ( ) , 
this . getResultService ( ) . getDescription ( ) ) ; 
for ( Iterator it = this . getResultService ( ) . getProperties ( ) . iterator ( ) ; it . hasNext ( ) ; ) 
service . addProperty ( ( InvProperty ) it . next ( ) ) ; 
for ( Iterator it = this . getResultService ( ) . getServices ( ) . iterator ( ) ; it . hasNext ( ) ; ) 
service . addService ( ( InvService ) it . next ( ) ) ; 
catalog . addService ( service ) ; 
File apFile = new File ( this . getAccessPoint ( ) ) ; 
InvDatasetImpl topDs = new LocalInvDataset ( null , apFile , prefixUrlPath ) ; 
ThreddsMetadata tm = new ThreddsMetadata ( false ) ; 
tm . setServiceName ( service . getName ( ) ) ; 
InvMetadata md = new InvMetadata ( topDs , null , XMLEntityResolver . CATALOG_NAMESPACE_10 , "" , true , true , null , tm ) ; 
ThreddsMetadata tm2 = new ThreddsMetadata ( false ) ; 
tm2 . addMetadata ( md ) ; 
topDs . setLocalMetadata ( tm2 ) ; 
catalog . addDataset ( topDs ) ; 
( ( InvCatalogImpl ) catalog ) . finish ( ) ; 
return ( catalog ) ; 
} protected List expandThisLevel ( InvDataset dataset , String prefixUrlPath ) 
File theDir = new File ( ( ( LocalInvDataset ) dataset ) . getLocalPath ( ) ) ; 
File [ ] allFiles = theDir . listFiles ( ) ; 
InvDataset curDs = null ; 
ArrayList list = new ArrayList ( ) ; 
for ( int i = 0 ; i < allFiles . length ; i ++ ) 
curDs = new LocalInvDataset ( dataset , allFiles [ i ] , prefixUrlPath ) ; 
list . add ( curDs ) ; 
return ( list ) ; 
} public final GridParameter getParameter ( GridRecord gr ) { 
McIDASGridRecord mgr = ( McIDASGridRecord ) gr ; 
String name = mgr . getParameterName ( ) ; 
String desc = mgr . getGridDescription ( ) ; 
if ( desc . trim ( ) . equals ( "" ) ) { 
desc = name ; 
String unit = visad . jmet . MetUnits . makeSymbol ( mgr . getParamUnitName ( ) ) ; 
return new GridParameter ( 0 , name , desc , unit ) ; 
} public final String getLevelName ( GridRecord gr ) { 
if ( cust != null ) { 
String result = cust . getLevelNameShort ( gr . getLevelType1 ( ) ) ; 
if ( result != null ) return result ; 
String levelUnit = getLevelUnit ( gr ) ; 
if ( levelUnit != null ) { 
int level1 = ( int ) gr . getLevel1 ( ) ; 
int level2 = ( int ) gr . getLevel2 ( ) ; 
if ( levelUnit . equalsIgnoreCase ( "hPa" ) ) { 
return "pressure" ; 
} else if ( level1 == 1013 ) { 
} else if ( level1 == 0 ) { 
return "tropopause" ; 
} else if ( level1 == 1001 ) { 
return "surface" ; 
} else if ( level2 != 0 ) { 
return "layer" ; 
} public final String getLevelDescription ( GridRecord gr ) { 
String result = cust . getLevelDescription ( gr . getLevelType1 ( ) ) ; 
return getLevelName ( gr ) ; 
} public final String getLevelUnit ( GridRecord gr ) { 
String result = cust . getLevelUnits ( gr . getLevelType1 ( ) ) ; 
return visad . jmet . MetUnits . makeSymbol ( ( ( McIDASGridRecord ) gr ) . getLevelUnitName ( ) ) ; 
} public final int getProjectionType ( GridDefRecord gds ) { 
String name = getProjectionName ( gds ) . trim ( ) ; 
switch ( name ) { 
case "MERC" : 
return Mercator ; 
case "CONF" : 
return LambertConformal ; 
case "PS" : 
return PolarStereographic ; 
} public final boolean isVerticalCoordinate ( GridRecord gr ) { 
return cust . isVerticalCoordinate ( gr . getLevelType1 ( ) ) ; 
int type = gr . getLevelType1 ( ) ; 
if ( ( ( McIDASGridRecord ) gr ) . hasGribInfo ( ) ) { 
if ( type == 20 ) { 
if ( type == 100 ) { 
if ( type == 101 ) { 
if ( ( type >= 103 ) && ( type <= 128 ) ) { 
if ( type == 141 ) { 
if ( type == 160 ) { 
} else if ( getLevelUnit ( gr ) . equals ( "hPa" ) ) { 
} public boolean isLayer ( GridRecord gr ) { 
return cust . isLayer ( gr . getLevelType1 ( ) ) ; 
if ( gr . getLevel2 ( ) == 0 ) { 
} CdmrFeatureProto . CoverageDataset . Builder encodeHeader ( CoverageCollection gridDataset , String location ) { 
CdmrFeatureProto . CoverageDataset . Builder builder = CdmrFeatureProto . CoverageDataset . newBuilder ( ) ; 
builder . setName ( location ) ; 
builder . setCoverageType ( convertCoverageType ( gridDataset . getCoverageType ( ) ) ) ; 
builder . setDateRange ( encodeDateRange ( gridDataset . getCalendarDateRange ( ) ) ) ; 
if ( gridDataset . getLatlonBoundingBox ( ) != null ) 
builder . setLatlonRect ( encodeRectangle ( gridDataset . getLatlonBoundingBox ( ) ) ) ; 
if ( gridDataset . getProjBoundingBox ( ) != null ) 
builder . setProjRect ( encodeRectangle ( gridDataset . getProjBoundingBox ( ) ) ) ; 
for ( Attribute att : gridDataset . getGlobalAttributes ( ) ) 
builder . addAtts ( NcStream . encodeAtt ( att ) ) ; 
for ( CoverageCoordSys gcs : gridDataset . getCoordSys ( ) ) 
builder . addCoordSys ( encodeCoordSys ( gcs ) ) ; 
for ( CoverageTransform gct : gridDataset . getCoordTransforms ( ) ) 
builder . addCoordTransforms ( encodeCoordTransform ( gct ) ) ; 
for ( CoverageCoordAxis axis : gridDataset . getCoordAxes ( ) ) 
builder . addCoordAxes ( encodeCoordAxis ( axis ) ) ; 
for ( Coverage grid : gridDataset . getCoverages ( ) ) 
builder . addGrids ( encodeGrid ( grid ) ) ; 
} CdmrFeatureProto . Rectangle . Builder encodeRectangle ( LatLonRect rect ) { 
CdmrFeatureProto . Rectangle . Builder builder = CdmrFeatureProto . Rectangle . newBuilder ( ) ; 
LatLonPoint ll = rect . getLowerLeftPoint ( ) ; 
LatLonPoint ur = rect . getUpperRightPoint ( ) ; 
builder . setStartx ( ll . getLongitude ( ) ) ; 
builder . setStarty ( ll . getLatitude ( ) ) ; 
builder . setIncx ( rect . getWidth ( ) ) ; 
builder . setIncy ( ur . getLatitude ( ) - ll . getLatitude ( ) ) ; 
} CdmrFeatureProto . CalendarDateRange . Builder encodeDateRange ( CalendarDateRange dateRange ) { 
CdmrFeatureProto . CalendarDateRange . Builder builder = CdmrFeatureProto . CalendarDateRange . newBuilder ( ) ; 
builder . setStart ( dateRange . getStart ( ) . getMillis ( ) ) ; 
builder . setEnd ( dateRange . getEnd ( ) . getMillis ( ) ) ; 
Calendar cal = dateRange . getStart ( ) . getCalendar ( ) ; 
builder . setCalendar ( convertCalendar ( cal ) ) ; 
} CdmrFeatureProto . Coverage . Builder encodeGrid ( Coverage grid ) { 
CdmrFeatureProto . Coverage . Builder builder = CdmrFeatureProto . Coverage . newBuilder ( ) ; 
builder . setName ( grid . getName ( ) ) ; 
builder . setDataType ( NcStream . convertDataType ( grid . getDataType ( ) ) ) ; 
for ( Attribute att : grid . getAttributes ( ) ) 
builder . setUnits ( grid . getUnitsString ( ) ) ; 
builder . setDescription ( grid . getDescription ( ) ) ; 
builder . setCoordSys ( grid . getCoordSysName ( ) ) ; 
} CdmrFeatureProto . CoordSys . Builder encodeCoordSys ( CoverageCoordSys gcs ) { 
CdmrFeatureProto . CoordSys . Builder builder = CdmrFeatureProto . CoordSys . newBuilder ( ) ; 
builder . setName ( gcs . getName ( ) ) ; 
builder . setCoverageType ( convertCoverageType ( gcs . getCoverageType ( ) ) ) ; 
for ( String axis : gcs . getAxisNames ( ) ) 
builder . addAxisNames ( axis ) ; 
for ( String gct : gcs . getTransformNames ( ) ) 
builder . addTransformNames ( gct ) ; 
} CdmrFeatureProto . CoordTransform . Builder encodeCoordTransform ( CoverageTransform gct ) { 
CdmrFeatureProto . CoordTransform . Builder builder = CdmrFeatureProto . CoordTransform . newBuilder ( ) ; 
builder . setIsHoriz ( gct . isHoriz ( ) ) ; 
builder . setName ( gct . getName ( ) ) ; 
for ( Attribute att : gct . getAttributes ( ) ) 
builder . addParams ( NcStream . encodeAtt ( att ) ) ; 
} CdmrFeatureProto . CoordAxis . Builder encodeCoordAxis ( CoverageCoordAxis axis ) { 
CdmrFeatureProto . CoordAxis . Builder builder = CdmrFeatureProto . CoordAxis . newBuilder ( ) ; 
builder . setName ( axis . getName ( ) ) ; 
builder . setDataType ( NcStream . convertDataType ( axis . getDataType ( ) ) ) ; 
builder . setAxisType ( convertAxisType ( axis . getAxisType ( ) ) ) ; 
builder . setNvalues ( axis . getNcoords ( ) ) ; 
if ( axis . getUnits ( ) != null ) builder . setUnits ( axis . getUnits ( ) ) ; 
if ( axis . getDescription ( ) != null ) builder . setDescription ( axis . getDescription ( ) ) ; 
builder . setDepend ( convertDependenceType ( axis . getDependenceType ( ) ) ) ; 
for ( String s : axis . getDependsOnList ( ) ) 
builder . addDependsOn ( s ) ; 
if ( axis instanceof LatLonAxis2D ) { 
LatLonAxis2D latlon2D = ( LatLonAxis2D ) axis ; 
for ( int shape : latlon2D . getShape ( ) ) 
builder . addShape ( shape ) ; 
for ( Attribute att : axis . getAttributes ( ) ) 
builder . setSpacing ( convertSpacing ( axis . getSpacing ( ) ) ) ; 
builder . setStartValue ( axis . getStartValue ( ) ) ; 
builder . setEndValue ( axis . getEndValue ( ) ) ; 
builder . setResolution ( axis . getResolution ( ) ) ; 
if ( ! axis . isRegular ( ) && axis . getNcoords ( ) < MAX_INLINE_NVALUES ) { 
double [ ] values = axis . getValues ( ) ; 
ByteBuffer bb = ByteBuffer . allocate ( 8 * values . length ) ; 
DoubleBuffer db = bb . asDoubleBuffer ( ) ; 
db . put ( values ) ; 
builder . setValues ( ByteString . copyFrom ( bb . array ( ) ) ) ; 
} static public CdmrFeatureProto . CoverageType convertCoverageType ( FeatureType type ) { 
switch ( type ) { 
case COVERAGE : 
return CdmrFeatureProto . CoverageType . General ; 
case CURVILINEAR : 
return CdmrFeatureProto . CoverageType . Curvilinear ; 
case GRID : 
return CdmrFeatureProto . CoverageType . Grid ; 
case SWATH : 
return CdmrFeatureProto . CoverageType . Swath ; 
case FMRC : 
return CdmrFeatureProto . CoverageType . Fmrc ; 
} public CdmrFeatureProto . CoverageDataResponse encodeDataResponse ( Iterable < CoverageCoordAxis > axes , 
Iterable < CoverageCoordSys > coordSys , Iterable < CoverageTransform > transforms , List < GeoReferencedArray > arrays , boolean deflate ) { 
CdmrFeatureProto . CoverageDataResponse . Builder builder = CdmrFeatureProto . CoverageDataResponse . newBuilder ( ) ; 
for ( CoverageCoordAxis axis : axes ) 
for ( CoverageCoordSys cs : coordSys ) 
builder . addCoordSys ( encodeCoordSys ( cs ) ) ; 
for ( CoverageTransform t : transforms ) 
builder . addCoordTransforms ( encodeCoordTransform ( t ) ) ; 
for ( GeoReferencedArray array : arrays ) 
builder . addGeoArray ( encodeGeoReferencedArray ( array , deflate ) ) ; 
} public static DirectoryStream newDirectoryStream ( Path dir , String glob ) throws IOException { 
FileSystem fs = dir . getFileSystem ( ) ; 
final PathMatcher matcher = fs . getPathMatcher ( "glob:" + glob ) ; 
DirectoryStream . Filter < Path > filter = new DirectoryStream . Filter < Path > ( ) { 
public boolean accept ( Path entry ) { 
return matcher . matches ( entry . getFileName ( ) ) ; 
return fs . provider ( ) . newDirectoryStream ( dir , filter ) ; 
} static public void registerTransform ( String transformName , Class c ) { 
if ( ! ( VertTransformBuilderIF . class . isAssignableFrom ( c ) ) && ! ( HorizTransformBuilderIF . class . isAssignableFrom ( c ) ) ) 
c . newInstance ( ) ; 
transformList . add ( 0 , new Transform ( transformName , c ) ) ; 
transformList . add ( new Transform ( transformName , c ) ) ; 
} static public void registerTransform ( String transformName , String className ) throws ClassNotFoundException { 
registerTransform ( transformName , c ) ; 
} static public void registerTransformMaybe ( String transformName , String className ) { 
Class c ; 
c = Class . forName ( className ) ; 
} static public CoordinateTransform makeCoordinateTransform ( NetcdfDataset ds , AttributeContainer ctv , Formatter parseInfo , Formatter errInfo ) { 
String transform_name = ctv . findAttValueIgnoreCase ( "transform_name" , null ) ; 
if ( null == transform_name ) 
transform_name = ctv . findAttValueIgnoreCase ( "Projection_Name" , null ) ; 
transform_name = ctv . findAttValueIgnoreCase ( CF . GRID_MAPPING_NAME , null ) ; 
transform_name = ctv . findAttValueIgnoreCase ( CF . STANDARD_NAME , null ) ; 
if ( null == transform_name ) { 
transform_name = transform_name . trim ( ) ; 
Class builderClass = null ; 
for ( Transform transform : transformList ) { 
if ( transform . transName . equals ( transform_name ) ) { 
builderClass = transform . transClass ; 
if ( null == builderClass ) { 
Object builderObject ; 
builderObject = builderClass . newInstance ( ) ; 
} catch ( InstantiationException | IllegalAccessException e ) { 
if ( null == builderObject ) { 
CoordinateTransform ct ; 
if ( builderObject instanceof VertTransformBuilderIF ) { 
VertTransformBuilderIF vertBuilder = ( VertTransformBuilderIF ) builderObject ; 
vertBuilder . setErrorBuffer ( errInfo ) ; 
ct = vertBuilder . makeCoordinateTransform ( ds , ctv ) ; 
} else if ( builderObject instanceof HorizTransformBuilderIF ) { 
HorizTransformBuilderIF horizBuilder = ( HorizTransformBuilderIF ) builderObject ; 
horizBuilder . setErrorBuffer ( errInfo ) ; 
String units = AbstractTransformBuilder . getGeoCoordinateUnits ( ds , ctv ) ; 
ct = horizBuilder . makeCoordinateTransform ( ctv , units ) ; 
if ( ct != null ) { 
return ct ; 
} static public VariableDS makeDummyTransformVariable ( NetcdfDataset ds , CoordinateTransform ct ) { 
VariableDS v = new VariableDS ( ds , null , null , ct . getName ( ) , DataType . CHAR , "" , null , null ) ; 
List < Parameter > params = ct . getParameters ( ) ; 
for ( Parameter p : params ) { 
if ( p . isString ( ) ) 
v . addAttribute ( new Attribute ( p . getName ( ) , p . getStringValue ( ) ) ) ; 
double [ ] data = p . getNumericValues ( ) ; 
Array dataA = Array . factory ( DataType . DOUBLE , new int [ ] { data . length } , data ) ; 
v . addAttribute ( new Attribute ( p . getName ( ) , dataA ) ) ; 
v . addAttribute ( new Attribute ( _Coordinate . TransformType , ct . getTransformType ( ) . toString ( ) ) ) ; 
v . setCachedData ( data , true ) ; 
} static public ProjectionImpl makeProjection ( CoverageTransform gct , Formatter errInfo ) { 
String transform_name = gct . findAttValueIgnoreCase ( CF . GRID_MAPPING_NAME , null ) ; 
HorizTransformBuilderIF builder ; 
builder = ( HorizTransformBuilderIF ) builderClass . newInstance ( ) ; 
if ( null == builder ) { 
String units = gct . findAttValueIgnoreCase ( CDM . UNITS , null ) ; 
builder . setErrorBuffer ( errInfo ) ; 
ProjectionCT ct = builder . makeCoordinateTransform ( gct , units ) ; 
assert ct != null ; 
return ct . getProjection ( ) ; 
} private void firePropertyChangeEvent ( PropertyChangeEvent event ) { 
if ( pipeOut ) 
pipeEvent ( event ) ; 
if ( messageOut ) 
messageEvent ( event ) ; 
firePropertyChange ( event . getPropertyName ( ) , event . getOldValue ( ) , event . getNewValue ( ) ) ; 
} public JDialog makeDialog ( JFrame parent , String title , boolean modal ) { 
return new Dialog ( frame , title , modal ) ; 
} public static void main ( String args [ ] ) { 
boolean usePopup = false ; 
for ( int i = 0 ; i < args . length ; i ++ ) { 
if ( args [ i ] . equals ( "-usePopup" ) ) 
usePopup = true ; 
store = XMLStore . createFromFile ( "ThreddsDatasetChooser" , null ) ; 
p = store . getPreferences ( ) ; 
frame . addWindowListener ( new WindowAdapter ( ) { 
public void windowClosing ( WindowEvent e ) { 
chooser . save ( ) ; 
Rectangle bounds = frame . getBounds ( ) ; 
p . putBeanObject ( FRAME_SIZE , bounds ) ; 
store . save ( ) ; 
ioe . printStackTrace ( ) ; 
System . exit ( 0 ) ; 
chooser = new ThreddsDatasetChooser ( p , null , frame , true , usePopup , false ) ; 
chooser . setDoResolve ( true ) ; 
frame . getContentPane ( ) . add ( chooser ) ; 
Rectangle bounds = ( Rectangle ) p . getBean ( FRAME_SIZE , new Rectangle ( 50 , 50 , 800 , 450 ) ) ; 
frame . setBounds ( bounds ) ; 
frame . pack ( ) ; 
frame . setVisible ( true ) ; 
} public D1 getCoordinateArray1D ( int timeIndex , int xIndex , int yIndex ) 
ArrayDouble . D3 ddata = getCoordinateArray ( timeIndex ) ; 
int [ ] origin = new int [ ] { 0 , yIndex , xIndex } ; 
int [ ] shape = new int [ ] { ddata . getShape ( ) [ 0 ] , 1 , 1 } ; 
return ( ArrayDouble . D1 ) ddata . section ( origin , shape ) . reduce ( ) ; 
} public String getFileLocationFromRequestPath ( String reqPath ) { 
if ( datasetScan != null ) { 
return getFileLocationFromRequestPath ( reqPath , datasetScan . getPath ( ) , datasetScan . getScanLocation ( ) , false ) ; 
} else if ( catScan != null ) { 
return getFileLocationFromRequestPath ( reqPath , catScan . getPath ( ) , catScan . getLocation ( ) , false ) ; 
} else if ( featCollection != null ) { 
return getFileLocationFromRequestPath ( reqPath , featCollection . getPath ( ) , featCollection . getTopDirectoryLocation ( ) , true ) ; 
return getFileLocationFromRequestPath ( reqPath , getPath ( ) , getDirLocation ( ) , false ) ; 
} public void save ( ) { 
collectionNameTable . saveState ( false ) ; 
dataTable . saveState ( false ) ; 
prefs . putBeanObject ( "InfoWindowBounds" , infoWindow . getBounds ( ) ) ; 
prefs . putInt ( "splitPos" , split . getDividerLocation ( ) ) ; 
} private void writeSequence ( StructureDS s , StructureDataIterator sdataIter ) throws IOException , XMLStreamException { 
while ( sdataIter . hasNext ( ) ) { 
StructureData sdata = sdataIter . next ( ) ; 
staxWriter . writeCharacters ( "\n" ) ; 
staxWriter . writeCharacters ( indent . toString ( ) ) ; 
staxWriter . writeStartElement ( "struct" ) ; 
staxWriter . writeAttribute ( "name" , escaper . escape ( s . getShortName ( ) ) ) ; 
staxWriter . writeAttribute ( "count" , Integer . toString ( count ++ ) ) ; 
for ( StructureMembers . Member m : sdata . getMembers ( ) ) { 
Variable v = s . findVariable ( m . getName ( ) ) ; 
indent . incr ( ) ; 
if ( m . getDataType ( ) . isString ( ) || m . getDataType ( ) . isNumeric ( ) ) { 
writeVariable ( ( VariableDS ) v , sdata . getArray ( m ) ) ; 
} else if ( m . getDataType ( ) == DataType . STRUCTURE ) { 
StructureDS sds = ( StructureDS ) v ; 
ArrayStructure data = ( ArrayStructure ) sdata . getArray ( m ) ; 
writeSequence ( sds , data . getStructureDataIterator ( ) ) ; 
} else if ( m . getDataType ( ) == DataType . SEQUENCE ) { 
SequenceDS sds = ( SequenceDS ) v ; 
ArraySequence data = ( ArraySequence ) sdata . getArray ( m ) ; 
indent . decr ( ) ; 
staxWriter . writeEndElement ( ) ; 
sdataIter . close ( ) ; 
} public void sendDataRequestForm ( HttpServletRequest request , 
HttpServletResponse response , 
String dataSet , 
ServerDDS sdds , 
DAS myDAS ) 
throws DAP2Exception , ParseException { 
String requestURL ; 
int suffixIndex = request . getRequestURL ( ) . toString ( ) . lastIndexOf ( "." ) ; 
requestURL = request . getRequestURL ( ) . substring ( 0 , suffixIndex ) ; 
String dapCssUrl = "/" + requestURL . split ( "/" , 5 ) [ 3 ] + "/" + "tdsDap.css" ; 
PrintWriter pw ; 
if ( false ) { 
pw = new PrintWriter ( 
new FileOutputStream ( 
new File ( "debug.html" ) 
pw = response . getWriter ( ) ; 
wwwOutPut wOut = new wwwOutPut ( pw ) ; 
DDS myDDS = getWebFormDDS ( dataSet , sdds ) ; 
jscriptCore jsc = new jscriptCore ( ) ; 
pw . println ( 
+ "\"http://www.w3.org/TR/REC-html40/loose.dtd\">\n" 
+ "<!--\n" 
pw . println ( jsc . jScriptCode ) ; 
+ "</script>\n" 
+ "</head>\n" 
+ "<body>\n" 
+ "<hr>\n" 
+ "<table>\n" 
wOut . writeDisposition ( requestURL ) ; 
pw . println ( "<tr><td><td><hr>\n" ) ; 
wOut . writeGlobalAttributes ( myDAS , myDDS ) ; 
wOut . writeVariableEntries ( myDAS , myDDS ) ; 
pw . println ( "</table></form>\n" ) ; 
pw . println ( "<hr>\n" ) ; 
pw . println ( "<address>" ) ; 
+ serverContactEmail + "</a></p>" ) ; 
pw . println ( "</address></body></html>" ) ; 
pw . println ( "<hr>" ) ; 
pw . println ( "<h2>DDS:</h2>" ) ; 
pw . println ( "<pre>" ) ; 
myDDS . print ( pw ) ; 
pw . println ( "</pre>" ) ; 
catch ( IOException ioe ) { 
ioe . printStackTrace ( System . out ) ; 
} public DDS getWebFormDDS ( String dataSet , ServerDDS sDDS ) 
wwwFactory wfactory = new wwwFactory ( ) ; 
DDS wwwDDS = new DDS ( dataSet , wfactory ) ; 
wwwDDS . setURL ( dataSet ) ; 
StringWriter ddsSW = new StringWriter ( ) ; 
sDDS . print ( new PrintWriter ( ddsSW ) ) ; 
ByteArrayInputStream bai = null ; 
bai = new ByteArrayInputStream ( ddsSW . toString ( ) . getBytes ( "UTF-8" ) ) ; 
} catch ( UnsupportedEncodingException uee ) { 
wwwDDS . parse ( bai ) ; 
return ( wwwDDS ) ; 
public final Chronology withZone ( DateTimeZone zone ) { 
if ( zone . equals ( DateTimeZone . UTC ) ) return this . withUTC ( ) ; 
} static public ByteBuffer 
encodeArray ( DapType vtype , Object values , ByteOrder order ) 
TypeSort atomtype = vtype . getAtomicType ( ) ; 
assert values != null && values . getClass ( ) . isArray ( ) ; 
int count = Array . getLength ( values ) ; 
int total = ( int ) TypeSort . getSize ( atomtype ) * count ; 
ByteBuffer buf = ByteBuffer . allocate ( total ) . order ( order ) ; 
switch ( atomtype ) { 
case Char : 
char [ ] datac = ( char [ ] ) values ; 
for ( int i = 0 ; i < datac . length ; i ++ ) { 
byte b = ( byte ) ( 0xFFL & ( long ) ( datac [ i ] ) ) ; 
buf . put ( b ) ; 
case UInt8 : 
case Int8 : 
byte [ ] data8 = ( byte [ ] ) values ; 
buf . put ( data8 ) ; 
case Int16 : 
case UInt16 : 
short [ ] data16 = ( short [ ] ) values ; 
buf . asShortBuffer ( ) . put ( data16 ) ; 
buf . position ( total ) ; 
case Int32 : 
case UInt32 : 
int [ ] data32 = ( int [ ] ) values ; 
buf . asIntBuffer ( ) . put ( data32 ) ; 
case Int64 : 
case UInt64 : 
long [ ] data64 = ( long [ ] ) values ; 
buf . asLongBuffer ( ) . put ( data64 ) ; 
case Float32 : 
float [ ] dataf = ( float [ ] ) values ; 
buf . asFloatBuffer ( ) . put ( dataf ) ; 
case Float64 : 
double [ ] datad = ( double [ ] ) values ; 
buf . asDoubleBuffer ( ) . put ( datad ) ; 
case URL : 
case String : 
String [ ] datas = ( String [ ] ) values ; 
total = 0 ; 
for ( int i = 0 ; i < datas . length ; i ++ ) { 
String content = datas [ i ] ; 
byte [ ] bytes = content . getBytes ( DapUtil . UTF8 ) ; 
total += ( bytes . length + COUNTSIZE ) ; 
buf = ByteBuffer . allocate ( total ) . order ( order ) ; 
buf . putLong ( bytes . length ) ; 
buf . put ( bytes ) ; 
case Opaque : 
Object [ ] datao = ( Object [ ] ) values ; 
for ( int i = 0 ; i < datao . length ; i ++ ) { 
ByteBuffer opaquedata = ( ByteBuffer ) datao [ i ] ; 
size = opaquedata . remaining ( ) ; 
total += ( size + COUNTSIZE ) ; 
buf . putLong ( size ) ; 
int savepos = opaquedata . position ( ) ; 
buf . put ( opaquedata ) ; 
opaquedata . position ( savepos ) ; 
case Enum : 
} public void 
writeCount ( long count ) 
countbuffer . clear ( ) ; 
countbuffer . putLong ( count ) ; 
byte [ ] countbuf = countbuffer . array ( ) ; 
int len = countbuffer . position ( ) ; 
writeBytes ( countbuf , len ) ; 
if ( DEBUG ) { 
writeAtomicArray ( DapType daptype , Object values ) 
ByteBuffer buf = SerialWriter . encodeArray ( daptype , values , this . order ) ; 
byte [ ] bytes = buf . array ( ) ; 
int len = buf . position ( ) ; 
writeBytes ( bytes , len ) ; 
for ( int i = 0 ; i < len ; i ++ ) { 
int x = ( int ) ( order == ByteOrder . BIG_ENDIAN ? bytes [ i ] : bytes [ ( len - 1 ) - i ] ) ; 
System . err . printf ( "%02x" , ( int ) ( x & 0xff ) ) ; 
System . err . println ( ) ; 
writeBytes ( byte [ ] bytes , int len ) 
outputBytes ( bytes , 0 , len ) ; 
if ( this . checksummode . enabled ( ChecksumMode . DAP ) ) { 
this . checksum . update ( bytes , 0 , len ) ; 
if ( DUMPCSUM ) { 
System . err . printf ( "%02x" , bytes [ i ] ) ; 
outputBytes ( byte [ ] bytes , int start , int count ) 
if ( DUMPDATA ) { 
for ( int i = 0 ; i < count ; i ++ ) { 
System . err . println ( "" ) ; 
System . err . flush ( ) ; 
output . write ( bytes , start , count ) ; 
public Object isMine ( FeatureType wantFeatureType , NetcdfDataset ds , Formatter errlog ) throws IOException { 
if ( wantFeatureType == null ) wantFeatureType = FeatureType . ANY_POINT ; 
if ( wantFeatureType != FeatureType . ANY_POINT ) { 
if ( ! wantFeatureType . isPointFeatureType ( ) ) 
TableConfigurer tc = TableAnalyzer . getTableConfigurer ( wantFeatureType , ds ) ; 
if ( tc == null ) { 
boolean hasTime = false ; 
boolean hasLat = false ; 
boolean hasLon = false ; 
for ( CoordinateAxis axis : ds . getCoordinateAxes ( ) ) { 
if ( axis . getAxisType ( ) == AxisType . Time ) 
hasTime = true ; 
if ( axis . getAxisType ( ) == AxisType . Lat ) 
hasLat = true ; 
if ( axis . getAxisType ( ) == AxisType . Lon ) 
hasLon = true ; 
if ( ! ( hasTime && hasLon && hasLat ) ) { 
} else if ( showTables ) { 
TableAnalyzer analyser = TableAnalyzer . factory ( tc , wantFeatureType , ds ) ; 
if ( analyser == null ) 
if ( ! analyser . featureTypeOk ( wantFeatureType , errlog ) ) { 
return analyser ; 
} private String prepCE ( String ce ) { 
int index ; 
if ( ce == null ) { 
ce = "" ; 
} else if ( ! ce . equals ( "" ) ) { 
index = ce . indexOf ( "%" ) ; 
if ( index == - 1 ) 
return ( ce ) ; 
if ( index > ( ce . length ( ) - 3 ) ) 
return ( null ) ; 
while ( index >= 0 ) { 
String specChar = ce . substring ( index + 1 , index + 3 ) ; 
char val = ( char ) Byte . parseByte ( specChar , 16 ) ; 
ce = ce . substring ( 0 , index ) + String . valueOf ( val ) + ce . substring ( index + 3 , ce . length ( ) ) ; 
} protected void processDodsURL ( ) { 
String cxtpath = HTTPUtil . canonicalpath ( myHttpRequest . getContextPath ( ) ) ; 
if ( cxtpath != null && cxtpath . length ( ) == 0 ) cxtpath = null ; 
if ( cxtpath == null ) cxtpath = "/" ; 
String servletpath = HTTPUtil . canonicalpath ( myHttpRequest . getServletPath ( ) ) ; 
if ( servletpath != null && servletpath . length ( ) == 0 ) servletpath = null ; 
this . dataSetName = HTTPUtil . canonicalpath ( myHttpRequest . getPathInfo ( ) ) ; 
if ( this . dataSetName != null && this . dataSetName . length ( ) == 0 ) this . dataSetName = null ; 
if ( this . dataSetName == null ) { 
if ( servletpath != null ) { 
if ( cxtpath != null && servletpath . startsWith ( cxtpath ) ) { 
this . dataSetName = servletpath . substring ( cxtpath . length ( ) ) ; 
this . dataSetName = servletpath ; 
if ( dataSetName . startsWith ( "/dodsC" ) ) dataSetName = dataSetName . substring ( 6 ) ; 
this . requestSuffix = null ; 
if ( this . dataSetName != null ) { 
String name = this . dataSetName ; 
if ( name . startsWith ( "/" ) ) name = name . substring ( 1 ) ; 
String [ ] pieces = name . split ( "/" ) ; 
if ( pieces . length == 0 || pieces [ 0 ] . length ( ) == 0 ) { 
requestSuffix = "" ; 
this . dataSetName = name ; 
String endOPath = pieces [ pieces . length - 1 ] ; 
int index = endOPath . lastIndexOf ( '.' ) ; 
requestSuffix = endOPath . substring ( index + 1 ) ; 
this . dataSetName = this . dataSetName . substring ( 1 , this . dataSetName . lastIndexOf ( '.' ) ) ; 
} public boolean getAcceptsCompressed ( ) { 
boolean isTiny ; 
isTiny = false ; 
String encoding = this . myHttpRequest . getHeader ( "Accept-Encoding" ) ; 
if ( encoding != null ) 
isTiny = encoding . contains ( "deflate" ) ; 
return ( isTiny ) ; 
} private ImmutableMap < Integer , Grib2Parameter > readTable ( String path ) throws IOException { 
ImmutableMap . Builder < Integer , Grib2Parameter > builder = ImmutableMap . builder ( ) ; 
if ( debugOpen ) { 
ClassLoader cl = Grib2TableConfig . class . getClassLoader ( ) ; 
try ( InputStream is = cl . getResourceAsStream ( path ) ) { 
try ( BufferedReader dataIS = new BufferedReader ( 
new InputStreamReader ( is , Charset . forName ( "UTF8" ) ) ) ) { 
String line = dataIS . readLine ( ) ; 
if ( line . startsWith ( "#" ) || line . trim ( ) . length ( ) == 0 ) { 
int lastParen = line . lastIndexOf ( '(' ) ; 
String num1 = line . substring ( 0 , posBlank1 ) . trim ( ) ; 
String num2 = line . substring ( posBlank1 + 1 , posBlank2 ) ; 
String desc = ( lastParen > 0 ) ? line . substring ( posBlank2 + 1 , lastParen ) . trim ( ) 
: line . substring ( posBlank2 + 1 ) . trim ( ) ; 
String units = ( lastParen > 0 ) ? line . substring ( lastParen ) . trim ( ) : "" ; 
if ( units . startsWith ( "(" ) & units . endsWith ( ")" ) ) 
units = units . substring ( 1 , units . length ( ) - 1 ) ; 
if ( ! num1 . equals ( num2 ) ) { 
if ( debug ) { 
int number = Integer . parseInt ( num1 ) ; 
Grib2Parameter parameter = new Grib2Parameter ( discipline , category , number , desc , units , 
null , desc ) ; 
builder . put ( parameter . getNumber ( ) , parameter ) ; 
} void finishInit ( ) { 
np = ui . panz ; 
vertPanel = ui . vertPanel ; 
dataValueLabel = ui . dataValueLabel ; 
posLabel = ui . positionLabel ; 
project = ( ProjectionImpl ) store . getBean ( LastProjectionName , null ) ; 
if ( project != null ) 
setProjection ( project ) ; 
ProjectionRect ma = ( ProjectionRect ) store . getBean ( LastMapAreaName , null ) ; 
if ( ma != null ) 
np . setMapArea ( ma ) ; 
makeEventManagement ( ) ; 
} boolean showDataset ( ) { 
java . util . List grids = gridDataset . getGrids ( ) ; 
if ( ( grids == null ) || grids . size ( ) == 0 ) { 
currentField = ( GridDatatype ) grids . get ( 0 ) ; 
currentSlice = 0 ; 
currentLevel = 0 ; 
currentTime = 0 ; 
currentEnsemble = 0 ; 
currentRunTime = 0 ; 
eventsOK = false ; 
renderGrid . setGeoGrid ( currentField ) ; 
ui . setFields ( gridDataset . getGrids ( ) ) ; 
setField ( currentField ) ; 
ProjectionImpl dataProjection = currentField . getProjection ( ) ; 
if ( dataProjection != null ) 
setProjection ( dataProjection ) ; 
eventsOK = true ; 
} private boolean setField ( Object fld ) { 
GridDatatype gg = null ; 
if ( fld instanceof GridDatatype ) 
gg = ( GridDatatype ) fld ; 
else if ( fld instanceof String ) 
gg = gridDataset . findGridDatatype ( ( String ) fld ) ; 
if ( null == gg ) 
renderGrid . setGeoGrid ( gg ) ; 
currentField = gg ; 
GridCoordSystem gcs = gg . getCoordinateSystem ( ) ; 
gcs . setProjectionBoundingBox ( ) ; 
CoordinateAxis1D vaxis = gcs . getVerticalAxis ( ) ; 
levelNames = ( vaxis == null ) ? new ArrayList ( ) : vaxis . getNames ( ) ; 
if ( ( levelNames == null ) || ( currentLevel >= levelNames . size ( ) ) ) 
vertPanel . setCoordSys ( currentField . getCoordinateSystem ( ) , currentLevel ) ; 
if ( gcs . hasTimeAxis ( ) ) { 
CoordinateAxis1DTime taxis = gcs . hasTimeAxis1D ( ) ? gcs . getTimeAxis1D ( ) : gcs . getTimeAxisForRun ( 0 ) ; 
timeNames = ( taxis == null ) ? new ArrayList ( ) : taxis . getNames ( ) ; 
if ( ( timeNames == null ) || ( currentTime >= timeNames . size ( ) ) ) 
hasDependentTimeAxis = ! gcs . hasTimeAxis1D ( ) ; 
hasDependentTimeAxis = false ; 
CoordinateAxis1D eaxis = gcs . getEnsembleAxis ( ) ; 
ensembleNames = ( eaxis == null ) ? new ArrayList ( ) : eaxis . getNames ( ) ; 
currentEnsemble = ensembleNames . size ( ) > 0 ? 0 : - 1 ; 
CoordinateAxis1DTime rtaxis = gcs . getRunTimeAxis ( ) ; 
runtimeNames = ( rtaxis == null ) ? new ArrayList ( ) : rtaxis . getNames ( ) ; 
currentRunTime = runtimeNames . size ( ) > 0 ? 0 : - 1 ; 
ui . setField ( gg ) ; 
public String getSubCenterName ( int subcenter ) { 
if ( nwsoSubCenter == null ) 
nwsoSubCenter = readNwsoSubCenter ( "resources/grib1/noaa_rfc/tableC.txt" ) ; 
if ( nwsoSubCenter == null ) return null ; 
return nwsoSubCenter . get ( subcenter ) ; 
private static Map < Integer , String > readNwsoSubCenter ( String path ) { 
Map < Integer , String > result = new HashMap < > ( ) ; 
try ( InputStream is = GribResourceReader . getInputStream ( path ) ; 
BufferedReader br = new BufferedReader ( new InputStreamReader ( is , CDM . utf8Charset ) ) ) { 
StringBuilder lineb = new StringBuilder ( line ) ; 
StringUtil2 . remove ( lineb , "'+,/" ) ; 
String [ ] flds = lineb . toString ( ) . split ( "[:]" ) ; 
int val = Integer . parseInt ( flds [ 0 ] . trim ( ) ) ; 
result . put ( val , name ) ; 
return Collections . unmodifiableMap ( result ) ; 
} catch ( IOException ioError ) { 
} static public CalendarDateRange of ( DateRange dr ) { 
if ( dr == null ) return null ; 
return CalendarDateRange . of ( dr . getStart ( ) . getDate ( ) , dr . getEnd ( ) . getDate ( ) ) ; 
} public static Grib2Gds factory ( int template , byte [ ] data ) { 
Grib2Gds result ; 
switch ( template ) { 
result = new LatLon ( data ) ; 
result = new RotatedLatLon ( data ) ; 
case 10 : 
result = new Mercator ( data ) ; 
case 20 : 
result = new PolarStereographic ( data ) ; 
case 30 : 
result = new LambertConformal ( data , 30 ) ; 
case 31 : 
result = new AlbersEqualArea ( data ) ; 
case 40 : 
result = new GaussLatLon ( data ) ; 
case 50 : 
result = new GdsSpherical ( data , template ) ; 
case 90 : 
result = new SpaceViewPerspective ( data ) ; 
result = new CurvilinearOrthogonal ( data ) ; 
case 32769 : 
result = new RotatedLatLon32769 ( data ) ; 
result . finish ( ) ; 
} protected Earth getEarth ( ) { 
switch ( earthShape ) { 
return new Earth ( 6367470.0 ) ; 
if ( earthRadius < 6000000 ) earthRadius *= 1000.0 ; 
return new Earth ( earthRadius ) ; 
return EarthEllipsoid . IAU ; 
case 3 : 
if ( majorAxis < 6000000 ) majorAxis *= 1000.0 ; 
if ( minorAxis < 6000000 ) minorAxis *= 1000.0 ; 
case 4 : 
return EarthEllipsoid . IAG_GRS80 ; 
case 5 : 
return EarthEllipsoid . WGS84 ; 
case 6 : 
return new Earth ( 6371229.0 ) ; 
case 7 : 
case 8 : 
return new Earth ( 6371200.0 ) ; 
case 9 : 
return EarthEllipsoid . Airy1830 ; 
return new Earth ( ) ; 
double term = earth . isSpherical ( ) ? n2 * Math . sin ( fromLat ) : n * MapMath . qsfn ( Math . sin ( fromLat ) , e , one_es ) ; 
double rho = c - term ; 
if ( rho < 0.0 ) 
throw new RuntimeException ( "F" ) ; 
rho = dd * Math . sqrt ( rho ) ; 
double toX = rho * Math . sin ( theta ) ; 
double toY = rho0 - rho * Math . cos ( theta ) ; 
if ( rho == 0.0 ) { 
double lpphi = rho / dd ; 
if ( ! earth . isSpherical ( ) ) { 
lpphi = ( c - lpphi * lpphi ) / n ; 
if ( Math . abs ( ec - Math . abs ( lpphi ) ) > TOL7 ) { 
if ( Math . abs ( lpphi ) > 2.0 ) 
lpphi = phi1_ ( lpphi , e , one_es ) ; 
if ( lpphi == Double . MAX_VALUE ) 
throw new RuntimeException ( "I" ) ; 
lpphi = ( lpphi < 0. ) ? - MapMath . HALFPI : MapMath . HALFPI ; 
lpphi = ( c - lpphi * lpphi ) / n2 ; 
if ( Math . abs ( lpphi ) <= 1.0 ) { 
lpphi = Math . asin ( lpphi ) ; 
toLat = lpphi ; 
} public int dapparse ( String text , DDS dds , DAS das , DAP2Exception err ) throws ParseException 
ddsobject = dds ; 
dasobject = das ; 
errobject = ( err == null ? new DAP2Exception ( ) : err ) ; 
dapdebug = getDebugLevel ( ) ; 
Boolean accept = parse ( text ) ; 
if ( ! accept ) 
return parseClass ; 
ddsparse ( String text , DDS dds ) throws ParseException 
return dapparse ( text , dds , null , null ) ; 
dasparse ( String text , DAS das ) 
return dapparse ( text , null , das , null ) ; 
errparse ( String text , DAP2Exception err ) 
return dapparse ( text , null , null , err ) ; 
} void 
tagparse ( Dap2Parse parsestate , int kind ) throws ParseException 
String expected = parseactual ( ) ; 
switch ( kind ) { 
case SCAN_DATASET : 
parseClass = DapDDS ; 
if ( ddsobject == null ) 
case SCAN_ATTR : 
parseClass = DapDAS ; 
if ( dasobject == null ) 
lexstate . dassetup ( ) ; 
case SCAN_ERROR : 
parseClass = DapERR ; 
if ( errobject == null ) 
} String 
extractname ( Object o ) 
if ( o instanceof BaseType ) 
return ( ( BaseType ) o ) . getClearName ( ) ; 
if ( o instanceof Attribute ) 
return ( ( Attribute ) o ) . getClearName ( ) ; 
if ( o instanceof AttributeTable ) 
return ( ( AttributeTable ) o ) . getClearName ( ) ; 
} public final boolean init ( RandomAccessFile raf , boolean fullCheck ) 
rf = raf ; 
return init ( fullCheck ) ; 
} protected boolean init ( boolean fullCheck ) throws IOException { 
if ( rf == null ) { 
gridIndex = new GridIndex ( rf . getLocation ( ) ) ; 
rf . order ( RandomAccessFile . BIG_ENDIAN ) ; 
if ( rf . length ( ) < 44 ) return false ; 
int numEntries = Math . abs ( readInt ( 10 ) ) ; 
if ( numEntries > 1000000 ) { 
needToSwap = true ; 
numEntries = Math . abs ( McIDASUtil . swbyt4 ( numEntries ) ) ; 
if ( numEntries > MAX_GRIDS ) { 
rf . seek ( 0 ) ; 
String label = rf . readString ( 32 ) ; 
for ( int i = 0 ; i < label . length ( ) ; i ++ ) { 
String s0 = label . substring ( i , i + 1 ) ; 
int date = readInt ( 9 ) ; 
if ( ( date < 10000 ) || ( date > 400000 ) ) { 
if ( rf . length ( ) < 4 * ( numEntries + 12 ) ) return false ; 
int [ ] entries = new int [ numEntries ] ; 
entries [ i ] = readInt ( i + 11 ) ; 
if ( entries [ i ] < - 1 ) { 
if ( ! fullCheck ) { 
if ( entries [ i ] == - 1 ) { 
int [ ] header = new int [ 64 ] ; 
rf . seek ( entries [ i ] * 4 ) ; 
rf . readInt ( header , 0 , 64 ) ; 
if ( needToSwap ) { 
swapGridHeader ( header ) ; 
McIDASGridRecord gr = new McIDASGridRecord ( entries [ i ] , 
header ) ; 
gridIndex . addGridRecord ( gr ) ; 
if ( gdsMap . get ( gr . getGridDefRecordId ( ) ) == null ) { 
McGridDefRecord mcdef = gr . getGridDefRecord ( ) ; 
gdsMap . put ( mcdef . toString ( ) , mcdef ) ; 
gridIndex . addHorizCoordSys ( mcdef ) ; 
} catch ( McIDASException me ) { 
if ( gridIndex . getGridRecords ( ) . isEmpty ( ) ) { 
} private void swapGridHeader ( int [ ] gh ) { 
McIDASUtil . flip ( gh , 0 , 5 ) ; 
McIDASUtil . flip ( gh , 7 , 7 ) ; 
McIDASUtil . flip ( gh , 9 , 10 ) ; 
McIDASUtil . flip ( gh , 12 , 14 ) ; 
McIDASUtil . flip ( gh , 32 , 51 ) ; 
} public float [ ] readGrid ( McIDASGridRecord gr ) throws IOException { 
float [ ] data ; 
int te = ( gr . getOffsetToHeader ( ) + 64 ) * 4 ; 
int rows = gr . getRows ( ) ; 
int cols = gr . getColumns ( ) ; 
rf . seek ( te ) ; 
float scale = ( float ) gr . getParamScale ( ) ; 
data = new float [ rows * cols ] ; 
rf . order ( needToSwap ? RandomAccessFile . LITTLE_ENDIAN : RandomAccessFile . BIG_ENDIAN ) ; 
for ( int nc = 0 ; nc < cols ; nc ++ ) { 
for ( int nr = 0 ; nr < rows ; nr ++ ) { 
int temp = rf . readInt ( ) ; 
data [ ( rows - nr - 1 ) * cols + nc ] = ( temp 
== McIDASUtil . MCMISSING ) 
? Float . NaN 
: ( ( float ) temp ) / scale ; 
} public int readInt ( int word ) throws IOException { 
rf . seek ( word * 4 ) ; 
rf . order ( RandomAccessFile . LITTLE_ENDIAN ) ; 
int idata = rf . readInt ( ) ; 
return idata ; 
String file = "GRID2001" ; 
if ( args . length > 0 ) { 
file = args [ 0 ] ; 
McIDASGridReader mg = new McIDASGridReader ( file ) ; 
GridIndex gridIndex = mg . getGridIndex ( ) ; 
List grids = gridIndex . getGridRecords ( ) ; 
int num = Math . min ( grids . size ( ) , 10 ) ; 
for ( int i = 0 ; i < num ; i ++ ) { 
System . out . println ( grids . get ( i ) ) ; 
} private void writeAConstraint ( String name , boolean isImplemented ) { 
String defValue ; 
if ( isImplemented ) defValue = "TRUE" ; else defValue = "FALSE" ; 
+ "</ows:Constraint>" ; 
} private void writeHeadersAndSS ( ) { 
writeServiceInfo ( ) ; 
} public void writeOperations ( ) { 
for ( WFSRequestType rt : operationList ) { 
writeAOperation ( rt ) ; 
+ "<ows:Value>2.0.0</ows:Value>" 
+ "</ows:AllowedValues>" 
+ "</ows:Parameter>" ; 
+ "<ows:Value>text/xml</ows:Value>" 
writeAConstraint ( "ImplementsBasicWFS" , true ) ; 
writeAConstraint ( "ImplementsTransactionalWFS" , false ) ; 
writeAConstraint ( "ImplementsLockingWFS" , false ) ; 
writeAConstraint ( "KVPEncoding" , false ) ; 
writeAConstraint ( "XMLEncoding" , true ) ; 
writeAConstraint ( "SOAPEncoding" , false ) ; 
writeAConstraint ( "ImplementsInheritance" , false ) ; 
writeAConstraint ( "ImplementsRemoteResolve" , false ) ; 
writeAConstraint ( "ImplementsResultPaging" , false ) ; 
writeAConstraint ( "ImplementsStandardJoins" , false ) ; 
writeAConstraint ( "ImplementsSpatialJoins" , false ) ; 
writeAConstraint ( "ImplementsTemporalJoins" , false ) ; 
writeAConstraint ( "ImplementsFeatureVersioning" , false ) ; 
writeAConstraint ( "ManageStoredQueries" , false ) ; 
writeAConstraint ( "PagingIsTransactionSafe" , false ) ; 
writeAConstraint ( "QueryExpressions" , false ) ; 
fileOutput += "</ows:OperationsMetadata>" ; 
} public void execute ( String filename ) throws IOException { 
try ( RandomAccessFile mraf = new RandomAccessFile ( filename , "r" ) ) { 
MessageScanner scanner = new MessageScanner ( mraf ) ; 
while ( scanner . hasNext ( ) ) { 
Message m = scanner . next ( ) ; 
if ( m == null ) continue ; 
total_msgs ++ ; 
if ( m . getNumberDatasets ( ) == 0 ) continue ; 
m . setRawBytes ( scanner . getMessageBytes ( m ) ) ; 
dispatcher . dispatch ( m ) ; 
dispatcher . resetBufrTableMessages ( ) ; 
} public void readAll ( File dir , FileFilter ff , Closure closure , LogFilter logf , Stats stat ) throws IOException { 
File [ ] files = dir . listFiles ( ) ; 
if ( files == null ) { 
List < File > list = Arrays . asList ( files ) ; 
Collections . sort ( list ) ; 
for ( File f : list ) { 
if ( ( ff != null ) && ! ff . accept ( f ) ) continue ; 
if ( f . isDirectory ( ) ) 
readAll ( f , ff , closure , logf , stat ) ; 
scanLogFile ( f , closure , logf , stat ) ; 
} public void scanLogFile ( File file , Closure closure , LogFilter logf , Stats stat ) throws IOException { 
try ( InputStream ios = new FileInputStream ( file ) ) { 
BufferedReader dataIS = new BufferedReader ( new InputStreamReader ( ios , 
CDM . utf8Charset ) , 40 * 1000 ) ; 
while ( ( maxLines < 0 ) || ( count < maxLines ) ) { 
Log log = parser . nextLog ( dataIS ) ; 
if ( log == null ) break ; 
if ( ( logf != null ) && ! logf . pass ( log ) ) continue ; 
closure . process ( log ) ; 
if ( stat != null ) { 
stat . total += total ; 
stat . passed += count ; 
} public static GempakGridReader getInstance ( RandomAccessFile raf , boolean fullCheck ) throws IOException { 
GempakGridReader ggr = new GempakGridReader ( raf . getLocation ( ) ) ; 
ggr . init ( raf , fullCheck ) ; 
return ggr ; 
boolean ok = super . init ( fullCheck ) ; 
if ( ! ok ) return false ; 
if ( dmLabel . kftype != MFGD ) { 
DMPart part = getPart ( "GRID" ) ; 
if ( part == null ) { 
int lenhdr = part . klnhdr ; 
if ( lenhdr > LLGDHD ) { 
for ( int i = 0 ; i < keys . kkcol . size ( ) ; i ++ ) { 
Key colkey = keys . kkcol . get ( i ) ; 
if ( ! colkey . name . equals ( kcolnm [ i ] ) ) { 
gridIndex = new GridIndex ( filename ) ; 
float [ ] headerArray = getFileHeader ( NAVB ) ; 
if ( headerArray == null ) { 
navBlock = new NavigationBlock ( headerArray ) ; 
gridIndex . addHorizCoordSys ( navBlock ) ; 
headerArray = getFileHeader ( ANLB ) ; 
analBlock = new AnalysisBlock ( headerArray ) ; 
List < GempakGridRecord > tmpList = new ArrayList < > ( ) ; 
int [ ] header = new int [ dmLabel . kckeys ] ; 
if ( ( headers == null ) || ( headers . colHeaders == null ) ) { 
int gridNum = 0 ; 
for ( int [ ] fullHeader : headers . colHeaders ) { 
gridNum ++ ; 
if ( ( fullHeader == null ) || ( fullHeader [ 0 ] == IMISSD ) ) { 
System . arraycopy ( fullHeader , 1 , header , 0 , header . length ) ; 
GempakGridRecord gh = new GempakGridRecord ( gridNum , header ) ; 
gh . navBlock = navBlock ; 
String name = gh . getParameterName ( ) ; 
tmpList . add ( gh ) ; 
fileSize = rf . length ( ) ; 
if ( ! tmpList . isEmpty ( ) ) { 
for ( GempakGridRecord gh : tmpList ) { 
gh . packingType = getGridPackingType ( gh . gridNumber ) ; 
if ( ( gh . packingType == MDGGRB ) || ( gh . packingType == MDGRB2 ) 
|| ( gh . packingType == MDGNON ) ) { 
gridIndex . addGridRecord ( gh ) ; 
if ( args . length == 0 ) { 
System . exit ( 1 ) ; 
GempakGridParameterTable . addParameters ( "resources/nj22/tables/gempak/wmogrib3.tbl" ) ; 
GempakGridParameterTable . addParameters ( "resources/nj22/tables/gempak/ncepgrib2.tbl" ) ; 
GempakGridReader ggr = getInstance ( getFile ( args [ 0 ] ) , true ) ; 
String var = "PMSL" ; 
if ( ( args . length > 1 ) && ! args [ 1 ] . equalsIgnoreCase ( "X" ) ) { 
var = args [ 1 ] ; 
ggr . showGridInfo ( args . length != 3 ) ; 
GempakGridRecord gh = ggr . findGrid ( var ) ; 
if ( gh != null ) { 
System . out . println ( "\n" + var + ":" ) ; 
System . out . println ( gh ) ; 
for ( int j = 0 ; j < 2 ; j ++ ) { 
float [ ] data = ggr . readGrid ( gh ) ; 
if ( data != null ) { 
int cnt = 0 ; 
int it = 10 ; 
float min = Float . POSITIVE_INFINITY ; 
float max = Float . NEGATIVE_INFINITY ; 
for ( int i = 0 ; i < data . length ; i ++ ) { 
if ( cnt == it ) { 
cnt = 0 ; 
cnt ++ ; 
if ( ( data [ i ] != RMISSD ) && ( data [ i ] < min ) ) { 
min = data [ i ] ; 
if ( ( data [ i ] != RMISSD ) && ( data [ i ] > max ) ) { 
max = data [ i ] ; 
ggr . useDP = ! ggr . useDP ; 
} public int getGridPackingType ( int gridNumber ) throws IOException { 
int irow = 1 ; 
if ( ( gridNumber < 1 ) || ( gridNumber > dmLabel . kcol ) ) { 
return - 9 ; 
int iprt = getPartNumber ( "GRID" ) ; 
if ( iprt == 0 ) { 
return - 10 ; 
DMPart part = parts . get ( iprt - 1 ) ; 
if ( part . ktyprt != MDGRID ) { 
+ GempakUtil . getDataType ( part . ktyprt ) ) ; 
return - 21 ; 
int ilenhd = part . klnhdr ; 
int ipoint = dmLabel . kpdata 
+ ( irow - 1 ) * dmLabel . kcol * dmLabel . kprt 
+ ( gridNumber - 1 ) * dmLabel . kprt + ( iprt - 1 ) ; 
int istart = DM_RINT ( ipoint ) ; 
if ( istart == 0 ) { 
return - 15 ; 
int length = DM_RINT ( istart ) ; 
int isword = istart + 1 ; 
if ( length <= ilenhd ) { 
+ ilenhd + ")" ) ; 
} else if ( Math . abs ( length ) > 10000000 ) { 
return - 34 ; 
int [ ] header = new int [ ilenhd ] ; 
DM_RINT ( isword , header ) ; 
isword += ilenhd ; 
return DM_RINT ( isword ) ; 
} public GempakGridRecord findGrid ( String parm ) { 
List < GridRecord > gridList = gridIndex . getGridRecords ( ) ; 
if ( gridList == null ) { 
for ( GridRecord grid : gridList ) { 
GempakGridRecord gh = ( GempakGridRecord ) grid ; 
if ( gh . param . trim ( ) . equals ( parm ) ) { 
return gh ; 
} public float [ ] readGrid ( GridRecord gr ) throws IOException { 
int gridNumber = ( ( GempakGridRecord ) gr ) . getGridNumber ( ) ; 
RData data = DM_RDTR ( 1 , gridNumber , "GRID" , gr . getDecimalScale ( ) ) ; 
float [ ] vals = null ; 
vals = data . data ; 
} public float [ ] DM_RPKG ( int isword , int nword , int decimalScale ) 
int ipktyp = DM_RINT ( isword ) ; 
int iiword = isword + 1 ; 
int lendat = nword - 1 ; 
if ( ipktyp == MDGNON ) { 
data = new float [ lendat ] ; 
DM_RFLT ( iiword , data ) ; 
int iiw ; 
int irw ; 
if ( ipktyp == MDGDIF ) { 
iiw = 4 ; 
irw = 3 ; 
} else if ( ipktyp == MDGRB2 ) { 
irw = 1 ; 
iiw = 3 ; 
irw = 2 ; 
int [ ] iarray = new int [ iiw ] ; 
float [ ] rarray = new float [ irw ] ; 
DM_RINT ( iiword , iarray ) ; 
iiword = iiword + iiw ; 
lendat = lendat - iiw ; 
DM_RFLT ( iiword , rarray ) ; 
iiword = iiword + irw ; 
lendat = lendat - irw ; 
if ( ipktyp == MDGRB2 ) { 
data = unpackGrib2Data ( iiword , lendat , iarray , rarray ) ; 
int nbits = iarray [ 0 ] ; 
int misflg = iarray [ 1 ] ; 
boolean miss = misflg != 0 ; 
int kxky = iarray [ 2 ] ; 
int kx = 0 ; 
if ( iiw == 4 ) { 
kx = iarray [ 3 ] ; 
float ref = rarray [ 0 ] ; 
float scale = rarray [ 1 ] ; 
float difmin = 0 ; 
if ( irw == 3 ) { 
difmin = rarray [ 2 ] ; 
data = unpackData ( iiword , lendat , ipktyp , kxky , nbits , ref , scale , 
miss , difmin , kx , decimalScale ) ; 
} private synchronized float [ ] unpackData ( int iiword , int nword , 
int ipktyp , int kxky , int nbits , 
float ref , float scale , 
boolean miss , float difmin , 
int kx , int decimalScale ) 
if ( ipktyp == MDGGRB ) { 
if ( ! useDP ) { 
return unpackGrib1Data ( iiword , nword , kxky , nbits , ref , 
scale , miss , decimalScale ) ; 
if ( nword * 32 < kxky * nbits ) { 
nword ++ ; 
int [ ] ksgrid = new int [ nword ] ; 
DM_RINT ( iiword , ksgrid ) ; 
return DP_UGRB ( ksgrid , kxky , nbits , ref , scale , miss , 
decimalScale ) ; 
} else if ( ipktyp == MDGNMC ) { 
} else if ( ipktyp == MDGDIF ) { 
} private synchronized float [ ] DP_UGRB ( int [ ] idata , int kxky , int nbits , 
float qmin , float scale , 
boolean misflg , int decimalScale ) 
float scaleFactor = ( decimalScale == 0 ) 
? 1.f 
: ( float ) Math . pow ( 10.0 , - decimalScale ) ; 
float [ ] grid = new float [ kxky ] ; 
if ( ( nbits <= 1 ) || ( nbits > 31 ) ) { 
return grid ; 
if ( scale == 0. ) { 
int imax = ( int ) ( Math . pow ( 2 , nbits ) - 1 ) ; 
int iword = 0 ; 
int ibit = 1 ; 
for ( int i = 0 ; i < kxky ; i ++ ) { 
int jshft = nbits + ibit - 33 ; 
int idat = 0 ; 
idat = ( jshft < 0 ) 
? idata [ iword ] > > > Math . abs ( jshft ) 
: idata [ iword ] << jshft ; 
idat = idat & imax ; 
if ( jshft > 0 ) { 
jshft -= 32 ; 
int idat2 = 0 ; 
idat2 = idata [ iword + 1 ] > > > Math . abs ( jshft ) ; 
idat = idat | idat2 ; 
if ( ( idat == imax ) && misflg ) { 
grid [ i ] = RMISSD ; 
grid [ i ] = ( qmin + idat * scale ) * scaleFactor ; 
ibit += nbits ; 
if ( ibit > 32 ) { 
ibit -= 32 ; 
iword ++ ; 
} private float [ ] unpackGrib1Data ( int iiword , int nword , int kxky , 
int nbits , float ref , float scale , 
boolean miss , int decimalScale ) 
float [ ] values = new float [ kxky ] ; 
bitPos = 0 ; 
bitBuf = 0 ; 
next = 0 ; 
ch1 = 0 ; 
ch2 = 0 ; 
ch3 = 0 ; 
ch4 = 0 ; 
rf . seek ( getOffset ( iiword ) ) ; 
int idat ; 
for ( int i = 0 ; i < values . length ; i ++ ) { 
idat = bits2UInt ( nbits ) ; 
if ( miss && ( idat == IMISSD ) ) { 
values [ i ] = IMISSD ; 
values [ i ] = ( ref + scale * idat ) * scaleFactor ; 
} private float [ ] unpackGrib2Data ( int iiword , int lendat , int [ ] iarray , float [ ] rarray ) throws IOException { 
long start = getOffset ( iiword ) ; 
rf . seek ( start ) ; 
Grib2Record gr = makeGribRecord ( rf , start ) ; 
float [ ] data = gr . readData ( rf ) ; 
if ( ( ( iarray [ 3 ] > > 6 ) & 1 ) == 0 ) { 
data = gb2_ornt ( iarray [ 1 ] , iarray [ 2 ] , iarray [ 3 ] , data ) ; 
} private Grib2Record makeGribRecord ( RandomAccessFile raf , long start ) throws IOException { 
Grib2SectionIndicator is = new Grib2SectionIndicator ( start , 0 , 0 ) ; 
Grib2SectionIdentification ids = null ; 
Grib2SectionLocalUse lus = null ; 
Grib2SectionGridDefinition gds = null ; 
Grib2SectionProductDefinition pds = null ; 
Grib2SectionDataRepresentation drs = null ; 
Grib2SectionBitMap bms = null ; 
Grib2SectionData dataSection = null ; 
raf . seek ( start ) ; 
int secLength = raf . readInt ( ) ; 
if ( secLength > 0 ) { 
ids = new Grib2SectionIdentification ( raf ) ; 
secLength = raf . readInt ( ) ; 
lus = new Grib2SectionLocalUse ( raf ) ; 
gds = new Grib2SectionGridDefinition ( raf ) ; 
pds = new Grib2SectionProductDefinition ( raf ) ; 
drs = new Grib2SectionDataRepresentation ( raf ) ; 
bms = new Grib2SectionBitMap ( raf ) ; 
dataSection = new Grib2SectionData ( raf ) ; 
if ( dataSection . getMsgLength ( ) > secLength ) 
return new Grib2Record ( null , is , ids , lus , gds , pds , drs , bms , dataSection , false , Grib2Index . ScanModeMissing ) ; 
} public void printNavBlock ( ) { 
if ( navBlock != null ) { 
buf . append ( navBlock . toString ( ) ) ; 
System . out . println ( buf . toString ( ) ) ; 
} public void printAnalBlock ( ) { 
if ( analBlock != null ) { 
buf . append ( analBlock . toString ( ) ) ; 
} public void printGrids ( ) { 
if ( gridList == null ) 
for ( GridRecord aGridList : gridList ) { 
System . out . println ( aGridList ) ; 
} public void showGridInfo ( boolean printGrids ) { 
List gridList = gridIndex . getGridRecords ( ) ; 
printNavBlock ( ) ; 
System . out . println ( "" ) ; 
printAnalBlock ( ) ; 
if ( printGrids ) { 
printGrids ( ) ; 
} private float [ ] gb2_ornt ( int kx , int ky , int scan_mode , float [ ] ingrid ) { 
float [ ] fgrid = new float [ ingrid . length ] ; 
int ibeg , jbeg , iinc , jinc , itmp ; 
int icnt , jcnt , kcnt , idxarr ; 
int idrct , jdrct , consec , boustr ; 
idrct = ( scan_mode > > 7 ) & 1 ; 
jdrct = ( scan_mode > > 6 ) & 1 ; 
consec = ( scan_mode > > 5 ) & 1 ; 
boustr = ( scan_mode > > 4 ) & 1 ; 
if ( idrct == 0 ) { 
ibeg = 0 ; 
iinc = 1 ; 
ibeg = kx - 1 ; 
iinc = - 1 ; 
if ( jdrct == 1 ) { 
jbeg = 0 ; 
jinc = 1 ; 
jbeg = ky - 1 ; 
jinc = - 1 ; 
kcnt = 0 ; 
if ( ( consec == 1 ) && ( boustr == 0 ) ) { 
for ( jcnt = jbeg ; ( ( 0 <= jcnt ) && ( jcnt < ky ) ) ; jcnt += jinc ) { 
for ( icnt = ibeg ; ( ( 0 <= icnt ) && ( icnt < kx ) ) ; 
icnt += iinc ) { 
idxarr = ky * icnt + jcnt ; 
fgrid [ kcnt ] = ingrid [ idxarr ] ; 
kcnt ++ ; 
} else if ( ( consec == 0 ) && ( boustr == 0 ) ) { 
idxarr = kx * jcnt + icnt ; 
} else if ( ( consec == 1 ) && ( boustr == 1 ) ) { 
itmp = jcnt ; 
if ( ( idrct == 1 ) && ( kx % 2 == 0 ) ) { 
itmp = ky - jcnt - 1 ; 
idxarr = ky * icnt + itmp ; 
itmp = ( itmp != jcnt ) 
? jcnt 
: ky - jcnt - 1 ; 
} else if ( ( consec == 0 ) && ( boustr == 1 ) ) { 
if ( jdrct == 0 ) { 
if ( ( idrct == 0 ) && ( ky % 2 == 0 ) ) { 
if ( ( idrct == 1 ) && ( ky % 2 == 0 ) ) { 
ibeg = ( ibeg != 0 ) 
? 0 
: kx - 1 ; 
iinc = ( iinc != 1 ) 
? 1 
: - 1 ; 
return fgrid ; 
} private int bits2UInt ( int nb ) throws IOException { 
int bitsLeft = nb ; 
if ( bitPos == 0 ) { 
getNextByte ( ) ; 
bitPos = 8 ; 
int shift = bitsLeft - bitPos ; 
if ( shift > 0 ) { 
result |= bitBuf << shift ; 
bitsLeft -= bitPos ; 
result |= bitBuf > > - shift ; 
bitPos -= bitsLeft ; 
bitBuf &= 0xff > > ( 8 - bitPos ) ; 
} private void getNextByte ( ) throws IOException { 
if ( ! needToSwap ) { 
bitBuf = rf . read ( ) ; 
if ( next == 3 ) { 
bitBuf = ch3 ; 
} else if ( next == 2 ) { 
bitBuf = ch2 ; 
} else if ( next == 1 ) { 
bitBuf = ch1 ; 
ch1 = rf . read ( ) ; 
ch2 = rf . read ( ) ; 
ch3 = rf . read ( ) ; 
ch4 = rf . read ( ) ; 
bitBuf = ch4 ; 
next = 4 ; 
next -- ; 
} public void addVariable ( BaseType v ) { 
vals = v . newPrimitiveVector ( ) ; 
setClearName ( v . getClearName ( ) ) ; 
v . setParent ( this ) ; 
setContainerVar ( v ) ; 
} public void printDecl ( PrintWriter os , String space , 
boolean print_semi , boolean constrained ) { 
os . print ( space + getTypeName ( ) ) ; 
} public void printVal ( PrintWriter os , String space , boolean print_decl_p ) { 
if ( print_decl_p ) { 
printDecl ( os , space , false ) ; 
vals . printVal ( os , "" ) ; 
if ( print_decl_p ) 
os . println ( "};" ) ; 
os . print ( "}" ) ; 
} public synchronized void deserialize ( DataInputStream source , 
ServerVersion sv , 
StatusUI statusUI ) 
throws IOException , 
EOFException , 
DataReadException { 
int length ; 
length = source . readInt ( ) ; 
if ( ! ( vals instanceof BaseTypePrimitiveVector ) ) { 
int length2 = source . readInt ( ) ; 
if ( length != length2 ) { 
if ( statusUI != null ) 
statusUI . incrementByteCount ( 8 ) ; 
vals . setLength ( length ) ; 
vals . deserialize ( source , sv , statusUI ) ; 
} public void externalize ( DataOutputStream sink ) throws IOException { 
int length = vals . getLength ( ) ; 
sink . writeInt ( length ) ; 
vals . externalize ( sink ) ; 
DVector v = ( DVector ) super . cloneDAG ( map ) ; 
v . vals = ( PrimitiveVector ) cloneDAG ( map , vals ) ; 
v . containedvar = ( BaseType ) cloneDAG ( map , containedvar ) ; 
} public static CalendarDate of ( Calendar cal , int year , int monthOfYear , int dayOfMonth , int hourOfDay , int minuteOfHour , int secondOfMinute ) { 
Chronology base = Calendar . getChronology ( cal ) ; 
DateTime dt = new DateTime ( year , monthOfYear , dayOfMonth , hourOfDay , minuteOfHour , secondOfMinute , base ) ; 
if ( ! Calendar . isDefaultChronology ( cal ) ) dt = dt . withChronology ( Calendar . getChronology ( cal ) ) ; 
dt = dt . withZone ( DateTimeZone . UTC ) ; 
return new CalendarDate ( cal , dt ) ; 
} public static CalendarDate of ( java . util . Date date ) { 
DateTime dt = new DateTime ( date , DateTimeZone . UTC ) ; 
return new CalendarDate ( null , dt ) ; 
} public static CalendarDate of ( long msecs ) { 
DateTime dt = new DateTime ( msecs , DateTimeZone . UTC ) ; 
} public static CalendarDate of ( Calendar cal , long msecs ) { 
DateTime dt = new DateTime ( msecs , base ) ; 
public static CalendarDate parseUdunitsOrIso ( String calendarName , String isoOrUdunits ) { 
CalendarDate result ; 
result = parseISOformat ( calendarName , isoOrUdunits ) ; 
result = parseUdunits ( calendarName , isoOrUdunits ) ; 
} public static CalendarDate parseISOformat ( String calendarName , String isoDateString ) { 
Calendar cal = Calendar . get ( calendarName ) ; 
if ( cal == null ) cal = Calendar . getDefault ( ) ; 
return CalendarDateFormatter . isoStringToCalendarDate ( cal , isoDateString ) ; 
} public static CalendarDate parseUdunits ( String calendarName , String udunits ) { 
if ( pos < 0 ) return null ; 
String valString = udunits . substring ( 0 , pos ) . trim ( ) ; 
String unitString = udunits . substring ( pos + 1 ) . trim ( ) ; 
CalendarDateUnit cdu = CalendarDateUnit . of ( calendarName , unitString ) ; 
double val = Double . parseDouble ( valString ) ; 
return cdu . makeCalendarDate ( val ) ; 
} public int getFieldValue ( CalendarPeriod . Field fld ) { 
switch ( fld ) { 
case Day : return dateTime . get ( DateTimeFieldType . dayOfMonth ( ) ) ; 
case Hour : return dateTime . get ( DateTimeFieldType . hourOfDay ( ) ) ; 
case Millisec : return dateTime . get ( DateTimeFieldType . millisOfSecond ( ) ) ; 
case Minute : return dateTime . get ( DateTimeFieldType . minuteOfHour ( ) ) ; 
case Month : return dateTime . get ( DateTimeFieldType . monthOfYear ( ) ) ; 
case Second : return dateTime . get ( DateTimeFieldType . secondOfMinute ( ) ) ; 
case Year : return dateTime . get ( DateTimeFieldType . year ( ) ) ; 
} public CalendarDate add ( CalendarPeriod period ) { 
switch ( period . getField ( ) ) { 
case Millisec : 
return new CalendarDate ( cal , dateTime . plusMillis ( period . getValue ( ) ) ) ; 
case Second : 
return new CalendarDate ( cal , dateTime . plusSeconds ( period . getValue ( ) ) ) ; 
case Minute : 
return new CalendarDate ( cal , dateTime . plusMinutes ( period . getValue ( ) ) ) ; 
case Hour : 
return new CalendarDate ( cal , dateTime . plusHours ( period . getValue ( ) ) ) ; 
case Day : 
return new CalendarDate ( cal , dateTime . plusDays ( period . getValue ( ) ) ) ; 
case Month : 
return new CalendarDate ( cal , dateTime . plusMonths ( period . getValue ( ) ) ) ; 
case Year : 
return new CalendarDate ( cal , dateTime . plusYears ( period . getValue ( ) ) ) ; 
} public CalendarDate subtract ( CalendarPeriod period ) { 
return new CalendarDate ( cal , dateTime . minusMillis ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusSeconds ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusMinutes ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusHours ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusDays ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusMonths ( period . getValue ( ) ) ) ; 
return new CalendarDate ( cal , dateTime . minusYears ( period . getValue ( ) ) ) ; 
} public CalendarDate truncate ( CalendarPeriod . Field fld ) { 
return CalendarDate . of ( cal , dateTime . getYear ( ) , dateTime . getMonthOfYear ( ) , dateTime . getDayOfMonth ( ) , dateTime . getHourOfDay ( ) , dateTime . getMinuteOfHour ( ) , 0 ) ; 
return CalendarDate . of ( cal , dateTime . getYear ( ) , dateTime . getMonthOfYear ( ) , dateTime . getDayOfMonth ( ) , dateTime . getHourOfDay ( ) , 0 , 0 ) ; 
return CalendarDate . of ( cal , dateTime . getYear ( ) , dateTime . getMonthOfYear ( ) , dateTime . getDayOfMonth ( ) , 0 , 0 , 0 ) ; 
return CalendarDate . of ( cal , dateTime . getYear ( ) , dateTime . getMonthOfYear ( ) , 1 , 0 , 0 , 0 ) ; 
return CalendarDate . of ( cal , dateTime . getYear ( ) , 1 , 1 , 0 , 0 , 0 ) ; 
} public long getDifference ( CalendarDate o , CalendarPeriod . Field fld ) { 
return getDifferenceInMsecs ( o ) ; 
return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_SECOND ) ; 
return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_MINUTE ) ; 
return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_HOUR ) ; 
return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_DAY ) ; 
int tmonth = getFieldValue ( CalendarPeriod . Field . Month ) ; 
int omonth = o . getFieldValue ( CalendarPeriod . Field . Month ) ; 
int years = ( int ) this . getDifference ( o , CalendarPeriod . Field . Year ) ; 
return tmonth - omonth + 12 * years ; 
int tyear = getFieldValue ( CalendarPeriod . Field . Year ) ; 
int oyear = o . getFieldValue ( CalendarPeriod . Field . Year ) ; 
return tyear - oyear ; 
return dateTime . getMillis ( ) - o . dateTime . getMillis ( ) ; 
} Map < Variable , Array > 
create ( ) 
List < DapVariable > topvars = this . dmr . getTopVariables ( ) ; 
Map < Variable , Array > map = null ; 
for ( DapVariable var : topvars ) { 
DataCursor cursor = this . dsp . getVariableData ( var ) ; 
Array array = createVar ( cursor ) ; 
Variable cdmvar = ( Variable ) nodemap . get ( var ) ; 
arraymap . put ( cdmvar , array ) ; 
return this . arraymap ; 
} protected CDMArrayAtomic 
createAtomicVar ( DataCursor data ) 
CDMArrayAtomic array = new CDMArrayAtomic ( data ) ; 
} protected CDMArrayStructure 
createStructure ( DataCursor data ) 
CDMArrayStructure arraystruct = new CDMArrayStructure ( this . cdmroot , data ) ; 
DapVariable var = ( DapVariable ) data . getTemplate ( ) ; 
DapStructure struct = ( DapStructure ) var . getBaseType ( ) ; 
int nmembers = struct . getFields ( ) . size ( ) ; 
List < DapDimension > dimset = var . getDimensions ( ) ; 
Odometer odom = Odometer . factory ( DapUtil . dimsetToSlices ( dimset ) ) ; 
while ( odom . hasNext ( ) ) { 
Index index = odom . next ( ) ; 
long offset = index . index ( ) ; 
DataCursor [ ] cursors = ( DataCursor [ ] ) data . read ( index ) ; 
DataCursor ithelement = cursors [ 0 ] ; 
for ( int f = 0 ; f < nmembers ; f ++ ) { 
DataCursor dc = ( DataCursor ) ithelement . readField ( f ) ; 
Array afield = createVar ( dc ) ; 
arraystruct . add ( offset , f , afield ) ; 
return arraystruct ; 
} protected CDMArraySequence 
createSequence ( DataCursor data ) 
CDMArraySequence arrayseq = new CDMArraySequence ( this . cdmroot , data ) ; 
DapSequence template = ( DapSequence ) var . getBaseType ( ) ; 
long dimsize = DapUtil . dimProduct ( dimset ) ; 
int nfields = template . getFields ( ) . size ( ) ; 
odom . next ( ) ; 
DataCursor seq = ( ( DataCursor [ ] ) data . read ( odom . indices ( ) ) ) [ 0 ] ; 
long nrecords = seq . getRecordCount ( ) ; 
for ( int r = 0 ; r < nrecords ; r ++ ) { 
DataCursor rec = seq . readRecord ( r ) ; 
for ( int f = 0 ; f < nfields ; f ++ ) { 
DataCursor dc = rec . readField ( f ) ; 
arrayseq . add ( r , f , afield ) ; 
return arrayseq ; 
} public void doonce ( HttpServletRequest req ) 
throws SendError 
if ( once ) 
super . initOnce ( req ) ; 
if ( this . downloaddir == null ) 
this . downloaddirname = new File ( this . downloaddir ) . getName ( ) ; 
File downform = null ; 
downform = tdsContext . getDownloadForm ( ) ; 
if ( downform == null ) { 
File root = tdsContext . getServletRootDirectory ( ) ; 
downform = new File ( root , DEFAULTDOWNLOADFORM ) ; 
this . downloadform = loadForm ( downform ) ; 
throw new SendError ( HttpStatus . SC_PRECONDITION_FAILED , ioe ) ; 
} public void setup ( HttpServletRequest req , HttpServletResponse resp ) 
this . req = req ; 
this . res = resp ; 
if ( ! once ) 
doonce ( req ) ; 
this . params = new DownloadParameters ( req ) ; 
throw new SendError ( res . SC_BAD_REQUEST , ioe ) ; 
} @ RequestMapping ( value = "**" , method = RequestMethod . GET ) 
public void 
doGet ( HttpServletRequest req , HttpServletResponse res ) 
throws ServletException 
setup ( req , res ) ; 
String sresult = null ; 
switch ( this . params . command ) { 
case DOWNLOAD : 
String fulltargetpath = download ( ) ; 
if ( this . params . fromform ) { 
Map < String , String > result = new HashMap < > ( ) ; 
result . put ( "download" , fulltargetpath ) ; 
sresult = mapToString ( result , true , "download" ) ; 
sendOK ( sresult ) ; 
} catch ( SendError se ) { 
throw se ; 
case INQUIRE : 
sresult = inquire ( ) ; 
case NONE : 
sendError ( se ) ; 
String msg = getStackTrace ( e ) ; 
sendError ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR , msg , e ) ; 
} protected void 
makeNetcdf4 ( NetcdfFile ncfile , String target ) 
CancelTaskImpl cancel = new CancelTaskImpl ( ) ; 
FileWriter2 writer = new FileWriter2 ( ncfile , target , 
NetcdfFileWriter . Version . netcdf4 , 
chunking ) ; 
writer . getNetcdfFileWriter ( ) . setLargeFile ( true ) ; 
NetcdfFile ncfileOut = writer . write ( cancel ) ; 
if ( ncfileOut != null ) ncfileOut . close ( ) ; 
cancel . setDone ( true ) ; 
throw ioe ; 
} static protected String escapeString ( String s ) 
StringBuilder buf = new StringBuilder ( ) ; 
for ( int i = 0 ; i < s . length ( ) ; i ++ ) { 
int c = s . charAt ( i ) ; 
buf . append ( "\\\"" ) ; 
case '\\' : 
buf . append ( "\\\\" ) ; 
case '\n' : 
buf . append ( '\n' ) ; 
case '\r' : 
buf . append ( '\r' ) ; 
case '\t' : 
case '\f' : 
buf . append ( '\f' ) ; 
buf . append ( String . format ( "\\x%02x" , ( c & 0xff ) ) ) ; 
buf . append ( ( char ) c ) ; 
return buf . toString ( ) ; 
protected String 
buildForm ( String msg ) 
StringBuilder svc = new StringBuilder ( ) ; 
svc . append ( this . server ) ; 
svc . append ( "/" ) ; 
svc . append ( this . threddsname ) ; 
String form = String . format ( this . downloadform , 
svc . toString ( ) , 
msg 
return form ; 
} static public List < Slice > 
createSlices ( List < Range > rangelist ) 
throws dap4 . core . util . DapException 
List < Slice > slices = new ArrayList < Slice > ( rangelist . size ( ) ) ; 
for ( int i = 0 ; i < rangelist . size ( ) ; i ++ ) { 
Range r = rangelist . get ( i ) ; 
int stride = r . stride ( ) ; 
int first = r . first ( ) ; 
int n = r . length ( ) ; 
int stop = first + ( n * stride ) ; 
Slice cer = new Slice ( first , stop - 1 , stride ) ; 
slices . add ( cer ) ; 
return slices ; 
} static public boolean 
isWhole ( List < Range > rangelist , List < DapDimension > dimset , int start , int stop ) 
int rsize = ( rangelist == null ? 0 : rangelist . size ( ) ) ; 
if ( rsize != dimset . size ( ) ) 
if ( rsize == 0 ) 
if ( start < 0 || stop < start || stop > rsize ) 
for ( int i = start ; i < stop ; i ++ ) { 
DapDimension d = dimset . get ( i ) ; 
if ( r . stride ( ) != 1 || r . first ( ) != 0 || r . length ( ) != d . getSize ( ) ) 
isWhole ( List < Range > rangelist , List < Slice > slices ) 
if ( rangelist . size ( ) != slices . size ( ) ) 
Slice slice = slices . get ( i ) ; 
if ( r . stride ( ) != 1 || r . first ( ) != 0 || r . length ( ) != slice . getCount ( ) ) 
isWhole ( List < Range > rangelist , Variable var ) 
List < Dimension > dimset = var . getDimensions ( ) ; 
if ( rangelist . size ( ) != dimset . size ( ) ) 
Dimension dim = dimset . get ( i ) ; 
if ( r . stride ( ) != 1 || r . first ( ) != 0 || r . length ( ) != dim . getLength ( ) ) 
} static public NetcdfFile unwrapfile ( NetcdfFile file ) 
if ( file instanceof NetcdfDataset ) { 
NetcdfDataset ds = ( NetcdfDataset ) file ; 
file = ds . getReferencedFile ( ) ; 
if ( file == null ) break ; 
} else break ; 
return file ; 
containsVLEN ( List < Dimension > dimset ) 
if ( dimset == null ) return false ; 
for ( Dimension dim : dimset ) { 
if ( dim . isVariableLength ( ) ) 
} static public int [ ] 
computeEffectiveShape ( List < DapDimension > dimset ) 
if ( dimset == null || dimset . size ( ) == 0 ) 
return new int [ 0 ] ; 
int effectiverank = dimset . size ( ) ; 
int [ ] shape = new int [ effectiverank ] ; 
for ( int i = 0 ; i < effectiverank ; i ++ ) { 
shape [ i ] = ( int ) dimset . get ( i ) . getSize ( ) ; 
return shape ; 
} static public long 
extractLongValue ( TypeSort atomtype , DataCursor dataset , Index index ) 
Object result ; 
result = dataset . read ( index ) ; 
long lvalue = CDMTypeFcns . extract ( atomtype , result ) ; 
return lvalue ; 
} static public double 
extractDoubleValue ( TypeSort atomtype , DataCursor dataset , Index index ) 
double dvalue = 0.0 ; 
if ( atomtype . isIntegerType ( ) || atomtype . isEnumType ( ) ) { 
long lvalue = extractLongValue ( atomtype , dataset , index ) ; 
dvalue = ( double ) lvalue ; 
} else if ( atomtype == TypeSort . Float32 ) { 
dvalue = ( double ) ( ( Float ) result ) . floatValue ( ) ; 
} else if ( atomtype == TypeSort . Float64 ) { 
dvalue = ( ( Double ) result ) . doubleValue ( ) ; 
throw new ForbiddenConversionException ( ) ; 
return dvalue ; 
} static public Object 
convertVector ( DapType dsttype , DapType srctype , Object src ) 
TypeSort srcatomtype = srctype . getAtomicType ( ) ; 
TypeSort dstatomtype = dsttype . getAtomicType ( ) ; 
if ( srcatomtype == dstatomtype ) { 
return src ; 
if ( srcatomtype . isIntegerType ( ) 
&& TypeSort . getSignedVersion ( srcatomtype ) == TypeSort . getSignedVersion ( dstatomtype ) ) 
Object result = CDMTypeFcns . convert ( dstatomtype , srcatomtype , src ) ; 
if ( result == null ) 
} static public String 
getChecksumString ( byte [ ] checksum ) 
for ( int i = 0 ; i < checksum . length ; i ++ ) { 
byte b = checksum [ i ] ; 
buf . append ( hexchars . charAt ( b > > 4 ) ) ; 
buf . append ( hexchars . charAt ( b & 0xF ) ) ; 
} static public List < Range > 
dimsetToRanges ( List < DapDimension > dimset ) 
if ( dimset == null ) 
List < Range > ranges = new ArrayList < > ( ) ; 
for ( int i = 0 ; i < dimset . size ( ) ; i ++ ) { 
DapDimension dim = dimset . get ( i ) ; 
Range r = new Range ( dim . getShortName ( ) , 0 , ( int ) dim . getSize ( ) - 1 , 1 ) ; 
ranges . add ( r ) ; 
} catch ( InvalidRangeException ire ) { 
throw new dap4 . core . util . DapException ( ire ) ; 
return ranges ; 
} public double convertTo ( double value , TimeUnit outputUnit ) throws ConversionException { 
return uu . convertTo ( value , outputUnit . uu ) ; 
} public Date add ( Date d ) { 
Calendar cal = Calendar . getInstance ( ) ; 
cal . setTime ( d ) ; 
cal . add ( Calendar . SECOND , ( int ) getValueInSeconds ( ) ) ; 
return cal . getTime ( ) ; 
protected Unit myMultiplyBy ( final Unit that ) throws MultiplyException { 
return that instanceof ScaledUnit 
? new ScaledUnit ( getScale ( ) * ( ( ScaledUnit ) that ) . getScale ( ) , 
getUnit ( ) . multiplyBy ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) 
: new ScaledUnit ( getScale ( ) , getUnit ( ) . multiplyBy ( that ) ) ; 
protected Unit myDivideBy ( final Unit that ) throws OperationException { 
? new ScaledUnit ( getScale ( ) / ( ( ScaledUnit ) that ) . getScale ( ) , 
getUnit ( ) . divideBy ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) 
: new ScaledUnit ( getScale ( ) , getUnit ( ) . divideBy ( that ) ) ; 
protected Unit myDivideInto ( final Unit that ) throws OperationException { 
? new ScaledUnit ( ( ( ScaledUnit ) that ) . getScale ( ) / getScale ( ) , 
getUnit ( ) . divideInto ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) 
: new ScaledUnit ( 1 / getScale ( ) , getUnit ( ) . divideInto ( that ) ) ; 
protected Unit myRaiseTo ( final int power ) throws RaiseException { 
return new ScaledUnit ( Math . pow ( getScale ( ) , power ) , getUnit ( ) . raiseTo ( 
power ) ) ; 
} public double toDerivedUnit ( final double amount ) throws ConversionException { 
if ( ! ( _unit instanceof DerivableUnit ) ) { 
throw new ConversionException ( this , getDerivedUnit ( ) ) ; 
return ( ( DerivableUnit ) _unit ) . toDerivedUnit ( amount * getScale ( ) ) ; 
} public float [ ] toDerivedUnit ( final float [ ] input , final float [ ] output ) 
throws ConversionException { 
final float scale = ( float ) getScale ( ) ; 
for ( int i = input . length ; -- i >= 0 ; ) { 
output [ i ] = input [ i ] * scale ; 
return ( ( DerivableUnit ) getUnit ( ) ) . toDerivedUnit ( output , output ) ; 
} public double fromDerivedUnit ( final double amount ) 
throw new ConversionException ( getDerivedUnit ( ) , this ) ; 
return ( ( DerivableUnit ) getUnit ( ) ) . fromDerivedUnit ( amount ) / getScale ( ) ; 
} public String getCanonicalString ( ) { 
return DerivedUnitImpl . DIMENSIONLESS . equals ( _unit ) 
? Double . toString ( getScale ( ) ) 
} public static void main ( final String [ ] args ) throws Exception { 
final BaseUnit meter = BaseUnit . getOrCreate ( UnitName . newUnitName ( 
"meter" , null , "m" ) , BaseQuantity . LENGTH ) ; 
final ScaledUnit nauticalMile = new ScaledUnit ( 1852f , meter ) ; 
System . out . println ( "nauticalMile.getUnit().equals(meter)=" 
+ nauticalMile . getUnit ( ) . equals ( meter ) ) ; 
final ScaledUnit nauticalMileMeter = ( ScaledUnit ) nauticalMile 
. multiplyBy ( meter ) ; 
System . out . println ( "nauticalMileMeter.divideBy(nauticalMile)=" 
+ nauticalMileMeter . divideBy ( nauticalMile ) ) ; 
System . out . println ( "meter.divideBy(nauticalMile)=" 
+ meter . divideBy ( nauticalMile ) ) ; 
System . out 
. println ( "nauticalMile.raiseTo(2)=" + nauticalMile . raiseTo ( 2 ) ) ; 
System . out . println ( "nauticalMile.toDerivedUnit(1.)=" 
+ nauticalMile . toDerivedUnit ( 1. ) ) ; 
+ nauticalMile . toDerivedUnit ( new float [ ] { 1 , 2 , 3 } , 
new float [ 3 ] ) [ 1 ] ) ; 
System . out . println ( "nauticalMile.fromDerivedUnit(1852.)=" 
+ nauticalMile . fromDerivedUnit ( 1852. ) ) ; 
+ nauticalMile . fromDerivedUnit ( new float [ ] { 1852 } , 
new float [ 1 ] ) [ 0 ] ) ; 
System . out . println ( "nauticalMile.equals(nauticalMile)=" 
+ nauticalMile . equals ( nauticalMile ) ) ; 
final ScaledUnit nautical2Mile = new ScaledUnit ( 2 , nauticalMile ) ; 
System . out . println ( "nauticalMile.equals(nautical2Mile)=" 
+ nauticalMile . equals ( nautical2Mile ) ) ; 
System . out . println ( "nauticalMile.isDimensionless()=" 
+ nauticalMile . isDimensionless ( ) ) ; 
final BaseUnit radian = BaseUnit . getOrCreate ( UnitName . newUnitName ( 
"radian" , null , "rad" ) , BaseQuantity . PLANE_ANGLE ) ; 
final ScaledUnit degree = new ScaledUnit ( 3.14159 / 180 , radian ) ; 
System . out . println ( "degree.isDimensionless()=" 
+ degree . isDimensionless ( ) ) ; 
} public Array readData ( SectionIterable want ) throws IOException , InvalidRangeException { 
if ( vindex instanceof PartitionCollectionImmutable . VariableIndexPartitioned ) 
return readDataFromPartition ( ( PartitionCollectionImmutable . VariableIndexPartitioned ) vindex , want ) ; 
return readDataFromCollection ( vindex , want ) ; 
} private Array readDataFromCollection ( GribCollectionImmutable . VariableIndex vindex , SectionIterable want ) throws IOException { 
vindex . readRecords ( ) ; 
int rank = want . getRank ( ) ; 
int sectionLen = rank - 2 ; 
SectionIterable sectionWanted = want . subSection ( 0 , sectionLen ) ; 
int resultIndex = 0 ; 
for ( int sourceIndex : sectionWanted ) { 
GribCollectionImmutable . Record record = vindex . getRecordAt ( sourceIndex ) ; 
if ( Grib . debugRead ) 
records . add ( new DataRecord ( resultIndex , record , vindex . group . getGdsHorizCoordSys ( ) ) ) ; 
resultIndex ++ ; 
DataReceiverIF dataReceiver = new DataReceiver ( want . getShape ( ) , want . getRange ( rank - 2 ) , want . getRange ( rank - 1 ) ) ; 
read ( dataReceiver ) ; 
return dataReceiver . getArray ( ) ; 
} private Array readDataFromPartition ( PartitionCollectionImmutable . VariableIndexPartitioned vindexP , SectionIterable section ) throws IOException { 
int rank = section . getRank ( ) ; 
SectionIterable sectionWanted = section . subSection ( 0 , rank - 2 ) ; 
SectionIterable . SectionIterator iterWanted = sectionWanted . getIterator ( ) ; 
int [ ] indexWanted = new int [ rank - 2 ] ; 
int [ ] useIndex = indexWanted ; 
int resultPos = 0 ; 
while ( iterWanted . hasNext ( ) ) { 
iterWanted . next ( indexWanted ) ; 
if ( vindexP . getType ( ) == GribCollectionImmutable . Type . MRUTP ) { 
CoordinateTime2D time2D = ( CoordinateTime2D ) vindexP . getCoordinateTime ( ) ; 
assert time2D != null ; 
int [ ] timeIndices = time2D . getTimeIndicesFromMrutp ( indexWanted [ 0 ] ) ; 
int [ ] indexReallyWanted = new int [ indexWanted . length + 1 ] ; 
indexReallyWanted [ 0 ] = timeIndices [ 0 ] ; 
indexReallyWanted [ 1 ] = timeIndices [ 1 ] ; 
System . arraycopy ( indexWanted , 1 , indexReallyWanted , 2 , indexWanted . length - 1 ) ; 
useIndex = indexReallyWanted ; 
PartitionCollectionImmutable . DataRecord record = vindexP . getDataRecord ( useIndex ) ; 
resultPos ++ ; 
record . resultIndex = resultPos ; 
records . add ( record ) ; 
DataReceiverIF dataReceiver = new DataReceiver ( section . getShape ( ) , section . getRange ( rank - 2 ) , section . getRange ( rank - 1 ) ) ; 
readPartitioned ( dataReceiver ) ; 
} public Array readData2 ( CoordsSet want , RangeIterator yRange , RangeIterator xRange ) throws IOException { 
return readDataFromPartition2 ( ( PartitionCollectionImmutable . VariableIndexPartitioned ) vindex , want , yRange , xRange ) ; 
return readDataFromCollection2 ( vindex , want , yRange , xRange ) ; 
} private void read ( DataReceiverIF dataReceiver ) throws IOException { 
Collections . sort ( records ) ; 
int currFile = - 1 ; 
RandomAccessFile rafData = null ; 
for ( DataRecord dr : records ) { 
if ( Grib . debugIndexOnly || Grib . debugGbxIndexOnly ) { 
GribIosp . debugIndexOnlyCount ++ ; 
currentDataRecord = dr . record ; 
currentDataRafFilename = gribCollection . getDataRafFilename ( dr . record . fileno ) ; 
if ( Grib . debugIndexOnlyShow ) dr . show ( gribCollection ) ; 
dataReceiver . setDataToZero ( ) ; 
if ( dr . record . fileno != currFile ) { 
if ( rafData != null ) rafData . close ( ) ; 
rafData = gribCollection . getDataRaf ( dr . record . fileno ) ; 
currFile = dr . record . fileno ; 
if ( dr . record . pos == GribCollectionMutable . MISSING_RECORD ) continue ; 
if ( GribDataReader . validator != null && dr . validation != null && rafData != null ) { 
GribDataReader . validator . validate ( gribCollection . cust , rafData , dr . record . pos + dr . record . drsOffset , dr . validation ) ; 
} else if ( show && rafData != null ) { 
show ( dr . validation ) ; 
show ( rafData , dr . record . pos + dr . record . drsOffset ) ; 
float [ ] data = readData ( rafData , dr ) ; 
GdsHorizCoordSys hcs = vindex . group . getGdsHorizCoordSys ( ) ; 
dataReceiver . addData ( data , dr . resultIndex , hcs . nx ) ; 
} protected StationHelper getStationHelper ( ) { 
if ( stationHelper == null ) { 
stationHelper = createStationHelper ( ) ; 
return stationHelper ; 
public StationTimeSeriesFeatureCollection subset ( ucar . unidata . geoloc . LatLonRect boundingBox ) throws IOException { 
return subset ( getStationFeatures ( boundingBox ) ) ; 
public PointFeatureCollection flatten ( List < String > stationNames , CalendarDateRange dateRange , List < VariableSimpleIF > varList ) throws IOException { 
if ( ( stationNames == null ) || ( stationNames . size ( ) == 0 ) ) 
return new StationTimeSeriesCollectionFlattened ( this , dateRange ) ; 
List < StationFeature > subsetStations = getStationHelper ( ) . getStationFeaturesFromNames ( stationNames ) ; 
return new StationTimeSeriesCollectionFlattened ( new StationSubset ( this , subsetStations ) , dateRange ) ; 
} public InvService findService ( String name ) { 
if ( name == null ) return null ; 
for ( InvService s : services ) { 
if ( name . equals ( s . getName ( ) ) ) return s ; 
if ( s . getServiceType ( ) == ServiceType . COMPOUND ) { 
InvService result = s . findNestedService ( name ) ; 
} public URI resolveUri ( String uriString ) throws URISyntaxException { 
URI want = new URI ( uriString ) ; 
if ( ( baseURI == null ) || want . isAbsolute ( ) ) 
return want ; 
String scheme = baseURI . getScheme ( ) ; 
if ( ( scheme != null ) && scheme . equals ( "file" ) ) { 
String baseString = baseURI . toString ( ) ; 
if ( ( uriString . length ( ) > 0 ) && ( uriString . charAt ( 0 ) == '#' ) ) 
return new URI ( baseString + uriString ) ; 
int pos = baseString . lastIndexOf ( '/' ) ; 
if ( pos > 0 ) { 
String r = baseString . substring ( 0 , pos + 1 ) + uriString ; 
return new URI ( r ) ; 
return baseURI . resolve ( want ) ; 
if ( valueS == null ) { 
StringBuilder sbuff = new StringBuilder ( ) ; 
for ( double v : valueD ) { 
valueS = sbuff . toString ( ) ; 
return valueS ; 
} public int getGateSize ( int datatype ) { 
switch ( datatype ) { 
case REFLECTIVITY : 
return ( ( int ) reflect_gate_size ) ; 
case VELOCITY_HI : 
case VELOCITY_LOW : 
case SPECTRUM_WIDTH : 
return ( ( int ) doppler_gate_size ) ; 
case REFLECTIVITY_HIGH : 
return ( ( int ) reflectHR_gate_size ) ; 
case VELOCITY_HIGH : 
return ( ( int ) velocityHR_gate_size ) ; 
case SPECTRUM_WIDTH_HIGH : 
return ( ( int ) spectrumHR_gate_size ) ; 
case DIFF_REFLECTIVITY_HIGH : 
return ( ( int ) zdrHR_gate_size ) ; 
case DIFF_PHASE : 
return ( ( int ) phiHR_gate_size ) ; 
case CORRELATION_COEFFICIENT : 
return ( ( int ) rhoHR_gate_size ) ; 
} public int getGateStart ( int datatype ) { 
return ( ( int ) reflect_first_gate ) ; 
return ( ( int ) doppler_first_gate ) ; 
return ( ( int ) reflectHR_first_gate ) ; 
return ( ( int ) velocityHR_first_gate ) ; 
return ( ( int ) spectrumHR_first_gate ) ; 
return ( ( int ) zdrHR_first_gate ) ; 
return ( ( int ) phiHR_first_gate ) ; 
return ( ( int ) rhoHR_first_gate ) ; 
} public int getGateCount ( int datatype ) { 
return ( ( int ) reflect_gate_count ) ; 
return ( ( int ) doppler_gate_count ) ; 
return ( ( int ) reflectHR_gate_count ) ; 
return ( ( int ) velocityHR_gate_count ) ; 
return ( ( int ) spectrumHR_gate_count ) ; 
return ( ( int ) zdrHR_gate_count ) ; 
return ( ( int ) phiHR_gate_count ) ; 
return ( ( int ) rhoHR_gate_count ) ; 
} public void readData ( RandomAccessFile raf , int datatype , Range gateRange , IndexIterator ii ) throws IOException { 
long offset = message_offset ; 
offset += MESSAGE_HEADER_SIZE ; 
offset += getDataOffset ( datatype ) ; 
raf . seek ( offset ) ; 
int dataCount = getGateCount ( datatype ) ; 
if ( datatype == DIFF_PHASE ) { 
short [ ] data = new short [ dataCount ] ; 
raf . readShort ( data , 0 , dataCount ) ; 
for ( int gateIdx : gateRange ) { 
if ( gateIdx >= dataCount ) 
ii . setShortNext ( MISSING_DATA ) ; 
ii . setShortNext ( data [ gateIdx ] ) ; 
byte [ ] data = new byte [ dataCount ] ; 
ii . setByteNext ( MISSING_DATA ) ; 
ii . setByteNext ( data [ gateIdx ] ) ; 
} public short [ ] convertunsignedByte2Short ( byte [ ] inb ) { 
int len = inb . length ; 
short [ ] outs = new short [ len ] ; 
for ( byte b : inb ) { 
outs [ i ++ ] = convertunsignedByte2Short ( b ) ; 
return outs ; 
} public void writeXML ( NetcdfDataset ncd , OutputStream os , boolean showCoords , String uri ) throws IOException { 
XMLOutputter fmt = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; 
fmt . output ( makeDocument ( ncd , showCoords , uri ) , os ) ; 
} private Element makeVariable ( VariableDS var ) { 
Element varElem = new Element ( "variable" , thredds . client . catalog . Catalog . ncmlNS ) ; 
varElem . setAttribute ( "name" , var . getFullName ( ) ) ; 
StringBuffer buff = new StringBuffer ( ) ; 
List dims = var . getDimensions ( ) ; 
for ( int i = 0 ; i < dims . size ( ) ; i ++ ) { 
Dimension dim = ( Dimension ) dims . get ( i ) ; 
buff . append ( dim . getShortName ( ) ) ; 
if ( buff . length ( ) > 0 ) 
varElem . setAttribute ( "shape" , buff . toString ( ) ) ; 
DataType dt = var . getDataType ( ) ; 
if ( dt != null ) 
varElem . setAttribute ( "type" , dt . toString ( ) ) ; 
for ( Attribute att : var . getAttributes ( ) ) { 
varElem . addContent ( makeAttribute ( att , "attribute" ) ) ; 
if ( var . isMetadata ( ) ) 
varElem . addContent ( makeValues ( var ) ) ; 
List csys = var . getCoordinateSystems ( ) ; 
if ( csys . size ( ) > 0 ) { 
buff . setLength ( 0 ) ; 
for ( int i = 0 ; i < csys . size ( ) ; i ++ ) { 
CoordinateSystem cs = ( CoordinateSystem ) csys . get ( i ) ; 
buff . append ( cs . getName ( ) ) ; 
varElem . setAttribute ( "coordinateSystems" , buff . toString ( ) ) ; 
return varElem ; 
} public SubsetParams makeSubset ( ) { 
SubsetParams subset = new SubsetParams ( ) ; 
subset . set ( SubsetParams . variables , var ) ; 
if ( stns != null ) 
subset . set ( SubsetParams . stations , stns ) ; 
else if ( hasLatLonBB ( ) ) 
subset . set ( SubsetParams . latlonBB , getLatLonBoundingBox ( ) ) ; 
else if ( hasLatLonPoint ( ) ) 
subset . set ( SubsetParams . latlonPoint , new LatLonPointImpl ( getLatitude ( ) , getLongitude ( ) ) ) ; 
CalendarDate date = getRequestedDate ( Calendar . getDefault ( ) ) ; 
CalendarDateRange dateRange = getCalendarDateRange ( Calendar . getDefault ( ) ) ; 
if ( isAllTimes ( ) ) { 
subset . set ( SubsetParams . timeAll , true ) ; 
} else if ( date != null ) { 
subset . set ( SubsetParams . time , date ) ; 
} else if ( dateRange != null ) { 
subset . set ( SubsetParams . timeRange , dateRange ) ; 
subset . set ( SubsetParams . timePresent , true ) ; 
if ( timeWindow != null ) { 
CalendarPeriod period = CalendarPeriod . of ( timeWindow ) ; 
subset . set ( SubsetParams . timeWindow , period ) ; 
return subset ; 
} public Dimension preferredLayoutSize ( Container target ) { 
synchronized ( target . getTreeLock ( ) ) { 
Dimension dim = new Dimension ( 0 , 0 ) ; 
for ( int i = 0 ; i < target . getComponentCount ( ) ; i ++ ) { 
Component m = target . getComponent ( i ) ; 
if ( m . isVisible ( ) ) { 
Dimension d = m . getPreferredSize ( ) ; 
Point p = m . getLocation ( ) ; 
dim . width = Math . max ( dim . width , p . x + d . width ) ; 
dim . height = Math . max ( dim . height , p . y + d . height ) ; 
Insets insets = target . getInsets ( ) ; 
dim . width += insets . left + insets . right + getHgap ( ) * 2 ; 
dim . height += insets . top + insets . bottom + getVgap ( ) * 2 ; 
return dim ; 
} static CrawlableDataset verifyDescendantDataset ( CrawlableDataset ancestorCrDs , 
String path , 
CrawlableDatasetFilter filter ) 
if ( ! ancestorCrDs . isCollection ( ) ) 
if ( ! path . startsWith ( ancestorCrDs . getPath ( ) ) ) 
if ( path . length ( ) == ancestorCrDs . getPath ( ) . length ( ) ) 
return ancestorCrDs ; 
String remainingPath = path . substring ( ancestorCrDs . getPath ( ) . length ( ) ) ; 
if ( remainingPath . startsWith ( "/" ) ) 
remainingPath = remainingPath . substring ( 1 ) ; 
String [ ] pathSegments = remainingPath . split ( "/" ) ; 
CrawlableDataset curCrDs = ancestorCrDs ; 
for ( int i = 0 ; i < pathSegments . length ; i ++ ) 
curCrDs = curCrDs . getDescendant ( pathSegments [ i ] ) ; 
if ( filter != null ) 
if ( ! filter . accept ( curCrDs ) ) 
if ( ! curCrDs . exists ( ) ) 
return curCrDs ; 
Array psArray = readArray ( psVar , timeIndex ) ; 
if ( null == aArray ) { 
aArray = aVar . read ( ) ; 
bArray = bVar . read ( ) ; 
p0 = computeP0 ( ) ; 
int nz = ( int ) aArray . getSize ( ) ; 
Index aIndex = aArray . getIndex ( ) ; 
Index bIndex = bArray . getIndex ( ) ; 
if ( psArray . getRank ( ) == 3 ) 
psArray = psArray . reduce ( 0 ) ; 
int [ ] shape2D = psArray . getShape ( ) ; 
int ny = shape2D [ 0 ] ; 
int nx = shape2D [ 1 ] ; 
Index psIndex = psArray . getIndex ( ) ; 
ArrayDouble . D3 press = new ArrayDouble . D3 ( nz , ny , nx ) ; 
double ps ; 
for ( int z = 0 ; z < nz ; z ++ ) { 
double term1 = aArray . getDouble ( aIndex . set ( z ) ) * p0 ; 
if ( ! apUnits . equals ( units ) ) { 
term1 = convertPressureToPSUnits ( apUnits , term1 ) ; 
double bz = bArray . getDouble ( bIndex . set ( z ) ) ; 
for ( int y = 0 ; y < ny ; y ++ ) { 
for ( int x = 0 ; x < nx ; x ++ ) { 
ps = psArray . getDouble ( psIndex . set ( y , x ) ) ; 
press . set ( z , y , x , term1 + bz * ps ) ; 
return press ; 
ArrayDouble . D1 press = new ArrayDouble . D1 ( nz ) ; 
ps = psArray . getDouble ( psIndex . set ( yIndex , xIndex ) ) ; 
press . set ( z , term1 + bz * ps ) ; 
public ProjectionRect latLonToProjBB ( LatLonRect rect ) { 
BoundingBoxHelper bbhelper = new BoundingBoxHelper ( this , maxR ) ; 
return bbhelper . latLonToProjBB ( rect ) ; 
} static void tryit ( double want , double x ) { 
} public static String udunitsToUcum ( String udunits ) { 
if ( udunits == null ) { 
if ( sincePo > 0 ) { 
double baf [ ] = ErddapCalendar2 . getTimeBaseAndFactor ( udunits ) ; 
String u ; 
if ( Misc . nearlyEquals ( baf [ 1 ] , 0.001 , 1e-6 ) ) { 
u = "ms" ; 
} else if ( baf [ 1 ] == 1 ) { 
u = "s" ; 
} else if ( baf [ 1 ] == ErddapCalendar2 . SECONDS_PER_MINUTE ) { 
u = "min" ; 
} else if ( baf [ 1 ] == ErddapCalendar2 . SECONDS_PER_HOUR ) { 
u = "h" ; 
} else if ( baf [ 1 ] == ErddapCalendar2 . SECONDS_PER_DAY ) { 
u = "d" ; 
} else if ( baf [ 1 ] == 30 * ErddapCalendar2 . SECONDS_PER_DAY ) { 
u = "mo" ; 
} else if ( baf [ 1 ] == 360 * ErddapCalendar2 . SECONDS_PER_DAY ) { 
u = "a" ; 
u = udunitsToUcum ( udunits . substring ( 0 , sincePo ) ) ; 
return u + "{" + udunits . substring ( sincePo + 1 ) + "}" ; 
StringBuilder ucum = new StringBuilder ( ) ; 
int udLength = udunits . length ( ) ; 
int po = 0 ; 
while ( po < udLength ) { 
char ch = udunits . charAt ( po ) ; 
if ( isUdunitsLetter ( ch ) ) { 
int po2 = po + 1 ; 
while ( po2 < udLength && 
( isUdunitsLetter ( udunits . charAt ( po2 ) ) || udunits . charAt ( po2 ) == '_' || 
ErddapString2 . isDigit ( udunits . charAt ( po2 ) ) ) ) { 
po2 ++ ; 
String tUdunits = udunits . substring ( po , po2 ) ; 
po = po2 ; 
int firstDigit = tUdunits . length ( ) ; 
while ( firstDigit >= 1 && ErddapString2 . isDigit ( tUdunits . charAt ( firstDigit - 1 ) ) ) { 
firstDigit -- ; 
String exponent = tUdunits . substring ( firstDigit ) ; 
tUdunits = tUdunits . substring ( 0 , firstDigit ) ; 
String tUcum = oneUdunitsToUcum ( tUdunits ) ; 
if ( tUcum . equals ( "/" ) ) { 
char lastUcum = ucum . length ( ) == 0 ? ' ' : ucum . charAt ( ucum . length ( ) - 1 ) ; 
if ( lastUcum == '/' ) { 
ucum . setCharAt ( ucum . length ( ) - 1 , '.' ) ; 
} else if ( lastUcum == '.' ) { 
ucum . setCharAt ( ucum . length ( ) - 1 , '/' ) ; 
ucum . append ( '/' ) ; 
ucum . append ( tUcum ) ; 
ucum . append ( exponent ) ; 
if ( ch == '-' || ErddapString2 . isDigit ( ch ) ) { 
while ( po2 < udLength && ErddapString2 . isDigit ( udunits . charAt ( po2 ) ) ) { 
boolean hasDot = false ; 
if ( po2 < udLength - 1 && udunits . charAt ( po2 ) == '.' && ErddapString2 . isDigit ( udunits . charAt ( po2 + 1 ) ) ) { 
hasDot = true ; 
po2 += 2 ; 
boolean hasE = false ; 
if ( po2 < udLength - 1 && Character . toLowerCase ( udunits . charAt ( po2 ) ) == 'e' && 
( udunits . charAt ( po2 + 1 ) == '-' || ErddapString2 . isDigit ( udunits . charAt ( po2 + 1 ) ) ) ) { 
hasE = true ; 
String num = udunits . substring ( po , po2 ) ; 
if ( hasDot || hasE ) { 
int rational [ ] = ErddapString2 . toRational ( ErddapString2 . parseDouble ( num ) ) ; 
if ( rational [ 1 ] == Integer . MAX_VALUE ) { 
ucum . append ( num ) ; 
} else if ( rational [ 1 ] == 0 ) 
ucum . append ( rational [ 0 ] ) ; 
ucum . append ( rational [ 0 ] ) . append ( ".10^" ) . append ( rational [ 1 ] ) ; 
if ( lastUcum == '/' || lastUcum == '.' ) { 
ucum . append ( '.' ) ; 
po ++ ; 
if ( ch == '*' ) { 
if ( po < udLength && udunits . charAt ( po ) == '*' ) { 
ucum . append ( '^' ) ; 
if ( ch == '/' ) { 
if ( ch == '\"' ) { 
ucum . append ( "''" ) ; 
ucum . append ( ch ) ; 
return ucum . toString ( ) ; 
} private static String oneUdunitsToUcum ( String udunits ) { 
String oldUdunits = udunits ; 
MAIN : 
String tUcum = udHashMap . get ( udunits ) ; 
if ( tUcum != null ) { 
for ( int p = 0 ; p < nMetric ; p ++ ) { 
if ( udunits . startsWith ( metricName [ p ] ) ) { 
udunits = udunits . substring ( metricName [ p ] . length ( ) ) ; 
ucum . append ( metricAcronym [ p ] ) ; 
if ( udunits . length ( ) == 0 ) { 
ucum . append ( "{count}" ) ; 
continue MAIN ; 
if ( udunits . startsWith ( metricAcronym [ p ] ) ) { 
udunits = udunits . substring ( metricAcronym [ p ] . length ( ) ) ; 
return oldUdunits ; 
} public static String ucumToUdunits ( String ucum ) { 
if ( ucum == null ) { 
StringBuilder udunits = new StringBuilder ( ) ; 
int ucLength = ucum . length ( ) ; 
if ( ucLength == 0 ) { 
if ( ucum . charAt ( ucLength - 1 ) == '}' && 
ucum . indexOf ( '}' ) == ucLength - 1 ) { 
String tUdunits = ucHashMap . get ( ucum . substring ( 0 , sincePo ) ) ; 
if ( tUdunits != null ) { 
while ( po < ucLength ) { 
char ch = ucum . charAt ( po ) ; 
if ( isUcumLetter ( ch ) ) { 
while ( po2 < ucLength && 
( isUcumLetter ( ucum . charAt ( po2 ) ) || ucum . charAt ( po2 ) == '_' || 
ErddapString2 . isDigit ( ucum . charAt ( po2 ) ) ) ) { 
String tUcum = ucum . substring ( po , po2 ) ; 
int firstDigit = tUcum . length ( ) ; 
while ( firstDigit >= 1 && ErddapString2 . isDigit ( tUcum . charAt ( firstDigit - 1 ) ) ) { 
String exponent = tUcum . substring ( firstDigit ) ; 
tUcum = tUcum . substring ( 0 , firstDigit ) ; 
String tUdunits = oneUcumToUdunits ( tUcum ) ; 
if ( tUdunits . equals ( "/" ) ) { 
char lastUdunits = udunits . length ( ) == 0 ? ' ' : udunits . charAt ( udunits . length ( ) - 1 ) ; 
if ( lastUdunits == '/' ) { 
udunits . setCharAt ( udunits . length ( ) - 1 , '.' ) ; 
} else if ( lastUdunits == '.' ) { 
udunits . setCharAt ( udunits . length ( ) - 1 , '/' ) ; 
udunits . append ( '/' ) ; 
udunits . append ( tUdunits ) ; 
udunits . append ( exponent ) ; 
while ( po2 < ucLength && ErddapString2 . isDigit ( ucum . charAt ( po2 ) ) ) { 
if ( po2 < ucLength - 1 && Character . toLowerCase ( ucum . charAt ( po2 ) ) == '^' && 
( ucum . charAt ( po2 + 1 ) == '-' || ErddapString2 . isDigit ( ucum . charAt ( po2 + 1 ) ) ) ) { 
String num = ucum . substring ( po , po2 ) ; 
udunits . append ( num ) ; 
if ( ch == '.' ) { 
udunits . append ( '^' ) ; 
if ( ch == '\'' ) { 
if ( po < ucLength && ucum . charAt ( po ) == '\'' ) { 
udunits . append ( "arc_second" ) ; 
udunits . append ( "arc_minute" ) ; 
udunits . append ( ch ) ; 
return udunits . toString ( ) ; 
} private static String oneUcumToUdunits ( String ucum ) { 
String oldUcum = ucum ; 
String tUdunits = ucHashMap . get ( ucum ) ; 
if ( ucum . startsWith ( metricAcronym [ p ] ) ) { 
ucum = ucum . substring ( metricAcronym [ p ] . length ( ) ) ; 
udunits . append ( metricAcronym [ p ] ) ; 
if ( ucum . length ( ) == 0 ) { 
udunits . append ( "{count}" ) ; 
for ( int p = 0 ; p < nTwo ; p ++ ) { 
if ( ucum . startsWith ( twoAcronym [ p ] ) ) { 
ucum = ucum . substring ( twoAcronym [ p ] . length ( ) ) ; 
char udch = udunits . length ( ) > 0 ? udunits . charAt ( udunits . length ( ) - 1 ) : ' ' ; 
if ( udch != ' ' && udch != '.' && udch != '/' ) { 
udunits . append ( '.' ) ; 
udunits . append ( twoValue [ p ] ) . append ( "." ) ; 
int po1 = oldUcum . lastIndexOf ( '{' ) ; 
if ( po1 > 0 && oldUcum . endsWith ( "}" ) ) { 
return oneUcumToUdunits ( oldUcum . substring ( 0 , po1 ) ) + oldUcum . substring ( po1 ) ; 
return oldUcum ; 
} public static HashMap < String , String > getHashMapStringString ( InputStream inputStream , String charset ) 
HashMap < String , String > ht = new HashMap < > ( ) ; 
ErddapStringArray sa = ErddapStringArray . fromInputStream ( inputStream , charset ) ; 
int n = sa . size ( ) ; 
while ( i < n ) { 
String s = sa . get ( i ++ ) ; 
if ( s . startsWith ( "#" ) ) { 
while ( i < n && s . endsWith ( "\\" ) ) { 
s = s . substring ( 0 , s . length ( ) - 1 ) + sa . get ( i ++ ) ; 
int po = s . indexOf ( '=' ) ; 
if ( po < 0 ) { 
ht . put ( s . substring ( 0 , po ) . trim ( ) , s . substring ( po + 1 ) . trim ( ) ) ; 
return ht ; 
} public static String getCenterName ( int center_id , int edition ) { 
String result = ( edition == 1 ) ? getTableValue ( 1 , center_id ) : getTableValue ( 11 , center_id ) ; 
} public static String getCenterNameBufr ( int center_id , int edition ) { 
String result = ( edition < 4 ) ? getTableValue ( 1 , center_id ) : getTableValue ( 11 , center_id ) ; 
} public InvCatalogImpl generateProxyDsResolverCatalog ( CrawlableDataset catalogCrDs , ProxyDatasetHandler pdh ) throws IOException 
} static public ThreddsMetadata . GeospatialCoverage extractGeospatial ( InvDatasetImpl threddsDataset ) throws IOException { 
ThreddsDataFactory . Result result = null ; 
result = new ThreddsDataFactory ( ) . openFeatureDataset ( threddsDataset , null ) ; 
if ( result . fatalError ) { 
if ( result . featureType == FeatureType . GRID ) { 
GridDataset gridDataset = ( GridDataset ) result . featureDataset ; 
return extractGeospatial ( gridDataset ) ; 
} else if ( result . featureType == FeatureType . POINT ) { 
PointObsDataset pobsDataset = ( PointObsDataset ) result . featureDataset ; 
LatLonRect llbb = pobsDataset . getBoundingBox ( ) ; 
if ( null != llbb ) { 
ThreddsMetadata . GeospatialCoverage gc = new ThreddsMetadata . GeospatialCoverage ( ) ; 
gc . setBoundingBox ( llbb ) ; 
return gc ; 
} else if ( result . featureType == FeatureType . STATION ) { 
StationObsDataset sobsDataset = ( StationObsDataset ) result . featureDataset ; 
LatLonRect llbb = sobsDataset . getBoundingBox ( ) ; 
if ( ( result != null ) && ( result . featureDataset != null ) ) 
result . featureDataset . close ( ) ; 
} static public ThreddsMetadata . Variables extractVariables ( InvDatasetImpl threddsDataset ) throws IOException { 
return extractVariables ( threddsDataset , gridDataset ) ; 
} else if ( ( result . featureType == FeatureType . STATION ) || ( result . featureType == FeatureType . POINT ) ) { 
ThreddsMetadata . Variables vars = new ThreddsMetadata . Variables ( "CF-1.0" ) ; 
for ( VariableSimpleIF vs : pobsDataset . getDataVariables ( ) ) { 
ThreddsMetadata . Variable v = new ThreddsMetadata . Variable ( ) ; 
vars . addVariable ( v ) ; 
v . setName ( vs . getShortName ( ) ) ; 
v . setDescription ( vs . getDescription ( ) ) ; 
v . setUnits ( vs . getUnitsString ( ) ) ; 
ucar . nc2 . Attribute att = vs . findAttributeIgnoreCase ( "standard_name" ) ; 
if ( att != null ) 
v . setVocabularyName ( att . getStringValue ( ) ) ; 
vars . sort ( ) ; 
return vars ; 
} static public ThreddsMetadata . Variables extractVariables ( FeatureDatasetPoint fd ) { 
ThreddsMetadata . Variables vars = new ThreddsMetadata . Variables ( "CF-1.5" ) ; 
List < VariableSimpleIF > dataVars = fd . getDataVariables ( ) ; 
if ( dataVars == null ) 
for ( VariableSimpleIF v : dataVars ) { 
ThreddsMetadata . Variable tv = new ThreddsMetadata . Variable ( ) ; 
vars . addVariable ( tv ) ; 
tv . setName ( v . getShortName ( ) ) ; 
tv . setDescription ( v . getDescription ( ) ) ; 
tv . setUnits ( v . getUnitsString ( ) ) ; 
ucar . nc2 . Attribute att = v . findAttributeIgnoreCase ( "standard_name" ) ; 
tv . setVocabularyName ( att . getStringValue ( ) ) ; 
} static public CalendarDateUnit of ( String calendarName , String udunitString ) { 
Calendar calt = Calendar . get ( calendarName ) ; 
if ( calt == null ) calt = Calendar . getDefault ( ) ; 
return new CalendarDateUnit ( calt , udunitString ) ; 
} static public CalendarDateUnit withCalendar ( Calendar calt , String udunitString ) { 
} static public CalendarDateUnit of ( Calendar calt , CalendarPeriod . Field periodField , CalendarDate baseDate ) { 
return new CalendarDateUnit ( calt , periodField , baseDate ) ; 
} public double makeOffsetFromRefDate ( CalendarDate date ) { 
if ( isCalendarField ) { 
if ( date . equals ( baseDate ) ) return 0.0 ; 
return date . getDifference ( baseDate , periodField ) ; 
long msecs = date . getDifferenceInMsecs ( baseDate ) ; 
return msecs / period . getValueInMillisecs ( ) ; 
} public CalendarDate makeCalendarDate ( double value ) { 
if ( isCalendarField ) 
return baseDate . add ( CalendarPeriod . of ( ( int ) value , periodField ) ) ; 
return baseDate . add ( value , periodField ) ; 
CalendarDateUnit cdu ; 
cdu = CalendarDateUnit . of ( null , s ) ; 
} public String chooseFilenameToSave ( String defaultFilename ) { 
chooser . setDialogType ( JFileChooser . SAVE_DIALOG ) ; 
String result = ( defaultFilename == null ) ? chooseFilename ( ) : chooseFilename ( defaultFilename ) ; 
chooser . setDialogType ( JFileChooser . OPEN_DIALOG ) ; 
} public String chooseFilename ( ) { 
if ( ! readOk ) return null ; 
selectedFile = false ; 
w . setVisible ( true ) ; 
if ( selectedFile ) { 
File file = chooser . getSelectedFile ( ) ; 
if ( file == null ) return null ; 
return file . getCanonicalPath ( ) . replace ( '\\' , '/' ) ; 
} public QuantityDimension 
getQuantityDimension ( ) 
Factor [ ] factors = getFactors ( ) ; 
for ( int i = factors . length ; -- i >= 0 ; ) 
Factor factor = factors [ i ] ; 
factors [ i ] = 
new Factor ( 
( ( BaseUnit ) factor . getBase ( ) ) . getBaseQuantity ( ) , 
factor . getExponent ( ) ) ; 
return new QuantityDimension ( factors ) ; 
} public static void 
main ( String [ ] args ) 
throws Exception 
new UnitDimension ( ) + '"' ) ; 
UnitDimension timeDimension = 
new UnitDimension ( 
BaseUnit . getOrCreate ( 
UnitName . newUnitName ( "second" , null , "s" ) , 
BaseQuantity . TIME ) ) ; 
UnitDimension lengthDimension = 
UnitName . newUnitName ( "meter" , null , "m" ) , 
BaseQuantity . LENGTH ) ) ; 
System . out . println ( 
lengthDimension . isReciprocalOf ( timeDimension ) + '"' ) ; 
UnitDimension hertzDimension = timeDimension . raiseTo ( - 1 ) ; 
hertzDimension . isReciprocalOf ( timeDimension ) + '"' ) ; 
lengthDimension . divideBy ( timeDimension ) + '"' ) ; 
lengthDimension . divideBy ( timeDimension ) . raiseTo ( 2 ) + '"' ) ; 
} public boolean isValidFile ( ucar . unidata . io . RandomAccessFile raf ) { 
raf . order ( RandomAccessFile . LITTLE_ENDIAN ) ; 
short [ ] data = new short [ 13 ] ; 
raf . readShort ( data , 0 , 13 ) ; 
return ( data [ 0 ] == ( short ) 27 && 
data [ 6 ] == ( short ) 26 && 
data [ 12 ] == ( short ) 15 ) ; 
} public void open ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile , 
ucar . nc2 . util . CancelTask cancelTask ) throws java . io . IOException { 
super . open ( raf , ncfile , cancelTask ) ; 
java . util . Map < String , String > hdrNames = new java . util . HashMap < String , String > ( ) ; 
volScan = new SigmetVolumeScan ( raf , ncfile , varList ) ; 
this . varList = init ( raf , ncfile , hdrNames ) ; 
} static public java . util . Map < String , Number > readRecordsHdr ( ucar . unidata . io . RandomAccessFile raf ) { 
java . util . Map < String , Number > recHdr1 = new java . util . HashMap < String , Number > ( ) ; 
int nparams = 0 ; 
raf . seek ( 452 ) ; 
int prf = raf . readInt ( ) ; 
raf . seek ( 480 ) ; 
int wave = raf . readInt ( ) ; 
float vNyq = calcNyquist ( prf , wave ) ; 
recHdr1 . put ( "vNyq" , vNyq ) ; 
raf . seek ( 6324 ) ; 
int radar_lat = raf . readInt ( ) ; 
int radar_lon = raf . readInt ( ) ; 
short ground_height = raf . readShort ( ) ; 
short radar_height = raf . readShort ( ) ; 
raf . skipBytes ( 4 ) ; 
short num_rays = raf . readShort ( ) ; 
raf . skipBytes ( 2 ) ; 
int radar_alt = raf . readInt ( ) ; 
raf . seek ( 6648 ) ; 
int time_beg = raf . readInt ( ) ; 
raf . seek ( 6652 ) ; 
int time_end = raf . readInt ( ) ; 
raf . seek ( 6772 ) ; 
int data_mask = raf . readInt ( ) ; 
nparams += ( ( data_mask > > j ) & ( 0x1 ) ) ; 
raf . seek ( 6912 ) ; 
short multiprf = raf . readShort ( ) ; 
raf . seek ( 7408 ) ; 
int range_first = raf . readInt ( ) ; 
int range_last = raf . readInt ( ) ; 
short bins = raf . readShort ( ) ; 
if ( bins % 2 != 0 ) bins = ( short ) ( bins + 1 ) ; 
int step = raf . readInt ( ) ; 
raf . seek ( 7574 ) ; 
short number_sweeps = raf . readShort ( ) ; 
raf . seek ( 12312 ) ; 
int base_time = raf . readInt ( ) ; 
short year = raf . readShort ( ) ; 
short month = raf . readShort ( ) ; 
short day = raf . readShort ( ) ; 
recHdr1 . put ( "radar_lat" , calcAngle ( radar_lat ) ) ; 
recHdr1 . put ( "radar_lon" , calcAngle ( radar_lon ) ) ; 
recHdr1 . put ( "range_first" , range_first ) ; 
recHdr1 . put ( "range_last" , range_last ) ; 
recHdr1 . put ( "ground_height" , ground_height ) ; 
recHdr1 . put ( "radar_height" , radar_height ) ; 
recHdr1 . put ( "radar_alt" , radar_alt ) ; 
recHdr1 . put ( "step" , step ) ; 
recHdr1 . put ( "bins" , bins ) ; 
recHdr1 . put ( "num_rays" , num_rays ) ; 
recHdr1 . put ( "nparams" , nparams ) ; 
recHdr1 . put ( "multiprf" , multiprf ) ; 
recHdr1 . put ( "number_sweeps" , number_sweeps ) ; 
recHdr1 . put ( "year" , year ) ; 
recHdr1 . put ( "month" , month ) ; 
recHdr1 . put ( "day" , day ) ; 
recHdr1 . put ( "base_time" , base_time ) ; 
System . out . println ( e . toString ( ) ) ; 
return recHdr1 ; 
} public java . util . Map < String , String > readStnNames ( ucar . unidata . io . RandomAccessFile raf ) { 
raf . seek ( 6288 ) ; 
String stnName = raf . readString ( 16 ) ; 
raf . seek ( 6306 ) ; 
String stnName_util = raf . readString ( 16 ) ; 
hdrNames . put ( "StationName" , stnName . trim ( ) ) ; 
hdrNames . put ( "StationName_SetupUtility" , stnName_util . trim ( ) ) ; 
return hdrNames ; 
} public ArrayList < Variable > init ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile , 
java . util . Map < String , String > hdrNames ) throws java . io . IOException { 
"Width" , "Differential_Reflectivity" } ; 
int [ ] type = { 1 , 2 , 3 , 4 , 5 } ; 
String def_datafile = "SIGMET-IRIS" ; 
String tim = "" ; 
int ngates = 0 ; 
recHdr = readRecordsHdr ( raf ) ; 
hdrNames = readStnNames ( raf ) ; 
String stnName = hdrNames . get ( "StationName" ) ; 
String stnName_util = hdrNames . get ( "StationName_SetupUtility" ) ; 
float radar_lat = recHdr . get ( "radar_lat" ) . floatValue ( ) ; 
float radar_lon = recHdr . get ( "radar_lon" ) . floatValue ( ) ; 
short ground_height = recHdr . get ( "ground_height" ) . shortValue ( ) ; 
short radar_height = recHdr . get ( "radar_height" ) . shortValue ( ) ; 
int radar_alt = ( recHdr . get ( "radar_alt" ) . intValue ( ) ) / 100 ; 
short num_rays = recHdr . get ( "num_rays" ) . shortValue ( ) ; 
short bins = recHdr . get ( "bins" ) . shortValue ( ) ; 
float range_first = ( recHdr . get ( "range_first" ) . intValue ( ) ) * 0.01f ; 
float range_last = ( recHdr . get ( "range_last" ) . intValue ( ) ) * 0.01f ; 
short number_sweeps = recHdr . get ( "number_sweeps" ) . shortValue ( ) ; 
int nparams = ( recHdr . get ( "nparams" ) . intValue ( ) ) ; 
short year = recHdr . get ( "year" ) . shortValue ( ) ; 
short month = recHdr . get ( "month" ) . shortValue ( ) ; 
short day = recHdr . get ( "day" ) . shortValue ( ) ; 
int base_time = ( recHdr . get ( "base_time" ) . intValue ( ) ) ; 
sweep_bins = new int [ nparams * number_sweeps ] ; 
if ( number_sweeps > 1 ) { 
sweep_bins = volScan . getNumberGates ( ) ; 
for ( int kk = 0 ; kk < nparams ; kk ++ ) { 
sweep_bins [ kk ] = bins ; 
Dimension scanR = new Dimension ( "scanR" , number_sweeps , true ) ; 
Dimension radial = new Dimension ( "radial" , num_rays , true ) ; 
Dimension [ ] gateR = new Dimension [ number_sweeps ] ; 
String dim_name = "gateR" ; 
for ( int j = 0 ; j < number_sweeps ; j ++ ) { 
dim_name = "gateR_sweep_" + ( j + 1 ) ; 
gateR [ j ] = new Dimension ( dim_name , sweep_bins [ j ] , true ) ; 
ncfile . addDimension ( null , scanR ) ; 
ncfile . addDimension ( null , radial ) ; 
ncfile . addDimension ( null , gateR [ j ] ) ; 
ArrayList < Dimension > dims0 = new ArrayList < Dimension > ( ) ; 
ArrayList < Dimension > dims1 = new ArrayList < Dimension > ( ) ; 
ArrayList < Dimension > dims2 = new ArrayList < Dimension > ( ) ; 
ArrayList < Dimension > dims3 = new ArrayList < Dimension > ( ) ; 
ArrayList < Variable > varList = new ArrayList < Variable > ( ) ; 
Variable [ ] [ ] v = new Variable [ nparams ] [ number_sweeps ] ; 
String var_name = "" ; 
for ( int j = 0 ; j < nparams ; j ++ ) { 
int tp = type [ j ] ; 
var_name = data_name [ tp ] ; 
for ( int jj = 0 ; jj < number_sweeps ; jj ++ ) { 
var_name = data_name [ tp ] + "_sweep_" + ( jj + 1 ) ; 
v [ j ] [ jj ] = new Variable ( ncfile , null , null , var_name ) ; 
v [ j ] [ jj ] . setDataType ( DataType . FLOAT ) ; 
dims2 . add ( radial ) ; 
dims2 . add ( gateR [ jj ] ) ; 
v [ j ] [ jj ] . setDimensions ( dims2 ) ; 
v [ j ] [ jj ] . addAttribute ( new Attribute ( CDM . LONG_NAME , var_name ) ) ; 
v [ j ] [ jj ] . addAttribute ( new Attribute ( CDM . UNITS , unit [ tp ] ) ) ; 
v [ j ] [ jj ] . addAttribute ( new Attribute ( _Coordinate . Axes , coordinates ) ) ; 
v [ j ] [ jj ] . addAttribute ( new Attribute ( CDM . MISSING_VALUE , - 999.99f ) ) ; 
ncfile . addVariable ( null , v [ j ] [ jj ] ) ; 
varList . add ( v [ j ] [ jj ] ) ; 
dims2 . clear ( ) ; 
tsu_sec = new int [ number_sweeps ] ; 
String [ ] tsu = new String [ number_sweeps ] ; 
String [ ] time_units = new String [ number_sweeps ] ; 
tsu_sec = volScan . getStartSweep ( ) ; 
for ( int i = 0 ; i < number_sweeps ; i ++ ) { 
String st1 = Short . toString ( month ) ; 
if ( st1 . length ( ) < 2 ) st1 = "0" + st1 ; 
String st2 = Short . toString ( day ) ; 
if ( st2 . length ( ) < 2 ) st2 = "0" + st2 ; 
date0 = String . valueOf ( year ) + "-" + st1 + "-" + st2 ; 
tsu [ i ] = date0 + "T" + calcTime ( tsu_sec [ i ] , 0 ) + "Z" ; 
dims0 . add ( radial ) ; 
Variable [ ] time = new Variable [ number_sweeps ] ; 
String tm = "time" ; 
String tm_name = "" ; 
tm_name = tm ; 
tm_name = tm + "_sweep_" + ( j + 1 ) ; 
time [ j ] = new Variable ( ncfile , null , null , tm_name ) ; 
time [ j ] . setDataType ( DataType . INT ) ; 
time [ j ] . setDimensions ( dims0 ) ; 
time [ j ] . addAttribute ( new Attribute ( CDM . UNITS , time_units [ j ] ) ) ; 
time [ j ] . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Time . toString ( ) ) ) ; 
time [ j ] . addAttribute ( new Attribute ( CDM . MISSING_VALUE , - 99 ) ) ; 
ncfile . addVariable ( null , time [ j ] ) ; 
varList . add ( time [ j ] ) ; 
Variable [ ] elevationR = new Variable [ number_sweeps ] ; 
String ele = "elevationR" ; 
String ele_name = "" ; 
ele_name = ele ; 
ele_name = ele + "_sweep_" + ( j + 1 ) ; 
elevationR [ j ] = new Variable ( ncfile , null , null , ele_name ) ; 
elevationR [ j ] . setDataType ( DataType . FLOAT ) ; 
elevationR [ j ] . setDimensions ( dims0 ) ; 
elevationR [ j ] . addAttribute ( new Attribute ( CDM . UNITS , "degrees" ) ) ; 
elevationR [ j ] . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . RadialElevation . toString ( ) ) ) ; 
elevationR [ j ] . addAttribute ( new Attribute ( CDM . MISSING_VALUE , - 999.99f ) ) ; 
ncfile . addVariable ( null , elevationR [ j ] ) ; 
varList . add ( elevationR [ j ] ) ; 
Variable [ ] azimuthR = new Variable [ number_sweeps ] ; 
String azim = "azimuthR" ; 
String azim_name = "" ; 
azim_name = azim ; 
azim_name = azim + "_sweep_" + ( j + 1 ) ; 
azimuthR [ j ] = new Variable ( ncfile , null , null , azim_name ) ; 
azimuthR [ j ] . setDataType ( DataType . FLOAT ) ; 
azimuthR [ j ] . setDimensions ( dims0 ) ; 
azimuthR [ j ] . addAttribute ( new Attribute ( CDM . UNITS , "degrees" ) ) ; 
azimuthR [ j ] . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . RadialAzimuth . toString ( ) ) ) ; 
azimuthR [ j ] . addAttribute ( new Attribute ( CDM . MISSING_VALUE , - 999.99f ) ) ; 
ncfile . addVariable ( null , azimuthR [ j ] ) ; 
varList . add ( azimuthR [ j ] ) ; 
Variable [ ] distanceR = new Variable [ number_sweeps ] ; 
String dName = "distanceR" ; 
String dist_name = "" ; 
dist_name = dName ; 
dist_name = dName + "_sweep_" + ( j + 1 ) ; 
distanceR [ j ] = new Variable ( ncfile , null , null , dist_name ) ; 
distanceR [ j ] . setDataType ( DataType . FLOAT ) ; 
dims1 . add ( gateR [ j ] ) ; 
distanceR [ j ] . setDimensions ( dims1 ) ; 
distanceR [ j ] . addAttribute ( new Attribute ( CDM . UNITS , "m" ) ) ; 
distanceR [ j ] . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . RadialDistance . toString ( ) ) ) ; 
ncfile . addVariable ( null , distanceR [ j ] ) ; 
varList . add ( distanceR [ j ] ) ; 
dims1 . clear ( ) ; 
dims3 . add ( scanR ) ; 
Variable numGates = new Variable ( ncfile , null , null , "numGates" ) ; 
numGates . setDataType ( DataType . INT ) ; 
numGates . setDimensions ( dims3 ) ; 
ncfile . addVariable ( null , numGates ) ; 
varList . add ( numGates ) ; 
ncfile . addAttribute ( null , new Attribute ( "StationName" , stnName ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "StationName_SetupUtility" , stnName_util ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "radar_lat" , radar_lat ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "radar_lon" , radar_lon ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "ground_height" , ground_height ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "radar_height" , radar_height ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "radar_alt" , radar_alt ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "num_data_types" , nparams ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "number_sweeps" , number_sweeps ) ) ; 
String sn = "start_sweep" ; 
String snn = "" ; 
snn = sn ; 
snn = sn + "_" + ( j + 1 ) ; 
ncfile . addAttribute ( null , new Attribute ( snn , tsu [ j ] ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "num_rays" , num_rays ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "max_number_gates" , bins ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "range_first" , range_first ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "range_last" , range_last ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "DataType" , "Radial" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( CDM . CONVENTIONS , _Coordinate . Convention ) ) ; 
doNetcdfFileCoordinate ( ncfile , volScan . base_time , volScan . year , volScan . month , volScan . day , varList , recHdr ) ; 
return varList ; 
} public void doNetcdfFileCoordinate ( ucar . nc2 . NetcdfFile ncfile , int [ ] bst , 
short [ ] yr , short [ ] m , short [ ] dda , 
ArrayList < Variable > varList , java . util . Map < String , Number > recHdr ) { 
Short header_length = 80 ; 
Short ray_header_length = 6 ; 
int last_t = volScan . lastRay . getTime ( ) ; 
String sss1 = Short . toString ( m [ 0 ] ) ; 
if ( sss1 . length ( ) < 2 ) sss1 = "0" + sss1 ; 
String sss2 = Short . toString ( dda [ 0 ] ) ; 
if ( sss2 . length ( ) < 2 ) sss2 = "0" + sss2 ; 
String base_date0 = String . valueOf ( yr [ 0 ] ) + "-" + sss1 + "-" + sss2 ; 
String sss11 = Short . toString ( m [ number_sweeps - 1 ] ) ; 
if ( sss11 . length ( ) < 2 ) sss11 = "0" + sss11 ; 
String sss22 = Short . toString ( dda [ number_sweeps - 1 ] ) ; 
if ( sss22 . length ( ) < 2 ) sss22 = "0" + sss22 ; 
String base_date1 = String . valueOf ( yr [ number_sweeps - 1 ] ) + "-" + sss11 + "-" + sss22 ; 
String start_time = base_date0 + "T" + calcTime ( bst [ 0 ] , 0 ) + "Z" ; 
String end_time = base_date1 + "T" + calcTime ( bst [ number_sweeps - 1 ] , last_t ) + "Z" ; 
ncfile . addAttribute ( null , new Attribute ( "time_coverage_start" , start_time ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "time_coverage_end" , end_time ) ) ; 
int sz = varList . size ( ) ; 
ArrayFloat . D2 [ ] dataArr = new ArrayFloat . D2 [ nparams * number_sweeps ] ; 
Index [ ] dataIndex = new Index [ nparams * number_sweeps ] ; 
Ray [ ] rtemp = new Ray [ ( int ) num_rays ] ; 
ArrayFloat . D1 [ ] distArr = new ArrayFloat . D1 [ number_sweeps ] ; 
Index [ ] distIndex = new Index [ number_sweeps ] ; 
String distName = "distanceR" ; 
distName = "distanceR_sweep_" + ( i + 1 ) ; 
for ( Variable aVarList : varList ) { 
if ( ( aVarList . getShortName ( ) ) . equals ( distName . trim ( ) ) ) { 
distanceR [ i ] = aVarList ; 
distArr [ i ] = ( ArrayFloat . D1 ) Array . factory ( DataType . FLOAT , distanceR [ i ] . getShape ( ) ) ; 
distIndex [ i ] = distArr [ i ] . getIndex ( ) ; 
ngates = sweep_bins [ i ] ; 
float stp = calcStep ( range_first , range_last , ( short ) ngates ) ; 
for ( int ii = 0 ; ii < ngates ; ii ++ ) { 
distArr [ i ] . setFloat ( distIndex [ i ] . set ( ii ) , ( range_first + ii * stp ) ) ; 
List rgp = volScan . getTotalPowerGroups ( ) ; 
if ( rgp . size ( ) == 0 ) rgp = volScan . getReflectivityGroups ( ) ; 
List [ ] sgp = new ArrayList [ number_sweeps ] ; 
sgp [ i ] = ( List ) rgp . get ( ( short ) i ) ; 
ArrayInt . D1 [ ] timeArr = new ArrayInt . D1 [ number_sweeps ] ; 
Index [ ] timeIndex = new Index [ number_sweeps ] ; 
String t_n = "time" ; 
t_n = "time_sweep_" + ( i + 1 ) ; 
if ( ( aVarList . getShortName ( ) ) . equals ( t_n . trim ( ) ) ) { 
time [ i ] = aVarList ; 
timeArr [ i ] = ( ArrayInt . D1 ) Array . factory ( DataType . INT , time [ i ] . getShape ( ) ) ; 
timeIndex [ i ] = timeArr [ i ] . getIndex ( ) ; 
List rlist = sgp [ i ] ; 
for ( int jj = 0 ; jj < num_rays ; jj ++ ) { 
rtemp [ jj ] = ( Ray ) rlist . get ( jj ) ; 
timeArr [ i ] . setInt ( timeIndex [ i ] . set ( jj ) , rtemp [ jj ] . getTime ( ) ) ; 
ArrayFloat . D1 [ ] azimArr = new ArrayFloat . D1 [ number_sweeps ] ; 
Index [ ] azimIndex = new Index [ number_sweeps ] ; 
String azimName = "azimuthR" ; 
azimName = "azimuthR_sweep_" + ( i + 1 ) ; 
if ( ( aVarList . getShortName ( ) ) . equals ( azimName . trim ( ) ) ) { 
azimuthR [ i ] = aVarList ; 
azimArr [ i ] = ( ArrayFloat . D1 ) Array . factory ( DataType . FLOAT , azimuthR [ i ] . getShape ( ) ) ; 
azimIndex [ i ] = azimArr [ i ] . getIndex ( ) ; 
azimArr [ i ] . setFloat ( azimIndex [ i ] . set ( jj ) , rtemp [ jj ] . getAz ( ) ) ; 
ArrayFloat . D1 [ ] elevArr = new ArrayFloat . D1 [ number_sweeps ] ; 
Index [ ] elevIndex = new Index [ number_sweeps ] ; 
String elevName = "elevationR" ; 
elevName = "elevationR_sweep_" + ( i + 1 ) ; 
if ( ( aVarList . getShortName ( ) ) . equals ( elevName . trim ( ) ) ) { 
elevationR [ i ] = aVarList ; 
elevArr [ i ] = ( ArrayFloat . D1 ) Array . factory ( DataType . FLOAT , elevationR [ i ] . getShape ( ) ) ; 
elevIndex [ i ] = elevArr [ i ] . getIndex ( ) ; 
elevArr [ i ] . setFloat ( elevIndex [ i ] . set ( jj ) , rtemp [ jj ] . getElev ( ) ) ; 
Variable numGates = null ; 
if ( ( aVarList . getShortName ( ) ) . equals ( "numGates" ) ) { 
numGates = aVarList ; 
ArrayInt . D1 gatesArr = ( ArrayInt . D1 ) Array . factory ( DataType . INT , numGates . getShape ( ) ) ; 
Index gatesIndex = gatesArr . getIndex ( ) ; 
ngates = rtemp [ 0 ] . getBins ( ) ; 
gatesArr . setInt ( gatesIndex . set ( i ) , ngates ) ; 
distanceR [ i ] . setCachedData ( distArr [ i ] , false ) ; 
time [ i ] . setCachedData ( timeArr [ i ] , false ) ; 
azimuthR [ i ] . setCachedData ( azimArr [ i ] , false ) ; 
elevationR [ i ] . setCachedData ( elevArr [ i ] , false ) ; 
numGates . setCachedData ( gatesArr , false ) ; 
} public Array readData1 ( ucar . nc2 . Variable v2 , Section section ) 
int [ ] sh = section . getShape ( ) ; 
Array temp = Array . factory ( v2 . getDataType ( ) , sh ) ; 
long pos0 = 0 ; 
LayoutRegular index = new LayoutRegular ( pos0 , v2 . getElementSize ( ) , v2 . getShape ( ) , section ) ; 
if ( v2 . getShortName ( ) . startsWith ( "time" ) | v2 . getShortName ( ) . startsWith ( "numGates" ) ) { 
temp = readIntData ( index , v2 ) ; 
temp = readFloatData ( index , v2 ) ; 
return temp ; 
} public Array readIntData ( LayoutRegular index , Variable v2 ) throws IOException { 
int [ ] var = ( int [ ] ) ( v2 . read ( ) . get1DJavaArray ( v2 . getDataType ( ) ) ) ; 
int [ ] data = new int [ ( int ) index . getTotalNelems ( ) ] ; 
while ( index . hasNext ( ) ) { 
Layout . Chunk chunk = index . next ( ) ; 
System . arraycopy ( var , ( int ) chunk . getSrcPos ( ) / 4 , data , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
return Array . factory ( v2 . getDataType ( ) , new int [ ] { ( int ) index . getTotalNelems ( ) } , data ) ; 
} public long readToByteChannel11 ( ucar . nc2 . Variable v2 , Section section , WritableByteChannel channel ) 
throws java . io . IOException , ucar . ma2 . InvalidRangeException { 
Array data = readData ( v2 , section ) ; 
float [ ] ftdata = new float [ ( int ) data . getSize ( ) ] ; 
byte [ ] bytedata = new byte [ ( int ) data . getSize ( ) * 4 ] ; 
IndexIterator iter = data . getIndexIterator ( ) ; 
ByteBuffer buffer = ByteBuffer . allocateDirect ( bytedata . length ) ; 
ftdata [ i ] = iter . getFloatNext ( ) ; 
bytedata [ i ] = new Float ( ftdata [ i ] ) . byteValue ( ) ; 
buffer . put ( bytedata [ i ] ) ; 
buffer = ByteBuffer . wrap ( bytedata ) ; 
int count = channel . write ( buffer ) ; 
System . out . println ( "COUNT=" + count ) ; 
if ( buffer . hasRemaining ( ) ) { 
buffer . compact ( ) ; 
return ( long ) count ; 
} static float calcElev ( short angle ) { 
final double maxval = 65536.0 ; 
double ang = ( double ) angle ; 
if ( angle < 0 ) ang = ( ~ angle ) + 1 ; 
double temp = ( ang / maxval ) * 360.0 ; 
BigDecimal bd = new BigDecimal ( temp ) ; 
BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; 
return result . floatValue ( ) ; 
} static float calcStep ( float range_first , float range_last , short num_bins ) { 
float step = ( range_last - range_first ) / ( num_bins - 1 ) ; 
BigDecimal bd = new BigDecimal ( step ) ; 
} static float calcAz ( short az0 , short az1 ) { 
float azim0 = calcAngle ( az0 ) ; 
float azim1 = calcAngle ( az1 ) ; 
float d = 0.0f ; 
d = Math . abs ( azim0 - azim1 ) ; 
if ( ( az0 < 0 ) & ( az1 > 0 ) ) { 
d = Math . abs ( 360.0f - azim0 ) + Math . abs ( azim1 ) ; 
double temp = azim0 + d * 0.5 ; 
if ( temp > 360.0 ) { 
temp -= 360.0 ; 
} static float calcData ( Map < String , Number > recHdr , short dty , byte data ) { 
short [ ] coef = { 1 , 2 , 3 , 4 } ; 
short multiprf = recHdr . get ( "multiprf" ) . shortValue ( ) ; 
float vNyq = recHdr . get ( "vNyq" ) . floatValue ( ) ; 
double temp = - 999.99 ; 
switch ( dty ) { 
if ( data != 0 ) { 
temp = ( ( ( int ) data & 0xFF ) - 64 ) * 0.5 ; 
temp = ( ( ( ( int ) data & 0xFF ) - 128 ) / 127.0 ) * vNyq * coef [ multiprf ] ; 
double v = ( ( ( ( int ) data & 0xFF ) - 128 ) / 127.0 ) * vNyq * coef [ multiprf ] ; 
temp = ( ( ( int ) data & 0xFF ) / 256.0 ) * v ; 
temp = ( ( ( ( int ) data & 0xFF ) - 128 ) / 16.0 ) ; 
} static String calcTime ( int t , int t0 ) { 
StringBuilder tim = new StringBuilder ( ) ; 
int [ ] tt = new int [ 3 ] ; 
int mmh = ( t + t0 ) / 60 ; 
tt [ 2 ] = ( t + t0 ) % 60 ; 
tt [ 0 ] = mmh / 60 ; 
tt [ 1 ] = mmh % 60 ; 
for ( int i = 0 ; i < 3 ; i ++ ) { 
String s = Integer . toString ( tt [ i ] ) ; 
int len = s . length ( ) ; 
if ( len < 2 ) { 
s = "0" + tt [ i ] ; 
if ( i != 2 ) s += ":" ; 
tim . append ( s ) ; 
return tim . toString ( ) ; 
} static float calcNyquist ( int prf , int wave ) { 
double tmp = ( prf * wave * 0.01 ) * 0.25 ; 
tmp = tmp * 0.01 ; 
BigDecimal bd = new BigDecimal ( tmp ) ; 
} public VerticalTransform makeVerticalTransform ( NetcdfDataset ds , Dimension timeDim ) { 
return builder . makeMathTransform ( ds , timeDim , this ) ; 
} public void removePartition ( MCollection partition ) { 
for ( MFile mfile : partIndexFiles ) { 
if ( mfile . getName ( ) . equalsIgnoreCase ( partition . getCollectionName ( ) ) ) { 
List < MFile > part = new ArrayList < > ( partIndexFiles ) ; 
part . remove ( mfile ) ; 
partIndexFiles = part ; 
} private RandomAccessFile uncompress ( RandomAccessFile raf2 , String ufilename , boolean debug ) throws IOException { 
raf2 . seek ( 0 ) ; 
byte [ ] header = new byte [ Cinrad2Record . FILE_HEADER_SIZE ] ; 
int bytesRead = raf2 . read ( header ) ; 
if ( bytesRead != header . length ) { 
RandomAccessFile dout2 = new RandomAccessFile ( ufilename , "rw" ) ; 
dout2 . write ( header ) ; 
numCompBytes = raf2 . readInt ( ) ; 
raf2 . readFully ( buf ) ; 
ByteArrayInputStream bis = new ByteArrayInputStream ( buf , 2 , numCompBytes - 2 ) ; 
if ( obuff . length >= 0 ) dout2 . write ( obuff , 0 , total ) ; 
dout2 . flush ( ) ; 
dout2 . close ( ) ; 
return dout2 ; 
} static public void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) { 
debugOpen = debugFlag . isSet ( "Grid/open" ) ; 
debugMissing = debugFlag . isSet ( "Grid/missing" ) ; 
debugMissingDetails = debugFlag . isSet ( "Grid/missingDetails" ) ; 
debugProj = debugFlag . isSet ( "Grid/projection" ) ; 
debugVert = debugFlag . isSet ( "Grid/vertical" ) ; 
debugTiming = debugFlag . isSet ( "Grid/timing" ) ; 
} static public void setExtendIndex ( boolean b ) { 
indexFileModeOnOpen = b ? IndexExtendMode . extendwrite : IndexExtendMode . readonly ; 
indexFileModeOnSync = b ? IndexExtendMode . extendwrite : IndexExtendMode . readonly ; 
public void open ( RandomAccessFile raf , NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { 
public Array readData ( Variable v2 , Section section ) throws IOException , InvalidRangeException { 
Array dataArray = Array . factory ( DataType . FLOAT , section . getShape ( ) ) ; 
GridVariable pv = ( GridVariable ) v2 . getSPobject ( ) ; 
int rangeIdx = 0 ; 
Range ensRange = pv . hasEnsemble ( ) ? section . getRange ( rangeIdx ++ ) : new Range ( 0 , 0 ) ; 
Range timeRange = ( section . getRank ( ) > 2 ) ? section . getRange ( rangeIdx ++ ) : new Range ( 0 , 0 ) ; 
Range levRange = pv . hasVert ( ) ? section . getRange ( rangeIdx ++ ) : new Range ( 0 , 0 ) ; 
Range yRange = section . getRange ( rangeIdx ++ ) ; 
Range xRange = section . getRange ( rangeIdx ) ; 
IndexIterator ii = dataArray . getIndexIterator ( ) ; 
for ( int ensIdx : ensRange ) { 
for ( int timeIdx : timeRange ) { 
for ( int levelIdx : levRange ) { 
readXY ( v2 , ensIdx , timeIdx , levelIdx , yRange , xRange , ii ) ; 
if ( debugTiming ) { 
long took = System . currentTimeMillis ( ) - start ; 
return dataArray ; 
} private void readXY ( Variable v2 , int ensIdx , int timeIdx , int levIdx , Range yRange , Range xRange , IndexIterator ii ) 
GridHorizCoordSys hsys = pv . getHorizCoordSys ( ) ; 
int nx = hsys . getNx ( ) ; 
GridRecord record = pv . findRecord ( ensIdx , timeIdx , levIdx ) ; 
Attribute att = v2 . findAttribute ( "missing_value" ) ; 
float missing_value = ( att == null ) ? - 9999.0f : att . getNumericValue ( ) . floatValue ( ) ; 
int xyCount = yRange . length ( ) * xRange . length ( ) ; 
for ( int j = 0 ; j < xyCount ; j ++ ) { 
ii . setFloatNext ( missing_value ) ; 
float [ ] data = _readData ( record ) ; 
if ( data == null ) { 
_readData ( record ) ; 
for ( int y : yRange ) { 
for ( int x : xRange ) { 
int index = y * nx + x ; 
ii . setFloatNext ( data [ index ] ) ; 
} public boolean isMissingXY ( Variable v2 , int timeIdx , int ensIdx , int levIdx ) throws InvalidRangeException { 
if ( ( timeIdx < 0 ) || ( timeIdx >= pv . getNTimes ( ) ) ) { 
throw new InvalidRangeException ( "timeIdx=" + timeIdx ) ; 
if ( ( levIdx < 0 ) || ( levIdx >= pv . getVertNlevels ( ) ) ) { 
throw new InvalidRangeException ( "levIdx=" + levIdx ) ; 
if ( ( ensIdx < 0 ) || ( ensIdx >= pv . getNEnsembles ( ) ) ) { 
throw new InvalidRangeException ( "ensIdx=" + ensIdx ) ; 
return ( null == pv . findRecord ( ensIdx , timeIdx , levIdx ) ) ; 
parse ( ) 
this . url = request . getRequestURL ( ) . toString ( ) ; 
if ( DapController . TESTING ) { 
this . querystring = makeQueryString ( this . request ) ; 
this . querystring = request . getQueryString ( ) ; 
XURI xuri ; 
xuri = new XURI ( this . url ) . parseQuery ( this . querystring ) ; 
buf . append ( request . getScheme ( ) ) ; 
buf . append ( "://" ) ; 
buf . append ( request . getServerName ( ) ) ; 
int port = request . getServerPort ( ) ; 
if ( port > 0 ) { 
buf . append ( ":" ) ; 
buf . append ( port ) ; 
this . server = buf . toString ( ) ; 
String id = controller . getServletID ( ) ; 
String sp = DapUtil . canonicalpath ( request . getServletPath ( ) ) ; 
String cp = DapUtil . canonicalpath ( request . getContextPath ( ) ) ; 
if ( ! cp . endsWith ( id ) ) 
cp = cp + "/" + id ; 
buf . append ( cp ) ; 
this . controllerpath = buf . toString ( ) ; 
sp = HTTPUtil . relpath ( sp ) ; 
if ( sp . startsWith ( id ) ) 
sp = sp . substring ( id . length ( ) ) ; 
this . datasetpath = HTTPUtil . relpath ( sp ) ; 
this . datasetpath = DapUtil . nullify ( this . datasetpath ) ; 
this . mode = null ; 
if ( this . datasetpath == null ) { 
this . mode = RequestMode . CAPABILITIES ; 
this . format = ResponseFormat . HTML ; 
String [ ] pieces = this . datasetpath . split ( "[.]" ) ; 
int modepos = 0 ; 
for ( int i = pieces . length - 1 ; i >= 1 ; i -- ) { 
String ext = pieces [ i ] ; 
RequestMode mode = RequestMode . modeFor ( ext ) ; 
ResponseFormat format = ResponseFormat . formatFor ( ext ) ; 
if ( mode != null ) { 
this . mode = mode ; 
modepos = i ; 
} else if ( format != null ) { 
if ( this . format != null ) 
. setCode ( HttpServletResponse . SC_BAD_REQUEST ) ; 
this . format = format ; 
if ( modepos > 0 ) 
this . datasetpath = DapUtil . join ( pieces , "." , 0 , modepos ) ; 
if ( this . mode == null ) 
this . mode = RequestMode . DSR ; 
if ( this . format == null ) 
this . format = ResponseFormat . NONE ; 
if ( querystring != null && querystring . length ( ) > 0 ) 
this . queries = xuri . getQueryFields ( ) ; 
String p = queryLookup ( Dap4Util . DAP4ENDIANTAG ) ; 
if ( p != null ) { 
Integer oz = DapUtil . stringToInteger ( p ) ; 
if ( oz == null ) 
this . order = ByteOrder . LITTLE_ENDIAN ; 
this . order = ( oz != 0 ? ByteOrder . LITTLE_ENDIAN : ByteOrder . BIG_ENDIAN ) ; 
p = queryLookup ( Dap4Util . DAP4CSUMTAG ) ; 
this . checksummode = ChecksumMode . modeFor ( p ) ; 
if ( this . checksummode == null ) 
this . checksummode = DEFAULTCSUM ; 
} public ProjectionRect getBoundingBox ( ) { 
if ( mapArea == null ) { 
CoordinateAxis horizXaxis = getXHorizAxis ( ) ; 
CoordinateAxis horizYaxis = getYHorizAxis ( ) ; 
if ( ( horizXaxis == null ) || ! horizXaxis . isNumeric ( ) || ( horizYaxis == null ) || ! horizYaxis . isNumeric ( ) ) 
if ( ( horizXaxis instanceof CoordinateAxis2D ) && ( horizYaxis instanceof CoordinateAxis2D ) ) { 
CoordinateAxis2D xaxis2 = ( CoordinateAxis2D ) horizXaxis ; 
CoordinateAxis2D yaxis2 = ( CoordinateAxis2D ) horizYaxis ; 
mapArea = null ; 
CoordinateAxis1D xaxis1 = ( CoordinateAxis1D ) horizXaxis ; 
CoordinateAxis1D yaxis1 = ( CoordinateAxis1D ) horizYaxis ; 
mapArea = new ProjectionRect ( xaxis1 . getCoordEdge ( 0 ) , yaxis1 . getCoordEdge ( 0 ) , 
xaxis1 . getCoordEdge ( ( int ) xaxis1 . getSize ( ) ) , 
yaxis1 . getCoordEdge ( ( int ) yaxis1 . getSize ( ) ) ) ; 
return mapArea ; 
} public LatLonPoint getLatLon ( int xindex , int yindex ) { 
double x , y ; 
if ( horizXaxis instanceof CoordinateAxis1D ) { 
CoordinateAxis1D horiz1D = ( CoordinateAxis1D ) horizXaxis ; 
x = horiz1D . getCoordValue ( xindex ) ; 
CoordinateAxis2D horiz2D = ( CoordinateAxis2D ) horizXaxis ; 
x = horiz2D . getCoordValue ( yindex , xindex ) ; 
if ( horizYaxis instanceof CoordinateAxis1D ) { 
CoordinateAxis1D horiz1D = ( CoordinateAxis1D ) horizYaxis ; 
y = horiz1D . getCoordValue ( yindex ) ; 
CoordinateAxis2D horiz2D = ( CoordinateAxis2D ) horizYaxis ; 
y = horiz2D . getCoordValue ( yindex , xindex ) ; 
return isLatLon ( ) ? new LatLonPointImpl ( y , x ) : getLatLon ( x , y ) ; 
} public LatLonRect getLatLonBoundingBox ( ) { 
if ( llbb == null ) { 
if ( ( getXHorizAxis ( ) instanceof CoordinateAxis2D ) && ( getYHorizAxis ( ) instanceof CoordinateAxis2D ) ) { 
if ( isLatLon ( ) ) { 
double startLat = horizYaxis . getMinValue ( ) ; 
double startLon = horizXaxis . getMinValue ( ) ; 
double deltaLat = horizYaxis . getMaxValue ( ) - startLat ; 
double deltaLon = horizXaxis . getMaxValue ( ) - startLon ; 
LatLonPoint llpt = new LatLonPointImpl ( startLat , startLon ) ; 
llbb = new LatLonRect ( llpt , deltaLat , deltaLon ) ; 
ProjectionImpl dataProjection = getProjection ( ) ; 
ProjectionRect bb = getBoundingBox ( ) ; 
if ( bb != null ) 
llbb = dataProjection . projToLatLonBB ( bb ) ; 
return llbb ; 
} public static void calcScaleOffset ( GribData . Bean bean1 , Formatter f ) { 
data = bean1 . readData ( ) ; 
int npoints = data . length ; 
int nbits = bean1 . getNBits ( ) ; 
int width = ( 2 << nbits - 1 ) - 2 ; 
int missing_value = ( 2 << nbits - 1 ) - 1 ; 
float dataMin = Float . MAX_VALUE ; 
float dataMax = - Float . MAX_VALUE ; 
for ( float fd : data ) { 
if ( Float . isNaN ( fd ) ) continue ; 
dataMin = Math . min ( dataMin , fd ) ; 
dataMax = Math . max ( dataMax , fd ) ; 
double scale_factor = ( dataMax - dataMin ) / width ; 
double add_offset = dataMin ; 
ByteBuffer bb = ByteBuffer . allocate ( 4 * npoints ) ; 
IntBuffer intBuffer = bb . asIntBuffer ( ) ; 
double diffMax = - Double . MAX_VALUE ; 
double diffTotal = 0 ; 
double diffTotal2 = 0 ; 
if ( Float . isNaN ( fd ) ) { 
intBuffer . put ( missing_value ) ; 
int packed_data = ( int ) Math . round ( ( fd - add_offset ) / scale_factor ) ; 
double unpacked_data = packed_data * scale_factor + add_offset ; 
double diff = Math . abs ( fd - unpacked_data ) ; 
if ( diff > scale_factor / 2 ) 
diffMax = Math . max ( diffMax , diff ) ; 
diffTotal += diff ; 
diffTotal2 += diff * diff ; 
intBuffer . put ( packed_data ) ; 
double mean = diffTotal / npoints ; 
double var = ( diffTotal2 / npoints - mean * mean ) ; 
f . format ( "%nCompression%n" ) ; 
int packedBitsLen = npoints * nbits / 8 ; 
byte [ ] bdata = convertToBytes ( data ) ; 
byte [ ] scaledData = bb . array ( ) ; 
Deflater deflater = new Deflater ( ) ; 
deflater . setInput ( bdata ) ; 
deflater . finish ( ) ; 
int compressedSize = deflater . deflate ( new byte [ 10 * npoints ] ) ; 
deflater . end ( ) ; 
deflater = new Deflater ( ) ; 
deflater . setInput ( scaledData ) ; 
compressedSize = deflater . deflate ( new byte [ 10 * npoints ] ) ; 
} public void finish ( ) { 
sequenceOffset = new int [ nelems ] ; 
for ( int i = 0 ; i < nelems ; i ++ ) { 
sequenceOffset [ i ] = total ; 
total += sequenceLen [ i ] ; 
sdata = new StructureData [ nelems ] ; 
for ( int i = 0 ; i < nelems ; i ++ ) 
sdata [ i ] = new StructureDataA ( this , sequenceOffset [ i ] ) ; 
int [ ] mShape = m . getShape ( ) ; 
int [ ] shape = new int [ mShape . length + 1 ] ; 
shape [ 0 ] = total ; 
System . arraycopy ( mShape , 0 , shape , 1 , mShape . length ) ; 
Array data = Array . factory ( m . getDataType ( ) , shape ) ; 
} public ArrayStructure flatten ( ) { 
ArrayStructureW aw = new ArrayStructureW ( getStructureMembers ( ) , new int [ ] { total } ) ; 
for ( int i = 0 ; i < total ; i ++ ) { 
StructureData sdata = new StructureDataA ( this , i ) ; 
aw . setStructureData ( sdata , i ) ; 
return aw ; 
} public static void tab ( StringBuffer sbuff , int tabStop , boolean alwaysOne ) { 
int len = sbuff . length ( ) ; 
if ( tabStop > len ) { 
sbuff . setLength ( tabStop ) ; 
for ( int i = len ; i < tabStop ; i ++ ) { 
} else if ( alwaysOne ) { 
sbuff . setLength ( len + 1 ) ; 
} public static String pad ( String s , int width , boolean rightJustify ) { 
if ( s . length ( ) >= width ) { 
StringBuilder sbuff = new StringBuilder ( width ) ; 
int need = width - s . length ( ) ; 
sbuff . setLength ( need ) ; 
for ( int i = 0 ; i < need ; i ++ ) { 
if ( rightJustify ) { 
sbuff . append ( s ) ; 
sbuff . insert ( 0 , s ) ; 
return sbuff . toString ( ) ; 
} public static String i ( int v , int width ) { 
return pad ( Integer . toString ( v ) , width , true ) ; 
} public static String l ( long v , int width ) { 
return pad ( Long . toString ( v ) , width , true ) ; 
} public static String d ( double d , int min_sigfig , int width ) { 
String s = Format . d ( d , min_sigfig ) ; 
return pad ( s , width , true ) ; 
} public static String formatByteSize ( double size ) { 
String unit = null ; 
if ( size > 1.0e15 ) { 
unit = "Pbytes" ; 
size *= 1.0e-15 ; 
} else if ( size > 1.0e12 ) { 
unit = "Tbytes" ; 
size *= 1.0e-12 ; 
} else if ( size > 1.0e9 ) { 
unit = "Gbytes" ; 
size *= 1.0e-9 ; 
} else if ( size > 1.0e6 ) { 
unit = "Mbytes" ; 
size *= 1.0e-6 ; 
} else if ( size > 1.0e3 ) { 
unit = "Kbytes" ; 
size *= 1.0e-3 ; 
unit = "bytes" ; 
} private static void show ( double d , int sigfig ) { 
+ Format . d ( d , sigfig ) ) ; 
} private static void show2 ( double d , int dec_places ) { 
+ Format . dfrac ( d , dec_places ) ) ; 
} public String writeXML ( Document doc ) { 
return fmt . outputString ( doc ) ; 
} public void writeXML ( Document doc , OutputStream os ) throws IOException { 
fmt . output ( doc , os ) ; 
} public Document makeDatasetDescription ( ) { 
Element rootElem = new Element ( "gridDataset" ) ; 
Document doc = new Document ( rootElem ) ; 
rootElem . setAttribute ( "location" , gds . getLocation ( ) ) ; 
if ( null != path ) 
rootElem . setAttribute ( "path" , path ) ; 
for ( CoordinateAxis axis : getCoordAxes ( gds ) ) { 
rootElem . addContent ( writeAxis ( axis ) ) ; 
List < GridDataset . Gridset > gridSets = gds . getGridsets ( ) ; 
Collections . sort ( gridSets , new GridSetComparator ( ) ) ; 
for ( GridDataset . Gridset gridset : gridSets ) { 
rootElem . addContent ( writeGridSet ( gridset ) ) ; 
for ( CoordinateTransform ct : getCoordTransforms ( gds ) ) { 
rootElem . addContent ( writeCoordTransform ( ct ) ) ; 
LatLonRect bb = gds . getBoundingBox ( ) ; 
rootElem . addContent ( writeBoundingBox ( bb ) ) ; 
CalendarDate start = gds . getCalendarDateStart ( ) ; 
CalendarDate end = gds . getCalendarDateEnd ( ) ; 
if ( ( start != null ) && ( end != null ) ) { 
Element dateRange = new Element ( "TimeSpan" ) ; 
dateRange . addContent ( new Element ( "begin" ) . addContent ( start . toString ( ) ) ) ; 
dateRange . addContent ( new Element ( "end" ) . addContent ( end . toString ( ) ) ) ; 
rootElem . addContent ( dateRange ) ; 
addAcceptList ( rootElem ) ; 
} public Document makeGridForm ( ) { 
Element rootElem = new Element ( "gridForm" ) ; 
List < GridDatatype > grids = gds . getGrids ( ) ; 
Collections . sort ( grids , new GridComparator ( ) ) ; 
CoordinateAxis currentTime = null ; 
CoordinateAxis currentVert = null ; 
Element timeElem = null ; 
Element vertElem = null ; 
boolean newTime ; 
for ( int i = 0 ; i < grids . size ( ) ; i ++ ) { 
GeoGrid grid = ( GeoGrid ) grids . get ( i ) ; 
GridCoordSystem gcs = grid . getCoordinateSystem ( ) ; 
CoordinateAxis time = gcs . getTimeAxis ( ) ; 
CoordinateAxis vert = gcs . getVerticalAxis ( ) ; 
CoordinateAxis1D ens = gcs . getEnsembleAxis ( ) ; 
if ( ens != null ) { 
Element ensAxisEl = writeAxis2 ( ens , "ensemble" ) ; 
rootElem . addContent ( ensAxisEl ) ; 
if ( ( i == 0 ) || ! compareAxis ( time , currentTime ) ) { 
timeElem = new Element ( "timeSet" ) ; 
rootElem . addContent ( timeElem ) ; 
Element timeAxisElement = writeAxis2 ( time , "time" ) ; 
if ( timeAxisElement != null ) 
timeElem . addContent ( timeAxisElement ) ; 
currentTime = time ; 
newTime = true ; 
newTime = false ; 
if ( newTime || ! compareAxis ( vert , currentVert ) ) { 
vertElem = new Element ( "vertSet" ) ; 
timeElem . addContent ( vertElem ) ; 
Element vertAxisElement = writeAxis2 ( vert , "vert" ) ; 
if ( vertAxisElement != null ) 
vertElem . addContent ( vertAxisElement ) ; 
currentVert = vert ; 
vertElem . addContent ( writeGrid ( grid ) ) ; 
ProjectionRect rect = grids . get ( 0 ) . getCoordinateSystem ( ) . getBoundingBox ( ) ; 
Element projBBOX = new Element ( "projectionBox" ) ; 
Element minx = new Element ( "minx" ) ; 
minx . addContent ( Double . valueOf ( rect . getMinX ( ) ) . toString ( ) ) ; 
projBBOX . addContent ( minx ) ; 
Element maxx = new Element ( "maxx" ) ; 
maxx . addContent ( Double . valueOf ( rect . getMaxX ( ) ) . toString ( ) ) ; 
projBBOX . addContent ( maxx ) ; 
Element miny = new Element ( "miny" ) ; 
miny . addContent ( Double . valueOf ( rect . getMinY ( ) ) . toString ( ) ) ; 
projBBOX . addContent ( miny ) ; 
Element maxy = new Element ( "maxy" ) ; 
maxy . addContent ( Double . valueOf ( rect . getMaxY ( ) ) . toString ( ) ) ; 
projBBOX . addContent ( maxy ) ; 
rootElem . addContent ( projBBOX ) ; 
} private Element writeAxis ( CoordinateAxis axis ) { 
NcMLWriter ncmlWriter = new NcMLWriter ( ) ; 
Element varElem = new Element ( "axis" ) ; 
varElem . setAttribute ( "name" , axis . getFullName ( ) ) ; 
varElem . setAttribute ( "shape" , getShapeString ( axis . getShape ( ) ) ) ; 
DataType dt = axis . getDataType ( ) ; 
AxisType axisType = axis . getAxisType ( ) ; 
if ( null != axisType ) 
varElem . setAttribute ( "axisType" , axisType . toString ( ) ) ; 
for ( Attribute att : axis . getAttributes ( ) ) { 
varElem . addContent ( ncmlWriter . makeAttributeElement ( att ) ) ; 
if ( axis . getRank ( ) == 1 ) { 
Element values = ncmlWriter . makeValuesElement ( axis , true ) ; 
varElem . addContent ( values ) ; 
String message = String . format ( 
logger . warn ( message , e ) ; 
} private String getShapeString ( int [ ] shape ) { 
for ( int i = 0 ; i < shape . length ; i ++ ) { 
buf . append ( shape [ i ] ) ; 
} private Element writeCoordTransform ( CoordinateTransform ct ) { 
Element ctElem = new Element ( "coordTransform" ) ; 
ctElem . setAttribute ( "name" , ct . getName ( ) ) ; 
ctElem . setAttribute ( "transformType" , ct . getTransformType ( ) . toString ( ) ) ; 
for ( Parameter param : ct . getParameters ( ) ) { 
Element pElem = new Element ( "parameter" ) ; 
pElem . setAttribute ( "name" , param . getName ( ) ) ; 
pElem . setAttribute ( "value" , param . getStringValue ( ) ) ; 
ctElem . addContent ( pElem ) ; 
return ctElem ; 
} public static void main ( String args [ ] ) throws IOException { 
String url = "cdmremote:http://localhost:8080/thredds/cdmremote/grib/NCDC/CFSR/NCDC-CFSR/PGB-LatLon0p5" ; 
GridDataset ncd = ucar . nc2 . dt . grid . GridDataset . open ( url ) ; 
GridDatasetInfo info = new GridDatasetInfo ( ncd , null ) ; 
FileOutputStream fos2 = new FileOutputStream ( "C:/tmp2/gridInfo.xml" ) ; 
info . writeXML ( info . makeGridForm ( ) , fos2 ) ; 
fos2 . close ( ) ; 
String infoString = info . writeXML ( info . makeGridForm ( ) ) ; 
System . out . println ( infoString ) ; 
} public Slice 
finish ( ) 
if ( this . first == UNDEFINED ) this . first = 0 ; 
if ( this . stride == UNDEFINED ) this . stride = 1 ; 
if ( this . stop == UNDEFINED && this . maxsize != UNDEFINED ) 
this . stop = this . maxsize ; 
if ( this . stop == UNDEFINED && this . maxsize == UNDEFINED ) 
this . stop = this . first + 1 ; 
if ( this . maxsize == UNDEFINED && this . stop != UNDEFINED ) 
this . maxsize = this . stop ; 
assert ( this . first != UNDEFINED ) ; 
assert ( this . stride != UNDEFINED ) ; 
assert ( this . stop != UNDEFINED ) ; 
if ( this . first > this . maxsize ) 
if ( this . stop > ( this . maxsize + 1 ) ) 
if ( this . first < 0 ) 
if ( this . stop < 0 ) 
if ( this . stride <= 0 ) 
if ( this . first > this . stop ) 
} public long 
getCount ( ) 
assert this . first != UNDEFINED && this . stride != UNDEFINED && this . stop != UNDEFINED ; 
long count = ( this . stop ) - this . first ; 
count = ( count + this . stride - 1 ) ; 
count /= this . stride ; 
} public String toConstraintString ( ) 
if ( ( this . stop - this . first ) == 0 ) { 
return String . format ( "[0]" ) ; 
} else if ( this . stride == 1 ) { 
if ( ( this . stop - this . first ) == 1 ) 
return String . format ( "[%d]" , this . first ) ; 
return String . format ( "[%d:%d]" , this . first , this . stop - 1 ) ; 
return String . format ( "[%d:%d:%d]" , this . first , this . stride , this . stop - 1 ) ; 
} static public Slice 
compose ( Slice target , Slice src ) 
long sr_stride = target . getStride ( ) * src . getStride ( ) ; 
long sr_first = MAP ( target , src . getFirst ( ) ) ; 
long lastx = MAP ( target , src . getLast ( ) ) ; 
long sr_last = ( target . getLast ( ) < lastx ? target . getLast ( ) : lastx ) ; 
return new Slice ( sr_first , sr_last + 1 , sr_stride , sr_last + 1 ) . finish ( ) ; 
} static long 
MAP ( Slice target , long i ) 
if ( i < 0 ) 
if ( i > target . getStop ( ) ) 
return target . getFirst ( ) + i * target . getStride ( ) ; 
} static public void 
dumpbytes ( ByteBuffer buf0 , boolean skipdmr ) 
int savepos = buf0 . position ( ) ; 
int limit0 = buf0 . limit ( ) ; 
int skipcount = 0 ; 
if ( limit0 > MAXLIMIT ) limit0 = MAXLIMIT ; 
if ( limit0 >= buf0 . limit ( ) ) limit0 = buf0 . limit ( ) ; 
if ( skipdmr ) { 
ByteOrder saveorder = buf0 . order ( ) ; 
buf0 . order ( ByteOrder . BIG_ENDIAN ) ; 
skipcount = buf0 . getInt ( ) ; 
buf0 . order ( saveorder ) ; 
skipcount &= 0xFFFFFF ; 
skipcount += 4 ; 
byte [ ] bytes = new byte [ ( limit0 + 8 ) - skipcount ] ; 
Arrays . fill ( bytes , ( byte ) 0 ) ; 
buf0 . position ( savepos + skipcount ) ; 
buf0 . get ( bytes , 0 , limit0 - skipcount ) ; 
buf0 . position ( savepos ) ; 
System . err . println ( "order=" + buf0 . order ( ) ) ; 
ByteBuffer buf = ByteBuffer . wrap ( bytes ) . order ( buf0 . order ( ) ) ; 
dumpbytes ( buf ) ; 
dumpbytes ( ByteBuffer buf0 ) 
int stop = buf0 . limit ( ) ; 
int size = stop + 8 ; 
assert savepos == 0 ; 
byte [ ] bytes = new byte [ size ] ; 
buf0 . get ( bytes , 0 , stop ) ; 
buf . position ( 0 ) ; 
buf . limit ( size ) ; 
for ( i = 0 ; buf . position ( ) < stop ; i ++ ) { 
savepos = buf . position ( ) ; 
int iv = buf . getInt ( ) ; 
buf . position ( savepos ) ; 
long lv = buf . getLong ( ) ; 
short sv = buf . getShort ( ) ; 
byte b = buf . get ( ) ; 
int ub = ( ( int ) b ) & 0x000000FF ; 
long uiv = ( ( long ) iv ) & 0xFFFFFFFFL ; 
int usv = ( ( int ) sv ) & 0xFFFF ; 
int ib = ( int ) b ; 
char c = ( char ) ub ; 
String s = Character . toString ( c ) ; 
if ( c == '\r' ) s = "\\r" ; 
else if ( c == '\n' ) s = "\\n" ; 
System . err . printf ( "\t%5d\t0x%04x" , sv , usv ) ; 
System . err . println ( "failure:" + e ) ; 
} public static EarthEllipsoid getType ( String name ) { 
return hash . get ( name ) ; 
} public static EarthEllipsoid getType ( int epsgId ) { 
Collection < EarthEllipsoid > all = getAll ( ) ; 
for ( EarthEllipsoid ellipsoid : all ) { 
if ( ellipsoid . epsgId == epsgId ) { 
return ellipsoid ; 
} public NcStreamProto . DataCol encodeData2 ( String name , boolean isVlen , Section section , Array data ) { 
NcStreamProto . DataCol . Builder builder = NcStreamProto . DataCol . newBuilder ( ) ; 
DataType dataType = data . getDataType ( ) ; 
builder . setName ( name ) ; 
builder . setDataType ( NcStream . convertDataType ( data . getDataType ( ) ) ) ; 
builder . setBigend ( ByteOrder . nativeOrder ( ) == ByteOrder . BIG_ENDIAN ) ; 
builder . setVersion ( NcStream . ncstream_data_version ) ; 
if ( ! isVlen ) { 
builder . setNelems ( ( int ) data . getSize ( ) ) ; 
builder . setSection ( NcStream . encodeSection ( section ) ) ; 
if ( isVlen ) { 
builder . setIsVlen ( true ) ; 
encodeVlenData ( builder , section , data ) ; 
} else if ( dataType == DataType . STRING ) { 
if ( data instanceof ArrayChar ) { 
ArrayChar cdata = ( ArrayChar ) data ; 
for ( String s : cdata ) 
builder . addStringdata ( s ) ; 
Section ssection = section . removeLast ( ) ; 
builder . setSection ( NcStream . encodeSection ( ssection ) ) ; 
} else if ( data instanceof ArrayObject ) { 
while ( iter . hasNext ( ) ) 
builder . addStringdata ( ( String ) iter . next ( ) ) ; 
} else if ( dataType == DataType . OPAQUE ) { 
if ( data instanceof ArrayObject ) { 
ByteBuffer bb = ( ByteBuffer ) iter . next ( ) ; 
builder . addOpaquedata ( ByteString . copyFrom ( bb . duplicate ( ) ) ) ; 
} else if ( dataType == DataType . STRUCTURE ) { 
builder . setStructdata ( encodeStructureData ( data ) ) ; 
} else if ( dataType == DataType . SEQUENCE ) { 
builder . setPrimdata ( copyArrayToByteString ( data ) ) ; 
} public Array decode ( NcStreamProto . DataCol dproto , Section parentSection ) throws IOException { 
ByteOrder bo = dproto . getBigend ( ) ? ByteOrder . BIG_ENDIAN : ByteOrder . LITTLE_ENDIAN ; 
DataType dataType = NcStream . convertDataType ( dproto . getDataType ( ) ) ; 
Section section = ( dataType == DataType . SEQUENCE ) ? new Section ( ) : NcStream . decodeSection ( dproto . getSection ( ) ) ; 
if ( ! dproto . getIsVlen ( ) ) { 
assert dproto . getNelems ( ) == section . computeSize ( ) ; 
if ( dproto . getIsVlen ( ) ) { 
if ( parentSection == null ) 
return decodeVlenData ( dproto ) ; 
return decodeVlenData ( dproto , parentSection ) ; 
Array data = Array . factory ( dataType , section . getShape ( ) ) ; 
IndexIterator ii = data . getIndexIterator ( ) ; 
for ( String s : dproto . getStringdataList ( ) ) { 
ii . setObjectNext ( s ) ; 
return decodeStructureData ( dproto , parentSection ) ; 
for ( ByteString s : dproto . getOpaquedataList ( ) ) { 
ii . setObjectNext ( s . asReadOnlyByteBuffer ( ) ) ; 
ByteBuffer bb = dproto . getPrimdata ( ) . asReadOnlyByteBuffer ( ) ; 
bb . order ( bo ) ; 
return Array . factory ( dataType , section . getShape ( ) , bb ) ; 
} public Array decodeVlenData ( NcStreamProto . DataCol dproto ) throws IOException { 
Array alldata = Array . factory ( dataType , new int [ ] { dproto . getNelems ( ) } , bb ) ; 
IndexIterator all = alldata . getIndexIterator ( ) ; 
Section section = NcStream . decodeSection ( dproto . getSection ( ) ) ; 
Array [ ] data = new Array [ ( int ) section . computeSize ( ) ] ; 
for ( int len : dproto . getVlensList ( ) ) { 
Array primdata = Array . factory ( dataType , new int [ ] { len } ) ; 
IndexIterator prim = primdata . getIndexIterator ( ) ; 
prim . setObjectNext ( all . getObjectNext ( ) ) ; 
data [ count ++ ] = primdata ; 
return Array . makeVlenArray ( section . getShape ( ) , data ) ; 
} private Array decodeVlenData ( NcStreamProto . DataCol dproto , Section parentSection ) throws IOException { 
int psize = ( int ) parentSection . computeSize ( ) ; 
Section vsection = section . removeFirst ( parentSection ) ; 
int vsectionSize = ( int ) vsection . computeSize ( ) ; 
int countInner = 0 ; 
Array [ ] pdata = new Array [ psize ] ; 
for ( int pCount = 0 ; pCount < psize ; pCount ++ ) { 
Array [ ] vdata = new Array [ vsectionSize ] ; 
for ( int vCount = 0 ; vCount < vsectionSize ; vCount ++ ) { 
int vlen = dproto . getVlens ( countInner ++ ) ; 
Array primdata = Array . factory ( dataType , new int [ ] { vlen } ) ; 
for ( int i = 0 ; i < vlen ; i ++ ) { 
vdata [ vCount ] = primdata ; 
pdata [ pCount ] = Array . makeVlenArray ( vsection . getShape ( ) , vdata ) ; 
return Array . makeVlenArray ( parentSection . getShape ( ) , pdata ) ; 
} public ArrayList extract ( String url ) throws IOException { 
baseURL = new URL ( url ) ; 
InputStream in = baseURL . openStream ( ) ; 
InputStreamReader r = new InputStreamReader ( filterTag ( in ) , CDM . UTF8 ) ; 
HTMLEditorKit . ParserCallback callback = new CallerBacker ( ) ; 
urlList = new ArrayList ( ) ; 
wantURLS = true ; 
wantText = false ; 
parser . parse ( r , callback , false ) ; 
return urlList ; 
} public String getTextContent ( String url ) throws IOException { 
textBuffer = new StringBuffer ( 3000 ) ; 
wantURLS = false ; 
wantText = true ; 
return textBuffer . toString ( ) ; 
} private InputStream filterTag ( InputStream in ) throws IOException { 
BufferedReader buffIn = new BufferedReader ( new InputStreamReader ( in , CDM . UTF8 ) ) ; 
ByteArrayOutputStream bos = new ByteArrayOutputStream ( 10000 ) ; 
String line = buffIn . readLine ( ) ; 
while ( line != null ) { 
String lline = line . toLowerCase ( ) ; 
bos . write ( line . getBytes ( CDM . utf8Charset ) ) ; 
line = buffIn . readLine ( ) ; 
buffIn . close ( ) ; 
return new ByteArrayInputStream ( bos . toByteArray ( ) ) ; 
public long readToByteChannel ( ucar . nc2 . Variable v2 , Section section , WritableByteChannel channel ) 
return IospHelper . copyToByteChannel ( data , channel ) ; 
} public Document makeDatasetDescription ( ) throws IOException { 
rootElem . setAttribute ( "location" , gcd . getName ( ) ) ; 
for ( CoverageCoordAxis axis : gcd . getCoordAxes ( ) ) { 
for ( CoordSysSet gridset : gcd . getCoverageSets ( ) ) { 
rootElem . addContent ( writeCoverageSet ( gridset . getCoordSys ( ) , gridset . getCoverages ( ) , gcd . getProjBoundingBox ( ) ) ) ; 
for ( CoverageTransform ct : gcd . getCoordTransforms ( ) ) { 
LatLonRect bb = gcd . getLatlonBoundingBox ( ) ; 
CalendarDateRange calDateRange = gcd . getCalendarDateRange ( ) ; 
if ( calDateRange != null ) { 
dateRange . addContent ( new Element ( "begin" ) . addContent ( calDateRange . getStart ( ) . toString ( ) ) ) ; 
dateRange . addContent ( new Element ( "end" ) . addContent ( calDateRange . getEnd ( ) . toString ( ) ) ) ; 
} private Element writeCoordTransform ( CoverageTransform ct ) { 
ctElem . setAttribute ( "transformType" , ct . isHoriz ( ) ? "Projection" : "Vertical" ) ; 
for ( Attribute param : ct . getAttributes ( ) ) { 
Element pElem = ncmlWriter . makeAttributeElement ( param ) ; 
pElem . setName ( "parameter" ) ; 
public void addAll ( Iterable < Attribute > atts ) { 
for ( Attribute att : atts ) addAttribute ( att ) ; 
public boolean removeAttribute ( String attName ) { 
Attribute att = findAttribute ( attName ) ; 
return att != null && atts . remove ( att ) ; 
public boolean removeAttributeIgnoreCase ( String attName ) { 
Attribute att = findAttributeIgnoreCase ( attName ) ; 
} public List < Double > getOffsetsInTimeUnits ( ) { 
double start = firstDate . getMillis ( ) ; 
List < Double > result = new ArrayList < > ( runtimes . length ) ; 
for ( int idx = 0 ; idx < runtimes . length ; idx ++ ) { 
double runtime = ( double ) getRuntime ( idx ) ; 
double msecs = ( runtime - start ) ; 
result . add ( msecs / timeUnit . getValueInMillisecs ( ) ) ; 
} public void addActionSourceListener ( ActionSourceListener l ) { 
if ( ! eventType . equals ( l . getEventTypeName ( ) ) ) 
lm . addListener ( l ) ; 
l . addActionValueListener ( this ) ; 
} static public void main ( String [ ] argv ) { 
ActionCoordinator ac = new ActionCoordinator ( "test" ) ; 
ActionSourceListener as1 = new ActionSourceListener ( "test" ) { 
public void actionPerformed ( ActionValueEvent e ) { 
ac . addActionSourceListener ( as1 ) ; 
ActionSourceListener as2 = new ActionSourceListener ( "test" ) { 
ac . addActionSourceListener ( as2 ) ; 
ActionSourceListener as3 = new ActionSourceListener ( "test" ) { 
ac . addActionSourceListener ( as3 ) ; 
} public void attributeRemoved ( HttpSessionBindingEvent e ) { 
if ( e . getValue ( ) instanceof GuardedDataset ) { 
GuardedDataset gdataset = ( GuardedDataset ) e . getValue ( ) ; 
gdataset . close ( ) ; 
} static public EsriShapefileRenderer factory ( String filename ) { 
if ( sfileHash == null ) 
sfileHash = new HashMap < String , EsriShapefileRenderer > ( ) ; 
if ( sfileHash . containsKey ( filename ) ) 
return sfileHash . get ( filename ) ; 
EsriShapefileRenderer sfile = new EsriShapefileRenderer ( filename ) ; 
sfileHash . put ( filename , sfile ) ; 
return sfile ; 
setData ( ncVar . read ( ) ) ; 
os . print ( "\"" + Util . escattr ( val ) + "\"" ) ; 
throws IOException , EOFException , DataReadException { 
int dap_len = source . readInt ( ) ; 
if ( dap_len < 0 ) 
if ( dap_len > Short . MAX_VALUE ) 
int modFour = dap_len % 4 ; 
int pad = ( modFour != 0 ) ? ( 4 - modFour ) : 0 ; 
byte byteArray [ ] = new byte [ dap_len ] ; 
source . readFully ( byteArray , 0 , dap_len ) ; 
byte unused ; 
for ( int i = 0 ; i < pad ; i ++ ) 
unused = source . readByte ( ) ; 
statusUI . incrementByteCount ( 4 + dap_len + pad ) ; 
val = new String ( byteArray , 0 , dap_len , "ISO8859_1" ) ; 
hasValue = true ; 
catch ( UnsupportedEncodingException e ) { 
byte byteArray [ ] = val . getBytes ( "ISO8859_1" ) ; 
sink . writeInt ( byteArray . length ) ; 
int modFour = byteArray . length % 4 ; 
sink . write ( byteArray , 0 , byteArray . length ) ; 
for ( int i = 0 ; i < pad ; i ++ ) { 
sink . writeByte ( 0 ) ; 
} public boolean isInfinite ( ) { 
return ( x == java . lang . Double . POSITIVE_INFINITY ) 
|| ( x == java . lang . Double . NEGATIVE_INFINITY ) 
|| ( y == java . lang . Double . POSITIVE_INFINITY ) 
|| ( y == java . lang . Double . NEGATIVE_INFINITY ) ; 
} static public boolean isInfinite ( ProjectionPoint pt ) { 
return ( pt . getX ( ) == java . lang . Double . POSITIVE_INFINITY ) 
|| ( pt . getX ( ) == java . lang . Double . NEGATIVE_INFINITY ) 
|| ( pt . getY ( ) == java . lang . Double . POSITIVE_INFINITY ) 
|| ( pt . getY ( ) == java . lang . Double . NEGATIVE_INFINITY ) ; 
} public int [ ] computeChunkShape ( long maxChunkElems ) { 
int [ ] chunkShape = new int [ rank ] ; 
for ( int iDim = 0 ; iDim < rank ; ++ iDim ) { 
int size = ( int ) ( maxChunkElems / stride [ iDim ] ) ; 
size = ( size == 0 ) ? 1 : size ; 
size = Math . min ( size , shape [ iDim ] - current [ iDim ] ) ; 
chunkShape [ iDim ] = size ; 
return chunkShape ; 
} public void setValue ( SizeT value ) { 
Pointer p = getPointer ( ) ; 
if ( Native . SIZE_T_SIZE == 8 ) { 
p . setLong ( 0 , value . longValue ( ) ) ; 
p . setInt ( 0 , value . intValue ( ) ) ; 
} static public Date getStandardDate ( String text ) { 
double value ; 
String udunitString ; 
text = text . trim ( ) ; 
StringTokenizer stoker = new StringTokenizer ( text ) ; 
String firstToke = stoker . nextToken ( ) ; 
value = Double . parseDouble ( firstToke ) ; 
udunitString = text . substring ( firstToke . length ( ) ) ; 
} catch ( NumberFormatException e ) { 
value = 0.0 ; 
udunitString = text ; 
DateUnit du ; 
du = new DateUnit ( udunitString ) ; 
return du . makeDate ( value ) ; 
} static public Date getStandardOrISO ( String text ) { 
Date result = getStandardDate ( text ) ; 
result = formatter . getISODate ( text ) ; 
} public Date getDateOrigin ( ) { 
if ( ! ( uu instanceof TimeScaleUnit ) ) return null ; 
TimeScaleUnit tu = ( TimeScaleUnit ) uu ; 
return tu . getOrigin ( ) ; 
} public Date getDate ( ) { 
double secs = timeUnit . getValueInSeconds ( value ) ; 
return new Date ( getDateOrigin ( ) . getTime ( ) + ( long ) ( 1000 * secs ) ) ; 
} public Date makeDate ( double val ) { 
if ( Double . isNaN ( val ) ) return null ; 
double secs = timeUnit . getValueInSeconds ( val ) ; 
} public double makeValue ( Date date ) { 
double secs = date . getTime ( ) / 1000.0 ; 
double origin_secs = getDateOrigin ( ) . getTime ( ) / 1000.0 ; 
double diff = secs - origin_secs ; 
timeUnit . setValueInSeconds ( diff ) ; 
throw new RuntimeException ( e . getMessage ( ) ) ; 
return timeUnit . getValue ( ) ; 
} public String makeStandardDateString ( double value ) { 
Date date = makeDate ( value ) ; 
if ( date == null ) return null ; 
return formatter . toDateTimeStringISO ( date ) ; 
} private double getGridSpacingInKm ( String type ) { 
double value = gds . getDouble ( type ) ; 
if ( Double . isNaN ( value ) ) return value ; 
String gridUnit = gds . getParam ( GridDefRecord . GRID_UNITS ) ; 
SimpleUnit unit ; 
if ( gridUnit == null || gridUnit . length ( ) == 0 ) { 
unit = SimpleUnit . meterUnit ; 
unit = SimpleUnit . factory ( gridUnit ) ; 
if ( unit != null && SimpleUnit . isCompatible ( unit . getUnitString ( ) , "km" ) ) { 
value = unit . convertTo ( value , SimpleUnit . kmUnit ) ; 
} void addDimensionsToNetcdfFile ( NetcdfFile ncfile ) { 
if ( isLatLon ) { 
ncfile . addDimension ( g , new Dimension ( "lat" , gds . getInt ( GridDefRecord . NY ) , true ) ) ; 
ncfile . addDimension ( g , new Dimension ( "lon" , gds . getInt ( GridDefRecord . NX ) , true ) ) ; 
ncfile . addDimension ( g , new Dimension ( "y" , gds . getInt ( GridDefRecord . NY ) , true ) ) ; 
ncfile . addDimension ( g , new Dimension ( "x" , gds . getInt ( GridDefRecord . NX ) , true ) ) ; 
} void addToNetcdfFile ( NetcdfFile ncfile ) { 
double dy ; 
if ( gds . getDouble ( GridDefRecord . DY ) == GridDefRecord . UNDEFINED ) { 
dy = setLatLonDxDy ( ) ; 
dy = ( gds . getDouble ( GridDefRecord . LA2 ) < gds . getDouble ( GridDefRecord . LA1 ) ) 
? - gds . getDouble ( GridDefRecord . DY ) : gds . getDouble ( GridDefRecord . DY ) ; 
if ( isGaussian ) { 
addCoordAxis ( ncfile , "lat" , gds . getInt ( GridDefRecord . NY ) , gds . getDouble ( GridDefRecord . LA1 ) , dy , 
addCoordAxis ( ncfile , "lon" , gds . getInt ( GridDefRecord . NX ) , gds . getDouble ( GridDefRecord . LO1 ) , gds . getDouble ( GridDefRecord . DX ) , 
int projType = lookup . getProjectionType ( gds ) ; 
if ( makeProjection ( ncfile , projType ) ) { 
double [ ] yData , xData ; 
if ( projType == GridTableLookup . RotatedLatLon ) { 
double dy = ( gds . getDouble ( "La2" ) < gds . getDouble ( GridDefRecord . LA1 ) 
? - gds . getDouble ( GridDefRecord . DY ) : gds . getDouble ( GridDefRecord . DY ) ) ; 
yData = addCoordAxis ( ncfile , "y" , gds . getInt ( GridDefRecord . NY ) , 
gds . getDouble ( GridDefRecord . LA1 ) , dy , "degrees" , 
xData = addCoordAxis ( ncfile , "x" , gds . getInt ( GridDefRecord . NX ) , 
gds . getDouble ( GridDefRecord . LO1 ) , gds . getDouble ( GridDefRecord . DX ) , "degrees" , 
} else if ( projType == GridTableLookup . Orthographic ) { 
yData = addCoordAxis ( ncfile , "y" , gds . getInt ( GridDefRecord . NY ) , starty , incry , "km" , 
xData = addCoordAxis ( ncfile , "x" , gds . getInt ( GridDefRecord . NX ) , startx , incrx , "km" , 
} else if ( projType == GridTableLookup . Curvilinear ) { 
yData = null ; 
xData = null ; 
"projection_y_coordinate" , AxisType . GeoY ) ; 
"projection_x_coordinate" , AxisType . GeoX ) ; 
if ( GridServiceProvider . addLatLon && ( projType != GridTableLookup . Curvilinear ) ) 
addLatLon2D ( ncfile , xData , yData ) ; 
} private double [ ] addCoordAxis ( NetcdfFile ncfile , String name , int n , 
double start , double incr , String units , 
String desc , String standard_name , 
AxisType axis ) { 
Variable v = new Variable ( ncfile , g , null , name ) ; 
v . setDataType ( DataType . DOUBLE ) ; 
v . setDimensions ( name ) ; 
double [ ] data = new double [ n ] ; 
data [ i ] = start + incr * i ; 
Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { n } , data ) ; 
v . setCachedData ( dataArray , false ) ; 
v . addAttribute ( new Attribute ( "units" , units ) ) ; 
v . addAttribute ( new Attribute ( "long_name" , desc ) ) ; 
v . addAttribute ( new Attribute ( "standard_name" , standard_name ) ) ; 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , axis . toString ( ) ) ) ; 
ncfile . addVariable ( g , v ) ; 
} private double [ ] addGaussianLatAxis ( NetcdfFile ncfile , String name , 
String units , String desc , String standard_name , AxisType axis ) { 
double np = gds . getDouble ( GridDefRecord . NUMBERPARALLELS ) ; 
if ( Double . isNaN ( np ) ) np = gds . getDouble ( "Np" ) ; 
if ( Double . isNaN ( np ) ) 
double startLat = gds . getDouble ( GridDefRecord . LA1 ) ; 
double endLat = gds . getDouble ( GridDefRecord . LA2 ) ; 
int nlats = ( int ) ( 2 * np ) ; 
GaussianLatitudes gaussLats = GaussianLatitudes . factory ( nlats ) ; 
int bestStartIndex = 0 , bestEndIndex = 0 ; 
double bestStartDiff = Double . MAX_VALUE ; 
double bestEndDiff = Double . MAX_VALUE ; 
for ( int i = 0 ; i < nlats ; i ++ ) { 
double diff = Math . abs ( gaussLats . latd [ i ] - startLat ) ; 
if ( diff < bestStartDiff ) { 
bestStartDiff = diff ; 
bestStartIndex = i ; 
diff = Math . abs ( gaussLats . latd [ i ] - endLat ) ; 
if ( diff < bestEndDiff ) { 
bestEndDiff = diff ; 
bestEndIndex = i ; 
int ny = gds . getInt ( GridDefRecord . NY ) ; 
if ( Math . abs ( bestEndIndex - bestStartIndex + 1 ) != ny ) { 
nlats = ny ; 
gaussLats = GaussianLatitudes . factory ( nlats ) ; 
bestStartIndex = 0 ; 
bestEndIndex = ny - 1 ; 
boolean goesUp = bestEndIndex > bestStartIndex ; 
int useIndex = bestStartIndex ; 
double [ ] data = new double [ ny ] ; 
double [ ] gaussw = new double [ ny ] ; 
for ( int i = 0 ; i < ny ; i ++ ) { 
data [ i ] = gaussLats . latd [ useIndex ] ; 
gaussw [ i ] = gaussLats . gaussw [ useIndex ] ; 
if ( goesUp ) { 
useIndex ++ ; 
useIndex -- ; 
Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { ny } , data ) ; 
v . addAttribute ( new Attribute ( "weights" , "gaussw" ) ) ; 
v = new Variable ( ncfile , g , null , "gaussw" ) ; 
dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { ny } , gaussw ) ; 
} private boolean makeProjection ( NetcdfFile ncfile , int projType ) { 
switch ( projType ) { 
case GridTableLookup . RotatedLatLon : 
makeRotatedLatLon ( ncfile ) ; 
case GridTableLookup . PolarStereographic : 
makePS ( ) ; 
case GridTableLookup . LambertConformal : 
makeLC ( ) ; 
case GridTableLookup . Mercator : 
makeMercator ( ) ; 
case GridTableLookup . Orthographic : 
makeMSGgeostationary ( ) ; 
case GridTableLookup . Curvilinear : 
makeCurvilinearAxis ( ncfile ) ; 
+ gds . getInt ( GridDefRecord . GRID_TYPE ) ) ; 
Variable v = new Variable ( ncfile , g , null , grid_name ) ; 
v . setDataType ( DataType . CHAR ) ; 
v . setDimensions ( "" ) ; 
char [ ] data = new char [ ] { 'd' } ; 
Array dataArray = Array . factory ( DataType . CHAR , new int [ 0 ] , data ) ; 
for ( Attribute att : attributes ) 
v . addAttribute ( att ) ; 
v . addAttribute ( new Attribute ( GridCF . EARTH_SHAPE , shape_name ) ) ; 
double radius_spherical_earth = gds . getDouble ( GridDefRecord . RADIUS_SPHERICAL_EARTH ) ; 
if ( Double . isNaN ( radius_spherical_earth ) ) 
radius_spherical_earth = gds . getDouble ( "radius_spherical_earth" ) ; 
if ( ! Double . isNaN ( radius_spherical_earth ) ) { 
if ( radius_spherical_earth < 10000.00 ) 
radius_spherical_earth *= 1000.0 ; 
v . addAttribute ( new Attribute ( GridCF . EARTH_RADIUS , radius_spherical_earth ) ) ; 
double major_axis = gds . getDouble ( GridDefRecord . MAJOR_AXIS_EARTH ) ; 
if ( Double . isNaN ( major_axis ) ) 
major_axis = gds . getDouble ( "major_axis_earth" ) ; 
double minor_axis = gds . getDouble ( GridDefRecord . MINOR_AXIS_EARTH ) ; 
if ( Double . isNaN ( minor_axis ) ) 
minor_axis = gds . getDouble ( "minor_axis_earth" ) ; 
if ( ! Double . isNaN ( major_axis ) && ! Double . isNaN ( minor_axis ) ) { 
v . addAttribute ( new Attribute ( GridCF . SEMI_MAJOR_AXIS , major_axis ) ) ; 
v . addAttribute ( new Attribute ( GridCF . SEMI_MINOR_AXIS , minor_axis ) ) ; 
addGDSparams ( v ) ; 
} private void addGDSparams ( Variable v ) { 
List < String > keyList = new ArrayList < > ( gds . getKeys ( ) ) ; 
Collections . sort ( keyList ) ; 
String pre = getGDSprefix ( ) ; 
for ( String key : keyList ) { 
String name = pre + "_param_" + key ; 
String vals = gds . getParam ( key ) ; 
int vali = Integer . parseInt ( vals ) ; 
if ( key . equals ( GridDefRecord . VECTOR_COMPONENT_FLAG ) ) { 
String cf = GridCF . VectorComponentFlag . of ( vali ) ; 
v . addAttribute ( new Attribute ( name , cf ) ) ; 
v . addAttribute ( new Attribute ( name , vali ) ) ; 
double vald = Double . parseDouble ( vals ) ; 
v . addAttribute ( new Attribute ( name , vald ) ) ; 
v . addAttribute ( new Attribute ( name , vals ) ) ; 
} private void addCoordSystemVariable ( NetcdfFile ncfile , String name , String dims ) { 
Array dataArray = Array . factory ( DataType . CHAR , new int [ 0 ] , new char [ ] { '0' } ) ; 
v . addAttribute ( new Attribute ( _Coordinate . Axes , dims ) ) ; 
if ( isLatLon ( ) ) 
v . addAttribute ( new Attribute ( _Coordinate . Transforms , "" ) ) ; 
v . addAttribute ( new Attribute ( _Coordinate . Transforms , getGridName ( ) ) ) ; 
} private void makeLC ( ) { 
proj = new LambertConformal ( 
gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LOV ) , 
gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LATIN2 ) ) ; 
LatLonPointImpl startLL = 
new LatLonPointImpl ( gds . getDouble ( GridDefRecord . LA1 ) , gds . getDouble ( GridDefRecord . LO1 ) ) ; 
ProjectionPointImpl start = ( ProjectionPointImpl ) proj . latLonToProj ( startLL ) ; 
startx = start . getX ( ) ; 
starty = start . getY ( ) ; 
if ( Double . isNaN ( getDxInKm ( ) ) ) { 
setDxDy ( startx , starty , proj ) ; 
if ( GridServiceProvider . debugProj ) { 
double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) ; 
double La2 = gds . getDouble ( GridDefRecord . LA2 ) ; 
LatLonPointImpl endLL = new LatLonPointImpl ( La2 , Lo2 ) ; 
ProjectionPointImpl endPP = ( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; 
double endx = startx + getNx ( ) * getDxInKm ( ) ; 
double endy = starty + getNy ( ) * getDyInKm ( ) ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "lambert_conformal_conic" ) ) ; 
if ( gds . getDouble ( GridDefRecord . LATIN1 ) == gds . getDouble ( GridDefRecord . LATIN2 ) ) { 
attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , gds . getDouble ( GridDefRecord . LATIN1 ) ) ) ; 
double [ ] data = new double [ ] { gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LATIN2 ) } ; 
attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , Array . factory ( DataType . DOUBLE , new int [ ] { 2 } , data ) ) ) ; 
attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_CENTRAL_MERIDIAN , gds . getDouble ( GridDefRecord . LOV ) ) ) ; 
attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , gds . getDouble ( GridDefRecord . LATIN1 ) ) ) ; 
} private void makePS ( ) { 
String nproj = gds . getParam ( GridDefRecord . NPPROJ ) ; 
double latOrigin = ( nproj == null || nproj . equalsIgnoreCase ( "true" ) ) ? 90.0 : - 90.0 ; 
double scale ; 
double lad = gds . getDouble ( GridDefRecord . LAD ) ; 
if ( Double . isNaN ( lad ) ) { 
scale = .933 ; 
scale = ( 1.0 + Math . sin ( Math . toRadians ( Math . abs ( lad ) ) ) ) / 2 ; 
proj = new Stereographic ( latOrigin , gds . getDouble ( GridDefRecord . LOV ) , scale ) ; 
ProjectionPointImpl start = ( ProjectionPointImpl ) proj . latLonToProj ( 
new LatLonPointImpl ( gds . getDouble ( GridDefRecord . LA1 ) , gds . getDouble ( GridDefRecord . LO1 ) ) ) ; 
if ( Double . isNaN ( getDxInKm ( ) ) ) 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "polar_stereographic" ) ) ; 
attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , gds . getDouble ( GridDefRecord . LOV ) ) ) ; 
attributes . add ( new Attribute ( GridCF . STRAIGHT_VERTICAL_LONGITUDE_FROM_POLE , gds . getDouble ( GridDefRecord . LOV ) ) ) ; 
attributes . add ( new Attribute ( GridCF . SCALE_FACTOR_AT_PROJECTION_ORIGIN , scale ) ) ; 
attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , latOrigin ) ) ; 
} private void makeMercator ( ) { 
double Latin = gds . getDouble ( GridDefRecord . LAD ) ; 
if ( Double . isNaN ( Latin ) ) 
Latin = gds . getDouble ( GridDefRecord . LATIN ) ; 
double Lo1 = gds . getDouble ( GridDefRecord . LO1 ) ; 
double La1 = gds . getDouble ( GridDefRecord . LA1 ) ; 
proj = new Mercator ( Lo1 , Latin ) ; 
ProjectionPoint startP = proj . latLonToProj ( 
new LatLonPointImpl ( La1 , Lo1 ) ) ; 
startx = startP . getX ( ) ; 
starty = startP . getY ( ) ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "mercator" ) ) ; 
attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , Latin ) ) ; 
attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , Lo1 ) ) ; 
if ( Lo2 < Lo1 ) Lo2 += 360 ; 
endLL ) ; 
new ProjectionPointImpl ( startx , starty ) ) ; 
double endx = startx + ( getNx ( ) - 1 ) * getDxInKm ( ) ; 
double endy = starty + ( getNy ( ) - 1 ) * getDyInKm ( ) ; 
} private void makeRotatedLatLon ( NetcdfFile ncfile ) { 
double splat = gds . getDouble ( GridDefRecord . SPLAT ) ; 
double splon = gds . getDouble ( GridDefRecord . SPLON ) ; 
double spangle = gds . getDouble ( GridDefRecord . ROTATIONANGLE ) ; 
proj = new RotatedLatLon ( splat , splon , spangle ) ; 
LatLonPoint startLL = proj . projToLatLon ( 
new ProjectionPointImpl ( 
gds . getDouble ( GridDefRecord . LO1 ) , gds . getDouble ( GridDefRecord . LA1 ) ) ) ; 
startx = startLL . getLongitude ( ) ; 
starty = startLL . getLatitude ( ) ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "rotated_latlon_grib" ) ) ; 
attributes . add ( new Attribute ( "grid_south_pole_latitude" , splat ) ) ; 
attributes . add ( new Attribute ( "grid_south_pole_longitude" , splon ) ) ; 
attributes . add ( new Attribute ( "grid_south_pole_angle" , spangle ) ) ; 
"Lat=" + gds . getDouble ( GridDefRecord . LA1 ) ) ; 
LatLonPoint endUR = proj . projToLatLon ( new ProjectionPointImpl ( Lo2 , La2 ) ) ; 
double dy = ( La2 < gds . getDouble ( GridDefRecord . LA1 ) ) ? 
- gds . getDouble ( GridDefRecord . DY ) : gds . getDouble ( GridDefRecord . DY ) ; 
double endx = gds . getDouble ( GridDefRecord . LO1 ) + ( getNx ( ) - 1 ) * gds . getDouble ( GridDefRecord . DX ) ; 
double endy = gds . getDouble ( GridDefRecord . LA1 ) + ( getNy ( ) - 1 ) * dy ; 
} private void makeSpaceViewOrOthographic ( ) { 
double Lat0 = gds . getDouble ( GridDefRecord . LAP ) ; 
double Lon0 = gds . getDouble ( GridDefRecord . LOP ) ; 
double xp = gds . getDouble ( GridDefRecord . XP ) ; 
double yp = gds . getDouble ( GridDefRecord . YP ) ; 
double dx = gds . getDouble ( GridDefRecord . DX ) ; 
double dy = gds . getDouble ( GridDefRecord . DY ) ; 
double nr = gds . getDouble ( GridDefRecord . NR ) * 1e-6 ; 
double apparentDiameter = 2 * Math . sqrt ( ( nr - 1 ) / ( nr + 1 ) ) ; 
double gridLengthX = major_axis * apparentDiameter / dx ; 
double gridLengthY = minor_axis * apparentDiameter / dy ; 
gds . addParam ( GridDefRecord . DX , String . valueOf ( 1000 * gridLengthX ) ) ; 
gds . addParam ( GridDefRecord . DX , new Double ( 1000 * gridLengthX ) ) ; 
gds . addParam ( GridDefRecord . DY , String . valueOf ( 1000 * gridLengthY ) ) ; 
gds . addParam ( GridDefRecord . DY , new Double ( 1000 * gridLengthY ) ) ; 
startx = - gridLengthX * xp ; 
starty = - gridLengthY * yp ; 
double radius = Earth . getRadius ( ) / 1000.0 ; 
if ( nr == 1111111111.0 ) { 
proj = new Orthographic ( Lat0 , Lon0 , radius ) ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "orthographic" ) ) ; 
attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , Lon0 ) ) ; 
attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , Lat0 ) ) ; 
double height = ( nr - 1.0 ) * radius ; 
proj = new VerticalPerspectiveView ( Lat0 , Lon0 , radius , height ) ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "vertical_perspective" ) ) ; 
attributes . add ( new Attribute ( "height_above_earth" , height ) ) ; 
double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) + 360.0 ; 
ProjectionPointImpl endPP = 
( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; 
} private void makeMSGgeostationary ( ) { 
int x_off = gds . getInt ( GridDefRecord . XP ) ; 
int y_off = gds . getInt ( GridDefRecord . YP ) ; 
double dx ; 
if ( dy < 2100 ) { 
dx = 1207 ; 
dy = 1203 ; 
dx = 3622 ; 
dy = 3610 ; 
double as = 2 * Math . asin ( 1.0 / nr ) ; 
double cfac = dx / as ; 
double lfac = dy / as ; 
double scale_factor = ( nr - 1 ) * major_axis / 1000 ; 
double scale_x = scale_factor ; 
double scale_y = - scale_factor ; 
startx = scale_factor * ( 1 - x_off ) / cfac ; 
starty = scale_factor * ( y_off - ny ) / lfac ; 
incrx = scale_factor / cfac ; 
incry = scale_factor / lfac ; 
attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , "MSGnavigation" ) ) ; 
attributes . add ( new Attribute ( "height_from_earth_center" , nr * major_axis ) ) ; 
attributes . add ( new Attribute ( "scale_x" , scale_x ) ) ; 
attributes . add ( new Attribute ( "scale_y" , scale_y ) ) ; 
proj = new MSGnavigation ( Lat0 , Lon0 , major_axis , minor_axis , nr * major_axis , scale_x , scale_y ) ; 
double endx = 1 + getNx ( ) ; 
double endy = 1 + getNy ( ) ; 
} private void makeCurvilinearAxis ( NetcdfFile ncfile ) { 
List < Variable > vars = ncfile . getRootGroup ( ) . getVariables ( ) ; 
String latpp = null , lonpp = null , latU = null , lonU = null , latV = null , lonV = null ; 
List < String > timeDimLL = new ArrayList < > ( ) ; 
List < String > timeDimV = new ArrayList < > ( ) ; 
for ( Variable var : vars ) { 
if ( var . getShortName ( ) . startsWith ( "Latitude" ) ) { 
int [ ] shape = var . getShape ( ) ; 
if ( var . getRank ( ) == 3 && shape [ 0 ] == 1 ) { 
List < Dimension > dims = var . getDimensions ( ) ; 
if ( ! timeDimLL . contains ( dims . get ( 0 ) . getShortName ( ) ) ) 
timeDimLL . add ( dims . get ( 0 ) . getShortName ( ) ) ; 
dims . remove ( 0 ) ; 
var . setDimensions ( dims ) ; 
var . addAttribute ( new Attribute ( "units" , "degrees_north" ) ) ; 
var . addAttribute ( new Attribute ( "standard_name" , "latitude" ) ) ; 
var . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lat . toString ( ) ) ) ; 
if ( var . getShortName ( ) . contains ( "U_Wind_Component" ) ) { 
latU = var . getFullName ( ) ; 
} else if ( var . getShortName ( ) . contains ( "V_Wind_Component" ) ) { 
latV = var . getFullName ( ) ; 
latpp = var . getFullName ( ) ; 
} else if ( var . getShortName ( ) . startsWith ( "Longitude" ) ) { 
var . addAttribute ( new Attribute ( "units" , "degrees_east" ) ) ; 
var . addAttribute ( new Attribute ( "standard_name" , "longitude" ) ) ; 
var . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lon . toString ( ) ) ) ; 
lonU = var . getFullName ( ) ; 
lonV = var . getFullName ( ) ; 
lonpp = var . getFullName ( ) ; 
if ( var . getShortName ( ) . startsWith ( "U-component" ) ) { 
if ( ! timeDimV . contains ( dims . get ( 0 ) . getShortName ( ) ) ) 
timeDimV . add ( dims . get ( 0 ) . getShortName ( ) ) ; 
} else if ( var . getShortName ( ) . startsWith ( "V-component" ) ) { 
} private void setDxDy ( double startx , double starty , ProjectionImpl proj ) { 
if ( Double . isNaN ( Lo2 ) || Double . isNaN ( La2 ) ) { 
ProjectionPointImpl end = 
double dx = Math . abs ( end . getX ( ) - startx ) 
/ ( gds . getInt ( GridDefRecord . NX ) - 1 ) ; 
double dy = Math . abs ( end . getY ( ) - starty ) 
/ ( gds . getInt ( GridDefRecord . NY ) - 1 ) ; 
gds . addParam ( GridDefRecord . DX , String . valueOf ( dx ) ) ; 
gds . addParam ( GridDefRecord . DY , String . valueOf ( dy ) ) ; 
gds . addParam ( GridDefRecord . GRID_UNITS , "km" ) ; 
} private double setLatLonDxDy ( ) { 
double lo1 = gds . getDouble ( GridDefRecord . LO1 ) ; 
double la1 = gds . getDouble ( GridDefRecord . LA1 ) ; 
double lo2 = gds . getDouble ( GridDefRecord . LO2 ) ; 
double la2 = gds . getDouble ( GridDefRecord . LA2 ) ; 
if ( Double . isNaN ( lo2 ) || Double . isNaN ( la2 ) ) { 
return Double . NaN ; 
if ( lo2 < lo1 ) lo2 += 360 ; 
double dx = Math . abs ( lo2 - lo1 ) 
double dy = Math . abs ( la2 - la1 ) 
gds . addParam ( GridDefRecord . DX , new Double ( dx ) ) ; 
gds . addParam ( GridDefRecord . DY , new Double ( dy ) ) ; 
gds . addParam ( GridDefRecord . GRID_UNITS , "degree" ) ; 
return dy ; 
} protected InvAccessImpl readAccess ( InvDatasetImpl dataset , Element accessElem ) { 
String urlPath = accessElem . getAttributeValue ( "urlPath" ) ; 
String serviceName = accessElem . getAttributeValue ( "serviceName" ) ; 
String dataFormat = accessElem . getAttributeValue ( "dataFormat" ) ; 
return new InvAccessImpl ( dataset , urlPath , serviceName , null , dataFormat , readDataSize ( accessElem ) ) ; 
} protected InvDatasetImpl readDataset ( InvCatalogImpl catalog , InvDatasetImpl parent , Element dsElem , URI base ) { 
String name = dsElem . getAttributeValue ( "name" ) ; 
String alias = dsElem . getAttributeValue ( "alias" ) ; 
if ( alias != null ) { 
InvDatasetImpl ds = ( InvDatasetImpl ) catalog . findDatasetByID ( alias ) ; 
if ( ds == null ) { 
return new InvDatasetImplProxy ( name , ds ) ; 
InvDatasetImpl dataset = new InvDatasetImpl ( parent , name ) ; 
readDatasetInfo ( catalog , dataset , dsElem , base ) ; 
return dataset ; 
} protected InvDatasetScan readDatasetScan ( InvCatalogImpl catalog , InvDatasetImpl parent , Element dsElem , URI base ) { 
InvDatasetScan datasetScan ; 
if ( dsElem . getAttributeValue ( "dirLocation" ) == null ) { 
if ( dsElem . getAttributeValue ( "location" ) == null ) { 
datasetScan = null ; 
return readDatasetScanNew ( catalog , parent , dsElem , base ) ; 
String path = dsElem . getAttributeValue ( "path" ) ; 
String scanDir = expandAliasForPath ( dsElem . getAttributeValue ( "dirLocation" ) ) ; 
String filter = dsElem . getAttributeValue ( "filter" ) ; 
String addDatasetSizeString = dsElem . getAttributeValue ( "addDatasetSize" ) ; 
String addLatest = dsElem . getAttributeValue ( "addLatest" ) ; 
String sortOrderIncreasingString = dsElem . getAttributeValue ( "sortOrderIncreasing" ) ; 
boolean sortOrderIncreasing = false ; 
if ( sortOrderIncreasingString != null ) 
if ( sortOrderIncreasingString . equalsIgnoreCase ( "true" ) ) 
sortOrderIncreasing = true ; 
boolean addDatasetSize = true ; 
if ( addDatasetSizeString != null ) 
if ( addDatasetSizeString . equalsIgnoreCase ( "false" ) ) 
addDatasetSize = false ; 
if ( path != null ) { 
if ( path . charAt ( 0 ) == '/' ) path = path . substring ( 1 ) ; 
int last = path . length ( ) - 1 ; 
if ( path . charAt ( last ) == '/' ) path = path . substring ( 0 , last ) ; 
if ( scanDir != null ) { 
int last = scanDir . length ( ) - 1 ; 
if ( scanDir . charAt ( last ) != '/' ) scanDir = scanDir + '/' ; 
Element atcElem = dsElem . getChild ( "addTimeCoverage" , defNS ) ; 
String dsNameMatchPattern = null ; 
String startTimeSubstitutionPattern = null ; 
String duration = null ; 
if ( atcElem != null ) { 
dsNameMatchPattern = atcElem . getAttributeValue ( "datasetNameMatchPattern" ) ; 
startTimeSubstitutionPattern = atcElem . getAttributeValue ( "startTimeSubstitutionPattern" ) ; 
duration = atcElem . getAttributeValue ( "duration" ) ; 
datasetScan = new InvDatasetScan ( catalog , parent , name , path , scanDir , filter , addDatasetSize , addLatest , sortOrderIncreasing , 
dsNameMatchPattern , startTimeSubstitutionPattern , duration ) ; 
readDatasetInfo ( catalog , datasetScan , dsElem , base ) ; 
return datasetScan ; 
} protected DatasetEnhancer readDatasetScanAddTimeCoverage ( Element addTimeCovElem ) { 
DatasetEnhancer timeCovEnhancer = null ; 
String matchName = addTimeCovElem . getAttributeValue ( "datasetNameMatchPattern" ) ; 
String matchPath = addTimeCovElem . getAttributeValue ( "datasetPathMatchPattern" ) ; 
String subst = addTimeCovElem . getAttributeValue ( "startTimeSubstitutionPattern" ) ; 
String duration = addTimeCovElem . getAttributeValue ( "duration" ) ; 
if ( matchName != null && subst != null && duration != null ) { 
timeCovEnhancer = RegExpAndDurationTimeCoverageEnhancer 
. getInstanceToMatchOnDatasetName ( matchName , subst , duration ) ; 
} else if ( matchPath != null && subst != null && duration != null ) { 
. getInstanceToMatchOnDatasetPath ( matchPath , subst , duration ) ; 
return timeCovEnhancer ; 
} public Object readMetadataContent ( InvDataset dataset , org . jdom2 . Element mdataElement ) { 
InvMetadata m = readMetadata ( dataset . getParentCatalog ( ) , ( InvDatasetImpl ) dataset , mdataElement ) ; 
return m . getThreddsMetadata ( ) ; 
} public Object readMetadataContentFromURL ( InvDataset dataset , java . net . URI uri ) throws java . io . IOException { 
Element elem = readContentFromURL ( uri ) ; 
Object contentObject = readMetadataContent ( dataset , elem ) ; 
return contentObject ; 
} public void writeXML ( InvCatalogImpl catalog , OutputStream os , boolean raw ) throws IOException { 
this . raw = raw ; 
writeXML ( catalog , os ) ; 
this . raw = false ; 
} protected void writeInheritedMetadata ( Element elem , ThreddsMetadata tmi ) { 
Element mdataElem = new Element ( "metadata" , defNS ) ; 
mdataElem . setAttribute ( "inherited" , "true" ) ; 
writeThreddsMetadata ( mdataElem , tmi ) ; 
if ( mdataElem . getChildren ( ) . size ( ) > 0 ) 
elem . addContent ( mdataElem ) ; 
} public int getLevelType1 ( ) { 
int gribLevel = getDirBlock ( ) [ 51 ] ; 
int levelType = 0 ; 
if ( ! ( ( gribLevel == McIDASUtil . MCMISSING ) || ( gribLevel == 0 ) ) ) { 
levelType = gribLevel ; 
levelType = 1 ; 
return levelType ; 
} public boolean isValidFile ( RandomAccessFile raf ) throws IOException { 
String test = raf . readString ( MAGIC . length ( ) ) ; 
return test . equals ( MAGIC ) ; 
} public void open ( RandomAccessFile raf , NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { 
Structure seq = new Sequence ( ncfile , null , null , RECORD ) ; 
ncfile . addVariable ( null , seq ) ; 
Variable v = makeLightningVariable ( ncfile , null , seq , TSEC , DataType . INT , 
secondsSince1970 , 
AxisType . Time ) ; 
seq . addMemberVariable ( v ) ; 
v = makeLightningVariable ( ncfile , null , seq , "nsec" , DataType . INT , 
v = makeLightningVariable ( ncfile , null , seq , LAT , DataType . INT , "" , 
"latitude" , "latitude" , CDM . LAT_UNITS , 
AxisType . Lat ) ; 
v . addAttribute ( new Attribute ( CDM . SCALE_FACTOR , new Float ( 1.0e-3 ) ) ) ; 
v = makeLightningVariable ( ncfile , null , seq , LON , DataType . INT , "" , 
"longitude" , "longitude" , CDM . LON_UNITS , 
AxisType . Lon ) ; 
v = makeLightningVariable ( 
ncfile , null , seq , SIGNAL , DataType . SHORT , "" , 
v . addAttribute ( new Attribute ( CDM . SCALE_FACTOR , new Float ( 1.0e-1 ) ) ) ; 
v = makeLightningVariable ( ncfile , null , seq , MULTIPLICITY , 
DataType . BYTE , "" , 
"" , null ) ; 
v = new Variable ( ncfile , null , seq , FILL ) ; 
v = makeLightningVariable ( ncfile , null , seq , MAJOR_AXIS , 
v = makeLightningVariable ( ncfile , null , seq , ECCENTRICITY , 
v = makeLightningVariable ( ncfile , null , seq , ELLIPSE_ANGLE , 
null , "degrees" , null ) ; 
v = makeLightningVariable ( ncfile , null , seq , CHISQR , DataType . BYTE , 
"" , "chi-squared" , null , "" , null ) ; 
addLightningGlobalAttributes ( ncfile ) ; 
sm = seq . makeStructureMembers ( ) ; 
sm . findMember ( TSEC ) . setDataParam ( 0 ) ; 
sm . findMember ( NSEC ) . setDataParam ( 4 ) ; 
sm . findMember ( LAT ) . setDataParam ( 8 ) ; 
sm . findMember ( LON ) . setDataParam ( 12 ) ; 
sm . findMember ( SIGNAL ) . setDataParam ( 18 ) ; 
sm . findMember ( MULTIPLICITY ) . setDataParam ( 22 ) ; 
sm . findMember ( FILL ) . setDataParam ( 23 ) ; 
sm . findMember ( MAJOR_AXIS ) . setDataParam ( 24 ) ; 
sm . findMember ( ECCENTRICITY ) . setDataParam ( 25 ) ; 
sm . findMember ( ELLIPSE_ANGLE ) . setDataParam ( 26 ) ; 
sm . findMember ( CHISQR ) . setDataParam ( 27 ) ; 
sm . setStructureSize ( recSize ) ; 
} protected void addLightningGlobalAttributes ( NetcdfFile ncfile ) { 
super . addLightningGlobalAttributes ( ncfile ) ; 
ncfile . addAttribute ( null , 
ncfile . addAttribute ( null , new Attribute ( CDM . CONVENTIONS , "NLDN-CDM" ) ) ; 
} public Array readData ( Variable v2 , Section section ) 
return new ArraySequence ( sm , new SeqIter ( ) , nelems ) ; 
} public void write ( byte [ ] b , int off , int len ) throws IOException { 
count += len ; 
super . write ( b , off , len ) ; 
if ( ! isProject ( ) ) 
super . printVal ( os , space , print_decl_p ) ; 
} public boolean equal ( BaseType bt ) throws InvalidOperatorException , RegExpException , SBHException { 
return ( Operator . op ( EQUAL , this , bt ) ) ; 
} public void serialize ( String dataset , DataOutputStream sink , CEEvaluator ce , Object specialO ) 
throws NoSuchVariableException , DAP2ServerSideException , IOException { 
if ( ! isRead ( ) ) 
read ( dataset , specialO ) ; 
if ( ce . evalClauses ( specialO ) ) 
externalize ( sink ) ; 
public void setClearName ( String clearname ) 
super . setClearName ( clearname ) ; 
if ( _attr != null ) _attr . setClearName ( clearname ) ; 
if ( _attrTbl != null ) _attrTbl . setClearName ( clearname ) ; 
if ( print_semi ) 
os . println ( ";" ) ; 
} public final void printDecl ( PrintWriter os , String space ) { 
printDecl ( os , space , true , false ) ; 
} public final void printDecl ( OutputStream os , String space , 
PrintWriter pw = new PrintWriter ( new BufferedWriter ( new OutputStreamWriter ( os , Util . UTF8 ) ) ) ; 
printDecl ( pw , space , print_semi , constrained ) ; 
boolean print_semi ) { 
printDecl ( os , space , print_semi , false ) ; 
BaseType bt = ( BaseType ) super . cloneDAG ( map ) ; 
if ( this . _attrTbl != null ) 
bt . _attrTbl = ( AttributeTable ) cloneDAG ( map , this . _attrTbl ) ; 
if ( this . _attr != null ) 
bt . _attr = new Attribute ( getClearName ( ) , bt . _attrTbl ) ; 
return bt ; 
} public static TimeInstantType initTimeInstant ( TimeInstantType timeInstant ) { 
String id = MarshallingUtil . createIdForType ( TimeInstantType . class ) ; 
timeInstant . setId ( id ) ; 
NcTimePositionType . initTimePosition ( timeInstant . addNewTimePosition ( ) ) ; 
return timeInstant ; 
} static public String getCoordinateName ( NetcdfDataset ds , AxisType a ) { 
List < Variable > varList = ds . getVariables ( ) ; 
for ( Variable v : varList ) { 
if ( v instanceof Structure ) { 
List < Variable > vars = ( ( Structure ) v ) . getVariables ( ) ; 
for ( Variable vs : vars ) { 
String axisType = ds . findAttValueIgnoreCase ( vs , _Coordinate . AxisType , null ) ; 
if ( ( axisType != null ) && axisType . equals ( a . toString ( ) ) ) 
return vs . getShortName ( ) ; 
String axisType = ds . findAttValueIgnoreCase ( v , _Coordinate . AxisType , null ) ; 
return v . getShortName ( ) ; 
if ( a == AxisType . Lat ) 
return findVariableName ( ds , "latitude" ) ; 
if ( a == AxisType . Lon ) 
return findVariableName ( ds , "longitude" ) ; 
if ( a == AxisType . Time ) 
return findVariableName ( ds , "time" ) ; 
if ( a == AxisType . Height ) { 
Variable v = findVariable ( ds , "altitude" ) ; 
if ( null == v ) v = findVariable ( ds , "depth" ) ; 
if ( v != null ) return v . getShortName ( ) ; 
} static public String getCoordinateName ( NetcdfDataset ds , AxisType a , Dimension dim ) { 
String name = getCoordinateName ( ds , a ) ; 
Variable v = ds . findVariable ( name ) ; 
if ( v == null ) return null ; 
if ( v . isScalar ( ) ) return null ; 
if ( ! v . getDimension ( 0 ) . equals ( dim ) ) return null ; 
} public String buildXML ( ) 
StringBuilder response = new StringBuilder ( ) ; 
response . append ( "<Error" ) ; 
if ( code > 0 ) 
response . append ( ">\n" ) ; 
if ( message != null ) 
response . append ( "<Message>" + getMessage ( ) + "</Message>\n" ) ; 
if ( context != null ) 
response . append ( "<Context>" + getContext ( ) + "</Context>\n" ) ; 
if ( otherinfo != null ) 
response . append ( "<OtherInformation>" + getOtherInfo ( ) + "</OtherInformation>\n" ) ; 
return response . toString ( ) ; 
} public DapException buildException ( ) 
String XML = buildXML ( ) ; 
DapException dapex = new DapException ( XML ) . setCode ( code ) ; 
return dapex ; 
} private List < Dimension > breakupLevels ( NetcdfDataset ds , Variable levelVar ) throws IOException { 
List < Dimension > dimList = new ArrayList < > ( ) ; 
ArrayChar levelVarData ; 
levelVarData = ( ArrayChar ) levelVar . read ( ) ; 
return dimList ; 
List < String > values = null ; 
String currentUnits = null ; 
ArrayChar . StringIterator iter = levelVarData . getStringIterator ( ) ; 
String s = iter . next ( ) ; 
StringTokenizer stoke = new StringTokenizer ( s ) ; 
if ( ! stoke . hasMoreTokens ( ) ) 
String units = stoke . nextToken ( ) . trim ( ) ; 
if ( ! units . equals ( currentUnits ) ) { 
if ( values != null ) 
dimList . add ( makeZCoordAxis ( ds , values , currentUnits ) ) ; 
values = new ArrayList < > ( ) ; 
currentUnits = units ; 
if ( stoke . hasMoreTokens ( ) ) 
values . add ( stoke . nextToken ( ) ) ; 
values . add ( "0" ) ; 
} private Dimension makeZCoordAxis ( NetcdfDataset ds , List < String > values , String units ) throws IOException { 
int len = values . size ( ) ; 
String name = makeZCoordName ( units ) ; 
if ( len > 1 ) 
name = name + Integer . toString ( len ) ; 
name = name + values . get ( 0 ) ; 
Dimension dim ; 
if ( null != ( dim = ds . getRootGroup ( ) . findDimension ( name ) ) ) { 
if ( dim . getLength ( ) == len ) { 
Variable coord = ds . getRootGroup ( ) . findVariable ( name ) ; 
Array coordData = coord . read ( ) ; 
Array newData = Array . makeArray ( coord . getDataType ( ) , values ) ; 
if ( MAMath . nearlyEquals ( coordData , newData ) ) { 
String orgName = name ; 
int count = 1 ; 
while ( ds . getRootGroup ( ) . findDimension ( name ) != null ) { 
name = orgName + "-" + count ; 
dim = new Dimension ( name , len ) ; 
ds . addDimension ( null , dim ) ; 
if ( debugBreakup ) { 
CoordinateAxis v = new CoordinateAxis1D ( ds , null , name , DataType . DOUBLE , name , 
makeUnitsName ( units ) , makeLongName ( name ) ) ; 
String positive = getZisPositive ( ds , v ) ; 
if ( null != positive ) 
v . addAttribute ( new Attribute ( _Coordinate . ZisPositive , positive ) ) ; 
v . setValues ( values ) ; 
ds . addCoordinateAxis ( v ) ; 
v . getNameAndDimensions ( parseInfo , true , false ) ; 
parseInfo . format ( "%n" ) ; 
} private void createNewVariables ( NetcdfDataset ds , Variable ncVar , List < Dimension > newDims , 
Dimension levelDim ) throws InvalidRangeException { 
List < Dimension > dims = ncVar . getDimensions ( ) ; 
int newDimIndex = dims . indexOf ( levelDim ) ; 
int [ ] origin = new int [ ncVar . getRank ( ) ] ; 
int [ ] shape = ncVar . getShape ( ) ; 
for ( Dimension dim : newDims ) { 
String name = ncVar . getShortName ( ) + "-" + dim . getShortName ( ) ; 
origin [ newDimIndex ] = count ; 
shape [ newDimIndex ] = dim . getLength ( ) ; 
Variable varNew = ncVar . section ( new Section ( origin , shape ) ) ; 
varNew . setName ( name ) ; 
varNew . setDimension ( newDimIndex , dim ) ; 
String long_name = ds . findAttValueIgnoreCase ( ncVar , CDM . LONG_NAME , ncVar . getShortName ( ) ) ; 
long_name = long_name + "-" + dim . getShortName ( ) ; 
ds . addVariableAttribute ( varNew , new Attribute ( CDM . LONG_NAME , long_name ) ) ; 
ds . addVariable ( null , varNew ) ; 
varNew . getNameAndDimensions ( parseInfo , true , false ) ; 
count += dim . getLength ( ) ; 
} private CoordinateAxis makeTimeCoordAxisFromReference ( NetcdfDataset ds , Variable timeVar , Array vals ) { 
Variable refVar = ds . findVariable ( "reftime" ) ; 
if ( refVar == null ) return null ; 
double refValue ; 
Array refArray = refVar . read ( ) ; 
refValue = refArray . getDouble ( refArray . getIndex ( ) ) ; 
if ( refValue == N3iosp . NC_FILL_DOUBLE ) 
Array dvals = Array . factory ( DataType . DOUBLE , vals . getShape ( ) ) ; 
IndexIterator diter = dvals . getIndexIterator ( ) ; 
IndexIterator iiter = vals . getIndexIterator ( ) ; 
while ( iiter . hasNext ( ) ) 
diter . setDoubleNext ( iiter . getDoubleNext ( ) + refValue ) ; 
units = normalize ( units ) ; 
CoordinateAxis1D timeCoord = new CoordinateAxis1D ( ds , null , "timeCoord" , DataType . DOUBLE , "record" , units , desc ) ; 
timeCoord . setCachedData ( dvals , true ) ; 
timeCoord . getNameAndDimensions ( parseInfo , true , false ) ; 
return timeCoord ; 
} public static float bitShave ( float value , int bitMask ) { 
if ( Float . isNaN ( value ) ) return value ; 
int bits = Float . floatToRawIntBits ( value ) ; 
int shave = bits & bitMask ; 
return Float . intBitsToFloat ( shave ) ; 
String fileIn = ( args . length > 0 ) ? args [ 0 ] : "Q:/cdmUnitTest/formats/grib2/LMPEF_CLM_050518_1200.grb" ; 
String fileOut = ( args . length > 1 ) ? args [ 1 ] : "C:/tmp/ds.mint.bi" ; 
try ( GribToNetcdfWriter writer = new GribToNetcdfWriter ( fileIn , fileOut ) ) { 
writer . write ( ) ; 
} static public Set < Enhance > parseEnhanceMode ( String enhanceMode ) { 
if ( enhanceMode == null ) return null ; 
switch ( enhanceMode . toLowerCase ( ) ) { 
case "all" : return getEnhanceAll ( ) ; 
case "none" : return getEnhanceNone ( ) ; 
case "convertenums" : return EnumSet . of ( Enhance . ConvertEnums ) ; 
case "convertunsigned" : return EnumSet . of ( Enhance . ConvertUnsigned ) ; 
case "applyscaleoffset" : return EnumSet . of ( Enhance . ApplyScaleOffset ) ; 
case "convertmissing" : return EnumSet . of ( Enhance . ConvertMissing ) ; 
case "coordsystems" : return EnumSet . of ( Enhance . CoordSystems ) ; 
case "incompletecoordsystems" : return EnumSet . of ( Enhance . CoordSystems , 
Enhance . IncompleteCoordSystems ) ; 
case "true" : return getEnhanceAll ( ) ; 
case "scalemissingdefer" : return getEnhanceNone ( ) ; 
case "alldefer" : return EnumSet . of ( Enhance . ConvertEnums , Enhance . CoordSystems ) ; 
case "scalemissing" : return EnumSet . of ( 
Enhance . ConvertUnsigned , Enhance . ApplyScaleOffset , Enhance . ConvertMissing ) ; 
default : return null ; 
} static public synchronized void initNetcdfFileCache ( 
int minElementsInMemory , int maxElementsInMemory , int hardLimit , int period ) { 
netcdfFileCache = new ucar . nc2 . util . cache . FileCache ( 
} static public NetcdfDataset wrap ( NetcdfFile ncfile , Set < Enhance > mode ) throws IOException { 
if ( ncfile instanceof NetcdfDataset ) { 
NetcdfDataset ncd = ( NetcdfDataset ) ncfile ; 
if ( ! ncd . enhanceNeeded ( mode ) ) 
return ( NetcdfDataset ) ncfile ; 
return new NetcdfDataset ( ncfile , mode ) ; 
} static public NetcdfDataset openDataset ( String location , boolean enhance , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
return openDataset ( location , enhance , - 1 , cancelTask , null ) ; 
} static public NetcdfDataset openDataset ( String location , boolean enhance , int buffer_size , ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
return openDataset ( durl , enhance ? defaultEnhanceMode : null , buffer_size , cancelTask , spiObject ) ; 
} static public NetcdfDataset openDataset ( DatasetUrl location , Set < Enhance > enhanceMode , int buffer_size , 
ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
NetcdfFile ncfile = openOrAcquireFile ( null , null , null , location , buffer_size , cancelTask , spiObject ) ; 
NetcdfDataset ds ; 
ds = ( NetcdfDataset ) ncfile ; 
enhance ( ds , enhanceMode , cancelTask ) ; 
ds = new NetcdfDataset ( ncfile , enhanceMode ) ; 
return ds ; 
} static private CoordSysBuilderIF enhance ( NetcdfDataset ds , Set < Enhance > mode , CancelTask cancelTask ) throws IOException { 
if ( mode == null ) { 
mode = EnumSet . noneOf ( Enhance . class ) ; 
CoordSysBuilderIF builder = null ; 
if ( mode . contains ( Enhance . CoordSystems ) && ! ds . enhanceMode . contains ( Enhance . CoordSystems ) ) { 
builder = ucar . nc2 . dataset . CoordSysBuilder . factory ( ds , cancelTask ) ; 
builder . augmentDataset ( ds , cancelTask ) ; 
ds . convUsed = builder . getConventionUsed ( ) ; 
if ( ( mode . contains ( Enhance . ConvertEnums ) && ! ds . enhanceMode . contains ( Enhance . ConvertEnums ) ) 
|| ( mode . contains ( Enhance . ConvertUnsigned ) && ! ds . enhanceMode . contains ( Enhance . ConvertUnsigned ) ) 
|| ( mode . contains ( Enhance . ApplyScaleOffset ) && ! ds . enhanceMode . contains ( Enhance . ApplyScaleOffset ) ) 
|| ( mode . contains ( Enhance . ConvertMissing ) && ! ds . enhanceMode . contains ( Enhance . ConvertMissing ) ) ) { 
for ( Variable v : ds . getVariables ( ) ) { 
VariableEnhanced ve = ( VariableEnhanced ) v ; 
ve . enhance ( mode ) ; 
if ( ( cancelTask != null ) && cancelTask . isCancel ( ) ) return null ; 
if ( builder != null ) { 
if ( mode . contains ( Enhance . IncompleteCoordSystems ) ) { 
ds . enhanceMode . add ( Enhance . IncompleteCoordSystems ) ; 
builder . buildCoordinateSystems ( ds ) ; 
ds . enhanceMode . remove ( Enhance . IncompleteCoordSystems ) ; 
ds . finish ( ) ; 
ds . enhanceMode . addAll ( mode ) ; 
} static public NetcdfDataset acquireDataset ( DatasetUrl location , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
return acquireDataset ( null , location , defaultEnhanceMode , - 1 , cancelTask , null ) ; 
} static public NetcdfDataset acquireDataset ( FileFactory fac , DatasetUrl durl , Set < Enhance > enhanceMode , int buffer_size , 
ucar . nc2 . util . CancelTask cancelTask , Object iospMessage ) throws IOException { 
if ( netcdfFileCache == null ) { 
if ( fac == null ) 
return openDataset ( durl , enhanceMode , buffer_size , cancelTask , iospMessage ) ; 
return ( NetcdfDataset ) fac . open ( durl , buffer_size , cancelTask , iospMessage ) ; 
if ( fac != null ) 
return ( NetcdfDataset ) openOrAcquireFile ( netcdfFileCache , fac , null , durl , buffer_size , cancelTask , iospMessage ) ; 
fac = new MyNetcdfDatasetFactory ( durl , enhanceMode ) ; 
return ( NetcdfDataset ) openOrAcquireFile ( netcdfFileCache , fac , fac . hashCode ( ) , durl , buffer_size , cancelTask , iospMessage ) ; 
} public static NetcdfFile openFile ( String location , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
return openOrAcquireFile ( null , null , null , durl , - 1 , cancelTask , null ) ; 
} public static NetcdfFile openFile ( DatasetUrl location , int buffer_size , ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
return openOrAcquireFile ( null , null , null , location , buffer_size , cancelTask , spiObject ) ; 
} static public NetcdfFile acquireFile ( DatasetUrl location , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
return acquireFile ( null , null , location , - 1 , cancelTask , null ) ; 
} static public NetcdfFile acquireFile ( ucar . nc2 . util . cache . FileFactory factory , Object hashKey , 
DatasetUrl location , int buffer_size , ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
if ( ( netcdfFileCache == null ) && ( factory != null ) ) { 
return ( NetcdfFile ) factory . open ( location , buffer_size , cancelTask , spiObject ) ; 
return openOrAcquireFile ( netcdfFileCache , factory , hashKey , location , buffer_size , cancelTask , spiObject ) ; 
} static private NetcdfFile openOrAcquireFile ( FileCache cache , FileFactory factory , Object hashKey , DatasetUrl durl , 
int buffer_size , ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
if ( durl . serviceType != null ) { 
switch ( durl . serviceType ) { 
case OPENDAP : 
return acquireDODS ( cache , factory , hashKey , durl . trueurl , buffer_size , cancelTask , spiObject ) ; 
case CdmRemote : 
return acquireCdmRemote ( cache , factory , hashKey , durl . trueurl , buffer_size , cancelTask , spiObject ) ; 
case DAP4 : 
return acquireDap4 ( cache , factory , hashKey , durl . trueurl , buffer_size , cancelTask , spiObject ) ; 
case NCML : 
return acquireNcml ( cache , factory , hashKey , durl . trueurl , buffer_size , cancelTask , spiObject ) ; 
case THREDDS : 
Formatter log = new Formatter ( ) ; 
DataFactory tdf = new DataFactory ( ) ; 
NetcdfFile ncfile = tdf . openDataset ( durl . trueurl , false , cancelTask , log ) ; 
if ( ncfile == null ) 
throw new IOException ( log . toString ( ) ) ; 
return ncfile ; 
case File : 
case HTTPServer : 
if ( cache != null ) { 
if ( factory == null ) factory = defaultNetcdfFileFactory ; 
return ( NetcdfFile ) cache . acquire ( factory , hashKey , durl , buffer_size , cancelTask , spiObject ) ; 
return NetcdfFile . open ( durl . trueurl , buffer_size , cancelTask , spiObject ) ; 
} static private NetcdfFile acquireNcml ( FileCache cache , FileFactory factory , Object hashKey , 
String location , int buffer_size , ucar . nc2 . util . CancelTask cancelTask , Object spiObject ) throws IOException { 
if ( cache == null ) return NcMLReader . readNcML ( location , cancelTask ) ; 
if ( factory == null ) factory = new NcMLFactory ( ) ; 
return ( NetcdfFile ) cache . acquire ( factory , hashKey , DatasetUrl . findDatasetUrl ( location ) , buffer_size , cancelTask , spiObject ) ; 
} public void clearCoordinateSystems ( ) { 
coordSys = new ArrayList < > ( ) ; 
coordAxes = new ArrayList < > ( ) ; 
coordTransforms = new ArrayList < > ( ) ; 
for ( Variable v : getVariables ( ) ) { 
ve . clearCoordinateSystems ( ) ; 
enhanceMode . remove ( Enhance . CoordSystems ) ; 
} public CoordinateAxis findCoordinateAxis ( AxisType type ) { 
if ( type == null ) return null ; 
for ( CoordinateAxis v : coordAxes ) { 
if ( type == v . getAxisType ( ) ) 
} public CoordinateAxis findCoordinateAxis ( String fullName ) { 
if ( fullName == null ) return null ; 
if ( fullName . equals ( v . getFullName ( ) ) ) 
} public CoordinateSystem findCoordinateSystem ( String name ) { 
for ( CoordinateSystem v : coordSys ) { 
if ( name . equals ( v . getName ( ) ) ) 
} public CoordinateTransform findCoordinateTransform ( String name ) { 
for ( CoordinateTransform v : coordTransforms ) { 
public synchronized void close ( ) throws java . io . IOException { 
if ( agg != null ) { 
agg . persistWrite ( ) ; 
agg . close ( ) ; 
if ( cache . release ( this ) ) return ; 
if ( orgFile != null ) orgFile . close ( ) ; 
orgFile = null ; 
protected Boolean makeRecordStructure ( ) { 
if ( this . orgFile == null ) return false ; 
Boolean hasRecord = ( Boolean ) this . orgFile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
if ( ( hasRecord == null ) || ! hasRecord ) return false ; 
Variable orgV = this . orgFile . getRootGroup ( ) . findVariable ( "record" ) ; 
if ( ( orgV == null ) || ! ( orgV instanceof Structure ) ) return false ; 
Structure orgStructure = ( Structure ) orgV ; 
Dimension udim = getUnlimitedDimension ( ) ; 
if ( udim == null ) return false ; 
Group root = getRootGroup ( ) ; 
StructureDS newStructure = new StructureDS ( this , root , null , "record" , udim . getShortName ( ) , null , null ) ; 
newStructure . setOriginalVariable ( orgStructure ) ; 
if ( ! v . isUnlimited ( ) ) continue ; 
VariableDS memberV ; 
memberV = ( VariableDS ) v . slice ( 0 , 0 ) ; 
memberV . setParentStructure ( newStructure ) ; 
newStructure . addMemberVariable ( memberV ) ; 
root . addVariable ( newStructure ) ; 
finish ( ) ; 
} public CoordinateAxis addCoordinateAxis ( VariableDS v ) { 
CoordinateAxis oldVar = findCoordinateAxis ( v . getFullName ( ) ) ; 
if ( oldVar != null ) 
coordAxes . remove ( oldVar ) ; 
CoordinateAxis ca = ( v instanceof CoordinateAxis ) ? ( CoordinateAxis ) v : CoordinateAxis . factory ( this , v ) ; 
coordAxes . add ( ca ) ; 
if ( v . isMemberOfStructure ( ) ) { 
Structure parentOrg = v . getParentStructure ( ) ; 
Structure parent = ( Structure ) findVariable ( parentOrg . getFullNameEscaped ( ) ) ; 
parent . replaceMemberVariable ( ca ) ; 
removeVariable ( v . getParentGroup ( ) , v . getShortName ( ) ) ; 
addVariable ( ca . getParentGroup ( ) , ca ) ; 
return ca ; 
} public boolean enhanceNeeded ( Set < Enhance > want ) throws IOException { 
if ( want == null ) return false ; 
for ( Enhance mode : want ) { 
if ( ! this . enhanceMode . contains ( mode ) ) return true ; 
} public void setValues ( Variable v , int npts , double start , double incr ) { 
if ( npts != v . getSize ( ) ) 
Array data = Array . makeArray ( v . getDataType ( ) , npts , start , incr ) ; 
if ( v . getRank ( ) != 1 ) 
data = data . reshape ( v . getShape ( ) ) ; 
} public void setValues ( Variable v , List < String > values ) throws IllegalArgumentException { 
Array data = Array . makeArray ( v . getDataType ( ) , values ) ; 
if ( data . getSize ( ) != v . getSize ( ) ) 
} static public Array makeArray ( DataType dtype , List < String > stringValues ) throws NumberFormatException { 
return Array . makeArray ( dtype , stringValues ) ; 
public void getDetailInfo ( Formatter f ) { 
if ( agg == null ) { 
f . format ( "%nAggregation:%n" ) ; 
agg . getDetailInfo ( f ) ; 
if ( orgFile == null ) { 
showCached ( f ) ; 
showProxies ( f ) ; 
f . format ( "%s" , orgFile . getDetailInfo ( ) ) ; 
} void dumpClasses ( Group g , PrintWriter out ) { 
out . println ( "Dimensions:" ) ; 
for ( Dimension ds : g . getDimensions ( ) ) { 
out . println ( "Atributes:" ) ; 
for ( Attribute a : g . getAttributes ( ) ) { 
out . println ( "Variables:" ) ; 
dumpVariables ( g . getVariables ( ) , out ) ; 
out . println ( "Groups:" ) ; 
for ( Group nested : g . getGroups ( ) ) { 
dumpClasses ( nested , out ) ; 
} public static void debugDump ( PrintWriter out , NetcdfDataset ncd ) { 
String referencedLocation = ncd . orgFile == null ? "(null)" : ncd . orgFile . getLocation ( ) ; 
ncd . dumpClasses ( ncd . getRootGroup ( ) , out ) ; 
} public static void main ( String arg [ ] ) throws IOException { 
if ( arg . length < 4 ) { 
System . out . println ( usage ) ; 
boolean isLargeFile = false ; 
boolean netcdf4 = false ; 
String datasetIn = null , datasetOut = null ; 
for ( int i = 0 ; i < arg . length ; i ++ ) { 
String s = arg [ i ] ; 
if ( s . equalsIgnoreCase ( "-in" ) ) datasetIn = arg [ i + 1 ] ; 
if ( s . equalsIgnoreCase ( "-out" ) ) datasetOut = arg [ i + 1 ] ; 
if ( s . equalsIgnoreCase ( "-isLargeFile" ) ) isLargeFile = true ; 
if ( s . equalsIgnoreCase ( "-netcdf4" ) ) netcdf4 = true ; 
if ( ( datasetIn == null ) || ( datasetOut == null ) ) { 
NetcdfFile ncfileIn = ucar . nc2 . dataset . NetcdfDataset . openFile ( datasetIn , cancel ) ; 
NetcdfFileWriter . Version version = netcdf4 ? NetcdfFileWriter . Version . netcdf4 : NetcdfFileWriter . Version . netcdf3 ; 
FileWriter2 writer = new ucar . nc2 . FileWriter2 ( ncfileIn , datasetOut , version , null ) ; 
writer . getNetcdfFileWriter ( ) . setLargeFile ( isLargeFile ) ; 
ncfileIn . close ( ) ; 
System . out . printf ( "%s%n" , cancel ) ; 
} public static FeatureDatasetPoint getPointDataset ( HttpServletRequest request , HttpServletResponse response , String path ) throws IOException { 
TdsRequestedDataset trd = new TdsRequestedDataset ( request , null ) ; 
if ( path != null ) trd . path = path ; 
return trd . openAsPointDataset ( request , response ) ; 
} public static GridDataset getGridDataset ( HttpServletRequest request , HttpServletResponse response , String path ) throws IOException { 
return trd . openAsGridDataset ( request , response ) ; 
} public static CoverageCollection getCoverageCollection ( HttpServletRequest request , HttpServletResponse response , String path ) throws IOException { 
return trd . openAsCoverageDataset ( request , response ) ; 
} public static NetcdfFile getNetcdfFile ( HttpServletRequest request , HttpServletResponse response , String path ) throws IOException { 
return trd . openAsNetcdfFile ( request , response ) ; 
} public FeatureDatasetPoint openAsPointDataset ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
return datasetManager . openPointDataset ( request , response , path ) ; 
} public CoverageCollection openAsCoverageDataset ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
return datasetManager . openCoverageDataset ( request , response , path ) ; 
} public GridDataset openAsGridDataset ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
return isRemote ? ucar . nc2 . dt . grid . GridDataset . open ( path ) : datasetManager . openGridDataset ( request , response , path ) ; 
} public NetcdfFile openAsNetcdfFile ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
return isRemote ? NetcdfDataset . openDataset ( path ) : datasetManager . openNetcdfFile ( request , response , path ) ; 
} private Array extractMemberArrayFromIteration ( StructureMembers . Member proxym , int [ ] rshape ) throws IOException { 
DataType dataType = proxym . getDataType ( ) ; 
Object dataArray = null ; 
int initial = 1000 ; 
try ( StructureDataIterator sdataIter = getStructureDataIterator ( ) ) { 
switch ( dataType ) { 
ArrayList < Double > result = new ArrayList < > ( initial ) ; 
StructureMembers . Member realm = sdata . getStructureMembers ( ) . findMember ( proxym . getName ( ) ) ; 
double [ ] data = sdata . getJavaArrayDouble ( realm ) ; 
for ( double aData : data ) result . add ( aData ) ; 
double [ ] da = new double [ result . size ( ) ] ; 
for ( Double d : result ) da [ i ++ ] = d ; 
dataArray = da ; 
ArrayList < Float > result = new ArrayList < > ( initial ) ; 
float [ ] data = sdata . getJavaArrayFloat ( realm ) ; 
for ( float aData : data ) result . add ( aData ) ; 
float [ ] da = new float [ result . size ( ) ] ; 
for ( Float d : result ) da [ i ++ ] = d ; 
case UBYTE : 
case BYTE : 
case ENUM1 : 
ArrayList < Byte > result = new ArrayList < > ( initial ) ; 
byte [ ] data = sdata . getJavaArrayByte ( realm ) ; 
for ( byte aData : data ) result . add ( aData ) ; 
byte [ ] da = new byte [ result . size ( ) ] ; 
for ( Byte d : result ) da [ i ++ ] = d ; 
case USHORT : 
case SHORT : 
case ENUM2 : 
ArrayList < Short > result = new ArrayList < > ( initial ) ; 
short [ ] data = sdata . getJavaArrayShort ( realm ) ; 
for ( short aData : data ) result . add ( aData ) ; 
short [ ] da = new short [ result . size ( ) ] ; 
for ( Short d : result ) da [ i ++ ] = d ; 
case UINT : 
case INT : 
case ENUM4 : 
ArrayList < Integer > result = new ArrayList < > ( initial ) ; 
int [ ] data = sdata . getJavaArrayInt ( realm ) ; 
for ( int aData : data ) result . add ( aData ) ; 
int [ ] da = new int [ result . size ( ) ] ; 
for ( Integer d : result ) da [ i ++ ] = d ; 
case ULONG : 
ArrayList < Long > result = new ArrayList < > ( initial ) ; 
long [ ] data = sdata . getJavaArrayLong ( realm ) ; 
for ( long aData : data ) result . add ( aData ) ; 
long [ ] da = new long [ result . size ( ) ] ; 
for ( Long d : result ) da [ i ++ ] = d ; 
case CHAR : { 
ArrayList < Character > result = new ArrayList < > ( initial ) ; 
char [ ] data = sdata . getJavaArrayChar ( realm ) ; 
for ( char aData : data ) result . add ( aData ) ; 
char [ ] da = new char [ result . size ( ) ] ; 
for ( Character d : result ) da [ i ++ ] = d ; 
ArrayList < String > result = new ArrayList < > ( initial ) ; 
String [ ] data = sdata . getJavaArrayString ( realm ) ; 
result . addAll ( Arrays . asList ( data ) ) ; 
String [ ] da = new String [ result . size ( ) ] ; 
for ( String d : result ) da [ i ++ ] = d ; 
case STRUCTURE : { 
ArrayList < StructureData > result = new ArrayList < > ( initial ) ; 
ArrayStructure as = sdata . getArrayStructure ( realm ) ; 
StructureDataIterator innerIter = as . getStructureDataIterator ( ) ; 
while ( innerIter . hasNext ( ) ) 
result . add ( innerIter . next ( ) ) ; 
rshape [ 0 ] = count ; 
StructureMembers membersw = new StructureMembers ( proxym . getStructureMembers ( ) ) ; 
return new ArrayStructureW ( membersw , rshape , result . toArray ( new StructureData [ 0 ] ) ) ; 
return Array . factory ( dataType , rshape , dataArray ) ; 
index ( ) 
long offset = 0 ; 
for ( int i = 0 ; i < this . indices . length ; i ++ ) { 
offset *= this . dimsizes [ i ] ; 
offset += this . indices [ i ] ; 
} static public MFileOS7 getExistingFile ( String filename ) throws IOException { 
if ( filename == null ) return null ; 
Path path = Paths . get ( filename ) ; 
if ( Files . exists ( path ) ) return new MFileOS7 ( path ) ; 
} public static ServiceType findType ( String name ) { 
for ( ServiceType serviceType : members ) { 
if ( serviceType . name . equalsIgnoreCase ( name ) ) 
return serviceType ; 
} public static ServiceType getType ( String name ) { 
ServiceType type = findType ( name ) ; 
return type != null ? type : new ServiceType ( name , false ) ; 
} public void setCollection ( String spec ) throws IOException { 
this . spec = spec ; 
this . cust = null ; 
this . dcm = scanCollection ( spec , f ) ; 
if ( dcm == null ) { 
Map < Grib2Variable , Grib2ParameterBean > pdsSet = new HashMap < > ( ) ; 
Map < Integer , Grib2SectionGridDefinition > gdsSet = new HashMap < > ( ) ; 
java . util . List < Grib2ParameterBean > params = new ArrayList < > ( ) ; 
int fileno = 0 ; 
for ( MFile mfile : fileList ) { 
try ( ucar . unidata . io . RandomAccessFile raf = new ucar . unidata . io . RandomAccessFile ( mfile . getPath ( ) , "r" ) ) { 
raf . order ( ByteOrder . BIG_ENDIAN ) ; 
processGribFile ( mfile , fileno ++ , raf , pdsSet , gdsSet , params , f ) ; 
param2BeanTable . setBeans ( params ) ; 
} public void showInfo ( Formatter f ) { 
if ( spec == null ) return ; 
dcm = scanCollection ( spec , f ) ; 
if ( dcm == null ) return ; 
int nrecords = 0 ; 
long dataSize = 0 ; 
long msgSize = 0 ; 
for ( Object o : param2BeanTable . getBeans ( ) ) { 
Grib2ParameterBean p = ( Grib2ParameterBean ) o ; 
for ( Grib2RecordBean r : p . getRecordBeans ( ) ) { 
nrecords ++ ; 
dataSize += r . getDataLength ( ) ; 
msgSize += r . getMsgLength ( ) ; 
} private void checkDuplicates ( Formatter f ) { 
Set < Long > pdsMap = new HashSet < > ( ) ; 
int dups = 0 ; 
Map < CalendarDate , DateCount > dateMap = new HashMap < > ( ) ; 
List < Grib2ParameterBean > params = param2BeanTable . getBeans ( ) ; 
for ( Grib2ParameterBean param : params ) { 
for ( Grib2RecordBean record : param . getRecordBeans ( ) ) { 
CalendarDate d = record . gr . getReferenceDate ( ) ; 
DateCount dc = dateMap . get ( d ) ; 
if ( dc == null ) { 
dc = new DateCount ( d ) ; 
dateMap . put ( d , dc ) ; 
dc . count ++ ; 
Grib2SectionProductDefinition pdss = record . gr . getPDSsection ( ) ; 
long crc = pdss . calcCRC ( ) ; 
if ( pdsMap . contains ( crc ) ) 
dups ++ ; 
pdsMap . add ( crc ) ; 
List < DateCount > dcList = new ArrayList < > ( dateMap . values ( ) ) ; 
Collections . sort ( dcList ) ; 
for ( DateCount dc : dcList ) { 
total += dc . count ; 
} private void writeToFile ( List beans ) { 
if ( fileChooser == null ) 
fileChooser = new FileManager ( null , null , null , ( PreferencesExt ) prefs . node ( "FileManager" ) ) ; 
FileOutputStream fos = null ; 
RandomAccessFile raf = null ; 
String filename = null ; 
boolean append = false ; 
int n = 0 ; 
MFile curr = null ; 
for ( Object o : beans ) { 
Grib2RecordBean bean = ( Grib2RecordBean ) o ; 
MFile mfile = fileList . get ( bean . gr . getFile ( ) ) ; 
if ( curr == null || curr != mfile ) { 
if ( raf != null ) raf . close ( ) ; 
raf = new RandomAccessFile ( mfile . getPath ( ) , "r" ) ; 
curr = mfile ; 
if ( fos == null ) { 
String defloc = mfile . getPath ( ) ; 
filename = fileChooser . chooseFilenameToSave ( defloc + ".grib2" ) ; 
File f = new File ( filename ) ; 
append = f . exists ( ) ; 
fos = new FileOutputStream ( filename , append ) ; 
Grib2SectionIndicator is = bean . gr . getIs ( ) ; 
int size = ( int ) ( is . getMessageLength ( ) ) ; 
long startPos = is . getStartPos ( ) ; 
if ( startPos < 0 ) { 
byte [ ] rb = new byte [ size ] ; 
raf . seek ( startPos ) ; 
raf . readFully ( rb ) ; 
fos . write ( rb ) ; 
n ++ ; 
ex . printStackTrace ( ) ; 
if ( fos != null ) fos . close ( ) ; 
} public List < EsriFeature > getFeatures ( Rectangle2D bBox ) { 
if ( bBox == null ) 
return features ; 
List < EsriFeature > list = new ArrayList < > ( ) ; 
for ( EsriFeature gf : features ) { 
if ( gf . getBounds2D ( ) . intersects ( bBox ) ) 
list . add ( gf ) ; 
} private void discretize ( double [ ] d , int n ) { 
if ( coarseness == 0.0 ) 
d [ i ] = ( Math . rint ( resolution * d [ i ] ) / resolution ) ; 
} protected AxisType getAxisType ( NetcdfDataset ncDataset , 
VariableEnhanced v ) { 
String name = v . getShortName ( ) ; 
if ( name . equals ( "time" ) ) { 
return AxisType . Time ; 
if ( name . equals ( "lat" ) ) { 
return AxisType . Lat ; 
if ( name . equals ( "lon" ) ) { 
return AxisType . Lon ; 
if ( name . equals ( "alt" ) ) { 
return AxisType . Height ; 
} public void augmentDataset ( NetcdfDataset ds , CancelTask cancelTask ) throws IOException { 
if ( ! hasAxisType ( ds , AxisType . Lat ) ) { 
if ( ! addAxisType ( ds , "latitude" , AxisType . Lat ) ) { 
String vname = ds . findAttValueIgnoreCase ( null , "latitude_coordinate" , null ) ; 
if ( ! addAxisType ( ds , vname , AxisType . Lat ) ) { 
Variable v = hasUnits ( ds , "degrees_north,degrees_N,degreesN,degree_north,degree_N,degreeN" ) ; 
addAxisType ( v , AxisType . Lat ) ; 
if ( ! hasAxisType ( ds , AxisType . Lon ) ) { 
if ( ! addAxisType ( ds , "longitude" , AxisType . Lon ) ) { 
String vname = ds . findAttValueIgnoreCase ( null , "longitude_coordinate" , null ) ; 
if ( ! addAxisType ( ds , vname , AxisType . Lon ) ) { 
Variable v = hasUnits ( ds , "degrees_east,degrees_E,degreesE,degree_east,degree_E,degreeE" ) ; 
addAxisType ( v , AxisType . Lon ) ; 
if ( ! hasAxisType ( ds , AxisType . Height ) ) { 
if ( ! addAxisType ( ds , "altitude" , AxisType . Height ) ) { 
if ( ! addAxisType ( ds , "depth" , AxisType . Height ) ) { 
String vname = ds . findAttValueIgnoreCase ( null , "altitude_coordinate" , null ) ; 
if ( ! addAxisType ( ds , vname , AxisType . Height ) ) { 
for ( int i = 0 ; i < ds . getVariables ( ) . size ( ) ; i ++ ) { 
VariableEnhanced ve = ( VariableEnhanced ) ds . getVariables ( ) . get ( i ) ; 
String positive = ds . findAttValueIgnoreCase ( ( Variable ) ve , CF . POSITIVE , null ) ; 
if ( positive != null ) { 
addAxisType ( ( Variable ) ve , AxisType . Height ) ; 
if ( ! hasAxisType ( ds , AxisType . Time ) ) { 
if ( ! addAxisType ( ds , "time" , AxisType . Time ) ) { 
String vname = ds . findAttValueIgnoreCase ( null , "time_coordinate" , null ) ; 
if ( ! addAxisType ( ds , vname , AxisType . Time ) ) { 
String unit = ve . getUnitsString ( ) ; 
if ( unit == null ) continue ; 
if ( SimpleUnit . isDateUnit ( unit ) ) { 
addAxisType ( ( Variable ) ve , AxisType . Time ) ; 
} public void add ( ThreddsMetadata tmd , boolean includeInherited ) { 
creators . addAll ( tmd . getCreators ( ) ) ; 
contributors . addAll ( tmd . getContributors ( ) ) ; 
dates . addAll ( tmd . getDates ( ) ) ; 
docs . addAll ( tmd . getDocumentation ( ) ) ; 
keywords . addAll ( tmd . getKeywords ( ) ) ; 
projects . addAll ( tmd . getProjects ( ) ) ; 
properties . addAll ( tmd . getProperties ( ) ) ; 
publishers . addAll ( tmd . getPublishers ( ) ) ; 
variables . addAll ( tmd . getVariables ( ) ) ; 
if ( includeInherited ) 
metadata . addAll ( tmd . getMetadata ( ) ) ; 
for ( InvMetadata mdata : tmd . getMetadata ( ) ) { 
if ( ! mdata . isInherited ( ) ) 
metadata . add ( mdata ) ; 
if ( gc == null ) gc = tmd . getGeospatialCoverage ( ) ; 
if ( timeCoverage == null ) timeCoverage = tmd . getTimeCoverage ( ) ; 
if ( serviceName == null ) serviceName = tmd . getServiceName ( ) ; 
if ( dataType == null ) dataType = tmd . getDataType ( ) ; 
if ( dataSize == 0.0 ) dataSize = tmd . getDataSize ( ) ; 
if ( dataFormat == null ) dataFormat = tmd . getDataFormatType ( ) ; 
if ( authorityName == null ) authorityName = tmd . getAuthority ( ) ; 
if ( variableMapLink == null ) variableMapLink = tmd . getVariableMap ( ) ; 
} public void addDocumentation ( String type , String content ) { 
if ( content == null ) { 
removeDocumentation ( type ) ; 
content = content . trim ( ) ; 
for ( InvDocumentation doc : getDocumentation ( ) ) { 
String dtype = doc . getType ( ) ; 
if ( ( dtype != null ) && dtype . equalsIgnoreCase ( type ) ) { 
doc . setInlineContent ( content ) ; 
if ( content . length ( ) > 0 ) 
addDocumentation ( new InvDocumentation ( null , null , null , type , content ) ) ; 
} public void removeDocumentation ( String type ) { 
Iterator iter = docs . iterator ( ) ; 
InvDocumentation doc = ( InvDocumentation ) iter . next ( ) ; 
if ( ( dtype != null ) && dtype . equalsIgnoreCase ( type ) ) 
int segno = 0 ; 
while ( elem >= segMax [ segno ] ) segno ++ ; 
return segPos [ segno ] + elem - segMin [ segno ] ; 
} private int getMaxBytes ( long start ) { 
while ( start >= segMax [ segno ] ) segno ++ ; 
return ( int ) ( segMax [ segno ] - start ) ; 
} public static CalendarPeriod getCalendarPeriod ( int timeUnit ) { 
switch ( timeUnit ) { 
return CalendarPeriod . of ( 1 , CalendarPeriod . Field . Minute ) ; 
return CalendarPeriod . of ( 1 , CalendarPeriod . Field . Hour ) ; 
return CalendarPeriod . of ( 1 , CalendarPeriod . Field . Day ) ; 
return CalendarPeriod . of ( 1 , CalendarPeriod . Field . Month ) ; 
return CalendarPeriod . of ( 1 , CalendarPeriod . Field . Year ) ; 
return CalendarPeriod . of ( 10 , CalendarPeriod . Field . Year ) ; 
return CalendarPeriod . of ( 30 , CalendarPeriod . Field . Year ) ; 
return CalendarPeriod . of ( 100 , CalendarPeriod . Field . Year ) ; 
return CalendarPeriod . of ( 3 , CalendarPeriod . Field . Hour ) ; 
case 11 : 
return CalendarPeriod . of ( 6 , CalendarPeriod . Field . Hour ) ; 
case 12 : 
return CalendarPeriod . of ( 12 , CalendarPeriod . Field . Hour ) ; 
case 13 : 
return CalendarPeriod . of ( 15 , CalendarPeriod . Field . Minute ) ; 
case 14 : 
return CalendarPeriod . of ( 30 , CalendarPeriod . Field . Minute ) ; 
} public void printVal ( PrintWriter os , String space ) { 
int len = getLength ( ) ; 
for ( int i = 0 ; i < len - 1 ; i ++ ) { 
os . print ( ( ( long ) getValue ( i ) ) & 0xFFFFL ) ; 
if ( len > 0 ) 
os . print ( ( ( long ) getValue ( len - 1 ) ) & 0xFFFFL ) ; 
int modFour = vals . length % 4 ; 
for ( int i = 0 ; i < vals . length ; i ++ ) { 
vals [ i ] = source . readByte ( ) ; 
if ( statusUI != null ) { 
statusUI . incrementByteCount ( 1 ) ; 
if ( statusUI . userCancelled ( ) ) 
statusUI . incrementByteCount ( pad ) ; 
sink . writeByte ( vals [ i ] ) ; 
} public void externalize ( DataOutputStream sink , int start , int stop , int stride ) throws IOException { 
for ( int i = start ; i <= stop ; i += stride ) { 
int modFour = count % 4 ; 
} public static InputStream getInputStream ( String resourceName ) throws FileNotFoundException { 
ClassLoader cl = GribResourceReader . class . getClassLoader ( ) ; 
InputStream s = cl . getResourceAsStream ( resourceName ) ; 
File f = new File ( resourceName ) ; 
if ( f . exists ( ) ) 
return new FileInputStream ( f ) ; 
} public static boolean isMine ( NetcdfFile ncfile ) { 
String cs = ncfile . findAttValueIgnoreCase ( null , CDM . CONVENTIONS , null ) ; 
if ( cs != null ) return false ; 
String s = ncfile . findAttValueIgnoreCase ( null , "DataType" , null ) ; 
if ( ( s == null ) || ! ( s . equalsIgnoreCase ( "LatLonGrid" ) || s . equalsIgnoreCase ( "LatLonHeightGrid" ) ) ) 
if ( ( null == ncfile . findGlobalAttribute ( "Latitude" ) ) || 
( null == ncfile . findGlobalAttribute ( "Longitude" ) ) || 
( null == ncfile . findGlobalAttribute ( "LatGridSpacing" ) ) || 
( null == ncfile . findGlobalAttribute ( "LonGridSpacing" ) ) || 
( null == ncfile . findGlobalAttribute ( "Time" ) ) ) 
return ! ( null == ncfile . findDimension ( "Lat" ) || 
null == ncfile . findDimension ( "Lon" ) ) ; 
} static public StructureData make ( String name , Object value ) { 
StructureMembers members = new StructureMembers ( "" ) ; 
DataType dtype = DataType . getType ( value . getClass ( ) , false ) ; 
StructureMembers . Member m = members . addMember ( name , null , null , dtype , new int [ ] { 1 } ) ; 
StructureDataW sw = new StructureDataW ( members ) ; 
Array dataArray = Array . factory ( dtype , new int [ ] { 1 } ) ; 
dataArray . setObject ( dataArray . getIndex ( ) , value ) ; 
sw . setMemberData ( m , dataArray ) ; 
return sw ; 
public void getDataset ( Dataset ds , Object context ) { 
if ( ds . hasAccess ( ) ) { 
DataFactory tdataFactory = new DataFactory ( ) ; 
Access access = tdataFactory . chooseDatasetAccess ( ds . getAccess ( ) ) ; 
if ( access == null ) throw new IllegalStateException ( ) ; 
MFileRemote mfile = new MFileRemote ( access ) ; 
if ( mfile . getPath ( ) . endsWith ( ".xml" ) ) return ; 
mfiles . add ( mfile ) ; 
} static public void registerConvention ( String conventionName , Class c , ConventionNameOk match ) { 
if ( ! ( CoordSysBuilderIF . class . isAssignableFrom ( c ) ) ) 
conventionList . add ( 0 , new Convention ( conventionName , c , match ) ) ; 
conventionList . add ( new Convention ( conventionName , c , match ) ) ; 
} static public void registerConvention ( String conventionName , String className ) throws ClassNotFoundException { 
registerConvention ( conventionName , c , null ) ; 
} static public List < String > breakupConventionNames ( String convAttValue ) { 
List < String > names = new ArrayList < > ( ) ; 
if ( ( convAttValue . indexOf ( ',' ) > 0 ) || ( convAttValue . indexOf ( ';' ) > 0 ) ) { 
StringTokenizer stoke = new StringTokenizer ( convAttValue , ",;" ) ; 
while ( stoke . hasMoreTokens ( ) ) { 
String name = stoke . nextToken ( ) ; 
names . add ( name . trim ( ) ) ; 
} else if ( ( convAttValue . indexOf ( '/' ) > 0 ) ) { 
StringTokenizer stoke = new StringTokenizer ( convAttValue , "/" ) ; 
return names ; 
} static public String buildConventionAttribute ( String mainConv , String ... convAtts ) { 
List < String > result = new ArrayList < > ( ) ; 
result . add ( mainConv ) ; 
for ( String convs : convAtts ) { 
if ( convs == null ) continue ; 
List < String > ss = breakupConventionNames ( convs ) ; 
for ( String s : ss ) { 
if ( matchConvention ( s ) == null ) 
boolean start = true ; 
for ( String s : result ) { 
if ( start ) 
f . format ( "%s" , s ) ; 
start = false ; 
} static public @ Nonnull 
CoordSysBuilderIF factory ( NetcdfDataset ds , CancelTask cancelTask ) throws IOException { 
String convName = ds . findAttValueIgnoreCase ( null , CDM . CONVENTIONS , null ) ; 
if ( convName == null ) 
convName = ds . findAttValueIgnoreCase ( null , "Convention" , null ) ; 
if ( convName != null ) 
convName = convName . trim ( ) ; 
if ( convName != null ) { 
String convNcML = ncmlHash . get ( convName ) ; 
if ( convNcML != null ) { 
CoordSysBuilder csb = new CoordSysBuilder ( ) ; 
NcMLReader . wrapNcML ( ds , convNcML , cancelTask ) ; 
return csb ; 
Class convClass = null ; 
convClass = matchConvention ( convName ) ; 
if ( convClass == null ) { 
List < String > names = breakupConventionNames ( convName ) ; 
if ( names . size ( ) > 0 ) { 
for ( Convention conv : conventionList ) { 
for ( String name : names ) { 
if ( name . equalsIgnoreCase ( conv . convName ) ) { 
convClass = conv . convClass ; 
convName = name ; 
if ( convClass != null ) break ; 
Class c = conv . convClass ; 
Method m ; 
m = c . getMethod ( "isMine" , NetcdfFile . class ) ; 
} catch ( NoSuchMethodException ex ) { 
Boolean result = ( Boolean ) m . invoke ( null , ds ) ; 
if ( result ) { 
convClass = c ; 
for ( CoordSysBuilderIF csb : ServiceLoader . load ( CoordSysBuilderIF . class ) ) { 
Class c = csb . getClass ( ) ; 
builder = csb ; 
if ( convClass == null ) 
convClass = DefaultConvention . class ; 
if ( builder == null ) { 
builder = ( CoordSysBuilderIF ) convClass . newInstance ( ) ; 
else if ( convClass == DefaultConvention . class ) 
builder . setConventionUsed ( convClass . getName ( ) ) ; 
ds . addAttribute ( null , new Attribute ( _Coordinate . _CoordSysBuilder , convClass . getName ( ) ) ) ; 
public void buildCoordinateSystems ( NetcdfDataset ncDataset ) { 
addVariables ( ncDataset , ncDataset . getVariables ( ) , varList ) ; 
findCoordinateAxes ( ncDataset ) ; 
findCoordinateSystems ( ncDataset ) ; 
findCoordinateTransforms ( ncDataset ) ; 
makeCoordinateAxes ( ncDataset ) ; 
makeCoordinateSystems ( ncDataset ) ; 
assignCoordinateSystemsExplicit ( ncDataset ) ; 
makeCoordinateSystemsImplicit ( ncDataset ) ; 
if ( useMaximalCoordSys ) 
makeCoordinateSystemsMaximal ( ncDataset ) ; 
makeCoordinateTransforms ( ncDataset ) ; 
assignCoordinateTransforms ( ncDataset ) ; 
} protected void findCoordinateAxes ( NetcdfDataset ncDataset ) { 
for ( VarProcess vp : varList ) { 
if ( vp . coordAxes != null ) 
findCoordinateAxes ( vp , vp . coordAxes ) ; 
if ( vp . coordinates != null ) 
findCoordinateAxes ( vp , vp . coordinates ) ; 
} protected void findCoordinateSystems ( NetcdfDataset ncDataset ) { 
if ( vp . coordSys != null ) { 
StringTokenizer stoker = new StringTokenizer ( vp . coordSys ) ; 
String vname = stoker . nextToken ( ) ; 
VarProcess ap = findVarProcess ( vname , vp ) ; 
if ( ap != null ) { 
if ( ! ap . isCoordinateSystem ) 
ap . isCoordinateSystem = true ; 
} protected void findCoordinateTransforms ( NetcdfDataset ncDataset ) { 
if ( vp . coordTransforms != null ) { 
StringTokenizer stoker = new StringTokenizer ( vp . coordTransforms ) ; 
if ( ! ap . isCoordinateTransform ) 
ap . isCoordinateTransform = true ; 
} protected void makeCoordinateAxes ( NetcdfDataset ncDataset ) { 
if ( vp . isCoordinateAxis || vp . isCoordinateVariable ) { 
if ( vp . axisType == null ) 
vp . axisType = getAxisType ( ncDataset , ( VariableEnhanced ) vp . v ) ; 
if ( vp . axisType == null ) { 
vp . makeIntoCoordinateAxis ( ) ; 
} protected void makeCoordinateSystems ( NetcdfDataset ncDataset ) { 
if ( vp . isCoordinateSystem ) { 
vp . makeCoordinateSystem ( ) ; 
} protected void assignCoordinateSystemsExplicit ( NetcdfDataset ncDataset ) { 
if ( vp . coordSys != null && ! vp . isCoordinateTransform ) { 
if ( ap == null ) { 
if ( ap . cs == null ) { 
VariableEnhanced ve = ( VariableEnhanced ) vp . v ; 
ve . addCoordinateSystem ( ap . cs ) ; 
for ( VarProcess csVar : varList ) { 
if ( ! csVar . isCoordinateSystem || ( csVar . coordSysFor == null ) ) 
List < Dimension > dimList = new ArrayList < > ( 6 ) ; 
StringTokenizer stoker = new StringTokenizer ( csVar . coordSysFor ) ; 
String dname = stoker . nextToken ( ) ; 
Dimension dim = ncDataset . getRootGroup ( ) . findDimension ( dname ) ; 
if ( dim == null ) { 
dimList . add ( dim ) ; 
if ( ! vp . hasCoordinateSystem ( ) && vp . isData ( ) && ( csVar . cs != null ) ) { 
if ( CoordinateSystem . isSubset ( dimList , vp . v . getDimensionsAll ( ) ) && CoordinateSystem . isSubset ( vp . v . getDimensionsAll ( ) , dimList ) ) 
ve . addCoordinateSystem ( csVar . cs ) ; 
if ( ! vp . hasCoordinateSystem ( ) && ( vp . coordAxes != null ) && vp . isData ( ) ) { 
List < CoordinateAxis > dataAxesList = getAxes ( vp , vp . coordAxes , vp . v . getFullName ( ) ) ; 
if ( dataAxesList . size ( ) > 1 ) { 
String coordSysName = CoordinateSystem . makeName ( dataAxesList ) ; 
CoordinateSystem cs = ncDataset . findCoordinateSystem ( coordSysName ) ; 
if ( cs != null ) { 
ve . addCoordinateSystem ( cs ) ; 
CoordinateSystem csnew = new CoordinateSystem ( ncDataset , dataAxesList , null ) ; 
ve . addCoordinateSystem ( csnew ) ; 
ncDataset . addCoordinateSystem ( csnew ) ; 
} protected void makeCoordinateSystemsImplicit ( NetcdfDataset ncDataset ) { 
if ( ! vp . hasCoordinateSystem ( ) && vp . maybeData ( ) ) { 
List < CoordinateAxis > dataAxesList = vp . findCoordinateAxes ( true ) ; 
if ( dataAxesList . size ( ) < 2 ) 
String csName = CoordinateSystem . makeName ( dataAxesList ) ; 
CoordinateSystem cs = ncDataset . findCoordinateSystem ( csName ) ; 
if ( ( cs != null ) && cs . isComplete ( vp . v ) ) { 
csnew . setImplicit ( true ) ; 
if ( csnew . isComplete ( vp . v ) ) { 
} protected void makeCoordinateSystemsMaximal ( NetcdfDataset ncDataset ) { 
boolean requireCompleteCoordSys = ! ncDataset . getEnhanceMode ( ) . contains ( NetcdfDataset . Enhance . IncompleteCoordSystems ) ; 
if ( vp . hasCoordinateSystem ( ) || ! vp . isData ( ) ) continue ; 
List < CoordinateAxis > axisList = new ArrayList < > ( ) ; 
List < CoordinateAxis > axes = ncDataset . getCoordinateAxes ( ) ; 
for ( CoordinateAxis axis : axes ) { 
if ( isCoordinateAxisForVariable ( axis , ve ) ) 
axisList . add ( axis ) ; 
if ( axisList . size ( ) < 2 ) continue ; 
String csName = CoordinateSystem . makeName ( axisList ) ; 
boolean okToBuild = false ; 
if ( requireCompleteCoordSys ) { 
okToBuild = cs . isComplete ( ve ) ; 
okToBuild = true ; 
if ( cs != null && okToBuild ) { 
CoordinateSystem csnew = new CoordinateSystem ( ncDataset , axisList , null ) ; 
okToBuild = csnew . isComplete ( ve ) ; 
if ( okToBuild ) { 
} protected boolean isCoordinateAxisForVariable ( Variable axis , VariableEnhanced v ) { 
List < Dimension > varDims = v . getDimensionsAll ( ) ; 
List < Dimension > axisDims = axis . getDimensionsAll ( ) ; 
int checkDims = axisDims . size ( ) ; 
if ( axis . getDataType ( ) == DataType . CHAR ) 
checkDims -- ; 
for ( int i = 0 ; i < checkDims ; i ++ ) { 
Dimension axisDim = axisDims . get ( i ) ; 
if ( ! varDims . contains ( axisDim ) ) { 
} protected void makeCoordinateTransforms ( NetcdfDataset ncDataset ) { 
if ( vp . isCoordinateTransform && vp . ct == null ) { 
vp . ct = CoordTransBuilder . makeCoordinateTransform ( vp . ds , vp . v , parseInfo , userAdvice ) ; 
} protected void assignCoordinateTransforms ( NetcdfDataset ncDataset ) { 
if ( vp . isCoordinateSystem && vp . coordTransforms != null ) { 
if ( ap . ct != null ) { 
vp . addCoordinateTransform ( ap . ct ) ; 
if ( vp . isCoordinateTransform && ( vp . ct != null ) && ( vp . coordSys != null ) ) { 
VarProcess vcs = findVarProcess ( vname , vp ) ; 
if ( vcs == null ) { 
vcs . addCoordinateTransform ( vp . ct ) ; 
if ( vp . isCoordinateTransform && ( vp . ct != null ) && ( vp . coordAxes != null ) ) { 
List < CoordinateAxis > dataAxesList = vp . findCoordinateAxes ( false ) ; 
if ( dataAxesList . size ( ) > 0 ) { 
for ( CoordinateSystem cs : ncDataset . getCoordinateSystems ( ) ) { 
if ( cs . containsAxes ( dataAxesList ) ) { 
cs . addCoordinateTransform ( vp . ct ) ; 
if ( vp . isCoordinateTransform && ( vp . ct != null ) && ( vp . coordAxisTypes != null ) ) { 
List < AxisType > axisTypesList = new ArrayList < > ( ) ; 
StringTokenizer stoker = new StringTokenizer ( vp . coordAxisTypes ) ; 
String name = stoker . nextToken ( ) ; 
AxisType atype ; 
if ( null != ( atype = AxisType . getType ( name ) ) ) 
axisTypesList . add ( atype ) ; 
if ( axisTypesList . size ( ) > 0 ) { 
if ( cs . containsAxisTypes ( axisTypesList ) ) { 
} protected void addCoordinateVariable ( Dimension dim , VarProcess vp ) { 
List < VarProcess > list = coordVarMap . get ( dim ) ; 
if ( list == null ) { 
list = new ArrayList < > ( ) ; 
coordVarMap . put ( dim , list ) ; 
if ( ! list . contains ( vp ) ) 
list . add ( vp ) ; 
} public void subset ( InvDataset ds ) { 
InvDatasetImpl dataset = ( InvDatasetImpl ) ds ; 
dataset . transferMetadata ( dataset , true ) ; 
topDataset = dataset ; 
datasets . clear ( ) ; 
datasets . add ( topDataset ) ; 
dataset . dataType = dataset . getDataType ( ) ; 
dataset . setCatalog ( this ) ; 
dataset . parent = null ; 
List < InvService > services = new ArrayList < InvService > ( dataset . getServicesLocal ( ) ) ; 
findServices ( services , dataset ) ; 
dataset . setServicesLocal ( services ) ; 
} void findServices ( List < InvService > result , InvDataset ds ) { 
if ( ds instanceof InvCatalogRef ) return ; 
for ( InvAccess a : ds . getAccess ( ) ) { 
InvService s = a . getService ( ) ; 
InvDataset d = a . getDataset ( ) ; 
if ( null == d . findService ( s . getName ( ) ) && ! ( result . contains ( s ) ) ) 
for ( InvDataset nested : ds . getDatasets ( ) ) { 
findServices ( result , nested ) ; 
} public void filter ( DatasetFilter filter ) { 
mark ( filter , topDataset ) ; 
delete ( topDataset ) ; 
this . filter = filter ; 
} private boolean mark ( DatasetFilter filter , InvDatasetImpl ds ) { 
if ( ds instanceof InvCatalogRef ) { 
InvCatalogRef catRef = ( InvCatalogRef ) ds ; 
if ( ! catRef . isRead ( ) ) return false ; 
boolean allMarked = true ; 
allMarked &= mark ( filter , ( InvDatasetImpl ) nested ) ; 
if ( ! allMarked ) return false ; 
if ( filter . accept ( ds ) >= 0 ) 
ds . setMark ( true ) ; 
} private void delete ( InvDatasetImpl ds ) { 
if ( ! catRef . isRead ( ) ) return ; 
Iterator iter = ds . getDatasets ( ) . iterator ( ) ; 
InvDatasetImpl nested = ( InvDatasetImpl ) iter . next ( ) ; 
if ( nested . getMark ( ) ) { 
delete ( nested ) ; 
} public boolean finish ( ) { 
if ( datasets . size ( ) == 1 ) { 
topDataset = ( InvDatasetImpl ) datasets . get ( 0 ) ; 
for ( InvDataset dataset : datasets ) 
topDataset . addDataset ( ( InvDatasetImpl ) dataset ) ; 
topDataset . setServicesLocal ( services ) ; 
topDataset . setCatalog ( this ) ; 
dsHash = new HashMap < String , InvDataset > ( ) ; 
addDatasetIds ( topDataset ) ; 
return topDataset . finish ( ) ; 
private void addDatasetIds ( InvDatasetImpl ds ) { 
addDatasetByID ( ds ) ; 
for ( InvDataset invDataset : ds . getDatasets ( ) ) { 
InvDatasetImpl nested = ( InvDatasetImpl ) invDataset ; 
addDatasetIds ( nested ) ; 
public void addDatasetByID ( InvDatasetImpl ds ) { 
if ( ds . getID ( ) != null ) 
dsHash . put ( ds . getID ( ) , ds ) ; 
public void removeDatasetByID ( InvDatasetImpl ds ) { 
dsHash . remove ( ds . getID ( ) ) ; 
public void addDataset ( InvDatasetImpl ds ) { 
if ( ds != null ) 
datasets . add ( ds ) ; 
public boolean removeDataset ( InvDatasetImpl ds ) { 
if ( this . datasets . remove ( ds ) ) { 
ds . setParent ( null ) ; 
removeDatasetByID ( ds ) ; 
public boolean replaceDataset ( InvDatasetImpl remove , InvDatasetImpl add ) { 
if ( topDataset . equals ( remove ) ) { 
topDataset = add ; 
for ( int i = 0 ; i < datasets . size ( ) ; i ++ ) { 
InvDataset dataset = datasets . get ( i ) ; 
if ( dataset . equals ( remove ) ) { 
datasets . set ( i , add ) ; 
removeDatasetByID ( remove ) ; 
addDatasetByID ( add ) ; 
public void addProperty ( InvProperty p ) { 
properties . add ( p ) ; 
public void addService ( InvService s ) { 
if ( s . getName ( ) != null ) { 
Object obj = serviceHash . get ( s . getName ( ) ) ; 
if ( obj == null ) { 
serviceHash . put ( s . getName ( ) , s ) ; 
services . add ( s ) ; 
if ( s . equals ( obj ) ) { 
public void setDataset ( InvDatasetImpl ds ) { 
topDataset = ds ; 
addDataset ( ds ) ; 
public String getCreateFrom ( ) { 
return createFrom ; 
public void setCreateFrom ( String createFrom ) { 
this . createFrom = createFrom ; 
public void setBaseURI ( URI baseURI ) { 
this . baseURI = baseURI ; 
public URI getBaseURI ( ) { 
return baseURI ; 
public String getDTDid ( ) { 
return dtdID ; 
public void setExpires ( DateType expiresDate ) { 
this . expires = expiresDate ; 
public boolean hasFatalError ( ) { 
return hasError ; 
public void appendErrorMessage ( String message , boolean isInvalid ) { 
log . append ( message ) ; 
hasError = hasError | isInvalid ; 
public boolean check ( StringBuilder out , boolean show ) { 
boolean isValid = ! hasError ; 
if ( log . length ( ) > 0 ) 
out . append ( log ) ; 
for ( InvDataset ds : datasets ) { 
InvDatasetImpl dsi = ( InvDatasetImpl ) ds ; 
dsi . check ( out , show ) ; 
return isValid ; 
public String getLog ( ) { 
return log . toString ( ) ; 
public String dump ( ) { 
StringBuilder buff = new StringBuilder ( 1000 ) ; 
buff . append ( topDataset . dump ( 2 ) ) ; 
return buff . toString ( ) ; 
public void addPropertyChangeListener ( PropertyChangeListener l ) { 
if ( listenerList == null ) listenerList = new EventListenerList ( ) ; 
listenerList . add ( PropertyChangeListener . class , l ) ; 
InvCatalogImpl getTopCatalog ( ) { 
return ( top == null ) ? this : top ; 
void setTopCatalog ( InvCatalogImpl top ) { 
this . top = top ; 
private InvCatalogImpl top = null ; 
public void writeXML ( java . io . OutputStream os ) throws java . io . IOException { 
InvCatalogConvertIF converter = InvCatalogFactory . getDefaultConverter ( ) ; 
converter . writeXML ( this , os ) ; 
public void writeXML ( java . io . OutputStream os , boolean raw ) throws java . io . IOException { 
converter . writeXML ( this , os , raw ) ; 
public java . util . List < DataRootConfig > getDatasetRoots ( ) { 
return roots ; 
public void addDatasetRoot ( DataRootConfig root ) { 
roots . add ( root ) ; 
public boolean equals ( Object o ) { 
if ( this == o ) return true ; 
if ( ! ( o instanceof InvCatalogImpl ) ) return false ; 
return o . hashCode ( ) == this . hashCode ( ) ; 
public int hashCode ( ) { 
if ( hashCode == 0 ) { 
int result = 17 ; 
if ( null != getName ( ) ) 
result = 37 * result + getName ( ) . hashCode ( ) ; 
result = 37 * result + getServices ( ) . hashCode ( ) ; 
result = 37 * result + getDatasets ( ) . hashCode ( ) ; 
hashCode = result ; 
return hashCode ; 
private volatile int hashCode = 0 ; 
public boolean isStatic ( ) { 
return isStatic ; 
public void setStatic ( boolean aStatic ) { 
isStatic = aStatic ; 
} public static double [ ] getTimeBaseAndFactor ( String tsUnits ) throws Exception { 
if ( tsUnits == null ) { 
if ( sincePo <= 0 ) 
double factorToGetSeconds = factorToGetSeconds ( tsUnits . substring ( 0 , sincePo ) ) ; 
GregorianCalendar baseGC = parseISODateTimeZulu ( tsUnits . substring ( sincePo + 7 ) ) ; 
double baseSeconds = baseGC . getTimeInMillis ( ) / 1000.0 ; 
return new double [ ] { baseSeconds , factorToGetSeconds } ; 
} public static double factorToGetSeconds ( String units ) throws Exception { 
units = units . trim ( ) . toLowerCase ( ) ; 
if ( units . equals ( "ms" ) || 
units . equals ( "msec" ) || 
units . equals ( "msecs" ) || 
units . equals ( "millis" ) || 
units . equals ( "millisec" ) || 
units . equals ( "millisecs" ) || 
units . equals ( "millisecond" ) || 
units . equals ( "milliseconds" ) ) return 0.001 ; 
if ( units . equals ( "s" ) || 
units . equals ( "sec" ) || 
units . equals ( "secs" ) || 
units . equals ( "second" ) || 
units . equals ( "seconds" ) ) return 1 ; 
if ( units . equals ( "m" ) || 
units . equals ( "min" ) || 
units . equals ( "mins" ) || 
units . equals ( "minute" ) || 
units . equals ( "minutes" ) ) return SECONDS_PER_MINUTE ; 
if ( units . equals ( "h" ) || 
units . equals ( "hr" ) || 
units . equals ( "hrs" ) || 
units . equals ( "hour" ) || 
units . equals ( "hours" ) ) return SECONDS_PER_HOUR ; 
if ( units . equals ( "d" ) || 
units . equals ( "day" ) || 
units . equals ( "days" ) ) return SECONDS_PER_DAY ; 
if ( units . equals ( "week" ) || 
units . equals ( "weeks" ) ) return 7 * SECONDS_PER_DAY ; 
if ( units . equals ( "mon" ) || 
units . equals ( "mons" ) || 
units . equals ( "month" ) || 
units . equals ( "months" ) ) return 30 * SECONDS_PER_DAY ; 
if ( units . equals ( "yr" ) || 
units . equals ( "yrs" ) || 
units . equals ( "year" ) || 
units . equals ( "years" ) ) return 360 * SECONDS_PER_DAY ; 
throw new RuntimeException ( 
} private static void parseN ( String s , char separatorN [ ] , int resultsN [ ] ) { 
s = "" ; 
s = s . trim ( ) ; 
int sLength = s . length ( ) ; 
if ( sLength < 1 || ! ( s . charAt ( 0 ) == '-' || ErddapString2 . isDigit ( s . charAt ( 0 ) ) ) ) { 
resultsN [ 0 ] = Integer . MAX_VALUE ; 
int po1 , po2 = - 1 ; 
boolean mMode = s . charAt ( 0 ) == '-' ; 
int nParts = separatorN . length ; 
for ( int part = 0 ; part < nParts ; part ++ ) { 
if ( po2 + 1 < sLength ) { 
po1 = po2 + 1 ; 
po2 = po1 ; 
if ( mMode ) { 
if ( po2 < sLength && s . charAt ( po2 ) == '-' ) po2 ++ ; 
else { resultsN [ 0 ] = Integer . MAX_VALUE ; return ; } 
while ( po2 < sLength && ErddapString2 . isDigit ( s . charAt ( po2 ) ) ) po2 ++ ; 
if ( po2 == po1 ) 
if ( part > 0 && separatorN [ part - 1 ] == '.' ) { 
resultsN [ part ] = ErddapMath2 . roundToInt ( 1000 * 
ErddapString2 . parseDouble ( "0." + s . substring ( po1 , po2 ) ) ) ; 
resultsN [ part ] = ErddapString2 . parseInt ( s . substring ( po1 , po2 ) ) ; 
if ( resultsN [ part ] == Integer . MAX_VALUE ) { 
if ( po2 >= sLength ) { 
mMode = false ; 
char ch = s . charAt ( po2 ) ; 
if ( ch == ',' ) 
ch = '.' ; 
if ( separatorN [ part ] == ' ' ) { 
} else if ( separatorN [ part ] == '±' ) { 
if ( ch == '+' ) { 
} else if ( ch == '-' ) { 
po2 -- ; 
mMode = true ; 
resultsN [ 0 ] = Integer . MAX_VALUE ; return ; 
} else if ( ch != separatorN [ part ] ) { 
if ( ( separatorN [ part ] == ':' || separatorN [ part ] == '.' ) && 
part < nParts - 1 ) { 
int pmPart = ErddapString2 . indexOf ( separatorN , '±' , part + 1 ) ; 
if ( pmPart >= 0 ) { 
part = pmPart ; 
} public static GregorianCalendar parseISODateTime ( GregorianCalendar gc , 
String s ) { 
boolean negative = s . startsWith ( "-" ) ; 
if ( negative ) 
s = s . substring ( 1 ) ; 
if ( s . length ( ) < 1 || ! ErddapString2 . isDigit ( s . charAt ( 0 ) ) ) 
if ( gc == null ) 
int ymdhmsmom [ ] = { Integer . MAX_VALUE , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 } ; 
if ( Character . toLowerCase ( s . charAt ( s . length ( ) - 1 ) ) == 'z' ) 
s = s . substring ( 0 , s . length ( ) - 1 ) . trim ( ) ; 
if ( s . length ( ) >= 3 ) { 
String last3 = s . substring ( s . length ( ) - 3 ) . toLowerCase ( ) ; 
if ( last3 . equals ( "utc" ) || last3 . equals ( "gmt" ) ) 
s = s . substring ( 0 , s . length ( ) - 3 ) . trim ( ) ; 
char separator [ ] = { '-' , '-' , ' ' , ':' , ':' , '.' , '±' , ':' , ' ' } ; 
parseN ( s , separator , ymdhmsmom ) ; 
if ( ymdhmsmom [ 0 ] == Integer . MAX_VALUE ) 
if ( ymdhmsmom [ 7 ] != 0 ) 
ymdhmsmom [ 3 ] -= ymdhmsmom [ 7 ] ; 
if ( ymdhmsmom [ 8 ] != 0 ) 
ymdhmsmom [ 4 ] -= ymdhmsmom [ 7 ] < 0 ? - ymdhmsmom [ 8 ] : ymdhmsmom [ 8 ] ; 
gc . set ( ( negative ? - 1 : 1 ) * ymdhmsmom [ 0 ] , ymdhmsmom [ 1 ] - 1 , ymdhmsmom [ 2 ] , 
ymdhmsmom [ 3 ] , ymdhmsmom [ 4 ] , ymdhmsmom [ 5 ] ) ; 
gc . set ( MILLISECOND , ymdhmsmom [ 6 ] ) ; 
gc . get ( YEAR ) ; 
} public static void main ( String args [ ] ) throws Exception { 
String fileIn = "D:/mlode/bufr/cat.out" ; 
NetcdfDataset ncf = NetcdfDataset . openDataset ( fileIn ) ; 
System . out . println ( ncf . toString ( ) ) ; 
new WriteT41_ncFlat ( ncf , "D:/mlode/bufr/cat2.nc" , true ) ; 
} static File 
findSystemTempDir ( String [ ] candidates ) 
for ( String candidate : candidates ) { 
File f = new File ( candidate ) ; 
if ( f . exists ( ) && f . canRead ( ) && f . canWrite ( ) ) 
if ( f . mkdirs ( ) ) 
File tempfile = File . createTempFile ( "tmp" , "tmp" ) ; 
File tempdir = tempfile . getParentFile ( ) ; 
if ( ! tempdir . canWrite ( ) || ! tempdir . canRead ( ) ) 
return tempdir ; 
} public void init ( ) 
if ( initialized ) 
initialized = true ; 
System . setProperty ( "file.encoding" , "UTF-8" ) ; 
Field charset = Charset . class . getDeclaredField ( "defaultCharset" ) ; 
charset . setAccessible ( true ) ; 
charset . set ( null , null ) ; 
throw new ServletException ( e ) ; 
} public void initOnce ( HttpServletRequest req ) 
once = true ; 
if ( this . tdsContext == null ) 
buf . append ( req . getServerName ( ) ) ; 
int port = req . getServerPort ( ) ; 
String tmp = HTTPUtil . canonicalpath ( req . getContextPath ( ) ) ; 
this . threddsname = HTTPUtil . nullify ( HTTPUtil . relpath ( tmp ) ) ; 
tmp = HTTPUtil . canonicalpath ( req . getServletPath ( ) ) ; 
this . requestname = HTTPUtil . nullify ( HTTPUtil . relpath ( tmp ) ) ; 
if ( this . threddsname == null ) 
this . threddsname = DEFAULTSERVLETNAME ; 
File updir = tdsContext . getUploadDir ( ) ; 
if ( updir == null ) { 
this . uploaddir = null ; 
this . uploaddir = HTTPUtil . canonicalpath ( updir . getAbsolutePath ( ) ) ; 
File downdir = tdsContext . getDownloadDir ( ) ; 
if ( downdir == null ) { 
this . downloaddir = null ; 
this . downloaddir = HTTPUtil . canonicalpath ( downdir . getAbsolutePath ( ) ) ; 
} protected String 
inquire ( ) 
if ( this . downloaddir != null ) 
result . put ( "downloaddir" , this . downloaddir ) ; 
if ( this . uploaddir != null ) 
result . put ( "uploaddir" , this . uploaddir ) ; 
String sresult = mapToString ( result , true , "download" ) ; 
return sresult ; 
} public void open ( RandomAccessFile raf , NetcdfFile ncfile , Message single ) throws IOException { 
protoMessage = single ; 
protoMessage . getRootDataDescriptor ( ) ; 
if ( ! protoMessage . isTablesComplete ( ) ) 
BufrConfig config = BufrConfig . openFromMessage ( raf , protoMessage , null ) ; 
Construct2 construct = new Construct2 ( protoMessage , config , ncfile ) ; 
obsStructure = construct . getObsStructure ( ) ; 
isSingle = true ; 
public String getDetailInfo ( ) { 
Formatter ff = new Formatter ( ) ; 
ff . format ( "%s" , super . getDetailInfo ( ) ) ; 
protoMessage . dump ( ff ) ; 
ff . format ( "%n" ) ; 
config . show ( ff ) ; 
return ff . toString ( ) ; 
} public boolean count ( String name , Comparable value ) { 
Counter counter = map . get ( name ) ; 
counter = add ( name ) ; 
return counter . count ( value ) ; 
} public static synchronized StandardPrefixDB instance ( ) throws PrefixDBException { 
if ( instance == null ) { 
instance = new StandardPrefixDB ( ) ; 
throw new PrefixDBException ( 
} private void add ( final String name , final String symbol , 
final double definition ) throws PrefixExistsException { 
addName ( name , definition ) ; 
addSymbol ( symbol , definition ) ; 
final PrefixDB db = StandardPrefixDB . instance ( ) ; 
+ db . getPrefixBySymbol ( "cm" ) + '"' ) ; 
+ db . getPrefixBySymbol ( "dm" ) + '"' ) ; 
} public int compare ( TableRow other , int col ) { 
String s1 = getValueAt ( col ) . toString ( ) ; 
String s2 = other . getValueAt ( col ) . toString ( ) ; 
int ret = s1 . compareToIgnoreCase ( s2 ) ; 
if ( ret == 0 ) 
return compareTie ( other , col ) ; 
} protected int compareBoolean ( TableRow other , int col , boolean b1 , boolean b2 ) { 
if ( b1 == b2 ) 
return b1 ? 1 : - 1 ; 
} DapGroup 
getGroupScope ( ) 
DapGroup gscope = ( DapGroup ) searchScope ( DapSort . GROUP , DapSort . DATASET ) ; 
return gscope ; 
} SaxEvent 
pull ( XMLAttributeMap map , String name ) 
SaxEvent event = map . remove ( name . toLowerCase ( ) ) ; 
return event ; 
passReserved ( XMLAttributeMap map , DapNode node ) 
DapAttribute attr = null ; 
for ( Map . Entry < String , SaxEvent > entry : map . entrySet ( ) ) { 
SaxEvent event = entry . getValue ( ) ; 
String value = event . value ; 
if ( isReserved ( key ) ) 
node . addXMLAttribute ( key , value ) ; 
} catch ( DapException de ) { 
throw new ParseException ( de ) ; 
peek ( XMLAttributeMap map , String name ) 
SaxEvent event = map . get ( name . toLowerCase ( ) ) ; 
} DapAttribute 
makeAttribute ( DapSort sort , String name , DapType basetype , 
List < String > nslist , DapNode parent ) 
DapAttribute attr = new DapAttribute ( name , basetype ) ; 
if ( sort == DapSort . ATTRIBUTE ) { 
attr . setBaseType ( basetype ) ; 
parent . addAttribute ( attr ) ; 
attr . setNamespaceList ( nslist ) ; 
return attr ; 
void 
enterdataset ( XMLAttributeMap attrs ) 
this . debug = getDebugLevel ( ) > 0 ; 
if ( debug ) report ( "enterdataset" ) ; 
SaxEvent name = pull ( attrs , "name" ) ; 
SaxEvent dapversion = pull ( attrs , "dapversion" ) ; 
SaxEvent dmrversion = pull ( attrs , "dmrversion" ) ; 
if ( isempty ( name ) ) 
float ndapversion = DAPVERSION ; 
if ( dapversion != null ) 
ndapversion = Float . parseFloat ( dapversion . value ) ; 
ndapversion = DAPVERSION ; 
if ( ndapversion != DAPVERSION ) 
float ndmrversion = DMRVERSION ; 
if ( dmrversion != null ) 
ndmrversion = Float . parseFloat ( dmrversion . value ) ; 
ndmrversion = DMRVERSION ; 
if ( ndmrversion != DMRVERSION ) 
this . root = new DapDataset ( name . value ) ; 
this . root . setDapVersion ( Float . toString ( ndapversion ) ) ; 
this . root . setDMRVersion ( Float . toString ( ndmrversion ) ) ; 
this . root . setDataset ( this . root ) ; 
passReserved ( attrs , this . root ) ; 
scopestack . push ( this . root ) ; 
void value ( String value ) 
if ( debug ) report ( "value" ) ; 
DapAttribute parent = ( DapAttribute ) getScope ( DapSort . ATTRIBUTE ) ; 
createvalue ( value , parent ) ; 
public boolean isValid ( NcssPointParamsBean params , ConstraintValidatorContext constraintValidatorContext ) { 
constraintValidatorContext . disableDefaultConstraintViolation ( ) ; 
boolean isValid = true ; 
boolean isStnRequest = params . hasLatLonPoint ( ) && params . hasStations ( ) ; 
boolean isPointRequest = params . hasLatLonPoint ( ) && ! params . hasStations ( ) ; 
if ( ! isStnRequest && ! isPointRequest ) { 
isValid = false ; 
constraintValidatorContext 
. buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.lat_or_lon_missing}" ) 
. addConstraintViolation ( ) ; 
} private boolean hasValidDateRange ( String time_start , String time_end , String time_duration ) { 
if ( ( null == time_start ) && ( null == time_end ) && ( null == time_duration ) ) 
if ( ( null != time_start ) && ( null != time_end ) ) 
if ( ( null != time_start ) && ( null != time_duration ) ) 
if ( ( null != time_end ) && ( null != time_duration ) ) 
public boolean hasNext ( ) 
switch ( state ) { 
case INITIAL : 
return ( slice . getFirst ( ) < slice . getStop ( ) ) ; 
case STARTED : 
return ( this . index < slice . getLast ( ) ) ; 
case DONE : 
} public final Attribute getAttribute ( String clearname ) { 
Attribute a = ( Attribute ) _attr . get ( clearname ) ; 
return ( a ) ; 
} public final boolean hasAttribute ( String clearname ) { 
if ( a == null ) { 
return ( true ) ; 
} public final void appendAttribute ( String clearname , int type , String value , 
boolean check ) throws DASException { 
if ( a != null && ( type != a . getType ( ) ) ) { 
} else if ( a != null ) { 
a . appendValue ( value , check ) ; 
a = new Attribute ( type , clearname , value , check ) ; 
_attr . put ( clearname , a ) ; 
} public final void appendAttribute ( String clearname , int type , String value ) 
throws DASException { 
appendAttribute ( clearname , type , value , true ) ; 
} public final AttributeTable appendContainer ( String clearname ) { 
if ( _attr . get ( clearname ) != null ) 
AttributeTable at = new AttributeTable ( clearname ) ; 
Attribute a = new Attribute ( clearname , at ) ; 
return at ; 
} public final void addContainer ( String clearname , AttributeTable at ) throws AttributeExistsException { 
if ( _attr . get ( clearname ) != null ) { 
getEncodedName ( ) + "'" ) ; 
} public final void addAlias ( String alias , String attributeName ) 
throws NoSuchAttributeException , AttributeExistsException { 
if ( _attr . get ( alias ) != null ) { 
if ( Debug . isSet ( "AttributTable" ) ) { 
Alias newAlias = new Alias ( alias , attributeName ) ; 
_attr . put ( alias , newAlias ) ; 
} public final void delAttribute ( String clearname , int i ) throws DASException { 
if ( i == - 1 ) { 
_attr . remove ( clearname ) ; 
if ( a != null ) { 
if ( a . isContainer ( ) ) { 
a . deleteValueAt ( i ) ; 
} public void print ( PrintWriter os , String pad ) { 
for ( Enumeration e = getNames ( ) ; e . hasMoreElements ( ) ; ) { 
String name = ( String ) e . nextElement ( ) ; 
Attribute a = getAttribute ( name ) ; 
if ( a != null ) 
os . println ( pad + "}" ) ; 
os . flush ( ) ; 
} public final void print ( OutputStream os , String pad ) { 
print ( new PrintWriter ( new BufferedWriter ( new OutputStreamWriter ( os , Util . UTF8 ) ) ) , pad ) ; 
AttributeTable at = ( AttributeTable ) super . cloneDAG ( map ) ; 
at . _attr = new SortedTable ( ) ; 
for ( int i = 0 ; i < _attr . size ( ) ; i ++ ) { 
String key = ( String ) _attr . getKey ( i ) ; 
Attribute element = ( Attribute ) _attr . elementAt ( i ) ; 
at . _attr . put ( key , ( Attribute ) cloneDAG ( map , element ) ) ; 
if ( subcenterMap == null ) 
subcenterMap = makeSubcenterMap ( ) ; 
return subcenterMap . get ( subcenter ) ; 
if ( genProcessMap == null ) makeGenProcessMap ( ) ; 
public Grib1ParamLevel getParamLevel ( Grib1SectionProductDefinition pds ) { 
int levelType = pds . getLevelType ( ) ; 
int pds11 = pds . getLevelValue1 ( ) ; 
int pds12 = pds . getLevelValue2 ( ) ; 
int pds1112 = pds11 << 8 | pds12 ; 
switch ( levelType ) { 
case 210 : 
return new Grib1ParamLevel ( this , levelType , ( float ) pds1112 , GribNumbers . MISSING ) ; 
case 218 : 
return new Grib1ParamLevel ( this , levelType , ( float ) pds11 + 200 , ( float ) pds12 + 200 ) ; 
case 246 : 
return new Grib1ParamLevel ( this , pds ) ; 
} public boolean nearlyEquals ( LatLonPointNoNormalize that , double maxRelDiff ) { 
return Misc . nearlyEquals ( this . getLatitude ( ) , that . getLatitude ( ) , maxRelDiff ) && 
Misc . nearlyEquals ( this . getLongitude ( ) , that . getLongitude ( ) , maxRelDiff ) ; 
} public static String stepDownRelativePath ( String [ ] pathSegments ) { 
if ( ! CrawlableDatasetUtils . isValidRelativePath ( pathSegments ) ) 
if ( pathSegments . length < 2 ) 
for ( int i = 1 ; i < pathSegments . length - 1 ; i ++ ) { 
sb . append ( pathSegments [ i ] ) . append ( "/" ) ; 
sb . append ( pathSegments [ pathSegments . length - 1 ] ) ; 
} synchronized public void register ( String className , boolean last ) 
Class < ? extends DSP > klass = ( Class < ? extends DSP > ) loader . loadClass ( className ) ; 
register ( klass , last ) ; 
throw new DapException ( e ) ; 
} synchronized public void 
register ( Class < ? extends DSP > klass , boolean last ) 
if ( registered ( klass ) ) return ; 
if ( last ) 
registry . add ( new Registration ( klass ) ) ; 
registry . add ( 0 , new Registration ( klass ) ) ; 
} synchronized public boolean 
registered ( Class < ? extends DSP > klass ) 
for ( Registration r : registry ) { 
if ( r . dspclass == klass ) return true ; 
unregister ( Class < ? extends DSP > klass ) 
for ( int i = 0 ; i < registry . size ( ) ; i ++ ) { 
if ( registry . get ( i ) . dspclass == klass ) { 
registry . remove ( i ) ; 
} public static Grib2Tables factory ( int center , int subCenter , int masterVersion , int localVersion , int genProcessId ) { 
Grib2TablesId id = new Grib2TablesId ( center , subCenter , masterVersion , localVersion , genProcessId ) ; 
Grib2Tables cust = tables . get ( id ) ; 
if ( cust != null ) return cust ; 
Grib2TableConfig config = Grib2TableConfig . matchTable ( id ) ; 
cust = build ( config ) ; 
tables . put ( id , cust ) ; 
return cust ; 
public TimeCoordIntvDateValue getForecastTimeInterval ( Grib2Record gr ) { 
if ( ! gr . getPDS ( ) . isTimeInterval ( ) ) return null ; 
Grib2Pds . PdsInterval pdsIntv = ( Grib2Pds . PdsInterval ) gr . getPDS ( ) ; 
int timeUnitOrg = gr . getPDS ( ) . getTimeUnit ( ) ; 
int range = 0 ; 
for ( Grib2Pds . TimeInterval ti : pdsIntv . getTimeIntervals ( ) ) { 
if ( ti . timeRangeUnit == 255 ) 
if ( ( ti . timeRangeUnit != timeUnitOrg ) || ( ti . timeIncrementUnit != timeUnitOrg && ti . timeIncrementUnit != 255 && ti . timeIncrement != 0 ) ) { 
if ( ! timeUnitWarnWasSent ) { 
timeUnitWarnWasSent = true ; 
range += ti . timeRangeLength ; 
if ( ti . timeIncrementUnit != 255 ) range += ti . timeIncrement ; 
CalendarPeriod unitPeriod = Grib2Utils . getCalendarPeriod ( convertTimeUnit ( timeUnitOrg ) ) ; 
if ( unitPeriod == null ) return null ; 
CalendarPeriod period = unitPeriod . multiply ( range ) ; 
CalendarDate EI = pdsIntv . getIntervalTimeEnd ( ) ; 
if ( EI == CalendarDate . UNKNOWN ) { 
return new TimeCoordIntvDateValue ( gr . getReferenceDate ( ) , period ) ; 
return new TimeCoordIntvDateValue ( period , EI ) ; 
} public double getForecastTimeIntervalSizeInHours ( Grib2Pds pds ) { 
Grib2Pds . PdsInterval pdsIntv = ( Grib2Pds . PdsInterval ) pds ; 
int timeUnitOrg = pds . getTimeUnit ( ) ; 
CalendarPeriod timeUnitPeriod = Grib2Utils . getCalendarPeriod ( convertTimeUnit ( timeUnitOrg ) ) ; 
if ( timeUnitPeriod == null ) return GribNumbers . UNDEFINEDD ; 
if ( timeUnitPeriod . equals ( CalendarPeriod . Hour ) ) return range ; 
double fac ; 
if ( timeUnitPeriod . getField ( ) == CalendarPeriod . Field . Month ) { 
fac = 30.0 * 24.0 ; 
} else if ( timeUnitPeriod . getField ( ) == CalendarPeriod . Field . Year ) { 
fac = 365.0 * 24.0 ; 
fac = CalendarPeriod . Hour . getConvertFactor ( timeUnitPeriod ) ; 
return fac * range ; 
TimeCoordIntvDateValue tinvd = getForecastTimeInterval ( gr ) ; 
if ( tinvd == null ) return null ; 
int unit = convertTimeUnit ( pds . getTimeUnit ( ) ) ; 
TimeCoordIntvValue tinv = tinvd . convertReferenceDate ( gr . getReferenceDate ( ) , Grib2Utils . getCalendarPeriod ( unit ) ) ; 
if ( tinv == null ) return null ; 
int [ ] result = new int [ 2 ] ; 
result [ 0 ] = tinv . getBounds1 ( ) ; 
result [ 1 ] = tinv . getBounds2 ( ) ; 
public VertCoordType getVertUnit ( int code ) { 
switch ( code ) { 
return new VertCoordType ( code , "m" , null , true ) ; 
return new VertCoordType ( code , "K" , null , false ) ; 
case 100 : 
return new VertCoordType ( code , "Pa" , null , false ) ; 
case 102 : 
case 103 : 
return new VertCoordType ( code , "m" , "ground" , true ) ; 
case 104 : 
case 105 : 
return new VertCoordType ( code , "sigma" , null , false ) ; 
case 106 : 
case 107 : 
return new VertCoordType ( code , "K" , null , true ) ; 
case 108 : 
return new VertCoordType ( code , "Pa" , "ground" , true ) ; 
case 109 : 
case 114 : 
return new VertCoordType ( code , "numeric" , null , false ) ; 
case 117 : 
case 119 : 
case 160 : 
case 161 : 
case 235 : 
case 237 : 
case 238 : 
return new VertCoordType ( code , null , null , true ) ; 
} public void finish ( ) 
if ( this . finished ) 
if ( this . ce == null ) 
this . visiblenodes = nodelist ; 
this . visiblenodes = new ArrayList < DapNode > ( nodelist . size ( ) ) ; 
for ( int i = 0 ; i < nodelist . size ( ) ; i ++ ) { 
DapNode node = nodelist . get ( i ) ; 
if ( ce . references ( node ) ) 
visiblenodes . add ( node ) ; 
this . topvariables = new ArrayList < DapVariable > ( ) ; 
this . allvariables = new ArrayList < DapVariable > ( ) ; 
this . allgroups = new ArrayList < DapGroup > ( ) ; 
this . allenums = new ArrayList < DapEnumeration > ( ) ; 
this . allcompounds = new ArrayList < DapStructure > ( ) ; 
this . alldimensions = new ArrayList < DapDimension > ( ) ; 
finishR ( this ) ; 
finishR ( DapNode node ) 
if ( ce != null && ! ce . references ( node ) ) return ; 
switch ( node . getSort ( ) ) { 
case DIMENSION : 
this . alldimensions . add ( ( DapDimension ) node ) ; 
case ENUMERATION : 
this . allenums . add ( ( DapEnumeration ) node ) ; 
case SEQUENCE : 
case STRUCTURE : 
this . allcompounds . add ( ( DapStructure ) node ) ; 
case VARIABLE : 
if ( node . isTopLevel ( ) ) 
this . topvariables . add ( ( DapVariable ) node ) ; 
this . allvariables . add ( ( DapVariable ) node ) ; 
case GROUP : 
case DATASET : 
DapGroup g = ( DapGroup ) node ; 
this . allgroups . add ( g ) ; 
for ( DapNode subnode : g . getDecls ( ) ) { 
finishR ( subnode ) ; 
} public DapNode 
lookup ( String fqn , DapSort ... sortset ) 
fqn = fqn . trim ( ) ; 
if ( fqn == null ) 
if ( "" . equals ( fqn ) || "/" . equals ( fqn ) ) { 
if ( fqn . charAt ( 0 ) == '/' ) 
fqn = fqn . substring ( 1 ) ; 
TypeSort ts = TypeSort . getTypeSort ( fqn ) ; 
if ( ts != null && ts . isAtomic ( ) ) { 
for ( DapSort ds : sortset ) { 
if ( ds == DapSort . ATOMICTYPE ) 
return DapType . lookup ( ts ) ; 
List < String > path = DapUtil . backslashSplit ( fqn , '/' ) ; 
DapGroup current = dataset ; 
for ( int i = 0 ; i < path . size ( ) - 1 ; i ++ ) { 
String groupname = Escape . backslashUnescape ( path . get ( i ) ) ; 
DapGroup g = ( DapGroup ) current . findInGroup ( groupname , DapSort . GROUP ) ; 
if ( g == null ) 
assert ( g . getSort ( ) == DapSort . GROUP ) ; 
current = ( DapGroup ) g ; 
if ( ! ALLOWFIELDMAPS ) { 
String targetname = Escape . backslashUnescape ( path . get ( path . size ( ) - 1 ) ) ; 
return current . findInGroup ( targetname , sortset ) ; 
String varpart = path . get ( path . size ( ) - 1 ) ; 
List < String > structpath = DapUtil . backslashSplit ( varpart , '.' ) ; 
String outer = Escape . backslashUnescape ( structpath . get ( 0 ) ) ; 
if ( structpath . size ( ) == 1 ) { 
return current . findInGroup ( outer , sortset ) ; 
DapStructure currentstruct = ( DapStructure ) current . findInGroup ( outer , DapSort . STRUCTURE , DapSort . SEQUENCE ) ; 
if ( currentstruct == null ) 
String fieldname ; 
for ( int i = 1 ; i < structpath . size ( ) - 1 ; i ++ ) { 
fieldname = Escape . backslashUnescape ( structpath . get ( i ) ) ; 
DapVariable field = ( DapVariable ) currentstruct . findByName ( fieldname ) ; 
if ( field == null ) 
if ( ! field . isCompound ( ) ) 
currentstruct = ( DapStructure ) field . getBaseType ( ) ; 
fieldname = Escape . backslashUnescape ( structpath . get ( structpath . size ( ) - 1 ) ) ; 
DapVariable field = currentstruct . findByName ( fieldname ) ; 
if ( field . getSort ( ) . oneof ( sortset ) ) 
return ( field ) ; 
sort ( ) 
List < DapNode > sorted = new ArrayList < DapNode > ( ) ; 
sortR ( this , sorted ) ; 
for ( int i = 0 ; i < sorted . size ( ) ; i ++ ) { 
sorted . get ( i ) . setIndex ( i ) ; 
this . nodelist = sorted ; 
sortR ( DapNode node , List < DapNode > sortlist ) 
DapVariable var = null ; 
Map < String , DapAttribute > attrs = null ; 
sortlist . add ( node ) ; 
DapGroup group = ( DapGroup ) node ; 
attrs = group . getAttributes ( ) ; 
for ( Map . Entry < String , DapAttribute > entry : attrs . entrySet ( ) ) { 
sortR ( entry . getValue ( ) , sortlist ) ; 
List < DapDimension > dims = group . getDimensions ( ) ; 
if ( dims != null ) 
sortR ( dims . get ( i ) , sortlist ) ; 
List < DapEnumeration > enums = group . getEnums ( ) ; 
if ( enums != null ) 
for ( int i = 0 ; i < enums . size ( ) ; i ++ ) { 
sortR ( enums . get ( i ) , sortlist ) ; 
List < DapVariable > vars = group . getVariables ( ) ; 
if ( vars != null ) 
for ( int i = 0 ; i < vars . size ( ) ; i ++ ) { 
sortR ( vars . get ( i ) , sortlist ) ; 
List < DapGroup > groups = group . getGroups ( ) ; 
if ( groups != null ) 
for ( int i = 0 ; i < groups . size ( ) ; i ++ ) { 
sortR ( groups . get ( i ) , sortlist ) ; 
var = ( DapVariable ) node ; 
attrs = var . getAttributes ( ) ; 
if ( attrs != null ) 
List < DapMap > maps = var . getMaps ( ) ; 
if ( maps != null ) 
for ( int i = 0 ; i < maps . size ( ) ; i ++ ) { 
sortR ( maps . get ( i ) , sortlist ) ; 
dims = var . getDimensions ( ) ; 
case ATTRIBUTE : 
attrs = node . getAttributes ( ) ; 
for ( String name : attrs . keySet ( ) ) { 
sortR ( attrs . get ( name ) , sortlist ) ; 
} public static void compareTables ( Grib2ParamTableInterface t1 , Grib2ParamTableInterface t2 , Formatter f ) { 
int extra = 0 ; 
int udunits = 0 ; 
int conflict = 0 ; 
f . format ( "%s%n" , t2 . getName ( ) ) ; 
for ( GribTables . Parameter p1 : t1 . getParameters ( ) ) { 
if ( t1 . getParameter ( p1 . getNumber ( ) ) == null ) { 
GribTables . Parameter p2 = t2 . getParameter ( p1 . getNumber ( ) ) ; 
if ( p2 == null ) { 
extra ++ ; 
if ( ! Util . equivilantName ( p1 . getName ( ) , p2 . getName ( ) ) ) { 
conflict ++ ; 
if ( ! p1 . getUnit ( ) . equalsIgnoreCase ( p2 . getUnit ( ) ) ) { 
String cu1 = Util . cleanUnit ( p1 . getUnit ( ) ) ; 
String cu2 = Util . cleanUnit ( p2 . getUnit ( ) ) ; 
boolean isUnitless1 = Util . isUnitless ( cu1 ) ; 
boolean isUnitless2 = Util . isUnitless ( cu2 ) ; 
if ( isUnitless1 != isUnitless2 ) { 
udunits ++ ; 
} else if ( ! isUnitless1 ) { 
SimpleUnit su1 = SimpleUnit . factoryWithExceptions ( cu1 ) ; 
if ( ! su1 . isCompatible ( cu2 ) ) { 
cu2 , p2 . getUnit ( ) ) ; 
int missing = 0 ; 
for ( GribTables . Parameter p2 : t2 . getParameters ( ) ) { 
if ( t2 . getParameter ( p2 . getNumber ( ) ) == null ) { 
GribTables . Parameter p1 = t1 . getParameter ( p2 . getNumber ( ) ) ; 
if ( p1 == null ) { 
missing ++ ; 
if ( conflict > 0 || udunits > 0 || missing > 0 ) { 
missing ) ; 
} RandomAccessFile getRaf ( int partno , int fileno ) throws IOException { 
Partition part = getPartition ( partno ) ; 
try ( GribCollectionImmutable gc = part . getGribCollection ( ) ) { 
return gc . getDataRaf ( fileno ) ; 
} public String getFilename ( int partno , int fileno ) throws IOException { 
return gc . getFilename ( fileno ) ; 
String test = raf . readString ( 40 ) ; 
return test . equals ( EMISSIONS ) || test . equals ( AVERAGE ) || test . equals ( AIRQUALITY ) || test . equals ( INSTANT ) ; 
String name = raf . readString ( 40 ) ; 
String note = raf . readString ( 240 ) ; 
int itzone = raf . readInt ( ) ; 
int nspec = raf . readInt ( ) ; 
int bdate = raf . readInt ( ) ; 
float btime = raf . readFloat ( ) ; 
int edate = raf . readInt ( ) ; 
float etime = raf . readFloat ( ) ; 
int btimei = ( int ) btime ; 
if ( btimei < 100 ) btimei = btimei * 100 ; 
if ( btimei < 10000 ) btimei = btimei * 100 ; 
if ( bdate < 70000 ) { 
edate = edate + 2000000 ; 
bdate = bdate + 2000000 ; 
edate = edate + 1900000 ; 
bdate = bdate + 1900000 ; 
float plon = raf . readFloat ( ) ; 
float plat = raf . readFloat ( ) ; 
int iutm = raf . readInt ( ) ; 
float xorg = raf . readFloat ( ) ; 
float yorg = raf . readFloat ( ) ; 
float delx = raf . readFloat ( ) ; 
float dely = raf . readFloat ( ) ; 
int nx = raf . readInt ( ) ; 
int ny = raf . readInt ( ) ; 
int nz = raf . readInt ( ) ; 
int iproj = raf . readInt ( ) ; 
int istag = raf . readInt ( ) ; 
float tlat1 = raf . readFloat ( ) ; 
float tlat2 = raf . readFloat ( ) ; 
raf . skipBytes ( 8 ) ; 
int nx2 = raf . readInt ( ) ; 
int ny2 = raf . readInt ( ) ; 
nz = Math . max ( nz , 1 ) ; 
String [ ] spc_names = new String [ nspec ] ; 
while ( count < nspec ) { 
String spc = raf . readString ( 40 ) ; 
this . species_names = spc_names ; 
this . data_start = raf . getFilePointer ( ) ; 
int data_length_float_equivalents = ( ( int ) raf . length ( ) - ( int ) data_start ) / 4 ; 
this . n2dvals = nx * ny ; 
this . n3dvals = nx * ny * nz ; 
int spc_2D_block = nx * ny + 10 + 2 + 1 ; 
this . spc_3D_block = spc_2D_block * nz ; 
this . data_block = this . spc_3D_block * nspec + 6 ; 
int ntimes = data_length_float_equivalents / this . data_block ; 
ncfile . addDimension ( null , new Dimension ( "TSTEP" , ntimes , true ) ) ; 
ncfile . addDimension ( null , new Dimension ( "LAY" , nz , true ) ) ; 
ncfile . addDimension ( null , new Dimension ( "ROW" , ny , true ) ) ; 
ncfile . addDimension ( null , new Dimension ( "COL" , nx , true ) ) ; 
count = 0 ; 
HashSet < String > AeroSpcs = new HashSet < > ( Arrays . asList ( "PSO4" , "PNO3" , "PNH4" , "PH2O" , "SOPA" , "SOPB" , "NA" , "PCL" , "POA" , "PEC" , "FPRM" , "FCRS" , "CPRM" , "CCRS" ) ) ; 
HashSet < String > LULC = new HashSet < > ( Arrays . asList ( "WATER" , "ICE" , "LAKE" , "ENEEDL" , "EBROAD" , "DNEEDL" , "DBROAD" , "TBROAD" , "DDECID" , "ESHRUB" , "DSHRUB" , "TSHRUB" , "SGRASS" , "LGRASS" , "CROPS" , "RICE" , "SUGAR" , "MAIZE" , "COTTON" , "ICROPS" , "URBAN" , "TUNDRA" , "SWAMP" , "DESERT" , "MWOOD" , "TFOREST" ) ) ; 
String spc = spc_names [ count ++ ] ; 
if ( spc . equals ( WINDX ) || spc . equals ( WINDY ) || 
spc . equals ( SPEED ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "m/s" ) ) ; 
} else if ( spc . equals ( VERTDIFF ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "m**2/s" ) ) ; 
} else if ( spc . equals ( TEMP ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "K" ) ) ; 
} else if ( spc . equals ( PRESS ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "hPa" ) ) ; 
} else if ( spc . equals ( HEIGHT ) || spc . equals ( PBL ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "m" ) ) ; 
} else if ( spc . equals ( CLDWATER ) || spc . equals ( PRECIP ) || spc . equals ( RAIN ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "g/m**3" ) ) ; 
} else if ( spc . equals ( CLDOD ) || spc . equals ( "CLOUDOD" ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "none" ) ) ; 
} else if ( spc . equals ( "SNOWCOVER" ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "yes/no" ) ) ; 
} else if ( spc . startsWith ( "SOA" ) || AeroSpcs . contains ( spc ) ) { 
if ( name . equals ( EMISSIONS ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "g/time" ) ) ; 
temp . addAttribute ( new Attribute ( CDM . UNITS , "ug/m**3" ) ) ; 
} else if ( LULC . contains ( spc ) ) { 
temp . addAttribute ( new Attribute ( CDM . UNITS , "fraction" ) ) ; 
} else if ( spc . lastIndexOf ( "_" ) > - 1 ) { 
String tmpunit = spc . substring ( spc . lastIndexOf ( "_" ) + 1 ) ; 
tmpunit = tmpunit . trim ( ) ; 
switch ( tmpunit ) { 
case "M2pS" : 
tmpunit = "m**2/s" ; 
case "MpS" : 
tmpunit = "m/s" ; 
case "PPM" : 
tmpunit = "ppm" ; 
case "MB" : 
tmpunit = "millibar" ; 
case "GpM3" : 
tmpunit = "g/m**3" ; 
case "M" : 
tmpunit = "m" ; 
temp . addAttribute ( new Attribute ( CDM . UNITS , tmpunit ) ) ; 
temp . addAttribute ( new Attribute ( CDM . UNITS , "mol/time" ) ) ; 
temp . addAttribute ( new Attribute ( CDM . UNITS , "ppm" ) ) ; 
temp . addAttribute ( new Attribute ( CDM . LONG_NAME , spc ) ) ; 
temp . addAttribute ( new Attribute ( "var_desc" , spc ) ) ; 
double [ ] sigma = new double [ nz + 1 ] ; 
while ( count < nz + 1 ) { 
sigma [ count ++ ] = count ; 
int [ ] size = new int [ 1 ] ; 
size [ 0 ] = nz + 1 ; 
Array sigma_arr = Array . factory ( DataType . DOUBLE , size , sigma ) ; 
ncfile . addAttribute ( null , new Attribute ( "VGLVLS" , sigma_arr ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "SDATE" , bdate ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "STIME" , btimei ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "TSTEP" , 10000 ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "NSTEPS" , ntimes ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "NLAYS" , nz ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "NROWS" , ny ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "NCOLS" , nx ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "XORIG" , ( double ) xorg ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "YORIG" , ( double ) yorg ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "XCELL" , ( double ) delx ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "YCELL" , ( double ) dely ) ) ; 
Integer gdtyp = 2 ; 
Double p_alp = 20. ; 
Double p_bet = 60. ; 
Double p_gam = 0. ; 
Double xcent = - 95. ; 
Double ycent = 25. ; 
if ( ! ( ( iproj == 0 ) && ( tlat1 == 0 ) && ( tlat2 == 0 ) && ( plon == 0 ) && ( plat == 0 ) ) ) { 
xcent = ( double ) plon ; 
ycent = ( double ) plat ; 
if ( iproj == 0 ) { 
gdtyp = 1 ; 
} else if ( iproj == 1 ) { 
gdtyp = 5 ; 
p_alp = ( double ) iutm ; 
} else if ( iproj == 2 ) { 
gdtyp = 2 ; 
p_alp = ( double ) tlat1 ; 
p_bet = ( double ) tlat2 ; 
p_gam = ( double ) plon ; 
} else if ( iproj == 3 ) { 
gdtyp = 6 ; 
if ( plat == 90 ) { 
p_alp = 1. ; 
} else if ( plat == - 90 ) { 
p_alp = - 1. ; 
p_bet = ( double ) tlat1 ; 
p_alp = 20. ; 
p_bet = 60. ; 
p_gam = 0. ; 
xcent = - 95. ; 
ycent = 25. ; 
String thisLine ; 
String projpath = raf . getLocation ( ) ; 
Boolean lgdtyp = false ; 
Boolean lp_alp = false ; 
Boolean lp_bet = false ; 
Boolean lp_gam = false ; 
Boolean lxcent = false ; 
Boolean lycent = false ; 
int lastIndex = projpath . lastIndexOf ( File . separator ) ; 
if ( lastIndex <= 0 ) 
lastIndex = projpath . lastIndexOf ( '/' ) ; 
if ( lastIndex > 0 ) 
projpath = projpath . substring ( 0 , lastIndex ) ; 
projpath = projpath + File . separator + "camxproj.txt" ; 
File paramFile = new File ( projpath ) ; 
if ( paramFile . exists ( ) ) { 
try ( BufferedReader br = new BufferedReader ( new InputStreamReader ( new FileInputStream ( paramFile ) , CDM . UTF8 ) ) ) { 
while ( ( thisLine = br . readLine ( ) ) != null ) { 
if ( thisLine . length ( ) == 0 ) continue ; 
if ( thisLine . charAt ( 0 ) == '#' ) continue ; 
String [ ] key_value = thisLine . split ( "=" ) ; 
switch ( key_value [ 0 ] ) { 
case "GDTYP" : 
gdtyp = Integer . parseInt ( key_value [ 1 ] ) ; 
lgdtyp = true ; 
case "P_ALP" : 
p_alp = Double . parseDouble ( key_value [ 1 ] ) ; 
lp_alp = true ; 
case "P_BET" : 
p_bet = Double . parseDouble ( key_value [ 1 ] ) ; 
lp_bet = true ; 
case "P_GAM" : 
p_gam = Double . parseDouble ( key_value [ 1 ] ) ; 
lp_gam = true ; 
case "YCENT" : 
ycent = Double . parseDouble ( key_value [ 1 ] ) ; 
lycent = true ; 
case "XCENT" : 
xcent = Double . parseDouble ( key_value [ 1 ] ) ; 
lxcent = true ; 
try ( FileOutputStream out = new FileOutputStream ( paramFile ) ) { 
OutputStreamWriter fout = new OutputStreamWriter ( out , CDM . utf8Charset ) ; 
BufferedWriter bw = new BufferedWriter ( fout ) ; 
bw . newLine ( ) ; 
bw . write ( "GDTYP=" ) ; 
bw . write ( gdtyp . toString ( ) ) ; 
bw . write ( "P_ALP=" ) ; 
bw . write ( p_alp . toString ( ) ) ; 
bw . write ( "P_BET=" ) ; 
bw . write ( p_bet . toString ( ) ) ; 
bw . write ( "P_GAM=" ) ; 
bw . write ( p_gam . toString ( ) ) ; 
bw . write ( "XCENT=" ) ; 
bw . write ( xcent . toString ( ) ) ; 
bw . write ( "YCENT=" ) ; 
bw . write ( ycent . toString ( ) ) ; 
bw . flush ( ) ; 
bw . close ( ) ; 
ncfile . addAttribute ( null , new Attribute ( "GDTYP" , gdtyp ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "P_ALP" , p_alp ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "P_BET" , p_bet ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "P_GAM" , p_gam ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "XCENT" , xcent ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "YCENT" , ycent ) ) ; 
} public ucar . ma2 . Array readData ( Variable v2 , Section wantSection ) throws IOException , InvalidRangeException { 
int size = ( int ) v2 . getSize ( ) ; 
float [ ] arr = new float [ size ] ; 
raf . seek ( this . data_start ) ; 
int pad1 = raf . readInt ( ) ; 
raf . skipBytes ( 16 ) ; 
int pad2 = raf . readInt ( ) ; 
if ( pad1 != pad2 ) { 
int spcid = - 1 ; 
String spc = "" ; 
while ( ! spc . equals ( v2 . getShortName ( ) ) ) { 
spc = this . species_names [ ++ spcid ] ; 
raf . skipBytes ( this . spc_3D_block * spcid * 4 ) ; 
while ( count < size ) { 
pad1 = raf . readInt ( ) ; 
int ione = raf . readInt ( ) ; 
spc = raf . readString ( 40 ) ; 
if ( ( count != 0 ) && ( ( count % this . n2dvals ) == 0 ) ) { 
pad2 = raf . readInt ( ) ; 
if ( ( count % this . n3dvals ) == 0 ) { 
raf . skipBytes ( ( this . data_block - this . spc_3D_block ) * 4 ) ; 
arr [ count ++ ] = raf . readFloat ( ) ; 
} catch ( java . lang . ArrayIndexOutOfBoundsException io ) { 
throw new IOException ( io . getMessage ( ) ) ; 
Array data = Array . factory ( DataType . FLOAT , v2 . getShape ( ) , arr ) ; 
return data . sectionNoReduce ( wantSection . getRanges ( ) ) ; 
} static public VarAtt findVariableWithAttribute ( NetcdfDataset ds , String attName ) { 
Attribute att = v . findAttributeIgnoreCase ( attName ) ; 
if ( att != null ) return new VarAtt ( v , att ) ; 
Structure s = ( Structure ) v ; 
for ( Variable vs : s . getVariables ( ) ) { 
Attribute att = vs . findAttributeIgnoreCase ( attName ) ; 
if ( att != null ) return new VarAtt ( vs , att ) ; 
} static public Variable findVariableWithAttributeValue ( NetcdfDataset ds , String attName , String attValue ) { 
String haveValue = ds . findAttValueIgnoreCase ( v , attName , null ) ; 
if ( ( haveValue != null ) && haveValue . equals ( attValue ) ) 
Variable vn = findVariableWithAttributeValue ( ( Structure ) v , attName , attValue ) ; 
if ( null != vn ) return vn ; 
} static public String findNameOfVariableWithAttributeValue ( NetcdfDataset ds , String attName , String attValue ) { 
Variable v = findVariableWithAttributeValue ( ds , attName , attValue ) ; 
return ( v == null ) ? null : v . getShortName ( ) ; 
} static public Variable findVariableWithAttributeValue ( Structure struct , String attName , String attValue ) { 
for ( Variable v : struct . getVariables ( ) ) { 
if ( ( att != null ) && att . getStringValue ( ) . equals ( attValue ) ) 
} static public Structure findStructureWithDimensions ( NetcdfDataset ds , Dimension dim0 , Dimension dim1 ) { 
if ( ! ( v instanceof Structure ) ) continue ; 
if ( dim1 != null && v . getRank ( ) == 2 && v . getDimension ( 0 ) . equals ( dim0 ) && v . getDimension ( 1 ) . equals ( dim1 ) ) 
return ( Structure ) v ; 
if ( dim1 == null && v . getRank ( ) == 1 && v . getDimension ( 0 ) . equals ( dim0 ) ) 
} static public Structure findNestedStructure ( Structure s ) { 
for ( Variable v : s . getVariables ( ) ) { 
if ( ( v instanceof Structure ) ) 
} static public boolean hasNetcdf3RecordStructure ( NetcdfDataset ds ) { 
Variable v = ds . findVariable ( "record" ) ; 
return ( v != null ) && ( v . getDataType ( ) == DataType . STRUCTURE ) ; 
} static public String getLiteral ( NetcdfDataset ds , String key , Formatter errlog ) { 
if ( key . startsWith ( ":" ) ) { 
String val = ds . findAttValueIgnoreCase ( null , key . substring ( 1 ) , null ) ; 
if ( ( val == null ) && ( errlog != null ) ) 
return val ; 
return key ; 
} static public FeatureType getFeatureType ( NetcdfDataset ds , String key , Formatter errlog ) { 
FeatureType ft = null ; 
String fts = getLiteral ( ds , key , errlog ) ; 
if ( fts != null ) { 
ft = FeatureType . valueOf ( fts . toUpperCase ( ) ) ; 
if ( ( ft == null ) && ( errlog != null ) ) 
} static public String getVariableName ( NetcdfDataset ds , String key , Formatter errlog ) { 
Variable v = null ; 
String vs = getLiteral ( ds , key , errlog ) ; 
if ( vs != null ) { 
v = ds . findVariable ( vs ) ; 
if ( ( v == null ) && ( errlog != null ) ) 
return v == null ? null : v . getShortName ( ) ; 
} static public Dimension getDimension ( NetcdfDataset ds , String key , Formatter errlog ) { 
Dimension d = null ; 
String s = getLiteral ( ds , key , errlog ) ; 
d = ds . findDimension ( s ) ; 
if ( ( d == null ) && ( errlog != null ) ) 
} static public String getDimensionName ( NetcdfDataset ds , String key , Formatter errlog ) { 
Dimension d = getDimension ( ds , key , errlog ) ; 
return ( d == null ) ? null : d . getShortName ( ) ; 
} public double getCoordValue ( int j , int i ) { 
if ( coords == null ) doRead ( ) ; 
return coords . get ( j , i ) ; 
} static private double connectLon ( double connect , double val ) { 
if ( Double . isNaN ( connect ) ) return val ; 
if ( Double . isNaN ( val ) ) return val ; 
double diff = val - connect ; 
if ( Math . abs ( diff ) < MAX_JUMP ) return val ; 
double result = diff > 0 ? val - 360 : val + 360 ; 
double diff2 = connect - result ; 
if ( ( Math . abs ( diff2 ) ) < Math . abs ( diff ) ) 
val = result ; 
} public double [ ] getCoordValues ( ) { 
if ( ! isNumeric ( ) ) 
return ( double [ ] ) coords . get1DJavaArray ( DataType . DOUBLE ) ; 
} public CoordinateAxis2D section ( Range r1 , Range r2 ) throws InvalidRangeException { 
List < Range > section = new ArrayList < > ( ) ; 
section . add ( r1 ) ; 
section . add ( r2 ) ; 
return ( CoordinateAxis2D ) section ( section ) ; 
} static public ArrayDouble . D2 makeEdges ( ArrayDouble . D2 midpoints ) { 
int [ ] shape = midpoints . getShape ( ) ; 
int ny = shape [ 0 ] ; 
int nx = shape [ 1 ] ; 
ArrayDouble . D2 edge = new ArrayDouble . D2 ( ny + 1 , nx + 1 ) ; 
for ( int y = 0 ; y < ny - 1 ; y ++ ) { 
for ( int x = 0 ; x < nx - 1 ; x ++ ) { 
double xval = ( midpoints . get ( y , x ) + midpoints . get ( y , x + 1 ) + midpoints . get ( y + 1 , x ) + midpoints . get ( y + 1 , x + 1 ) ) / 4 ; 
edge . set ( y + 1 , x + 1 , xval ) ; 
edge . set ( y + 1 , 0 , edge . get ( y + 1 , 1 ) - ( edge . get ( y + 1 , 2 ) - edge . get ( y + 1 , 1 ) ) ) ; 
edge . set ( y + 1 , nx , edge . get ( y + 1 , nx - 1 ) + ( edge . get ( y + 1 , nx - 1 ) - edge . get ( y + 1 , nx - 2 ) ) ) ; 
for ( int x = 0 ; x < nx + 1 ; x ++ ) { 
edge . set ( 0 , x , edge . get ( 1 , x ) - ( edge . get ( 2 , x ) - edge . get ( 1 , x ) ) ) ; 
edge . set ( ny , x , edge . get ( ny - 1 , x ) + ( edge . get ( ny - 1 , x ) - edge . get ( ny - 2 , x ) ) ) ; 
return edge ; 
} static public ArrayDouble . D2 makeXEdgesRotated ( ArrayDouble . D2 midx ) { 
int [ ] shape = midx . getShape ( ) ; 
ArrayDouble . D2 edgex = new ArrayDouble . D2 ( ny + 2 , nx + 1 ) ; 
for ( int x = 1 ; x < nx ; x ++ ) { 
double xval = ( midx . get ( y , x - 1 ) + midx . get ( y , x ) ) / 2 ; 
edgex . set ( y + 1 , x , xval ) ; 
edgex . set ( y + 1 , 0 , midx . get ( y , 0 ) - ( edgex . get ( y + 1 , 1 ) - midx . get ( y , 0 ) ) ) ; 
edgex . set ( y + 1 , nx , midx . get ( y , nx - 1 ) - ( edgex . get ( y + 1 , nx - 1 ) - midx . get ( y , nx - 1 ) ) ) ; 
edgex . set ( 0 , x , midx . get ( 0 , x ) ) ; 
edgex . set ( ny + 1 , x , midx . get ( ny - 1 , x ) ) ; 
return edgex ; 
} static public ArrayDouble . D2 makeYEdgesRotated ( ArrayDouble . D2 midy ) { 
int [ ] shape = midy . getShape ( ) ; 
ArrayDouble . D2 edgey = new ArrayDouble . D2 ( ny + 2 , nx + 1 ) ; 
double yval = ( midy . get ( y , x - 1 ) + midy . get ( y , x ) ) / 2 ; 
edgey . set ( y + 1 , x , yval ) ; 
edgey . set ( y + 1 , 0 , midy . get ( y , 0 ) - ( edgey . get ( y + 1 , 1 ) - midy . get ( y , 0 ) ) ) ; 
edgey . set ( y + 1 , nx , midy . get ( y , nx - 1 ) - ( edgey . get ( y + 1 , nx - 1 ) - midy . get ( y , nx - 1 ) ) ) ; 
double pt0 = midy . get ( 0 , x ) ; 
double pt = edgey . get ( 2 , x ) ; 
double diff = pt0 - pt ; 
edgey . set ( 0 , x , pt0 + diff ) ; 
double pt0 = midy . get ( ny - 1 , x ) ; 
double pt = edgey . get ( ny - 1 , x ) ; 
edgey . set ( ny + 1 , x , pt0 + diff ) ; 
return edgey ; 
} private ArrayDouble . D3 makeBoundsFromAux ( ) { 
if ( ! computeIsInterval ( ) ) return null ; 
Attribute boundsAtt = findAttributeIgnoreCase ( CF . BOUNDS ) ; 
if ( boundsAtt == null ) return null ; 
String boundsVarName = boundsAtt . getStringValue ( ) ; 
VariableDS boundsVar = ( VariableDS ) ncd . findVariable ( getParentGroup ( ) , boundsVarName ) ; 
Array data ; 
data = boundsVar . read ( ) ; 
ArrayDouble . D3 bounds ; 
if ( data instanceof ArrayDouble . D3 ) { 
bounds = ( ArrayDouble . D3 ) data ; 
bounds = ( ArrayDouble . D3 ) Array . factory ( DataType . DOUBLE , data . getShape ( ) ) ; 
MAMath . copy ( data , bounds ) ; 
return bounds ; 
} private int findSingleHit ( ArrayDouble . D2 boundsForRun , double target ) { 
int hits = 0 ; 
int idxFound = - 1 ; 
int n = boundsForRun . getShape ( ) [ 0 ] ; 
if ( contains ( target , boundsForRun . get ( i , 0 ) , boundsForRun . get ( i , 1 ) ) ) { 
hits ++ ; 
idxFound = i ; 
if ( hits == 1 ) return idxFound ; 
if ( hits == 0 ) return - 1 ; 
return - hits ; 
} private int findClosest ( ArrayDouble . D2 boundsForRun , double target ) { 
double minDiff = Double . MAX_VALUE ; 
double midpoint = ( boundsForRun . get ( i , 0 ) + boundsForRun . get ( i , 1 ) ) / 2.0 ; 
double diff = Math . abs ( midpoint - target ) ; 
if ( diff < minDiff ) { 
minDiff = diff ; 
return idxFound ; 
} private static void doit ( String spec , Formatter errlog ) { 
CollectionSpecParser specp = new CollectionSpecParser ( spec , errlog ) ; 
String err = errlog . toString ( ) ; 
if ( err . length ( ) > 0 ) 
System . out . printf ( "%s%n" , err ) ; 
System . out . printf ( "-----------------------------------%n" ) ; 
} public static synchronized void setInstance ( final UnitSystem instance ) 
throws UnitSystemException { 
if ( instance != null ) { 
UnitSystemManager . instance = instance ; 
public String getName ( ) 
switch ( sort ) { 
return getShortName ( ) ; 
return getFullName ( ) ; 
} static public CDMNode 
unwrap ( CDMNode node ) 
if ( ! ( node instanceof Variable ) ) 
return node ; 
Variable inner = ( Variable ) node ; 
if ( inner instanceof VariableDS ) { 
VariableDS vds = ( VariableDS ) inner ; 
inner = vds . getOriginalVariable ( ) ; 
if ( inner == null ) { 
inner = vds ; 
} else if ( inner instanceof StructureDS ) { 
StructureDS sds = ( StructureDS ) inner ; 
inner = sds . getOriginalVariable ( ) ; 
inner = sds ; 
return inner ; 
} public void addAction ( String menuName , Action act ) { 
act . putValue ( Action . NAME , menuName ) ; 
super . add ( act ) ; 
} public void addAction ( String menuName , String iconName , Action act ) { 
addAction ( menuName , BAMutil . getIcon ( iconName , true ) , act ) ; 
} public void addAction ( String menuName , ImageIcon icon , Action act ) { 
act . putValue ( Action . SMALL_ICON , icon ) ; 
JMenuItem mi = add ( act ) ; 
mi . setHorizontalTextPosition ( SwingConstants . LEFT ) ; 
} public void addActionCheckBox ( String menuName , AbstractAction act , boolean state ) { 
JMenuItem mi = new JCheckBoxMenuItem ( menuName , state ) ; 
mi . addActionListener ( new BAMutil . ActionToggle ( act , mi ) ) ; 
act . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
add ( mi ) ; 
} public Match match ( String path ) { 
SortedMap < String , Match > tail = treeMap . tailMap ( path ) ; 
if ( tail . isEmpty ( ) ) return null ; 
String after = tail . firstKey ( ) ; 
if ( path . startsWith ( after ) ) 
return treeMap . get ( after ) ; 
for ( String key : tail . keySet ( ) ) { 
if ( path . startsWith ( key ) ) 
return treeMap . get ( key ) ; 
if ( StringUtil2 . match ( path , key ) == 0 ) 
} public static MetadataType findType ( String name ) { 
for ( MetadataType m : members ) { 
if ( m . name . equalsIgnoreCase ( name ) ) 
} public static MetadataType getType ( String name ) { 
MetadataType type = findType ( name ) ; 
return type != null ? type : new MetadataType ( name , false ) ; 
} public void open ( RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
headerParser = new H5header ( this . raf , ncfile , this ) ; 
headerParser . read ( null ) ; 
Group eosInfo = ncfile . getRootGroup ( ) . findGroup ( HdfEos . HDF5_GROUP ) ; 
if ( eosInfo != null && useHdfEos ) { 
isEos = HdfEos . amendFromODL ( ncfile , eosInfo ) ; 
} private Array readData ( ucar . nc2 . Variable v2 , long dataPos , Section wantSection ) throws IOException , InvalidRangeException { 
H5header . Vinfo vinfo = ( H5header . Vinfo ) v2 . getSPobject ( ) ; 
Object data ; 
Layout layout ; 
if ( vinfo . useFillValue ) { 
Object pa = IospHelper . makePrimitiveArray ( ( int ) wantSection . computeSize ( ) , dataType , vinfo . getFillValue ( ) ) ; 
if ( dataType == DataType . CHAR ) 
pa = IospHelper . convertByteToChar ( ( byte [ ] ) pa ) ; 
return Array . factory ( dataType , wantSection . getShape ( ) , pa ) ; 
if ( vinfo . mfp != null ) { 
assert vinfo . isChunked ; 
ByteOrder bo = ( vinfo . typeInfo . endian == 0 ) ? ByteOrder . BIG_ENDIAN : ByteOrder . LITTLE_ENDIAN ; 
layout = new H5tiledLayoutBB ( v2 , wantSection , raf , vinfo . mfp . getFilters ( ) , bo ) ; 
if ( vinfo . typeInfo . isVString ) { 
data = readFilteredStringData ( ( LayoutBB ) layout ) ; 
data = IospHelper . readDataFill ( ( LayoutBB ) layout , v2 . getDataType ( ) , vinfo . getFillValue ( ) ) ; 
DataType readDtype = v2 . getDataType ( ) ; 
int elemSize = v2 . getElementSize ( ) ; 
Object fillValue = vinfo . getFillValue ( ) ; 
int endian = vinfo . typeInfo . endian ; 
wantSection = Section . fill ( wantSection , v2 . getShape ( ) ) ; 
if ( vinfo . typeInfo . hdfType == 2 ) { 
readDtype = vinfo . mdt . timeType ; 
elemSize = readDtype . getSize ( ) ; 
fillValue = N3iosp . getFillValueDefault ( readDtype ) ; 
} else if ( vinfo . typeInfo . hdfType == 8 ) { 
H5header . TypeInfo baseInfo = vinfo . typeInfo . base ; 
readDtype = baseInfo . dataType ; 
endian = baseInfo . endian ; 
} else if ( vinfo . typeInfo . hdfType == 9 ) { 
elemSize = vinfo . typeInfo . byteSize ; 
endian = vinfo . typeInfo . endian ; 
if ( vinfo . isChunked ) { 
layout = new H5tiledLayout ( ( H5header . Vinfo ) v2 . getSPobject ( ) , readDtype , wantSection ) ; 
layout = new LayoutRegular ( dataPos , elemSize , v2 . getShape ( ) , wantSection ) ; 
data = readData ( vinfo , v2 , layout , readDtype , wantSection . getShape ( ) , fillValue , endian ) ; 
if ( data instanceof Array ) 
return ( Array ) data ; 
else if ( dataType == DataType . STRUCTURE ) 
return convertStructure ( ( Structure ) v2 , layout , wantSection . getShape ( ) , ( byte [ ] ) data ) ; 
return Array . factory ( dataType , wantSection . getShape ( ) , data ) ; 
} private Object readData ( H5header . Vinfo vinfo , Variable v , Layout layout , DataType dataType , int [ ] shape , 
Object fillValue , int endian ) throws java . io . IOException , InvalidRangeException { 
H5header . TypeInfo typeInfo = vinfo . typeInfo ; 
if ( typeInfo . hdfType == 2 ) { 
Object data = IospHelper . readDataFill ( raf , layout , dataType , fillValue , endian , true ) ; 
Array timeArray = Array . factory ( dataType , shape , data ) ; 
String [ ] stringData = new String [ ( int ) timeArray . getSize ( ) ] ; 
while ( timeArray . hasNext ( ) ) { 
long time = timeArray . nextLong ( ) ; 
stringData [ count ++ ] = CalendarDate . of ( time ) . toString ( ) ; 
return Array . factory ( DataType . STRING , shape , stringData ) ; 
if ( typeInfo . hdfType == 8 ) { 
Object data = IospHelper . readDataFill ( raf , layout , dataType , fillValue , endian ) ; 
return Array . factory ( dataType , shape , data ) ; 
if ( typeInfo . isVlen ) { 
DataType readType = dataType ; 
if ( typeInfo . base . hdfType == 7 ) 
readType = DataType . LONG ; 
Array [ ] data = new Array [ ( int ) layout . getTotalNelems ( ) ] ; 
while ( layout . hasNext ( ) ) { 
Layout . Chunk chunk = layout . next ( ) ; 
if ( chunk == null ) continue ; 
for ( int i = 0 ; i < chunk . getNelems ( ) ; i ++ ) { 
long address = chunk . getSrcPos ( ) + layout . getElemSize ( ) * i ; 
Array vlenArray = headerParser . getHeapDataArray ( address , readType , endian ) ; 
data [ count ++ ] = ( typeInfo . base . hdfType == 7 ) ? convertReference ( vlenArray ) : vlenArray ; 
int prefixrank = 0 ; 
if ( shape [ i ] < 0 ) { 
prefixrank = i ; 
Array result ; 
if ( prefixrank == 0 ) 
result = data [ 0 ] ; 
int [ ] newshape = new int [ prefixrank ] ; 
System . arraycopy ( shape , 0 , newshape , 0 , prefixrank ) ; 
result = Array . makeVlenArray ( newshape , data ) ; 
if ( dataType == DataType . STRUCTURE ) { 
int recsize = layout . getElemSize ( ) ; 
long size = recsize * layout . getTotalNelems ( ) ; 
byte [ ] byteArray = new byte [ ( int ) size ] ; 
if ( debugStructure ) 
raf . seek ( chunk . getSrcPos ( ) ) ; 
raf . readFully ( byteArray , ( int ) chunk . getDestElem ( ) * recsize , chunk . getNelems ( ) * recsize ) ; 
return convertStructure ( ( Structure ) v , layout , shape , byteArray ) ; 
return readDataPrimitive ( layout , dataType , shape , fillValue , endian , true ) ; 
} private boolean convertStructure ( Structure s , StructureMembers sm ) { 
boolean hasHeap = false ; 
for ( StructureMembers . Member m : sm . getMembers ( ) ) { 
assert v2 != null ; 
H5header . Vinfo vm = ( H5header . Vinfo ) v2 . getSPobject ( ) ; 
if ( vm . typeInfo . endian >= 0 ) 
m . setDataObject ( vm . typeInfo . endian == RandomAccessFile . LITTLE_ENDIAN ? ByteOrder . LITTLE_ENDIAN : ByteOrder . BIG_ENDIAN ) ; 
m . setDataParam ( ( int ) vm . dataPos ) ; 
if ( v2 . getDataType ( ) == DataType . STRING || v2 . isVariableLength ( ) ) 
hasHeap = true ; 
Structure nested = ( Structure ) v2 ; 
StructureMembers nestSm = nested . makeStructureMembers ( ) ; 
m . setStructureMembers ( nestSm ) ; 
hasHeap |= convertStructure ( nested , nestSm ) ; 
return hasHeap ; 
} void convertHeap ( ArrayStructureBB asbb , int pos , StructureMembers sm ) throws java . io . IOException , InvalidRangeException { 
ByteBuffer bb = asbb . getByteBuffer ( ) ; 
if ( m . getDataType ( ) == DataType . STRING ) { 
m . setDataObject ( ByteOrder . nativeOrder ( ) ) ; 
int size = m . getSize ( ) ; 
int destPos = pos + m . getDataParam ( ) ; 
String [ ] result = new String [ size ] ; 
for ( int i = 0 ; i < size ; i ++ ) 
result [ i ] = headerParser . readHeapString ( bb , destPos + i * 16 ) ; 
int index = asbb . addObjectToHeap ( result ) ; 
bb . order ( ByteOrder . nativeOrder ( ) ) ; 
bb . putInt ( destPos , index ) ; 
} else if ( m . isVariableLength ( ) ) { 
int startPos = pos + m . getDataParam ( ) ; 
bb . order ( ByteOrder . LITTLE_ENDIAN ) ; 
ByteOrder bo = ( ByteOrder ) m . getDataObject ( ) ; 
int endian = bo . equals ( ByteOrder . LITTLE_ENDIAN ) ? RandomAccessFile . LITTLE_ENDIAN : RandomAccessFile . BIG_ENDIAN ; 
int [ ] fieldshape = m . getShape ( ) ; 
int size = 1 ; 
for ( ; prefixrank < fieldshape . length ; prefixrank ++ ) { 
if ( fieldshape [ prefixrank ] < 0 ) break ; 
size *= fieldshape [ prefixrank ] ; 
Array [ ] fieldarray = new Array [ size ] ; 
int destPos = startPos ; 
Array vlenArray = headerParser . readHeapVlen ( bb , destPos , m . getDataType ( ) , endian ) ; 
fieldarray [ i ] = vlenArray ; 
destPos += VLEN_T_SIZE ; 
result = fieldarray [ 0 ] ; 
System . arraycopy ( fieldshape , 0 , newshape , 0 , prefixrank ) ; 
result = Array . makeVlenArray ( newshape , fieldarray ) ; 
bb . putInt ( startPos , index ) ; 
} Object readDataPrimitive ( Layout layout , DataType dataType , int [ ] shape , Object fillValue , int endian , boolean convertChar ) throws java . io . IOException , InvalidRangeException { 
if ( dataType == DataType . STRING ) { 
int size = ( int ) layout . getTotalNelems ( ) ; 
String [ ] sa = new String [ size ] ; 
sa [ count ++ ] = headerParser . readHeapString ( chunk . getSrcPos ( ) + layout . getElemSize ( ) * i ) ; 
return sa ; 
if ( dataType == DataType . OPAQUE ) { 
Array opArray = Array . factory ( DataType . OPAQUE , shape ) ; 
assert ( new Section ( shape ) . computeSize ( ) == layout . getTotalNelems ( ) ) ; 
byte [ ] pa = new byte [ recsize ] ; 
raf . seek ( chunk . getSrcPos ( ) + i * recsize ) ; 
raf . readFully ( pa , 0 , recsize ) ; 
opArray . setObject ( count ++ , ByteBuffer . wrap ( pa ) ) ; 
return opArray ; 
return IospHelper . readDataFill ( raf , layout , dataType , fillValue , endian , convertChar ) ; 
} private StructureData readStructure ( Structure s , ArrayStructureW asw , long dataPos ) throws IOException , InvalidRangeException { 
StructureDataW sdata = new StructureDataW ( asw . getStructureMembers ( ) ) ; 
for ( Variable v2 : s . getVariables ( ) ) { 
Array dataArray = readData ( v2 , dataPos + vinfo . dataPos , v2 . getShapeAsSection ( ) ) ; 
sdata . setMemberData ( v2 . getShortName ( ) , dataArray ) ; 
return sdata ; 
if ( null != ds . findVariable ( "x" ) ) return ; 
Attribute att = ds . findGlobalAttribute ( "MAPPROJ" ) ; 
int projType = att . getNumericValue ( ) . intValue ( ) ; 
double lat1 = findAttributeDouble ( ds , "TRUELAT1" , Double . NaN ) ; 
double lat2 = findAttributeDouble ( ds , "TRUELAT2" , Double . NaN ) ; 
double lat_origin = lat1 ; 
double lon_origin = findAttributeDouble ( ds , "TRUELON" , Double . NaN ) ; 
double false_easting = 0.0 ; 
double false_northing = 0.0 ; 
String projName = ds . findAttValueIgnoreCase ( null , CF . GRID_MAPPING_NAME , null ) ; 
if ( projName != null ) { 
projName = projName . trim ( ) ; 
lat_origin = findAttributeDouble ( ds , "latitude_of_projection_origin" , Double . NaN ) ; 
lon_origin = findAttributeDouble ( ds , "longitude_of_central_meridian" , Double . NaN ) ; 
false_easting = findAttributeDouble ( ds , "false_easting" , 0.0 ) ; 
false_northing = findAttributeDouble ( ds , "false_northing" , 0.0 ) ; 
Attribute att2 = ds . findGlobalAttributeIgnoreCase ( "standard_parallel" ) ; 
if ( att2 != null ) { 
lat1 = att2 . getNumericValue ( ) . doubleValue ( ) ; 
lat2 = ( att2 . getLength ( ) > 1 ) ? att2 . getNumericValue ( 1 ) . doubleValue ( ) : lat1 ; 
if ( projType == 2 ) projName = "lambert_conformal_conic" ; 
Variable coord_var = ds . findVariable ( "x_stag" ) ; 
if ( ! Double . isNaN ( false_easting ) || ! Double . isNaN ( false_northing ) ) { 
String units = ds . findAttValueIgnoreCase ( coord_var , CDM . UNITS , null ) ; 
double scalef = 1.0 ; 
scalef = SimpleUnit . getConversionFactor ( units , "km" ) ; 
false_easting *= scalef ; 
false_northing *= scalef ; 
ProjectionImpl proj ; 
if ( ( projName != null ) && projName . equalsIgnoreCase ( "lambert_conformal_conic" ) ) { 
proj = new LambertConformal ( lat_origin , lon_origin , lat1 , lat2 , false_easting , false_northing ) ; 
projCT = new ProjectionCT ( "Projection" , "FGDC" , proj ) ; 
if ( false_easting == 0.0 ) calcCenterPoints ( ds , proj ) ; 
if ( debugProj && ( proj != null ) ) { 
double lat_check = findAttributeDouble ( ds , "CTRLAT" , Double . NaN ) ; 
double lon_check = findAttributeDouble ( ds , "CTRLON" , Double . NaN ) ; 
LatLonPointImpl lpt0 = new LatLonPointImpl ( lat_check , lon_check ) ; 
ProjectionPoint ppt0 = proj . latLonToProj ( lpt0 , new ProjectionPointImpl ( ) ) ; 
Variable xstag = ds . findVariable ( "x_stag" ) ; 
ArrayFloat . D1 xstagData = ( ArrayFloat . D1 ) xstag . read ( ) ; 
float center_x = xstagData . get ( ( int ) xstag . getSize ( ) - 1 ) ; 
Variable ystag = ds . findVariable ( "y_stag" ) ; 
ArrayFloat . D1 ystagData = ( ArrayFloat . D1 ) ystag . read ( ) ; 
float center_y = ystagData . get ( ( int ) ystag . getSize ( ) - 1 ) ; 
lpt0 = new LatLonPointImpl ( lat_origin , lon_origin ) ; 
ppt0 = proj . latLonToProj ( lpt0 , new ProjectionPointImpl ( ) ) ; 
if ( projCT != null ) { 
VariableDS v = makeCoordinateTransformVariable ( ds , projCT ) ; 
ds . addVariable ( null , v ) ; 
if ( ds . findVariable ( "x_stag" ) != null ) 
ds . addCoordinateAxis ( makeCoordAxis ( ds , "x" ) ) ; 
if ( ds . findVariable ( "y_stag" ) != null ) 
ds . addCoordinateAxis ( makeCoordAxis ( ds , "y" ) ) ; 
if ( ds . findVariable ( "z_stag" ) != null ) 
ds . addCoordinateAxis ( makeCoordAxis ( ds , "z" ) ) ; 
Variable zsoil = ds . findVariable ( "ZPSOIL" ) ; 
if ( zsoil != null ) 
zsoil . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . GeoZ . toString ( ) ) ) ; 
} private void calcCenterPoints ( NetcdfDataset ds , Projection proj ) throws IOException { 
int nxpts = ( int ) xstag . getSize ( ) ; 
float center_x = xstagData . get ( nxpts - 1 ) ; 
double false_easting = center_x / 2000 - ppt0 . getX ( ) * 1000.0 ; 
int nypts = ( int ) ystag . getSize ( ) ; 
float center_y = ystagData . get ( nypts - 1 ) ; 
double false_northing = center_y / 2000 - ppt0 . getY ( ) * 1000.0 ; 
double dx = findAttributeDouble ( ds , "DX" , Double . NaN ) ; 
double dy = findAttributeDouble ( ds , "DY" , Double . NaN ) ; 
double w = dx * ( nxpts - 1 ) ; 
double h = dy * ( nypts - 1 ) ; 
double startx = ppt0 . getX ( ) * 1000.0 - w / 2 ; 
double starty = ppt0 . getY ( ) * 1000.0 - h / 2 ; 
xstag . setValues ( nxpts , startx , dx ) ; 
ystag . setValues ( nypts , starty , dy ) ; 
} private CoordinateAxis makeCoordAxis ( NetcdfDataset ds , String axisName ) throws IOException { 
Variable stagV = ds . findVariable ( axisName + "_stag" ) ; 
Array data_stag = stagV . read ( ) ; 
int n = ( int ) data_stag . getSize ( ) - 1 ; 
DataType dt = DataType . getType ( data_stag ) ; 
Array data = Array . factory ( dt , new int [ ] { n } ) ; 
Index stagIndex = data_stag . getIndex ( ) ; 
Index dataIndex = data . getIndex ( ) ; 
double val = data_stag . getDouble ( stagIndex . set ( i ) ) + data_stag . getDouble ( stagIndex . set ( i + 1 ) ) ; 
data . setDouble ( dataIndex . set ( i ) , 0.5 * val ) ; 
DataType dtype = DataType . getType ( data ) ; 
String units = ds . findAttValueIgnoreCase ( stagV , CDM . UNITS , "m" ) ; 
addSegment ( CEAST segment ) 
assert sort == Sort . SEGMENT ; 
if ( subnodes == null ) 
subnodes = new NodeList ( ) ; 
subnodes . add ( segment ) ; 
ProjectionManager d = new ProjectionManager ( null , null ) ; 
d . setVisible ( ) ; 
} public int indexOf ( byte [ ] data , int start , int max ) { 
if ( data . length == 0 ) return - 1 ; 
if ( start + max > data . length ) 
for ( int i = start ; i < start + max ; i ++ ) { 
while ( j > 0 && match [ j ] != data [ i ] ) 
j = failure [ j - 1 ] ; 
if ( match [ j ] == data [ i ] ) 
j ++ ; 
if ( j == match . length ) 
return i - match . length + 1 ; 
} private int [ ] computeFailure ( byte [ ] match ) { 
int [ ] result = new int [ match . length ] ; 
for ( int i = 1 ; i < match . length ; i ++ ) { 
while ( j > 0 && match [ j ] != match [ i ] ) 
j = result [ j - 1 ] ; 
if ( match [ j ] == match [ i ] ) 
result [ i ] = j ; 
} public Object isMine ( FeatureType wantFeatureType , NetcdfDataset ncd , Formatter errlog ) throws IOException { 
String convention = ncd . findAttValueIgnoreCase ( null , "Conventions" , null ) ; 
if ( ( null != convention ) && convention . equals ( _Coordinate . Convention ) ) { 
String format = ncd . findAttValueIgnoreCase ( null , "Format" , null ) ; 
if ( format != null && format . equals ( "Level3/NIDS" ) ) 
} public static synchronized void removeLeastPopular ( ) { 
Tools . log ( "PictureCache.removeLeastPopular:" ) ; 
Enumeration e = removalQueue . elements ( ) ; 
while ( ( e . hasMoreElements ( ) ) 
&& ( pictureCache . size ( ) >= maxCache ) ) { 
String removeElement = ( String ) e . nextElement ( ) ; 
pictureCache . remove ( removeElement ) ; 
removalQueue . remove ( removeElement ) ; 
e = pictureCache . keys ( ) ; 
while ( ( pictureCache . size ( ) >= maxCache ) 
&& ( e . hasMoreElements ( ) ) ) { 
} public static synchronized void add ( URL url , SourcePicture sp ) { 
if ( sp . getSourceBufferedImage ( ) == null ) { 
if ( ( maxCache < 1 ) ) { 
if ( isInCache ( url ) ) { 
if ( pictureCache . size ( ) >= maxCache ) 
removeLeastPopular ( ) ; 
if ( pictureCache . size ( ) < maxCache ) 
pictureCache . put ( url . toString ( ) , sp ) ; 
} public static synchronized void reportCache ( ) { 
+ Integer . toString ( pictureCache . size ( ) ) 
+ Integer . toString ( maxCache ) ) ; 
Enumeration e = pictureCache . keys ( ) ; 
while ( e . hasMoreElements ( ) ) { 
} public static void stopBackgroundLoading ( ) { 
Enumeration e = cacheLoadsInProgress . elements ( ) ; 
( ( SourcePicture ) e . nextElement ( ) ) . stopLoading ( ) ; 
} public static boolean stopBackgroundLoadingExcept ( URL exemptionURL ) { 
SourcePicture sp ; 
String exemptionURLString = exemptionURL . toString ( ) ; 
boolean inProgress = false ; 
sp = ( ( SourcePicture ) e . nextElement ( ) ) ; 
if ( ! sp . getUrlString ( ) . equals ( exemptionURLString ) ) 
sp . stopLoading ( ) ; 
inProgress = true ; 
return inProgress ; 
} public void setColumnVisible ( TableColumn column , boolean visible ) { 
if ( isColumnVisible ( column ) == visible ) { 
if ( ! visible ) { 
super . removeColumn ( column ) ; 
int noVisibleColumns = tableColumns . size ( ) ; 
int noInvisibleColumns = allTableColumns . size ( ) ; 
int visibleIndex = 0 ; 
for ( int invisibleIndex = 0 ; invisibleIndex < noInvisibleColumns ; ++ invisibleIndex ) { 
TableColumn visibleColumn = 
( visibleIndex < noVisibleColumns ? tableColumns . get ( visibleIndex ) : null ) ; 
TableColumn testColumn = allTableColumns . get ( invisibleIndex ) ; 
if ( testColumn == column ) { 
if ( visibleColumn != column ) { 
super . addColumn ( column ) ; 
super . moveColumn ( tableColumns . size ( ) - 1 , visibleIndex ) ; 
if ( testColumn == visibleColumn ) { 
++ visibleIndex ; 
public void removeColumn ( TableColumn column ) { 
int allColumnsIndex = allTableColumns . indexOf ( column ) ; 
if ( allColumnsIndex != - 1 ) { 
allTableColumns . removeElementAt ( allColumnsIndex ) ; 
public void moveColumn ( int oldIndex , int newIndex ) { 
if ( ( oldIndex < 0 ) || ( oldIndex >= getColumnCount ( ) ) || 
( newIndex < 0 ) || ( newIndex >= getColumnCount ( ) ) ) 
TableColumn fromColumn = tableColumns . get ( oldIndex ) ; 
TableColumn toColumn = tableColumns . get ( newIndex ) ; 
int allColumnsOldIndex = allTableColumns . indexOf ( fromColumn ) ; 
int allColumnsNewIndex = allTableColumns . indexOf ( toColumn ) ; 
if ( oldIndex != newIndex ) { 
allTableColumns . removeElementAt ( allColumnsOldIndex ) ; 
allTableColumns . insertElementAt ( fromColumn , allColumnsNewIndex ) ; 
super . moveColumn ( oldIndex , newIndex ) ; 
} public Enumeration < TableColumn > getColumns ( boolean onlyVisible ) { 
Vector columns = ( onlyVisible ? tableColumns : allTableColumns ) ; 
return columns . elements ( ) ; 
} public TableColumn getColumn ( int columnIndex , boolean onlyVisible ) { 
if ( onlyVisible ) { 
return tableColumns . elementAt ( columnIndex ) ; 
return allTableColumns . elementAt ( columnIndex ) ; 
} public void createColumnsFromModel ( TableModel newModel ) { 
if ( newModel != model ) { 
if ( model != null ) { 
model . removeTableModelListener ( this ) ; 
newModel . addTableModelListener ( this ) ; 
model = newModel ; 
while ( ! allTableColumns . isEmpty ( ) ) { 
removeColumn ( allTableColumns . elementAt ( 0 ) ) ; 
for ( int modelColumnIndex = 0 ; modelColumnIndex < newModel . getColumnCount ( ) ; modelColumnIndex ++ ) { 
TableColumn newColumn = new TableColumn ( modelColumnIndex ) ; 
String columnName = newModel . getColumnName ( modelColumnIndex ) ; 
newColumn . setHeaderValue ( columnName ) ; 
addColumn ( newColumn ) ; 
} static public HTTPMethod Get ( HTTPSession session , String legalurl ) throws HTTPException 
return makemethod ( HTTPSession . Methods . Get , session , legalurl ) ; 
} static protected HTTPMethod makemethod ( HTTPSession . Methods m , HTTPSession session , String url ) 
throws HTTPException 
HTTPMethod meth = null ; 
if ( MOCKMETHODCLASS == null ) { 
meth = new HTTPMethod ( m , session , url ) ; 
java . lang . Class methodcl = MOCKMETHODCLASS ; 
Constructor < HTTPMethod > cons = null ; 
cons = methodcl . getConstructor ( HTTPSession . Methods . class , HTTPSession . class , String . class ) ; 
meth = cons . newInstance ( m , session , url ) ; 
return meth ; 
} public void deflate ( Formatter f , Variable v ) throws IOException { 
H5header . Vinfo vinfo = ( H5header . Vinfo ) v . getSPobject ( ) ; 
DataBTree btree = vinfo . btree ; 
if ( btree == null || vinfo . useFillValue ) { 
protected GribCollectionMutable . VariableIndex readVariableExtensions ( GribCollectionMutable . GroupGC group , GribCollectionProto . Variable proto , GribCollectionMutable . VariableIndex vi ) { 
List < GribCollectionProto . PartitionVariable > pvList = proto . getPartVariableList ( ) ; 
PartitionCollectionMutable . VariableIndexPartitioned vip = pc . makeVariableIndexPartitioned ( group , vi , pvList . size ( ) ) ; 
vip . setPartitions ( pvList ) ; 
vip . ndups = vi . ndups ; 
vip . nrecords = vi . nrecords ; 
vip . nmissing = vi . nmissing ; 
return vip ; 
} private PartitionCollectionMutable . Partition makePartition ( GribCollectionProto . Partition proto ) { 
long partitionDateMillisecs = proto . getPartitionDate ( ) ; 
CalendarDate partitionDate = partitionDateMillisecs > 0 ? CalendarDate . of ( partitionDateMillisecs ) : null ; 
return pc . addPartition ( proto . getName ( ) , proto . getFilename ( ) , proto . getLastModified ( ) , proto . getLength ( ) , null , partitionDate ) ; 
} public Object 
nextInteger ( DapType basetype ) 
TypeSort atomtype = basetype . getTypeSort ( ) ; 
if ( ! atomtype . isIntegerType ( ) ) 
boolean unsigned = atomtype . isUnsigned ( ) ; 
return new byte [ ] { ( byte ) ( random . nextInt ( 1 << 8 ) - ( 1 << 7 ) ) } ; 
return new byte [ ] { ( byte ) ( random . nextInt ( 1 << 8 ) & 0xFF ) } ; 
return new short [ ] { ( short ) ( random . nextInt ( 1 << 16 ) - ( 1 << 15 ) ) } ; 
return new short [ ] { ( short ) ( random . nextInt ( 1 << 16 ) ) } ; 
return new int [ ] { random . nextInt ( ) } ; 
long l = random . nextLong ( ) ; 
l = l & 0xFFFFFFFF ; 
return new int [ ] { ( int ) l } ; 
return new long [ ] { random . nextLong ( ) } ; 
return new long [ ] { new BigInteger ( 64 , random ) . longValue ( ) } ; 
nextFloat ( DapType basetype ) 
return new float [ ] { random . nextFloat ( ) } ; 
return new double [ ] { random . nextDouble ( ) } ; 
nextCount ( int max ) 
int min = 1 ; 
if ( max < min || min < 1 ) 
int range = ( max + 1 ) - min ; 
int n = random . nextInt ( range ) ; 
n = n + min ; 
if ( DEBUG ) 
public synchronized void close ( ) 
throws java . io . IOException 
if ( closed ) return ; 
closed = true ; 
dsp = null ; 
public List < Array > 
readArrays ( List < Variable > variables ) 
List < Array > result = new ArrayList < Array > ( ) ; 
for ( Variable variable : variables ) { 
result . add ( variable . read ( ) ) ; 
protected Array 
readData ( Variable cdmvar , Section section ) 
throws IOException , InvalidRangeException 
assert this . dsp != null ; 
Array result = arraymap . get ( cdmvar ) ; 
if ( section != null ) { 
if ( cdmvar . getRank ( ) != section . getRank ( ) ) 
List < Range > ranges = section . getRanges ( ) ; 
if ( CDMUtil . hasVLEN ( ranges ) ) { 
ranges = ranges . subList ( 0 , ranges . size ( ) - 1 ) ; 
if ( ranges . size ( ) > 0 && ! CDMUtil . isWhole ( ranges , cdmvar ) ) 
result = result . sectionNoReduce ( ranges ) ; 
throws IOException , EOFException { 
val = source . readInt ( ) ; 
statusUI . incrementByteCount ( 4 ) ; 
} private static FileSystemProvider getProvider ( URI uri ) throws IOException { 
if ( fsproviders . containsKey ( uri . getScheme ( ) ) ) { 
return fsproviders . get ( uri . getScheme ( ) ) ; 
FileSystem fs ; 
fs = FileSystems . newFileSystem ( uri , 
new HashMap < String , Object > ( ) , 
Thread . currentThread ( ) . getContextClassLoader ( ) ) ; 
} catch ( FileSystemAlreadyExistsException e ) { 
fs = FileSystems . getFileSystem ( uri ) ; 
fsproviders . put ( uri . getScheme ( ) , fs . provider ( ) ) ; 
return fs . provider ( ) ; 
} private static void readStationTable ( ) throws IOException { 
stationTableHash = new HashMap < String , Station > ( ) ; 
ClassLoader cl = Level2VolumeScan . class . getClassLoader ( ) ; 
InputStream is = cl . getResourceAsStream ( "resources/nj22/tables/nexrad.tbl" ) ; 
for ( TableParser . Record record : recs ) { 
Station s = new Station ( ) ; 
s . id = "K" + record . get ( 0 ) ; 
s . lat = ( Double ) record . get ( 4 ) * .01 ; 
s . lon = ( Double ) record . get ( 5 ) * .01 ; 
s . elev = ( Double ) record . get ( 6 ) ; 
stationTableHash . put ( s . id , s ) ; 
} static private int parseLine ( String line ) throws IOException { 
int balony = 0 ; 
Matcher matcher = dataPattern . matcher ( line ) ; 
for ( int i = 1 ; i <= matcher . groupCount ( ) ; i ++ ) { 
String r = matcher . group ( i ) ; 
if ( r == null ) continue ; 
int value = ( int ) Long . parseLong ( r . trim ( ) ) ; 
balony += value ; 
return balony ; 
} static private NetcdfFile open ( String filename ) throws IOException { 
Ghcnm iosp = new Ghcnm ( ) ; 
RandomAccessFile raf = new RandomAccessFile ( filename , "r" ) ; 
NetcdfFile ncfile = new NetcdfFileSubclass ( iosp , filename ) ; 
iosp . open ( raf , ncfile , null ) ; 
ArrayDouble . D3 data = original . getCoordinateArray ( timeIndex ) ; 
int [ ] origin = new int [ 3 ] ; 
int [ ] shape = new int [ 3 ] ; 
shape [ 0 ] = subsetList . get ( 0 ) . length ( ) ; 
shape [ 1 ] = 1 ; 
shape [ 2 ] = 1 ; 
origin [ 0 ] = timeIndex ; 
if ( isTimeDependent ( ) && ( t_range != null ) ) { 
origin [ 0 ] = t_range . element ( timeIndex ) ; 
origin [ 1 ] = yIndex ; 
origin [ 2 ] = xIndex ; 
Array section = data . section ( origin , shape ) ; 
return ( ArrayDouble . D1 ) section . reduce ( ) ; 
public int getIndex ( T gr ) { 
Integer result = valMap . get ( extract ( gr ) ) ; 
return ( result == null ) ? 0 : result ; 
} public static void main ( String args [ ] ) throws HTTPException { 
String prefStore = ucar . util . prefs . XMLStore . makeStandardFilename ( ".unidata" , "TdsMonitor.xml" ) ; 
store = ucar . util . prefs . XMLStore . createFromFile ( prefStore , null ) ; 
prefs = store . getPreferences ( ) ; 
Debug . setStore ( prefs . node ( "Debug" ) ) ; 
BAMutil . setResourcePath ( "/resources/nj22/ui/icons/" ) ; 
ui = new TdsMonitor ( prefs , frame ) ; 
frame . setIconImage ( BAMutil . getImage ( "netcdfUI" ) ) ; 
if ( ! done ) ui . exit ( ) ; 
frame . getContentPane ( ) . add ( ui ) ; 
Rectangle bounds = ( Rectangle ) prefs . getBean ( FRAME_SIZE , new Rectangle ( 50 , 50 , 800 , 450 ) ) ; 
} protected void removeDataVariable ( String varName ) { 
Iterator iter = dataVariables . iterator ( ) ; 
VariableSimpleIF v = ( VariableSimpleIF ) iter . next ( ) ; 
if ( v . getShortName ( ) . equals ( varName ) ) 
} private String cloud_hgt2_meters ( String height ) { 
if ( height . equals ( "999" ) ) { 
return "30000" ; 
return Integer . toString ( 30 * Integer . parseInt ( height ) ) ; 
} private void writeDiff ( TableB wmo , TableB t , Formatter out ) { 
out . format ( "Class,FXY,enElementName,BUFR_Unit,BUFR_Scale,BUFR_ReferenceValue,BUFR_DataWidth_Bits%n" ) ; 
List < TableB . Descriptor > listDesc = new ArrayList < > ( t . getDescriptors ( ) ) ; 
Collections . sort ( listDesc ) ; 
for ( TableB . Descriptor d1 : listDesc ) { 
TableB . Descriptor d2 = wmo . getDescriptor ( d1 . getId ( ) ) ; 
if ( ( d2 == null ) || ( d1 . getScale ( ) != d2 . getScale ( ) ) || ( d1 . getRefVal ( ) != d2 . getRefVal ( ) ) || ( d1 . getDataWidth ( ) != d2 . getDataWidth ( ) ) ) { 
short fxy = d1 . getId ( ) ; 
int x = ( fxy & 0x3F00 ) > > 8 ; 
int y = fxy & 0xFF ; 
out . format ( "%d,%2d%03d,\"%s\",%s,%d,%d,%d%n" , x , x , y , d1 . getName ( ) , d1 . getUnits ( ) , d1 . getScale ( ) , d1 . getRefVal ( ) , d1 . getDataWidth ( ) ) ; 
public Array reallyRead ( Variable mainv , Section section , CancelTask cancelTask ) throws IOException , InvalidRangeException { 
FmrcInvLite . Gridset . Grid gridLite = ( FmrcInvLite . Gridset . Grid ) mainv . getSPobject ( ) ; 
DataType dtype = ( mainv instanceof VariableDS ) ? ( ( VariableDS ) mainv ) . getOriginalDataType ( ) : mainv . getDataType ( ) ; 
Array allData = Array . factory ( dtype , section . getShape ( ) ) ; 
int destPos = 0 ; 
Range runRange = ranges . get ( 0 ) ; 
Range timeRange = ranges . get ( 1 ) ; 
List < Range > innerSection = ranges . subList ( 2 , ranges . size ( ) ) ; 
HashMap < String , NetcdfDataset > openFilesRead = new HashMap < > ( ) ; 
for ( int runIdx : runRange ) { 
Array result = null ; 
TimeInventory . Instance timeInv = gridLite . getInstance ( runIdx , timeIdx ) ; 
if ( timeInv != null ) { 
result = read ( timeInv , gridLite . name , innerSection , openFilesRead ) ; 
result = MAMath . convert ( result , dtype ) ; 
int [ ] shape = new Section ( innerSection ) . getShape ( ) ; 
result = ( ( VariableDS ) mainv ) . getMissingDataArray ( shape ) ; 
if ( debugRead ) 
runIdx , timeIdx , mainv . getFullName ( ) , result . getSize ( ) , destPos , allData . getSize ( ) ) ; 
Array . arraycopy ( result , 0 , allData , destPos , ( int ) result . getSize ( ) ) ; 
destPos += result . getSize ( ) ; 
return allData ; 
closeAll ( openFilesRead ) ; 
} private void constructTransient ( ) { 
useColors = colors ; 
edge = new double [ ncolors ] ; 
hist = new int [ ncolors + 1 ] ; 
lm = new ListenerManager ( 
"java.beans.PropertyChangeListener" , 
"java.beans.PropertyChangeEvent" , 
"propertyChange" ) ; 
missingDataColor = Color . white ; 
} public void setNumColors ( int n ) { 
if ( n != ncolors ) { 
colors = new Color [ n ] ; 
int prevn = Math . min ( ncolors , n ) ; 
System . arraycopy ( useColors , 0 , colors , 0 , prevn ) ; 
for ( int i = ncolors ; i < n ; i ++ ) 
colors [ i ] = Color . white ; 
ncolors = n ; 
} public Color getColor ( int i ) { 
if ( i >= 0 && i < ncolors ) 
return useColors [ i ] ; 
else if ( i == ncolors && hasMissingData ) 
return missingDataColor ; 
} public void setMinMax ( double min , double max ) { 
this . min = min ; 
this . max = max ; 
interval = ( max - min ) / ( ncolors - 2 ) ; 
for ( int i = 0 ; i < ncolors ; i ++ ) 
edge [ i ] = min + i * interval ; 
lm . sendEvent ( new PropertyChangeEvent ( this , "ColorScaleLimits" , null , this ) ) ; 
public int getHistMax ( ) { 
int max = 0 , maxi = 0 ; 
for ( int i = 0 ; i <= ncolors ; i ++ ) 
if ( hist [ i ] > max ) { 
max = hist [ i ] ; 
maxi = i ; 
return maxi ; 
public void resetHist ( ) { 
hist [ i ] = 0 ; 
public String toString ( ) { 
public Object clone ( ) { 
ColorScale cl = new ColorScale ( name , colors ) ; 
return ( Object ) cl ; 
private void editModeBegin ( ) { 
Color [ ] editColors = new Color [ ncolors ] ; 
System . arraycopy ( colors , 0 , editColors , 0 , ncolors ) ; 
useColors = editColors ; 
private void editModeEnd ( boolean accept ) { 
if ( accept ) { 
System . arraycopy ( useColors , 0 , colors , 0 , ncolors ) ; 
private void setColor ( int i , Color c ) { 
useColors [ i ] = c ; 
private void setColors ( Color [ ] c ) { 
ncolors = c . length ; 
colors = new Color [ ncolors ] ; 
System . arraycopy ( c , 0 , colors , 0 , ncolors ) ; 
private void readObject ( ObjectInputStream s ) throws IOException , ClassNotFoundException { 
s . readInt ( ) ; 
this . name = s . readUTF ( ) ; 
this . colors = ( Color [ ] ) s . readObject ( ) ; 
this . ncolors = colors . length ; 
constructTransient ( ) ; 
private void writeObject ( ObjectOutputStream s ) throws IOException { 
s . writeInt ( objectVersion ) ; 
s . writeUTF ( this . name ) ; 
s . writeObject ( this . colors ) ; 
public static class Panel extends JPanel { 
private int type ; 
private int size = 50 ; 
private ColorScale cs ; 
private JLabel unitLabel = new JLabel ( "unit" , SwingConstants . CENTER ) ; 
private JPanel lpanel ; 
private boolean editable = false ; 
private int selected = - 1 ; 
private int nColorInterval ; 
private String [ ] label ; 
private boolean useLabel = true ; 
private FontUtil . StandardFont sf = FontUtil . getStandardFont ( 10 ) ; 
public Panel ( Component parent ) { 
this ( parent , ColorScale . VERTICAL , null ) ; 
public Panel ( Component parent , ColorScale cscale ) { 
this ( parent , ColorScale . VERTICAL , cscale ) ; 
public Panel ( Component parent , int type , ColorScale cscale ) { 
this . cs = ( cscale == null ) ? new ColorScale ( "default" ) : cscale ; 
this . type = type ; 
if ( type == ColorScale . VERTICAL ) { 
setPreferredSize ( new Dimension ( size , 400 ) ) ; 
setLayout ( new BoxLayout ( this , BoxLayout . Y_AXIS ) ) ; 
setPreferredSize ( new Dimension ( 400 , size ) ) ; 
setLayout ( new BoxLayout ( this , BoxLayout . X_AXIS ) ) ; 
setListener ( ) ; 
nColorInterval = cs . getNumColors ( ) ; 
for ( int i = 0 ; i < nColorInterval ; i ++ ) { 
ColorInterval intv = new ColorInterval ( nColorInterval - i - 1 ) ; 
add ( intv ) ; 
lpanel = new JPanel ( ) ; 
lpanel . add ( unitLabel ) ; 
if ( type == ColorScale . VERTICAL ) 
lpanel . setPreferredSize ( new Dimension ( size , 0 ) ) ; 
lpanel . setPreferredSize ( new Dimension ( 0 , size ) ) ; 
add ( lpanel ) ; 
label = new String [ nColorInterval ] ; 
calcLabels ( ) ; 
private void calcLabels ( ) { 
label [ 0 ] = "<" + Format . d ( cs . getEdge ( 0 ) , sigfig ) ; 
for ( int i = 1 ; i < nColorInterval - 1 ; i ++ ) { 
label [ i ] = Format . d ( cs . getEdge ( i ) , sigfig ) ; 
label [ nColorInterval - 1 ] = ">" + Format . d ( cs . getEdge ( nColorInterval - 2 ) , sigfig ) ; 
private void setListener ( ) { 
cs . addPropertyChangeListener ( new java . beans . PropertyChangeListener ( ) { 
if ( e . getPropertyName ( ) . equals ( "ColorScaleLimits" ) ) 
public ColorScale getColorScale ( ) { 
return cs ; 
public void setColorScale ( ColorScale cscale ) { 
if ( nColorInterval != cscale . getNumColors ( ) ) { 
removeAll ( ) ; 
nColorInterval = cscale . getNumColors ( ) ; 
label [ i ] = "none" ; 
revalidate ( ) ; 
this . cs = cscale ; 
public void setColors ( Color [ ] c ) { 
if ( nColorInterval != c . length ) { 
nColorInterval = c . length ; 
cs . setColors ( c ) ; 
cs . editModeBegin ( ) ; 
if ( debugColors ) { 
for ( int i = 0 ; i < cs . getNumColors ( ) ; i ++ ) 
System . out . println ( cs . getColor ( i ) ) ; 
public void setColor ( Color c ) { 
cs . setColor ( selected , c ) ; 
public void setEditMode ( boolean on , boolean accept ) { 
editable = true ; 
cs . editModeEnd ( accept ) ; 
if ( accept ) 
setColorScale ( cs ) ; 
selected = - 1 ; 
editable = false ; 
public void setSelected ( int i ) { 
selected = i ; 
public void setShowText ( boolean b ) { 
useLabel = b ; 
public void setUnitString ( String s ) { 
unitLabel . setText ( s ) ; 
public void print ( Graphics2D g , double x , double y , double width , double height ) { 
int n = cs . getNumColors ( ) ; 
double size = ( type == ColorScale . VERTICAL ) ? height / n : width / n ; 
for ( int i = 0 ; i < getComponentCount ( ) ; i ++ ) { 
Component c = getComponent ( i ) ; 
if ( c instanceof ColorInterval ) { 
ColorInterval intv = ( ColorInterval ) c ; 
intv . printV ( g , ( int ) x , ( int ) ( y + count * size ) , ( int ) width , ( int ) size ) ; 
double xpos = x + width - ( count + 1 ) * size ; 
intv . printH ( g , ( int ) xpos , ( int ) y , ( int ) size , ( int ) height ) ; 
private class ColorInterval extends JComponent { 
private int rank ; 
ColorInterval ( int r ) { 
this . rank = r ; 
addMouseListener ( new MouseAdapter ( ) { 
public void mousePressed ( MouseEvent e ) { 
if ( editable ) { 
selected = rank ; 
Panel . this . repaint ( ) ; 
public void printV ( Graphics2D g , int x , int y , int width , int height ) { 
int textSize = 15 ; 
g . setColor ( cs . getColor ( rank ) ) ; 
g . fillRect ( x , y + textSize , width , height - textSize ) ; 
if ( useLabel ) { 
g . setFont ( sf . getFont ( ) ) ; 
g . drawString ( label [ rank ] , x + 3 , y + 10 ) ; 
public void printH ( Graphics2D g , int x , int y , int width , int height ) { 
g . fillRect ( x , y + textSize , width , height - 2 * textSize ) ; 
g . setColor ( Color . white ) ; 
g . drawRect ( x , y + textSize , width , height - 2 * textSize ) ; 
if ( rank % 2 == 0 ) 
g . drawString ( label [ rank ] , x , y + textSize ) ; 
g . drawString ( label [ rank ] , x , y + height ) ; 
public void paintComponent ( Graphics g ) { 
Rectangle b = getBounds ( ) ; 
g . fillRect ( 0 , 0 , b . width - 1 , b . height - 1 ) ; 
g . setColor ( ( selected == rank ) ? Color . magenta : Color . black ) ; 
g . drawRect ( 0 , 0 , b . width - 1 , b . height - 1 ) ; 
if ( selected == rank ) { 
g . drawLine ( 0 , 0 , b . width , b . height ) ; 
g . drawLine ( 0 , b . height , b . width , 0 ) ; 
g . drawString ( label [ rank ] , 3 , 10 ) ; 
int len = vals . length ; 
os . print ( vals [ i ] ) ; 
os . print ( vals [ len - 1 ] ) ; 
sink . writeDouble ( vals [ i ] ) ; 
} public void setWorldBounds ( ScaledPanel . Bounds world ) { 
worldBounds . set ( world ) ; 
transform = null ; 
} public Graphics2D getBufferedImageGraphics ( ) { 
if ( bImage == null ) 
Graphics2D g2 = bImage . createGraphics ( ) ; 
transform = calcTransform ( screenBounds , worldBounds ) ; 
g2 . setTransform ( transform ) ; 
g2 . setStroke ( new BasicStroke ( 0.0f ) ) ; 
g2 . setRenderingHint ( RenderingHints . KEY_RENDERING , RenderingHints . VALUE_RENDER_SPEED ) ; 
g2 . setBackground ( backColor ) ; 
g2 . setClip ( worldBounds . getRect ( ) ) ; 
return g2 ; 
} public void paintComponent ( Graphics g ) { 
if ( bImage != null ) 
g . drawImage ( bImage , 0 , 0 , backColor , imageObs ) ; 
} private AffineTransform calcTransform ( Rectangle2D screen , Bounds world ) { 
double xs = screen . getWidth ( ) / ( world . getRight ( ) - world . getLeft ( ) ) ; 
double ys = screen . getHeight ( ) / ( world . getLower ( ) - world . getUpper ( ) ) ; 
AffineTransform cat = new AffineTransform ( ) ; 
cat . setToScale ( xs , ys ) ; 
cat . translate ( - world . getLeft ( ) , - world . getUpper ( ) ) ; 
if ( debugTransform ) { 
Point2D src = new Point2D . Double ( world . getLeft ( ) , world . getUpper ( ) ) ; 
Point2D dst = new Point2D . Double ( 0.0 , 0.0 ) ; 
src = new Point2D . Double ( world . getRight ( ) , world . getLower ( ) ) ; 
} static boolean 
authscopeCompatible ( AuthScope ss , AuthScope ms ) 
assert ( ss . getScheme ( ) != null && ms . getScheme ( ) != null ) ; 
if ( ! ss . getHost ( ) . equalsIgnoreCase ( ms . getHost ( ) ) ) 
if ( ss . getPort ( ) != ms . getPort ( ) ) 
String sss = ss . getScheme ( ) . toLowerCase ( ) ; 
String mss = ms . getScheme ( ) . toLowerCase ( ) ; 
if ( ! sss . equals ( mss ) ) { 
if ( sss . endsWith ( "s" ) ) sss = sss . substring ( 0 , sss . length ( ) - 1 ) ; 
if ( mss . endsWith ( "s" ) ) mss = mss . substring ( 0 , mss . length ( ) - 1 ) ; 
if ( ! sss . equals ( mss ) ) 
} static AuthScope 
authscopeUpgrade ( AuthScope ss , AuthScope ms ) 
assert ( HTTPAuthUtil . authscopeCompatible ( ss , ms ) ) ; 
String upgrade = sss ; 
if ( sss . startsWith ( "http" ) && mss . startsWith ( "http" ) ) { 
if ( sss . equals ( "https" ) || mss . equals ( "https" ) ) 
upgrade = "https" ; 
AuthScope host = new AuthScope ( ss . getHost ( ) , ss . getPort ( ) , AuthScope . ANY_REALM , upgrade ) ; 
uriToAuthScope ( URI uri ) 
assert ( uri != null ) ; 
return new AuthScope ( uri . getHost ( ) , uri . getPort ( ) , AuthScope . ANY_REALM , uri . getScheme ( ) ) ; 
if ( gcs . size ( ) == 1 ) 
if ( gcs . size ( ) == 2 ) { 
List hcs = getHorizCoordSys ( ) ; 
GridDefRecord . compare ( ( GridDefRecord ) hcs . get ( 0 ) , ( GridDefRecord ) hcs . get ( 1 ) ) ; 
} public boolean isReciprocalOf ( final Factor that ) { 
return getBase ( ) . equals ( that . getBase ( ) ) 
&& getExponent ( ) == - that . getExponent ( ) ; 
} public static TVPMeasurementMetadataType initDefaultTVPMeasurementMetadata ( 
TVPMeasurementMetadataType defaultTVPMeasurementMetadata , VariableSimpleIF dataVar ) { 
UnitReference uom = NcUnitReference . initUom ( defaultTVPMeasurementMetadata . addNewUom ( ) , dataVar ) ; 
if ( uom == null ) { 
defaultTVPMeasurementMetadata . unsetUom ( ) ; 
NcReferenceType . initInterpolationType ( defaultTVPMeasurementMetadata . addNewInterpolationType ( ) ) ; 
return defaultTVPMeasurementMetadata ; 
} public boolean isRelativeBase ( ) { 
if ( getType ( ) == ServiceType . Compound ) 
URI uri = new java . net . URI ( base ) ; 
return ! uri . isAbsolute ( ) ; 
} catch ( java . net . URISyntaxException e ) { 
throw new IllegalArgumentException ( e . getMessage ( ) ) ; 
} public static String setupRequestContext ( HttpServletRequest req ) { 
MDC . put ( "ID" , Long . toString ( logServerAccessId . incrementAndGet ( ) ) ) ; 
MDC . put ( "startTime" , Long . toString ( System . currentTimeMillis ( ) ) ) ; 
String query = req . getQueryString ( ) ; 
query = ( query != null ) ? "?" + query : "" ; 
Formatter request = new Formatter ( ) ; 
MDC . put ( "request" , request . toString ( ) ) ; 
} public static String setupNonRequestContext ( ) { 
} public String generate ( String dataseturl ) 
StringWriter sw = new StringWriter ( ) ; 
IndentWriter printer = new IndentWriter ( sw ) ; 
printer . marginPrintln ( "<DatasetServices" ) ; 
printer . indent ( 2 ) ; 
printer . marginPrintln ( "xmlns=\"http://xml.opendap.org/ns/DAP/4.0/dataset-services#\">" ) ; 
printer . outdent ( ) ; 
printer . marginPrint ( "<DapVersion>" ) ; 
printer . print ( DapProtocol . X_DAP_VERSION ) ; 
printer . println ( "</DapVersion>" ) ; 
printer . marginPrint ( "<ServerSoftwareVersion>" ) ; 
printer . print ( DapProtocol . X_DAP_SERVER ) ; 
printer . println ( "</ServerSoftwareVersion>" ) ; 
printer . indent ( 3 ) ; 
printer . marginPrintln ( "role=\"http://services.opendap.org/dap4/dataset-services\">" ) ; 
printer . outdent ( 3 ) ; 
printer . indent ( ) ; 
printer . print ( DapProtocol . contenttypes . get ( RequestMode . DSR ) . contenttype ) ; 
printer . println ( "\"" ) ; 
printer . marginPrint ( "href=\"" ) ; 
printer . print ( dataseturl ) ; 
printer . println ( "\">" ) ; 
printer . outdent ( 2 ) ; 
printer . marginPrintln ( "</link>" ) ; 
printer . println ( ".xml\"/>" ) ; 
printer . marginPrintln ( "</Service>" ) ; 
printer . marginPrintln ( "role=\"http://services.opendap.org/dap4/dataset-metadata\">" ) ; 
printer . print ( DapProtocol . contenttypes . get ( RequestMode . DMR ) . contenttype ) ; 
printer . println ( ".dmr\">" ) ; 
printer . println ( ".dmr.xml\"/>" ) ; 
printer . marginPrintln ( "role=\"http://services.opendap.org/dap4/data\">" ) ; 
printer . print ( DapProtocol . contenttypes . get ( RequestMode . DAP ) . contenttype ) ; 
printer . println ( ".dap\"/>" ) ; 
printer . marginPrintln ( "</DatasetServices>" ) ; 
printer . flush ( ) ; 
printer . close ( ) ; 
sw . close ( ) ; 
return sw . toString ( ) ; 
} public InvCatalog getDirCatalog ( File directory , String filterPattern , boolean sortInIncreasingOrder , boolean addDatasetSize ) 
return ( this . getDirCatalog ( directory , filterPattern , sortInIncreasingOrder , null , addDatasetSize , null , null , null ) ) ; 
} public int findIdx ( int want ) { 
if ( isConstant ) return ( want == start ) ? 0 : - 1 ; 
if ( isSequential ) return want - start ; 
if ( isSorted ) { 
return Arrays . binarySearch ( raw , want ) ; 
for ( int i = 0 ; i < raw . length ; i ++ ) 
if ( raw [ i ] == want ) return i ; 
} private Object readMetadataContentFromURL ( InvDataset dataset , String urlString ) 
throws java . net . MalformedURLException , java . io . IOException 
Document doc ; 
SAXBuilder builder = new SAXBuilder ( true ) ; 
doc = builder . build ( urlString ) ; 
} catch ( JDOMException e ) 
if ( showParsedXML ) 
XMLOutputter xmlOut = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; 
return ( readMetadataContentJdom ( dataset , doc . getRootElement ( ) ) ) ; 
} public Object readMetadataContent ( InvDataset dataset , org . jdom2 . Element mdataElement ) 
return readMetadataContentJdom ( dataset , mdataElement ) ; 
} public void addMetadataContent ( org . jdom2 . Element mdataJdomElement , Object contentObject ) 
ArrayList catGenConfigList = ( ArrayList ) contentObject ; 
Iterator iter = catGenConfigList . iterator ( ) ; 
CatalogGenConfig cgc = ( CatalogGenConfig ) iter . next ( ) ; 
mdataJdomElement . addContent ( createCatGenConfigElement ( cgc ) ) ; 
} public boolean validateMetadataContent ( Object contentObject , StringBuilder out ) 
boolean ok = true ; 
CatalogGenConfig catGenConf = ( CatalogGenConfig ) iter . next ( ) ; 
ok &= catGenConf . validate ( out ) ; 
return ok ; 
} private Object readMetadataContentJdom ( InvDataset dataset , Element mdataElement ) 
Namespace catGenConfigNamespace = null ; 
ArrayList catGenConfigList = new ArrayList ( ) ; 
Iterator iter = mdataElement . getChildren ( "catalogGenConfig" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) . iterator ( ) ; 
if ( ! iter . hasNext ( ) ) 
iter = mdataElement . getChildren ( "catalogGenConfig" , mdataElement . getNamespace ( ) ) . iterator ( ) ; 
Element catGenConfigElement = ( Element ) iter . next ( ) ; 
log . debug ( "readMetadataContent=" + catGenConfigElement ) ; 
catGenConfigList . add ( readCatGenConfigElement ( dataset , catGenConfigElement ) ) ; 
return ( catGenConfigList ) ; 
} private CatalogGenConfig readCatGenConfigElement ( 
InvDataset parentDataset , Element catGenConfElement ) 
String type = catGenConfElement . getAttributeValue ( "type" ) ; 
CatalogGenConfig catGenConf = new CatalogGenConfig ( parentDataset , type ) ; 
java . util . List list = catGenConfElement . getChildren ( "datasetSource" , catGenConfElement . getNamespace ( ) ) ; 
for ( int i = 0 ; i < list . size ( ) ; i ++ ) 
Element dsSourceElement = ( Element ) list . get ( i ) ; 
catGenConf . setDatasetSource ( readDatasetSourceElement ( parentDataset , 
dsSourceElement ) ) ; 
return ( catGenConf ) ; 
} private DatasetSource readDatasetSourceElement ( InvDataset parentDataset , 
Element dsSourceElement ) 
String name = dsSourceElement . getAttributeValue ( "name" ) ; 
String type = dsSourceElement . getAttributeValue ( "type" ) ; 
String structure = dsSourceElement . getAttributeValue ( "structure" ) ; 
String accessPoint = dsSourceElement . getAttributeValue ( "accessPoint" ) ; 
String createCatalogRefs = dsSourceElement . getAttributeValue ( "createCatalogRefs" ) ; 
Element resultServiceElement = dsSourceElement . getChild ( "resultService" , dsSourceElement . getNamespace ( ) ) ; 
ResultService resultService = readResultServiceElement ( parentDataset , 
resultServiceElement ) ; 
DatasetSource dsSource = DatasetSource . newDatasetSource ( name , 
DatasetSourceType . getType ( type ) , 
DatasetSourceStructure . getStructure ( structure ) , 
accessPoint , resultService ) ; 
if ( createCatalogRefs != null ) 
dsSource . setCreateCatalogRefs ( Boolean . valueOf ( createCatalogRefs ) . booleanValue ( ) ) ; 
java . util . List list = dsSourceElement . getChildren ( "datasetNamer" , dsSourceElement . getNamespace ( ) ) ; 
Element dsNamerElement = ( Element ) list . get ( i ) ; 
dsSource . addDatasetNamer ( readDatasetNamerElement ( parentDataset , 
dsNamerElement ) ) ; 
list = dsSourceElement . getChildren ( "datasetFilter" , dsSourceElement . getNamespace ( ) ) ; 
Element dsFilterElement = ( Element ) list . get ( i ) ; 
dsSource . addDatasetFilter ( readDatasetFilterElement ( dsSource , 
dsFilterElement ) ) ; 
return ( dsSource ) ; 
} private DatasetNamer readDatasetNamerElement ( InvDataset parentDataset , 
Element dsNamerElement ) 
String name = dsNamerElement . getAttributeValue ( "name" ) ; 
String addLevel = dsNamerElement . getAttributeValue ( "addLevel" ) ; 
String type = dsNamerElement . getAttributeValue ( "type" ) ; 
String matchPattern = dsNamerElement . getAttributeValue ( "matchPattern" ) ; 
String substitutePattern = dsNamerElement . getAttributeValue ( "substitutePattern" ) ; 
String attribContainer = dsNamerElement . getAttributeValue ( "attribContainer" ) ; 
String attribName = dsNamerElement . getAttributeValue ( "attribName" ) ; 
DatasetNamer dsNamer = new DatasetNamer ( parentDataset , 
name , addLevel , type , 
matchPattern , substitutePattern , 
attribContainer , attribName ) ; 
return ( dsNamer ) ; 
} private DatasetFilter readDatasetFilterElement ( DatasetSource parentDatasetSource , 
Element dsFilterElement ) 
String name = dsFilterElement . getAttributeValue ( "name" ) ; 
String type = dsFilterElement . getAttributeValue ( "type" ) ; 
String matchPattern = dsFilterElement . getAttributeValue ( "matchPattern" ) ; 
DatasetFilter dsFilter = new DatasetFilter ( parentDatasetSource , 
name , DatasetFilter . Type . getType ( type ) , matchPattern ) ; 
String matchPatternTarget = dsFilterElement . getAttributeValue ( "matchPatternTarget" ) ; 
dsFilter . setMatchPatternTarget ( matchPatternTarget ) ; 
if ( dsFilterElement . getAttributeValue ( "applyToCollectionDatasets" ) != null ) 
boolean applyToCollectionDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( "applyToCollectionDatasets" ) ) . booleanValue ( ) ; 
dsFilter . setApplyToCollectionDatasets ( applyToCollectionDatasets ) ; 
if ( dsFilterElement . getAttributeValue ( "applyToAtomicDatasets" ) != null ) 
boolean applyToAtomicDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( "applyToAtomicDatasets" ) ) . booleanValue ( ) ; 
dsFilter . setApplyToAtomicDatasets ( applyToAtomicDatasets ) ; 
if ( dsFilterElement . getAttributeValue ( "rejectMatchingDatasets" ) != null ) 
boolean rejectMatchingDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( "rejectMatchingDatasets" ) ) . booleanValue ( ) ; 
dsFilter . setRejectMatchingDatasets ( rejectMatchingDatasets ) ; 
return ( dsFilter ) ; 
} private ResultService readResultServiceElement ( InvDataset parentDataset , 
Element resultServiceElement ) 
String name = resultServiceElement . getAttributeValue ( "name" ) ; 
String serviceType = resultServiceElement . getAttributeValue ( "serviceType" ) ; 
String base = resultServiceElement . getAttributeValue ( "base" ) ; 
String suffix = resultServiceElement . getAttributeValue ( "suffix" ) ; 
String accessPointHeader = 
resultServiceElement . getAttributeValue ( "accessPointHeader" ) ; 
return ( new ResultService ( name , ServiceType . getType ( serviceType ) , base , suffix , 
accessPointHeader ) ) ; 
} private org . jdom2 . Element createCatGenConfigElement ( CatalogGenConfig cgc ) 
Element cgcElem = new Element ( "catalogGenConfig" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; 
if ( cgc != null ) 
if ( cgc . getType ( ) != null ) 
cgcElem . setAttribute ( "type" , cgc . getType ( ) . toString ( ) ) ; 
DatasetSource dsSource = cgc . getDatasetSource ( ) ; 
cgcElem . addContent ( createDatasetSourceElement ( dsSource ) ) ; 
return ( cgcElem ) ; 
} private org . jdom2 . Element createDatasetSourceElement ( DatasetSource dsSource ) 
Element dssElem = new Element ( "datasetSource" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; 
if ( dsSource != null ) 
if ( dsSource . getName ( ) != null ) 
dssElem . setAttribute ( "name" , dsSource . getName ( ) ) ; 
if ( dsSource . getType ( ) != null ) 
dssElem . setAttribute ( "type" , dsSource . getType ( ) . toString ( ) ) ; 
if ( dsSource . getStructure ( ) != null ) 
dssElem . setAttribute ( "structure" , dsSource . getStructure ( ) . toString ( ) ) ; 
if ( dsSource . getAccessPoint ( ) != null ) 
dssElem . setAttribute ( "accessPoint" , dsSource . getAccessPoint ( ) ) ; 
dssElem . setAttribute ( "createCatalogRefs" , Boolean . toString ( dsSource . isCreateCatalogRefs ( ) ) ) ; 
ResultService rs = dsSource . getResultService ( ) ; 
dssElem . addContent ( createResultServiceElement ( rs ) ) ; 
java . util . List list = dsSource . getDatasetNamerList ( ) ; 
for ( int j = 0 ; j < list . size ( ) ; j ++ ) 
DatasetNamer dsNamer = ( DatasetNamer ) list . get ( j ) ; 
dssElem . addContent ( createDatasetNamerElement ( dsNamer ) ) ; 
list = dsSource . getDatasetFilterList ( ) ; 
DatasetFilter dsFilter = ( DatasetFilter ) list . get ( j ) ; 
dssElem . addContent ( createDatasetFilterElement ( dsFilter ) ) ; 
return ( dssElem ) ; 
} private org . jdom2 . Element createDatasetNamerElement ( DatasetNamer dsNamer ) 
Element dsnElem = new Element ( "datasetNamer" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; 
if ( dsNamer != null ) 
if ( dsNamer . getName ( ) != null ) 
dsnElem . setAttribute ( "name" , dsNamer . getName ( ) ) ; 
dsnElem . setAttribute ( "addLevel" , Boolean . toString ( dsNamer . getAddLevel ( ) ) ) ; 
if ( dsNamer . getType ( ) != null ) 
dsnElem . setAttribute ( "type" , dsNamer . getType ( ) . toString ( ) ) ; 
if ( dsNamer . getMatchPattern ( ) != null ) 
dsnElem . setAttribute ( "matchPattern" , dsNamer . getMatchPattern ( ) ) ; 
if ( dsNamer . getSubstitutePattern ( ) != null ) 
dsnElem . setAttribute ( "substitutePattern" , dsNamer . getSubstitutePattern ( ) ) ; 
if ( dsNamer . getAttribContainer ( ) != null ) 
dsnElem . setAttribute ( "attribContainer" , dsNamer . getAttribContainer ( ) ) ; 
if ( dsNamer . getAttribName ( ) != null ) 
dsnElem . setAttribute ( "attribName" , dsNamer . getAttribName ( ) ) ; 
return ( dsnElem ) ; 
} private org . jdom2 . Element createDatasetFilterElement ( DatasetFilter dsFilter ) 
Element dsfElem = new Element ( "datasetFilter" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; 
if ( dsFilter != null ) 
if ( dsFilter . getName ( ) != null ) 
dsfElem . setAttribute ( "name" , dsFilter . getName ( ) ) ; 
if ( dsFilter . getType ( ) != null ) 
dsfElem . setAttribute ( "type" , dsFilter . getType ( ) . toString ( ) ) ; 
if ( dsFilter . getMatchPattern ( ) != null ) 
dsfElem . setAttribute ( "matchPattern" , dsFilter . getMatchPattern ( ) ) ; 
if ( dsFilter . getMatchPatternTarget ( ) != null ) 
dsfElem . setAttribute ( "matchPatternTarget" , dsFilter . getMatchPatternTarget ( ) ) ; 
dsfElem . setAttribute ( "applyToCollectionDatasets" , String . valueOf ( dsFilter . isApplyToCollectionDatasets ( ) ) ) ; 
dsfElem . setAttribute ( "applyToAtomicDatasets" , String . valueOf ( dsFilter . isApplyToAtomicDatasets ( ) ) ) ; 
dsfElem . setAttribute ( "rejectMatchingDatasets" , String . valueOf ( dsFilter . isRejectMatchingDatasets ( ) ) ) ; 
return ( dsfElem ) ; 
} private org . jdom2 . Element createResultServiceElement ( ResultService resultService ) 
Element rsElem = new Element ( "resultService" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; 
if ( resultService != null ) 
if ( resultService . getName ( ) != null ) 
rsElem . setAttribute ( "name" , resultService . getName ( ) ) ; 
if ( resultService . getServiceType ( ) != null ) 
rsElem . setAttribute ( "serviceType" , resultService . getServiceType ( ) . toString ( ) ) ; 
if ( resultService . getBase ( ) != null ) 
rsElem . setAttribute ( "base" , resultService . getBase ( ) ) ; 
if ( resultService . getSuffix ( ) != null ) 
rsElem . setAttribute ( "suffix" , resultService . getSuffix ( ) ) ; 
if ( resultService . getAccessPointHeader ( ) != null ) 
rsElem . setAttribute ( "accessPointHeader" , resultService . getAccessPointHeader ( ) ) ; 
return ( rsElem ) ; 
} static public boolean isSet ( String flagName ) { 
if ( store == null ) return false ; 
NamePart np = partit ( flagName ) ; 
if ( ( np . storeName . length ( ) > 0 ) && ! store . nodeExists ( np . storeName ) ) 
else if ( null == store . node ( np . storeName ) . get ( np . keyName , null ) ) 
} catch ( BackingStoreException e ) { } 
boolean value = store . node ( np . storeName ) . getBoolean ( np . keyName , false ) ; 
store . node ( np . storeName ) . putBoolean ( np . keyName , value ) ; 
} static public void constructMenu ( JMenu topMenu ) { 
if ( topMenu . getItemCount ( ) > 0 ) 
topMenu . removeAll ( ) ; 
addToMenu ( topMenu , store ) ; 
topMenu . revalidate ( ) ; 
} static private void addToMenu ( JMenu menu , Preferences prefs ) throws BackingStoreException { 
String [ ] keys = prefs . keys ( ) ; 
for ( String key : keys ) { 
boolean bval = prefs . getBoolean ( key , false ) ; 
String fullname = prefs . absolutePath ( ) + "/" + key ; 
menu . add ( new DebugMenuItem ( fullname , key , bval ) ) ; 
String [ ] kidName = prefs . childrenNames ( ) ; 
for ( String aKidName : kidName ) { 
Preferences pkid = prefs . node ( aKidName ) ; 
JMenu subMenu = new JMenu ( pkid . name ( ) ) ; 
menu . add ( subMenu ) ; 
addToMenu ( subMenu , pkid ) ; 
} public void addParameters ( String tbl ) throws IOException { 
try ( InputStream is = getInputStream ( tbl ) ) { 
String content = readContents ( is ) ; 
String [ ] lines = content . split ( "\n" ) ; 
List < String [ ] > result = new ArrayList < > ( ) ; 
for ( String line : lines ) { 
String tline = line . trim ( ) ; 
if ( tline . length ( ) == 0 ) { 
if ( tline . startsWith ( "!" ) ) { 
String [ ] words = new String [ indices . length ] ; 
for ( int idx = 0 ; idx < indices . length ; idx ++ ) { 
if ( indices [ idx ] >= tline . length ( ) ) { 
if ( indices [ idx ] + lengths [ idx ] > tline . length ( ) ) { 
words [ idx ] = line . substring ( indices [ idx ] ) ; 
words [ idx ] = line . substring ( indices [ idx ] , 
indices [ idx ] + lengths [ idx ] ) ; 
words [ idx ] = words [ idx ] . trim ( ) ; 
result . add ( words ) ; 
for ( String [ ] aResult : result ) { 
GempakParameter p = makeParameter ( aResult ) ; 
if ( p . getName ( ) . contains ( "(" ) ) { 
templateParamMap . put ( p . getName ( ) , p ) ; 
paramMap . put ( p . getName ( ) , p ) ; 
} private GempakParameter makeParameter ( String [ ] words ) { 
int num = 0 ; 
String description ; 
if ( words [ 0 ] != null ) { 
num = ( int ) Double . parseDouble ( words [ 0 ] ) ; 
if ( ( words [ 3 ] == null ) || words [ 3 ] . equals ( "" ) ) { 
String name = words [ 3 ] ; 
if ( name . contains ( "-" ) ) { 
int first = name . indexOf ( "-" ) ; 
int last = name . lastIndexOf ( "-" ) ; 
StringBuilder buf = new StringBuilder ( name . substring ( 0 , first ) ) ; 
buf . append ( "(" ) ; 
for ( int i = first ; i <= last ; i ++ ) { 
buf . append ( "\\d" ) ; 
buf . append ( ")" ) ; 
buf . append ( name . substring ( last + 1 ) ) ; 
name = buf . toString ( ) ; 
if ( ( words [ 1 ] == null ) || words [ 1 ] . equals ( "" ) ) { 
description = words [ 3 ] ; 
description = words [ 1 ] ; 
String unit = words [ 2 ] ; 
if ( unit != null ) { 
unit = unit . replaceAll ( "\\*\\*" , "" ) ; 
if ( unit . equals ( "-" ) ) { 
unit = "" ; 
int decimalScale ; 
decimalScale = Integer . parseInt ( words [ 4 ] . trim ( ) ) ; 
} catch ( NumberFormatException ne ) { 
decimalScale = 0 ; 
return new GempakParameter ( num , name , description , unit , 
} public GempakParameter getParameter ( String name ) { 
GempakParameter param = paramMap . get ( name ) ; 
if ( param == null ) { 
Set < String > keys = templateParamMap . keySet ( ) ; 
if ( ! keys . isEmpty ( ) ) { 
Pattern p = Pattern . compile ( key ) ; 
Matcher m = p . matcher ( name ) ; 
if ( m . matches ( ) ) { 
String value = m . group ( 1 ) ; 
GempakParameter match = templateParamMap . get ( key ) ; 
param = new GempakParameter ( match . getNumber ( ) , name , 
match . getDecimalScale ( ) ) ; 
paramMap . put ( name , param ) ; 
return param ; 
GempakParameterTable pt = new GempakParameterTable ( ) ; 
pt . addParameters ( "resources/nj22/tables/gempak/params.tbl" ) ; 
String param = args [ 0 ] ; 
GempakParameter parm = pt . getParameter ( param ) ; 
if ( parm != null ) { 
} private String readContents ( InputStream is ) throws IOException { 
return new String ( readBytes ( is ) , CDM . utf8Charset ) ; 
} private byte [ ] readBytes ( InputStream is ) throws IOException { 
int totalRead = 0 ; 
byte [ ] content = new byte [ 1000000 ] ; 
int howMany = is . read ( content , totalRead , 
content . length - totalRead ) ; 
if ( howMany < 0 ) { 
if ( howMany == 0 ) { 
totalRead += howMany ; 
if ( totalRead >= content . length ) { 
byte [ ] tmp = content ; 
int newLength = ( ( content . length < 25000000 ) 
? content . length * 2 
: content . length + 5000000 ) ; 
content = new byte [ newLength ] ; 
System . arraycopy ( tmp , 0 , content , 0 , totalRead ) ; 
byte [ ] results = new byte [ totalRead ] ; 
System . arraycopy ( content , 0 , results , 0 , totalRead ) ; 
} private InputStream getInputStream ( String resourceName ) throws IOException { 
ClassLoader cl = GempakParameterTable . class . getClassLoader ( ) ; 
if ( f . exists ( ) ) { 
s = new FileInputStream ( f ) ; 
String encodedUrl = m . replaceAll ( "%20" ) ; 
URL dataUrl = new URL ( encodedUrl ) ; 
URLConnection connection = dataUrl . openConnection ( ) ; 
return connection . getInputStream ( ) ; 
} public static UnitReference initUom ( UnitReference uom , VariableSimpleIF dataVar ) { 
String udunits = dataVar . getUnitsString ( ) ; 
String ucum = ErddapEDUnits . udunitsToUcum ( udunits ) ; 
uom . setCode ( ucum ) ; 
return uom ; 
} protected static double getMetersConversionFactor ( 
String unitsString ) throws Exception { 
SimpleUnit unit = SimpleUnit . factoryWithExceptions ( unitsString ) ; 
return unit . convertTo ( 1.0 , SimpleUnit . meterUnit ) ; 
} public String getDetailInfo ( ) { 
StringBuffer sbuff = new StringBuffer ( ) ; 
sbuff . append ( "TrajectoryObsDataset\n" ) ; 
for ( Iterator it = 
this . getTrajectoryIds ( ) . iterator ( ) ; it . hasNext ( ) ; ) { 
sbuff . append ( super . getDetailInfo ( ) ) ; 
} public boolean syncExtend ( ) { 
if ( ! this . netcdfDataset . hasUnlimitedDimension ( ) ) { 
if ( ! this . netcdfDataset . syncExtend ( ) ) { 
int newNumPoints = this . trajectoryDim . getLength ( ) ; 
if ( this . trajectoryNumPoint >= newNumPoints ) { 
this . trajectoryNumPoint = newNumPoints ; 
( ( Trajectory ) this . trajectory ) . setNumPoints ( 
this . trajectoryNumPoint ) ; 
endDate = trajectory . getTime ( trajectoryNumPoint - 1 ) ; 
( ( Trajectory ) trajectory ) . setEndDate ( endDate ) ; 
public PointFeature next ( ) throws NoSuchElementException { 
if ( ! hasNext ( ) ) { 
PointFeature pointFeat = pointIter . next ( ) ; 
calcBounds ( pointFeat ) ; 
return pointFeat ; 
for ( int i = 0 ; i < getSize ( ) ; i ++ ) { 
vals [ i ] = i ; 
} public String replaceFileTemplate ( String filespec , int ensIndex ) { 
return filespec . replaceAll ( ENS_TEMPLATE_ID , 
getEnsembleNames ( ) . get ( ensIndex ) ) ; 
} public void setStationInfo ( String stnIdVName , String stnDescVName ) { 
this . stnIdVName = stnIdVName ; 
this . stnDescVName = stnDescVName ; 
Variable stationVar = ncfile . findVariable ( stnIdVName ) ; 
stationIdType = stationVar . getDataType ( ) ; 
} public ArrayList readAllCreateObs ( CancelTask cancel ) throws IOException { 
boolean hasStations = stnIdVName != null ; 
if ( hasStations ) 
stnHash = new HashMap < Object , ucar . unidata . geoloc . Station > ( ) ; 
double minDate = Double . MAX_VALUE ; 
double maxDate = - Double . MAX_VALUE ; 
double minLat = Double . MAX_VALUE ; 
double maxLat = - Double . MAX_VALUE ; 
double minLon = Double . MAX_VALUE ; 
double maxLon = - Double . MAX_VALUE ; 
int recno = 0 ; 
try ( StructureDataIterator ii = recordVar . getStructureIterator ( ) ) { 
StructureData sdata = ii . next ( ) ; 
StructureMembers members = sdata . getStructureMembers ( ) ; 
Object stationId = null ; 
if ( hasStations ) { 
if ( stationIdType == DataType . INT ) { 
int stationNum = sdata . getScalarInt ( stnIdVName ) ; 
stationId = new Integer ( stationNum ) ; 
stationId = sdata . getScalarString ( stnIdVName ) . trim ( ) ; 
String desc = ( stnDescVName == null ) ? null : sdata . getScalarString ( stnDescVName ) ; 
double lat = sdata . convertScalarDouble ( latVName ) ; 
double lon = sdata . convertScalarDouble ( lonVName ) ; 
double alt = ( altVName == null ) ? Double . NaN : altScaleFactor * sdata . convertScalarDouble ( altVName ) ; 
double obsTime = sdata . convertScalarDouble ( members . findMember ( obsTimeVName ) ) ; 
double nomTime = ( nomTimeVName == null ) ? obsTime : sdata . convertScalarDouble ( members . findMember ( nomTimeVName ) ) ; 
StationImpl stn = ( StationImpl ) stnHash . get ( stationId ) ; 
if ( stn == null ) { 
stn = new StationImpl ( stationId . toString ( ) , desc , lat , lon , alt ) ; 
stnHash . put ( stationId , stn ) ; 
RecordStationObs stnObs = new RecordStationObs ( stn , obsTime , nomTime , recno ) ; 
records . add ( stnObs ) ; 
stn . addObs ( stnObs ) ; 
records . add ( new RecordPointObs ( new ucar . unidata . geoloc . EarthLocationImpl ( lat , lon , alt ) , obsTime , nomTime , recno ) ) ; 
minDate = Math . min ( minDate , obsTime ) ; 
maxDate = Math . max ( maxDate , obsTime ) ; 
minLat = Math . min ( minLat , lat ) ; 
maxLat = Math . max ( maxLat , lat ) ; 
minLon = Math . min ( minLon , lon ) ; 
maxLon = Math . max ( maxLon , lon ) ; 
recno ++ ; 
if ( ( cancel != null ) && cancel . isCancel ( ) ) return null ; 
boundingBox = new LatLonRect ( new LatLonPointImpl ( minLat , minLon ) , new LatLonPointImpl ( maxLat , maxLon ) ) ; 
return records ; 
} public void addPropertyChangeListener ( PropertyChangeListener pcl ) { 
if ( listenerList == null ) 
listenerList = new javax . swing . event . EventListenerList ( ) ; 
listenerList . add ( PropertyChangeListener . class , pcl ) ; 
} protected boolean validate ( StringBuffer buff ) { 
if ( ! _validate ( buff ) ) return false ; 
Object editValue = getEditValue ( ) ; 
if ( editValue == null ) 
for ( FieldValidator v : validators ) { 
if ( ! v . validate ( this , editValue , buff ) ) return false ; 
if ( acceptIfDifferent ( editValue ) ) { 
setEditValue ( validValue ) ; 
sendEvent ( ) ; 
} protected boolean accept ( StringBuffer buff ) { 
if ( ! validate ( buff ) ) { 
validate ( buff ) ; 
if ( acceptIfDifferent ( getEditValue ( ) ) ) { 
setStoreValue ( validValue ) ; 
} protected boolean acceptIfDifferent ( Object newValue ) { 
if ( ( newValue == null ) && ( validValue == null ) ) return false ; 
if ( ( validValue != null ) && validValue . equals ( newValue ) ) return false ; 
previousValue = getValue ( ) ; 
validValue = newValue ; 
} protected void restoreValue ( Object defValue ) { 
if ( storeData != null ) { 
validValue = getStoreValue ( defValue ) ; 
} protected void setNewValueFromStore ( ) { 
Object newValue = getStoreValue ( validValue ) ; 
if ( acceptIfDifferent ( newValue ) ) { 
setEditValue ( newValue ) ; 
} protected void sendEvent ( ) { 
if ( listenerList != null ) { 
PropertyChangeEvent event = new PropertyChangeEvent ( this , name , previousValue , getValue ( ) ) ; 
Object [ ] listeners = listenerList . getListenerList ( ) ; 
for ( int i = listeners . length - 2 ; i >= 0 ; i -= 2 ) 
( ( PropertyChangeListener ) listeners [ i + 1 ] ) . propertyChange ( event ) ; 
} static private void showFormatInfo ( JFormattedTextField tf ) { 
JFormattedTextField . AbstractFormatter ff = tf . getFormatter ( ) ; 
if ( ff instanceof NumberFormatter ) { 
NumberFormatter nf = ( NumberFormatter ) ff ; 
Format f = nf . getFormat ( ) ; 
if ( f instanceof NumberFormat ) { 
NumberFormat nfat = ( NumberFormat ) f ; 
nfat . getMinimumIntegerDigits ( ) ) ; 
nfat . getMaximumIntegerDigits ( ) ) ; 
nfat . getMinimumFractionDigits ( ) ) ; 
nfat . getMaximumFractionDigits ( ) ) ; 
if ( f instanceof DecimalFormat ) { 
DecimalFormat df = ( DecimalFormat ) f ; 
} private static String formatDouble ( double d , int min_sigFigs , int fixed_decimals ) { 
String s = java . lang . Double . toString ( d ) ; 
if ( java . lang . Double . isNaN ( d ) ) return s ; 
String sign ; 
String unsigned ; 
if ( s . startsWith ( "-" ) || s . startsWith ( "+" ) ) { 
sign = s . substring ( 0 , 1 ) ; 
unsigned = s . substring ( 1 ) ; 
sign = "" ; 
unsigned = s ; 
String mantissa ; 
String exponent ; 
int eInd = unsigned . indexOf ( 'E' ) ; 
if ( eInd == - 1 ) 
eInd = unsigned . indexOf ( 'e' ) ; 
if ( eInd == - 1 ) { 
mantissa = unsigned ; 
exponent = "" ; 
mantissa = unsigned . substring ( 0 , eInd ) ; 
exponent = unsigned . substring ( eInd ) ; 
StringBuffer number , fraction ; 
int dotInd = mantissa . indexOf ( '.' ) ; 
if ( dotInd == - 1 ) { 
number = new StringBuffer ( mantissa ) ; 
fraction = new StringBuffer ( "" ) ; 
number = new StringBuffer ( mantissa . substring ( 0 , dotInd ) ) ; 
fraction = new StringBuffer ( mantissa . substring ( dotInd + 1 ) ) ; 
int numFigs = number . length ( ) ; 
int fracFigs = fraction . length ( ) ; 
if ( fixed_decimals != - 1 ) { 
if ( fixed_decimals == 0 ) { 
fraction . setLength ( 0 ) ; 
} else if ( fixed_decimals > fracFigs ) { 
int want = fixed_decimals - fracFigs ; 
for ( int i = 0 ; i < want ; i ++ ) 
fraction . append ( "0" ) ; 
} else if ( fixed_decimals < fracFigs ) { 
int chop = fracFigs - fixed_decimals ; 
fraction . setLength ( fraction . length ( ) - chop ) ; 
fracFigs = fixed_decimals ; 
if ( ( numFigs == 0 || number . toString ( ) . equals ( "0" ) ) && fracFigs > 0 ) { 
numFigs = 0 ; 
number = new StringBuffer ( "" ) ; 
for ( int i = 0 ; i < fraction . length ( ) ; ++ i ) { 
if ( fraction . charAt ( i ) != '0' ) 
-- fracFigs ; 
if ( ( fracFigs == 0 ) && numFigs > 0 ) { 
for ( int i = number . length ( ) - 1 ; i > 0 ; i -- ) { 
if ( number . charAt ( i ) != '0' ) 
-- numFigs ; 
int sigFigs = numFigs + fracFigs ; 
if ( sigFigs > min_sigFigs ) { 
int chop = Math . min ( sigFigs - min_sigFigs , fracFigs ) ; 
fracFigs -= chop ; 
if ( fraction . length ( ) == 0 ) 
return sign + number + exponent ; 
return sign + number + "." + fraction + exponent ; 
public byte [ ] getBitmap ( RandomAccessFile raf ) throws IOException { 
if ( bitMapIndicator == 255 ) 
if ( bitMapIndicator == 254 ) 
if ( bitMapIndicator != 0 ) { 
raf . seek ( startingPosition ) ; 
int length = GribNumbers . int4 ( raf ) ; 
byte [ ] data = new byte [ length - 6 ] ; 
} public void writeExternal ( DataOutputStream out ) throws IOException { 
ConfigCatalogExtProto . Catalog . Builder builder = ConfigCatalogExtProto . Catalog . newBuilder ( ) ; 
builder . setCatId ( catId ) ; 
builder . setCatLocation ( catRelLocation ) ; 
builder . setIsRoot ( isRoot ) ; 
builder . setLastRead ( lastRead ) ; 
ConfigCatalogExtProto . Catalog index = builder . build ( ) ; 
byte [ ] b = index . toByteArray ( ) ; 
out . writeInt ( b . length ) ; 
out . write ( b ) ; 
total_count ++ ; 
total_nbytes += b . length + 4 ; 
} public static DataFormatType findType ( String name ) { 
for ( DataFormatType m : members ) { 
} public static DataFormatType getType ( String name ) 
DataFormatType t = findType ( name ) ; 
return t != null ? t : new DataFormatType ( name , false ) ; 
} public static PointType initPoint ( PointType point , StationTimeSeriesFeature stationFeat ) { 
String id = MarshallingUtil . createIdForType ( PointType . class ) ; 
point . setId ( id ) ; 
NcDirectPositionType . initPos ( point . addNewPos ( ) , stationFeat ) ; 
return point ; 
} public void setNetcdfFile ( NetcdfFile ncf ) { 
this . ncfile = ncf ; 
this . filename = ncf . getLocation ( ) ; 
final GetDataRunnable runner = new GetDataRunnable ( ) { 
public void run ( Object o ) throws IOException { 
final StringWriter sw = new StringWriter ( 50000 ) ; 
NCdumpW . print ( ncfile , command , sw , task ) ; 
result = sw . toString ( ) ; 
task = new GetDataTask ( runner , filename , null ) ; 
stopButton . startProgressMonitorTask ( task ) ; 
} public Optional < List < CoverageCoordAxis > > subset ( SubsetParams params , AtomicBoolean isConstantForcast , boolean makeCFcompliant ) { 
List < CoverageCoordAxis > result = new ArrayList < > ( ) ; 
Optional < CoverageCoordAxis > axiso = runAxis . subset ( params ) ; 
if ( ! axiso . isPresent ( ) ) 
return Optional . empty ( axiso . getErrorMessage ( ) ) ; 
CoverageCoordAxis1D runAxisSubset = ( CoverageCoordAxis1D ) axiso . get ( ) ; 
result . add ( runAxisSubset ) ; 
if ( params . hasTimeOffsetParam ( ) || ! params . hasTimeParam ( ) ) { 
axiso = timeOffset . subset ( params ) ; 
CoverageCoordAxis timeOffsetSubset = axiso . get ( ) ; 
result . add ( timeOffsetSubset ) ; 
if ( makeCFcompliant ) 
result . add ( makeCFTimeCoord ( runAxisSubset , ( CoverageCoordAxis1D ) timeOffsetSubset ) ) ; 
return Optional . of ( result ) ; 
if ( runAxisSubset . getNcoords ( ) == 1 ) { 
double val = runAxisSubset . getCoordMidpoint ( 0 ) ; 
CalendarDate runDate = runAxisSubset . makeDate ( val ) ; 
Optional < TimeOffsetAxis > too = timeOffset . subsetFromTime ( params , runDate ) ; 
if ( ! too . isPresent ( ) ) 
return Optional . empty ( too . getErrorMessage ( ) ) ; 
TimeOffsetAxis timeOffsetSubset = too . get ( ) ; 
result . add ( makeCFTimeCoord ( runAxisSubset , timeOffsetSubset ) ) ; 
isConstantForcast . set ( true ) ; 
CalendarDate dateWanted ; 
if ( params . isTrue ( SubsetParams . timePresent ) ) 
dateWanted = CalendarDate . present ( ) ; 
dateWanted = ( CalendarDate ) params . get ( SubsetParams . time ) ; 
if ( dateWanted == null ) 
double wantOffset = runAxisSubset . convert ( dateWanted ) ; 
double start = timeOffset . getStartValue ( ) ; 
double end = timeOffset . getEndValue ( ) ; 
CoordAxisHelper helper = new CoordAxisHelper ( timeOffset ) ; 
List < Integer > runtimeIdx = new ArrayList < > ( ) ; 
List < Double > offset = new ArrayList < > ( ) ; 
for ( int i = 0 ; i < runAxisSubset . getNcoords ( ) ; i ++ ) { 
double runOffset = runAxisSubset . getCoordMidpoint ( i ) ; 
if ( end + runOffset < wantOffset ) continue ; 
if ( wantOffset < start + runOffset ) break ; 
int idx = helper . search ( wantOffset - runOffset ) ; 
if ( idx >= 0 ) { 
runtimeIdx . add ( i ) ; 
offset . add ( wantOffset - runOffset ) ; 
int ncoords = runtimeIdx . size ( ) ; 
double [ ] runValues = new double [ ncoords ] ; 
double [ ] offsetValues = new double [ ncoords ] ; 
for ( int k = 0 ; k < ncoords ; k ++ ) { 
offsetValues [ count ] = offset . get ( k ) ; 
runValues [ count ++ ] = runAxisSubset . getCoordMidpoint ( runtimeIdx . get ( k ) ) ; 
CoverageCoordAxisBuilder runbuilder = new CoverageCoordAxisBuilder ( runAxisSubset ) 
. subset ( null , CoverageCoordAxis . Spacing . irregularPoint , ncoords , runValues ) ; 
CoverageCoordAxis1D runAxisSubset2 = new CoverageCoordAxis1D ( runbuilder ) ; 
CoverageCoordAxisBuilder timebuilder = new CoverageCoordAxisBuilder ( timeOffset ) 
. subset ( runAxisSubset2 . getName ( ) , CoverageCoordAxis . Spacing . irregularPoint , ncoords , offsetValues ) ; 
CoverageCoordAxis1D timeOffsetSubset = new TimeOffsetAxis ( timebuilder ) ; 
CoverageCoordAxis scalarTimeCoord = makeScalarTimeCoord ( wantOffset , runAxisSubset ) ; 
return Optional . of ( Lists . newArrayList ( runAxisSubset2 , timeOffsetSubset , scalarTimeCoord ) ) ; 
} public void toASCII ( PrintWriter pw , 
boolean addName , 
String rootName , 
boolean newLine ) { 
if ( addName ) 
pw . print ( ( new Float ( getValue ( ) ) ) . toString ( ) ) ; 
if ( newLine ) 
pw . print ( "\n" ) ; 
} static public void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) 
debugCE = debugFlag . isSet ( "DODS/constraintExpression" ) ; 
debugServerCall = debugFlag . isSet ( "DODS/serverCall" ) ; 
debugOpenResult = debugFlag . isSet ( "DODS/debugOpenResult" ) ; 
debugDataResult = debugFlag . isSet ( "DODS/debugDataResult" ) ; 
debugCharArray = debugFlag . isSet ( "DODS/charArray" ) ; 
debugConstruct = debugFlag . isSet ( "DODS/constructNetcdf" ) ; 
debugPreload = debugFlag . isSet ( "DODS/preload" ) ; 
debugTime = debugFlag . isSet ( "DODS/timeCalls" ) ; 
showNCfile = debugFlag . isSet ( "DODS/showNCfile" ) ; 
debugAttributes = debugFlag . isSet ( "DODS/attributes" ) ; 
debugCached = debugFlag . isSet ( "DODS/cache" ) ; 
} public static String canonicalURL ( String urlName ) 
if ( urlName . startsWith ( "http:" ) ) 
return "dods:" + urlName . substring ( 5 ) ; 
if ( urlName . startsWith ( "https:" ) ) 
return "dods:" + urlName . substring ( 6 ) ; 
return urlName ; 
} private void parseGlobalAttributes ( DAS das , DodsV root , DODSNetcdfFile dodsfile ) { 
List < DODSAttribute > atts = root . attributes ; 
for ( ucar . nc2 . Attribute ncatt : atts ) { 
rootGroup . addAttribute ( ncatt ) ; 
Enumeration tableNames = das . getNames ( ) ; 
while ( tableNames . hasMoreElements ( ) ) { 
String tableName = ( String ) tableNames . nextElement ( ) ; 
AttributeTable attTable = das . getAttributeTableN ( tableName ) ; 
if ( attTable == null ) 
if ( tableName . equals ( "DODS_EXTRA" ) ) { 
Enumeration attNames = attTable . getNames ( ) ; 
while ( attNames . hasMoreElements ( ) ) { 
String attName = ( String ) attNames . nextElement ( ) ; 
if ( attName . equals ( "Unlimited_Dimension" ) ) { 
opendap . dap . Attribute att = attTable . getAttribute ( attName ) ; 
DODSAttribute ncatt = new DODSAttribute ( attName , att ) ; 
setUnlimited ( ncatt . getStringValue ( ) ) ; 
} else if ( tableName . equals ( "EXTRA_DIMENSION" ) ) { 
int length = ncatt . getNumericValue ( ) . intValue ( ) ; 
Dimension extraDim = new Dimension ( attName , length ) ; 
addDimension ( null , extraDim ) ; 
} protected void reGroup ( ) 
throws DAP2Exception 
assert ( RC . getUseGroups ( ) ) ; 
Group rootgroup = this . getRootGroup ( ) ; 
Object [ ] gattlist = rootgroup . getAttributes ( ) . toArray ( ) ; 
for ( Object att : gattlist ) { 
Attribute ncatt = ( Attribute ) att ; 
String dodsname = ncatt . getDODSName ( ) ; 
NamePieces pieces = parseName ( dodsname ) ; 
if ( pieces . var != null ) { 
String searchname = pieces . var ; 
if ( pieces . prefix != null ) searchname = pieces . prefix + '/' + searchname ; 
Variable v = findVariable ( searchname ) ; 
rootgroup . remove ( ncatt ) ; 
v . addAttribute ( ncatt ) ; 
String newname = pieces . name ; 
ncatt . setName ( newname ) ; 
} else if ( pieces . prefix != null ) { 
Group g = rootgroup . makeRelativeGroup ( this , dodsname , true ) ; 
g . addAttribute ( ncatt ) ; 
if ( OLDGROUPCODE ) { 
ncatt . setName ( pieces . name ) ; 
Object [ ] varlist = rootgroup . getVariables ( ) . toArray ( ) ; 
for ( Object var : varlist ) { 
if ( var instanceof DODSVariable ) { 
DODSVariable v = ( DODSVariable ) var ; 
reGroupVariable ( rootgroup , v ) ; 
+ var . getClass ( ) . getCanonicalName ( ) ) ; 
reGroupVariableAttributes ( rootgroup , ( Variable ) var ) ; 
} NamePieces parseName ( String name ) { 
NamePieces pieces = new NamePieces ( ) ; 
int dotpos = name . lastIndexOf ( '.' ) ; 
int slashpos = name . lastIndexOf ( '/' ) ; 
if ( slashpos < 0 && dotpos < 0 ) { 
pieces . name = name ; 
} else if ( slashpos >= 0 && dotpos < 0 ) { 
pieces . prefix = name . substring ( 0 , slashpos ) ; 
pieces . name = name . substring ( slashpos + 1 , name . length ( ) ) ; 
} else if ( slashpos < 0 && dotpos >= 0 ) { 
pieces . var = name . substring ( 0 , dotpos ) ; 
pieces . name = name . substring ( dotpos + 1 , name . length ( ) ) ; 
if ( slashpos > dotpos ) { 
pieces . var = name . substring ( slashpos + 1 , dotpos ) ; 
if ( pieces . prefix != null && pieces . prefix . length ( ) == 0 ) pieces . prefix = null ; 
if ( pieces . var != null && pieces . var . length ( ) == 0 ) pieces . var = null ; 
if ( pieces . name . length ( ) == 0 ) pieces . name = null ; 
return pieces ; 
} private void constructTopVariables ( DodsV rootDodsV , CancelTask cancelTask ) throws IOException { 
List < DodsV > topVariables = rootDodsV . children ; 
for ( DodsV dodsV : topVariables ) { 
if ( dodsV . bt instanceof DConstructor ) continue ; 
addVariable ( rootGroup , null , dodsV ) ; 
if ( cancelTask != null && cancelTask . isCancel ( ) ) return ; 
} Variable addVariable ( Group parentGroup , Structure parentStructure , DodsV dodsV ) throws IOException { 
Variable v = makeVariable ( parentGroup , parentStructure , dodsV ) ; 
addAttributes ( v , dodsV ) ; 
if ( parentStructure != null ) 
parentStructure . addMemberVariable ( v ) ; 
parentGroup = computeGroup ( v . getDODSName ( ) , v , parentGroup ) ; 
parentGroup . addVariable ( v ) ; 
dodsV . isDone = true ; 
} private boolean isGroup ( DStructure dstruct ) { 
BaseType parent = ( BaseType ) dstruct . getParent ( ) ; 
if ( parent == null ) return true ; 
if ( parent instanceof DStructure ) 
return isGroup ( ( DStructure ) parent ) ; 
} private void addAttributes ( Variable v , DodsV dodsV ) { 
List < DODSAttribute > atts = dodsV . attributes ; 
for ( Attribute ncatt : atts ) { 
Attribute axes = v . findAttribute ( CF . COORDINATES ) ; 
Attribute _axes = v . findAttribute ( _Coordinate . Axes ) ; 
if ( ( null != axes ) && ( null != _axes ) ) { 
v . addAttribute ( combineAxesAttrs ( axes , _axes ) ) ; 
} Dimension getNetcdfStrlenDim ( DODSVariable v ) { 
AttributeTable table = das . getAttributeTableN ( v . getFullName ( ) ) ; 
if ( table == null ) return null ; 
opendap . dap . Attribute dodsAtt = table . getAttribute ( "DODS" ) ; 
if ( dodsAtt == null ) return null ; 
AttributeTable dodsTable = dodsAtt . getContainerN ( ) ; 
if ( dodsTable == null ) return null ; 
opendap . dap . Attribute att = dodsTable . getAttribute ( "strlen" ) ; 
if ( att == null ) return null ; 
String strlen = att . getValueAtN ( 0 ) ; 
opendap . dap . Attribute att2 = dodsTable . getAttribute ( "dimName" ) ; 
String dimName = ( att2 == null ) ? null : att2 . getValueAtN ( 0 ) ; 
int dimLength ; 
dimLength = Integer . parseInt ( strlen ) ; 
if ( dimLength <= 0 ) return null ; 
return new Dimension ( dimName , dimLength , dimName != null ) ; 
} Dimension getSharedDimension ( Group group , Dimension d ) { 
if ( d . getShortName ( ) == null ) return d ; 
if ( group == null ) group = rootGroup ; 
for ( Dimension sd : group . getDimensions ( ) ) { 
if ( sd . getShortName ( ) . equals ( d . getShortName ( ) ) && sd . getLength ( ) == d . getLength ( ) ) 
return sd ; 
d . setShared ( true ) ; 
group . addDimension ( d ) ; 
} List < Dimension > constructDimensions ( Group group , opendap . dap . DArray dodsArray ) { 
List < Dimension > dims = new ArrayList < Dimension > ( ) ; 
Enumeration enumerate = dodsArray . getDimensions ( ) ; 
while ( enumerate . hasMoreElements ( ) ) { 
opendap . dap . DArrayDimension dad = ( opendap . dap . DArrayDimension ) enumerate . nextElement ( ) ; 
String name = dad . getEncodedName ( ) ; 
if ( name != null ) 
name = StringUtil2 . unescape ( name ) ; 
Dimension myd ; 
myd = new Dimension ( null , dad . getSize ( ) , false ) ; 
if ( RC . getUseGroups ( ) ) { 
if ( name . indexOf ( '/' ) >= 0 ) { 
group = group . makeRelativeGroup ( this , name , true ) ; 
name = name . substring ( name . lastIndexOf ( '/' ) + 1 ) ; 
myd = group . findDimension ( name ) ; 
if ( myd == null ) { 
myd = new Dimension ( name , dad . getSize ( ) ) ; 
group . addDimension ( myd ) ; 
} else if ( myd . getLength ( ) != dad . getSize ( ) ) { 
myd = new Dimension ( name , dad . getSize ( ) , false ) ; 
dims . add ( myd ) ; 
return dims ; 
} private String makeDODSname ( DodsV dodsV ) { 
DodsV parent = dodsV . parent ; 
if ( parent . bt != null ) 
return ( makeDODSname ( parent ) + "." + dodsV . bt . getEncodedName ( ) ) ; 
return dodsV . bt . getEncodedName ( ) ; 
} static public int convertToDODSType ( DataType dataType ) 
if ( dataType == DataType . STRING ) 
return opendap . dap . Attribute . STRING ; 
if ( dataType == DataType . BYTE ) 
return opendap . dap . Attribute . BYTE ; 
if ( dataType == DataType . FLOAT ) 
return opendap . dap . Attribute . FLOAT32 ; 
if ( dataType == DataType . DOUBLE ) 
return opendap . dap . Attribute . FLOAT64 ; 
if ( dataType == DataType . SHORT ) 
return opendap . dap . Attribute . INT16 ; 
if ( dataType == DataType . USHORT ) 
return opendap . dap . Attribute . UINT16 ; 
if ( dataType == DataType . INT ) 
return opendap . dap . Attribute . INT32 ; 
if ( dataType == DataType . UINT ) 
return opendap . dap . Attribute . UINT32 ; 
if ( dataType == DataType . BOOLEAN ) 
if ( dataType == DataType . LONG ) 
} static public DataType convertToNCType ( int dodsDataType , boolean isUnsigned ) 
switch ( dodsDataType ) { 
case opendap . dap . Attribute . BYTE : 
return isUnsigned ? DataType . UBYTE : DataType . BYTE ; 
case opendap . dap . Attribute . FLOAT32 : 
return DataType . FLOAT ; 
case opendap . dap . Attribute . FLOAT64 : 
return DataType . DOUBLE ; 
case opendap . dap . Attribute . INT16 : 
return DataType . SHORT ; 
case opendap . dap . Attribute . UINT16 : 
return DataType . USHORT ; 
case opendap . dap . Attribute . INT32 : 
return DataType . INT ; 
case opendap . dap . Attribute . UINT32 : 
return DataType . UINT ; 
return DataType . STRING ; 
} static public DataType convertToNCType ( opendap . dap . BaseType dtype , boolean isUnsigned ) 
if ( dtype instanceof DString ) 
else if ( ( dtype instanceof DStructure ) || ( dtype instanceof DSequence ) || ( dtype instanceof DGrid ) ) 
return DataType . STRUCTURE ; 
else if ( dtype instanceof DFloat32 ) 
else if ( dtype instanceof DFloat64 ) 
else if ( dtype instanceof DUInt32 ) 
else if ( dtype instanceof DUInt16 ) 
else if ( dtype instanceof DInt32 ) 
else if ( dtype instanceof DInt16 ) 
else if ( dtype instanceof DByte ) 
} static public boolean isUnsigned ( opendap . dap . BaseType dtype ) 
return ( dtype instanceof DByte ) || 
( dtype instanceof DUInt16 ) || 
( dtype instanceof DUInt32 ) ; 
} DataDDS readDataDDSfromServer ( String CE ) throws IOException , opendap . dap . DAP2Exception 
long start = 0 ; 
if ( debugTime ) start = System . currentTimeMillis ( ) ; 
if ( ! CE . startsWith ( "?" ) ) 
CE = "?" + CE ; 
DataDDS data ; 
data = dodsConnection . getData ( CE , null ) ; 
if ( debugTime ) 
if ( debugDataResult ) { 
data . print ( System . out ) ; 
public List < Array > readArrays ( List < Variable > preloadVariables ) throws IOException 
if ( preloadVariables . size ( ) == 0 ) return new ArrayList < Array > ( ) ; 
List < DodsV > reqDodsVlist = new ArrayList < DodsV > ( ) ; 
DodsV root ; 
for ( Variable var : preloadVariables ) { 
if ( var . hasCachedData ( ) ) continue ; 
reqDodsVlist . add ( ( DodsV ) var . getSPobject ( ) ) ; 
Collections . sort ( reqDodsVlist ) ; 
DataDDS dataDDS ; 
Map < DodsV , DodsV > map = new HashMap < DodsV , DodsV > ( 2 * reqDodsVlist . size ( ) + 1 ) ; 
if ( reqDodsVlist . size ( ) > 0 ) { 
StringBuilder requestString = new StringBuilder ( ) ; 
for ( int i = 0 ; i < reqDodsVlist . size ( ) ; i ++ ) { 
DodsV dodsV = reqDodsVlist . get ( i ) ; 
requestString . append ( i == 0 ? "?" : "," ) ; 
requestString . append ( dodsV . getEncodedName ( ) ) ; 
String s = requestString . toString ( ) ; 
dataDDS = readDataDDSfromServer ( requestString . toString ( ) ) ; 
root = DodsV . parseDataDDS ( dataDDS ) ; 
} catch ( Exception exc ) { 
throw new IOException ( exc . getMessage ( ) ) ; 
for ( DodsV ddsV : reqDodsVlist ) { 
DodsV dataV = root . findDataV ( ddsV ) ; 
if ( dataV != null ) { 
dataV . isDone = true ; 
map . put ( ddsV , dataV ) ; 
if ( var . hasCachedData ( ) ) { 
result . add ( var . read ( ) ) ; 
Array data = null ; 
DodsV ddsV = ( DodsV ) var . getSPobject ( ) ; 
DodsV dataV = map . get ( ddsV ) ; 
if ( dataV == null ) { 
if ( var . isMemberOfStructure ( ) ) { 
while ( ( dataV . parent != null ) && ( dataV . parent . bt != null ) ) { 
dataV = dataV . parent ; 
data = convertD2N . convertNestedVariable ( var , null , dataV , true ) ; 
data = convertD2N . convertTopVariable ( var , null , dataV ) ; 
} catch ( DAP2Exception de ) { 
throw new IOException ( de . getMessage ( ) ) ; 
if ( var . isCaching ( ) ) { 
var . setCachedData ( data ) ; 
if ( debugCached ) 
result . add ( data ) ; 
} public Array readWithCE ( ucar . nc2 . Variable v , String CE ) throws IOException 
Array dataArray ; 
DataDDS dataDDS = readDataDDSfromServer ( CE ) ; 
DodsV root = DodsV . parseDataDDS ( dataDDS ) ; 
DodsV want = root . children . get ( 0 ) ; 
if ( v . isMemberOfStructure ( ) ) 
dataArray = convertD2N . convertNestedVariable ( v , null , want , true ) ; 
dataArray = convertD2N . convertTopVariable ( v , null , want ) ; 
} catch ( DAP2Exception ex ) { 
throw new IOException ( ex . getMessage ( ) ) ; 
} catch ( ParseException ex ) { 
} public void getDetailInfo ( Formatter f ) 
super . getDetailInfo ( f ) ; 
ByteArrayOutputStream buffOS = new ByteArrayOutputStream ( 8000 ) ; 
dds . print ( buffOS ) ; 
f . format ( "%s%n" , new String ( buffOS . toByteArray ( ) , Util . UTF8 ) ) ; 
buffOS = new ByteArrayOutputStream ( 8000 ) ; 
das . print ( buffOS ) ; 
} public static ImageIcon getIcon ( String fullIconName , boolean errMsg ) { 
ImageIcon icon = null ; 
java . net . URL iconR = cl . getResource ( fullIconName ) ; 
if ( debugIcon ) { 
if ( iconR != null ) 
icon = new ImageIcon ( iconR ) ; 
return icon ; 
} public static Image getImage ( String fullImageName ) { 
Image image = null ; 
java . net . URL url = cl . getResource ( fullImageName ) ; 
if ( url != null ) 
image = Toolkit . getDefaultToolkit ( ) . createImage ( url ) ; 
} public static Cursor makeCursor ( String name ) { 
Image image = getImage ( name ) ; 
if ( null == image ) 
Cursor cursor ; 
Toolkit tk = Toolkit . getDefaultToolkit ( ) ; 
ImageObserver obs = new ImageObserver ( ) { 
public boolean imageUpdate ( Image image , int flags , int x , int y , int width , int height ) { 
cursor = tk . createCustomCursor ( image , new Point ( 17 , 17 ) , name ) ; 
} catch ( IndexOutOfBoundsException e ) { 
} public static InputStream getFileResource ( String resourcePath ) { 
InputStream is = cl . getResourceAsStream ( resourcePath ) ; 
if ( is != null ) { 
return is ; 
} else if ( debug ) 
is = new FileInputStream ( resourcePath ) ; 
} catch ( FileNotFoundException e ) { 
} catch ( java . security . AccessControlException e ) { 
try ( InputStream is = getFileResource ( "/ucar.unidata.util/Resource.java" ) ) { } 
try ( InputStream is = getFileResource ( "Resource.java" ) ) { } 
try ( InputStream is = getFileResource ( "test/test/Resource.java" ) ) { } 
} static public Object readDataFill ( RandomAccessFile raf , Layout index , DataType dataType , Object fillValue , 
int byteOrder ) throws java . io . IOException { 
Object arr = ( fillValue == null ) ? makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType ) : 
makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType , fillValue ) ; 
return readData ( raf , index , dataType , arr , byteOrder , true ) ; 
} static public Object readData ( RandomAccessFile raf , Layout layout , DataType dataType , Object arr , int byteOrder , boolean convertChar ) throws java . io . IOException { 
if ( dataType . getPrimitiveClassType ( ) == byte . class || dataType == DataType . CHAR ) { 
byte [ ] pa = ( byte [ ] ) arr ; 
raf . order ( byteOrder ) ; 
raf . readFully ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
if ( convertChar && dataType == DataType . CHAR ) return convertByteToChar ( pa ) ; 
else return pa ; 
} else if ( dataType . getPrimitiveClassType ( ) == short . class ) { 
short [ ] pa = ( short [ ] ) arr ; 
raf . readShort ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
return pa ; 
} else if ( dataType . getPrimitiveClassType ( ) == int . class ) { 
int [ ] pa = ( int [ ] ) arr ; 
raf . readInt ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
} else if ( dataType == DataType . FLOAT ) { 
float [ ] pa = ( float [ ] ) arr ; 
raf . readFloat ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
} else if ( dataType == DataType . DOUBLE ) { 
double [ ] pa = ( double [ ] ) arr ; 
raf . readDouble ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
} else if ( dataType . getPrimitiveClassType ( ) == long . class ) { 
long [ ] pa = ( long [ ] ) arr ; 
raf . readLong ( pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
raf . readFully ( pa , ( int ) chunk . getDestElem ( ) * recsize , chunk . getNelems ( ) * recsize ) ; 
} static public Object readDataFill ( PositioningDataInputStream is , Layout index , DataType dataType , Object fillValue ) throws java . io . IOException { 
return readData ( is , index , dataType , arr ) ; 
} static public Object readData ( PositioningDataInputStream raf , Layout index , DataType dataType , Object arr ) throws java . io . IOException { 
raf . read ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
if ( dataType == DataType . CHAR ) return convertByteToChar ( pa ) ; 
raf . readShort ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
raf . readInt ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
raf . readFloat ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
raf . readDouble ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
raf . readLong ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; 
int recsize = index . getElemSize ( ) ; 
raf . read ( chunk . getSrcPos ( ) , pa , ( int ) chunk . getDestElem ( ) * recsize , chunk . getNelems ( ) * recsize ) ; 
} static public Object readDataFill ( LayoutBB layout , DataType dataType , Object fillValue ) throws java . io . IOException { 
long size = layout . getTotalNelems ( ) ; 
if ( dataType == DataType . STRUCTURE ) size *= layout . getElemSize ( ) ; 
Object arr = ( fillValue == null ) ? makePrimitiveArray ( ( int ) size , dataType ) : 
makePrimitiveArray ( ( int ) size , dataType , fillValue ) ; 
return readData ( layout , dataType , arr ) ; 
} static public Object readData ( LayoutBB layout , DataType dataType , Object arr ) throws java . io . IOException { 
if ( dataType . getPrimitiveClassType ( ) == byte . class || ( dataType == DataType . CHAR ) ) { 
LayoutBB . Chunk chunk = layout . next ( ) ; 
ByteBuffer bb = chunk . getByteBuffer ( ) ; 
bb . position ( chunk . getSrcElem ( ) ) ; 
int pos = ( int ) chunk . getDestElem ( ) ; 
for ( int i = 0 ; i < chunk . getNelems ( ) ; i ++ ) 
pa [ pos ++ ] = bb . get ( ) ; 
ShortBuffer buff = chunk . getShortBuffer ( ) ; 
buff . position ( chunk . getSrcElem ( ) ) ; 
pa [ pos ++ ] = buff . get ( ) ; 
IntBuffer buff = chunk . getIntBuffer ( ) ; 
FloatBuffer buff = chunk . getFloatBuffer ( ) ; 
DoubleBuffer buff = chunk . getDoubleBuffer ( ) ; 
LongBuffer buff = chunk . getLongBuffer ( ) ; 
bb . position ( chunk . getSrcElem ( ) * recsize ) ; 
int pos = ( int ) chunk . getDestElem ( ) * recsize ; 
for ( int i = 0 ; i < chunk . getNelems ( ) * recsize ; i ++ ) 
} public static long copyToByteChannel ( Array data , WritableByteChannel channel ) throws java . io . IOException { 
Class classType = data . getElementType ( ) ; 
DataOutputStream outStream = new DataOutputStream ( Channels . newOutputStream ( channel ) ) ; 
IndexIterator iterA = data . getIndexIterator ( ) ; 
if ( classType == double . class ) { 
while ( iterA . hasNext ( ) ) 
outStream . writeDouble ( iterA . getDoubleNext ( ) ) ; 
} else if ( classType == float . class ) { 
outStream . writeFloat ( iterA . getFloatNext ( ) ) ; 
} else if ( classType == long . class ) { 
outStream . writeLong ( iterA . getLongNext ( ) ) ; 
} else if ( classType == int . class ) { 
outStream . writeInt ( iterA . getIntNext ( ) ) ; 
} else if ( classType == short . class ) { 
outStream . writeShort ( iterA . getShortNext ( ) ) ; 
} else if ( classType == char . class ) { 
byte [ ] pa = convertCharToByte ( ( char [ ] ) data . get1DJavaArray ( DataType . CHAR ) ) ; 
outStream . write ( pa , 0 , pa . length ) ; 
} else if ( classType == byte . class ) { 
outStream . writeByte ( iterA . getByteNext ( ) ) ; 
} else if ( classType == boolean . class ) { 
outStream . writeBoolean ( iterA . getBooleanNext ( ) ) ; 
} else if ( classType == String . class ) { 
long size = 0 ; 
while ( iterA . hasNext ( ) ) { 
String s = ( String ) iterA . getObjectNext ( ) ; 
size += NcStream . writeVInt ( outStream , s . length ( ) ) ; 
byte [ ] b = s . getBytes ( CDM . utf8Charset ) ; 
outStream . write ( b ) ; 
size += b . length ; 
} else if ( classType == ByteBuffer . class ) { 
ByteBuffer bb = ( ByteBuffer ) iterA . getObjectNext ( ) ; 
size += NcStream . writeVInt ( outStream , bb . limit ( ) ) ; 
bb . rewind ( ) ; 
channel . write ( bb ) ; 
size += bb . limit ( ) ; 
Array row = ( Array ) iterA . getObjectNext ( ) ; 
ByteBuffer bb = row . getDataAsByteBuffer ( ) ; 
byte [ ] result = bb . array ( ) ; 
size += NcStream . writeVInt ( outStream , result . length ) ; 
outStream . write ( result ) ; 
size += result . length ; 
return data . getSizeBytes ( ) ; 
} static public Object makePrimitiveArray ( int size , DataType dataType ) { 
Object arr = null ; 
if ( ( dataType . getPrimitiveClassType ( ) == byte . class ) || ( dataType == DataType . CHAR ) || ( dataType == DataType . OPAQUE ) || ( dataType == DataType . STRUCTURE ) ) { 
arr = new byte [ size ] ; 
arr = new short [ size ] ; 
arr = new int [ size ] ; 
arr = new long [ size ] ; 
arr = new float [ size ] ; 
arr = new double [ size ] ; 
arr = new String [ size ] ; 
return arr ; 
} static public Object makePrimitiveArray ( int size , DataType dataType , Object fillValue ) { 
byte [ ] pa = new byte [ size ] ; 
byte val = ( ( Number ) fillValue ) . byteValue ( ) ; 
if ( val != 0 ) 
for ( int i = 0 ; i < size ; i ++ ) pa [ i ] = val ; 
return new byte [ size ] ; 
short [ ] pa = new short [ size ] ; 
short val = ( ( Number ) fillValue ) . shortValue ( ) ; 
int [ ] pa = new int [ size ] ; 
int val = ( ( Number ) fillValue ) . intValue ( ) ; 
long [ ] pa = new long [ size ] ; 
long val = ( ( Number ) fillValue ) . longValue ( ) ; 
float [ ] pa = new float [ size ] ; 
float val = ( ( Number ) fillValue ) . floatValue ( ) ; 
if ( val != 0.0 ) 
double [ ] pa = new double [ size ] ; 
double val = ( ( Number ) fillValue ) . doubleValue ( ) ; 
String [ ] pa = new String [ size ] ; 
for ( int i = 0 ; i < size ; i ++ ) pa [ i ] = ( String ) fillValue ; 
if ( fillValue != null ) { 
byte [ ] val = ( byte [ ] ) fillValue ; 
while ( count < size ) 
for ( byte aVal : val ) pa [ count ++ ] = aVal ; 
} static public char [ ] convertByteToCharUTF ( byte [ ] byteArray ) { 
Charset c = CDM . utf8Charset ; 
CharBuffer output = c . decode ( ByteBuffer . wrap ( byteArray ) ) ; 
return output . array ( ) ; 
} static public byte [ ] convertCharToByteUTF ( char [ ] from ) { 
ByteBuffer output = c . encode ( CharBuffer . wrap ( from ) ) ; 
} static public char [ ] convertByteToChar ( byte [ ] byteArray ) { 
int size = byteArray . length ; 
char [ ] cbuff = new char [ size ] ; 
cbuff [ i ] = ( char ) DataType . unsignedByteToShort ( byteArray [ i ] ) ; 
return cbuff ; 
static public byte [ ] convertCharToByte ( char [ ] from ) { 
byte [ ] to = null ; 
int size = from . length ; 
to = new byte [ size ] ; 
to [ i ] = ( byte ) from [ i ] ; 
} static public ucar . ma2 . Array readSection ( ParsedSectionSpec cer ) throws IOException , InvalidRangeException { 
Variable inner = null ; 
List < Range > totalRanges = new ArrayList < > ( ) ; 
ParsedSectionSpec current = cer ; 
totalRanges . addAll ( current . section . getRanges ( ) ) ; 
inner = current . v ; 
current = current . child ; 
assert inner != null ; 
Section total = new Section ( totalRanges ) ; 
Array result = Array . factory ( inner . getDataType ( ) , total . getShape ( ) ) ; 
Structure outer = ( Structure ) cer . v ; 
Structure outerSubset = outer . select ( cer . child . v . getShortName ( ) ) ; 
ArrayStructure outerData = ( ArrayStructure ) outerSubset . read ( cer . section ) ; 
extractSection ( cer . child , outerData , result . getIndexIterator ( ) ) ; 
} static private ArrayStructure sectionArrayStructure ( ParsedSectionSpec child , ArrayStructure innerData , StructureMembers . Member m ) throws IOException , InvalidRangeException { 
StructureMembers membersw = new StructureMembers ( m . getStructureMembers ( ) ) ; 
ArrayStructureW result = new ArrayStructureW ( membersw , child . section . getShape ( ) ) ; 
Section . Iterator iter = child . section . getIterator ( child . v . getShape ( ) ) ; 
int recno = iter . next ( null ) ; 
StructureData sd = innerData . getStructureData ( recno ) ; 
result . setStructureData ( sd , count ++ ) ; 
add ( long recno , int fieldno , Array field ) 
FieldArrays fs = records [ ( int ) recno ] ; 
if ( fs == null ) 
records [ ( int ) recno ] = ( fs = new FieldArrays ( this . nmembers ) ) ; 
fs . fields [ fieldno ] = field ; 
public StructureData 
getStructureData ( int index ) 
assert ( super . sdata != null ) ; 
if ( index < 0 || index >= this . dimsize ) 
assert ( super . sdata [ index ] != null ) ; 
return super . sdata [ index ] ; 
} public String getScalarString ( int recnum , StructureMembers . Member m ) 
Array data = m . getDataArray ( ) ; 
return ( String ) data . getObject ( recnum ) . toString ( ) ; 
} public StructureData 
getScalarStructure ( int index , StructureMembers . Member m ) 
if ( m . getDataType ( ) != DataType . STRUCTURE ) 
Array ca = memberArray ( index , memberIndex ( m ) ) ; 
if ( ca . getDataType ( ) != DataType . STRUCTURE && ca . getDataType ( ) != DataType . SEQUENCE ) 
CDMArrayStructure as = ( CDMArrayStructure ) ca ; 
return as . getStructureData ( 0 ) ; 
public ucar . ma2 . Array 
getArray ( int recno , StructureMembers . Member m ) 
return ( ucar . ma2 . Array ) memberArray ( recno , memberIndex ( m ) ) ; 
protected StructureData 
makeStructureData ( ArrayStructure as , int index ) 
if ( super . sdata [ index ] == null ) 
super . sdata [ index ] = new StructureDataA ( as , index ) ; 
} static StructureMembers 
computemembers ( DapVariable var ) 
DapStructure ds = ( DapStructure ) var . getBaseType ( ) ; 
StructureMembers sm 
= new StructureMembers ( ds . getShortName ( ) ) ; 
List < DapVariable > fields = ds . getFields ( ) ; 
for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { 
DapVariable field = fields . get ( i ) ; 
DapType dt = field . getBaseType ( ) ; 
DataType cdmtype = CDMTypeFcns . daptype2cdmtype ( dt ) ; 
StructureMembers . Member m = 
sm . addMember ( 
field . getShortName ( ) , "" , null , 
cdmtype , 
CDMUtil . computeEffectiveShape ( field . getDimensions ( ) ) ) ; 
m . setDataParam ( i ) ; 
if ( dt . getTypeSort ( ) . isStructType ( ) ) { 
StructureMembers subsm = computemembers ( field ) ; 
m . setStructureMembers ( subsm ) ; 
return sm ; 
long tempVal = ( ( long ) getValue ( ) ) & 0xFFFFFFFFL ; 
os . print ( tempVal ) ; 
} public void addDimensionsToNetcdfFile ( NetcdfFile ncfile , Group g ) { 
ncfile . addDimension ( g , new Dimension ( getName ( ) , getNEnsembles ( ) , true ) ) ; 
public void windowClosing ( WindowEvent e ) { System . exit ( 0 ) ; } 
PrefPanel . Dialog d = new PrefPanel . Dialog ( frame , false , "title" , null , null ) ; 
PrefPanel pp = d . getPrefPanel ( ) ; 
final Field . Text tf = pp . addTextField ( "text" , "text" , "defValue" ) ; 
pp . setCursor ( 1 , 0 ) ; 
pp . addTextField ( "text2" , "text2" , "text2" ) ; 
d . finish ( ) ; 
d . show ( ) ; 
JPanel main = new JPanel ( new FlowLayout ( ) ) ; 
frame . getContentPane ( ) . add ( main ) ; 
main . setPreferredSize ( new Dimension ( 200 , 200 ) ) ; 
frame . setLocation ( 300 , 300 ) ; 
pp . addActionListener ( e -> { 
String text = tf . getText ( ) ; 
tf . setText ( text + "1" ) ; 
} public static CrawlableDataset createCrawlableDataset ( String path , String className , Object configObj ) 
ClassNotFoundException , NoSuchMethodException , 
IllegalAccessException , InvocationTargetException , 
InstantiationException , IllegalArgumentException , NullPointerException 
String tmpClassName = ( className == null 
? defaultClassName 
: className ) ; 
Class crDsClass = Class . forName ( tmpClassName ) ; 
if ( ! CrawlableDataset . class . isAssignableFrom ( crDsClass ) ) 
Class [ ] argTypes = { String . class , Object . class } ; 
Object [ ] args = { path , configObj } ; 
Constructor constructor = crDsClass . getDeclaredConstructor ( argTypes ) ; 
return ( CrawlableDataset ) constructor . newInstance ( args ) ; 
if ( IOException . class . isAssignableFrom ( e . getCause ( ) . getClass ( ) ) ) 
throw ( IOException ) e . getCause ( ) ; 
else throw e ; 
} public static String normalizePath ( String path ) 
String newPath = path . replaceAll ( "\\\\" , "/" ) ; 
while ( newPath . endsWith ( "/" ) && ! newPath . equals ( "/" ) ) 
newPath = newPath . substring ( 0 , newPath . length ( ) - 1 ) ; 
return newPath ; 
} public java . awt . geom . Rectangle2D getBounds2D ( ) { 
double x0 = ( ( ( ContourLine ) ( lines . get ( 0 ) ) ) . getX ( ) ) [ 0 ] ; 
double y0 = ( ( ( ContourLine ) ( lines . get ( 0 ) ) ) . getY ( ) ) [ 0 ] ; 
double xMaxInd = x0 , xmin = x0 , yMaxInd = y0 , ymin = y0 ; 
for ( int i = 0 ; i < lines . size ( ) ; i ++ ) { 
GisPart cline = ( ContourLine ) ( lines . get ( i ) ) ; 
double [ ] xpts = cline . getX ( ) ; 
double [ ] ypts = cline . getY ( ) ; 
for ( int j = 0 ; j < cline . getNumPoints ( ) ; j ++ ) { 
if ( xpts [ j ] < xmin ) 
xmin = xpts [ j ] ; 
else if ( xpts [ j ] > xMaxInd ) 
xMaxInd = xpts [ j ] ; 
if ( ypts [ j ] < ymin ) 
ymin = ypts [ j ] ; 
else if ( ypts [ j ] > yMaxInd ) 
yMaxInd = ypts [ j ] ; 
Rectangle2D . Double rect = 
new Rectangle2D . Double ( xmin , ymin , xMaxInd - xmin , yMaxInd - ymin ) ; 
return rect ; 
} static public void setPersistenceCache ( DiskCache2 dc ) { 
diskCache2 = dc ; 
if ( diskCache2 != null ) 
diskCache2 . setAlwaysUseCache ( true ) ; 
} public void addExplicitDataset ( String cacheName , String location , String id , String ncoordS , String coordValueS , String sectionSpec , 
ucar . nc2 . util . cache . FileFactory reader ) { 
Dataset nested = makeDataset ( cacheName , location , id , ncoordS , coordValueS , sectionSpec , null , reader ) ; 
explicitDatasets . add ( nested ) ; 
} public void addDatasetScan ( Element crawlableDatasetElement , String dirName , String suffix , 
String regexpPatternString , String dateFormatMark , Set < NetcdfDataset . Enhance > enhanceMode , String subdirs , String olderThan ) { 
datasetManager . addDirectoryScan ( dirName , suffix , regexpPatternString , subdirs , olderThan , enhanceMode ) ; 
this . dateFormatMark = dateFormatMark ; 
if ( dateFormatMark != null ) { 
isDate = true ; 
if ( type == Type . joinExisting ) type = Type . joinExistingOne ; 
DateExtractor dateExtractor = new DateExtractorFromName ( dateFormatMark , true ) ; 
datasetManager . setDateExtractor ( dateExtractor ) ; 
} public void addCollection ( String spec , String olderThan ) throws IOException { 
datasetManager = MFileCollectionManager . open ( spec , spec , olderThan , new Formatter ( ) ) ; 
} public void finish ( CancelTask cancelTask ) throws IOException { 
datasetManager . scan ( true ) ; 
cacheDirty = true ; 
makeDatasets ( cancelTask ) ; 
buildNetcdfDataset ( cancelTask ) ; 
} protected void makeDatasets ( CancelTask cancelTask ) throws IOException { 
datasets = new ArrayList < > ( ) ; 
for ( MFile cd : datasetManager . getFilesSorted ( ) ) { 
datasets . add ( makeDataset ( cd ) ) ; 
Collections . sort ( datasets ) ; 
for ( Aggregation . Dataset dataset : explicitDatasets ) { 
datasets . add ( dataset ) ; 
for ( Iterator < Dataset > datasetsIter = datasets . iterator ( ) ; datasetsIter . hasNext ( ) ; ) { 
Dataset dataset = datasetsIter . next ( ) ; 
Path datasetPath ; 
if ( dataset . getMFile ( ) instanceof MFileOS ) { 
datasetPath = ( ( MFileOS ) dataset . getMFile ( ) ) . getFile ( ) . toPath ( ) ; 
} else if ( dataset . getMFile ( ) instanceof MFileOS7 ) { 
datasetPath = ( ( MFileOS7 ) dataset . getMFile ( ) ) . getNioPath ( ) ; 
if ( ! Files . isReadable ( datasetPath ) ) { 
datasetsIter . remove ( ) ; 
Set < String > dset = new HashSet < > ( 2 * datasets . size ( ) ) ; 
for ( Aggregation . Dataset dataset : datasets ) { 
if ( dset . contains ( dataset . cacheLocation ) ) 
dset . add ( dataset . cacheLocation ) ; 
if ( datasets . size ( ) == 0 ) { 
} protected Dataset getTypicalDataset ( ) throws IOException { 
List < Dataset > nestedDatasets = getDatasets ( ) ; 
int n = nestedDatasets . size ( ) ; 
if ( n == 0 ) 
int select ; 
if ( typicalDatasetMode == TypicalDataset . LATEST ) 
select = n - 1 ; 
else if ( typicalDatasetMode == TypicalDataset . PENULTIMATE ) 
select = ( n < 2 ) ? 0 : n - 2 ; 
else if ( typicalDatasetMode == TypicalDataset . FIRST ) 
select = 0 ; 
if ( r == null ) r = new Random ( ) ; 
select = ( n < 2 ) ? 0 : r . nextInt ( n ) ; 
return nestedDatasets . get ( select ) ; 
} protected Dataset makeDataset ( String cacheName , String location , String id , String ncoordS , String coordValueS , 
String sectionSpec , EnumSet < NetcdfDataset . Enhance > enhance , ucar . nc2 . util . cache . FileFactory reader ) { 
return new Dataset ( cacheName , location , id , enhance , reader ) ; 
} protected void setDatasetAcquireProxy ( Dataset typicalDataset , NetcdfDataset newds ) throws IOException { 
DatasetProxyReader proxy = new DatasetProxyReader ( typicalDataset ) ; 
setDatasetAcquireProxy ( proxy , newds . getRootGroup ( ) ) ; 
} void putResourceControl ( Dataset ds ) { 
resourceControlHash . put ( ds . getUrlPath ( ) , ds . getRestrictAccess ( ) ) ; 
hasResourceControl = true ; 
} public void addPoint ( double x , double y ) { 
Point ptPrev = null ; 
if ( points . size ( ) > 0 ) { 
ptPrev = points . get ( points . size ( ) - 1 ) ; 
this . points . add ( new CFPoint ( x , y , ptPrev , null , null ) ) ; 
} public void setNext ( Line next ) { 
if ( next instanceof CFLine ) { 
setNext ( ( CFLine ) next ) ; 
else this . next = next ; 
} public void setPrev ( Line prev ) { 
if ( prev instanceof CFLine ) 
setPrev ( ( CFLine ) prev ) ; 
else this . prev = prev ; 
} public Line setupLine ( NetcdfDataset dataset , Variable var , int index ) 
this . points . clear ( ) ; 
Array xPts = null ; 
Array yPts = null ; 
Variable nodeCounts = null ; 
Variable partNodeCounts = null ; 
List < CoordinateAxis > axes = dataset . getCoordinateAxes ( ) ; 
CoordinateAxis x = null ; CoordinateAxis y = null ; 
for ( CoordinateAxis ax : axes ) { 
if ( ax . getFullName ( ) . equals ( nodeCoords [ 0 ] ) ) x = ax ; 
if ( ax . getFullName ( ) . equals ( nodeCoords [ 1 ] ) ) y = ax ; 
String node_c_str = var . findAttValueIgnoreCase ( CF . NODE_COUNT , "" ) ; 
if ( ! node_c_str . equals ( "" ) ) { 
nodeCounts = dataset . findVariable ( node_c_str ) ; 
else return null ; 
String pNodeCoStr = var . findAttValueIgnoreCase ( CF . PART_NODE_COUNT , "" ) ; 
if ( ! pNodeCoStr . equals ( "" ) ) { 
partNodeCounts = dataset . findVariable ( pNodeCoStr ) ; 
SimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder ( nodeCounts ) ; 
int lower = indexFinder . getBeginning ( index ) ; 
int upper = indexFinder . getEnd ( index ) ; 
xPts = x . read ( lower + ":" + upper ) . reduce ( ) ; 
yPts = y . read ( lower + ":" + upper ) . reduce ( ) ; 
IndexIterator itrX = xPts . getIndexIterator ( ) ; 
IndexIterator itrY = yPts . getIndexIterator ( ) ; 
if ( partNodeCounts == null ) { 
this . next = null ; 
this . prev = null ; 
while ( itrX . hasNext ( ) ) { 
this . addPoint ( itrX . getDoubleNext ( ) , itrY . getDoubleNext ( ) ) ; 
switch ( var . getRank ( ) ) { 
this . setData ( var . read ( CFSimpleGeometryHelper . getSubsetString ( var , index ) ) . reduce ( ) ) ; 
this . setData ( var . read ( "" + index ) ) ; 
throw new InvalidDataseriesException ( InvalidDataseriesException . RANK_MISMATCH ) ; 
Line tail = this ; 
Array pnc = partNodeCounts . read ( ) ; 
IndexIterator pncItr = pnc . getIndexIterator ( ) ; 
int pncInd = 0 ; 
int pncEnd = 0 ; 
while ( pncEnd < lower ) 
pncEnd += pncItr . getIntNext ( ) ; 
pncInd ++ ; 
while ( lower < upper ) { 
int smaller = pnc . getInt ( pncInd ) ; 
while ( smaller > 0 ) { 
tail . addPoint ( itrX . getDoubleNext ( ) , itrY . getDoubleNext ( ) ) ; 
smaller -- ; 
tail . setData ( var . read ( CFSimpleGeometryHelper . getSubsetString ( var , index ) ) . reduce ( ) ) ; 
tail . setData ( var . read ( "" + index ) ) ; 
lower += tail . getPoints ( ) . size ( ) ; 
tail . setNext ( new CFLine ( ) ) ; 
tail = tail . getNext ( ) ; 
tail = tail . getPrev ( ) ; 
if ( tail != null ) tail . setNext ( null ) ; 
catch ( IOException | InvalidRangeException | InvalidDataseriesException e ) { 
cfl . error ( e . getMessage ( ) ) ; ; 
} public double [ ] getBBUpper ( ) { 
double [ ] bbUpper = new double [ 2 ] ; 
List < Point > ptList = this . getPoints ( ) ; 
if ( ptList . isEmpty ( ) ) return null ; 
bbUpper [ 0 ] = ptList . get ( 0 ) . getY ( ) ; 
bbUpper [ 1 ] = ptList . get ( 0 ) . getY ( ) ; 
for ( Point pt : this . getPoints ( ) ) { 
if ( bbUpper [ 0 ] < pt . getX ( ) ) { 
bbUpper [ 0 ] = pt . getX ( ) ; 
if ( bbUpper [ 1 ] < pt . getY ( ) ) { 
bbUpper [ 1 ] = pt . getY ( ) ; 
bbUpper [ 0 ] += 10 ; 
bbUpper [ 1 ] += 10 ; 
return bbUpper ; 
} public double [ ] getBBLower ( ) { 
double [ ] bbLower = new double [ 2 ] ; 
bbLower [ 0 ] = ptList . get ( 0 ) . getY ( ) ; 
bbLower [ 1 ] = ptList . get ( 0 ) . getY ( ) ; 
if ( bbLower [ 0 ] > pt . getX ( ) ) { 
bbLower [ 0 ] = pt . getX ( ) ; 
if ( bbLower [ 1 ] > pt . getY ( ) ) { 
bbLower [ 1 ] = pt . getY ( ) ; 
bbLower [ 0 ] -= 10 ; 
bbLower [ 1 ] -= 10 ; 
return bbLower ; 
} boolean validate ( StringBuilder out ) { 
this . isValid = true ; 
if ( this . log . length ( ) > 0 ) { 
out . append ( this . log ) ; 
if ( this . getName ( ) == null ) { 
if ( this . getType ( ) == null ) { 
if ( this . type == DatasetFilter . Type . REGULAR_EXPRESSION && 
this . matchPattern == null ) { 
if ( this . type != DatasetFilter . Type . REGULAR_EXPRESSION && 
this . type != null && 
this . matchPattern != null ) { 
return ( this . isValid ) ; 
} private boolean match ( InvDataset dataset ) { 
if ( this . getParentDatasetSource ( ) . isCollection ( dataset ) && ! this . applyToCollectionDatasets ) 
if ( ( ! this . getParentDatasetSource ( ) . isCollection ( dataset ) ) && ! this . applyToAtomicDatasets ) 
if ( this . matchPatternTarget == null ) { 
if ( this . getParentDatasetSource ( ) . isCollection ( dataset ) ) { 
this . setMatchPatternTarget ( "name" ) ; 
this . setMatchPatternTarget ( "urlPath" ) ; 
if ( this . type == DatasetFilter . Type . REGULAR_EXPRESSION ) { 
boolean isMatch ; 
if ( this . getMatchPatternTarget ( ) . equals ( "name" ) ) { 
java . util . regex . Matcher matcher = this . regExpPattern . matcher ( dataset . getName ( ) ) ; 
isMatch = matcher . find ( ) ; 
} else if ( this . getMatchPatternTarget ( ) . equals ( "urlPath" ) ) { 
java . util . regex . Matcher matcher = this . regExpPattern . matcher ( ( ( InvDatasetImpl ) dataset ) . getUrlPath ( ) ) ; 
isMatch = false ; 
return ( isMatch ) ; 
} public static boolean acceptDatasetByFilterGroup ( List filters , InvDataset dataset , boolean isCollectionDataset ) { 
if ( filters . isEmpty ( ) ) 
boolean accept = false ; 
boolean anyApplyToAtomic = false ; 
boolean anyApplyToCollection = false ; 
for ( Iterator it = filters . iterator ( ) ; it . hasNext ( ) ; ) { 
DatasetFilter curFilter = ( DatasetFilter ) it . next ( ) ; 
anyApplyToAtomic |= curFilter . isApplyToAtomicDatasets ( ) ; 
anyApplyToCollection |= curFilter . isApplyToCollectionDatasets ( ) ; 
if ( curFilter . isAcceptMatchingDatasets ( ) ) { 
if ( curFilter . accept ( dataset ) ) { 
accept = true ; 
if ( curFilter . reject ( dataset ) ) { 
if ( accept ) return ( true ) ; 
if ( isCollectionDataset ) { 
if ( ! anyApplyToCollection ) return ( true ) ; 
if ( ! anyApplyToAtomic ) return ( true ) ; 
} public void addAll ( FeatureDatasetPoint fdPoint ) throws IOException { 
try ( PointFeatureIterator pointFeatIter = 
new FlattenedDatasetPointCollection ( fdPoint ) . getPointFeatureIterator ( ) ) { 
while ( pointFeatIter . hasNext ( ) ) { 
StationPointFeature pointFeat = ( StationPointFeature ) pointFeatIter . next ( ) ; 
add ( pointFeat ) ; 
} private StationFeatureCopyFactory getStationFeatureCopyFactory ( StationPointFeature proto ) throws IOException { 
if ( stationFeatCopyFactory == null ) { 
stationFeatCopyFactory = createStationFeatureCopyFactory ( proto ) ; 
return stationFeatCopyFactory ; 
} public void parseConstraint ( String constraint , String urlencoded ) 
throws ParseException , opendap . dap . DAP2Exception , NoSuchVariableException , 
NoSuchFunctionException , InvalidOperatorException , 
InvalidParameterException , SBHException , WrongTypeException { 
if ( clauseFactory == null ) { 
clauseFactory = new ClauseFactory ( ) ; 
CeParser . constraint_expression ( this , 
_dds . getFactory ( ) , 
clauseFactory , 
constraint , urlencoded ) ; 
} catch ( ConstraintException ce ) { 
ce . printStackTrace ( ) ; 
throw new DAP2Exception ( ce ) ; 
if ( _Debug ) { 
int it = 0 ; 
Enumeration ec = getClauses ( ) ; 
if ( ! ec . hasMoreElements ( ) ) 
while ( ec . hasMoreElements ( ) ) { 
it ++ ; 
} public void parseConstraint ( ReqState rs ) 
InvalidParameterException , SBHException , WrongTypeException 
parseConstraint ( rs . getConstraintExpression ( ) , rs . getRequestURL ( ) . toString ( ) ) ; 
} public void send ( String dataset , OutputStream sink , Object specialO ) 
Enumeration e = _dds . getVariables ( ) ; 
ServerMethods s = ( ServerMethods ) e . nextElement ( ) ; 
if ( _Debug ) 
( ( BaseType ) s ) . getEncodedName ( ) ) ; 
if ( s . isProject ( ) ) { 
+ ( ( BaseType ) s ) . getTypeName ( ) 
+ ( ( BaseType ) s ) . getEncodedName ( ) 
+ ")" ) ; 
s . serialize ( dataset , ( DataOutputStream ) sink , this , specialO ) ; 
} public boolean evalClauses ( Object specialO ) throws NoSuchVariableException , DAP2ServerSideException , IOException { 
boolean result = true ; 
while ( ec . hasMoreElements ( ) && result == true ) { 
Object o = ec . nextElement ( ) ; 
result = ( ( TopLevelClause ) o ) . evaluate ( ) ; 
return ( result ) ; 
} public void markAll ( boolean state ) 
throws DAP2Exception , NoSuchVariableException , SBHException 
Object o = e . nextElement ( ) ; 
if ( state ) { 
if ( o instanceof SDArray ) { 
SDArray SDA = ( SDArray ) o ; 
Enumeration eSDA = SDA . getDimensions ( ) ; 
while ( eSDA . hasMoreElements ( ) ) { 
DArrayDimension dad = ( DArrayDimension ) eSDA . nextElement ( ) ; 
dad . setProjection ( 0 , 1 , dad . getSize ( ) - 1 ) ; 
} else if ( o instanceof SDGrid ) { 
SDGrid SDG = ( SDGrid ) o ; 
SDArray sdgA = ( SDArray ) SDG . getVar ( 0 ) ; 
Enumeration eSDA = sdgA . getDimensions ( ) ; 
ServerMethods s = ( ServerMethods ) o ; 
s . setProject ( state ) ; 
} public void printConstraint ( PrintWriter pw ) 
Clause cl = ( Clause ) ec . nextElement ( ) ; 
cl . printConstraint ( pw ) ; 
} static public boolean amendFromODL ( NetcdfFile ncfile , Group eosGroup ) throws IOException { 
String smeta = getStructMetadata ( eosGroup ) ; 
if ( smeta == null ) { return false ; } 
HdfEos fixer = new HdfEos ( ) ; 
fixer . fixAttributes ( ncfile . getRootGroup ( ) ) ; 
fixer . amendFromODL ( ncfile , smeta ) ; 
} private void amendFromODL ( NetcdfFile ncfile , String structMetadata ) throws IOException { 
Group rootg = ncfile . getRootGroup ( ) ; 
ODLparser parser = new ODLparser ( ) ; 
Element root = parser . parseFromString ( structMetadata ) ; 
FeatureType featureType = null ; 
Element swathStructure = root . getChild ( "SwathStructure" ) ; 
if ( swathStructure != null ) { 
List < Element > swaths = swathStructure . getChildren ( ) ; 
for ( Element elemSwath : swaths ) { 
Element swathNameElem = elemSwath . getChild ( "SwathName" ) ; 
if ( swathNameElem == null ) { 
String swathName = NetcdfFile . makeValidCdmObjectName ( swathNameElem . getText ( ) . trim ( ) ) ; 
Group swathGroup = findGroupNested ( rootg , swathName ) ; 
if ( swathGroup != null ) { 
featureType = amendSwath ( ncfile , elemSwath , swathGroup ) ; 
Element gridStructure = root . getChild ( "GridStructure" ) ; 
if ( gridStructure != null ) { 
List < Element > grids = gridStructure . getChildren ( ) ; 
for ( Element elemGrid : grids ) { 
Element gridNameElem = elemGrid . getChild ( "GridName" ) ; 
if ( gridNameElem == null ) { 
String gridName = NetcdfFile . makeValidCdmObjectName ( gridNameElem . getText ( ) . trim ( ) ) ; 
Group gridGroup = findGroupNested ( rootg , gridName ) ; 
if ( gridGroup != null ) { 
featureType = amendGrid ( elemGrid , ncfile , gridGroup , ncfile . getLocation ( ) ) ; 
Element pointStructure = root . getChild ( "PointStructure" ) ; 
if ( pointStructure != null ) { 
List < Element > pts = pointStructure . getChildren ( ) ; 
for ( Element elem : pts ) { 
Element nameElem = elem . getChild ( "PointName" ) ; 
if ( nameElem == null ) { 
String name = nameElem . getText ( ) . trim ( ) ; 
Group ptGroup = findGroupNested ( rootg , name ) ; 
if ( ptGroup != null ) { 
featureType = FeatureType . POINT ; 
if ( featureType != null ) { 
rootg . addAttribute ( new Attribute ( CF . FEATURE_TYPE , featureType . toString ( ) ) ) ; 
} private void setSharedDimensions ( Variable v , List < Element > values , List < Dimension > unknownDims , String location ) { 
if ( values . size ( ) == 0 ) { 
Iterator < Element > iter = values . iterator ( ) ; 
Element value = iter . next ( ) ; 
String dimName = value . getText ( ) . trim ( ) ; 
if ( dimName . equalsIgnoreCase ( "scalar" ) ) { 
List < Dimension > oldDims = v . getDimensions ( ) ; 
if ( oldDims . size ( ) != values . size ( ) ) { 
List < Dimension > newDims = new ArrayList < > ( ) ; 
Group group = v . getParentGroup ( ) ; 
for ( int i = 0 ; i < values . size ( ) ; i ++ ) { 
Element value = values . get ( i ) ; 
dimName = NetcdfFile . makeValidCdmObjectName ( dimName ) ; 
Dimension dim = group . findDimension ( dimName ) ; 
Dimension oldDim = oldDims . get ( i ) ; 
dim = checkUnknownDims ( dimName , unknownDims , oldDim , location ) ; 
if ( dim . getLength ( ) != oldDim . getLength ( ) ) { 
dim . getShortName ( ) , oldDim . getShortName ( ) , 
dim . getLength ( ) , oldDim . getLength ( ) , v , location ) ; 
newDims . add ( dim ) ; 
v . setDimensions ( newDims ) ; 
} private Dimension checkUnknownDims ( String wantDim , List < Dimension > unknownDims , Dimension oldDim , String location ) { 
for ( Dimension dim : unknownDims ) { 
if ( dim . getShortName ( ) . equals ( wantDim ) ) { 
int len = oldDim . getLength ( ) ; 
dim . setUnlimited ( true ) ; 
dim . setLength ( len ) ; 
Group parent = dim . getGroup ( ) ; 
parent . addDimensionIfNotExists ( dim ) ; 
unknownDims . remove ( dim ) ; 
} private Group findGroupNested ( Group parent , String name ) { 
for ( Group g : parent . getGroups ( ) ) { 
if ( g . getShortName ( ) . equals ( name ) ) { return g ; } 
Group result = findGroupNested ( g , name ) ; 
if ( result != null ) { return result ; } 
} public String readXlinkContent ( ) throws java . io . IOException { 
if ( uri == null ) return "" ; 
URL url = uri . toURL ( ) ; 
InputStream is = url . openStream ( ) ; 
ByteArrayOutputStream os = new ByteArrayOutputStream ( is . available ( ) ) ; 
byte [ ] buffer = new byte [ 1024 ] ; 
int bytesRead = is . read ( buffer ) ; 
if ( bytesRead == - 1 ) break ; 
os . write ( buffer , 0 , bytesRead ) ; 
return new String ( os . toByteArray ( ) , CDM . utf8Charset ) ; 
} public String getStandardUrlName ( ) { 
URI uri = getStandardUri ( ) ; 
if ( uri == null ) return null ; 
return uri . toString ( ) ; 
} public URI getStandardUri ( ) { 
InvCatalog cat = dataset . getParentCatalog ( ) ; 
if ( cat == null ) 
return new URI ( getUnresolvedUrlName ( ) ) ; 
return cat . resolveUri ( getUnresolvedUrlName ( ) ) ; 
} private void parseFile ( ) 
try ( 
BufferedReader fp = new BufferedReader ( new InputStreamReader ( new FileInputStream ( iniFile ) , Charset . forName ( "UTF-8" ) ) ) ; 
boolean done = false ; 
while ( ! done ) { 
String thisLine = fp . readLine ( ) ; 
if ( thisLine != null && thisLine . trim ( ) . length ( ) == 0 ) 
thisLine = null ; 
if ( thisLine != null ) { 
if ( thisLine . startsWith ( ";" ) || thisLine . equalsIgnoreCase ( "" ) ) { 
int cindx = thisLine . indexOf ( ";" ) ; 
if ( cindx > 0 ) 
thisLine = thisLine . substring ( 0 , cindx ) . trim ( ) ; 
if ( thisLine . startsWith ( "[" ) && thisLine . endsWith ( "]" ) ) { 
String sname = thisLine . substring ( 1 , thisLine . length ( ) - 1 ) . trim ( ) ; 
if ( sectionNames == null ) 
sectionNames = new Vector ( ) ; 
sectionNames . add ( sname ) ; 
if ( sectionProperties == null ) 
sectionProperties = new Vector ( ) ; 
sectionProperties . add ( new Vector ( ) ) ; 
} else if ( sectionNames != null && sectionProperties != null ) { 
int eqidx = thisLine . indexOf ( "=" ) ; 
if ( eqidx != - 1 ) { 
String pair [ ] = new String [ 2 ] ; 
pair [ 0 ] = thisLine . substring ( 0 , eqidx ) . trim ( ) ; 
pair [ 1 ] = thisLine . substring ( eqidx + 1 , thisLine . length ( ) ) . trim ( ) ; 
if ( Debug ) 
( ( Vector ) sectionProperties . lastElement ( ) ) . add ( pair ) ; 
} public Enumeration getPropList ( String sectionName ) 
if ( sectionNames == null ) { 
System . err . println ( errMsg ) ; 
int sectionIndex = 0 ; 
Enumeration e = sectionNames . elements ( ) ; 
while ( ! done && e . hasMoreElements ( ) ) { 
String thisName = ( String ) e . nextElement ( ) ; 
if ( sectionName . equalsIgnoreCase ( thisName ) ) 
sectionIndex ++ ; 
if ( ! done ) 
return ( ( ( Vector ) sectionProperties . elementAt ( sectionIndex ) ) . elements ( ) ) ; 
} public String getProperty ( String propertyName ) 
if ( currentSection < 0 ) { 
System . err . println ( msg ) ; 
return ( msg ) ; 
String pair [ ] = null ; 
Enumeration e = ( ( Vector ) sectionProperties . elementAt ( currentSection ) ) . elements ( ) ; 
pair = ( String [ ] ) e . nextElement ( ) ; 
if ( pair [ 0 ] . equalsIgnoreCase ( propertyName ) ) 
if ( done ) 
return ( pair [ 1 ] ) ; 
} public void printProps ( PrintStream ps ) 
Enumeration se = getSectionList ( ) ; 
if ( se == null ) { 
ps . println ( errMsg ) ; 
while ( se . hasMoreElements ( ) ) { 
String sname = ( String ) se . nextElement ( ) ; 
setSection ( sname ) ; 
ps . println ( "[" + sname + "]" ) ; 
Enumeration pe = getPropList ( sname ) ; 
while ( pe != null && pe . hasMoreElements ( ) ) { 
String pair [ ] = ( String [ ] ) pe . nextElement ( ) ; 
String prop = pair [ 0 ] ; 
String valu = getProperty ( prop ) ; 
} public boolean setSection ( String sectionName ) 
currentSection = sectionIndex ; 
} public void setProjection ( ProjectionManager . ProjectionClass pc ) { 
for ( ProjectionManager . ProjectionParam pp : pc . paramList ) { 
JPanel thisPanel = new JPanel ( ) ; 
JTextField tf = new JTextField ( ) ; 
pp . setTextField ( tf ) ; 
tf . setColumns ( 12 ) ; 
thisPanel . add ( tf ) ; 
add ( thisPanel ) ; 
} public static String nameForJsCode ( String dodsName ) { 
StringBuilder buf = new StringBuilder ( dodsName ) ; 
for ( int i = 0 ; i < buf . length ( ) ; i ++ ) { 
char c = buf . charAt ( i ) ; 
if ( c == '-' ) buf . replace ( i , i + 1 , "_" ) ; 
else if ( legal_javascript_id_chars . indexOf ( c ) < 0 ) { 
String s = "_" + String . valueOf ( ( int ) c ) + "_" ; 
buf . replace ( i , i + 1 , s ) ; 
return "dods_" + buf . toString ( ) ; 
} public void writeVariableEntries ( DAS das , DDS dds ) { 
pWrt . print ( "<tr>\n" 
+ "<br><td>\n" 
Enumeration e = dds . getVariables ( ) ; 
BaseType bt = ( BaseType ) e . nextElement ( ) ; 
( ( BrowserForm ) bt ) . printBrowserForm ( pWrt , das ) ; 
writeVariableAttributes ( bt , das ) ; 
pWrt . print ( "\n<p><p>\n\n" ) ; 
pWrt . print ( "<tr><td><td>\n\n" ) ; 
} public void writeVariableAttributes ( BaseType bt , DAS das ) { 
AttributeTable attr = das . getAttributeTable ( bt . getEncodedName ( ) ) ; 
+ bt . getLongName ( ) . replace ( '.' , '_' ) 
+ "_attr" 
+ _attrRows 
+ _attrCols 
+ ">\n" 
writeAttributes ( attr ) ; 
pWrt . print ( "</textarea>\n\n" ) ; 
} catch ( NoSuchAttributeException nsae ) { 
} public static ShapeType initShape ( ShapeType shape , StationTimeSeriesFeature stationFeat ) { 
PointDocument pointDoc = PointDocument . Factory . newInstance ( ) ; 
NcPointType . initPoint ( pointDoc . addNewPoint ( ) , stationFeat ) ; 
shape . set ( pointDoc ) ; 
} public void addLayoutComponent ( Component comp , Object constraint ) { 
if ( ! ( constraint instanceof Constraint ) ) 
constraintMap . put ( comp , constraint ) ; 
globalBounds = null ; 
} public void invalidateLayout ( Container target ) { 
} public void removeLayoutComponent ( Component comp ) { 
if ( debug ) System . out . println ( "removeLayoutComponent" ) ; 
constraintMap . remove ( comp ) ; 
} public Dimension preferredLayoutSize ( Container parent ) { 
if ( globalBounds == null ) layoutContainer ( parent ) ; 
return globalBounds . getSize ( ) ; 
} public Dimension minimumLayoutSize ( Container parent ) { 
if ( debug ) System . out . println ( "minimumLayoutSize" ) ; 
} public void layoutContainer ( Container target ) { 
int n = target . getComponentCount ( ) ; 
Component comp = target . getComponent ( i ) ; 
if ( comp instanceof Container ) { 
Container c = ( Container ) comp ; 
LayoutManager m = c . getLayout ( ) ; 
if ( m instanceof LayoutM ) 
m . layoutContainer ( c ) ; 
reset ( target ) ; 
globalBounds = new Rectangle ( 0 , 0 , 0 , 0 ) ; 
while ( ! layoutPass ( target ) ) 
target . setPreferredSize ( globalBounds . getSize ( ) ) ; 
} public static boolean isRadialCoordSys ( Formatter parseInfo , CoordinateSystem cs ) { 
return ( cs . getAzimuthAxis ( ) != null ) && ( cs . getRadialAxis ( ) != null ) && ( cs . getElevationAxis ( ) != null ) ; 
} public static RadialCoordSys makeRadialCoordSys ( Formatter parseInfo , CoordinateSystem cs , VariableEnhanced v ) { 
if ( parseInfo != null ) { 
if ( isRadialCoordSys ( parseInfo , cs ) ) { 
RadialCoordSys rcs = new RadialCoordSys ( cs ) ; 
if ( cs . isComplete ( v ) ) { 
return rcs ; 
} public double getMaximumRadial ( ) { 
if ( maxRadial == 0.0 ) { 
Array radialData = getRadialAxisDataCached ( ) ; 
maxRadial = MAMath . getMaximum ( radialData ) ; 
String units = getRadialAxis ( ) . getUnitsString ( ) ; 
SimpleUnit radialUnit = SimpleUnit . factory ( units ) ; 
maxRadial = radialUnit . convertTo ( maxRadial , SimpleUnit . kmUnit ) ; 
return maxRadial ; 
} public ucar . nc2 . units . DateUnit getTimeUnits ( ) throws Exception { 
if ( null == dateUnit ) { 
dateUnit = new DateUnit ( timeAxis . getUnitsString ( ) ) ; 
return dateUnit ; 
} static public void main ( String [ ] args ) { 
} public Point readData ( GridDatatype grid , CalendarDate date , EarthLocation location , boolean bounded ) throws java . io . IOException { 
if ( ! bounded ) { 
if ( Double . isNaN ( location . getAltitude ( ) ) ) { 
return readData ( grid , date , location . getLatitude ( ) , location . getLongitude ( ) ) ; 
return readData ( grid , date , location . getAltitude ( ) , location . getLatitude ( ) , location . getLongitude ( ) ) ; 
int tidx = findTimeIndexForCalendarDate ( gcs , date ) ; 
int [ ] xy = gcs . findXYindexFromLatLonBounded ( location . getLatitude ( ) , location . getLongitude ( ) , null ) ; 
LatLonPoint latlon = gcs . getLatLon ( xy [ 0 ] , xy [ 1 ] ) ; 
Point p = new Point ( ) ; 
p . lat = latlon . getLatitude ( ) ; 
p . lon = latlon . getLongitude ( ) ; 
int zidx = - 1 ; 
if ( ! Double . isNaN ( location . getAltitude ( ) ) ) { 
CoordinateAxis1D zAxis = gcs . getVerticalAxis ( ) ; 
zidx = zAxis . findCoordElement ( location . getAltitude ( ) ) ; 
p . z = zAxis . getCoordValue ( zidx ) ; 
Array data = grid . readDataSlice ( tidx , zidx , xy [ 1 ] , xy [ 0 ] ) ; 
p . dataValue = data . getDouble ( data . getIndex ( ) ) ; 
return p ; 
} private HTTPMethod processMethod ( HTTPSession httpclient , String url , Command cmd ) throws HTTPException , UnsupportedEncodingException { 
HTTPMethod m = null ; 
if ( cmd == Command . GET ) 
m = HTTPFactory . Get ( httpclient , url ) ; 
else if ( cmd == Command . HEAD ) 
m = HTTPFactory . Head ( httpclient , url ) ; 
else if ( cmd == Command . OPTIONS ) 
m = HTTPFactory . Options ( httpclient , url ) ; 
else if ( cmd == Command . PUT ) { 
m = HTTPFactory . Put ( httpclient , url ) ; 
m . setRequestContent ( new StringEntity ( ta . getText ( ) ) ) ; 
private void openURL2 ( String urlString , Command cmd ) { 
HTTPMethod m ; 
try ( HTTPSession httpclient = HTTPFactory . newSession ( urlString ) ) { 
m = HTTPFactory . Get ( httpclient , urlString ) ; 
m = HTTPFactory . Head ( httpclient , urlString ) ; 
m = HTTPFactory . Options ( httpclient , urlString ) ; 
m = HTTPFactory . Put ( httpclient , urlString ) ; 
m . setCompression ( "gzip,deflate" ) ; 
if ( cmd == Command . GET ) { 
appendLine ( "\nResponseBody---------------" ) ; 
String charset = m . getResponseCharSet ( ) ; 
if ( charset == null ) charset = CDM . UTF8 ; 
String contents = null ; 
Header h = m . getResponseHeader ( "content-encoding" ) ; 
String encoding = ( h == null ) ? null : h . getValue ( ) ; 
if ( encoding != null && encoding . equals ( "deflate" ) ) { 
byte [ ] body = m . getResponseAsBytes ( ) ; 
if ( body != null ) { 
InputStream is = new BufferedInputStream ( new InflaterInputStream ( new ByteArrayInputStream ( body ) ) , 10000 ) ; 
contents = IO . readContents ( is , charset ) ; 
double ratio = ( double ) contents . length ( ) / body . length ; 
} else if ( encoding != null && encoding . equals ( "gzip" ) ) { 
InputStream is = new BufferedInputStream ( new GZIPInputStream ( new ByteArrayInputStream ( body ) ) , 10000 ) ; 
byte [ ] body = m . getResponseAsBytes ( 50 * 1000 ) ; 
contents = ( body == null ) ? "" : new String ( body , charset ) ; 
if ( contents != null ) { 
if ( contents . length ( ) > 50 * 1000 ) 
contents = contents . substring ( 0 , 50 * 1000 ) ; 
appendLine ( contents ) ; 
} else if ( cmd == Command . OPTIONS ) 
StringWriter sw = new StringWriter ( 5000 ) ; 
e . printStackTrace ( new PrintWriter ( sw ) ) ; 
appendLine ( sw . toString ( ) ) ; 
} private void openURL ( String urlString , Command command ) { 
URL u = new URL ( urlString ) ; 
currentConnection = ( HttpURLConnection ) u . openConnection ( ) ; 
currentConnection . setRequestMethod ( command . toString ( ) ) ; 
currentConnection . setAllowUserInteraction ( true ) ; 
clear ( ) ; 
Map < String , List < String > > reqs = currentConnection . getRequestProperties ( ) ; 
for ( Map . Entry < String , List < String > > ent : reqs . entrySet ( ) ) { 
for ( String v : ent . getValue ( ) ) 
appendLine ( "" ) ; 
appendLine ( "getFollowRedirects=" + HttpURLConnection . getFollowRedirects ( ) ) ; 
appendLine ( "getInstanceFollowRedirects=" + currentConnection . getInstanceFollowRedirects ( ) ) ; 
appendLine ( "AllowUserInteraction=" + currentConnection . getAllowUserInteraction ( ) ) ; 
int code = currentConnection . getResponseCode ( ) ; 
String response = currentConnection . getResponseMessage ( ) ; 
for ( int j = 1 ; true ; j ++ ) { 
String header = currentConnection . getHeaderField ( j ) ; 
String key = currentConnection . getHeaderFieldKey ( j ) ; 
if ( header == null || key == null ) break ; 
appendLine ( "contents:" ) ; 
java . io . InputStream is = currentConnection . getInputStream ( ) ; 
ByteArrayOutputStream bout = new ByteArrayOutputStream ( 200000 ) ; 
IO . copy ( is , bout ) ; 
append ( new String ( bout . toByteArray ( ) , CDM . utf8Charset ) ) ; 
catch ( IOException e ) { 
} public double [ ] earthToSat ( double geographic_lon , double geographic_lat ) { 
geographic_lat = geographic_lat * DEG_TO_RAD ; 
geographic_lon = geographic_lon * DEG_TO_RAD ; 
double geocentric_lat = Math . atan ( ( ( r_pol * r_pol ) / ( r_eq * r_eq ) ) * Math . tan ( geographic_lat ) ) ; 
double r_earth = r_pol / Math . sqrt ( 1.0 - ( ( r_eq * r_eq - r_pol * r_pol ) / ( r_eq * r_eq ) ) * Math . cos ( geocentric_lat ) * Math . cos ( geocentric_lat ) ) ; 
double r_1 = h - r_earth * Math . cos ( geocentric_lat ) * Math . cos ( geographic_lon - sub_lon ) ; 
double r_2 = - r_earth * Math . cos ( geocentric_lat ) * Math . sin ( geographic_lon - sub_lon ) ; 
double r_3 = r_earth * Math . sin ( geocentric_lat ) ; 
if ( r_1 > h ) { 
return new double [ ] { Double . NaN , Double . NaN } ; 
double lamda_sat = Double . NaN ; 
double theta_sat = Double . NaN ; 
if ( scan_geom . equals ( GEOS ) ) { 
lamda_sat = Math . atan ( - r_2 / r_1 ) ; 
theta_sat = Math . asin ( r_3 / Math . sqrt ( r_1 * r_1 + r_2 * r_2 + r_3 * r_3 ) ) ; 
} else if ( scan_geom . equals ( GOES ) ) { 
lamda_sat = Math . asin ( - r_2 / Math . sqrt ( r_1 * r_1 + r_2 * r_2 + r_3 * r_3 ) ) ; 
theta_sat = Math . atan ( r_3 / r_1 ) ; 
return new double [ ] { lamda_sat , theta_sat } ; 
} public double [ ] satToEarth ( double x , double y ) { 
if ( scan_geom . equals ( GOES ) ) { 
double [ ] lambda_theta_geos = GOES_to_GEOS ( x , y ) ; 
x = lambda_theta_geos [ 0 ] ; 
y = lambda_theta_geos [ 1 ] ; 
double c1 = ( h * Math . cos ( x ) * Math . cos ( y ) ) * ( h * Math . cos ( x ) * Math . cos ( y ) ) ; 
double c2 = ( Math . cos ( y ) * Math . cos ( y ) + fp * Math . sin ( y ) * Math . sin ( y ) ) * d ; 
if ( c1 < c2 ) { 
double s_d = Math . sqrt ( c1 - c2 ) ; 
double s_n = ( h * Math . cos ( x ) * Math . cos ( y ) - s_d ) / ( Math . cos ( y ) * Math . cos ( y ) + fp * Math . sin ( y ) * Math . sin ( y ) ) ; 
double s_1 = h - s_n * Math . cos ( x ) * Math . cos ( y ) ; 
double s_2 = s_n * Math . sin ( x ) * Math . cos ( y ) ; 
double s_3 = - s_n * Math . sin ( y ) ; 
double s_xy = Math . sqrt ( s_1 * s_1 + s_2 * s_2 ) ; 
double geographic_lon = Math . atan ( s_2 / s_1 ) + sub_lon ; 
double geographic_lat = Math . atan ( - fp * ( s_3 / s_xy ) ) ; 
double lonDegrees = RAD_TO_DEG * geographic_lon ; 
double latDegrees = RAD_TO_DEG * geographic_lat ; 
if ( lonDegrees < - 180.0 ) lonDegrees += 360.0 ; 
if ( lonDegrees > 180.0 ) lonDegrees -= 360.0 ; 
return new double [ ] { lonDegrees , latDegrees } ; 
} public double [ ] GOES_to_GEOS ( double lamda_goes , double theta_goes ) { 
double theta_geos = Math . asin ( Math . sin ( theta_goes ) * Math . cos ( lamda_goes ) ) ; 
double lamda_geos = Math . atan ( Math . tan ( lamda_goes ) / Math . cos ( theta_goes ) ) ; 
return new double [ ] { lamda_geos , theta_geos } ; 
} public double [ ] FGFtoEarth ( double fgf_x , double fgf_y , double scale_x , double offset_x , double scale_y , double offset_y ) { 
double [ ] xy = FGFtoSat ( fgf_x , fgf_y , scale_x , offset_x , scale_y , offset_y ) ; 
return satToEarth ( xy [ 0 ] , xy [ 1 ] ) ; 
} public double [ ] FGFtoSat ( double fgf_x , double fgf_y , double scale_x , double offset_x , double scale_y , double offset_y ) { 
double x = fgf_x * scale_x + offset_x ; 
double y = fgf_y * scale_y + offset_y ; 
return new double [ ] { x , y } ; 
} public double [ ] elemLineToEarth ( int elem , int line , double scale_x , double offset_x , double scale_y , double offset_y ) { 
return FGFtoEarth ( ( double ) elem , ( double ) line , scale_x , offset_x , scale_y , offset_y ) ; 
} public double [ ] earthToFGF ( double geographic_lon , double geographic_lat , double scale_x , double offset_x , double scale_y , double offset_y ) { 
double [ ] xy = earthToSat ( geographic_lon , geographic_lat ) ; 
return SatToFGF ( xy [ 0 ] , xy [ 1 ] , scale_x , offset_x , scale_y , offset_y ) ; 
} public int [ ] earthToElemLine ( double geographic_lon , double geographic_lat , double scale_x , double offset_x , double scale_y , double offset_y ) { 
double [ ] fgf = earthToFGF ( geographic_lon , geographic_lat , scale_x , offset_x , scale_y , offset_y ) ; 
int elem = ( int ) Math . floor ( fgf [ 0 ] + 0.5 ) ; 
int line = ( int ) Math . floor ( fgf [ 1 ] + 0.5 ) ; 
return new int [ ] { elem , line } ; 
} public double [ ] SatToFGF ( double lamda , double theta , double scale_x , double offset_x , double scale_y , double offset_y ) { 
double fgf_x = ( lamda - offset_x ) / scale_x ; 
double fgf_y = ( theta - offset_y ) / scale_y ; 
return new double [ ] { fgf_x , fgf_y } ; 
} public static String scanGeomToSweepAngleAxis ( String scanGeometry ) { 
String sweepAngleAxis = "y" ; 
if ( scanGeometry . equals ( GOES ) ) { 
sweepAngleAxis = "x" ; 
return sweepAngleAxis ; 
} public static String sweepAngleAxisToScanGeom ( String sweepAngleAxis ) { 
String scanGeom = GOES ; 
if ( sweepAngleAxis . equals ( "y" ) ) { 
scanGeom = GEOS ; 
return scanGeom ; 
} void setRuntimeCoords ( CoordinateRuntime runtimes ) { 
for ( int idx = 0 ; idx < runtimes . getSize ( ) ; idx ++ ) { 
CalendarDate cd = runtimes . getRuntimeDate ( idx ) ; 
long runtime = runtimes . getRuntime ( idx ) ; 
CoordinateTimeAbstract time = timeMap . get ( runtime ) ; 
if ( time == null ) { 
time = isTimeInterval ? new CoordinateTimeIntv ( this . code , this . timeUnit , cd , new ArrayList < > ( 0 ) , null ) : 
new CoordinateTime ( this . code , this . timeUnit , cd , new ArrayList < > ( 0 ) , null ) ; 
timeMap . put ( runtime , time ) ; 
} public static boolean rewritePointObsDataset ( String fileIn , String fileOut , boolean inMemory ) throws IOException { 
NetcdfFile ncfile = inMemory ? NetcdfFile . openInMemory ( fileIn ) : NetcdfFile . open ( fileIn ) ; 
NetcdfDataset ncd = new NetcdfDataset ( ncfile ) ; 
StringBuilder errlog = new StringBuilder ( ) ; 
PointObsDataset pobsDataset = ( PointObsDataset ) TypedDatasetFactory . open ( FeatureType . POINT , ncd , null , errlog ) ; 
if ( pobsDataset == null ) return false ; 
writePointObsDataset ( pobsDataset , fileOut ) ; 
pobsDataset . close ( ) ; 
} public static void writePointObsDataset ( PointObsDataset pobsDataset , String fileOut ) throws IOException { 
String altUnits = null ; 
DataIterator iterOne = pobsDataset . getDataIterator ( - 1 ) ; 
while ( iterOne . hasNext ( ) ) { 
PointObsDatatype pobsData = ( PointObsDatatype ) iterOne . nextData ( ) ; 
ucar . unidata . geoloc . EarthLocation loc = pobsData . getLocation ( ) ; 
altUnits = Double . isNaN ( loc . getAltitude ( ) ) ? null : "meters" ; 
List < VariableSimpleIF > vars = pobsDataset . getDataVariables ( ) ; 
List < PointObVar > nvars = new ArrayList < PointObVar > ( vars . size ( ) ) ; 
for ( VariableSimpleIF v : vars ) { 
if ( v . getDataType ( ) . isNumeric ( ) ) 
nvars . add ( new PointObVar ( v ) ) ; 
int ndoubles = vars . size ( ) ; 
double [ ] dvals = new double [ ndoubles ] ; 
if ( v . getDataType ( ) . isString ( ) ) 
String [ ] svals = new String [ vars . size ( ) - ndoubles ] ; 
FileOutputStream fos = new FileOutputStream ( fileOut ) ; 
DataOutputStream out = new DataOutputStream ( fos ) ; 
CFPointObWriter writer = new CFPointObWriter ( out , pobsDataset . getGlobalAttributes ( ) , altUnits , nvars , - 1 ) ; 
DataIterator iter = pobsDataset . getDataIterator ( 1000 * 1000 ) ; 
PointObsDatatype pobsData = ( PointObsDatatype ) iter . nextData ( ) ; 
StructureData sdata = pobsData . getData ( ) ; 
int dcount = 0 ; 
int scount = 0 ; 
for ( PointObVar v : nvars ) { 
if ( v . getDataType ( ) . isNumeric ( ) ) { 
Array data = sdata . getArray ( v . getName ( ) ) ; 
data . resetLocalIterator ( ) ; 
if ( data . hasNext ( ) ) 
dvals [ dcount ++ ] = data . nextDouble ( ) ; 
} else if ( v . getDataType ( ) . isString ( ) ) { 
ArrayChar data = ( ArrayChar ) sdata . getArray ( v . getName ( ) ) ; 
svals [ scount ++ ] = data . getString ( ) ; 
writer . addPoint ( loc . getLatitude ( ) , loc . getLongitude ( ) , loc . getAltitude ( ) , pobsData . getObservationTimeAsDate ( ) , 
dvals , svals ) ; 
writer . finish ( ) ; 
} public static boolean rewritePointFeatureDataset ( String fileIn , String fileOut , boolean inMemory ) throws IOException { 
Formatter errlog = new Formatter ( ) ; 
FeatureDataset fd = FeatureDatasetFactoryManager . wrap ( FeatureType . ANY_POINT , ncd , null , errlog ) ; 
if ( fd == null ) return false ; 
if ( fd instanceof FeatureDatasetPoint ) { 
writePointFeatureCollection ( ( FeatureDatasetPoint ) fd , fileOut ) ; 
fd . close ( ) ; 
} public static int writePointFeatureCollection ( FeatureDatasetPoint pfDataset , String fileOut ) throws IOException { 
PointFeatureCollection pointFeatureCollection = null ; 
List < DsgFeatureCollection > featureCollectionList = pfDataset . getPointFeatureCollectionList ( ) ; 
for ( DsgFeatureCollection featureCollection : featureCollectionList ) { 
if ( featureCollection instanceof PointFeatureCollection ) 
pointFeatureCollection = ( PointFeatureCollection ) featureCollection ; 
if ( null == pointFeatureCollection ) 
DataOutputStream out = new DataOutputStream ( new BufferedOutputStream ( fos , 10000 ) ) ; 
WriterCFPointDataset writer = null ; 
for ( PointFeature pointFeature : pointFeatureCollection ) { 
StructureData data = pointFeature . getDataAll ( ) ; 
EarthLocation loc = pointFeature . getLocation ( ) ; 
String altUnits = Double . isNaN ( loc . getAltitude ( ) ) ? null : "meters" ; 
writer = new WriterCFPointDataset ( out , pfDataset . getGlobalAttributes ( ) , altUnits ) ; 
writer . writeHeader ( pfDataset . getDataVariables ( ) , - 1 ) ; 
writer . writeRecord ( pointFeature , data ) ; 
} public Array getArray ( String memberName ) { 
StructureMembers . Member m = members . findMember ( memberName ) ; 
return getArray ( m ) ; 
} public Object getScalarObject ( String memberName ) { 
return getScalarObject ( m ) ; 
} public Object getScalarObject ( StructureMembers . Member m ) { 
DataType dataType = m . getDataType ( ) ; 
if ( dataType == DataType . DOUBLE ) { 
return getScalarDouble ( m ) ; 
return getScalarFloat ( m ) ; 
} else if ( dataType . getPrimitiveClassType ( ) == byte . class ) { 
return getScalarByte ( m ) ; 
return getScalarShort ( m ) ; 
return getScalarInt ( m ) ; 
return getScalarLong ( m ) ; 
} else if ( dataType == DataType . CHAR ) { 
return getScalarString ( m ) ; 
return getScalarStructure ( m ) ; 
return getArraySequence ( m ) ; 
} public float convertScalarFloat ( String memberName ) { 
return convertScalarFloat ( m ) ; 
} public String getScalarString ( String memberName ) { 
StructureMembers . Member m = findMember ( memberName ) ; 
if ( null == m ) 
} public StructureData getScalarStructure ( String memberName ) { 
} public ArrayStructure getArrayStructure ( String memberName ) { 
return getArrayStructure ( m ) ; 
} public ArraySequence getArraySequence ( String memberName ) { 
} public void showInternal ( Formatter f , Indent indent ) { 
} public String getFullName ( ) { 
return ( parent == null ) 
? name 
: ( parent . getFullName ( ) == null || parent . getFullName ( ) . length ( ) == 0 ) 
: parent . getFullName ( ) + "/" + name ; 
} public String getUniqueID ( ) { 
String authority = getAuthority ( ) ; 
if ( ( authority != null ) && ( getID ( ) != null ) ) 
return authority + ":" + getID ( ) ; 
else if ( getID ( ) != null ) 
return getID ( ) ; 
} public InvAccess getAccess ( thredds . catalog . ServiceType type ) { 
for ( InvAccess a : getAccess ( ) ) { 
if ( s . getServiceType ( ) == type ) 
} public InvAccess findAccess ( String accessURL ) { 
if ( accessURL . equals ( a . getStandardUrlName ( ) ) ) 
} public InvDatasetImpl findDatasetByName ( String name ) { 
for ( InvDataset ds : getDatasets ( ) ) { 
if ( ds . getName ( ) . equals ( name ) ) 
return ( InvDatasetImpl ) ds ; 
} public InvCatalog getParentCatalog ( ) { 
if ( catalog != null ) return catalog ; 
return ( parent != null ) ? parent . getParentCatalog ( ) : null ; 
} public java . util . List < InvMetadata > getMetadata ( thredds . catalog . MetadataType want ) { 
List < InvMetadata > result = new ArrayList < InvMetadata > ( ) ; 
for ( InvMetadata m : getMetadata ( ) ) { 
MetadataType mtype = MetadataType . getType ( m . getMetadataType ( ) ) ; 
if ( mtype == want ) 
result . add ( m ) ; 
for ( InvService p : services ) { 
if ( p . getName ( ) . equals ( name ) ) 
return parent . findService ( name ) ; 
return ( catalog == null ) ? null : catalog . findService ( name ) ; 
} public String getRestrictAccess ( ) { 
if ( restrictAccess != null ) return restrictAccess ; 
return parent . getRestrictAccess ( ) ; 
} public ThreddsMetadata . Variables getVariables ( String vocab ) { 
ThreddsMetadata . Variables result = new ThreddsMetadata . Variables ( vocab , null , null , null , null ) ; 
if ( variables == null ) return result ; 
for ( ThreddsMetadata . Variables vs : variables ) { 
if ( vs . getVocabulary ( ) . equals ( vocab ) ) 
result . getVariableList ( ) . addAll ( vs . getVariableList ( ) ) ; 
public ProjectionImpl constructCopy ( ) { 
ProjectionImpl result = new FlatEarth ( getOriginLat ( ) , getOriginLon ( ) , getRotationAngle ( ) ) ; 
result . setDefaultMapArea ( defaultMapArea ) ; 
result . setName ( name ) ; 
double dx , dy ; 
fromLat = Math . toRadians ( fromLat ) ; 
dy = radius * ( fromLat - lat0 ) ; 
dx = radius * Math . cos ( fromLat ) 
* ( Math . toRadians ( fromLon ) - lon0 ) ; 
toX = cosRot * dx - sinRot * dy ; 
toY = sinRot * dx + cosRot * dy ; 
result . setLocation ( toX , toY ) ; 
double x = world . getX ( ) ; 
double y = world . getY ( ) ; 
double cosl ; 
int TOLERENCE = 1 ; 
double xp , yp ; 
xp = cosRot * x + sinRot * y ; 
yp = - sinRot * x + cosRot * y ; 
toLat = Math . toDegrees ( lat0 ) + Math . toDegrees ( yp / radius ) ; 
cosl = Math . cos ( Math . toRadians ( toLat ) ) ; 
if ( Math . abs ( cosl ) < TOLERANCE ) { 
toLon = Math . toDegrees ( lon0 ) ; 
toLon = Math . toDegrees ( lon0 ) 
+ Math . toDegrees ( xp / cosl / radius ) ; 
toLon = LatLonPointImpl . lonNormal ( toLon ) ; 
double dy = radius * ( fromLat - lat0 ) ; 
double dx = radius * Math . cos ( fromLat ) 
double xp = cosRot * fromX + sinRot * fromY ; 
double yp = - sinRot * fromX + cosRot * fromY ; 
toLat = Math . toDegrees ( lat0 ) 
+ Math . toDegrees ( yp / radius ) ; 
double cosl = Math . cos ( Math . toRadians ( toLat ) ) ; 
toLatA [ i ] = toLat ; 
toLonA [ i ] = toLon ; 
FlatEarth a = new FlatEarth ( 90 , - 100 , 0.0 ) ; 
ProjectionPoint p = a . latLonToProj ( 89 , - 101 ) ; 
LatLonPoint ll = a . projToLatLon ( p ) ; 
} public static List < InvCatalogRef > findAllCatRefsInDatasetTree ( List < InvDataset > datasets , StringBuilder log , boolean onlyRelativeUrls ) 
List < InvCatalogRef > catRefList = new ArrayList < InvCatalogRef > ( ) ; 
for ( InvDataset invds : datasets ) 
InvDatasetImpl curDs = ( InvDatasetImpl ) invds ; 
if ( curDs instanceof InvDatasetScan ) 
if ( curDs instanceof InvCatalogRef ) 
InvCatalogRef catRef = ( InvCatalogRef ) curDs ; 
String name = catRef . getName ( ) ; 
String href = catRef . getXlinkHref ( ) ; 
URI uri ; 
uri = new URI ( href ) ; 
catch ( URISyntaxException e ) 
log . append ( log . length ( ) > 0 ? "\n" : "" ) 
if ( onlyRelativeUrls && uri . isAbsolute ( ) ) 
catRefList . add ( catRef ) ; 
if ( curDs . hasNestedDatasets ( ) ) 
catRefList . addAll ( findAllCatRefsInDatasetTree ( curDs . getDatasets ( ) , log , onlyRelativeUrls ) ) ; 
return catRefList ; 
} static public String escapePathForURL ( String path ) { 
return new URI ( null , null , path , null ) . toString ( ) ; 
ArrayDouble . D3 array ; 
Array pertArray = getTimeSlice ( pertVar , timeIndex ) ; 
Array baseArray = getTimeSlice ( baseVar , timeIndex ) ; 
int [ ] shape = pertArray . getShape ( ) ; 
int ni = shape [ 0 ] ; 
int nj = shape [ 1 ] ; 
int nk = shape [ 2 ] ; 
array = new ArrayDouble . D3 ( ni , nj , nk ) ; 
Index index = array . getIndex ( ) ; 
for ( int i = 0 ; i < ni ; i ++ ) { 
for ( int j = 0 ; j < nj ; j ++ ) { 
for ( int k = 0 ; k < nk ; k ++ ) { 
index . set ( i , j , k ) ; 
double d = pertArray . getDouble ( index ) + baseArray . getDouble ( index ) ; 
if ( isZStag ) { 
d = d / 9.81 ; 
array . setDouble ( index , d ) ; 
if ( isXStag ) { 
array = addStagger ( array , 2 ) ; 
if ( isYStag ) { 
array = addStagger ( array , 1 ) ; 
ArrayDouble . D3 data = getCoordinateArray ( timeIndex ) ; 
origin [ 0 ] = 0 ; 
shape [ 0 ] = data . getShape ( ) [ 0 ] ; 
Array tmp = data . section ( origin , shape ) ; 
return ( ArrayDouble . D1 ) tmp . reduce ( ) ; 
} private ArrayDouble . D3 addStagger ( ArrayDouble . D3 array , int dimIndex ) { 
int [ ] shape = array . getShape ( ) ; 
int [ ] newShape = new int [ 3 ] ; 
System . arraycopy ( shape , 0 , newShape , 0 , 3 ) ; 
newShape [ dimIndex ] ++ ; 
int ni = newShape [ 0 ] ; 
int nj = newShape [ 1 ] ; 
int nk = newShape [ 2 ] ; 
ArrayDouble . D3 newArray = new ArrayDouble . D3 ( ni , nj , nk ) ; 
int n = shape [ dimIndex ] ; 
double [ ] d = new double [ n ] ; 
int [ ] eshape = new int [ 3 ] ; 
int [ ] neweshape = new int [ 3 ] ; 
eshape [ i ] = ( i == dimIndex ) 
? n 
: 1 ; 
neweshape [ i ] = ( i == dimIndex ) 
? n + 1 
for ( int i = 0 ; i < ( ( dimIndex == 0 ) 
: ni ) ; i ++ ) { 
for ( int j = 0 ; j < ( ( dimIndex == 1 ) 
: nj ) ; j ++ ) { 
for ( int k = 0 ; k < ( ( dimIndex == 2 ) 
: nk ) ; k ++ ) { 
origin [ 0 ] = i ; 
origin [ 1 ] = j ; 
origin [ 2 ] = k ; 
IndexIterator it = array . section ( origin , 
eshape ) . getIndexIterator ( ) ; 
for ( int l = 0 ; l < n ; l ++ ) { 
d [ l ] = it . getDoubleNext ( ) ; 
double [ ] d2 = extrapinterpolate ( d ) ; 
IndexIterator newit = 
newArray . section ( origin , 
neweshape ) . getIndexIterator ( ) ; 
for ( int l = 0 ; l < n + 1 ; l ++ ) { 
newit . setDoubleNext ( d2 [ l ] ) ; 
return newArray ; 
} private double [ ] extrapinterpolate ( double [ ] array ) { 
int n = array . length ; 
double [ ] d = new double [ n + 1 ] ; 
d [ 0 ] = 1.5 * array [ 0 ] - 0.5 * array [ 1 ] ; 
d [ n ] = 1.5 * array [ n - 1 ] - 0.5 * array [ n - 2 ] ; 
for ( int i = 1 ; i < n ; i ++ ) { 
d [ i ] = 0.5 * ( array [ i - 1 ] + array [ i ] ) ; 
} public ProjectionImpl constructCopy ( ) { 
ProjectionImpl result = new AlbersEqualArea ( getOriginLat ( ) , getOriginLon ( ) , getParallelOne ( ) , getParallelTwo ( ) , 
getFalseEasting ( ) , getFalseNorthing ( ) , getEarthRadius ( ) ) ; 
} private void precalculate ( ) { 
double par1r = Math . toRadians ( this . par1 ) ; 
double par2r = Math . toRadians ( this . par2 ) ; 
if ( Math . abs ( par2 - par1 ) < TOLERANCE ) { 
n = Math . sin ( par1r ) ; 
n = ( Math . sin ( par1r ) + Math . sin ( par2r ) ) / 2.0 ; 
double c2 = Math . pow ( Math . cos ( par1r ) , 2 ) ; 
C = c2 + 2 * n * Math . sin ( par1r ) ; 
rho0 = computeRho ( lat0 ) ; 
} private double computeRho ( double lat ) { 
return earth_radius * Math . sqrt ( C - 2 * n * Math . sin ( lat ) ) / n ; 
double dlon = LatLonPointImpl . lonNormal ( Math . toDegrees ( lon ) - lon0Degrees ) ; 
} public double getScale ( double lat ) { 
lat = Math . toRadians ( lat ) ; 
double n = Math . cos ( lat ) ; 
double d = Math . sqrt ( C - 2 * n * Math . sin ( lat ) ) ; 
return n / d ; 
fromLon = Math . toRadians ( fromLon ) ; 
double rho = computeRho ( fromLat ) ; 
double theta = computeTheta ( fromLon ) ; 
toX = rho * Math . sin ( theta ) + falseEasting ; 
toY = rho0 - rho * Math . cos ( theta ) + falseNorthing ; 
double fromX = world . getX ( ) - falseEasting ; 
double fromY = world . getY ( ) - falseNorthing ; 
double rrho0 = rho0 ; 
if ( n < 0 ) { 
rrho0 *= - 1.0 ; 
fromX *= - 1.0 ; 
fromY *= - 1.0 ; 
double yd = rrho0 - fromY ; 
double rho = Math . sqrt ( fromX * fromX + yd * yd ) ; 
double theta = Math . atan2 ( fromX , yd ) ; 
rho *= - 1.0 ; 
toLat = Math . toDegrees ( Math . asin ( ( C - Math . pow ( ( rho * n / earth_radius ) , 2 ) ) / ( 2 * n ) ) ) ; 
toLon = Math . toDegrees ( theta / n + lon0 ) ; 
} public float [ ] [ ] projToLatLon ( float [ ] [ ] from , float [ ] [ ] to ) { 
float [ ] fromXA = from [ INDEX_X ] ; 
float [ ] fromYA = from [ INDEX_Y ] ; 
float [ ] toLatA = to [ INDEX_LAT ] ; 
float [ ] toLonA = to [ INDEX_LON ] ; 
double fromX = fromXA [ i ] - falseEasting ; 
double fromY = fromYA [ i ] - falseNorthing ; 
toLat = Math . toDegrees ( Math . asin ( ( C 
- Math . pow ( ( rho * n / earth_radius ) , 2 ) ) / ( 2 * n ) ) ) ; 
toLatA [ i ] = ( float ) toLat ; 
toLonA [ i ] = ( float ) toLon ; 
} public double [ ] [ ] latLonToProj ( double [ ] [ ] from , double [ ] [ ] to , 
int latIndex , int lonIndex ) { 
double [ ] fromLatA = from [ latIndex ] ; 
double [ ] fromLonA = from [ lonIndex ] ; 
double [ ] resultXA = to [ INDEX_X ] ; 
double [ ] resultYA = to [ INDEX_Y ] ; 
toX = rho * Math . sin ( theta ) ; 
toY = rho0 - rho * Math . cos ( theta ) ; 
resultXA [ i ] = toX + falseEasting ; 
resultYA [ i ] = toY + falseNorthing ; 
AlbersEqualArea a = new AlbersEqualArea ( 23 , - 96 , 29.5 , 45.5 ) ; 
System . out . printf ( "name=%s%n" , a . getName ( ) ) ; 
ProjectionPoint p = a . latLonToProj ( 35 , - 75 ) ; 
String s = getValue ( ) ; 
if ( ( s . length ( ) > 0 ) && s . charAt ( s . length ( ) - 1 ) == ( ( char ) 0 ) ) { 
char cArray [ ] = s . toCharArray ( ) ; 
s = new String ( cArray , 0 , cArray . length - 1 ) ; 
pw . print ( "\"" + s + "\"" ) ; 
} public void writeDataset ( InvDataset ds , Element rootElem ) { 
rootElem . addContent ( new Element ( "title" , defNS ) . addContent ( ds . getName ( ) ) ) ; 
rootElem . addContent ( new Element ( "Entry_ID" , defNS ) . addContent ( ds . getUniqueID ( ) ) ) ; 
List < ThreddsMetadata . Vocab > list = ds . getKeywords ( ) ; 
if ( list . size ( ) > 0 ) { 
for ( ThreddsMetadata . Vocab k : list ) { 
rootElem . addContent ( new Element ( "Keyword" , defNS ) . addContent ( k . getText ( ) ) ) ; 
CalendarDateRange tm = ds . getCalendarDateCoverage ( ) ; 
Element tmElem = new Element ( "Temporal_Coverage" , defNS ) ; 
rootElem . addContent ( tmElem ) ; 
tmElem . addContent ( new Element ( "Start_Date" , defNS ) . addContent ( tm . getStart ( ) . toString ( ) ) ) ; 
tmElem . addContent ( new Element ( "End_Date" , defNS ) . addContent ( tm . getEnd ( ) . toString ( ) ) ) ; 
ThreddsMetadata . GeospatialCoverage geo = ds . getGeospatialCoverage ( ) ; 
Element geoElem = new Element ( "Spatial_Coverage" , defNS ) ; 
rootElem . addContent ( geoElem ) ; 
geoElem . addContent ( new Element ( "Southernmost_Latitude" , defNS ) . addContent ( Double . toString ( geo . getLatSouth ( ) ) ) ) ; 
geoElem . addContent ( new Element ( "Northernmost_Latitude" , defNS ) . addContent ( Double . toString ( geo . getLatNorth ( ) ) ) ) ; 
geoElem . addContent ( new Element ( "Westernmost_Latitude" , defNS ) . addContent ( Double . toString ( geo . getLonWest ( ) ) ) ) ; 
geoElem . addContent ( new Element ( "Easternmost_Latitude" , defNS ) . addContent ( Double . toString ( geo . getLonEast ( ) ) ) ) ; 
rootElem . addContent ( new Element ( "Use_Constraints" , defNS ) . addContent ( ds . getDocumentation ( "rights" ) ) ) ; 
List < ThreddsMetadata . Source > slist = ds . getPublishers ( ) ; 
for ( ThreddsMetadata . Source p : slist ) { 
Element dataCenter = new Element ( "Data_Center" , defNS ) ; 
rootElem . addContent ( dataCenter ) ; 
writePublisher ( p , dataCenter ) ; 
rootElem . addContent ( new Element ( "Summary" , defNS ) . addContent ( ds . getDocumentation ( "summary" ) ) ) ; 
Element primaryURLelem = new Element ( "Related_URL" , defNS ) ; 
rootElem . addContent ( primaryURLelem ) ; 
String primaryURL = threddsServerURL + 
"?catalog=" + ( ( InvCatalogImpl ) ds . getParentCatalog ( ) ) . getBaseURI ( ) . toString ( ) + 
"&dataset=" + ds . getID ( ) ; 
primaryURLelem . addContent ( new Element ( "URL" , defNS ) . addContent ( primaryURL ) ) ; 
DateType today = new DateType ( false , new Date ( ) ) ; 
rootElem . addContent ( new Element ( "DIF_Creation_Date" , defNS ) . addContent ( today . toDateTimeStringISO ( ) ) ) ; 
} public static void main ( String [ ] args ) throws Exception { 
InvCatalogFactory catFactory = InvCatalogFactory . getDefaultFactory ( true ) ; 
doOne ( catFactory , "file:///C:/dev/thredds/catalog/test/data/TestHarvest.xml" ) ; 
public boolean isValidFile ( RandomAccessFile raf ) throws IOException { 
gemreader = makeStationReader ( ) ; 
return gemreader . init ( raf , false ) ; 
} catch ( Exception ioe ) { 
if ( gemreader == null ) { 
initTables ( ) ; 
gemreader . init ( raf , true ) ; 
buildNCFile ( ) ; 
ff . format ( "%s" , parseInfo ) ; 
} protected Structure makeStructure ( String partName , List < Dimension > dimensions , boolean includeMissing ) { 
List < GempakParameter > params = gemreader . getParameters ( partName ) ; 
if ( params == null ) { 
Structure sVar = new Structure ( ncfile , null , null , partName ) ; 
sVar . setDimensions ( dimensions ) ; 
for ( GempakParameter param : params ) { 
sVar . addMemberVariable ( makeParamVariable ( param , null ) ) ; 
if ( includeMissing ) { 
sVar . addMemberVariable ( makeMissingVariable ( ) ) ; 
return sVar ; 
} protected Variable makeMissingVariable ( ) { 
Variable var = new Variable ( ncfile , null , null , MISSING_VAR ) ; 
var . setDataType ( DataType . BYTE ) ; 
var . setDimensions ( ( List < Dimension > ) null ) ; 
var . addAttribute ( new Attribute ( CDM . MISSING_VALUE , ( byte ) 1 ) ) ; 
return var ; 
} protected Variable makeParamVariable ( GempakParameter param , List < Dimension > dims ) { 
Variable var = new Variable ( ncfile , null , null , param . getName ( ) ) ; 
var . setDataType ( DataType . FLOAT ) ; 
var . addAttribute ( new Attribute ( CDM . LONG_NAME , param . getDescription ( ) ) ) ; 
String units = param . getUnit ( ) ; 
if ( ( units != null ) && ! units . equals ( "" ) ) { 
var . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; 
var . addAttribute ( new Attribute ( CDM . MISSING_VALUE , RMISS ) ) ; 
} protected void addGlobalAttributes ( ) { 
ncfile . addAttribute ( null , new Attribute ( CDM . CONVENTIONS , getConventions ( ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "file_format" , fileType ) ) ; 
ncfile . addAttribute ( null , new Attribute ( CF . FEATURE_TYPE , getCFFeatureType ( ) ) ) ; 
} protected int getStnVarSize ( String name ) { 
int size = - 1 ; 
for ( int i = 0 ; i < stnVarNames . length ; i ++ ) { 
if ( name . equals ( stnVarNames [ i ] ) ) { 
size = stnVarSizes [ i ] ; 
} protected List < Variable > makeStationVars ( List < GempakStation > stations , Dimension dim ) { 
int numStations = stations . size ( ) ; 
List < Variable > vars = new ArrayList < > ( ) ; 
List < String > stnKeyNames = gemreader . getStationKeyNames ( ) ; 
for ( String varName : stnKeyNames ) { 
Variable v = makeStationVariable ( varName , dim ) ; 
Attribute stIDAttr = new Attribute ( CF . STANDARD_NAME , "station_id" ) ; 
if ( varName . equals ( GempakStation . STID ) ) { 
v . addAttribute ( stIDAttr ) ; 
vars . add ( v ) ; 
if ( ( dim != null ) && ( numStations > 0 ) ) { 
for ( Variable v : vars ) { 
Array varArray ; 
if ( v . getDataType ( ) . equals ( DataType . CHAR ) ) { 
int [ ] shape = v . getShape ( ) ; 
varArray = new ArrayChar . D2 ( shape [ 0 ] , shape [ 1 ] ) ; 
varArray = get1DArray ( v . getDataType ( ) , numStations ) ; 
assert varArray != null ; 
String varname = v . getFullName ( ) ; 
for ( GempakStation stn : stations ) { 
String test = "" ; 
switch ( varname ) { 
case GempakStation . STID : 
test = stn . getName ( ) ; 
case GempakStation . STNM : 
( ( ArrayInt . D1 ) varArray ) . set ( index , stn . getSTNM ( ) ) ; 
case GempakStation . SLAT : 
( ( ArrayFloat . D1 ) varArray ) . set ( index , ( float ) stn . getLatitude ( ) ) ; 
case GempakStation . SLON : 
( ( ArrayFloat . D1 ) varArray ) . set ( index , ( float ) stn . getLongitude ( ) ) ; 
case GempakStation . SELV : 
( ( ArrayFloat . D1 ) varArray ) . set ( index , ( float ) stn . getAltitude ( ) ) ; 
case GempakStation . STAT : 
test = stn . getSTAT ( ) ; 
case GempakStation . COUN : 
test = stn . getCOUN ( ) ; 
case GempakStation . STD2 : 
test = stn . getSTD2 ( ) ; 
case GempakStation . SPRI : 
( ( ArrayInt . D1 ) varArray ) . set ( index , stn . getSPRI ( ) ) ; 
case GempakStation . SWFO : 
test = stn . getSWFO ( ) ; 
case GempakStation . WFO2 : 
test = stn . getWFO2 ( ) ; 
if ( ! test . equals ( "" ) ) { 
( ( ArrayChar . D2 ) varArray ) . setString ( index , test ) ; 
v . setCachedData ( varArray , false ) ; 
} private Array get1DArray ( DataType type , int len ) { 
Array varArray = null ; 
if ( type . equals ( DataType . FLOAT ) ) { 
varArray = new ArrayFloat . D1 ( len ) ; 
} else if ( type . equals ( DataType . DOUBLE ) ) { 
varArray = new ArrayDouble . D1 ( len ) ; 
} else if ( type . equals ( DataType . INT ) ) { 
varArray = new ArrayInt . D1 ( len , false ) ; 
return varArray ; 
} protected Variable makeStationVariable ( String varname , Dimension firstDim ) { 
String longName = varname ; 
DataType type = DataType . CHAR ; 
List < Attribute > attrs = new ArrayList < > ( ) ; 
if ( firstDim != null ) { 
dims . add ( firstDim ) ; 
dims . add ( DIM_LEN8 ) ; 
type = DataType . INT ; 
longName = "latitude" ; 
unit = CDM . LAT_UNITS ; 
type = DataType . FLOAT ; 
attrs . add ( new Attribute ( CF . STANDARD_NAME , "latitude" ) ) ; 
longName = "longitude" ; 
unit = CDM . LON_UNITS ; 
attrs . add ( new Attribute ( CF . STANDARD_NAME , "longitude" ) ) ; 
longName = "altitude" ; 
unit = "meter" ; 
attrs . add ( new Attribute ( CF . POSITIVE , CF . POSITIVE_UP ) ) ; 
attrs . add ( new Attribute ( CF . STANDARD_NAME , CF . STATION_ALTITUDE ) ) ; 
dims . add ( DIM_LEN2 ) ; 
dims . add ( DIM_LEN4 ) ; 
Variable v = new Variable ( ncfile , null , null , varname ) ; 
v . setDataType ( type ) ; 
v . addAttribute ( new Attribute ( CDM . LONG_NAME , longName ) ) ; 
v . addAttribute ( new Attribute ( CDM . UNITS , unit ) ) ; 
v . addAttribute ( new Attribute ( CDM . MISSING_VALUE , RMISS ) ) ; 
v . addAttribute ( new Attribute ( CDM . MISSING_VALUE , IMISS ) ) ; 
if ( ! attrs . isEmpty ( ) ) { 
for ( Attribute attr : attrs ) { 
v . addAttribute ( attr ) ; 
if ( ! dims . isEmpty ( ) ) { 
v . setDimensions ( ( String ) null ) ; 
} private int yy_lr_goto_state_ ( int yystate , int yysym ) 
int yyr = yypgoto_ [ yysym - yyntokens_ ] + yystate ; 
if ( 0 <= yyr && yyr <= yylast_ && yycheck_ [ yyr ] == yystate ) 
return yytable_ [ yyr ] ; 
return yydefgoto_ [ yysym - yyntokens_ ] ; 
} private final String yytnamerr_ ( String yystr ) 
if ( yystr . charAt ( 0 ) == '"' ) 
StringBuffer yyr = new StringBuffer ( ) ; 
strip_quotes : for ( int i = 1 ; i < yystr . length ( ) ; i ++ ) 
switch ( yystr . charAt ( i ) ) 
case ',' : 
break strip_quotes ; 
if ( yystr . charAt ( ++ i ) != '\\' ) 
yyr . append ( yystr . charAt ( i ) ) ; 
return yyr . toString ( ) ; 
else if ( yystr . equals ( "$end" ) ) 
return yystr ; 
} private void yy_symbol_print ( String s , int yytype , 
Object yyvaluep ) 
if ( yydebug > 0 ) 
+ ( yyvaluep == null ? "(null)" : yyvaluep . toString ( ) ) + ")" ) ; 
} public boolean parse ( ) throws ParseException , ParseException 
int yychar = yyempty_ ; 
int yytoken = 0 ; 
int yyn = 0 ; 
int yylen = 0 ; 
int yystate = 0 ; 
YYStack yystack = new YYStack ( ) ; 
int label = YYNEWSTATE ; 
int yynerrs_ = 0 ; 
Object yylval = null ; 
yyerrstatus_ = 0 ; 
yystack . push ( yystate , yylval ) ; 
for ( ; ; ) 
switch ( label ) 
case YYNEWSTATE : 
yystack . print ( yyDebugStream ) ; 
if ( yystate == yyfinal_ ) 
yyn = yypact_ [ yystate ] ; 
if ( yy_pact_value_is_default_ ( yyn ) ) 
label = YYDEFAULT ; 
if ( yychar == yyempty_ ) 
yychar = yylexer . yylex ( ) ; 
yylval = yylexer . getLVal ( ) ; 
if ( yychar <= Lexer . EOF ) 
yychar = yytoken = Lexer . EOF ; 
yytoken = yytranslate_ ( yychar ) ; 
yylval ) ; 
yyn += yytoken ; 
if ( yyn < 0 || yylast_ < yyn || yycheck_ [ yyn ] != yytoken ) 
else if ( ( yyn = yytable_ [ yyn ] ) <= 0 ) 
if ( yy_table_value_is_error_ ( yyn ) ) 
label = YYERRLAB ; 
yyn = - yyn ; 
label = YYREDUCE ; 
yy_symbol_print ( "Shifting" , yytoken , 
yychar = yyempty_ ; 
if ( yyerrstatus_ > 0 ) 
-- yyerrstatus_ ; 
yystate = yyn ; 
label = YYNEWSTATE ; 
case YYDEFAULT : 
yyn = yydefact_ [ yystate ] ; 
if ( yyn == 0 ) 
case YYREDUCE : 
yylen = yyr2_ [ yyn ] ; 
label = yyaction ( yyn , yystack , yylen ) ; 
yystate = yystack . stateAt ( 0 ) ; 
case YYERRLAB : 
if ( yyerrstatus_ == 0 ) 
++ yynerrs_ ; 
yytoken = yyempty_ ; 
yyerror ( yysyntax_error ( yystate , yytoken ) ) ; 
if ( yyerrstatus_ == 3 ) 
if ( yychar == Lexer . EOF ) 
label = YYERRLAB1 ; 
case YYERROR : 
yystack . pop ( yylen ) ; 
yylen = 0 ; 
case YYERRLAB1 : 
yyerrstatus_ = 3 ; 
if ( ! yy_pact_value_is_default_ ( yyn ) ) 
yyn += yyterror_ ; 
if ( 0 <= yyn && yyn <= yylast_ && yycheck_ [ yyn ] == yyterror_ ) 
yyn = yytable_ [ yyn ] ; 
if ( 0 < yyn ) 
if ( yystack . height == 0 ) 
yystack . pop ( ) ; 
if ( label == YYABORT ) 
yy_symbol_print ( "Shifting" , yystos_ [ yyn ] , 
yystack . push ( yyn , yylval ) ; 
case YYACCEPT : 
case YYABORT : 
} private String yysyntax_error ( int yystate , int tok ) 
if ( yyErrorVerbose ) 
if ( tok != yyempty_ ) 
StringBuffer res = 
res . append ( yytnamerr_ ( yytname_ [ tok ] ) ) ; 
int yyn = yypact_ [ yystate ] ; 
int yyxbegin = yyn < 0 ? - yyn : 0 ; 
int yychecklim = yylast_ - yyn + 1 ; 
int yyxend = yychecklim < yyntokens_ ? yychecklim : yyntokens_ ; 
for ( int x = yyxbegin ; x < yyxend ; ++ x ) 
if ( yycheck_ [ x + yyn ] == x && x != yyterror_ 
&& ! yy_table_value_is_error_ ( yytable_ [ x + yyn ] ) ) 
++ count ; 
if ( count < 5 ) 
res . append ( yytnamerr_ ( yytname_ [ x ] ) ) ; 
return res . toString ( ) ; 
} private void yy_reduce_print ( int yyrule , YYStack yystack ) 
if ( yydebug == 0 ) 
int yylno = yyrline_ [ yyrule ] ; 
int yynrhs = yyr2_ [ yyrule ] ; 
for ( int yyi = 0 ; yyi < yynrhs ; yyi ++ ) 
yystos_ [ yystack . stateAt ( yynrhs - ( yyi + 1 ) ) ] , 
( ( yystack . valueAt ( yynrhs - ( yyi + 1 ) ) ) ) ) ; 
} boolean parse ( String constraint ) throws ParseException 
( ( Celex ) yylexer ) . reset ( parsestate , constraint ) ; 
return parse ( ) ; 
} static public boolean constraint_expression ( CEEvaluator ceEval , 
BaseTypeFactory factory , 
ClauseFactory clauseFactory , 
String constraint , 
String url 
throws DAP2Exception , ParseException 
CeParser parser = new CeParser ( factory ) ; 
parser . setURL ( url ) ; 
parser . setConstraint ( constraint ) ; 
ServerDDS sdds = ceEval . getDDS ( ) ; 
if ( ! parser . parse ( constraint ) ) return false ; 
ASTconstraint root = ( ASTconstraint ) parser . getAST ( ) ; 
root . init ( ceEval , factory , clauseFactory , sdds , parser . getASTnodeset ( ) ) ; 
root . walkConstraint ( ) ; 
} public final int 
compareTo ( Object obj ) 
String thatID = ( ( PrefixSymbol ) obj ) . getID ( ) ; 
int comp = thatID . length ( ) - getID ( ) . length ( ) ; 
if ( comp == 0 ) 
comp = getID ( ) . compareTo ( thatID ) ; 
return comp ; 
compareTo ( String string ) 
int comp = string . length ( ) - getID ( ) . length ( ) ; 
return comp < 0 
? comp 
: comp == 0 
? ( getID ( ) . compareTo ( string ) == 0 ? 0 : - 1 ) 
: ( getID ( ) . compareTo ( string . substring ( 0 , getID ( ) . length ( ) ) ) 
== 0 
: - 1 ) ; 
} public String 
readDMR ( ) 
if ( state != State . INITIAL ) 
byte [ ] dmr8 = null ; 
if ( requestmode == RequestMode . DMR ) { 
ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; 
int c ; 
while ( ( c = input . read ( ) ) >= 0 ) { 
baos . write ( c ) ; 
dmr8 = baos . toByteArray ( ) ; 
} else if ( requestmode == RequestMode . DAP ) { 
if ( ! readHeader ( input ) ) 
dmr8 = new byte [ this . chunksize ] ; 
int red = read ( dmr8 , 0 , this . chunksize ) ; 
if ( red < this . chunksize ) 
String dmr = new String ( dmr8 , DapUtil . UTF8 ) ; 
dmr = dmr . trim ( ) ; 
if ( dmr . endsWith ( "\r\n" ) ) { 
} else if ( dmr . endsWith ( "\n" ) ) 
dmr = dmr . substring ( 0 , dmr . length ( ) - 2 ) + "\r\n" ; 
dmr = dmr + "\r\n" ; 
this . remoteorder = ( flags & DapUtil . CHUNK_LITTLE_ENDIAN ) == 0 ? ByteOrder . BIG_ENDIAN 
: ByteOrder . LITTLE_ENDIAN ; 
this . nochecksum = ( flags & DapUtil . CHUNK_NOCHECKSUM ) != 0 ; 
if ( ( flags & DapUtil . CHUNK_ERROR ) != 0 ) 
state = State . ERROR ; 
else if ( ( flags & DapUtil . CHUNK_END ) != 0 ) 
state = State . END ; 
state = State . DATA ; 
return dmr ; 
throw new DapException ( ioe . getMessage ( ) ) ; 
readError ( ) 
byte [ ] bytes = new byte [ this . chunksize ] ; 
if ( read ( bytes , 0 , this . chunksize ) < this . chunksize ) 
throw new ErrorException ( ioe ) ; 
String document = new String ( bytes , DapUtil . UTF8 ) ; 
read ( ) 
if ( requestmode == RequestMode . DMR ) 
if ( avail <= 0 ) { 
if ( ( flags & DapUtil . CHUNK_END ) != 0 ) 
if ( ( flags & DapUtil . CHUNK_ERROR ) != 0 ) { 
String document = readError ( ) ; 
throwError ( document ) ; 
avail -- ; 
return input . read ( ) ; 
read ( byte [ ] buf , int off , int len ) 
if ( off < 0 || len < 0 ) 
throw new IndexOutOfBoundsException ( ) ; 
if ( off >= buf . length || buf . length < ( off + len ) ) 
int count = len ; 
int pos = off ; 
while ( count > 0 ) { 
if ( ( flags & DapUtil . CHUNK_END ) != 0 
|| ! readHeader ( input ) ) 
return ( len - count ) ; 
int actual = ( this . avail < count ? this . avail : count ) ; 
int red = input . read ( buf , pos , actual ) ; 
if ( red < 0 ) 
pos += red ; 
count -= red ; 
this . avail -= red ; 
} boolean 
readHeader ( InputStream input ) 
byte [ ] bytehdr = new byte [ 4 ] ; 
int red = input . read ( bytehdr ) ; 
if ( red == - 1 ) return false ; 
if ( red < 4 ) 
this . flags = ( ( int ) bytehdr [ 0 ] ) & 0xFF ; 
bytehdr [ 0 ] = 0 ; 
ByteBuffer buf = ByteBuffer . wrap ( bytehdr ) . order ( ByteOrder . BIG_ENDIAN ) ; 
this . chunksize = buf . getInt ( ) ; 
this . avail = this . chunksize ; 
} static private void init ( Map < Short , CodeFlagTables > table ) { 
String filename = BufrTables . RESOURCE_PATH + CodeFlagFilename ; 
try ( InputStream is = CodeFlagTables . class . getResourceAsStream ( filename ) ) { 
org . jdom2 . Document tdoc = builder . build ( is ) ; 
org . jdom2 . Element root = tdoc . getRootElement ( ) ; 
List < Element > elems = root . getChildren ( ) ; 
for ( Element elem : elems ) { 
String fxyS = elem . getChildText ( "FXY" ) ; 
String desc = elem . getChildText ( "ElementName_en" ) ; 
short fxy = Descriptor . getFxy2 ( fxyS ) ; 
CodeFlagTables ct = table . get ( fxy ) ; 
if ( ct == null ) { 
ct = new CodeFlagTables ( fxy , desc ) ; 
table . put ( fxy , ct ) ; 
String line = elem . getChildText ( "No" ) ; 
String codeS = elem . getChildText ( "CodeFigure" ) ; 
String value = elem . getChildText ( "EntryName_en" ) ; 
if ( ( codeS == null ) || ( value == null ) ) continue ; 
if ( value . toLowerCase ( ) . startsWith ( "reserved" ) ) continue ; 
int code ; 
if ( codeS . toLowerCase ( ) . contains ( "all" ) ) { 
code = - 1 ; 
} else try { 
code = Integer . parseInt ( codeS ) ; 
ct . addValue ( ( short ) code , value ) ; 
} static public String toDateTimeStringISO ( CalendarDate cd ) { 
if ( cd . getDateTime ( ) . getMillisOfSecond ( ) == 0 ) 
return isof . print ( cd . getDateTime ( ) ) ; 
return isof_with_millis_of_second . print ( cd . getDateTime ( ) ) ; 
static public Date parseISODate ( String iso ) { 
DateFormatter df = new DateFormatter ( ) ; 
return df . getISODate ( iso ) ; 
} static public CalendarDate isoStringToCalendarDate ( Calendar calt , String iso ) throws IllegalArgumentException { 
DateTime dt = parseIsoTimeString ( calt , iso ) ; 
Calendar useCal = Calendar . of ( dt . getChronology ( ) ) ; 
return new CalendarDate ( useCal , dt ) ; 
} static public Date isoStringToDate ( String iso ) throws IllegalArgumentException { 
CalendarDate dt = isoStringToCalendarDate ( null , iso ) ; 
return dt . toDate ( ) ; 
} public static MeasureTVPType initMeasurementTVP ( MeasureTVPType measurementTVP , PointFeature pointFeat , 
VariableSimpleIF dataVar ) throws IOException { 
NcTimePositionType . initTime ( measurementTVP . addNewTime ( ) , pointFeat ) ; 
NcMeasureType . initValue ( measurementTVP . addNewValue ( ) , pointFeat , dataVar ) ; 
return measurementTVP ; 
} static public List < Record > readTable ( String urlString , String format , int maxLines ) throws IOException , NumberFormatException { 
InputStream ios ; 
if ( urlString . startsWith ( "http:" ) ) { 
URL url = new URL ( urlString ) ; 
ios = url . openStream ( ) ; 
ios = new FileInputStream ( urlString ) ; 
return readTable ( ios , format , maxLines ) ; 
} static public List < Record > readTable ( InputStream ios , String format , int maxLines ) throws IOException , NumberFormatException { 
List < Record > result ; 
TableParser parser = new TableParser ( format ) ; 
result = parser . readAllRecords ( ios , maxLines ) ; 
ios . close ( ) ; 
} static public void transferDataset ( NetcdfFile src , NetcdfDataset target , ReplaceVariableCheck replaceCheck ) { 
transferGroup ( src , target , src . getRootGroup ( ) , target . getRootGroup ( ) , replaceCheck ) ; 
} static private void transferGroup ( NetcdfFile ds , NetcdfDataset targetDs , Group src , Group targetGroup , ReplaceVariableCheck replaceCheck ) { 
boolean unlimitedOK = true ; 
transferGroupAttributes ( src , targetGroup ) ; 
for ( Dimension d : src . getDimensions ( ) ) { 
if ( null == targetGroup . findDimensionLocal ( d . getShortName ( ) ) ) { 
Dimension newd = new Dimension ( d . getShortName ( ) , d . getLength ( ) , d . isShared ( ) , unlimitedOK && d . isUnlimited ( ) , d . isVariableLength ( ) ) ; 
targetGroup . addDimension ( newd ) ; 
for ( Variable v : src . getVariables ( ) ) { 
Variable targetV = targetGroup . findVariable ( v . getShortName ( ) ) ; 
VariableEnhanced targetVe = ( VariableEnhanced ) targetV ; 
boolean replace = ( replaceCheck != null ) && replaceCheck . replace ( v ) ; 
if ( replace || ( null == targetV ) ) { 
if ( ( v instanceof Structure ) && ! ( v instanceof StructureDS ) ) { 
v = new StructureDS ( targetGroup , ( Structure ) v ) ; 
} else if ( ! ( v instanceof VariableDS ) ) { 
v = new VariableDS ( targetGroup , v , false ) ; 
if ( null != targetV ) targetGroup . remove ( targetV ) ; 
targetGroup . addVariable ( v ) ; 
v . resetDimensions ( ) ; 
} else if ( ! targetV . hasCachedData ( ) && ( targetVe . getOriginalVariable ( ) == null ) ) { 
targetVe . setOriginalVariable ( v ) ; 
for ( Group srcNested : src . getGroups ( ) ) { 
Group nested = targetGroup . findGroup ( srcNested . getShortName ( ) ) ; 
if ( null == nested ) { 
nested = new Group ( ds , targetGroup , srcNested . getShortName ( ) ) ; 
targetGroup . addGroup ( nested ) ; 
transferGroup ( ds , targetDs , srcNested , nested , replaceCheck ) ; 
} static public void transferVariableAttributes ( Variable src , Variable target ) { 
for ( Attribute a : src . getAttributes ( ) ) { 
if ( null == target . findAttribute ( a . getShortName ( ) ) ) 
target . addAttribute ( a ) ; 
} static public void transferGroupAttributes ( Group src , Group target ) { 
} static public Group findGroup ( NetcdfFile newFile , Group oldGroup ) { 
List < Group > chain = new ArrayList < > ( 5 ) ; 
Group g = oldGroup ; 
while ( g . getParentGroup ( ) != null ) { 
chain . add ( 0 , g ) ; 
g = g . getParentGroup ( ) ; 
Group newg = newFile . getRootGroup ( ) ; 
for ( Group oldg : chain ) { 
newg = newg . findGroup ( oldg . getShortName ( ) ) ; 
if ( newg == null ) return null ; 
return newg ; 
} private File getStnFile ( String location ) { 
File file = new File ( location ) ; 
File stnFile = new File ( file . getParentFile ( ) , STN_FILE ) ; 
if ( ! stnFile . exists ( ) ) { 
if ( file . getParentFile ( ) == null ) return null ; 
stnFile = new File ( file . getParentFile ( ) . getParentFile ( ) , STN_FILE ) ; 
if ( ! stnFile . exists ( ) ) return null ; 
return stnFile ; 
public void open ( RandomAccessFile raff , NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { 
super . open ( raff , ncfile , cancelTask ) ; 
int pos = location . lastIndexOf ( "." ) ; 
String ext = location . substring ( pos ) ; 
File stnFile = getStnFile ( location ) ; 
if ( stnFile == null ) 
if ( ext . equals ( IDX_EXT ) ) { 
stnRaf = RandomAccessFile . acquire ( stnFile . getPath ( ) ) ; 
} else if ( ext . equals ( DAT_EXT ) ) { 
dataRaf = raff ; 
String name = file . getName ( ) ; 
stationId = name . substring ( 0 , name . length ( ) - DAT_EXT . length ( ) ) ; 
stnRaf = raff ; 
dataDir = new File ( file . getParentFile ( ) , DAT_DIR ) ; 
NcmlConstructor ncmlc = new NcmlConstructor ( ) ; 
if ( ! ncmlc . populateFromResource ( "resources/nj22/iosp/igra-por.ncml" , ncfile ) ) { 
throw new IllegalStateException ( ncmlc . getErrlog ( ) . toString ( ) ) ; 
stnVinfo = setVinfo ( stnRaf , ncfile , stnPattern , "station" ) ; 
seriesVinfo = setVinfo ( stnRaf , ncfile , dataHeaderPattern , "station.time_series" ) ; 
profileVinfo = setVinfo ( stnRaf , ncfile , dataPattern , "station.time_series.levels" ) ; 
StructureMembers . Member m = stnVinfo . sm . findMember ( STNID ) ; 
StructureDataRegexp . VinfoField f = ( StructureDataRegexp . VinfoField ) m . getDataObject ( ) ; 
stn_fldno = f . fldno ; 
StructureDataRegexp . Vinfo vinfo = ( StructureDataRegexp . Vinfo ) v2 . getSPobject ( ) ; 
if ( stationId != null ) 
return new ArraySequence ( vinfo . sm , new SingleStationSeqIter ( vinfo ) , vinfo . nelems ) ; 
return new ArraySequence ( vinfo . sm , new StationSeqIter ( vinfo ) , vinfo . nelems ) ; 
} public SubsetParams makeSubset ( CoverageCollection gcd ) { 
Calendar cal = gcd . getCalendar ( ) ; 
boolean isFmrc = gcd . getCoverageType ( ) == FeatureType . FMRC ; 
if ( vertCoord != null ) 
subset . set ( SubsetParams . vertCoord , vertCoord ) ; 
if ( ensCoord != null ) 
subset . set ( SubsetParams . ensCoord , ensCoord ) ; 
if ( hasProjectionBB ( ) ) 
subset . set ( SubsetParams . projBB , getProjectionBB ( ) ) ; 
if ( horizStride != null && horizStride != 1 ) 
subset . set ( SubsetParams . horizStride , horizStride ) ; 
if ( hasLatLonPoint ( ) ) 
if ( isFmrc ) { 
CalendarDate rundate = getRuntimeDate ( cal ) ; 
if ( rundate != null ) 
subset . set ( SubsetParams . runtime , rundate ) ; 
else if ( allRuntime ) 
subset . set ( SubsetParams . runtimeAll , true ) ; 
subset . set ( SubsetParams . runtimeLatest , true ) ; 
if ( timeOffsetVal != null ) 
subset . set ( SubsetParams . timeOffset , timeOffsetVal ) ; 
else if ( firstTimeOffset ) 
subset . set ( SubsetParams . timeOffsetFirst , true ) ; 
CalendarDate date = getRequestedDate ( cal ) ; 
CalendarDateRange dateRange = getCalendarDateRange ( cal ) ; 
if ( isPresentTime ( ) ) 
subset . setTimePresent ( ) ; 
else if ( isAllTimes ( ) && ! allRuntime ) { 
if ( timeStride != null && timeStride != 1 ) 
subset . set ( SubsetParams . timeStride , timeStride ) ; 
} else if ( dateRange != null && ! allRuntime ) { 
else if ( isAllTimes ( ) ) { 
} public static int indexOf ( char [ ] cArray , char c , int fromIndex ) { 
int cArrayLength = cArray . length ; 
for ( int index = Math . max ( fromIndex , 0 ) ; index < cArrayLength ; index ++ ) { 
if ( cArray [ index ] == c ) 
} public static boolean isLetter ( int c ) { 
if ( c < 'A' ) return false ; 
if ( c <= 'Z' ) return true ; 
if ( c < 'a' ) return false ; 
if ( c <= 'z' ) return true ; 
if ( c < 'À' ) return false ; 
if ( c == '×' ) return false ; 
if ( c <= 'ÿ' ) return true ; 
} public static String replaceAll ( String s , char oldCh , char newCh ) { 
int po = s . indexOf ( oldCh ) ; 
if ( po < 0 ) 
StringBuilder buffer = new StringBuilder ( s ) ; 
while ( po >= 0 ) { 
buffer . setCharAt ( po , newCh ) ; 
po = s . indexOf ( oldCh , po + 1 ) ; 
} public static int parseInt ( String s ) { 
return Integer . MAX_VALUE ; 
if ( s . length ( ) == 0 ) 
char ch = s . charAt ( 0 ) ; 
if ( ( ch < '0' || ch > '9' ) && ch != '-' && ch != '+' && ch != '.' ) 
if ( s . startsWith ( "0x" ) ) 
return Integer . parseInt ( s . substring ( 2 ) , 16 ) ; 
return Integer . parseInt ( s ) ; 
return ErddapMath2 . roundToInt ( Double . parseDouble ( s ) ) ; 
} public static double parseDouble ( String s ) { 
return Double . parseDouble ( s ) ; 
} public static long parseLong ( String s ) { 
if ( ( ch < '0' || ch > '9' ) && ch != '-' && ch != '+' ) 
return Long . parseLong ( s . substring ( 2 ) , 16 ) ; 
return Long . parseLong ( s ) ; 
} public static int [ ] toRational ( double d ) { 
if ( d == 0 ) 
return new int [ ] { 0 , 0 } ; 
if ( ! ErddapMath2 . isFinite ( d ) ) 
return new int [ ] { 1 , Integer . MAX_VALUE } ; 
String s = "" + d ; 
int ten = 0 ; 
int epo = s . indexOf ( 'E' ) ; 
if ( epo > 0 ) { 
ten = parseInt ( s . substring ( epo + 1 ) ) ; 
s = s . substring ( 0 , epo ) ; 
if ( s . endsWith ( ".0" ) ) 
s = s . substring ( 0 , s . length ( ) - 2 ) ; 
int dpo = s . indexOf ( '.' ) ; 
if ( dpo > 0 ) { 
ten -= s . length ( ) - dpo - 1 ; 
s = s . substring ( 0 , dpo ) + s . substring ( dpo + 1 ) ; 
long tl = parseLong ( s ) ; 
while ( Math . abs ( tl ) > 1000000000 ) { 
tl = Math . round ( tl / 10.0 ) ; 
ten ++ ; 
while ( tl != 0 && tl / 10 == tl / 10.0 ) { 
tl /= 10 ; 
if ( tl < 100000 && ten >= 1 && ten <= 3 ) { 
while ( ten > 0 ) { 
tl *= 10 ; 
ten -- ; 
return new int [ ] { ( int ) tl , ten } ; 
} public int getBeginning ( int index ) { 
if ( index == ( pastIndex + 1 ) ) 
return previousEnd + 1 ; 
int newBeginning = 0 ; 
newBeginning += getNodeCount ( i ) ; 
pastIndex = index ; 
previousBegin = newBeginning ; 
return newBeginning ; 
} public int getEnd ( int index ) { 
if ( index == ( pastIndex - 1 ) ) 
return previousBegin - 1 ; 
int new_end = 0 ; 
for ( int i = 0 ; i < index + 1 ; i ++ ) { 
new_end += getNodeCount ( i ) ; 
previousEnd = new_end ; 
return new_end - 1 ; 
} public void sendASCII ( ReqState rs , 
String dataSet ) 
if ( Debug . isSet ( "showResponse" ) ) 
String requestURL , ce ; 
DataDDS dds ; 
if ( rs . getConstraintExpression ( ) == null ) { 
ce = "?" + rs . getConstraintExpression ( ) ; 
int suffixIndex = rs . getRequestURL ( ) . toString ( ) . lastIndexOf ( "." ) ; 
requestURL = rs . getRequestURL ( ) . substring ( 0 , suffixIndex ) ; 
if ( Debug . isSet ( "showResponse" ) ) { 
try ( DConnect2 url = new DConnect2 ( requestURL , true ) ) { 
dds = url . getData ( ce , null , new asciiFactory ( ) ) ; 
if ( _Debug ) dds . print ( System . out ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( rs . getResponse ( ) . getOutputStream ( ) , Util . UTF8 ) ) ; 
PrintWriter pwDebug = new PrintWriter ( new OutputStreamWriter ( System . out , Util . UTF8 ) ) ; 
if ( dds != null ) { 
dds . print ( pw ) ; 
pw . println ( "---------------------------------------------" ) ; 
String s = "" ; 
if ( _Debug ) ( ( toASCII ) bt ) . toASCII ( pwDebug , true , null , true ) ; 
( ( toASCII ) bt ) . toASCII ( pw , true , null , true ) ; 
String betterURL = rs . getRequestURL ( ) . substring ( 0 , rs . getRequestURL ( ) . lastIndexOf ( "." ) ) + 
".dods?" + rs . getConstraintExpression ( ) ; 
pw . println ( "" ) ; 
if ( _Debug ) pwDebug . flush ( ) ; 
catch ( FileNotFoundException fnfe ) { 
fnfe . printStackTrace ( System . out ) ; 
catch ( MalformedURLException mue ) { 
mue . printStackTrace ( System . out ) ; 
catch ( Throwable t ) { 
t . printStackTrace ( System . out ) ; 
} boolean createIndex ( FeatureCollectionConfig . PartitionType ptype , Formatter errlog ) throws IOException { 
if ( ptype == FeatureCollectionConfig . PartitionType . all ) 
return createAllRuntimeCollections ( errlog ) ; 
return createMultipleRuntimeCollections ( errlog ) ; 
} private boolean createMultipleRuntimeCollections ( Formatter errlog ) throws IOException { 
List < MFile > files = new ArrayList < > ( ) ; 
List < ? extends Group > groups = makeGroups ( files , false , errlog ) ; 
List < MFile > allFiles = Collections . unmodifiableList ( files ) ; 
if ( allFiles . size ( ) == 0 ) { 
if ( groups . size ( ) == 0 ) { 
CalendarDateRange calendarDateRangeAll = null ; 
boolean allTimesAreUnique = true ; 
Set < Long > allRuntimes = new HashSet < > ( ) ; 
for ( Group g : groups ) { 
allRuntimes . addAll ( g . getCoordinateRuntimes ( ) ) ; 
for ( Coordinate coord : g . getCoordinates ( ) ) { 
if ( coord instanceof CoordinateTime2D ) { 
CoordinateTime2D coord2D = ( CoordinateTime2D ) coord ; 
if ( allTimesAreUnique ) { 
allTimesAreUnique = coord2D . hasUniqueTimes ( ) ; 
if ( coord instanceof CoordinateTimeAbstract ) { 
CalendarDateRange calendarDateRange = ( ( CoordinateTimeAbstract ) coord ) . makeCalendarDateRange ( null ) ; 
if ( calendarDateRangeAll == null ) calendarDateRangeAll = calendarDateRange ; 
else calendarDateRangeAll = calendarDateRangeAll . extend ( calendarDateRange ) ; 
List < Long > sortedList = new ArrayList < > ( allRuntimes ) ; 
Collections . sort ( sortedList ) ; 
if ( sortedList . size ( ) == 0 ) 
else if ( sortedList . size ( ) == 1 ) 
this . type = GribCollectionImmutable . Type . SRC ; 
else if ( allTimesAreUnique ) 
this . type = GribCollectionImmutable . Type . MRUTC ; 
this . type = GribCollectionImmutable . Type . MRC ; 
CoordinateRuntime masterRuntimes = new CoordinateRuntime ( sortedList , null ) ; 
MFile indexFileForRuntime = GribCollectionMutable . makeIndexMFile ( this . name , directory ) ; 
boolean ok = writeIndex ( this . name , indexFileForRuntime . getPath ( ) , masterRuntimes , groups , allFiles , calendarDateRangeAll ) ; 
} private boolean createAllRuntimeCollections ( Formatter errlog ) throws IOException { 
List < ? extends Group > groups = makeGroups ( files , true , errlog ) ; 
Map < Long , List < Group > > runGroups = new HashMap < > ( ) ; 
List < Group > runGroup = runGroups 
. computeIfAbsent ( g . getRuntime ( ) . getMillis ( ) , k -> new ArrayList < > ( ) ) ; 
runGroup . add ( g ) ; 
boolean multipleRuntimes = runGroups . values ( ) . size ( ) > 1 ; 
List < MFile > partitions = new ArrayList < > ( ) ; 
for ( List < Group > runGroupList : runGroups . values ( ) ) { 
Group g = runGroupList . get ( 0 ) ; 
String gcname = multipleRuntimes ? GribCollectionMutable . makeName ( this . name , g . getRuntime ( ) ) : this . name ; 
MFile indexFileForRuntime = GribCollectionMutable . makeIndexMFile ( gcname , directory ) ; 
partitions . add ( indexFileForRuntime ) ; 
List < Long > runtimes = new ArrayList < > ( 1 ) ; 
runtimes . add ( g . getRuntime ( ) . getMillis ( ) ) ; 
CoordinateRuntime masterRuntimes = new CoordinateRuntime ( runtimes , null ) ; 
assert calendarDateRangeAll != null ; 
ok &= writeIndex ( gcname , indexFileForRuntime . getPath ( ) , masterRuntimes , runGroupList , allFiles , calendarDateRangeAll ) ; 
if ( multipleRuntimes ) { 
Collections . sort ( partitions ) ; 
PartitionManager part = new PartitionManagerFromIndexList ( dcm , partitions , logger ) ; 
part . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , dcm . getAuxInfo ( FeatureCollectionConfig . AUX_CONFIG ) ) ; 
ok &= GribCdmIndex . updateGribCollectionFromPCollection ( isGrib1 , part , CollectionUpdateType . always , errlog , logger ) ; 
} protected boolean _validate ( StringBuffer buff ) { 
String editValue = tf . getText ( ) . trim ( ) ; 
if ( editValue . length ( ) == 0 ) return true ; 
new TimeDuration ( tf . getText ( ) ) ; 
} catch ( java . text . ParseException e ) { 
} protected Object getEditValue ( ) { 
if ( editValue . length ( ) == 0 ) return null ; 
return new TimeDuration ( editValue ) ; 
} protected void setEditValue ( Object value ) { 
tf . setText ( "" ) ; 
tf . setText ( value . toString ( ) ) ; 
} DataType getDataType ( int format ) { 
DataType p ; 
switch ( format ) { 
p = DataType . SHORT ; 
p = DataType . FLOAT ; 
p = DataType . LONG ; 
p = DataType . DOUBLE ; 
p = null ; 
} public void augmentDataset ( NetcdfDataset ds , 
CancelTask cancelTask ) throws IOException { 
Attribute leoAtt = ds . findGlobalAttribute ( "leoId" ) ; 
if ( leoAtt == null ) { 
if ( ds . findVariable ( "time" ) == null ) { 
double start = ds . readAttributeDouble ( null , "start_time" , 
Double . NaN ) ; 
double stop = ds . readAttributeDouble ( null , "stop_time" , 
if ( Double . isNaN ( start ) && Double . isNaN ( stop ) ) { 
double top = ds . readAttributeDouble ( null , "toptime" , 
double bot = ds . readAttributeDouble ( null , "bottime" , 
this . conventionName = "Cosmic2" ; 
if ( top > bot ) { 
stop = top ; 
start = bot ; 
stop = bot ; 
start = top ; 
Dimension dim = ds . findDimension ( "MSL_alt" ) ; 
Variable dimV = ds . findVariable ( "MSL_alt" ) ; 
Array dimU = dimV . read ( ) ; 
int inscr = ( dimU . getFloat ( 1 ) - dimU . getFloat ( 0 ) ) > 0 
: 0 ; 
int n = dim . getLength ( ) ; 
double incr = ( stop - start ) / n ; 
Variable timeVar = new VariableDS ( ds , null , null , "time" , 
DataType . DOUBLE , dim . getShortName ( ) , 
timeUnits , null ) ; 
ds . addVariable ( null , timeVar ) ; 
timeVar . addAttribute ( new Attribute ( CDM . UNITS , timeUnits ) ) ; 
timeVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
AxisType . Time . toString ( ) ) ) ; 
int dir = ds . readAttributeInteger ( null , "irs" , 1 ) ; 
ArrayDouble . D1 data = 
( ArrayDouble . D1 ) Array . factory ( DataType . DOUBLE , 
new int [ ] { n } ) ; 
if ( inscr == 0 ) { 
if ( dir == 1 ) { 
data . set ( i , start + i * incr ) ; 
data . set ( i , stop - i * incr ) ; 
timeVar . setCachedData ( data , false ) ; 
Variable v = ds . findVariable ( "Lat" ) ; 
v = ds . findVariable ( "GEO_lat" ) ; 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , 
AxisType . Lat . toString ( ) ) ) ; 
Variable v1 = ds . findVariable ( "Lon" ) ; 
if ( v1 == null ) { 
v1 = ds . findVariable ( "GEO_lon" ) ; 
v1 . addAttribute ( new Attribute ( _Coordinate . AxisType , 
AxisType . Lon . toString ( ) ) ) ; 
Dimension dim = ds . findDimension ( "time" ) ; 
Variable latVar = new VariableDS ( ds , null , null , "Lat" , 
DataType . FLOAT , dim . getShortName ( ) , 
"degree" , null ) ; 
latVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
ds . addVariable ( null , latVar ) ; 
Variable lonVar = new VariableDS ( ds , null , null , "Lon" , 
lonVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
ds . addVariable ( null , lonVar ) ; 
Variable altVar = new VariableDS ( ds , null , null , "MSL_alt" , 
"meter" , null ) ; 
altVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
AxisType . Height . toString ( ) ) ) ; 
ds . addVariable ( null , altVar ) ; 
ArrayFloat . D1 latData = 
( ArrayFloat . D1 ) Array . factory ( DataType . FLOAT , 
ArrayFloat . D1 lonData = 
ArrayFloat . D1 altData = 
ArrayDouble . D1 timeData = 
this . conventionName = "Cosmic3" ; 
int iyr = ds . readAttributeInteger ( null , "year" , 2009 ) ; 
int mon = ds . readAttributeInteger ( null , "month" , 0 ) ; 
int iday = ds . readAttributeInteger ( null , "day" , 0 ) ; 
int ihr = ds . readAttributeInteger ( null , "hour" , 0 ) ; 
int min = ds . readAttributeInteger ( null , "minute" , 0 ) ; 
int sec = ds . readAttributeInteger ( null , "second" , 0 ) ; 
double start = ds . readAttributeDouble ( null , "startTime" , 
double stop = ds . readAttributeDouble ( null , "stopTime" , 
int t = 0 ; 
double dtheta = gast ( iyr , mon , iday , ihr , min , sec , t ) ; 
Variable tVar = ds . findVariable ( "time" ) ; 
tVar . removeAttributeIgnoreCase ( CDM . VALID_RANGE ) ; 
tVar . removeAttributeIgnoreCase ( CDM . UNITS ) ; 
tVar . addAttribute ( new Attribute ( CDM . UNITS , timeUnits ) ) ; 
tVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
Variable v = ds . findVariable ( "xLeo" ) ; 
Array xLeo = v . read ( ) ; 
v = ds . findVariable ( "yLeo" ) ; 
Array yLeo = v . read ( ) ; 
v = ds . findVariable ( "zLeo" ) ; 
Array zLeo = v . read ( ) ; 
double a = 6378.1370 ; 
double b = 6356.7523142 ; 
IndexIterator iiter0 = xLeo . getIndexIterator ( ) ; 
IndexIterator iiter1 = yLeo . getIndexIterator ( ) ; 
IndexIterator iiter2 = zLeo . getIndexIterator ( ) ; 
while ( iiter0 . hasNext ( ) ) { 
double [ ] v_inertial = new double [ 3 ] ; 
v_inertial [ 0 ] = iiter0 . getDoubleNext ( ) ; 
v_inertial [ 1 ] = iiter1 . getDoubleNext ( ) ; 
v_inertial [ 2 ] = iiter2 . getDoubleNext ( ) ; 
double [ ] uvz = new double [ 3 ] ; 
uvz [ 0 ] = 0.0 ; 
uvz [ 1 ] = 0.0 ; 
uvz [ 2 ] = 1.0 ; 
double [ ] v_ecf = spin ( v_inertial , uvz , - 1 * dtheta ) ; 
double [ ] llh = xyzell ( a , b , v_ecf ) ; 
latData . set ( i , ( float ) llh [ 0 ] ) ; 
lonData . set ( i , ( float ) llh [ 1 ] ) ; 
altData . set ( i , ( float ) llh [ 2 ] ) ; 
timeData . set ( i , start + i * incr ) ; 
latVar . setCachedData ( latData , false ) ; 
lonVar . setCachedData ( lonData , false ) ; 
altVar . setCachedData ( altData , false ) ; 
tVar . setCachedData ( timeData , false ) ; 
} public double [ ] xyzell ( double a , double b , double [ ] xstat ) { 
double [ ] xstell = new double [ 3 ] ; 
double e2 , s , rlam , zps , h , phi , n , hp , phip ; 
int i , niter ; 
e2 = ( a * a - b * b ) / ( a * a ) ; 
s = Math . sqrt ( xstat [ 0 ] * xstat [ 0 ] + xstat [ 1 ] * xstat [ 1 ] ) ; 
rlam = Math . atan2 ( xstat [ 1 ] , xstat [ 0 ] ) ; 
zps = xstat [ 2 ] / s ; 
h = Math . sqrt ( xstat [ 0 ] * xstat [ 0 ] + xstat [ 1 ] * xstat [ 1 ] 
+ xstat [ 2 ] * xstat [ 2 ] ) - a ; 
phi = Math . atan ( zps / ( 1.0 - e2 * a / ( a + h ) ) ) ; 
niter = 0 ; 
for ( i = 1 ; i <= 10000000 ; i ++ ) { 
n = a / Math . sqrt ( 1.0 - e2 * Math . sin ( phi ) * Math . sin ( phi ) ) ; 
hp = h ; 
phip = phi ; 
h = s / Math . cos ( phi ) - n ; 
phi = Math . atan ( zps / ( 1.0 - e2 * n / ( n + h ) ) ) ; 
niter = niter + 1 ; 
if ( ( Math . abs ( phip - phi ) <= 1.e-11 ) 
&& ( Math . abs ( hp - h ) <= 1.e-5 ) ) { 
if ( niter >= 10 ) { 
phi = - 999.0 ; 
rlam = - 999.0 ; 
h = - 999.0 ; 
xstell [ 0 ] = phi * 180 / 3.1415926 ; 
xstell [ 1 ] = rlam * 180 / 3.1415926 ; 
xstell [ 2 ] = h ; 
return xstell ; 
} public double gast ( int iyr , int imon , int iday , int ihr , int imin , 
double sec , double dsec ) { 
double djd = juday ( imon , iday , iyr ) ; 
double tu = ( djd - 2451545.0 ) / 36525.0 ; 
double gmst = 24110.548410 + 8640184.8128660 * tu 
+ 0.093104 * tu * tu - 6.2E-6 * Math . pow ( tu , 3 ) ; 
double utco = ( ihr * 3600 ) + ( imin * 60 ) + sec ; 
return togreenw ( dsec , utco , gmst ) ; 
} public double juday ( int M , int D , int Y ) { 
double JD ; 
double IY = Y - ( 12 - M ) / 10 ; 
double IM = M + 1 + 12 * ( ( 12 - M ) / 10 ) ; 
double I = IY / 100 ; 
double J = 2 - I + I / 4 + Math . round ( 365.25 * IY ) 
+ Math . round ( 30.6001 * IM ) ; 
JD = ( J + D + 1720994.50 ) ; 
return JD ; 
} public double togreenw ( double rectt , double utco , double gmst ) { 
double pi = Math . acos ( - 1.00 ) ; 
double utc = ( utco + rectt ) * 1.0027379093 ; 
gmst = gmst + utc ; 
while ( gmst < 0.0 ) { 
gmst = gmst + 86400.00 ; 
while ( gmst > 86400.00 ) { 
gmst = gmst - 86400.00 ; 
return gmst * 2.0 * pi / 86400.0 ; 
} public double [ ] spin ( double [ ] v1 , double [ ] vs , double a ) { 
double [ ] v2 = new double [ 3 ] ; 
double [ ] vsn = new double [ 3 ] ; 
double [ ] v3 = new double [ 3 ] ; 
double vsabs = Math . sqrt ( vs [ 0 ] * vs [ 0 ] + vs [ 1 ] * vs [ 1 ] 
+ vs [ 2 ] * vs [ 2 ] ) ; 
vsn [ i ] = vs [ i ] / vsabs ; 
double a1 = Math . cos ( a ) ; 
double a2 = 1.0 - a1 ; 
double a3 = Math . sin ( a ) ; 
double [ ] [ ] s = new double [ 3 ] [ 3 ] ; 
s [ 0 ] [ 0 ] = a2 * vsn [ 0 ] * vsn [ 0 ] + a1 ; 
s [ 0 ] [ 1 ] = a2 * vsn [ 0 ] * vsn [ 1 ] - a3 * vsn [ 2 ] ; 
s [ 0 ] [ 2 ] = a2 * vsn [ 0 ] * vsn [ 2 ] + a3 * vsn [ 1 ] ; 
s [ 1 ] [ 0 ] = a2 * vsn [ 1 ] * vsn [ 0 ] + a3 * vsn [ 2 ] ; 
s [ 1 ] [ 1 ] = a2 * vsn [ 1 ] * vsn [ 1 ] + a1 ; 
s [ 1 ] [ 2 ] = a2 * vsn [ 1 ] * vsn [ 2 ] - a3 * vsn [ 0 ] ; 
s [ 2 ] [ 0 ] = a2 * vsn [ 2 ] * vsn [ 0 ] - a3 * vsn [ 1 ] ; 
s [ 2 ] [ 1 ] = a2 * vsn [ 2 ] * vsn [ 1 ] + a3 * vsn [ 0 ] ; 
s [ 2 ] [ 2 ] = a2 * vsn [ 2 ] * vsn [ 2 ] + a1 ; 
v3 [ i ] = s [ i ] [ 0 ] * v1 [ 0 ] + s [ i ] [ 1 ] * v1 [ 1 ] + s [ i ] [ 2 ] * v1 [ 2 ] ; 
System . arraycopy ( v3 , 0 , v2 , 0 , 3 ) ; 
return v2 ; 
} public double [ ] execute ( double [ ] eci , double julian ) { 
double Xi = eci [ 0 ] ; 
double Yi = eci [ 1 ] ; 
double Zi = eci [ 2 ] ; 
double c , s ; 
double GHA ; 
double [ ] ecef = new double [ 3 ] ; 
double d__1 , d__2 , d__3 ; 
double tsec , tday , gmst , t , omega , tfrac , tu , dat ; 
tday = ( double ) ( ( int ) ( julian / 86400. ) ) ; 
tsec = julian - tday * 86400 ; 
t = tday - ( float ) 10957.5 ; 
tfrac = tsec / 86400. ; 
dat = t ; 
tu = dat / 36525. ; 
d__1 = tu ; 
d__2 = tu ; 
d__3 = d__2 ; 
gmst = tu * 8640184.812866 + 24110.54841 + d__1 * d__1 * .093104 
- d__3 * ( d__2 * d__2 ) * 6.2e-6 ; 
omega = tu * 5.098097e-6 + 86636.55536790872 - d__1 * d__1 * 5.09e-10 ; 
double da = 0.0 ; 
gmst = gmst + omega * tfrac + da * RTD * 86400. / 360. ; 
gmst = gmst % 86400 ; 
if ( gmst < 0. ) { 
gmst += 86400. ; 
gmst = gmst / 86400. * 360. ; 
gmst = gmst * DTR ; 
GHA = gmst ; 
c = Math . cos ( GHA ) ; 
s = Math . sin ( GHA ) ; 
double X = c * Xi + s * Yi ; 
double Y = - s * Xi + c * Yi ; 
ecef [ 0 ] = X ; 
ecef [ 1 ] = Y ; 
ecef [ 2 ] = Zi ; 
return ecef ; 
} public static double [ ] ECFtoLLA ( double x , double y , double z , 
double a , double b ) { 
double longitude = Math . atan2 ( y , x ) ; 
double ePrimeSquared = ( a * a - b * b ) / ( b * b ) ; 
double p = Math . sqrt ( x * x + y * y ) ; 
double theta = Math . atan ( ( z * a ) / ( p * b ) ) ; 
double sineTheta = Math . sin ( theta ) ; 
double cosTheta = Math . cos ( theta ) ; 
double f = 1 / 298.257223563 ; 
double e2 = 2 * f - f * f ; 
double top = z + ePrimeSquared * b * sineTheta * sineTheta 
* sineTheta ; 
double bottom = p - e2 * a * cosTheta * cosTheta * cosTheta ; 
double geodeticLat = Math . atan ( top / bottom ) ; 
double sineLat = Math . sin ( geodeticLat ) ; 
double N = a / Math . sqrt ( 1 - e2 * sineLat * sineLat ) ; 
double altitude = ( p / Math . cos ( geodeticLat ) ) - N ; 
if ( longitude > Math . PI ) { 
longitude -= 2 * Math . PI ; 
} else if ( longitude < - Math . PI ) { 
longitude += 2 * Math . PI ; 
return new double [ ] { geodeticLat , longitude , altitude } ; 
} private static boolean readWorldMap ( ) { 
java . io . DataInputStream dis ; 
String filename = "/resources/nj22/ui/maps/cil_100km.mapr" ; 
java . io . InputStream is = null ; 
long secs = System . currentTimeMillis ( ) ; 
is = Resource . getFileResource ( filename ) ; 
dis = new java . io . DataInputStream ( is ) ; 
worldMapFeature = new WorldMapFeature ( ) ; 
gisList = new ArrayList ( ) ; 
gisList . add ( worldMapFeature ) ; 
partList = new ArrayList ( ) ; 
int npts = dis . readInt ( ) ; 
dis . readInt ( ) ; 
MapRun run = new MapRun ( npts ) ; 
for ( int i = 0 ; i < npts ; i ++ ) { 
run . wx [ i ] = ( ( double ) dis . readInt ( ) ) / SECS_PER_DEG ; 
run . wy [ i ] = ( ( double ) dis . readInt ( ) ) / SECS_PER_DEG ; 
partList . add ( run ) ; 
total_pts += npts ; 
} catch ( EOFException ex ) { 
try { is . close ( ) ; 
} catch ( Exception ex ) { } 
if ( debugTime ) { 
secs = System . currentTimeMillis ( ) - secs ; 
} public static String cleanUnit ( String unit ) { 
if ( unit == null ) return null ; 
if ( unit . equalsIgnoreCase ( "Proportion" ) || unit . equalsIgnoreCase ( "Numeric" ) ) 
else if ( unit . equalsIgnoreCase ( "-" ) ) { 
} else if ( unit . startsWith ( "degree" ) && unit . endsWith ( "true" ) ) { 
if ( unit . startsWith ( "/" ) ) unit = "1" + unit ; 
unit = unit . trim ( ) ; 
unit = StringUtil2 . remove ( unit , "**" ) ; 
StringBuilder sb = new StringBuilder ( unit ) ; 
StringUtil2 . remove ( sb , "^[]" ) ; 
StringUtil2 . replace ( sb , '*' , "." ) ; 
unit = sb . toString ( ) ; 
} public static String cleanName ( String name ) { 
int pos = name . indexOf ( "(see" ) ; 
if ( pos < 0 ) pos = name . indexOf ( "(See" ) ; 
if ( pos > 0 ) name = name . substring ( 0 , pos ) ; 
name = StringUtil2 . replace ( name , '/' , "-" ) ; 
StringUtil2 . replace ( sb , '+' , "plus" ) ; 
StringUtil2 . remove ( sb , ".;,=[]()/*\"" ) ; 
return StringUtil2 . collapseWhitespace ( sb . toString ( ) . trim ( ) ) ; 
} public static boolean equivilantName ( String name1 , String name2 ) { 
if ( name1 == null || name2 == null ) return ( name1 == name2 ) ; 
String name1clean = cleanName ( name1 ) . toLowerCase ( ) ; 
String name2clean = cleanName ( name2 ) . toLowerCase ( ) ; 
if ( name1 . equals ( name2 ) ) return true ; 
StringBuilder sb1 = new StringBuilder ( name1clean ) ; 
StringBuilder sb2 = new StringBuilder ( name2clean ) ; 
return sb1 . toString ( ) . equals ( sb2 . toString ( ) ) ; 
} public static boolean isUnitless ( String unit ) { 
if ( unit == null ) return true ; 
String munge = unit . toLowerCase ( ) . trim ( ) ; 
munge = StringUtil2 . remove ( munge , '(' ) ; 
return munge . length ( ) == 0 || 
munge . startsWith ( "numeric" ) || munge . startsWith ( "non-dim" ) || munge . startsWith ( "see" ) || 
munge . startsWith ( "proportion" ) || munge . startsWith ( "code" ) || munge . startsWith ( "0=" ) || 
munge . equals ( "1" ) ; 
} public String prepareUrlStringForHtml ( String url ) { 
uri = new URI ( url ) ; 
if ( uri . isAbsolute ( ) ) 
if ( url . startsWith ( "/" ) ) 
return url ; 
return this . getWebappContextPath ( ) + "/" + url ; 
} static public FeatureCollectionConfig getConfigFromSnippet ( String filename ) { 
org . jdom2 . Document doc ; 
doc = builder . build ( filename ) ; 
return FeatureCollectionReader . readFeatureCollection ( doc . getRootElement ( ) ) ; 
} public Shape getShape ( ) { 
int npts = getNumPoints ( ) ; 
GeneralPath path = new GeneralPath ( GeneralPath . WIND_EVEN_ODD , npts ) ; 
java . util . Iterator pi = getGisParts ( ) ; 
while ( pi . hasNext ( ) ) { 
GisPart gp = ( GisPart ) pi . next ( ) ; 
double [ ] xx = gp . getX ( ) ; 
double [ ] yy = gp . getY ( ) ; 
int np = gp . getNumPoints ( ) ; 
if ( np > 0 ) 
path . moveTo ( ( float ) xx [ 0 ] , ( float ) yy [ 0 ] ) ; 
for ( int i = 1 ; i < np ; i ++ ) { 
path . lineTo ( ( float ) xx [ i ] , ( float ) yy [ i ] ) ; 
} public Shape getProjectedShape ( ProjectionImpl displayProject ) { 
LatLonPointImpl workL = new LatLonPointImpl ( ) ; 
ProjectionPointImpl lastW = new ProjectionPointImpl ( ) ; 
GeneralPath path = new GeneralPath ( GeneralPath . WIND_EVEN_ODD , getNumPoints ( ) ) ; 
boolean showPts = ucar . util . prefs . ui . Debug . isSet ( "projection/showPoints" ) ; 
boolean skipPrev = false ; 
for ( int i = 0 ; i < gp . getNumPoints ( ) ; i ++ ) { 
workL . set ( yy [ i ] , xx [ i ] ) ; 
ProjectionPoint pt = displayProject . latLonToProj ( workL ) ; 
if ( showPts ) { 
if ( Double . isNaN ( pt . getX ( ) ) || Double . isNaN ( pt . getY ( ) ) ) { 
skipPrev = true ; 
if ( ( count == 0 ) || skipPrev || displayProject . crossSeam ( pt , lastW ) ) 
path . moveTo ( ( float ) pt . getX ( ) , ( float ) pt . getY ( ) ) ; 
path . lineTo ( ( float ) pt . getX ( ) , ( float ) pt . getY ( ) ) ; 
skipPrev = false ; 
lastW . setLocation ( pt ) ; 
} public Shape getProjectedShape ( ProjectionImpl dataProject , ProjectionImpl displayProject ) { 
ProjectionPointImpl pt1 = new ProjectionPointImpl ( ) ; 
pt1 . setLocation ( xx [ i ] , yy [ i ] ) ; 
LatLonPoint llpt = dataProject . projToLatLon ( pt1 ) ; 
ProjectionPoint pt2 = displayProject . latLonToProj ( llpt ) ; 
if ( Double . isNaN ( pt2 . getX ( ) ) || Double . isNaN ( pt2 . getY ( ) ) ) { 
if ( ( count == 0 ) || skipPrev || displayProject . crossSeam ( pt2 , lastW ) ) 
path . moveTo ( ( float ) pt2 . getX ( ) , ( float ) pt2 . getY ( ) ) ; 
path . lineTo ( ( float ) pt2 . getX ( ) , ( float ) pt2 . getY ( ) ) ; 
lastW . setLocation ( pt2 ) ; 
add ( 209 , 3 , 57 , "ReflectivityAtLowestAltitude" , "ReflectivityAtLowestAltitude" , "dBZ" , - 999 , - 99 ) ; 
- 99 ) ; 
- 1 ) ; 
- 999 , - 99 ) ; 
"dBZ" , - 999 , - 99 ) ; 
} static Notes 
factory ( NoteSort ns , int g , int id , Nc4DSP dsp ) 
Notes note = null ; 
switch ( ns ) { 
case TYPE : 
note = new TypeNotes ( g , id , dsp ) ; 
case VAR : 
note = new VarNotes ( g , id , dsp ) ; 
case DIM : 
note = new DimNotes ( g , id , dsp ) ; 
note = new GroupNotes ( g , id , dsp ) ; 
return note ; 
getVarId ( VarNotes note ) 
return getVarId ( note . gid , note . id , note . getFieldIndex ( ) ) ; 
} static DodsV parseDDS ( DDS dds ) { 
DodsV root = new DodsV ( null , null ) ; 
Enumeration variables = dds . getVariables ( ) ; 
parseVariables ( root , variables ) ; 
root . assignSequence ( root ) ; 
} static private void parseVariables ( DodsV parent , Enumeration children ) { 
while ( children . hasMoreElements ( ) ) { 
opendap . dap . BaseType bt = ( opendap . dap . BaseType ) children . nextElement ( ) ; 
if ( bt instanceof DList ) { 
logger . warn ( mess ) ; 
DodsV dodsV = new DodsV ( parent , bt ) ; 
if ( bt instanceof DConstructor ) { 
DConstructor dcon = ( DConstructor ) bt ; 
java . util . Enumeration enumerate2 = dcon . getVariables ( ) ; 
parseVariables ( dodsV , enumerate2 ) ; 
} else if ( bt instanceof DArray ) { 
DArray da = ( DArray ) bt ; 
for ( Enumeration e = da . getDimensions ( ) ; e . hasMoreElements ( ) ; ) { 
DArrayDimension dim = ( DArrayDimension ) e . nextElement ( ) ; 
if ( dim . getSize ( ) <= 0 ) return ; 
BaseType elemType = da . getPrimitiveVector ( ) . getTemplate ( ) ; 
dodsV . bt = elemType ; 
dodsV . darray = da ; 
if ( ( elemType instanceof DGrid ) || ( elemType instanceof DSequence ) || ( elemType instanceof DList ) ) { 
if ( elemType instanceof DStructure ) { 
DConstructor dcon = ( DConstructor ) elemType ; 
java . util . Enumeration nestedVariables = dcon . getVariables ( ) ; 
parseVariables ( dodsV , nestedVariables ) ; 
parent . children . add ( dodsV ) ; 
} static DodsV parseDataDDS ( DataDDS dds ) throws NoSuchVariableException { 
parseDataVariables ( root , variables ) ; 
} static private void parseDataVariables ( DodsV parent , Enumeration children ) throws NoSuchVariableException { 
if ( bt instanceof DGrid ) { 
DGrid dgrid = ( DGrid ) bt ; 
if ( dodsV . parent . bt == null ) { 
dodsV . darray = ( DArray ) dgrid . getVar ( 0 ) ; 
processDArray ( dodsV ) ; 
dodsV . makeAllDimensions ( ) ; 
java . util . Enumeration enumerate2 = dgrid . getVariables ( ) ; 
parseDataVariables ( dodsV , enumerate2 ) ; 
} else if ( bt instanceof DSequence ) { 
DSequence dseq = ( DSequence ) bt ; 
int seqlen = dseq . getRowCount ( ) ; 
if ( seqlen > 0 ) { 
DArrayDimension ddim = new DArrayDimension ( seqlen , null ) ; 
dodsV . dimensions . add ( ddim ) ; 
java . util . Enumeration enumerate2 = dseq . getVariables ( ) ; 
} else if ( bt instanceof DConstructor ) { 
DStructure dcon = ( DStructure ) bt ; 
dodsV . darray = ( DArray ) bt ; 
dodsV . bt = dodsV . elemType ; 
if ( dodsV . elemType instanceof DStructure ) { 
DStructure dcon = ( DStructure ) dodsV . elemType ; 
parseDataVariables ( dodsV , nestedVariables ) ; 
} void parseDAS ( DAS das ) throws IOException { 
if ( tableName . equals ( "NC_GLOBAL" ) || tableName . equals ( "HDF_GLOBAL" ) ) { 
addAttributeTable ( this , attTable , tableName , true ) ; 
} else if ( tableName . equals ( "DODS_EXTRA" ) || tableName . equals ( "EXTRA_DIMENSION" ) ) { 
DodsV dodsV = findDodsV ( tableName , false ) ; 
if ( dodsV != null ) { 
addAttributeTable ( dodsV , attTable , tableName , true ) ; 
dodsV = findTableDotDelimited ( tableName ) ; 
addAttributeTable ( this , attTable , tableName , false ) ; 
} DodsV findDodsV ( String name , boolean useDone ) { 
for ( DodsV dodsV : children ) { 
if ( useDone && dodsV . isDone ) continue ; 
if ( ( name == null ) || ( dodsV == null ) || ( dodsV . bt == null ) ) { 
if ( name . equals ( dodsV . bt . getEncodedName ( ) ) ) 
return dodsV ; 
} DodsV findDataV ( DodsV ddsV ) { 
if ( ddsV . parent . bt != null ) { 
DodsV parentV = findDataV ( ddsV . parent ) ; 
if ( parentV == null ) 
return findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; 
return parentV . findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; 
DodsV dataV = findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; 
return dataV ; 
} DodsV findByIndex ( int index ) { 
if ( children . size ( ) <= index ) return null ; 
return children . get ( index ) ; 
} private static void doit ( String urlName ) throws IOException , DAP2Exception { 
try ( DConnect2 dodsConnection = new DConnect2 ( urlName , true ) ) { 
DDS dds = dodsConnection . getDDS ( ) ; 
dds . print ( System . out ) ; 
DodsV root = DodsV . parseDDS ( dds ) ; 
DAS das = dodsConnection . getDAS ( ) ; 
das . print ( System . out ) ; 
root . parseDAS ( das ) ; 
root . show ( System . out , "" ) ; 
} public int [ ] getShape ( ) { 
int [ ] result = new int [ shape . length ] ; 
System . arraycopy ( shape , 0 , result , 0 , shape . length ) ; 
} public Group getParentGroup ( ) { 
Group g = super . getParentGroup ( ) ; 
if ( g == null ) { 
g = ncfile . getRootGroup ( ) ; 
super . setParentGroup ( g ) ; 
assert g != null ; 
} public Dimension getDimension ( int i ) { 
if ( ( i < 0 ) || ( i >= getRank ( ) ) ) return null ; 
return dimensions . get ( i ) ; 
} public int findDimensionIndex ( String name ) { 
for ( int i = 0 ; i < dimensions . size ( ) ; i ++ ) { 
Dimension d = dimensions . get ( i ) ; 
if ( name . equals ( d . getShortName ( ) ) ) 
} public String getUnitsString ( ) { 
String units = null ; 
Attribute att = findAttribute ( CDM . UNITS ) ; 
if ( att == null ) att = findAttributeIgnoreCase ( CDM . UNITS ) ; 
if ( ( att != null ) && att . isString ( ) ) { 
units = att . getStringValue ( ) ; 
if ( units != null ) units = units . trim ( ) ; 
return units ; 
} public Section getShapeAsSection ( ) { 
if ( shapeAsSection == null ) { 
List < Range > list = new ArrayList < > ( ) ; 
for ( Dimension d : dimensions ) { 
int len = d . getLength ( ) ; 
list . add ( new Range ( d . getShortName ( ) , 0 , len - 1 ) ) ; 
else if ( len == 0 ) 
list . add ( Range . EMPTY ) ; 
assert d . isVariableLength ( ) ; 
list . add ( Range . VLEN ) ; 
shapeAsSection = new Section ( list ) . makeImmutable ( ) ; 
throw new IllegalStateException ( e . getMessage ( ) ) ; 
return shapeAsSection ; 
} public Variable section ( List < Range > ranges ) throws InvalidRangeException { 
return section ( new Section ( ranges , shape ) . makeImmutable ( ) ) ; 
} public Variable section ( Section subsection ) throws InvalidRangeException { 
subsection = Section . fill ( subsection , shape ) ; 
Variable sectionV = copy ( ) ; 
sectionV . setProxyReader ( new SectionReader ( this , subsection ) ) ; 
sectionV . shape = subsection . getShape ( ) ; 
sectionV . createNewCache ( ) ; 
sectionV . setCaching ( false ) ; 
sectionV . dimensions = new ArrayList < > ( ) ; 
for ( int i = 0 ; i < getRank ( ) ; i ++ ) { 
Dimension oldD = getDimension ( i ) ; 
Dimension newD = ( oldD . getLength ( ) == sectionV . shape [ i ] ) ? oldD : new Dimension ( oldD . getShortName ( ) , sectionV . shape [ i ] , false ) ; 
newD . setUnlimited ( oldD . isUnlimited ( ) ) ; 
sectionV . dimensions . add ( newD ) ; 
sectionV . resetShape ( ) ; 
return sectionV ; 
} public Variable slice ( int dim , int value ) throws InvalidRangeException { 
if ( ( dim < 0 ) || ( dim >= shape . length ) ) 
boolean recordSliceOk = false ; 
if ( ( dim == 0 ) && ( value == 0 ) ) { 
Dimension d = getDimension ( 0 ) ; 
recordSliceOk = d . isUnlimited ( ) ; 
if ( ! recordSliceOk ) { 
if ( ( value < 0 ) || ( value >= shape [ dim ] ) ) 
Variable sliceV = copy ( ) ; 
Section slice = new Section ( getShapeAsSection ( ) ) ; 
slice . replaceRange ( dim , new Range ( value , value ) ) . makeImmutable ( ) ; 
sliceV . setProxyReader ( new SliceReader ( this , dim , slice ) ) ; 
sliceV . createNewCache ( ) ; 
sliceV . setCaching ( false ) ; 
sliceV . dimensions . remove ( dim ) ; 
sliceV . resetShape ( ) ; 
return sliceV ; 
} public Variable reduce ( List < Dimension > dims ) throws InvalidRangeException { 
List < Integer > dimIdx = new ArrayList < > ( dims . size ( ) ) ; 
for ( Dimension d : dims ) { 
assert dimensions . contains ( d ) ; 
assert d . getLength ( ) == 1 ; 
dimIdx . add ( dimensions . indexOf ( d ) ) ; 
sliceV . setProxyReader ( new ReduceReader ( this , dimIdx ) ) ; 
for ( Dimension d : dims ) sliceV . dimensions . remove ( d ) ; 
} public void setEnumTypedef ( EnumTypedef enumTypedef ) { 
if ( ! dataType . isEnum ( ) ) 
this . enumTypedef = enumTypedef ; 
} public Array read ( int [ ] origin , int [ ] shape ) throws IOException , InvalidRangeException { 
if ( ( origin == null ) && ( shape == null ) ) 
return read ( ) ; 
if ( origin == null ) 
return read ( new Section ( shape ) ) ; 
if ( shape == null ) 
return read ( new Section ( origin , this . shape ) ) ; 
return read ( new Section ( origin , shape ) ) ; 
} public Array read ( List < Range > ranges ) throws IOException , InvalidRangeException { 
if ( null == ranges ) 
return _read ( ) ; 
return read ( new Section ( ranges ) ) ; 
} public Array read ( ucar . ma2 . Section section ) throws java . io . IOException , ucar . ma2 . InvalidRangeException { 
return ( section == null ) ? _read ( ) : _read ( Section . fill ( section , shape ) ) ; 
} public String readScalarString ( ) throws IOException { 
Array data = getScalarData ( ) ; 
return ( String ) data . getObject ( Index . scalarIndexImmutable ) ; 
else if ( dataType == DataType . CHAR ) { 
ArrayChar dataC = ( ArrayChar ) data ; 
return dataC . getString ( ) ; 
} protected Array _read ( ) throws IOException { 
if ( cache . data != null ) { 
return cache . data . copy ( ) ; 
Array data = proxyReader . reallyRead ( this , null ) ; 
if ( isCaching ( ) ) { 
setCachedData ( data ) ; 
public Array reallyRead ( Variable client , CancelTask cancelTask ) throws IOException { 
if ( isMemberOfStructure ( ) ) { 
List < String > memList = new ArrayList < > ( ) ; 
memList . add ( this . getShortName ( ) ) ; 
Structure s = getParentStructure ( ) . select ( memList ) ; 
ArrayStructure as = ( ArrayStructure ) s . read ( ) ; 
return as . extractMemberArray ( as . findMember ( getShortName ( ) ) ) ; 
return ncfile . readData ( this , getShapeAsSection ( ) ) ; 
} protected Array _read ( Section section ) throws IOException , InvalidRangeException { 
if ( ( null == section ) || section . computeSize ( ) == getSize ( ) ) 
if ( cache . data == null ) { 
setCachedData ( _read ( ) ) ; 
return cache . data . sectionNoReduce ( section . getRanges ( ) ) . copy ( ) ; 
return proxyReader . reallyRead ( this , section , null ) ; 
public Array reallyRead ( Variable client , Section section , CancelTask cancelTask ) throws IOException , InvalidRangeException { 
return ncfile . readData ( this , section ) ; 
} public long readToByteChannel ( Section section , WritableByteChannel wbc ) throws IOException , InvalidRangeException { 
if ( ( ncfile == null ) || hasCachedData ( ) ) 
return IospHelper . copyToByteChannel ( read ( section ) , wbc ) ; 
return ncfile . readToByteChannel ( this , section , wbc ) ; 
} public String getNameAndDimensions ( ) { 
Formatter buf = new Formatter ( ) ; 
getNameAndDimensions ( buf , true , false ) ; 
} public String getNameAndDimensions ( boolean strict ) { 
getNameAndDimensions ( buf , false , strict ) ; 
} public void getNameAndDimensions ( StringBuffer buf ) { 
Formatter proxy = new Formatter ( ) ; 
getNameAndDimensions ( proxy , true , false ) ; 
buf . append ( proxy . toString ( ) ) ; 
} public void getNameAndDimensions ( StringBuilder buf , boolean useFullName , boolean strict ) { 
getNameAndDimensions ( proxy , useFullName , strict ) ; 
} public void getNameAndDimensions ( Formatter buf , boolean useFullName , boolean strict ) { 
useFullName = useFullName && ! strict ; 
String name = useFullName ? getFullName ( ) : getShortName ( ) ; 
if ( strict ) name = NetcdfFile . makeValidCDLName ( getShortName ( ) ) ; 
buf . format ( "%s" , name ) ; 
if ( shape != null ) { 
if ( getRank ( ) > 0 ) buf . format ( "(" ) ; 
Dimension myd = dimensions . get ( i ) ; 
String dimName = myd . getShortName ( ) ; 
if ( ( dimName != null ) && strict ) 
dimName = NetcdfFile . makeValidCDLName ( dimName ) ; 
if ( myd . isVariableLength ( ) ) { 
buf . format ( "*" ) ; 
} else if ( myd . isShared ( ) ) { 
if ( ! strict ) 
buf . format ( "%s=%d" , dimName , myd . getLength ( ) ) ; 
buf . format ( "%s" , dimName ) ; 
if ( dimName != null ) { 
buf . format ( "%s=" , dimName ) ; 
buf . format ( "%d" , myd . getLength ( ) ) ; 
if ( getRank ( ) > 0 ) buf . format ( ")" ) ; 
} public String writeCDL ( boolean useFullName , boolean strict ) { 
writeCDL ( buf , new Indent ( 2 ) , useFullName , strict ) ; 
} public String toStringDebug ( ) { 
if ( ncfile != null ) { 
String extra = ncfile . toStringDebug ( this ) ; 
if ( extra != null ) 
} public void setDataType ( DataType dataType ) { 
this . dataType = dataType ; 
this . elementSize = getDataType ( ) . getSize ( ) ; 
} public void setDimensions ( List < Dimension > dims ) { 
this . dimensions = ( dims == null ) ? new ArrayList < > ( ) : new ArrayList < > ( dims ) ; 
resetShape ( ) ; 
} public void resetShape ( ) { 
this . shape = new int [ dimensions . size ( ) ] ; 
Dimension dim = dimensions . get ( i ) ; 
shape [ i ] = dim . getLength ( ) ; 
if ( dim . isVariableLength ( ) ) { 
isVariableLength = true ; 
this . shapeAsSection = null ; 
} public void setDimensions ( String dimString ) { 
setDimensions ( Dimension . makeDimensionsList ( getParentGroup ( ) , dimString ) ) ; 
} catch ( IllegalStateException e ) { 
} public void resetDimensions ( ) { 
ArrayList < Dimension > newDimensions = new ArrayList < > ( ) ; 
for ( Dimension dim : dimensions ) { 
if ( dim . isShared ( ) ) { 
Dimension newD = getParentGroup ( ) . findDimension ( dim . getShortName ( ) ) ; 
if ( newD == null ) 
newDimensions . add ( newD ) ; 
newDimensions . add ( dim ) ; 
this . dimensions = newDimensions ; 
} public void setDimensionsAnonymous ( int [ ] shape ) throws InvalidRangeException { 
this . dimensions = new ArrayList < > ( ) ; 
if ( ( shape [ i ] < 1 ) && ( shape [ i ] != - 1 ) ) 
Dimension anon ; 
if ( shape [ i ] == - 1 ) { 
anon = Dimension . VLEN ; 
anon = new Dimension ( null , shape [ i ] , false , false , false ) ; 
dimensions . add ( anon ) ; 
} public void setDimension ( int idx , Dimension dim ) { 
dimensions . set ( idx , dim ) ; 
} public boolean isCaching ( ) { 
if ( ! permitCaching ) { 
if ( ! this . cache . cachingSet ) { 
cache . isCaching = ! isVariableLength && ( getSize ( ) * getElementSize ( ) < getSizeToCache ( ) ) ; 
this . cache . cachingSet = true ; 
return cache . isCaching ; 
} public void setCachedData ( Array cacheData , boolean isMetadata ) { 
if ( ( cacheData != null ) && ( cacheData . getElementType ( ) != getDataType ( ) . getPrimitiveClassType ( ) ) ) 
this . cache . data = cacheData ; 
this . isMetadata = isMetadata ; 
this . cache . isCaching = true ; 
} public List < Dimension > getDimensionsAll ( ) { 
List < Dimension > dimsAll = new ArrayList < > ( ) ; 
addDimensionsAll ( dimsAll , this ) ; 
return dimsAll ; 
} public boolean isCoordinateVariable ( ) { 
if ( ( dataType == DataType . STRUCTURE ) || isMemberOfStructure ( ) ) 
int n = getRank ( ) ; 
if ( n == 1 && dimensions . size ( ) == 1 ) { 
Dimension firstd = dimensions . get ( 0 ) ; 
if ( getShortName ( ) . equals ( firstd . getShortName ( ) ) ) { 
if ( n == 2 && dimensions . size ( ) == 2 ) { 
if ( shortName . equals ( firstd . getShortName ( ) ) && 
( getDataType ( ) == DataType . CHAR ) ) { 
} protected void setBoundingBox ( ) { 
LatLonRect largestBB = null ; 
for ( Object o : csHash . values ( ) ) { 
RadialCoordSys sys = ( RadialCoordSys ) o ; 
sys . setOrigin ( origin ) ; 
LatLonRect bb = sys . getBoundingBox ( ) ; 
if ( largestBB == null ) 
largestBB = bb ; 
else if ( bb != null ) 
largestBB . extend ( bb ) ; 
boundingBox = largestBB ; 
} void finish ( ) { 
gridList = new ArrayList < > ( uvHash . values ( ) ) ; 
Collections . sort ( gridList ) ; 
for ( GridVariable grid : gridList ) { 
grid . finish ( ) ; 
int seqno = 0 ; 
for ( TimeCoord tc : timeCoords ) 
tc . setId ( seqno ++ ) ; 
HashMap < String , List < VertCoord > > map = new HashMap < > ( ) ; 
for ( VertCoord vc : vertCoords ) { 
List < VertCoord > list = map . get ( vc . getName ( ) ) ; 
map . put ( vc . getName ( ) , list ) ; 
list . add ( vc ) ; 
for ( List < VertCoord > list : map . values ( ) ) { 
for ( VertCoord vc : list ) { 
if ( count > 0 ) vc . setName ( vc . getName ( ) + count ) ; 
} private void parseTemporalExtentForm ( ) { 
if ( temporal == null ) { 
fatal = true ; 
if ( temporal . equalsIgnoreCase ( "all" ) ) temporalSelection = TemporalSelection . all ; 
else if ( temporal . equalsIgnoreCase ( "range" ) ) temporalSelection = TemporalSelection . range ; 
else if ( temporal . equalsIgnoreCase ( "point" ) ) temporalSelection = TemporalSelection . point ; 
if ( temporal . equalsIgnoreCase ( "range" ) ) { 
parseTimeExtent ( ) ; 
} else if ( temporal . equalsIgnoreCase ( "point" ) ) { 
timePoint = parseDate ( "time" , time ) ; 
} public Iterable < Dataset > getAllDatasets ( ) { 
List < Dataset > all = new ArrayList < > ( ) ; 
addAll ( this , all ) ; 
return all ; 
} public boolean dspMatch ( String path , DapContext context ) 
for ( String ext : SYNEXTENSIONS ) { 
} public CDMDSP open ( NetcdfDataset ncd ) 
assert this . context != null ; 
this . dmrfactory = new DMRFactory ( ) ; 
this . ncdfile = ncd ; 
setLocation ( this . ncdfile . getLocation ( ) ) ; 
buildDMR ( ) ; 
recordNode ( CDMNode cdm , DapNode dap ) 
assert this . nodemap . get ( cdm ) == null && this . nodemap . get ( dap ) == null ; 
this . nodemap . put ( cdm , dap ) ; 
recordVar ( Variable cdm , DapVariable dap ) 
cdm = CDMUtil . unwrap ( cdm ) ; 
assert varmap . get ( cdm ) == null && varmap . get ( dap ) == null ; 
varmap . put ( cdm , dap ) ; 
recordStruct ( Variable cdm , DapStructure dap ) 
compoundmap . put ( cdm , dap ) ; 
recordSeq ( Variable cdm , DapSequence dap ) 
assert this . vlenmap . get ( cdm ) == null && this . vlenmap . get ( dap ) == null ; 
vlenmap . put ( cdm , dap ) ; 
buildDMR ( ) 
if ( getDMR ( ) != null ) 
if ( DUMPCDL ) { 
System . out . println ( "writecdl:" ) ; 
this . ncdfile . writeCDL ( System . out , false ) ; 
System . out . flush ( ) ; 
String name = this . ncdfile . getLocation ( ) ; 
name = DapUtil . canonicalpath ( name ) ; 
int index = name . lastIndexOf ( '/' ) ; 
if ( index >= 0 ) 
name = name . substring ( index + 1 , name . length ( ) ) ; 
setDMR ( ( DapDataset ) dmrfactory . newDataset ( name ) . annotate ( NetcdfDataset . class , this . ncdfile ) ) ; 
recordNode ( this . ncdfile . getRootGroup ( ) , getDMR ( ) ) ; 
getDMR ( ) . setBase ( DapUtil . canonicalpath ( this . ncdfile . getLocation ( ) ) ) ; 
fillgroup ( getDMR ( ) , this . ncdfile . getRootGroup ( ) ) ; 
getDMR ( ) . sort ( ) ; 
processmappedvariables ( this . ncdfile . getRootGroup ( ) ) ; 
getDMR ( ) . finish ( ) ; 
} catch ( DapException e ) { 
setDMR ( null ) ; 
fillgroup ( DapGroup dapgroup , Group cdmgroup ) 
for ( Dimension cdmdim : cdmgroup . getDimensions ( ) ) { 
DapDimension dapdim = builddim ( cdmdim ) ; 
for ( EnumTypedef cdmenum : cdmgroup . getEnumTypedefs ( ) ) { 
String name = cdmenum . getShortName ( ) ; 
DapEnumeration dapenum = buildenum ( cdmenum ) ; 
dapenum . setShortName ( name ) ; 
dapgroup . addDecl ( dapenum ) ; 
for ( Variable cdmvar0 : cdmgroup . getVariables ( ) ) { 
Variable cdmvar = CDMUtil . unwrap ( cdmvar0 ) ; 
buildseqtypes ( cdmvar ) ; 
if ( cdmvar . getDataType ( ) != DataType . STRUCTURE 
&& cdmvar . getDataType ( ) != DataType . SEQUENCE ) 
DapStructure struct = buildcompoundtype ( cdmvar , dapgroup ) ; 
DapNode newvar = buildvariable ( cdmvar , dapgroup , cdmvar . getDimensions ( ) ) ; 
for ( Group subgroup : cdmgroup . getGroups ( ) ) { 
DapGroup newgroup = buildgroup ( subgroup ) ; 
dapgroup . addDecl ( newgroup ) ; 
buildattributes ( dapgroup , cdmgroup . getAttributes ( ) ) ; 
} protected DapDimension 
builddim ( Dimension cdmdim ) 
if ( cdmdim . isVariableLength ( ) ) 
DapDimension dapdim = null ; 
long cdmsize = dapsize ( cdmdim ) ; 
String name = cdmdim . getShortName ( ) ; 
if ( name != null && name . length ( ) == 0 ) 
boolean shared = cdmdim . isShared ( ) ; 
if ( ! shared ) { 
dapdim = ( DapDimension ) dmrfactory . newDimension ( null , cdmsize ) ; 
getDMR ( ) . addDecl ( dapdim ) ; 
dapdim = ( DapDimension ) dmrfactory . newDimension ( name , cdmsize ) ; 
dapdim . setShared ( true ) ; 
if ( cdmdim . isUnlimited ( ) ) { 
dapdim . setUnlimited ( true ) ; 
Group cdmparent = cdmdim . getGroup ( ) ; 
DapGroup dapparent = ( DapGroup ) this . nodemap . get ( cdmparent ) ; 
assert dapparent != null ; 
assert ( dapparent != null ) ; 
dapparent . addDecl ( dapdim ) ; 
recordNode ( cdmdim , dapdim ) ; 
return dapdim ; 
} protected DapSequence 
buildseqtype ( Variable cdmvar ) 
cdmvar = CDMUtil . unwrap ( cdmvar ) ; 
assert ( CDMUtil . hasVLEN ( cdmvar ) ) ; 
DataType dt = cdmvar . getDataType ( ) ; 
DapType daptype = CDMTypeFcns . cdmtype2daptype ( dt ) ; 
DapSequence seq = ( DapSequence ) dmrfactory . newSequence ( cdmvar . getShortName ( ) ) ; 
DapVariable field = dmrfactory . newVariable ( cdmvar . getShortName ( ) , daptype ) ; 
seq . addField ( field ) ; 
field . setParent ( seq ) ; 
recordSeq ( cdmvar , seq ) ; 
return seq ; 
buildseqtypes ( Variable cdmvar ) 
if ( CDMUtil . hasVLEN ( cdmvar ) ) { 
buildseqtype ( cdmvar ) ; 
if ( cdmvar . getDataType ( ) == DataType . STRUCTURE 
|| cdmvar . getDataType ( ) == DataType . SEQUENCE ) { 
Structure struct = ( Structure ) cdmvar ; 
List < Variable > fields = struct . getVariables ( ) ; 
Variable field = fields . get ( i ) ; 
buildseqtypes ( field ) ; 
builddimrefs ( DapVariable dapvar , List < Dimension > cdmdims ) 
if ( cdmdims == null || cdmdims . size ( ) == 0 ) 
for ( Dimension cdmdim : cdmdims ) { 
if ( cdmdim . isShared ( ) ) { 
Dimension declareddim = finddimdecl ( cdmdim ) ; 
if ( declareddim == null ) 
dapdim = ( DapDimension ) this . nodemap . get ( declareddim ) ; 
assert dapdim != null ; 
} else if ( cdmdim . isVariableLength ( ) ) { 
dapdim = builddim ( cdmdim ) ; 
dapvar . addDimension ( dapdim ) ; 
} protected EnumTypedef 
findMatchingEnum ( EnumTypedef varenum ) 
List < EnumTypedef > candidates = new ArrayList < > ( ) ; 
for ( Map . Entry < DapNode , CDMNode > entry : this . nodemap . getCDMMap ( ) . entrySet ( ) ) { 
CDMNode cdmnode = entry . getValue ( ) ; 
if ( cdmnode . getSort ( ) != CDMSort . ENUMERATION ) 
EnumTypedef target = ( EnumTypedef ) cdmnode ; 
Map < Integer , String > targetmap = target . getMap ( ) ; 
Map < Integer , String > varmap = varenum . getMap ( ) ; 
if ( targetmap . size ( ) != varmap . size ( ) ) 
boolean match = true ; 
for ( Map . Entry < Integer , String > tpair : targetmap . entrySet ( ) ) { 
String tname = tpair . getValue ( ) ; 
int value = ( int ) tpair . getKey ( ) ; 
for ( Map . Entry < Integer , String > vpair : varmap . entrySet ( ) ) { 
if ( tname . equals ( vpair . getValue ( ) ) && value == ( int ) vpair . getKey ( ) ) { 
match = false ; 
if ( ! match ) 
boolean shadowed = false ; 
for ( EnumTypedef etd : candidates ) { 
if ( shadows ( etd . getGroup ( ) , target . getGroup ( ) ) ) { 
shadowed = true ; 
if ( ! shadowed ) 
candidates . add ( target ) ; 
switch ( candidates . size ( ) ) { 
return candidates . get ( 0 ) ; 
} protected NetcdfFile 
createNetcdfFile ( String location , CancelTask canceltask ) 
NetcdfFile ncfile = NetcdfFile . open ( location , - 1 , canceltask , getContext ( ) ) ; 
de . printStackTrace ( ) ; 
throw de ; 
} static List < Dimension > 
getCoreDimset ( List < Dimension > dimset ) 
if ( dimset == null ) return null ; 
List < Dimension > core = new ArrayList < > ( ) ; 
int pos = - 1 ; 
if ( dimset . get ( i ) . isVariableLength ( ) ) { 
pos = i ; 
core . add ( dimset . get ( i ) ) ; 
if ( ( pos != dimset . size ( ) - 1 ) || count > 1 ) 
return core ; 
} protected boolean suppress ( String attrname ) 
if ( attrname . startsWith ( "_Coord" ) ) return true ; 
if ( attrname . equals ( CDM . UNSIGNED ) ) 
} public java . util . List < FileBean > scan ( String top , Formatter errlog ) { 
List < FileBean > result = new ArrayList < > ( ) ; 
File topFile = new File ( top ) ; 
if ( ! topFile . exists ( ) ) { 
if ( topFile . isDirectory ( ) ) 
scanDirectory ( topFile , false , result , errlog ) ; 
FileBean fdb = null ; 
fdb = new FileBean ( topFile ) ; 
result . add ( fdb ) ; 
} public void printConstraint ( PrintWriter os ) 
if ( constant ) { 
value . printVal ( os , "" , false ) ; 
value . printConstraint ( os ) ; 
} public static StringOrRefType initDescription ( StringOrRefType description , StationTimeSeriesFeature stationFeat ) { 
description . setStringValue ( stationFeat . getDescription ( ) ) ; 
return description ; 
} public int scanBufrFile ( String filename , Counter total ) throws Exception { 
try ( RandomAccessFile raf = new RandomAccessFile ( filename , "r" ) ) { 
MessageScanner scan = new MessageScanner ( raf ) ; 
Message m = scan . next ( ) ; 
Counter counter = new Counter ( ) ; 
processBufrMessageAsDataset ( scan , m , counter ) ; 
total . add ( counter ) ; 
indent . setIndentLevel ( 0 ) ; 
} private void processBufrMessageAsDataset ( MessageScanner scan , Message m , Counter counter ) throws Exception { 
byte [ ] mbytes = scan . getMessageBytes ( m ) ; 
NetcdfFile ncfile = NetcdfFile . openInMemory ( "test" , mbytes , "ucar.nc2.iosp.bufr.BufrIosp" ) ; 
Sequence obs = ( Sequence ) ncfile . findVariable ( BufrIosp2 . obsRecord ) ; 
StructureDataIterator sdataIter = obs . getStructureIterator ( - 1 ) ; 
processSequence ( obs , sdataIter , counter ) ; 
} private void processSequence ( Structure s , StructureDataIterator sdataIter , Counter counter ) throws IOException { 
processVariable ( v , sdata . getArray ( m ) , counter ) ; 
Structure sds = ( Structure ) v ; 
processSequence ( sds , data . getStructureDataIterator ( ) , counter ) ; 
Sequence sds = ( Sequence ) v ; 
} private void createRecordVariables ( List < ? extends VariableSimpleIF > dataVars ) { 
ncfileOut . addDimension ( null , new Dimension ( recordDimName , 0 , true , true , false ) ) ; 
Variable timeVar = ncfileOut . addVariable ( null , timeName , DataType . DOUBLE , recordDimName ) ; 
recordVars . add ( timeVar ) ; 
Variable latVar = ncfileOut . addVariable ( null , latName , DataType . DOUBLE , recordDimName ) ; 
latVar . addAttribute ( new Attribute ( CDM . UNITS , "degrees_north" ) ) ; 
latVar . addAttribute ( new Attribute ( "standard_name" , "latitude" ) ) ; 
recordVars . add ( latVar ) ; 
Variable lonVar = ncfileOut . addVariable ( null , lonName , DataType . DOUBLE , recordDimName ) ; 
lonVar . addAttribute ( new Attribute ( CDM . UNITS , "degrees_east" ) ) ; 
lonVar . addAttribute ( new Attribute ( "standard_name" , "longitude" ) ) ; 
recordVars . add ( lonVar ) ; 
if ( useAlt ) { 
Variable altVar = ncfileOut . addVariable ( null , altName , DataType . DOUBLE , recordDimName ) ; 
altVar . addAttribute ( new Attribute ( CDM . UNITS , altUnits ) ) ; 
altVar . addAttribute ( new Attribute ( "standard_name" , "longitude" ) ) ; 
altVar . addAttribute ( new Attribute ( CF . POSITIVE , CF1Convention . getZisPositive ( altName , altUnits ) ) ) ; 
recordVars . add ( altVar ) ; 
Attribute coordAtt = new Attribute ( CF . COORDINATES , coordinates ) ; 
for ( VariableSimpleIF var : dataVars ) { 
dimSet . addAll ( dims ) ; 
for ( Dimension d : dimSet ) { 
if ( isExtraDimension ( d ) ) 
ncfileOut . addDimension ( null , new Dimension ( d . getShortName ( ) , d . getLength ( ) , true , false , d . isVariableLength ( ) ) ) ; 
for ( VariableSimpleIF oldVar : dataVars ) { 
if ( ncfileOut . findVariable ( oldVar . getShortName ( ) ) != null ) continue ; 
List < Dimension > dims = oldVar . getDimensions ( ) ; 
StringBuilder dimNames = new StringBuilder ( recordDimName ) ; 
Variable newVar = ncfileOut . addVariable ( null , oldVar . getShortName ( ) , oldVar . getDataType ( ) , dimNames . toString ( ) ) ; 
recordVars . add ( newVar ) ; 
List < Attribute > atts = oldVar . getAttributes ( ) ; 
for ( Attribute att : atts ) 
newVar . addAttribute ( att ) ; 
newVar . addAttribute ( coordAtt ) ; 
List < VariableSimpleIF > dataVars = new ArrayList < VariableSimpleIF > ( ) ; 
ucar . nc2 . NetcdfFile ncfile = pfDataset . getNetcdfFile ( ) ; 
if ( ( ncfile == null ) || ! ( ncfile instanceof NetcdfDataset ) ) { 
dataVars . addAll ( pfDataset . getDataVariables ( ) ) ; 
for ( VariableSimpleIF vs : pfDataset . getDataVariables ( ) ) { 
if ( ncd . findCoordinateAxis ( vs . getShortName ( ) ) == null ) 
dataVars . add ( vs ) ; 
writer . writeHeader ( dataVars , - 1 ) ; 
} public static void rewritePointObsDataset ( String fileIn , String fileOut , boolean inMemory ) throws IOException { 
if ( writer == null ) { 
writer = new WriterCFPointDataset ( out , ncfile . getGlobalAttributes ( ) , altUnits ) ; 
writer . writeHeader ( pobsDataset . getDataVariables ( ) , - 1 ) ; 
writer . writeRecord ( pobsData , sdata ) ; 
} public void doGet ( HttpServletRequest req , HttpServletResponse res ) 
throws ServletException , IOException { 
String urlString = req . getParameter ( "URL" ) ; 
if ( urlString == null ) { 
URI uri = new URI ( urlString ) ; 
urlString = uri . toASCIIString ( ) ; 
String xml = req . getParameter ( "xml" ) ; 
boolean wantXml = ( xml != null ) && xml . equals ( "true" ) ; 
int len = showValidatorResults ( res , urlString , wantXml ) ; 
} public void doPost ( HttpServletRequest req , HttpServletResponse res ) 
boolean isMultipart = ServletFileUpload . isMultipartContent ( req ) ; 
if ( ! isMultipart ) { 
res . sendError ( HttpServletResponse . SC_BAD_REQUEST ) ; 
ServletFileUpload upload = new ServletFileUpload ( this . cdmValidatorContext . getFileuploadFileItemFactory ( ) ) ; 
upload . setSizeMax ( this . cdmValidatorContext . getMaxFileUploadSize ( ) ) ; 
List < FileItem > fileItems ; 
fileItems = ( List < FileItem > ) upload . parseRequest ( req ) ; 
} catch ( FileUploadException e ) { 
if ( ! res . isCommitted ( ) ) res . sendError ( HttpServletResponse . SC_BAD_REQUEST ) ; 
String username = null ; 
boolean wantXml = false ; 
for ( FileItem item : fileItems ) { 
if ( item . isFormField ( ) ) { 
if ( "username" . equals ( item . getFieldName ( ) ) ) 
username = item . getString ( ) ; 
if ( "xml" . equals ( item . getFieldName ( ) ) ) 
wantXml = item . getString ( ) . equals ( "true" ) ; 
if ( ! item . isFormField ( ) ) { 
processUploadedFile ( req , res , ( DiskFileItem ) item , username , wantXml ) ; 
res . sendError ( HttpServletResponse . SC_BAD_REQUEST , e . getMessage ( ) ) ; 
public Iterator < TrajectoryFeature > iterator ( ) { 
PointFeatureCollectionIterator pfIterator = getPointFeatureCollectionIterator ( ) ; 
return new CollectionIteratorAdapter < > ( pfIterator ) ; 
} public AffineTransform getTransform ( ) { 
at . setTransform ( pix_per_world , 0.0 , 0.0 , - pix_per_world , pix_x0 , pix_y0 ) ; 
} public boolean wantRotate ( double displayWidth , double displayHeight ) { 
getMapArea ( bb ) ; 
boolean aspectDisplay = displayHeight < displayWidth ; 
boolean aspectWorldBB = bb . getHeight ( ) < bb . getWidth ( ) ; 
return ( aspectDisplay ^ aspectWorldBB ) ; 
} public AffineTransform calcTransform ( boolean rotate , double displayX , double displayY , double displayWidth , double displayHeight ) { 
double pxpsx , pypsy ; 
if ( rotate ) { 
pxpsx = displayHeight / bb . getWidth ( ) ; 
pypsy = displayWidth / bb . getHeight ( ) ; 
pxpsx = displayWidth / bb . getWidth ( ) ; 
pypsy = displayHeight / bb . getHeight ( ) ; 
double pps = Math . min ( pxpsx , pypsy ) ; 
double wx0 = bb . getX ( ) + bb . getWidth ( ) / 2 ; 
double wy0 = bb . getY ( ) + bb . getHeight ( ) / 2 ; 
double x0 = displayX + displayWidth / 2 - pps * wx0 ; 
double y0 = displayY + displayHeight / 2 + pps * wy0 ; 
AffineTransform cat = new AffineTransform ( pps , 0.0 , 0.0 , - pps , x0 , y0 ) ; 
if ( rotate ) 
cat . rotate ( Math . PI / 2 , wx0 , wy0 ) ; 
} public ProjectionRect getMapArea ( ProjectionRect rect ) { 
if ( rect == null ) 
rect = new ProjectionRect ( ) ; 
double width = pwidth / pix_per_world ; 
double height = pheight / pix_per_world ; 
double wx0 = ( pwidth / 2 - pix_x0 ) / pix_per_world ; 
double wy0 = ( pix_y0 - pheight / 2 ) / pix_per_world ; 
rect . setRect ( wx0 - width / 2 , wy0 - height / 2 , 
width , height ) ; 
} public Point2D worldToScreen ( ProjectionPointImpl w , Point2D p ) { 
p . setLocation ( pix_per_world * w . getX ( ) + pix_x0 , 
- pix_per_world * w . getY ( ) + pix_y0 ) ; 
} public ProjectionRect screenToWorld ( Point2D start , Point2D end ) { 
ProjectionPointImpl p1 = new ProjectionPointImpl ( ) ; 
ProjectionPointImpl p2 = new ProjectionPointImpl ( ) ; 
screenToWorld ( start , p1 ) ; 
screenToWorld ( end , p2 ) ; 
return new ProjectionRect ( p1 . getX ( ) , p1 . getY ( ) , p2 . getX ( ) , p2 . getY ( ) ) ; 
} public java . awt . Rectangle worldToScreen ( ProjectionRect projRect ) { 
Point2D p1 = new Point2D . Double ( ) ; 
Point2D p2 = new Point2D . Double ( ) ; 
worldToScreen ( ( ProjectionPointImpl ) projRect . getMaxPoint ( ) , p1 ) ; 
worldToScreen ( ( ProjectionPointImpl ) projRect . getMinPoint ( ) , p2 ) ; 
return new java . awt . Rectangle ( ( int ) p1 . getX ( ) , ( int ) p1 . getY ( ) , ( int ) p2 . getX ( ) , ( int ) p2 . getY ( ) ) ; 
} public void pan ( double deltax , double deltay ) { 
zoom . push ( ) ; 
pix_x0 -= deltax ; 
pix_y0 -= deltay ; 
fireMapAreaEvent ( ) ; 
} public void zoom ( double startx , double starty , double width , double height ) { 
if ( debugZoom ) 
if ( ( width < 5 ) || ( height < 5 ) ) 
pix_x0 -= startx + width / 2 - pwidth / 2 ; 
pix_y0 -= starty + height / 2 - pheight / 2 ; 
zoom ( pwidth / width ) ; 
} private void recalcFromBoundingBox ( ) { 
if ( debugRecalc ) { 
double pixx_per_wx = ( bb . getWidth ( ) == 0.0 ) ? 1 : pwidth / bb . getWidth ( ) ; 
double pixy_per_wy = ( bb . getHeight ( ) == 0.0 ) ? 1 : pheight / bb . getHeight ( ) ; 
pix_per_world = Math . min ( pixx_per_wx , pixy_per_wy ) ; 
pix_x0 = pwidth / 2 - pix_per_world * wx0 ; 
pix_y0 = pheight / 2 + pix_per_world * wy0 ; 
} public synchronized void addListener ( Object l ) { 
if ( ! listeners . contains ( l ) ) { 
listeners . add ( l ) ; 
hasListeners = true ; 
} public synchronized void removeListener ( Object l ) { 
if ( listeners . contains ( l ) ) { 
listeners . remove ( l ) ; 
hasListeners = ( listeners . size ( ) > 0 ) ; 
} public synchronized void sendEvent ( java . util . EventObject event ) { 
if ( ! hasListeners || ! enabled ) 
Object [ ] args = new Object [ 1 ] ; 
args [ 0 ] = event ; 
ListIterator iter = listeners . listIterator ( ) ; 
Object client = iter . next ( ) ; 
method . invoke ( client , args ) ; 
} public synchronized void sendEventExcludeSource ( java . util . EventObject event ) { 
Object source = event . getSource ( ) ; 
if ( client == source ) 
} catch ( IllegalAccessException | InvocationTargetException | IllegalArgumentException e ) { 
if ( e . getCause ( ) != null ) 
e . getCause ( ) . printStackTrace ( ) ; 
} public static boolean print ( String command , Writer out , ucar . nc2 . util . CancelTask ct ) throws IOException { 
String filename ; 
StringTokenizer stoke = new StringTokenizer ( command ) ; 
filename = stoke . nextToken ( ) ; 
out . write ( usage ) ; 
try ( NetcdfFile nc = NetcdfDataset . openFile ( filename , ct ) ) { 
int pos = command . indexOf ( filename ) ; 
command = command . substring ( pos + filename . length ( ) ) ; 
return print ( nc , command , out , ct ) ; 
} catch ( java . io . FileNotFoundException e ) { 
out . write ( filename ) ; 
} public static boolean print ( NetcdfFile nc , String command , Writer out , ucar . nc2 . util . CancelTask ct ) 
WantValues showValues = WantValues . none ; 
boolean ncml = false ; 
boolean strict = false ; 
String varNames = null ; 
String trueDataset = null ; 
String fakeDataset = null ; 
if ( command != null ) { 
String toke = stoke . nextToken ( ) ; 
if ( toke . equalsIgnoreCase ( "-help" ) ) { 
out . write ( '\n' ) ; 
if ( toke . equalsIgnoreCase ( "-vall" ) ) 
showValues = WantValues . all ; 
if ( toke . equalsIgnoreCase ( "-c" ) && ( showValues == WantValues . none ) ) 
showValues = WantValues . coordsOnly ; 
if ( toke . equalsIgnoreCase ( "-ncml" ) ) 
ncml = true ; 
if ( toke . equalsIgnoreCase ( "-cdl" ) || toke . equalsIgnoreCase ( "-strict" ) ) 
strict = true ; 
if ( toke . equalsIgnoreCase ( "-v" ) && stoke . hasMoreTokens ( ) ) 
varNames = stoke . nextToken ( ) ; 
if ( toke . equalsIgnoreCase ( "-datasetname" ) && stoke . hasMoreTokens ( ) ) { 
fakeDataset = stoke . nextToken ( ) ; 
if ( fakeDataset . length ( ) == 0 ) fakeDataset = null ; 
if ( fakeDataset != null ) { 
trueDataset = nc . getLocation ( ) ; 
nc . setLocation ( fakeDataset ) ; 
boolean ok = print ( nc , out , showValues , ncml , strict , varNames , ct ) ; 
if ( trueDataset != null && fakeDataset != null ) 
nc . setLocation ( trueDataset ) ; 
} public static boolean print ( String filename , Writer out , boolean showAll , boolean showCoords , boolean ncml , 
boolean strict , String varNames , ucar . nc2 . util . CancelTask ct ) throws IOException { 
return print ( nc , out , showAll , showCoords , ncml , strict , varNames , ct ) ; 
} public static boolean print ( NetcdfFile nc , Writer out , boolean showAll , boolean showCoords , 
boolean ncml , boolean strict , String varNames , ucar . nc2 . util . CancelTask ct ) throws IOException { 
if ( showAll ) 
else if ( showCoords ) 
return print ( nc , out , showValues , ncml , strict , varNames , ct ) ; 
} public static boolean print ( NetcdfFile nc , Writer out , WantValues showValues , boolean ncml , boolean strict , 
String varNames , ucar . nc2 . util . CancelTask ct ) throws IOException { 
boolean headerOnly = ( showValues == WantValues . none ) && ( varNames == null ) ; 
if ( ncml ) 
writeNcML ( nc , out , showValues , null ) ; 
else if ( headerOnly ) 
nc . writeCDL ( new PrintWriter ( out ) , strict ) ; 
PrintWriter ps = new PrintWriter ( out ) ; 
nc . toStringStart ( ps , strict ) ; 
Indent indent = new Indent ( 2 ) ; 
ps . printf ( "%n%sdata:%n" , indent ) ; 
if ( showValues == WantValues . all ) { 
for ( Variable v : nc . getVariables ( ) ) { 
printArray ( v . read ( ) , v . getFullName ( ) , ps , indent , ct ) ; 
if ( ct != null && ct . isCancel ( ) ) return false ; 
} else if ( showValues == WantValues . coordsOnly ) { 
if ( v . isCoordinateVariable ( ) ) 
if ( ( showValues != WantValues . all ) && ( varNames != null ) ) { 
StringTokenizer stoke = new StringTokenizer ( varNames , ";" ) ; 
String varSubset = stoke . nextToken ( ) ; 
if ( varSubset . indexOf ( '(' ) >= 0 ) { 
Array data = nc . readSection ( varSubset ) ; 
printArray ( data , varSubset , ps , indent , ct ) ; 
Variable v = nc . findVariable ( varSubset ) ; 
if ( ( showValues != WantValues . coordsOnly ) || v . isCoordinateVariable ( ) ) 
nc . toStringEnd ( ps ) ; 
out . write ( e . getMessage ( ) ) ; 
} static public String printVariableData ( VariableIF v , ucar . nc2 . util . CancelTask ct ) throws IOException { 
Array data = v . read ( ) ; 
StringWriter writer = new StringWriter ( 10000 ) ; 
printArray ( data , v . getFullName ( ) , new PrintWriter ( writer ) , new Indent ( 2 ) , ct ) ; 
return writer . toString ( ) ; 
} static public String printVariableDataSection ( Variable v , String sectionSpec , ucar . nc2 . util . CancelTask ct ) throws IOException , InvalidRangeException { 
Array data = v . read ( sectionSpec ) ; 
StringWriter writer = new StringWriter ( 20000 ) ; 
} static public void printStructureData ( PrintWriter out , StructureData sdata ) throws IOException { 
printStructureData ( out , sdata , new Indent ( 2 ) , null ) ; 
} static public void printArrayPlain ( Array ma , PrintWriter out ) { 
ma . resetLocalIterator ( ) ; 
while ( ma . hasNext ( ) ) { 
out . print ( ma . next ( ) ) ; 
} static public void printArray ( Array array , PrintWriter pw ) { 
printArray ( array , null , null , pw , new Indent ( 2 ) , null , true ) ; 
} static public void writeNcML ( NetcdfFile ncfile , Writer writer , WantValues showValues , String url ) throws IOException { 
Preconditions . checkNotNull ( ncfile ) ; 
Preconditions . checkNotNull ( writer ) ; 
Preconditions . checkNotNull ( showValues ) ; 
Predicate < Variable > writeVarsPred ; 
switch ( showValues ) { 
case none : 
writeVarsPred = NcMLWriter . writeNoVariablesPredicate ; 
case coordsOnly : 
writeVarsPred = NcMLWriter . writeCoordinateVariablesPredicate ; 
case all : 
writeVarsPred = NcMLWriter . writeAllVariablesPredicate ; 
throw new AssertionError ( message ) ; 
ncmlWriter . setWriteVariablesPredicate ( writeVarsPred ) ; 
Element netcdfElement = ncmlWriter . makeNetcdfElement ( ncfile , url ) ; 
ncmlWriter . writeToWriter ( netcdfElement , writer ) ; 
for ( String arg : args ) { 
sbuff . append ( arg ) ; 
Writer writer = new BufferedWriter ( new OutputStreamWriter ( System . out , CDM . utf8Charset ) ) ; 
NCdumpW . print ( sbuff . toString ( ) , writer , null ) ; 
} static public double getFalseEastingScaleFactor ( NetcdfDataset ds , AttributeContainer ctv ) { 
String units = getGeoCoordinateUnits ( ds , ctv ) ; 
return getFalseEastingScaleFactor ( units ) ; 
} protected double readAttributeDouble ( AttributeContainer v , String attname , double defValue ) { 
Attribute att = v . findAttributeIgnoreCase ( attname ) ; 
if ( att == null ) return defValue ; 
if ( att . isString ( ) ) 
return Double . parseDouble ( att . getStringValue ( ) ) ; 
return att . getNumericValue ( ) . doubleValue ( ) ; 
} protected double [ ] readAttributeDouble2 ( Attribute att ) { 
double [ ] val = new double [ 2 ] ; 
if ( att . isString ( ) ) { 
StringTokenizer stoke = new StringTokenizer ( att . getStringValue ( ) ) ; 
val [ 0 ] = Double . parseDouble ( stoke . nextToken ( ) ) ; 
val [ 1 ] = stoke . hasMoreTokens ( ) ? Double . parseDouble ( stoke . nextToken ( ) ) : val [ 0 ] ; 
val [ 0 ] = att . getNumericValue ( ) . doubleValue ( ) ; 
val [ 1 ] = ( att . getLength ( ) > 1 ) ? att . getNumericValue ( 1 ) . doubleValue ( ) : val [ 0 ] ; 
} protected boolean addParameter ( CoordinateTransform rs , String paramName , NetcdfFile ds , String varNameEscaped ) { 
if ( null == ( ds . findVariable ( varNameEscaped ) ) ) { 
if ( null != errBuffer ) 
rs . addParameter ( new Parameter ( paramName , varNameEscaped ) ) ; 
} protected double getEarthRadiusInKm ( AttributeContainer ctv ) { 
double earth_radius = readAttributeDouble ( ctv , CF . EARTH_RADIUS , Earth . getRadius ( ) ) ; 
if ( earth_radius > 10000.0 ) earth_radius *= .001 ; 
return earth_radius ; 
AccessLogParser p = new AccessLogParser ( ) ; 
Matcher m = regPattern . matcher ( line ) ; 
for ( int i = 0 ; i < m . groupCount ( ) ; i ++ ) { 
LogReader . Log log = p . parseLog ( line ) ; 
System . out . printf ( "%s%n" , log ) ; 
if ( serviceName != null ) { 
this . service = dataset . findService ( serviceName ) ; 
if ( this . service == null ) 
new java . net . URI ( urlPath ) ; 
} boolean check ( StringBuilder out , boolean show ) { 
if ( log . length ( ) > 0 ) { 
if ( getService ( ) == null ) { 
else if ( getStandardUrlName ( ) == null ) { 
public Object 
read ( Index index ) 
return read ( DapUtil . indexToSlices ( index ) ) ; 
} protected Object 
readAtomic ( List < Slice > slices ) 
if ( slices == null ) 
assert this . scheme == Scheme . ATOMIC ; 
DapVariable atomvar = ( DapVariable ) getTemplate ( ) ; 
int rank = atomvar . getRank ( ) ; 
assert slices != null && ( ( rank == 0 && slices . size ( ) == 1 ) || ( slices . size ( ) == rank ) ) ; 
DapType basetype = atomvar . getBaseType ( ) ; 
return readAs ( atomvar , basetype , slices ) ; 
readAs ( DapVariable atomvar , DapType basetype , List < Slice > slices ) 
if ( basetype . getTypeSort ( ) == TypeSort . Enum ) { 
basetype = ( ( DapEnumeration ) basetype ) . getBaseType ( ) ; 
long count = DapUtil . sliceProduct ( slices ) ; 
Object result = LibTypeFcns . newVector ( basetype , count ) ; 
Odometer odom = Odometer . factory ( slices ) ; 
if ( DapUtil . isContiguous ( slices ) && basetype . isFixedSize ( ) ) 
readContig ( slices , basetype , count , odom , result ) ; 
readOdom ( slices , basetype , odom , result ) ; 
} public D4Cursor 
setElements ( D4Cursor [ ] instances ) 
if ( ! ( getScheme ( ) == Scheme . SEQARRAY 
|| getScheme ( ) == Scheme . STRUCTARRAY ) ) 
DapVariable var = ( DapVariable ) getTemplate ( ) ; 
this . elements = instances ; 
Map < String , Object > flds = new HashMap < > ( ) ; 
flds . put ( Dataset . FeatureType , FeatureType . GRID . toString ( ) ) ; 
flds . put ( Dataset . ServiceName , ServiceType . File . toString ( ) ) ; 
invDs = new Dataset ( null , filename , flds , null , null ) ; 
ProjectionImpl proj = navPanel . getProjectionImpl ( ) . constructCopy ( ) ; 
proj . setDefaultMapArea ( navPanel . getMapArea ( ) ) ; 
start ( true ) ; 
draw ( true ) ; 
if ( coverageDataset != null ) { 
coverageDataset . toString ( f ) ; 
datasetInfoTA . appendLine ( f . toString ( ) ) ; 
setDataMinMaxType ( ColorScale . MinMaxType . horiz ) ; 
setDataMinMaxType ( ColorScale . MinMaxType . log ) ; 
setDataMinMaxType ( ColorScale . MinMaxType . hold ) ; 
runtimeLoopAction = new LoopControlAction ( runtimeChooser ) ; 
} private void makeActions ( ) { 
boolean state ; 
dataProjectionAction = new AbstractAction ( ) { 
Boolean state = ( Boolean ) getValue ( BAMutil . STATE ) ; 
ProjectionImpl dataProjection = coverageRenderer . getDataProjection ( ) ; 
if ( null != dataProjection ) 
setProjection ( new LatLonProjection ( ) ) ; 
dataProjectionAction . putValue ( BAMutil . STATE , true ) ; 
drawBBAction = new AbstractAction ( ) { 
coverageRenderer . setDrawBB ( state . booleanValue ( ) ) ; 
draw ( false ) ; 
drawBBAction . putValue ( BAMutil . STATE , false ) ; 
drawHorizAction = new AbstractAction ( ) { 
drawHorizOn = state . booleanValue ( ) ; 
setDrawHorizAndVert ( drawHorizOn , drawVertOn ) ; 
state = store . getBoolean ( "drawHorizAction" , true ) ; 
drawHorizAction . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
drawHorizOn = state ; 
drawVertAction = new AbstractAction ( ) { 
drawVertOn = state . booleanValue ( ) ; 
state = store . getBoolean ( "drawVertAction" , false ) ; 
drawVertAction . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
drawVertOn = state ; 
showGridAction = new AbstractAction ( ) { 
coverageRenderer . setDrawGridLines ( state . booleanValue ( ) ) ; 
state = store . getBoolean ( "showGridAction" , false ) ; 
showGridAction . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
coverageRenderer . setDrawGridLines ( state ) ; 
showContoursAction = new AbstractAction ( ) { 
coverageRenderer . setDrawContours ( state . booleanValue ( ) ) ; 
state = store . getBoolean ( "showContoursAction" , false ) ; 
showContoursAction . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
coverageRenderer . setDrawContours ( state ) ; 
showContourLabelsAction = new AbstractAction ( ) { 
coverageRenderer . setDrawContourLabels ( state . booleanValue ( ) ) ; 
state = store . getBoolean ( "showContourLabelsAction" , false ) ; 
showContourLabelsAction . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
coverageRenderer . setDrawContourLabels ( state ) ; 
store . putBeanObject ( LastMapAreaName , navPanel . getMapArea ( ) ) ; 
store . putBeanObject ( LastProjectionName , navPanel . getProjectionImpl ( ) ) ; 
store . putBeanObject ( ColorScaleName , colorScale ) ; 
store . putBoolean ( "showGridAction" , ( ( Boolean ) showGridAction . getValue ( BAMutil . STATE ) ) . booleanValue ( ) ) ; 
store . putBoolean ( "showContoursAction" , ( ( Boolean ) showContoursAction . getValue ( BAMutil . STATE ) ) . booleanValue ( ) ) ; 
store . putBoolean ( "showContourLabelsAction" , ( ( Boolean ) showContourLabelsAction . getValue ( BAMutil . STATE ) ) . booleanValue ( ) ) ; 
} private void setSelected ( boolean b ) { 
selected = b ; 
navToolbarAction . setEnabled ( b ) ; 
moveToolbarAction . setEnabled ( b ) ; 
redrawAction . setEnabled ( b ) ; 
minmaxHorizAction . setEnabled ( b ) ; 
minmaxLogAction . setEnabled ( b ) ; 
minmaxHoldAction . setEnabled ( b ) ; 
fieldLoopAction . setEnabled ( b ) ; 
levelLoopAction . setEnabled ( b ) ; 
timeLoopAction . setEnabled ( b ) ; 
runtimeLoopAction . setEnabled ( b ) ; 
navPanel . setEnabledActions ( b ) ; 
Iterable < Coverage > grids = coverageDataset . getCoverages ( ) ; 
currentField = grids . iterator ( ) . next ( ) ; 
this . dataState = coverageRenderer . setCoverage ( coverageDataset , currentField ) ; 
coverageRenderer . setDataProjection ( currentField . getCoordSys ( ) . getProjection ( ) ) ; 
ProjectionImpl dataProjection = currentField . getCoordSys ( ) . getProjection ( ) ; 
} private synchronized void redrawLater ( ) { 
boolean already = redrawTimer . isRunning ( ) ; 
if ( already ) 
redrawTimer . restart ( ) ; 
redrawTimer . start ( ) ; 
String name = gr . getParameterName ( ) ; 
GridParameter gp = GempakGridParameterTable . getParameter ( name ) ; 
if ( gp != null ) { 
return gp ; 
return new GridParameter ( 0 , name , name , "" ) ; 
} public final boolean isPositiveUp ( GridRecord gr ) { 
if ( ( type == 1 ) || ( type == 5 ) ) { 
} public static ReferenceType initObservedProperty ( ReferenceType observedProperty , VariableSimpleIF dataVar ) { 
observedProperty . setTitle ( dataVar . getShortName ( ) ) ; 
return observedProperty ; 
} public javax . swing . Action getAction ( ) { 
AbstractAction useMap = new AbstractAction ( getActionName ( ) , getIcon ( ) ) { 
public void actionPerformed ( java . awt . event . ActionEvent e ) { 
firePropertyChangeEvent ( this , "Renderer" , null , getRenderer ( ) ) ; 
useMap . putValue ( Action . SHORT_DESCRIPTION , getActionDesc ( ) ) ; 
return useMap ; 
} static public PopupMenu makeMapSelectButton ( ) { 
AbstractAction mapSelectAction = new AbstractAction ( ) { 
AbstractButton mapSelectButton = BAMutil . makeButtconFromAction ( mapSelectAction ) ; 
return mapPopup ; 
} public double [ ] convertTo ( final double [ ] amounts , final Unit outputUnit ) 
return convertTo ( amounts , outputUnit , new double [ amounts . length ] ) ; 
} public float [ ] convertTo ( final float [ ] input , final Unit outputUnit , 
final float [ ] output ) throws ConversionException { 
return getConverterTo ( outputUnit ) . convert ( input , output ) ; 
} public boolean isCompatible ( final Unit that ) { 
final Unit u1 = getDerivedUnit ( ) ; 
return u1 . equals ( that . getDerivedUnit ( ) ) ; 
} public String makeLabel ( final String quantityID ) { 
final StringBuilder buf = new StringBuilder ( quantityID ) ; 
buf . insert ( 0 , '(' ) . append ( ')' ) ; 
buf . append ( '/' ) ; 
final int start = buf . length ( ) ; 
buf . append ( toString ( ) ) ; 
buf . insert ( start , '(' ) . append ( ')' ) ; 
} public static MonitoringPointType initMonitoringPointType ( 
MonitoringPointType monitoringPoint , StationTimeSeriesFeature stationFeat ) { 
String id = MarshallingUtil . createIdForType ( MonitoringPointType . class ) ; 
monitoringPoint . setId ( id ) ; 
NcCodeWithAuthorityType . initIdentifier ( monitoringPoint . addNewIdentifier ( ) , stationFeat ) ; 
NcStringOrRefType . initDescription ( monitoringPoint . addNewDescription ( ) , stationFeat ) ; 
if ( monitoringPoint . getDescription ( ) . getStringValue ( ) == null || 
monitoringPoint . getDescription ( ) . getStringValue ( ) . isEmpty ( ) ) { 
monitoringPoint . unsetDescription ( ) ; 
monitoringPoint . addNewSampledFeature ( ) ; 
monitoringPoint . setNilSampledFeatureArray ( 0 ) ; 
NcShapeType . initShape ( monitoringPoint . addNewShape ( ) , stationFeat ) ; 
return monitoringPoint ; 
} public List < Polygon > getPolygons ( String name , int indexBegin , int indexEnd ) { 
return builder . getPolygons ( name , indexBegin , indexEnd ) ; 
} public List < Line > getLines ( String name , int indexBegin , int indexEnd ) { 
return builder . getLines ( name , indexBegin , indexEnd ) ; 
} public List < Point > getPoints ( String name , int indexBegin , int indexEnd ) { 
return builder . getPoints ( name , indexBegin , indexEnd ) ; 
} public void setBitOffset ( int bitOffset ) throws IOException { 
if ( bitOffset % 8 == 0 ) { 
raf . seek ( startPos + bitOffset / 8 ) ; 
bitPos = 8 - ( bitOffset % 8 ) ; 
bitBuf = ( byte ) raf . read ( ) ; 
} public long bits2UInt ( int nb ) throws IOException { 
assert nb <= 64 ; 
assert nb >= 0 ; 
while ( bitsLeft > 0 ) { 
bitBuf = nextByte ( ) ; 
bitPos = BIT_LENGTH ; 
int size = Math . min ( bitsLeft , bitPos ) ; 
int myBits = bitBuf > > ( bitPos - size ) ; 
myBits &= BYTE_BITMASK ; 
myBits &= ~ ( BYTE_BITMASK << size ) ; 
int shift = bitsLeft - size ; 
assert shift >= 0 ; 
result |= myBits << shift ; 
bitsLeft -= size ; 
bitPos -= size ; 
} public long bits2SInt ( int nb ) throws IOException { 
long result = bits2UInt ( nb ) ; 
if ( getBit ( result , nb ) ) { 
result = setBit ( result , nb , false ) ; 
result = ~ result & LONG_BITMASK ; 
result = result + 1 ; 
} private void openConnection ( String urlString , Command command ) throws IOException , DAP2Exception 
try ( HTTPMethod method = HTTPFactory . Get ( _session , urlString ) ) { 
if ( acceptCompress ) 
method . setCompression ( "deflate,gzip" ) ; 
if ( allowSessions ) 
method . setUseSessions ( true ) ; 
int statusCode ; 
statusCode = method . execute ( ) ; 
if ( statusCode != HttpStatus . SC_SERVICE_UNAVAILABLE ) 
if ( statusCode == HttpStatus . SC_NOT_FOUND ) { 
if ( statusCode == HttpStatus . SC_UNAUTHORIZED || statusCode == HttpStatus . SC_FORBIDDEN ) { 
throw new InvalidCredentialsException ( method . getStatusText ( ) ) ; 
if ( statusCode != HttpStatus . SC_OK ) { 
is = method . getResponseAsStream ( ) ; 
Header header = method . getResponseHeader ( "Content-Description" ) ; 
if ( header != null && ( header . getValue ( ) . equals ( "dods-error" ) 
|| header . getValue ( ) . equals ( "dods_error" ) ) ) { 
DAP2Exception ds = new DAP2Exception ( ) ; 
ds . parse ( is ) ; 
throw ds ; 
ver = new ServerVersion ( method ) ; 
checkHeaders ( method ) ; 
Header h = method . getResponseHeader ( "content-encoding" ) ; 
is = new BufferedInputStream ( new InflaterInputStream ( is ) , 1000 ) ; 
is = new BufferedInputStream ( new GZIPInputStream ( is ) , 1000 ) ; 
command . process ( is ) ; 
} catch ( IOException | DAP2Exception e ) { 
Util . check ( e ) ; 
throw new DAP2Exception ( e ) ; 
} public DAS getDAS ( ) throws IOException , DAP2Exception 
DASCommand command = new DASCommand ( ) ; 
if ( filePath != null ) { 
File daspath = new File ( filePath + ".das" ) ; 
if ( daspath . canRead ( ) ) { 
try ( FileInputStream is = new FileInputStream ( daspath ) ) { 
} else if ( stream != null ) { 
command . process ( stream ) ; 
openConnection ( urlString + ".das" + getCompleteCE ( projString , selString ) , command ) ; 
return command . das ; 
} public DDS getDDS ( String CE ) throws IOException , ParseException , DAP2Exception 
DDSCommand command = new DDSCommand ( ) ; 
command . setURL ( CE == null || CE . length ( ) == 0 ? urlString : urlString + "?" + CE ) ; 
try ( FileInputStream is = new FileInputStream ( filePath + ".dds" ) ) { 
openConnection ( urlString + ".dds" + ( getCompleteCE ( CE ) ) , command ) ; 
return command . dds ; 
} private String getCompleteCE ( String CE ) 
String localProjString = null ; 
String localSelString = null ; 
if ( CE == null ) 
if ( CE . startsWith ( "?" ) ) CE = CE . substring ( 1 ) ; 
int selIndex = CE . indexOf ( '&' ) ; 
if ( selIndex == 0 ) { 
localProjString = "" ; 
localSelString = CE ; 
} else if ( selIndex > 0 ) { 
localSelString = CE . substring ( selIndex ) ; 
localProjString = CE . substring ( 0 , selIndex ) ; 
localProjString = CE ; 
localSelString = "" ; 
String ce = projString ; 
if ( ! localProjString . equals ( "" ) ) { 
if ( ! ce . equals ( "" ) && localProjString . indexOf ( ',' ) != 0 ) 
ce += "," ; 
ce += localProjString ; 
if ( ! selString . equals ( "" ) ) { 
if ( selString . indexOf ( '&' ) != 0 ) 
ce += "&" ; 
ce += selString ; 
if ( ! localSelString . equals ( "" ) ) { 
if ( localSelString . indexOf ( '&' ) != 0 ) 
ce += localSelString ; 
if ( ce . length ( ) > 0 ) ce = "?" + ce ; 
return ce ; 
} private String 
getCompleteCE ( String proj , String sel ) 
if ( proj != null && proj . length ( ) == 0 ) proj = "" ; 
if ( sel != null && sel . length ( ) == 0 ) sel = null ; 
if ( proj . startsWith ( "?" ) ) 
buf . append ( proj . substring ( 1 ) ) ; 
buf . append ( proj ) ; 
if ( sel != null ) { 
if ( sel . startsWith ( "&" ) ) 
buf . append ( sel ) ; 
buf . append ( "&" ) ; 
return getCompleteCE ( buf . toString ( ) ) ; 
} public DDS getDDX ( String CE ) throws IOException , ParseException , DDSException , DAP2Exception 
DDXCommand command = new DDXCommand ( ) ; 
openConnection ( urlString + ".ddx" + ( getCompleteCE ( CE ) ) , command ) ; 
} public DataDDS getDataDDX ( String CE ) throws MalformedURLException , IOException , 
ParseException , DDSException , DAP2Exception 
return getDataDDX ( CE , new DefaultFactory ( ) ) ; 
} public DataDDS getDataDDX ( String CE , BaseTypeFactory btf ) throws MalformedURLException , IOException , 
DataDDXCommand command = new DataDDXCommand ( btf , this . ver ) ; 
} public DataDDS getData ( String CE , StatusUI statusUI , BaseTypeFactory btf ) throws MalformedURLException , IOException , 
if ( CE != null && CE . trim ( ) . length ( ) == 0 ) CE = null ; 
DataDDS dds = new DataDDS ( ver , btf ) ; 
DataDDSCommand command = new DataDDSCommand ( dds , statusUI ) ; 
command . setURL ( urlString + ( CE == null ? "" : "?" + CE ) ) ; 
File dodspath = new File ( filePath + ".dods" ) ; 
if ( dodspath . canRead ( ) ) { 
try ( FileInputStream is = new FileInputStream ( dodspath ) ) { 
String urls = urlString + ".dods" + ( CE == null ? "" : getCompleteCE ( CE ) ) ; 
openConnection ( urls , command ) ; 
} public DataDDS getData ( String CE , StatusUI statusUI ) throws MalformedURLException , IOException , 
return getData ( CE , statusUI , new DefaultFactory ( ) ) ; 
public boolean crossSeam ( ProjectionPoint pt1 , ProjectionPoint pt2 ) { 
double x1 = pt1 . getX ( ) - falseEasting ; 
double x2 = pt2 . getX ( ) - falseEasting ; 
return ( x1 * x2 < 0 ) && ( Math . abs ( x1 - x2 ) > earthRadius ) ; 
public ProjectionPoint latLonToProj ( LatLonPoint latLon , ProjectionPointImpl result ) { 
double deltaLon_d = LatLonPointImpl . range180 ( latLon . getLongitude ( ) - centMeridian ) ; 
double fromLat_r = Math . toRadians ( latLon . getLatitude ( ) ) ; 
double toX = earthRadius * Math . toRadians ( deltaLon_d ) * Math . cos ( fromLat_r ) ; 
double toY = earthRadius * fromLat_r ; 
public LatLonPoint projToLatLon ( ProjectionPoint world , LatLonPointImpl result ) { 
double toLat_r = fromY / earthRadius ; 
double toLon_r ; 
if ( Misc . nearlyEquals ( Math . abs ( toLat_r ) , PI_OVER_2 , 1e-10 ) ) { 
toLat_r = toLat_r < 0 ? - PI_OVER_2 : + PI_OVER_2 ; 
toLon_r = Math . toRadians ( centMeridian ) ; 
} else if ( Math . abs ( toLat_r ) < PI_OVER_2 ) { 
toLon_r = Math . toRadians ( centMeridian ) + fromX / ( earthRadius * Math . cos ( toLat_r ) ) ; 
return INVALID ; 
if ( Misc . nearlyEquals ( Math . abs ( toLon_r ) , PI , 1e-10 ) ) { 
toLon_r = toLon_r < 0 ? - PI : + PI ; 
} else if ( Math . abs ( toLon_r ) > PI ) { 
result . setLatitude ( Math . toDegrees ( toLat_r ) ) ; 
result . setLongitude ( Math . toDegrees ( toLon_r ) ) ; 
} public List < ProjectionPoint > getMapEdgeIntercepts ( ProjectionRect projBB ) { 
List < ProjectionPoint > intercepts = new LinkedList < > ( ) ; 
for ( ProjectionPoint topIntercept : getMapEdgeInterceptsAtY ( projBB . getUpperRightPoint ( ) . getY ( ) ) ) { 
if ( pointIsBetween ( topIntercept , projBB . getUpperLeftPoint ( ) , projBB . getUpperRightPoint ( ) ) ) { 
intercepts . add ( topIntercept ) ; 
for ( ProjectionPoint rightIntercept : getMapEdgeInterceptsAtX ( projBB . getUpperRightPoint ( ) . getX ( ) ) ) { 
if ( pointIsBetween ( rightIntercept , projBB . getUpperRightPoint ( ) , projBB . getLowerRightPoint ( ) ) ) { 
intercepts . add ( rightIntercept ) ; 
for ( ProjectionPoint bottomIntercept : getMapEdgeInterceptsAtY ( projBB . getLowerLeftPoint ( ) . getY ( ) ) ) { 
if ( pointIsBetween ( bottomIntercept , projBB . getLowerLeftPoint ( ) , projBB . getLowerRightPoint ( ) ) ) { 
intercepts . add ( bottomIntercept ) ; 
for ( ProjectionPoint leftIntercept : getMapEdgeInterceptsAtX ( projBB . getLowerLeftPoint ( ) . getX ( ) ) ) { 
if ( pointIsBetween ( leftIntercept , projBB . getLowerLeftPoint ( ) , projBB . getUpperLeftPoint ( ) ) ) { 
intercepts . add ( leftIntercept ) ; 
return intercepts ; 
} public List < ProjectionPoint > getMapEdgeInterceptsAtX ( double x0 ) { 
List < ProjectionPoint > mapEdgeIntercepts = new LinkedList < > ( ) ; 
if ( projToLatLon ( x0 , falseNorthing ) == INVALID ) { 
return mapEdgeIntercepts ; 
double x0natural = x0 - falseEasting ; 
double limitLon_r = ( x0natural < 0 ) ? - PI : + PI ; 
double deltaLon_r = limitLon_r - Math . toRadians ( centMeridian ) ; 
double minY = - earthRadius * Math . acos ( x0natural / ( earthRadius * deltaLon_r ) ) ; 
double maxY = + earthRadius * Math . acos ( x0natural / ( earthRadius * deltaLon_r ) ) ; 
mapEdgeIntercepts . add ( new ProjectionPointImpl ( x0 , minY + falseNorthing ) ) ; 
mapEdgeIntercepts . add ( new ProjectionPointImpl ( x0 , maxY + falseNorthing ) ) ; 
} public List < ProjectionPoint > getMapEdgeInterceptsAtY ( double y0 ) { 
if ( projToLatLon ( falseEasting , y0 ) == INVALID ) { 
double minX = getXAt ( y0 , - PI ) ; 
double maxX = getXAt ( y0 , + PI ) ; 
mapEdgeIntercepts . add ( new ProjectionPointImpl ( minX , y0 ) ) ; 
mapEdgeIntercepts . add ( new ProjectionPointImpl ( maxX , y0 ) ) ; 
} public final CalendarDate getReferenceDate ( ) { 
int century = getReferenceCentury ( ) - 1 ; 
if ( century == - 1 ) century = 20 ; 
int year = getOctet ( 13 ) ; 
int month = getOctet ( 14 ) ; 
int day = getOctet ( 15 ) ; 
int hour = getOctet ( 16 ) ; 
int minute = getOctet ( 17 ) ; 
return CalendarDate . of ( null , century * 100 + year , month , day , hour , minute , 0 ) ; 
} public boolean isEnsemble ( ) { 
switch ( getCenter ( ) ) { 
return ( ( rawData . length >= 43 ) && ( getOctet ( 41 ) == 1 ) ) ; 
case 98 : 
return ( ( rawData . length >= 51 ) && 
( getOctet ( 41 ) == 1 || getOctet ( 41 ) == 30 ) && 
( getOctet ( 43 ) == 10 || getOctet ( 43 ) == 11 ) ) ; 
} public boolean isMine ( FeatureType wantFeatureType , NetcdfDataset ds ) { 
String title = ds . findAttValueIgnoreCase ( null , "title" , null ) ; 
if ( title == null ) { 
title = ds . findAttValueIgnoreCase ( null , "DD_reference" , null ) ; 
if ( title != null ) { 
title = ds . findVariable ( "staLat" ) != null ? title : null ; 
} private String idvDatasetCatalog ( String xml ) 
String ret = xml . replace ( "variables" , "Variables" ) ; 
ret = ret . replace ( "timeCoverage" , "TimeSpan" ) ; 
StringBuilder sub = new StringBuilder ( ret . substring ( 0 , 
ret . indexOf ( "<geospatialCoverage>" ) ) ) ; 
sub . append ( "<LatLonBox>\n\t<north>90.0</north>\n\t<south>-90.0</south>" ) ; 
sub . append ( "\n\t<east>180.0</east>\n\t<west>-180.0</west></LatLonBox>" ) ; 
String endCoverage = "</geospatialCoverage>" ; 
sub . append ( ret . substring ( ret . indexOf ( endCoverage ) + endCoverage . length ( ) ) ) ; 
return sub . toString ( ) ; 
} private DateRange idvCompatibleRange ( DateRange range ) 
CalendarDate start = range . getStart ( ) . getCalendarDate ( ) ; 
CalendarDate end = range . getEnd ( ) . getCalendarDate ( ) ; 
return new DateRange ( start . toDate ( ) , end . toDate ( ) ) ; 
} public static TimeObjectPropertyType initPhenomenonTime ( 
TimeObjectPropertyType phenomenonTime , StationTimeSeriesFeature stationFeat ) throws IOException { 
TimePeriodDocument timePeriodDoc = TimePeriodDocument . Factory . newInstance ( ) ; 
NcTimePeriodType . initTimePeriod ( timePeriodDoc . addNewTimePeriod ( ) , stationFeat ) ; 
phenomenonTime . set ( timePeriodDoc ) ; 
return phenomenonTime ; 
} boolean isValidFile ( ucar . unidata . io . RandomAccessFile raFile ) 
this . raFile = raFile ; 
this . actualSize = raFile . length ( ) ; 
this . readHeaderFromFile ( raFile ) ; 
this . handleFileInformation ( ) ; 
this . handleProcessingInformation ( ) ; 
this . handleSatelliteInformation ( ) ; 
this . handleSensorInformation ( ) ; 
} private void readHeaderFromFile ( ucar . unidata . io . RandomAccessFile raFile ) 
long pos = 0 ; 
raFile . seek ( pos ) ; 
this . headerSizeInBytes = raFile . length ( ) > this . headerSizeInBytesGuess ? 
this . headerSizeInBytesGuess : ( int ) raFile . length ( ) ; 
byte [ ] b = new byte [ this . headerSizeInBytes ] ; 
String fullHeader = new String ( b , CDM . utf8Charset ) ; 
if ( ! fullHeader . startsWith ( HeaderInfoTitle . FILE_ID . toString ( ) ) ) 
int endOfHeaderIndex = fullHeader . indexOf ( HeaderInfoTitle . END_HEADER . toString ( ) ) ; 
if ( endOfHeaderIndex == - 1 ) 
header = fullHeader . substring ( 0 , endOfHeaderIndex - 1 ) . split ( "\n" ) ; 
int lineSeperatorIndex = 0 ; 
String curHeaderLine = null ; 
String curHeaderTitle = null ; 
String curHeaderValue = null ; 
for ( String aHeader : this . header ) { 
curHeaderLine = aHeader . trim ( ) ; 
lineSeperatorIndex = curHeaderLine . indexOf ( ':' ) ; 
if ( lineSeperatorIndex == - 1 ) 
if ( lineSeperatorIndex == 0 ) 
if ( lineSeperatorIndex == curHeaderLine . length ( ) - 1 ) 
curHeaderTitle = curHeaderLine . substring ( 0 , lineSeperatorIndex ) . trim ( ) ; 
curHeaderValue = curHeaderLine . substring ( lineSeperatorIndex + 1 ) . trim ( ) ; 
if ( curHeaderValue . equals ( "" ) ) 
headerInfo . put ( curHeaderTitle , curHeaderValue ) ; 
} private void handleFileInformation ( ) 
fileIdAtt = new Attribute ( this . fileIdAttName , headerInfo . get ( HeaderInfoTitle . FILE_ID . toString ( ) ) ) ; 
datasetIdAtt = new Attribute ( this . datasetIdAttName , headerInfo . get ( HeaderInfoTitle . DATA_SET_ID . toString ( ) ) ) ; 
recordSizeInBytes = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . RECORD_BYTES . toString ( ) ) ) ; 
numRecords = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . NUM_RECORDS . toString ( ) ) ) ; 
numHeaderRecords = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . NUM_HEADER_RECORDS . toString ( ) ) ) ; 
numDataRecords = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . NUM_DATA_RECORDS . toString ( ) ) ) ; 
numDataRecordsDim = new Dimension ( this . numDataRecordsDimName , numDataRecords , true , true , false ) ; 
numArtificialDataRecords = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . NUM_ARTIFICIAL_DATA_RECORDS . toString ( ) ) ) ; 
this . headerSizeInBytes = this . numHeaderRecords * this . recordSizeInBytes ; 
if ( numRecords * ( ( long ) this . recordSizeInBytes ) != this . actualSize ) 
} private void handleProcessingInformation ( ) 
suborbitHistoryAtt = new Attribute ( this . suborbitHistoryAttName , 
headerInfo . get ( HeaderInfoTitle . SUBORBIT_HISTORY . toString ( ) ) ) ; 
processingSystemAtt = new Attribute ( this . processingSystemAttName , 
headerInfo . get ( HeaderInfoTitle . PROCESSING_SYSTEM . toString ( ) ) ) ; 
String processingDateString = headerInfo . get ( HeaderInfoTitle . PROCESSING_DATE . toString ( ) ) ; 
processingDate = DateFormatHandler . ALT_DATE_TIME . getDateFromDateTimeString ( processingDateString ) ; 
catch ( ParseException e ) 
processingDateAtt = new Attribute ( 
this . processingDateAttName , 
DateFormatHandler . ISO_DATE_TIME . getDateTimeStringFromDate ( processingDate ) ) ; 
} private void handleSatelliteInformation ( ) 
spacecraftIdAtt = new Attribute ( 
this . spacecraftIdAttName , 
headerInfo . get ( HeaderInfoTitle . SPACECRAFT_ID . toString ( ) ) ) ; 
noradIdAtt = new Attribute ( 
this . noradIdAttName , 
headerInfo . get ( HeaderInfoTitle . NORAD_ID . toString ( ) ) ) ; 
} private void handleSensorInformation ( ) 
numSamplesPerBand = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . SAMPLES_PER_BAND . toString ( ) ) ) ; 
numSamplesPerBandDim = new Dimension ( 
this . numSamplesPerBandDimName , 
numSamplesPerBand ) ; 
nominalResolutionAtt = new Attribute ( nominalResolutionAttName , headerInfo . get ( HeaderInfoTitle . NOMINAL_RESOLUTION . toString ( ) ) ) ; 
bandsPerScanlineAtt = new Attribute ( bandsPerScanlineAttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BANDS_PER_SCANLINE . toString ( ) ) ) ) ; 
bytesPerSampleAtt = new Attribute ( bytesPerSampleAttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTES_PER_SAMPLE . toString ( ) ) ) ) ; 
byteOffsetBand1Att = new Attribute ( byteOffsetBand1AttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTE_OFFSET_BAND_1 . toString ( ) ) ) ) ; 
byteOffsetBand2Att = new Attribute ( byteOffsetBand2AttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTE_OFFSET_BAND_2 . toString ( ) ) ) ) ; 
band1Att = new Attribute ( band1AttName , headerInfo . get ( HeaderInfoTitle . BAND_1 . toString ( ) ) ) ; 
band2Att = new Attribute ( band2AttName , headerInfo . get ( HeaderInfoTitle . BAND_2 . toString ( ) ) ) ; 
bandOrganizationAtt = new Attribute ( bandOrganizationAttName , headerInfo . get ( HeaderInfoTitle . ORGANIZATION . toString ( ) ) ) ; 
thermalOffsetAtt = new Attribute ( thermalOffsetAttName , headerInfo . get ( HeaderInfoTitle . THERMAL_OFFSET . toString ( ) ) ) ; 
thermalScaleAtt = new Attribute ( thermalScaleAttName , headerInfo . get ( HeaderInfoTitle . THERMAL_SCALE . toString ( ) ) ) ; 
percentDaylightAtt = new Attribute ( percentDaylightAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_DAYLIGHT . toString ( ) ) ) ) ; 
percentFullMoonAtt = new Attribute ( percentFullMoonAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_FULL_MOON . toString ( ) ) ) ) ; 
percentTerminatorEvidentAtt = new Attribute ( percentTerminatorEvidentAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_TERMINATOR_EVIDENT . toString ( ) ) ) ) ; 
} protected String headerInfoDump ( ) 
StringBuilder retVal = new StringBuilder ( ) ; 
for ( String curHeaderTitle : this . headerInfo . keySet ( ) ) { 
String curHeaderValue = this . headerInfo . get ( curHeaderTitle ) ; 
retVal . append ( curHeaderTitle ) ; 
retVal . append ( ":::::" ) ; 
retVal . append ( curHeaderValue ) ; 
retVal . append ( ":::::\n" ) ; 
return ( retVal . toString ( ) ) ; 
} static public Element readRootElement ( String location ) throws IOException { 
doc = builder . build ( location ) ; 
} catch ( JDOMException e ) { 
return doc . getRootElement ( ) ; 
} static public String cleanCharacterData ( String text ) { 
if ( text == null ) return null ; 
boolean bad = false ; 
for ( int i = 0 , len = text . length ( ) ; i < len ; i ++ ) { 
int ch = text . charAt ( i ) ; 
if ( ! org . jdom2 . Verifier . isXMLCharacter ( ch ) ) { 
bad = true ; 
if ( ! bad ) return text ; 
StringBuilder sbuff = new StringBuilder ( text . length ( ) ) ; 
if ( org . jdom2 . Verifier . isXMLCharacter ( ch ) ) 
sbuff . append ( ( char ) ch ) ; 
int n = MAGIC . length ( ) ; 
if ( raf . length ( ) < n ) { 
String got = raf . readString ( n ) ; 
return ( pMAGIC . matcher ( got ) . find ( ) || pMAGIC_OLD . matcher ( got ) . find ( ) ) ; 
isExtended = checkFormat ( ) ; 
isoDateFormat = new SimpleDateFormat ( ) ; 
isoDateFormat . setTimeZone ( java . util . TimeZone . getTimeZone ( "GMT" ) ) ; 
isoDateFormat . applyPattern ( isExtended 
? TIME_FORMAT_EX 
: TIME_FORMAT ) ; 
Sequence seq = makeSequence ( ncfile ) ; 
ArrayStructureBB . setOffsets ( sm ) ; 
new Attribute ( "file_format" , 
? "(extended)" 
: "(original)" ) ) ) ; 
} private boolean checkFormat ( ) throws IOException { 
boolean extended = false ; 
long offset = raf . getFilePointer ( ) ; 
if ( pMAGIC . matcher ( line ) . find ( ) || pMAGIC_OLD . matcher ( line ) . find ( ) ) { 
extended = pMAGIC_EX . matcher ( line ) . find ( ) ; 
return extended ; 
} int readAllData ( RandomAccessFile raf ) 
throws IOException , NumberFormatException , ParseException { 
ArrayList offsetList = new ArrayList ( ) ; 
java . text . SimpleDateFormat isoDateTimeFormat = 
new java . text . SimpleDateFormat ( TIME_FORMAT ) ; 
lat_min = 1000.0 ; 
lat_max = - 1000.0 ; 
lon_min = 1000.0 ; 
lon_max = - 1000.0 ; 
time_min = Double . POSITIVE_INFINITY ; 
time_max = Double . NEGATIVE_INFINITY ; 
boolean knowExtended = false ; 
if ( ! knowExtended ) { 
isExtended = pMAGIC_EX . matcher ( line ) . find ( ) ; 
if ( isExtended ) { 
isoDateTimeFormat . applyPattern ( TIME_FORMAT_EX ) ; 
knowExtended = true ; 
Date date = isoDateTimeFormat . parse ( stoker . nextToken ( ) ) ; 
int nstrokes = 1 ; 
double axisMaj = Double . NaN ; 
double axisMin = Double . NaN ; 
int orient = 0 ; 
axisMaj = Double . parseDouble ( stoker . nextToken ( ) ) ; 
axisMin = Double . parseDouble ( stoker . nextToken ( ) ) ; 
orient = Integer . parseInt ( stoker . nextToken ( ) ) ; 
nstrokes = Integer . parseInt ( stoker . nextToken ( ) ) ; 
Stroke s = isExtended 
? new Stroke ( date , lat , lon , amp , axisMaj , 
axisMin , orient ) 
: new Stroke ( date , lat , lon , amp , nstrokes ) ; 
lat_min = Math . min ( lat_min , s . lat ) ; 
lat_max = Math . max ( lat_max , s . lat ) ; 
lon_min = Math . min ( lon_min , s . lon ) ; 
lon_max = Math . max ( lon_max , s . lon ) ; 
time_min = Math . min ( time_min , s . secs ) ; 
time_max = Math . max ( time_max , s . secs ) ; 
offsetList . add ( new Long ( offset ) ) ; 
offsets = new long [ count ] ; 
for ( int i = 0 ; i < offsetList . size ( ) ; i ++ ) { 
Long off = ( Long ) offsetList . get ( i ) ; 
offsets [ i ] = off . longValue ( ) ; 
return new ArraySequence ( sm , getStructureIterator ( null , 0 ) , nelems ) ; 
} private static String xunescapeString ( String in , char escape , boolean spaceplus ) 
if ( in == null ) return null ; 
byte [ ] utf8 = in . getBytes ( utf8Charset ) ; 
byte escape8 = ( byte ) escape ; 
byte [ ] out = new byte [ utf8 . length ] ; 
int index8 = 0 ; 
for ( int i = 0 ; i < utf8 . length ; ) { 
byte b = utf8 [ i ++ ] ; 
if ( b == plus && spaceplus ) { 
out [ index8 ++ ] = blank ; 
} else if ( b == escape8 ) { 
if ( i + 2 <= utf8 . length ) { 
b = ( byte ) ( fromHex ( utf8 [ i ] ) << 4 | fromHex ( utf8 [ i + 1 ] ) ) ; 
i += 2 ; 
out [ index8 ++ ] = b ; 
return new String ( out , 0 , index8 , utf8Charset ) ; 
return in ; 
} public static String escapeURLQuery ( String ce ) 
ce = escapeString ( ce , _allowableInUrlQuery ) ; 
ce = null ; 
} public static String unescapeURLQuery ( String ce ) 
ce = unescapeString ( ce ) ; 
} public static String backslashDecode ( String s ) 
StringBuilder buf = new StringBuilder ( s ) ; 
while ( i < buf . length ( ) ) { 
if ( buf . charAt ( i ) == '\\' ) { 
buf . deleteCharAt ( i ) ; 
} public static String backslashEncode ( String s ) 
int c = buf . charAt ( i ) ; 
if ( _MustBackslashEscape . indexOf ( c ) >= 0 ) 
buf . append ( _BACKSLASHEscape ) ; 
} protected Variable makeLightningVariable ( NetcdfFile ncfile , Group group , 
Structure seq , String name , 
DataType dataType , String dims , 
String longName , String cfName , 
String units , AxisType type ) { 
Variable v = new Variable ( ncfile , group , seq , name ) ; 
v . setDataType ( dataType ) ; 
if ( cfName != null ) { 
v . addAttribute ( new Attribute ( CF . STANDARD_NAME , cfName ) ) ; 
if ( units != null ) { 
v . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; 
type . toString ( ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( CF . FEATURE_TYPE , CF . FeatureType . point . toString ( ) ) ) ; 
} public static String setContentDispositionValue ( String filename , String suffix ) { 
int pos = filename . lastIndexOf ( '/' ) ; 
String outname = ( pos > 0 ) ? filename . substring ( pos + 1 ) : filename ; 
int pos2 = outname . lastIndexOf ( '.' ) ; 
outname = ( pos > 0 ) ? outname . substring ( 0 , pos2 ) : outname ; 
outname = outname + suffix ; 
return setContentDispositionValue ( outname ) ; 
} public void printDecl ( PrintWriter os , String space , boolean print_semi , boolean constrained ) { 
boolean isSingle = false ; 
boolean isStructure = false ; 
boolean isGrid = false ; 
boolean psemi = true ; 
if ( constrained && projectedComponents ( true ) == 0 ) 
else if ( constrained && ! projectionYieldsGrid ( true ) ) { 
isStructure = true ; 
isGrid = true ; 
for ( Enumeration e = mapVars . elements ( ) ; e . hasMoreElements ( ) ; ) { 
SDArray sda = ( SDArray ) e . nextElement ( ) ; 
if ( isStructure || isGrid ) { 
printDecl ( os , space , false , true ) ; 
boolean isStillGrid = projectionYieldsGrid ( true ) ; 
if ( ( ( SDArray ) arrayVar ) . isProject ( ) ) 
arrayVar . printVal ( os , "" , false ) ; 
boolean firstPass = true ; 
Enumeration e = mapVars . elements ( ) ; 
if ( ( ( SDArray ) sda ) . isProject ( ) ) { 
sda . printVal ( os , "" , false ) ; 
firstPass = false ; 
public void setProject ( boolean state , boolean all ) { 
setProjected ( state ) ; 
if ( all ) { 
( ( SDArray ) arrayVar ) . setProject ( state ) ; 
ServerMethods sm = ( ServerMethods ) e . nextElement ( ) ; 
sm . setProject ( state ) ; 
if ( ce . evalClauses ( specialO ) ) { 
if ( ( ( ServerMethods ) arrayVar ) . isProject ( ) ) 
( ( ServerMethods ) arrayVar ) . serialize ( dataset , sink , ce , specialO ) ; 
if ( sm . isProject ( ) ) 
sm . serialize ( dataset , sink , ce , specialO ) ; 
} public void setProjection ( int dimension , int start , int stride , int stop ) 
throws InvalidDimensionException , SBHException { 
DArray a = ( DArray ) getVar ( 0 ) ; 
DArrayDimension d = a . getDimension ( dimension ) ; 
d . setProjection ( start , stride , stop ) ; 
DArray map = ( DArray ) getVar ( dimension + 1 ) ; 
DArrayDimension mapD = map . getDimension ( 0 ) ; 
mapD . setProjection ( start , stride , stop ) ; 
catch ( NoSuchVariableException e ) { 
+ e . getMessage ( ) ) ; 
} public int getStart ( int dimension ) throws InvalidDimensionException { 
return ( d . getStart ( ) ) ; 
} public void printXML ( PrintWriter pw , String pad , boolean constrained ) { 
if ( constrained && projectedComponents ( true ) == 1 ) { 
if ( isGrid ) { 
if ( getEncodedName ( ) != null ) { 
DDSXMLParser . normalizeToXML ( getEncodedName ( ) ) + "\"" ) ; 
pw . println ( ">" ) ; 
if ( isStructure ) { 
pw . print ( pad + "<Structure" ) ; 
Enumeration e = getAttributeNames ( ) ; 
String aName = ( String ) e . nextElement ( ) ; 
Attribute a = getAttribute ( aName ) ; 
a . printXML ( pw , pad + "\t" , constrained ) ; 
( ( SDArray ) arrayVar ) . printXML ( pw , pad + ( isSingle ? "" : "\t" ) , constrained ) ; 
e = mapVars . elements ( ) ; 
SDArray map = ( SDArray ) e . nextElement ( ) ; 
map . printAsMapXML ( pw , pad + ( isSingle ? "" : "\t" ) , constrained ) ; 
sda . printXML ( pw , pad + ( isSingle ? "" : "\t" ) , constrained ) ; 
pw . println ( pad + "</Structure>" ) ; 
} else if ( isGrid ) { 
pw . println ( pad + "</Grid>" ) ; 
} static public short swapShort ( byte [ ] b , int offset ) { 
int low = b [ offset ] & 0xff ; 
int high = b [ offset + 1 ] & 0xff ; 
return ( short ) ( high << 8 | low ) ; 
} static public int swapInt ( byte [ ] b , int offset ) { 
int accum = 0 ; 
for ( int shiftBy = 0 , i = offset ; shiftBy < 32 ; shiftBy += 8 , i ++ ) { 
accum |= ( b [ i ] & 0xff ) << shiftBy ; 
return accum ; 
} static public double swapDouble ( byte [ ] b , int offset ) { 
long accum = 0 ; 
long shiftedval ; 
for ( int shiftBy = 0 , i = offset ; shiftBy < 64 ; shiftBy += 8 , i ++ ) { 
shiftedval = ( ( long ) ( b [ i ] & 0xff ) ) << shiftBy ; 
accum |= shiftedval ; 
return Double . longBitsToDouble ( accum ) ; 
} static public float swapFloat ( float v ) { 
int l = swapInt ( Float . floatToIntBits ( v ) ) ; 
return ( Float . intBitsToFloat ( l ) ) ; 
} static public double swapDouble ( double v ) { 
long l = swapLong ( Double . doubleToLongBits ( v ) ) ; 
return ( Double . longBitsToDouble ( l ) ) ; 
} static public byte [ ] shortToBytes ( short v ) { 
byte [ ] b = new byte [ 2 ] ; 
int allbits = 255 ; 
b [ 1 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) > > i * 8 ) ; 
} static public byte [ ] intToBytes ( int v ) { 
for ( int i = 0 ; i < 4 ; i ++ ) { 
b [ 3 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) > > i * 8 ) ; 
} static public byte [ ] longToBytes ( long v ) { 
byte [ ] b = new byte [ 8 ] ; 
long allbits = 255 ; 
for ( int i = 0 ; i < 8 ; i ++ ) { 
b [ 7 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) > > i * 8 ) ; 
} protected Array readArray ( Variable v , int timeIndex ) throws IOException , InvalidRangeException { 
int [ ] origin = new int [ v . getRank ( ) ] ; 
if ( getTimeDimension ( ) != null ) { 
int dimIndex = v . findDimensionIndex ( getTimeDimension ( ) . getShortName ( ) ) ; 
if ( dimIndex >= 0 ) { 
shape [ dimIndex ] = 1 ; 
origin [ dimIndex ] = timeIndex ; 
return v . read ( origin , shape ) . reduce ( dimIndex ) ; 
return v . read ( origin , shape ) ; 
} public VerticalTransform subset ( Range t_range , Range z_range , 
Range y_range , Range x_range ) 
throws ucar . ma2 . InvalidRangeException { 
return new VerticalTransformSubset ( this , t_range , z_range , y_range , x_range ) ; 
} public static GridDatasetInv open ( MCollection cm , MFile mfile , Element ncml ) throws IOException { 
byte [ ] xmlBytes = ( ( CollectionManagerAbstract ) cm ) . getMetadata ( mfile , "fmrInv.xml" ) ; 
if ( xmlBytes != null ) { 
if ( xmlBytes . length < 300 ) { 
GridDatasetInv inv = readXML ( xmlBytes ) ; 
if ( inv . version >= REQ_VERSION ) { 
long fileModifiedSecs = mfile . getLastModified ( ) / 1000 ; 
long xmlModifiedSecs = inv . getLastModified ( ) / 1000 ; 
if ( xmlModifiedSecs >= fileModifiedSecs ) { 
return inv ; 
GridDataset gds = null ; 
if ( ncml == null ) { 
gds = GridDataset . open ( mfile . getPath ( ) ) ; 
NetcdfFile nc = NetcdfDataset . acquireFile ( new DatasetUrl ( null , mfile . getPath ( ) ) , null ) ; 
NetcdfDataset ncd = NcMLReader . mergeNcML ( nc , ncml ) ; 
ncd . enhance ( ) ; 
gds = new GridDataset ( ncd ) ; 
GridDatasetInv inv = new GridDatasetInv ( gds , cm . extractDate ( mfile ) ) ; 
String xmlString = inv . writeXML ( new Date ( mfile . getLastModified ( ) ) ) ; 
( ( CollectionManagerAbstract ) cm ) . putMetadata ( mfile , "fmrInv.xml" , xmlString . getBytes ( CDM . utf8Charset ) ) ; 
if ( gds != null ) gds . close ( ) ; 
} private TimeCoord getTimeCoordinate ( CoordinateAxis1DTime axis ) { 
for ( TimeCoord tc : times ) { 
if ( tc . getAxisName ( ) . equals ( axis . getFullName ( ) ) ) 
return tc ; 
TimeCoord want = new TimeCoord ( runDate , axis ) ; 
if ( ( tc . equalsData ( want ) ) ) 
times . add ( want ) ; 
} private VertCoord getVertCoordinate ( int wantId ) { 
if ( wantId < 0 ) return null ; 
for ( VertCoord vc : vaxes ) { 
if ( vc . getId ( ) == wantId ) 
return vc ; 
} private EnsCoord getEnsCoordinate ( int ens_id ) { 
if ( ens_id < 0 ) return null ; 
for ( EnsCoord ec : eaxes ) { 
if ( ( ec . getId ( ) == ens_id ) ) 
return ec ; 
} public String writeXML ( Date lastModified ) { 
return fmt . outputString ( writeDocument ( lastModified ) ) ; 
} Document writeDocument ( Date lastModified ) { 
Element rootElem = new Element ( "gridInventory" ) ; 
rootElem . setAttribute ( "location" , location ) ; 
rootElem . setAttribute ( "runTime" , runTimeString ) ; 
if ( lastModified != null ) { 
rootElem . setAttribute ( "lastModified" , CalendarDateFormatter . toDateTimeString ( lastModified ) ) ; 
rootElem . setAttribute ( "version" , Integer . toString ( CURR_VERSION ) ) ; 
Collections . sort ( vaxes ) ; 
vc . setId ( count ++ ) ; 
Element vcElem = new Element ( "vertCoord" ) ; 
rootElem . addContent ( vcElem ) ; 
vcElem . setAttribute ( "id" , Integer . toString ( vc . getId ( ) ) ) ; 
vcElem . setAttribute ( "name" , vc . getName ( ) ) ; 
if ( vc . getUnits ( ) != null ) 
vcElem . setAttribute ( CDM . UNITS , vc . getUnits ( ) ) ; 
double [ ] values1 = vc . getValues1 ( ) ; 
double [ ] values2 = vc . getValues2 ( ) ; 
for ( int j = 0 ; j < values1 . length ; j ++ ) { 
sbuff . append ( Double . toString ( values1 [ j ] ) ) ; 
if ( values2 != null ) { 
sbuff . append ( "," ) ; 
sbuff . append ( Double . toString ( values2 [ j ] ) ) ; 
vcElem . addContent ( sbuff . toString ( ) ) ; 
tc . setId ( count ++ ) ; 
Element timeElement = new Element ( "timeCoord" ) ; 
rootElem . addContent ( timeElement ) ; 
timeElement . setAttribute ( "id" , Integer . toString ( tc . getId ( ) ) ) ; 
timeElement . setAttribute ( "name" , tc . getName ( ) ) ; 
timeElement . setAttribute ( "isInterval" , tc . isInterval ( ) ? "true" : "false" ) ; 
Formatter sbuff = new Formatter ( ) ; 
if ( tc . isInterval ( ) ) { 
double [ ] bound1 = tc . getBound1 ( ) ; 
double [ ] bound2 = tc . getBound2 ( ) ; 
for ( int j = 0 ; j < bound1 . length ; j ++ ) 
for ( double offset : tc . getOffsetTimes ( ) ) 
sbuff . format ( ( Locale ) null , "%f," , offset ) ; 
timeElement . addContent ( sbuff . toString ( ) ) ; 
List < GridDatasetInv . Grid > vars = tc . getGridInventory ( ) ; 
Collections . sort ( vars ) ; 
for ( Grid grid : vars ) { 
Element varElem = new Element ( "grid" ) ; 
timeElement . addContent ( varElem ) ; 
varElem . setAttribute ( "name" , grid . name ) ; 
if ( grid . ec != null ) 
varElem . setAttribute ( "ens_id" , Integer . toString ( grid . ec . getId ( ) ) ) ; 
if ( grid . vc != null ) 
varElem . setAttribute ( "vert_id" , Integer . toString ( grid . vc . getId ( ) ) ) ; 
} private static GridDatasetInv readXML ( byte [ ] xmlString ) throws IOException { 
InputStream is = new BufferedInputStream ( new ByteArrayInputStream ( xmlString ) ) ; 
doc = builder . build ( is ) ; 
Element rootElem = doc . getRootElement ( ) ; 
GridDatasetInv fmr = new GridDatasetInv ( ) ; 
fmr . runTimeString = rootElem . getAttributeValue ( "runTime" ) ; 
fmr . location = rootElem . getAttributeValue ( "location" ) ; 
if ( fmr . location == null ) 
fmr . location = rootElem . getAttributeValue ( "name" ) ; 
String lastModifiedS = rootElem . getAttributeValue ( "lastModified" ) ; 
if ( lastModifiedS != null ) 
fmr . lastModified = CalendarDateFormatter . isoStringToDate ( lastModifiedS ) ; 
String version = rootElem . getAttributeValue ( "version" ) ; 
fmr . version = ( version == null ) ? 0 : Integer . parseInt ( version ) ; 
if ( fmr . version < REQ_VERSION ) return fmr ; 
fmr . runDate = DateUnit . parseCalendarDate ( fmr . runTimeString ) ; 
java . util . List < Element > vList = rootElem . getChildren ( "vertCoord" ) ; 
for ( Element vertElem : vList ) { 
VertCoord vc = new VertCoord ( ) ; 
fmr . vaxes . add ( vc ) ; 
vc . setId ( Integer . parseInt ( vertElem . getAttributeValue ( "id" ) ) ) ; 
vc . setName ( vertElem . getAttributeValue ( "name" ) ) ; 
vc . setUnits ( vertElem . getAttributeValue ( CDM . UNITS ) ) ; 
String values = vertElem . getTextNormalize ( ) ; 
StringTokenizer stoke = new StringTokenizer ( values ) ; 
int n = stoke . countTokens ( ) ; 
double [ ] values1 = new double [ n ] ; 
double [ ] values2 = null ; 
int pos = toke . indexOf ( ',' ) ; 
values1 [ count ] = Double . parseDouble ( toke ) ; 
if ( values2 == null ) 
values2 = new double [ n ] ; 
String val1 = toke . substring ( 0 , pos ) ; 
String val2 = toke . substring ( pos + 1 ) ; 
values1 [ count ] = Double . parseDouble ( val1 ) ; 
values2 [ count ] = Double . parseDouble ( val2 ) ; 
vc . setValues1 ( values1 ) ; 
vc . setValues2 ( values2 ) ; 
java . util . List < Element > tList = rootElem . getChildren ( "timeCoord" ) ; 
for ( Element timeElem : tList ) { 
TimeCoord tc = new TimeCoord ( fmr . runDate ) ; 
fmr . times . add ( tc ) ; 
tc . setId ( Integer . parseInt ( timeElem . getAttributeValue ( "id" ) ) ) ; 
String s = timeElem . getAttributeValue ( "isInterval" ) ; 
boolean isInterval = ( s != null ) && ( s . equals ( "true" ) ) ; 
if ( isInterval ) { 
String boundsAll = timeElem . getTextNormalize ( ) ; 
String [ ] bounds = boundsAll . split ( "," ) ; 
int n = bounds . length ; 
double [ ] bound1 = new double [ n ] ; 
double [ ] bound2 = new double [ n ] ; 
for ( String b : bounds ) { 
bound1 [ count ] = Double . parseDouble ( value [ 0 ] ) ; 
bound2 [ count ] = Double . parseDouble ( value [ 1 ] ) ; 
tc . setBounds ( bound1 , bound2 ) ; 
String values = timeElem . getTextNormalize ( ) ; 
String [ ] value = values . split ( "," ) ; 
int n = value . length ; 
double [ ] offsets = new double [ n ] ; 
for ( String v : value ) 
offsets [ count ++ ] = Double . parseDouble ( v ) ; 
tc . setOffsetTimes ( offsets ) ; 
List < Element > varList = timeElem . getChildren ( "grid" ) ; 
for ( Element vElem : varList ) { 
Grid grid = fmr . makeGrid ( vElem . getAttributeValue ( "name" ) ) ; 
if ( vElem . getAttributeValue ( "ens_id" ) != null ) 
grid . ec = fmr . getEnsCoordinate ( Integer . parseInt ( vElem . getAttributeValue ( "ens_id" ) ) ) ; 
if ( vElem . getAttributeValue ( "vert_id" ) != null ) 
grid . vc = fmr . getVertCoordinate ( Integer . parseInt ( vElem . getAttributeValue ( "vert_id" ) ) ) ; 
tc . addGridInventory ( grid ) ; 
grid . tc = tc ; 
return fmr ; 
} public void reset ( Dap2Parse state ) 
this . parsestate = state ; 
this . text = new TextStream ( ) ; 
yytext = new StringBuilder ( ) ; 
while ( token < 0 && ( c = text . read ( ) ) > 0 ) { 
if ( c == '\n' ) { 
lineno ++ ; 
} else if ( c == '#' ) { 
if ( c == '\n' || c == '\0' ) break ; 
} else if ( worddelims . indexOf ( c ) >= 0 ) { 
} else if ( c == '"' ) { 
if ( DAP2STRING ) { 
more = false ; 
if ( c < 0 ) more = false ; 
case '(' : 
default : break ; 
case 'x' : { 
int d1 , d2 ; 
d1 = tohex ( c ) ; 
if ( d1 < 0 ) { 
d2 = tohex ( c ) ; 
if ( d2 < 0 ) { 
c = ( ( d1 ) << 4 ) | d2 ; 
token = WORD_STRING ; 
} else if ( wordchars1 . indexOf ( c ) >= 0 ) { 
if ( wordcharsn . indexOf ( c ) < 0 ) { 
text . backup ( ) ; 
token = WORD_WORD ; 
String tmp = yytext . toString ( ) ; 
for ( int i = 0 ; ; i ++ ) { 
if ( keywords [ i ] == null ) break ; 
if ( keywords [ i ] . equalsIgnoreCase ( tmp ) ) { 
token = keytokens [ i ] ; 
lexerror ( msg ) ; 
throw new ParseException ( msg ) ; 
if ( token <= 0 ) { 
throw new ParseException ( ioe ) ; 
String kind = "?" ; 
switch ( parsestate . parseClass ) { 
case Dap2Parse . DapDAS : kind = "DAS" ; break ; 
case Dap2Parse . DapDDS : kind = "DDS" ; break ; 
case Dap2Parse . DapERR : kind = "Error" ; break ; 
default : kind = "?" ; break ; 
String context = parsestate . flatten ( getInput ( ) ) ; 
if ( parsestate . getURL ( ) != null ) 
System . err . println ( "\turl=" + parsestate . getURL ( ) ) ; 
} public ArrayDouble . D3 getCoordinateArray ( int timeIndex ) throws IOException , InvalidRangeException { 
if ( null == c ) { 
double a = aVar . readScalarDouble ( ) ; 
double b = bVar . readScalarDouble ( ) ; 
c = makeC ( sArray , a , b ) ; 
return makeHeight ( etaArray , sArray , depthArray , c , depth_c ) ; 
return makeHeight1D ( etaArray , sArray , depthArray , c , depth_c , xIndex , yIndex ) ; 
} private Array makeC ( Array s , double a , double b ) { 
int nz = ( int ) s . getSize ( ) ; 
Index sIndex = s . getIndex ( ) ; 
if ( a == 0 ) return s ; 
ArrayDouble . D1 c = new ArrayDouble . D1 ( nz ) ; 
double fac1 = 1.0 - b ; 
double denom1 = 1.0 / Math . sinh ( a ) ; 
double denom2 = 1.0 / ( 2.0 * Math . tanh ( 0.5 * a ) ) ; 
for ( int i = 0 ; i < nz ; i ++ ) { 
double sz = s . getDouble ( sIndex . set ( i ) ) ; 
double term1 = fac1 * Math . sinh ( a * sz ) * denom1 ; 
double term2 = b * ( Math . tanh ( a * ( sz + 0.5 ) ) 
* denom2 - 0.5 ) ; 
c . set ( i , term1 + term2 ) ; 
return c ; 
} private ArrayDouble . D3 makeHeight ( Array eta , Array s , Array depth , Array c , double depth_c ) { 
Index cIndex = c . getIndex ( ) ; 
int [ ] shape2D = eta . getShape ( ) ; 
Index etaIndex = eta . getIndex ( ) ; 
Index depthIndex = depth . getIndex ( ) ; 
ArrayDouble . D3 height = new ArrayDouble . D3 ( nz , ny , nx ) ; 
double sz = s . getDouble ( sIndex . set ( z ) ) ; 
double cz = c . getDouble ( cIndex . set ( z ) ) ; 
double term1 = depth_c * sz ; 
double fac1 = depth . getDouble ( depthIndex . set ( y , x ) ) ; 
double term2 = ( fac1 - depth_c ) * cz ; 
double Sterm = term1 + term2 ; 
double term3 = eta . getDouble ( etaIndex . set ( y , x ) ) ; 
double term4 = 1 + Sterm / fac1 ; 
double hterm = Sterm + term3 * term4 ; 
height . set ( z , y , x , hterm ) ; 
return height ; 
} public void startXML ( ) { 
"version=\"0.1\">" ; 
"schemaLocation=\"http://schemas.opengis.net/gml/2.1.2/feature.xsd\"/>" ; 
} public void writeFeatures ( ) { 
for ( WFSFeature feat : featureList ) { 
fileOutput += "<xsd:complexContent>" ; 
fileOutput += "<xsd:sequence>" ; 
for ( WFSFeatureAttribute attribute : feat . getAttributes ( ) ) { 
fileOutput += "</xsd:sequence>" ; 
fileOutput += "</xsd:extension>" ; 
fileOutput += "</xsd:complexContent>" ; 
fileOutput += "</xsd:complexType>" ; 
} void addLevels ( List < GridRecord > records ) { 
for ( GridRecord record : records ) { 
Double d = new Double ( record . getLevel1 ( ) ) ; 
if ( ! levels . contains ( d ) ) { 
levels . add ( d ) ; 
if ( dontUseVertical && ( levels . size ( ) > 1 ) ) { 
if ( GridServiceProvider . debugVert ) { 
+ levels . size ( ) ) ; 
Collections . sort ( levels ) ; 
if ( positive . equals ( "down" ) ) { 
Collections . reverse ( levels ) ; 
} boolean matchLevels ( List < GridRecord > records ) { 
List < Double > levelList = new ArrayList < Double > ( records . size ( ) ) ; 
if ( ! levelList . contains ( d ) ) { 
levelList . add ( d ) ; 
Collections . sort ( levelList ) ; 
Collections . reverse ( levelList ) ; 
return levelList . equals ( levels ) ; 
} void addDimensionsToNetcdfFile ( NetcdfFile ncfile , Group g ) { 
if ( dontUseVertical ) { 
int nlevs = levels . size ( ) ; 
ncfile . addDimension ( g , new Dimension ( verticalName , nlevs , true ) ) ; 
} void addToNetcdfFile ( NetcdfFile ncfile , Group g ) { 
String dims = "time" ; 
if ( ! dontUseVertical ) { 
if ( hcs . isLatLon ( ) ) { 
Variable v = new Variable ( ncfile , g , null , verticalName ) ; 
v . addAttribute ( new Attribute ( "long_name" , 
lookup . getLevelDescription ( record ) ) ) ; 
v . addAttribute ( new Attribute ( "units" , lookup . getLevelUnit ( record ) ) ) ; 
v . addAttribute ( new Attribute ( "positive" , positive ) ) ; 
AxisType axisType ; 
if ( SimpleUnit . isCompatible ( "millibar" , units ) ) { 
axisType = AxisType . Pressure ; 
} else if ( SimpleUnit . isCompatible ( "m" , units ) ) { 
axisType = AxisType . Height ; 
axisType = AxisType . GeoZ ; 
v . addAttribute ( 
new Attribute ( 
"grid_level_type" , 
Integer . toString ( record . getLevelType1 ( ) ) ) ) ; 
axisType . toString ( ) ) ) ; 
if ( ! hcs . isLatLon ( ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . Transforms , 
hcs . getGridName ( ) ) ) ; 
double [ ] data = new double [ nlevs ] ; 
for ( int i = 0 ; i < levels . size ( ) ; i ++ ) { 
Double d = ( Double ) levels . get ( i ) ; 
data [ i ] = d . doubleValue ( ) ; 
Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { nlevs } , data ) ; 
v . setDimensions ( verticalName ) ; 
if ( record . getLevelType1 ( ) == 109 ) { 
findCoordinateTransform ( g , "Pressure" , record . getLevelType1 ( ) ) ; 
} void findCoordinateTransform ( Group g , String nameStartsWith , int levelType ) { 
List < Variable > vars = g . getVariables ( ) ; 
if ( v . getShortName ( ) . equals ( nameStartsWith ) ) { 
Attribute att = v . findAttribute ( "grid_level_type" ) ; 
if ( ( att == null ) || ( att . getNumericValue ( ) . intValue ( ) != levelType ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . TransformType , "Vertical" ) ) ; 
v . addAttribute ( new Attribute ( "transform_name" , "Existing3DField" ) ) ; 
} int getIndex ( GridRecord record ) { 
return levels . indexOf ( d ) ; 
} static public void exit ( ) { 
if ( timer != null ) { 
timer . cancel ( ) ; 
System . out . printf ( "DiskCache2.exit()%n" ) ; 
timer = null ; 
} static public DiskCache2 getDefault ( ) { 
String root = System . getProperty ( "nj22.cache" ) ; 
String home = System . getProperty ( "user.home" ) ; 
if ( home == null ) 
home = System . getProperty ( "user.dir" ) ; 
home = "." ; 
root = home + "/.unidata/cache/" ; 
DiskCache2 result = new DiskCache2 ( ) ; 
result . setRootDirectory ( root ) ; 
result . alwaysUseCache = false ; 
} public void setRootDirectory ( String cacheDir ) { 
if ( ! cacheDir . endsWith ( "/" ) ) 
cacheDir = cacheDir + "/" ; 
root = StringUtil2 . replace ( cacheDir , '\\' , "/" ) ; 
File dir = new File ( root ) ; 
if ( ! dir . mkdirs ( ) ) { 
if ( ! dir . exists ( ) ) { 
fail = true ; 
} public File getCacheFile ( String fileLocation ) { 
if ( neverUseCache ) 
if ( ! alwaysUseCache ) { 
File f = new File ( fileLocation ) ; 
if ( canWrite ( f ) ) return f ; 
File f = new File ( makeCachePath ( fileLocation ) ) ; 
if ( cachePathPolicy == CachePathPolicy . NestedDirectory ) { 
File dir = f . getParentFile ( ) ; 
boolean ret = dir . mkdirs ( ) ; 
} public File getFile ( String fileLocation ) { 
if ( f . exists ( ) ) return f ; 
if ( neverUseCache ) { 
if ( ! dir . exists ( ) && ! dir . mkdirs ( ) ) 
} public static boolean canWrite ( File f ) { 
Path path = f . toPath ( ) . toAbsolutePath ( ) ; 
if ( Files . isDirectory ( path ) ) { 
Files . delete ( Files . createTempFile ( path , "check" , null ) ) ; 
} else if ( Files . isRegularFile ( path ) ) { 
Files . newOutputStream ( path , StandardOpenOption . APPEND ) . close ( ) ; 
Files . delete ( Files . createTempFile ( path . getParent ( ) , "check" , null ) ) ; 
} catch ( IOException | SecurityException e ) { 
} public File getExistingFileOrCache ( String fileLocation ) { 
if ( neverUseCache ) return null ; 
File fc = new File ( makeCachePath ( fileLocation ) ) ; 
if ( fc . exists ( ) ) return fc ; 
} public synchronized File createUniqueFile ( String prefix , String suffix ) { 
if ( suffix == null ) suffix = ".tmp" ; 
Random random = new Random ( System . currentTimeMillis ( ) ) ; 
File result = new File ( getRootDirectory ( ) , prefix + Integer . toString ( random . nextInt ( ) ) + suffix ) ; 
while ( result . exists ( ) ) 
result = new File ( getRootDirectory ( ) , prefix + Integer . toString ( random . nextInt ( ) ) + suffix ) ; 
} private String makeCachePath ( String fileLocation ) { 
String cachePath = fileLocation ; 
cachePath = StringUtil2 . remove ( cachePath , '?' ) ; 
cachePath = StringUtil2 . remove ( cachePath , '=' ) ; 
cachePath = StringUtil2 . replace ( cachePath , '\\' , "/" ) ; 
if ( cachePath . startsWith ( "/" ) ) 
cachePath = cachePath . substring ( 1 ) ; 
if ( cachePath . endsWith ( "/" ) ) 
cachePath = cachePath . substring ( 0 , cachePath . length ( ) - 1 ) ; 
cachePath = StringUtil2 . remove ( cachePath , ':' ) ; 
if ( cachePathPolicy == CachePathPolicy . OneDirectory ) { 
cachePath = StringUtil2 . replace ( cachePath , '/' , "-" ) ; 
else if ( cachePathPolicy == CachePathPolicy . NestedTruncate ) { 
int pos = cachePath . indexOf ( cachePathPolicyParam ) ; 
if ( pos >= 0 ) 
cachePath = cachePath . substring ( pos + cachePathPolicyParam . length ( ) ) ; 
if ( cachePathPolicy != CachePathPolicy . OneDirectory ) { 
File file = new File ( root + cachePath ) ; 
File parent = file . getParentFile ( ) ; 
if ( ! parent . exists ( ) ) { 
new Throwable ( ) . printStackTrace ( ) ; 
boolean ret = parent . mkdirs ( ) ; 
return root + cachePath ; 
} public void showCache ( PrintStream pw ) { 
String org = null ; 
org = URLDecoder . decode ( file . getName ( ) , "UTF8" ) ; 
} public void cleanCache ( File dir , Formatter sbuff , boolean isRoot ) { 
long now = System . currentTimeMillis ( ) ; 
if ( ! isRoot && ( files . length == 0 ) ) { 
long duration = now - dir . lastModified ( ) ; 
duration /= 1000 * 60 ; 
if ( duration > persistMinutes ) { 
boolean ok = dir . delete ( ) ; 
if ( ! ok ) 
if ( sbuff != null ) 
cleanCache ( file , sbuff , false ) ; 
long duration = now - file . lastModified ( ) ; 
boolean ok = file . delete ( ) ; 
} public String getMessage ( ) { 
if ( ! specialConstructor ) { 
return super . getMessage ( ) ; 
StringBuilder expected = new StringBuilder ( ) ; 
int maxSize = 0 ; 
for ( int [ ] expectedTokenSequence : expectedTokenSequences ) { 
if ( maxSize < expectedTokenSequence . length ) { 
maxSize = expectedTokenSequence . length ; 
for ( int anExpectedTokenSequence : expectedTokenSequence ) { 
if ( expectedTokenSequence [ expectedTokenSequence . length - 1 ] != 0 ) { 
expected . append ( "..." ) ; 
Token tok = currentToken . next ; 
for ( int i = 0 ; i < maxSize ; i ++ ) { 
if ( tok . kind == 0 ) { 
b . append ( tokenImage [ 0 ] ) ; 
b . append ( add_escapes ( tok . image ) ) ; 
tok = tok . next ; 
b . append ( "." ) . append ( eol ) ; 
if ( expectedTokenSequences . length == 1 ) { 
expected . append ( expected . toString ( ) ) ; 
} @ Override public void tableChanged ( final TableModelEvent e ) { 
if ( e . getFirstRow ( ) == TableModelEvent . HEADER_ROW ) { 
EventQueue . invokeLater ( new Runnable ( ) { 
@ Override public void run ( ) { 
boolean doFullScan = table . getRowCount ( ) <= fullScanCutoff ; 
if ( e . getColumn ( ) == TableModelEvent . ALL_COLUMNS ) { 
resize ( table , doFullScan ) ; 
resize ( table , e . getColumn ( ) , doFullScan ) ; 
} @ Override public void columnAdded ( TableColumnModelEvent e ) { 
resize ( table , e . getToIndex ( ) , doFullScan ) ; 
} public static Bearing calculateBearing ( Earth e , LatLonPoint pt1 , 
LatLonPoint pt2 , Bearing result ) { 
return calculateBearing ( e , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , 
pt2 . getLatitude ( ) , pt2 . getLongitude ( ) , 
result ) ; 
} public static Bearing calculateBearing ( LatLonPoint pt1 , LatLonPoint pt2 , 
Bearing result ) { 
return calculateBearing ( defaultEarth , pt1 . getLatitude ( ) , 
pt1 . getLongitude ( ) , pt2 . getLatitude ( ) , 
pt2 . getLongitude ( ) , result ) ; 
} public static Bearing calculateBearing ( double lat1 , double lon1 , 
double lat2 , double lon2 , 
return calculateBearing ( defaultEarth , lat1 , lon1 , lat2 , lon2 , result ) ; 
} public static Bearing calculateBearing ( Earth e , double lat1 , double lon1 , 
result = new Bearing ( ) ; 
if ( ( lat1 == lat2 ) && ( lon1 == lon2 ) ) { 
result . distance = 0 ; 
result . azimuth = 0 ; 
result . backazimuth = 0 ; 
A = e . getMajor ( ) ; 
F = e . getFlattening ( ) ; 
R = 1.0 - F ; 
double GLAT1 = rad * lat1 ; 
double GLAT2 = rad * lat2 ; 
double TU1 = R * Math . sin ( GLAT1 ) / Math . cos ( GLAT1 ) ; 
double TU2 = R * Math . sin ( GLAT2 ) / Math . cos ( GLAT2 ) ; 
double CU1 = 1. / Math . sqrt ( TU1 * TU1 + 1. ) ; 
double SU1 = CU1 * TU1 ; 
double CU2 = 1. / Math . sqrt ( TU2 * TU2 + 1. ) ; 
double S = CU1 * CU2 ; 
double BAZ = S * TU2 ; 
double FAZ = BAZ * TU1 ; 
double GLON1 = rad * lon1 ; 
double GLON2 = rad * lon2 ; 
double X = GLON2 - GLON1 ; 
double D , SX , CX , SY , CY , Y , SA , C2A , CZ , E , C ; 
int loopCnt = 0 ; 
loopCnt ++ ; 
if ( loopCnt > 1000 ) { 
SX = Math . sin ( X ) ; 
CX = Math . cos ( X ) ; 
TU1 = CU2 * SX ; 
TU2 = BAZ - SU1 * CU2 * CX ; 
SY = Math . sqrt ( TU1 * TU1 + TU2 * TU2 ) ; 
CY = S * CX + FAZ ; 
Y = Math . atan2 ( SY , CY ) ; 
SA = S * SX / SY ; 
C2A = - SA * SA + 1. ; 
CZ = FAZ + FAZ ; 
if ( C2A > 0. ) { 
CZ = - CZ / C2A + CY ; 
E = CZ * CZ * 2. - 1. ; 
C = ( ( - 3. * C2A + 4. ) * F + 4. ) * C2A * F / 16. ; 
D = X ; 
X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ; 
X = ( 1. - C ) * X * F + GLON2 - GLON1 ; 
} while ( Math . abs ( D - X ) > EPS ) ; 
if ( loopCnt > maxLoopCnt ) { 
maxLoopCnt = loopCnt ; 
FAZ = Math . atan2 ( TU1 , TU2 ) ; 
BAZ = Math . atan2 ( CU1 * SX , BAZ * CX - SU1 * CU2 ) + Math . PI ; 
X = Math . sqrt ( ( 1. / R / R - 1. ) * C2A + 1. ) + 1. ; 
X = ( X - 2. ) / X ; 
C = 1. - X ; 
C = ( X * X / 4. + 1. ) / C ; 
D = ( 0.375 * X * X - 1. ) * X ; 
X = E * CY ; 
S = 1. - E - E ; 
S = ( ( ( ( SY * SY * 4. - 3. ) * S * CZ * D / 6. - X ) * D / 4. + CZ ) * SY 
* D + Y ) * C * A * R ; 
result . distance = S / 1000.0 ; 
result . azimuth = FAZ * deg ; 
if ( result . azimuth < 0.0 ) { 
result . azimuth += 360.0 ; 
result . backazimuth = BAZ * deg ; 
LatLonPointImpl pt1 = new LatLonPointImpl ( 40 , - 105 ) ; 
LatLonPointImpl pt2 = new LatLonPointImpl ( 37.4 , - 118.4 ) ; 
Bearing b = calculateBearing ( pt1 , pt2 , null ) ; 
+ b ) ; 
LatLonPointImpl pt3 = new LatLonPointImpl ( ) ; 
pt3 = findPoint ( pt1 , b . getAngle ( ) , b . getDistance ( ) , pt3 ) ; 
+ pt3 ) ; 
pt3 = findPoint ( pt2 , b . getBackAzimuth ( ) , b . getDistance ( ) , pt3 ) ; 
} public static LatLonPointImpl findPoint ( Earth e , LatLonPoint pt1 , 
double az , double dist , 
return findPoint ( e , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , az , dist , 
} public static LatLonPointImpl findPoint ( LatLonPoint pt1 , double az , 
double dist , 
return findPoint ( defaultEarth , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , 
az , dist , result ) ; 
} public static LatLonPointImpl findPoint ( double lat1 , double lon1 , 
return findPoint ( defaultEarth , lat1 , lon1 , az , dist , result ) ; 
} public static LatLonPointImpl findPoint ( Earth e , double lat1 , 
double lon1 , double az , 
result = new LatLonPointImpl ( ) ; 
if ( ( dist == 0 ) ) { 
result . setLatitude ( lat1 ) ; 
result . setLongitude ( lon1 ) ; 
if ( az < 0.0 ) { 
az += 360.0 ; 
double FAZ = az * rad ; 
double GLAT1 = lat1 * rad ; 
double GLON1 = lon1 * rad ; 
double S = dist * 1000. ; 
double TU = R * Math . sin ( GLAT1 ) / Math . cos ( GLAT1 ) ; 
double SF = Math . sin ( FAZ ) ; 
double CF = Math . cos ( FAZ ) ; 
double BAZ = 0. ; 
if ( CF != 0 ) { 
BAZ = Math . atan2 ( TU , CF ) * 2 ; 
double CU = 1. / Math . sqrt ( TU * TU + 1. ) ; 
double SU = TU * CU ; 
double SA = CU * SF ; 
double C2A = - SA * SA + 1. ; 
double X = Math . sqrt ( ( 1. / R / R - 1. ) * C2A + 1. ) + 1. ; 
double C = 1. - X ; 
C = ( X * X / 4. + 1 ) / C ; 
double D = ( 0.375 * X * X - 1. ) * X ; 
TU = S / R / A / C ; 
double Y = TU ; 
double SY , CY , CZ , E , GLAT2 , GLON2 ; 
SY = Math . sin ( Y ) ; 
CY = Math . cos ( Y ) ; 
CZ = Math . cos ( BAZ + Y ) ; 
C = Y ; 
Y = E + E - 1. ; 
Y = ( ( ( SY * SY * 4. - 3. ) * Y * CZ * D / 6. + X ) * D / 4. - CZ ) 
* SY * D + TU ; 
} while ( Math . abs ( Y - C ) > EPS ) ; 
BAZ = CU * CY * CF - SU * SY ; 
C = R * Math . sqrt ( SA * SA + BAZ * BAZ ) ; 
D = SU * CY + CU * SY * CF ; 
GLAT2 = Math . atan2 ( D , C ) ; 
C = CU * CY - SU * SY * CF ; 
X = Math . atan2 ( SY * SF , C ) ; 
D = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ; 
GLON2 = GLON1 + X - ( 1. - C ) * D * F ; 
BAZ = ( Math . atan2 ( SA , BAZ ) + Math . PI ) * deg ; 
result . setLatitude ( GLAT2 * deg ) ; 
result . setLongitude ( GLON2 * deg ) ; 
} public void loadPictureInThread ( URL imageUrl , int priority , double rotation ) { 
if ( pictureStatusCode == LOADING ) { 
stopLoadingExcept ( imageUrl ) ; 
this . imageUrl = imageUrl ; 
this . rotation = rotation ; 
LoadThread t = new LoadThread ( this ) ; 
t . setPriority ( priority ) ; 
} public void loadPicture ( URL imageUrl , double rotation ) { 
loadPicture ( ) ; 
} public void loadPicture ( ) { 
abortFlag = false ; 
ImageInputStream iis = ImageIO . createImageInputStream ( imageUrl . openStream ( ) ) ; 
Iterator i = ImageIO . getImageReaders ( iis ) ; 
reader = ( ImageReader ) i . next ( ) ; 
reader . addIIOReadProgressListener ( imageProgressListener ) ; 
reader . setInput ( iis ) ; 
sourcePictureBufferedImage = null ; 
sourcePictureBufferedImage = reader . read ( 0 ) ; 
iis . close ( ) ; 
reader . removeIIOReadProgressListener ( imageProgressListener ) ; 
reader . dispose ( ) ; 
if ( ! abortFlag ) { 
if ( rotation != 0 ) { 
int xRot = sourcePictureBufferedImage . getWidth ( ) / 2 ; 
int yRot = sourcePictureBufferedImage . getHeight ( ) / 2 ; 
AffineTransform rotateAf = AffineTransform . getRotateInstance ( Math . toRadians ( rotation ) , xRot , yRot ) ; 
AffineTransformOp op = new AffineTransformOp ( rotateAf , AffineTransformOp . TYPE_BILINEAR ) ; 
Rectangle2D newBounds = op . getBounds2D ( sourcePictureBufferedImage ) ; 
double minX = newBounds . getMinX ( ) ; 
double minY = newBounds . getMinY ( ) ; 
AffineTransform translateAf = AffineTransform . getTranslateInstance ( minX * ( - 1 ) , minY * ( - 1 ) ) ; 
rotateAf . preConcatenate ( translateAf ) ; 
op = new AffineTransformOp ( rotateAf , AffineTransformOp . TYPE_BILINEAR ) ; 
newBounds = op . getBounds2D ( sourcePictureBufferedImage ) ; 
BufferedImage targetImage = new BufferedImage ( 
( int ) newBounds . getWidth ( ) , 
( int ) newBounds . getHeight ( ) , 
BufferedImage . TYPE_3BYTE_BGR ) ; 
sourcePictureBufferedImage = op . filter ( sourcePictureBufferedImage , targetImage ) ; 
PictureCache . add ( imageUrl , ( SourcePicture ) this . clone ( ) ) ; 
} public void stopLoading ( ) { 
if ( imageUrl == null ) 
reader . abort ( ) ; 
abortFlag = true ; 
} public boolean stopLoadingExcept ( URL exemptionURL ) { 
if ( pictureStatusCode != LOADING ) { 
if ( ! exemptionURL . toString ( ) . equals ( imageUrl . toString ( ) ) ) { 
stopLoading ( ) ; 
} public Dimension getSize ( ) { 
if ( sourcePictureBufferedImage != null ) 
return new Dimension ( sourcePictureBufferedImage . getWidth ( ) , sourcePictureBufferedImage . getHeight ( ) ) ; 
return new Dimension ( 0 , 0 ) ; 
} public void addListener ( SourcePictureListener listener ) { 
sourcePictureListeners . add ( listener ) ; 
} public void removeListener ( SourcePictureListener listener ) { 
sourcePictureListeners . remove ( listener ) ; 
} private void setStatus ( int statusCode , String statusMessage ) { 
pictureStatusCode = statusCode ; 
pictureStatusMessage = statusMessage ; 
Vector nonmodifiedVector = ( Vector ) sourcePictureListeners . clone ( ) ; 
Enumeration e = nonmodifiedVector . elements ( ) ; 
SourcePictureListener spl = ( ( SourcePictureListener ) e . nextElement ( ) ) ; 
spl . sourceStatusChange ( pictureStatusCode , pictureStatusMessage , this ) ; 
} public void setSourceBufferedImage ( BufferedImage img , String statusMessage ) { 
sourcePictureBufferedImage = img ; 
setStatus ( READY , statusMessage ) ; 
Catalog cat = dataset . getParentCatalog ( ) ; 
} DataDescriptor makeAssociatedField ( int bitWidth ) { 
DataDescriptor assDD = new DataDescriptor ( ) ; 
assDD . name = name + "_associated_field" ; 
assDD . units = "" ; 
assDD . refVal = 0 ; 
assDD . scale = 0 ; 
assDD . bitWidth = bitWidth ; 
assDD . type = 0 ; 
assDD . f = 0 ; 
assDD . x = 31 ; 
assDD . y = 22 ; 
assDD . fxy = ( short ) ( ( f << 14 ) + ( x << 8 ) + ( y ) ) ; 
return assDD ; 
} static public void transferInfo ( List < DataDescriptor > fromList , List < DataDescriptor > toList ) { 
if ( fromList . size ( ) != toList . size ( ) ) 
for ( int i = 0 ; i < fromList . size ( ) ; i ++ ) { 
DataDescriptor from = fromList . get ( i ) ; 
DataDescriptor to = toList . get ( i ) ; 
to . refersTo = from . refersTo ; 
to . name = from . name ; 
if ( from . getSubKeys ( ) != null ) 
transferInfo ( from . getSubKeys ( ) , to . getSubKeys ( ) ) ; 
} int countBits ( ) { 
int total_nbits = 0 ; 
total_nbytesCDM = 0 ; 
for ( DataDescriptor dd : subKeys ) { 
if ( dd . subKeys != null ) { 
total_nbits += dd . countBits ( ) ; 
total_nbytesCDM += dd . total_nbytesCDM ; 
} else if ( dd . f == 0 ) { 
total_nbits += dd . bitWidth ; 
total_nbytesCDM += dd . getByteWidthCDM ( ) ; 
if ( replication > 1 ) { 
total_nbits *= replication ; 
total_nbytesCDM *= replication ; 
return total_nbits ; 
} public boolean equals2 ( Object o ) { 
if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; 
DataDescriptor that = ( DataDescriptor ) o ; 
if ( fxy != that . fxy ) return false ; 
if ( replication != that . replication ) return false ; 
if ( type != that . type ) return false ; 
if ( subKeys != null ? ! subKeys . equals ( that . subKeys ) : that . subKeys != null ) return false ; 
} private int getListHash ( ) { 
if ( subKeys == null ) return 0 ; 
int result = 1 ; 
for ( DataDescriptor e : subKeys ) 
result = 31 * result + ( e == null ? 0 : e . hashCode2 ( ) ) ; 
} private int loadHeader ( ) { 
if ( headerLoaded ) return 0 ; 
InputStream s = stream ; 
if ( s == null ) return - 1 ; 
BufferedInputStream bs = new BufferedInputStream ( s ) ; 
ds = new DataInputStream ( bs ) ; 
Header = new byte [ 32 ] ; 
ds . readFully ( Header ) ; 
if ( Header [ 0 ] == '<' ) { 
close ( ds ) ; 
filetype = Header [ 0 ] ; 
nrecords = Swap . swapInt ( Header , 4 ) ; 
nbytesheader = Swap . swapShort ( Header , 8 ) ; 
nfields = ( nbytesheader / 32 ) - 1 ; 
if ( nfields < 1 ) { 
nbytesheader ) ; 
FieldDesc = new DbaseFieldDesc [ nfields ] ; 
data = new DbaseData [ nfields ] ; 
for ( int i = 0 ; i < nfields ; i ++ ) { 
FieldDesc [ i ] = new DbaseFieldDesc ( ds , filetype ) ; 
data [ i ] = new DbaseData ( FieldDesc [ i ] , 
nrecords ) ; 
ds . readByte ( ) ; 
headerLoaded = true ; 
} catch ( java . io . IOException e ) { 
close ( s ) ; 
} private int loadData ( ) { 
if ( ! headerLoaded ) return - 1 ; 
if ( dataLoaded ) return 0 ; 
for ( int i = 0 ; i < nrecords ; i ++ ) { 
byte recbyte = ds . readByte ( ) ; 
if ( recbyte == 0x20 ) { 
for ( int j = 0 ; j < nfields ; j ++ ) { 
data [ j ] . readRowN ( ds , i ) ; 
nrecords -- ; 
i -- ; 
dataLoaded = true ; 
} public DbaseData getField ( String Name ) { 
if ( FieldDesc [ i ] . Name . equals ( Name ) ) return data [ i ] ; 
} public double [ ] getDoublesByName ( String Name ) { 
DbaseData d ; 
if ( ( d = getField ( Name ) ) == null ) return null ; 
if ( d . getType ( ) == DbaseData . TYPE_CHAR ) { 
String [ ] s = d . getStrings ( ) ; 
double [ ] dd = new double [ s . length ] ; 
for ( int i = 0 ; i < s . length ; i ++ ) { 
dd [ i ] = Double . valueOf ( s [ i ] ) ; 
return dd ; 
if ( d . getType ( ) == DbaseData . TYPE_BOOLEAN ) { 
boolean [ ] b = d . getBooleans ( ) ; 
double [ ] dd = new double [ b . length ] ; 
for ( int i = 0 ; i < b . length ; i ++ ) { 
if ( b [ i ] ) { 
dd [ i ] = 1 ; 
dd [ i ] = 0 ; 
return d . getDoubles ( ) ; 
} public String [ ] getStringsByName ( String Name ) { 
if ( d . getType ( ) != DbaseData . TYPE_CHAR ) return null ; 
return d . getStrings ( ) ; 
} public boolean [ ] getBooleansByName ( String Name ) { 
if ( d . getType ( ) != DbaseData . TYPE_BOOLEAN ) return null ; 
return d . getBooleans ( ) ; 
} public String getFieldName ( int i ) { 
if ( i >= nfields || i < 0 ) { 
return ( FieldDesc [ i ] . Name ) ; 
} public String [ ] getFieldNames ( ) { 
String [ ] s = new String [ nfields ] ; 
s [ i ] = getFieldName ( i ) ; 
if ( args . length < 1 ) { 
System . exit ( - 1 ) ; 
DbaseFile dbf = new DbaseFile ( s ) ; 
if ( dbf . loadHeader ( ) != 0 ) { 
String [ ] fieldNames = dbf . getFieldNames ( ) ; 
System . out . print ( "[" ) ; 
int nf = dbf . getNumFields ( ) ; 
DbaseData [ ] dbd = new DbaseData [ nf ] ; 
for ( int field = 0 ; field < nf ; field ++ ) { 
dbd [ field ] = dbf . getField ( field ) ; 
switch ( dbd [ field ] . getType ( ) ) { 
case DbaseData . TYPE_BOOLEAN : 
case DbaseData . TYPE_CHAR : 
case DbaseData . TYPE_NUMERIC : 
System . out . print ( fieldNames [ field ] ) ; 
if ( field < nf - 1 ) 
System . out . println ( "]" ) ; 
if ( dbf . loadData ( ) != 0 ) { 
for ( int rec = 0 ; rec < dbf . getNumRecords ( ) ; rec ++ ) { 
System . out . print ( dbd [ field ] . getData ( rec ) ) ; 
System . out . println ( ) ; 
} public Map < String , DapAttribute > getAttributes ( ) 
if ( attributes == null ) attributes = new HashMap < String , DapAttribute > ( ) ; 
return attributes ; 
} synchronized public DapAttribute setAttribute ( DapAttribute attr ) 
if ( attributes == null ) 
attributes = new HashMap < String , DapAttribute > ( ) ; 
DapAttribute old = attributes . get ( attr . getShortName ( ) ) ; 
attributes . put ( attr . getShortName ( ) , attr ) ; 
attr . setParent ( this ) ; 
return old ; 
} public synchronized void removeAttribute ( DapAttribute attr ) 
if ( this . attributes == null ) 
String name = attr . getShortName ( ) ; 
if ( this . attributes . containsKey ( name ) ) 
this . attributes . remove ( name ) ; 
} public DapGroup getGroup ( ) 
if ( this . sort == DapSort . DATASET ) 
DapNode group = parent ; 
while ( group != null ) { 
switch ( group . getSort ( ) ) { 
return ( DapGroup ) group ; 
group = group . getParent ( ) ; 
} public DapNode getContainer ( ) 
DapNode parent = this . parent ; 
switch ( getSort ( ) ) { 
case ENUMCONST : 
parent = ( ( DapEnumConst ) this ) . getParent ( ) . getContainer ( ) ; 
case ATTRIBUTESET : 
case OTHERXML : 
parent = ( ( DapAttribute ) this ) . getParent ( ) ; 
if ( parent instanceof DapVariable ) 
parent = parent . getContainer ( ) ; 
case MAP : 
parent = ( ( DapMap ) this ) . getVariable ( ) . getContainer ( ) ; 
return parent ; 
} public void setParent ( DapNode parent ) 
assert this . parent == null ; 
assert ( 
( this . getSort ( ) == DapSort . ENUMCONST && parent . getSort ( ) == DapSort . ENUMERATION ) 
|| parent . getSort ( ) . isa ( DapSort . GROUP ) 
|| parent . getSort ( ) == DapSort . VARIABLE 
|| parent . getSort ( ) == DapSort . STRUCTURE 
|| parent . getSort ( ) == DapSort . SEQUENCE 
|| this . getSort ( ) == DapSort . ATTRIBUTE 
|| this . getSort ( ) == DapSort . ATTRIBUTESET 
this . parent = parent ; 
} public String getEscapedShortName ( ) 
if ( this . escapedname == null ) 
this . escapedname = Escape . backslashEscape ( getShortName ( ) , null ) ; 
return this . escapedname ; 
} public List < DapNode > 
getPath ( ) 
List < DapNode > path = new ArrayList < DapNode > ( ) ; 
DapNode current = this ; 
path . add ( 0 , current ) ; 
current = current . getParent ( ) ; 
if ( current == null ) 
} public List < DapNode > getContainerPath ( ) 
DapNode current = this . getContainer ( ) ; 
if ( current . getContainer ( ) == null ) 
current = current . getContainer ( ) ; 
} public List < DapGroup > getGroupPath ( ) 
List < DapGroup > path = new ArrayList < DapGroup > ( ) ; 
if ( current . getSort ( ) == DapSort . GROUP 
|| current . getSort ( ) == DapSort . DATASET ) 
path . add ( 0 , ( DapGroup ) current ) ; 
computefqn ( ) 
List < DapNode > path = getPath ( ) ; 
StringBuilder fqn = new StringBuilder ( ) ; 
DapNode parent = path . get ( 0 ) ; 
for ( int i = 1 ; i < path . size ( ) ; i ++ ) { 
DapNode current = path . get ( i ) ; 
switch ( parent . getSort ( ) ) { 
fqn . append ( '/' ) ; 
fqn . append ( Escape . backslashEscape ( current . getShortName ( ) , "/." ) ) ; 
fqn . append ( '.' ) ; 
fqn . append ( current . getEscapedShortName ( ) ) ; 
parent = current ; 
return fqn . toString ( ) ; 
} public boolean isTopLevel ( ) 
return parent == null 
|| parent . getSort ( ) == DapSort . DATASET 
|| parent . getSort ( ) == DapSort . GROUP ; 
String convStr = ncd . findAttValueIgnoreCase ( null , "Conventions" , null ) ; 
if ( ( null != convStr ) && convStr . startsWith ( "CF/Radial" ) ) 
} protected void addRadialVariable ( NetcdfDataset nds , Variable var ) { 
RadialVariable rsvar = null ; 
String vName = var . getShortName ( ) ; 
int tIdx = var . findDimensionIndex ( "time" ) ; 
int rIdx = var . findDimensionIndex ( "range" ) ; 
int ptsIdx = var . findDimensionIndex ( "n_points" ) ; 
if ( ( ( tIdx == 0 ) && ( rIdx == 1 ) ) || ( ptsIdx == 0 ) ) { 
VariableSimpleIF v = new MyRadialVariableAdapter ( vName , var . getAttributes ( ) ) ; 
rsvar = makeRadialVariable ( nds , v , var ) ; 
if ( rsvar != null ) { 
dataVariables . add ( rsvar ) ; 
} public String getInfo ( ) { 
sbuff . append ( "CFRadial2Dataset\n" ) ; 
sbuff . append ( "\n\n" ) ; 
sbuff . append ( parseInfo . toString ( ) ) ; 
build ( String document , byte [ ] serialdata , ByteOrder order ) 
DapDataset dmr = parseDMR ( document ) ; 
if ( DEBUG || DUMPDMR ) { 
System . err . println ( "\n+++++++++++++++++++++" ) ; 
System . err . println ( dmr ) ; 
System . err . println ( "+++++++++++++++++++++\n" ) ; 
if ( DEBUG || DUMPDAP ) { 
ByteBuffer data = ByteBuffer . wrap ( serialdata ) ; 
System . err . println ( "+++++++++++++++++++++" ) ; 
System . err . println ( "\n---------------------" ) ; 
DapDump . dumpbytes ( data , false ) ; 
System . err . println ( "\n---------------------\n" ) ; 
build ( dmr , serialdata , order ) ; 
build ( DapDataset dmr , byte [ ] serialdata , ByteOrder order ) 
setDMR ( dmr ) ; 
this . databuffer = ByteBuffer . wrap ( serialdata ) . order ( order ) ; 
D4DataCompiler compiler = new D4DataCompiler ( this , getChecksumMode ( ) , getOrder ( ) , this . databuffer ) ; 
compiler . compile ( ) ; 
} private void write ( StationObsDataset sobsDataset ) throws IOException { 
createGlobalAttributes ( ) ; 
createStations ( sobsDataset . getStations ( ) ) ; 
ncfile . addGlobalAttribute ( "time_coverage_start" , dateFormatter . toDateTimeStringISO ( sobsDataset . getStartDate ( ) ) ) ; 
ncfile . addGlobalAttribute ( "time_coverage_end" , dateFormatter . toDateTimeStringISO ( sobsDataset . getEndDate ( ) ) ) ; 
createDataVariables ( sobsDataset . getDataVariables ( ) ) ; 
List gatts = sobsDataset . getGlobalAttributes ( ) ; 
for ( int i = 0 ; i < gatts . size ( ) ; i ++ ) { 
Attribute att = ( Attribute ) gatts . get ( i ) ; 
ncfile . addGlobalAttribute ( att ) ; 
ncfile . create ( ) ; 
writeStationData ( sobsDataset . getStations ( ) ) ; 
if ( ! ( Boolean ) ncfile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ) 
int [ ] origin = new int [ 1 ] ; 
int [ ] originTime = new int [ 2 ] ; 
ArrayStructureW sArray = null ; 
ArrayObject . D1 timeArray = new ArrayObject . D1 ( DataType . STRING , String . class , false , 1 ) ; 
DataIterator diter = sobsDataset . getDataIterator ( 1000 * 1000 ) ; 
while ( diter . hasNext ( ) ) { 
StationObsDatatype sobs = ( StationObsDatatype ) diter . nextData ( ) ; 
StructureData recordData = sobs . getData ( ) ; 
if ( sArray == null ) 
sArray = new ArrayStructureW ( recordData . getStructureMembers ( ) , new int [ ] { 1 } ) ; 
sArray . setStructureData ( recordData , 0 ) ; 
timeArray . set ( 0 , dateFormatter . toDateTimeStringISO ( sobs . getObservationTimeAsDate ( ) ) ) ; 
origin [ 0 ] = recno ; 
originTime [ 0 ] = recno ; 
ncfile . write ( "record" , origin , sArray ) ; 
ncfile . writeStringData ( timeName , originTime , timeArray ) ; 
ncfile . close ( ) ; 
} public Object getBean ( String key , Object def ) { 
if ( isRemoved ( ) ) 
synchronized ( lock ) { 
result = _getObject ( key ) ; 
if ( result instanceof Bean . Collection ) 
result = ( ( Bean . Collection ) result ) . getCollection ( ) ; 
else if ( result instanceof Bean ) 
result = ( ( Bean ) result ) . getObject ( ) ; 
return ( result == null ? def : result ) ; 
} public void putBean ( String key , Object newValue ) { 
Object oldValue = getBean ( key , null ) ; 
if ( ( oldValue == null ) || ! oldValue . equals ( newValue ) ) 
keyValues . put ( key , new Bean ( newValue ) ) ; 
} public void putBeanCollection ( String key , Collection newValue ) { 
keyValues . put ( key , new Bean . Collection ( newValue ) ) ; 
} public void putBeanObject ( String key , Object newValue ) { 
keyValues . put ( key , newValue ) ; 
} public List getList ( String key , List def ) { 
Object bean = getBean ( key , def ) ; 
return ( List ) bean ; 
} protected String [ ] childrenNamesSpi ( ) { 
HashSet allKids = new HashSet ( children . keySet ( ) ) ; 
PreferencesExt sd = getStoredDefaults ( ) ; 
if ( sd != null ) 
allKids . addAll ( sd . childrenNamesSpi ( absolutePath ( ) ) ) ; 
ArrayList list = new ArrayList ( allKids ) ; 
String result [ ] = new String [ list . size ( ) ] ; 
result [ i ] = list . get ( i ) . toString ( ) ; 
} protected Collection childrenNamesSpi ( String nodePath ) { 
HashSet allKids = new HashSet ( ) ; 
if ( nodeExists ( nodePath ) ) { 
PreferencesExt node = ( PreferencesExt ) node ( nodePath ) ; 
allKids . addAll ( node . children . keySet ( ) ) ; 
} catch ( java . util . prefs . BackingStoreException e ) { } 
allKids . addAll ( sd . childrenNamesSpi ( nodePath ) ) ; 
return allKids ; 
} protected String [ ] keysSpi ( ) throws BackingStoreException { 
HashSet allKeys = new HashSet ( keyValues . keySet ( ) ) ; 
allKeys . addAll ( sd . keysSpi ( absolutePath ( ) ) ) ; 
ArrayList list = new ArrayList ( allKeys ) ; 
} protected Collection keysSpi ( String nodePath ) { 
HashSet allKeys = new HashSet ( ) ; 
allKeys . addAll ( node . keyValues . keySet ( ) ) ; 
if ( sd != null ) { 
allKeys . addAll ( sd . keysSpi ( nodePath ) ) ; 
return allKeys ; 
} protected AbstractPreferences childSpi ( String name ) { 
PreferencesExt child ; 
if ( null != ( child = ( PreferencesExt ) children . get ( name ) ) ) 
return child ; 
child = new PreferencesExt ( this , name ) ; 
children . put ( name , child ) ; 
child . newNode = true ; 
} protected String getSpi ( String keyName ) { 
Object o = _getObject ( keyName ) ; 
return ( o == null ) ? null : o . toString ( ) ; 
} protected void putSpi ( String key , String newValue ) { 
String oldValue = getSpi ( key ) ; 
} protected void removeNodeSpi ( ) throws BackingStoreException { 
if ( null == parent . children . remove ( name ( ) ) ) 
} private Object _getObject ( String keyName ) { 
result = keyValues . get ( keyName ) ; 
result = sd . getObjectFromNode ( absolutePath ( ) , keyName ) ; 
} public float [ ] readData ( RandomAccessFile raf ) throws IOException { 
Grib2Gds gds = getGDS ( ) ; 
Grib2DataReader reader = new Grib2DataReader ( drss . getDataTemplate ( ) , gdss . getNumberPoints ( ) , drss . getDataPoints ( ) , 
getScanMode ( ) , gds . getNxRaw ( ) , dataSection . getStartingPosition ( ) , dataSection . getMsgLength ( ) ) ; 
Grib2Drs gdrs = drss . getDrs ( raf ) ; 
float [ ] data = reader . getData ( raf , bms , gdrs ) ; 
if ( gds . isThin ( ) ) 
data = QuasiRegular . convertQuasiGrid ( data , gds . getNptsInLine ( ) , gds . getNxRaw ( ) , gds . getNyRaw ( ) , GribData . getInterpolationMethod ( ) ) ; 
lastRecordRead = this ; 
public int [ ] readRawData ( RandomAccessFile raf ) throws IOException { 
return reader . getRawData ( raf , bms , gdrs ) ; 
} public float [ ] readData ( RandomAccessFile raf , long drsPos ) throws IOException { 
raf . seek ( drsPos ) ; 
Grib2SectionDataRepresentation drs = new Grib2SectionDataRepresentation ( raf ) ; 
Grib2SectionBitMap bms = new Grib2SectionBitMap ( raf ) ; 
Grib2SectionData dataSection = new Grib2SectionData ( raf ) ; 
Grib2DataReader reader = new Grib2DataReader ( drs . getDataTemplate ( ) , gdss . getNumberPoints ( ) , drs . getDataPoints ( ) , 
Grib2Drs gdrs = drs . getDrs ( raf ) ; 
} public static float [ ] readData ( RandomAccessFile raf , long drsPos , long bmsPos , int gdsNumberPoints , int scanMode , int nx , int ny , int [ ] nptsInLine ) throws IOException { 
if ( bmsPos > 0 ) 
bms = Grib2SectionBitMap . factory ( raf , bmsPos ) ; 
Grib2DataReader reader = new Grib2DataReader ( drs . getDataTemplate ( ) , gdsNumberPoints , drs . getDataPoints ( ) , 
scanMode , nx , dataSection . getStartingPosition ( ) , dataSection . getMsgLength ( ) ) ; 
if ( nptsInLine != null ) 
data = QuasiRegular . convertQuasiGrid ( data , nptsInLine , nx , ny , GribData . getInterpolationMethod ( ) ) ; 
if ( getlastRecordRead ) 
lastRecordRead = Grib2RecordScanner . findRecordByDrspos ( raf , drsPos ) ; 
} public DSPPrinter 
print ( ) 
DapDataset dmr = this . dsp . getDMR ( ) ; 
this . ce = CEConstraint . getUniversal ( dmr ) ; 
this . printer . setIndent ( 0 ) ; 
List < DapVariable > topvars = dmr . getTopVariables ( ) ; 
for ( int i = 0 ; i < topvars . size ( ) ; i ++ ) { 
DapVariable top = topvars . get ( i ) ; 
List < Slice > slices = this . ce . getConstrainedSlices ( top ) ; 
if ( this . ce . references ( top ) ) { 
DataCursor data = dsp . getVariableData ( top ) ; 
printVariable ( data , slices ) ; 
printer . eol ( ) ; 
printVariable ( DataCursor data , List < Slice > slices ) 
DapVariable dapv = ( DapVariable ) data . getTemplate ( ) ; 
if ( data . isScalar ( ) ) { 
assert slices == Slice . SCALARSLICES ; 
printScalar ( data ) ; 
printArray ( data , slices ) ; 
printCompoundInstance ( DataCursor datav ) 
DapStructure dstruct = ( DapStructure ) ( ( DapVariable ) datav . getTemplate ( ) ) . getBaseType ( ) ; 
switch ( datav . getScheme ( ) ) { 
case RECORD : 
List < DapVariable > dfields = dstruct . getFields ( ) ; 
for ( int f = 0 ; f < dfields . size ( ) ; f ++ ) { 
DapVariable field = dfields . get ( f ) ; 
List < Slice > fieldslices = this . ce . getConstrainedSlices ( field ) ; 
DataCursor fdata = datav . readField ( f ) ; 
printVariable ( fdata , fieldslices ) ; 
DapSequence dseq = ( DapSequence ) dstruct ; 
long count = datav . getRecordCount ( ) ; 
for ( long r = 0 ; r < count ; r ++ ) { 
DataCursor dr = datav . readRecord ( r ) ; 
printer . marginPrint ( "[" ) ; 
printCompoundInstance ( dr ) ; 
printer . marginPrint ( "]" ) ; 
String sweepAxisAngle = GEOSTransform . scanGeomToSweepAngleAxis ( navigation . scan_geom ) ; 
return new Geostationary ( navigation . sub_lon_degrees , sweepAxisAngle , geoCoordinateScaleFactor ) ; 
} public String writeToString ( Element elem ) { 
try ( StringWriter writer = new StringWriter ( ) ) { 
writeToWriter ( elem , writer ) ; 
} public void writeToFile ( Element elem , File outFile ) throws IOException { 
try ( OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outFile , false ) ) ) { 
writeToStream ( elem , outStream ) ; 
} public void writeToStream ( Element elem , OutputStream outStream ) throws IOException { 
try ( Writer writer = new BufferedWriter ( new OutputStreamWriter ( 
new BufferedOutputStream ( outStream ) , xmlFormat . getEncoding ( ) ) ) ) { 
} public void writeToWriter ( Element elem , Writer writer ) throws IOException { 
xmlOutputter . setFormat ( xmlFormat ) ; 
elem . detach ( ) ; 
xmlOutputter . output ( new Document ( elem ) , writer ) ; 
} public Element makeExplicitNetcdfElement ( NetcdfFile ncFile , String location ) { 
Element netcdfElem = makeNetcdfElement ( ncFile , location ) ; 
netcdfElem . addContent ( 0 , new Element ( "explicit" , namespace ) ) ; 
return netcdfElem ; 
} public Element makeEnumTypedefElement ( EnumTypedef etd ) { 
Element typeElem = new Element ( "enumTypedef" , namespace ) ; 
typeElem . setAttribute ( "name" , etd . getShortName ( ) ) ; 
typeElem . setAttribute ( "type" , etd . getBaseType ( ) . toString ( ) ) ; 
TreeMap < Integer , String > map = new TreeMap < > ( etd . getMap ( ) ) ; 
for ( Map . Entry < Integer , String > entry : map . entrySet ( ) ) { 
typeElem . addContent ( new Element ( "enum" , namespace ) 
. setAttribute ( "key" , Integer . toString ( entry . getKey ( ) ) ) 
. addContent ( entry . getValue ( ) ) ) ; 
return typeElem ; 
} public Element makeDimensionElement ( Dimension dim ) throws IllegalArgumentException { 
if ( ! dim . isShared ( ) ) { 
Element dimElem = new Element ( "dimension" , namespace ) ; 
dimElem . setAttribute ( "name" , dim . getShortName ( ) ) ; 
dimElem . setAttribute ( "length" , Integer . toString ( dim . getLength ( ) ) ) ; 
if ( dim . isUnlimited ( ) ) 
dimElem . setAttribute ( "isUnlimited" , "true" ) ; 
return dimElem ; 
} public Element makeValuesElement ( Variable variable , boolean allowRegular ) throws IOException { 
Element elem = new Element ( "values" , namespace ) ; 
StringBuilder buff = new StringBuilder ( ) ; 
Array a = variable . read ( ) ; 
if ( variable . getDataType ( ) == DataType . CHAR ) { 
char [ ] data = ( char [ ] ) a . getStorage ( ) ; 
elem . setText ( new String ( data ) ) ; 
} else if ( variable . getDataType ( ) == DataType . STRING ) { 
elem . setAttribute ( "separator" , "|" ) ; 
for ( IndexIterator iter = a . getIndexIterator ( ) ; iter . hasNext ( ) ; ) { 
if ( count ++ > 0 ) { 
buff . append ( "|" ) ; 
buff . append ( iter . getObjectNext ( ) ) ; 
elem . setText ( buff . toString ( ) ) ; 
if ( allowRegular && ( a . getRank ( ) == 1 ) && ( a . getSize ( ) > 2 ) ) { 
Index ima = a . getIndex ( ) ; 
double start = a . getDouble ( ima . set ( 0 ) ) ; 
double incr = a . getDouble ( ima . set ( 1 ) ) - start ; 
boolean isRegular = true ; 
for ( int i = 2 ; i < a . getSize ( ) ; i ++ ) { 
double v1 = a . getDouble ( ima . set ( i ) ) ; 
double v0 = a . getDouble ( ima . set ( i - 1 ) ) ; 
if ( ! ucar . nc2 . util . Misc . nearlyEquals ( v1 - v0 , incr ) ) 
isRegular = false ; 
if ( isRegular ) { 
elem . setAttribute ( "start" , Double . toString ( start ) ) ; 
elem . setAttribute ( "increment" , Double . toString ( incr ) ) ; 
elem . setAttribute ( "npts" , Long . toString ( variable . getSize ( ) ) ) ; 
return elem ; 
boolean isRealType = ( variable . getDataType ( ) == DataType . DOUBLE ) || ( variable . getDataType ( ) == DataType . FLOAT ) ; 
IndexIterator iter = a . getIndexIterator ( ) ; 
buff . append ( isRealType ? iter . getDoubleNext ( ) : iter . getIntNext ( ) ) ; 
} public static MeasureType initValue ( MeasureType value , PointFeature pointFeat , VariableSimpleIF dataVar ) 
StructureMembers . Member firstDataMember = pointFeat . getDataAll ( ) . findMember ( dataVar . getShortName ( ) ) ; 
assert firstDataMember != null : String . format ( 
Array dataArray = pointFeat . getDataAll ( ) . getArray ( firstDataMember ) ; 
Arrays . toString ( dataArray . getShape ( ) ) ) ; 
double dataVal = dataArray . getDouble ( 0 ) ; 
value . setDoubleValue ( dataVal ) ; 
} public ProjectionCT makeCoordinateTransform ( AttributeContainer ctv , String units ) { 
int [ ] area = getIntArray ( ctv , McIDASAreaProjection . ATTR_AREADIR ) ; 
int [ ] nav = getIntArray ( ctv , McIDASAreaProjection . ATTR_NAVBLOCK ) ; 
int [ ] aux = null ; 
if ( ctv . findAttributeIgnoreCase ( McIDASAreaProjection . ATTR_AUXBLOCK ) != null ) { 
aux = getIntArray ( ctv , McIDASAreaProjection . ATTR_AUXBLOCK ) ; 
McIDASAreaProjection proj = new McIDASAreaProjection ( area , nav , aux ) ; 
return new ProjectionCT ( ctv . getName ( ) , "FGDC" , proj ) ; 
} private int [ ] getIntArray ( AttributeContainer ctv , String attName ) { 
Attribute att = ctv . findAttribute ( attName ) ; 
if ( att == null ) { 
Array arr = att . getValues ( ) ; 
return ( int [ ] ) arr . get1DJavaArray ( int . class ) ; 
case 241 : 
return new VertCoordType ( code , "count" , null , true ) ; 
return super . getVertUnit ( code ) ; 
public String getStatisticName ( int id ) { 
if ( id < 192 ) return super . getStatisticName ( id ) ; 
if ( statName == null ) statName = initTable410 ( ) ; 
if ( statName == null ) return null ; 
return statName . get ( id ) ; 
if ( genProcessMap == null ) genProcessMap = NcepTables . getNcepGenProcess ( ) ; 
} private Map < String , String > initCodes ( ) { 
codeMap . put ( "3.1.204" , "Curvilinear_Orthogonal" ) ; 
return codeMap ; 
} public static void main1 ( String [ ] args ) 
String collectionPath = "C:/Ethan/data/mlode" ; 
String startPath = "grid/NCEP" ; 
String catWriteDirPath = "C:/Ethan/data/tmpTest" ; 
if ( args . length == 3 ) 
collectionPath = args [ 0 ] ; 
startPath = args [ 1 ] ; 
catWriteDirPath = args [ 2 ] ; 
File catWriteDir = new File ( catWriteDirPath ) ; 
File collectionFile = new File ( collectionPath ) ; 
CrawlableDataset collectionCrDs = new CrawlableDatasetFile ( collectionFile ) ; 
InvService service = new InvService ( "myServer" , "File" , collectionCrDs . getPath ( ) + "/" , null , null ) ; 
CrawlableDatasetFilter filter = null ; 
CrawlableDataset topCatCrDs = collectionCrDs . getDescendant ( startPath ) ; 
collectionCrDs , topCatCrDs , filter , null , catWriteDir ) ; 
cgaw . genCatAndSubCats ( topCatCrDs ) ; 
} private static BaseUnit bu ( final String name , final String symbol , 
final BaseQuantity quantity ) throws NameException , 
UnitExistsException { 
return BaseUnit . getOrCreate ( UnitName . newUnitName ( name , null , symbol ) , 
quantity ) ; 
} private static Unit du ( final String name , final String symbol , 
final Unit definition ) throws NameException { 
return definition . clone ( UnitName . newUnitName ( name , null , symbol ) ) ; 
} private static UnitDBImpl baseUnitDB ( ) throws NameException , UnitExistsException , NoSuchUnitException { 
final UnitDBImpl db = new UnitDBImpl ( 9 , 9 ) ; 
db . addUnit ( AMPERE ) ; 
db . addUnit ( CANDELA ) ; 
db . addUnit ( KELVIN ) ; 
db . addUnit ( KILOGRAM ) ; 
db . addUnit ( METER ) ; 
db . addUnit ( MOLE ) ; 
db . addUnit ( SECOND ) ; 
db . addUnit ( RADIAN ) ; 
db . addUnit ( STERADIAN ) ; 
db . addAlias ( "metre" , "meter" ) ; 
return db ; 
} private static UnitDBImpl derivedUnitDB ( ) throws NameException , UnitExistsException , NoSuchUnitException { 
final UnitDBImpl db = new UnitDBImpl ( 42 , 43 ) ; 
db . addUnit ( HERTZ ) ; 
db . addUnit ( NEWTON ) ; 
db . addUnit ( PASCAL ) ; 
db . addUnit ( JOULE ) ; 
db . addUnit ( WATT ) ; 
db . addUnit ( COULOMB ) ; 
db . addUnit ( VOLT ) ; 
db . addUnit ( FARAD ) ; 
db . addUnit ( OHM ) ; 
db . addUnit ( SIEMENS ) ; 
db . addUnit ( WEBER ) ; 
db . addUnit ( TESLA ) ; 
db . addUnit ( HENRY ) ; 
db . addUnit ( DEGREE_CELSIUS ) ; 
db . addUnit ( LUMEN ) ; 
db . addUnit ( LUX ) ; 
db . addUnit ( BECQUEREL ) ; 
db . addUnit ( GRAY ) ; 
db . addUnit ( SIEVERT ) ; 
db . addUnit ( MINUTE ) ; 
db . addUnit ( HOUR ) ; 
db . addUnit ( DAY ) ; 
db . addUnit ( ARC_DEGREE ) ; 
db . addUnit ( ARC_MINUTE ) ; 
db . addUnit ( ARC_SECOND ) ; 
db . addUnit ( LITER ) ; 
db . addUnit ( METRIC_TON ) ; 
db . addUnit ( NAUTICAL_MILE ) ; 
db . addUnit ( KNOT ) ; 
db . addUnit ( ANGSTROM ) ; 
db . addUnit ( ARE ) ; 
db . addUnit ( HECTARE ) ; 
db . addUnit ( BARN ) ; 
db . addUnit ( BAR ) ; 
db . addUnit ( GAL ) ; 
db . addUnit ( CURIE ) ; 
db . addUnit ( ROENTGEN ) ; 
db . addUnit ( RAD ) ; 
db . addUnit ( REM ) ; 
db . addAlias ( "litre" , "liter" , "l" ) ; 
db . addSymbol ( "tne" , "tonne" ) ; 
} public static synchronized SI instance ( ) throws UnitSystemException { 
if ( si == null ) { 
si = new SI ( ) ; 
} catch ( final UnitException e ) { 
return si ; 
} protected void update ( CollectionUpdateType force ) throws IOException { 
boolean changed ; 
MFileCollectionManager dcm ; 
switch ( force ) { 
case always : 
case test : 
dcm = ( MFileCollectionManager ) getDatasetCollectionManager ( ) ; 
changed = dcm . scan ( false ) ; 
if ( changed ) 
super . update ( force ) ; 
case never : 
public CatalogBuilder makeCatalog ( String match , String orgPath , URI catURI ) throws IOException { 
State localState = checkState ( ) ; 
} else if ( match . equals ( RUNS ) && wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . Runs ) ) 
return makeCatalogRuns ( catURI , localState ) ; 
else if ( match . equals ( OFFSET ) && wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . ConstantOffsets ) ) 
return makeCatalogOffsets ( catURI , localState ) ; 
else if ( match . equals ( FORECAST ) && wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . ConstantForecasts ) ) 
return makeCatalogForecasts ( catURI , localState ) ; 
else if ( match . startsWith ( FILES ) && wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . Files ) ) { 
return makeCatalogFiles ( catURI , localState , datasetCollection . getFilenames ( ) , true ) ; 
protected DatasetBuilder makeDatasetTop ( URI catURI , State localState ) { 
DatasetBuilder top = new DatasetBuilder ( null ) ; 
top . transferInheritedMetadata ( parent ) ; 
top . setName ( name ) ; 
top . addServiceToCatalog ( virtualService ) ; 
ThreddsMetadata tmi = top . getInheritableMetadata ( ) ; 
tmi . set ( Dataset . FeatureType , FeatureType . GRID . toString ( ) ) ; 
tmi . set ( Dataset . ServiceName , virtualService . getName ( ) ) ; 
if ( localState . coverage != null ) tmi . set ( Dataset . GeospatialCoverage , localState . coverage ) ; 
if ( localState . dateRange != null ) tmi . set ( Dataset . TimeCoverage , localState . dateRange ) ; 
if ( localState . vars != null ) tmi . set ( Dataset . VariableGroups , localState . vars ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . TwoD ) ) { 
DatasetBuilder twoD = new DatasetBuilder ( top ) ; 
String myname = name + "_" + FMRC ; 
twoD . put ( Dataset . UrlPath , this . configPath + "/" + myname ) ; 
twoD . put ( Dataset . Id , this . configPath + "/" + myname ) ; 
top . addDataset ( twoD ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . Best ) ) { 
DatasetBuilder best = new DatasetBuilder ( top ) ; 
String myname = name + "_" + BEST ; 
best . put ( Dataset . UrlPath , this . configPath + "/" + myname ) ; 
best . put ( Dataset . Id , this . configPath + "/" + myname ) ; 
top . addDataset ( best ) ; 
if ( config . fmrcConfig . getBestDatasets ( ) != null ) { 
for ( FeatureCollectionConfig . BestDataset bd : config . fmrcConfig . getBestDatasets ( ) ) { 
DatasetBuilder ds = new DatasetBuilder ( top ) ; 
ds . setName ( bd . name ) ; 
String myname = name + "_" + bd . name ; 
ds . put ( Dataset . UrlPath , this . configPath + "/" + myname ) ; 
ds . put ( Dataset . Id , this . configPath + "/" + myname ) ; 
top . addDataset ( ds ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . Runs ) ) { 
CatalogRefBuilder ds = new CatalogRefBuilder ( top ) ; 
ds . setTitle ( RUN_TITLE ) ; 
ds . setHref ( getCatalogHref ( RUNS ) ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . ConstantForecasts ) ) { 
ds . setTitle ( FORECAST_TITLE ) ; 
ds . setHref ( getCatalogHref ( FORECAST ) ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . ConstantOffsets ) ) { 
ds . setTitle ( OFFSET_TITLE ) ; 
ds . setHref ( getCatalogHref ( OFFSET ) ) ; 
if ( wantDatasets . contains ( FeatureCollectionConfig . FmrcDatasetType . Files ) && ( topDirectory != null ) ) { 
ds . setTitle ( FILES ) ; 
ds . setHref ( getCatalogHref ( FILES ) ) ; 
return top ; 
} int findCoordElement ( double [ ] target , boolean bounded ) { 
switch ( axis . getSpacing ( ) ) { 
case regularInterval : 
return findCoordElementRegular ( ( target [ 0 ] + target [ 1 ] ) / 2 , bounded ) ; 
case contiguousInterval : 
return findCoordElementContiguous ( ( target [ 0 ] + target [ 1 ] ) / 2 , bounded ) ; 
case discontiguousInterval : 
return findCoordElementDiscontiguousInterval ( target , bounded ) ; 
} private int findCoordElementRegular ( double coordValue , boolean bounded ) { 
int n = axis . getNcoords ( ) ; 
if ( n == 1 && bounded ) return 0 ; 
double distance = coordValue - axis . getCoordEdge1 ( 0 ) ; 
double exactNumSteps = distance / axis . getResolution ( ) ; 
int index = ( int ) exactNumSteps ; 
if ( bounded && index < 0 ) return 0 ; 
if ( bounded && index >= n ) return n - 1 ; 
if ( index >= 0 && index < n ) { 
double lower = axis . getCoordEdge1 ( index ) ; 
double upper = axis . getCoordEdge2 ( index ) ; 
if ( axis . isAscending ( ) ) { 
} private int findCoordElementContiguous ( double target , boolean bounded ) { 
int low = 0 ; 
int high = n - 1 ; 
if ( target < axis . getCoordEdge1 ( 0 ) ) 
return bounded ? 0 : - 1 ; 
else if ( target > axis . getCoordEdgeLast ( ) ) 
return bounded ? n - 1 : n ; 
int mid ; 
while ( high > low + 1 ) { 
mid = ( low + high ) / 2 ; 
if ( contains ( target , mid , true ) ) return mid ; 
else if ( axis . getCoordEdge2 ( mid ) < target ) low = mid ; 
else high = mid ; 
return contains ( target , low , true ) ? low : high ; 
if ( target > axis . getCoordEdge1 ( 0 ) ) 
else if ( target < axis . getCoordEdgeLast ( ) ) 
if ( contains ( target , mid , false ) ) return mid ; 
else if ( axis . getCoordEdge2 ( mid ) < target ) high = mid ; 
else low = mid ; 
return contains ( target , low , false ) ? low : high ; 
} private int findCoordElementDiscontiguousInterval ( double target , boolean bounded ) { 
int idx = findSingleHit ( target ) ; 
if ( idx >= 0 ) return idx ; 
if ( idx == - 1 ) return - 1 ; 
return findClosest ( target ) ; 
} private int findCoordElementDiscontiguousInterval ( double [ ] target , boolean bounded ) { 
for ( int i = 0 ; i < axis . getNcoords ( ) ; i ++ ) { 
double edge1 = axis . getCoordEdge1 ( i ) ; 
double edge2 = axis . getCoordEdge2 ( i ) ; 
if ( Misc . nearlyEquals ( edge1 , target [ 0 ] ) && Misc . nearlyEquals ( edge2 , target [ 1 ] ) ) 
} private int findSingleHit ( double target ) { 
if ( contains ( target , i ) ) { 
} private int findClosest ( double target ) { 
double useValue = Double . MIN_VALUE ; 
double coord = axis . getCoordMidpoint ( i ) ; 
double diff = Math . abs ( coord - target ) ; 
if ( diff < minDiff || ( diff == minDiff && coord > useValue ) ) { 
useValue = coord ; 
} public Optional < CoverageCoordAxisBuilder > subset ( double minValue , double maxValue , int stride ) { 
return subsetValues ( minValue , maxValue , stride ) ; 
} private Optional < CoverageCoordAxisBuilder > subsetValues ( double minValue , double maxValue , int stride ) { 
if ( axis . getSpacing ( ) == CoverageCoordAxis . Spacing . discontiguousInterval ) 
return subsetValuesDiscontinuous ( minValue , maxValue , stride ) ; 
double lower = axis . isAscending ( ) ? Math . min ( minValue , maxValue ) : Math . max ( minValue , maxValue ) ; 
double upper = axis . isAscending ( ) ? Math . max ( minValue , maxValue ) : Math . min ( minValue , maxValue ) ; 
int minIndex = findCoordElement ( lower , false ) ; 
int maxIndex = findCoordElement ( upper , false ) ; 
if ( minIndex >= axis . getNcoords ( ) ) 
if ( maxIndex < 0 ) 
if ( minIndex < 0 ) 
minIndex = 0 ; 
if ( maxIndex >= axis . getNcoords ( ) ) 
maxIndex = axis . getNcoords ( ) - 1 ; 
int count = maxIndex - minIndex + 1 ; 
if ( count <= 0 ) 
return Optional . of ( subsetByIndex ( new Range ( minIndex , maxIndex , stride ) ) ) ; 
return Optional . empty ( e . getMessage ( ) ) ; 
} @ Nonnull 
CoverageCoordAxisBuilder subsetByIndex ( Range range ) throws InvalidRangeException { 
int ncoords = range . length ( ) ; 
if ( range . last ( ) >= axis . getNcoords ( ) ) 
double resolution = 0.0 ; 
int count2 = 0 ; 
double [ ] subsetValues = null ; 
case regularPoint : 
resolution = range . stride ( ) * axis . getResolution ( ) ; 
case irregularPoint : 
subsetValues = new double [ ncoords ] ; 
for ( int i : range ) 
subsetValues [ count2 ++ ] = values [ i ] ; 
subsetValues = new double [ ncoords + 1 ] ; 
subsetValues [ count2 ] = values [ range . last ( ) + 1 ] ; 
subsetValues = new double [ 2 * ncoords ] ; 
for ( int i : range ) { 
subsetValues [ count2 ++ ] = values [ 2 * i ] ; 
subsetValues [ count2 ++ ] = values [ 2 * i + 1 ] ; 
CoverageCoordAxisBuilder builder = new CoverageCoordAxisBuilder ( axis ) ; 
builder . subset ( ncoords , axis . getCoordMidpoint ( range . first ( ) ) , axis . getCoordMidpoint ( range . last ( ) ) , resolution , subsetValues ) ; 
builder . setRange ( range ) ; 
public void destroy ( ) { 
if ( cdmDiskCacheTimer != null ) 
cdmDiskCacheTimer . cancel ( ) ; 
FileCache . shutdown ( ) ; 
DiskCache2 . exit ( ) ; 
thredds . inventory . bdb . MetadataManager . closeAll ( ) ; 
executor . shutdownNow ( ) ; 
RandomAccessFile . shutdown ( ) ; 
NetcdfDataset . shutdown ( ) ; 
GribCdmIndex . shutdown ( ) ; 
datasetManager . setDatasetTracker ( null ) ; 
collectionUpdater . shutdown ( ) ; 
MDC . clear ( ) ; 
} void writeNetcdf ( NetcdfOutputChooser . Data data ) { 
if ( data . version == NetcdfFileWriter . Version . ncstream ) { 
writeNcstream ( data . outputFilename ) ; 
FileWriter2 writer = new FileWriter2 ( ds , data . outputFilename , data . version , 
Nc4ChunkingStrategy . factory ( data . chunkerType , data . deflate , data . shuffle ) ) ; 
NetcdfFile result = writer . write ( ) ; 
} private void showDeclaration ( BeanTable from , boolean isNcml ) { 
Variable v = getCurrentVariable ( from ) ; 
if ( v == null ) return ; 
infoTA . clear ( ) ; 
if ( isNcml ) { 
ncmlWriter . setNamespace ( null ) ; 
ncmlWriter . getXmlFormat ( ) . setOmitDeclaration ( true ) ; 
Element varElement = ncmlWriter . makeVariableElement ( v , false ) ; 
infoTA . appendLine ( ncmlWriter . writeToString ( varElement ) ) ; 
infoTA . appendLine ( v . toString ( ) ) ; 
if ( Debug . isSet ( "Xdeveloper" ) ) { 
infoTA . appendLine ( "\n" ) ; 
infoTA . appendLine ( v . toStringDebug ( ) ) ; 
infoTA . gotoTop ( ) ; 
} private void dataTable ( BeanTable from ) { 
VariableBean vb = ( VariableBean ) from . getSelectedBean ( ) ; 
if ( vb == null ) return ; 
Variable v = vb . vs ; 
dataTable . setStructure ( ( Structure ) v ) ; 
dataWindow . setComponent ( dataTable ) ; 
List < VariableBean > l = from . getSelectedBeans ( ) ; 
List < Variable > vl = new ArrayList < > ( ) ; 
for ( VariableBean vb1 : l ) { 
if ( vb1 == null ) return ; 
v = vb1 . vs ; 
vl . add ( v ) ; 
else return ; 
variableTable . setDataset ( ds ) ; 
variableTable . setVariableList ( vl ) ; 
variableTable . createTable ( ) ; 
dataWindow . setComponent ( variableTable ) ; 
Rectangle r = ( Rectangle ) prefs . getBean ( "dataWindowBounds" , new Rectangle ( 50 , 300 , 1000 , 1200 ) ) ; 
dataWindow . setBounds ( r ) ; 
dataWindow . show ( ) ; 
} private void doGribIndex ( Formatter f , MCollection dcm , boolean eachFile ) throws IOException { 
Counters counters = new Counters ( ) ; 
try ( MCollection dcm2 = getCollectionUnfiltered ( spec , f ) ) { 
for ( MFile mfile : dcm2 . getFilesSorted ( ) ) { 
doGribIndex ( f , mfile , counters , eachFile ) ; 
counters . show ( f ) ; 
} private void doCheckLocalParams ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
doCheckLocalParams ( mfile , f , accum ) ; 
} private void doCheckTables ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
if ( useIndex ) 
doCheckTablesWithIndex ( f , mfile , counters ) ; 
doCheckTablesNoIndex ( f , mfile , counters ) ; 
} private void doScanIssues ( Formatter f , MCollection dcm , boolean useIndex , boolean eachFile , boolean extraInfo ) throws IOException { 
Counters countersAll = new Counters ( ) ; 
Counters countersOneFile = countersAll . makeSubCounters ( ) ; 
doScanIssuesWithIndex ( f , mfile , extraInfo , countersOneFile ) ; 
doScanIssuesNoIndex ( f , mfile , extraInfo , countersOneFile ) ; 
if ( eachFile ) { 
countersOneFile . show ( f ) ; 
countersAll . addTo ( countersOneFile ) ; 
countersAll . show ( f ) ; 
} private void doShowEncoding ( Formatter f , MCollection dcm ) throws IOException { 
doShowEncodingNoIndex ( f , mfile , countersAll ) ; 
} private void doUniqueGds ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
Map < Integer , GdsList > gdsSet = new HashMap < > ( ) ; 
doUniqueGds ( mfile , gdsSet , f ) ; 
List < GdsList > sorted = new ArrayList < > ( gdsSet . values ( ) ) ; 
Collections . sort ( sorted ) ; 
for ( GdsList gdsl : sorted ) { 
for ( FileCount fc : gdsl . fileList ) { 
} public DataFactory . Result openFeatureDataset ( String urlString , ucar . nc2 . util . CancelTask task ) throws IOException { 
DataFactory . Result result = new DataFactory . Result ( ) ; 
Dataset dataset = openCatalogFromLocation ( urlString , task , result ) ; 
if ( result . fatalError || dataset == null ) 
return openFeatureDataset ( null , dataset , task , result ) ; 
public DataFactory . Result openFeatureDataset ( Dataset Dataset , ucar . nc2 . util . CancelTask task ) throws IOException { 
return openFeatureDataset ( null , Dataset , task , new Result ( ) ) ; 
} public DataFactory . Result openFeatureDataset ( Access access , ucar . nc2 . util . CancelTask task ) throws IOException { 
Dataset ds = access . getDataset ( ) ; 
DataFactory . Result result = new Result ( ) ; 
if ( ds . getFeatureType ( ) == null ) { 
result . fatalError = true ; 
return openFeatureDataset ( ds . getFeatureType ( ) , access , task , result ) ; 
} public NetcdfDataset openDataset ( String location , boolean acquire , ucar . nc2 . util . CancelTask task , Formatter log ) throws IOException { 
Result result = new Result ( ) ; 
Dataset dataset = openCatalogFromLocation ( location , task , result ) ; 
if ( result . fatalError || dataset == null ) { 
if ( log != null ) log . format ( "%s" , result . errLog ) ; 
return openDataset ( dataset , acquire , task , result ) ; 
} public Access chooseDatasetAccess ( List < Access > accessList ) { 
if ( accessList . size ( ) == 0 ) 
Access access = null ; 
if ( preferAccess != null ) { 
for ( ServiceType type : preferAccess ) { 
access = findAccessByServiceType ( accessList , type ) ; 
if ( access != null ) break ; 
if ( access == null ) 
access = findAccessByServiceType ( accessList , ServiceType . CdmRemote ) ; 
access = findAccessByServiceType ( accessList , ServiceType . DODS ) ; 
access = findAccessByServiceType ( accessList , ServiceType . OPENDAP ) ; 
access = findAccessByServiceType ( accessList , ServiceType . DAP4 ) ; 
access = findAccessByServiceType ( accessList , ServiceType . File ) ; 
access = findAccessByServiceType ( accessList , ServiceType . HTTPServer ) ; 
access = findAccessByServiceType ( accessList , ServiceType . ADDE ) ; 
if ( access == null ) { 
access = findAccessByServiceType ( accessList , ServiceType . Resolver ) ; 
return access ; 
} public static void annotate ( Dataset ds , NetcdfDataset ncDataset ) { 
ncDataset . setTitle ( ds . getName ( ) ) ; 
ncDataset . setId ( ds . getId ( ) ) ; 
for ( Property p : ds . getProperties ( ) ) { 
String name = p . getName ( ) ; 
if ( null == ncDataset . findGlobalAttribute ( name ) ) { 
ncDataset . addAttribute ( null , new Attribute ( name , p . getValue ( ) ) ) ; 
ncDataset . finish ( ) ; 
} private Access getImageAccess ( Dataset ds , ucar . nc2 . util . CancelTask task , Result result ) throws IOException { 
List < Access > accessList = new ArrayList < > ( ds . getAccess ( ) ) ; 
while ( accessList . size ( ) > 0 ) { 
Access access = chooseImageAccess ( accessList ) ; 
String datasetLocation = access . getStandardUrlName ( ) ; 
Dataset rds = openResolver ( datasetLocation , task , result ) ; 
if ( rds == null ) 
accessList = new ArrayList < > ( ds . getAccess ( ) ) ; 
} private Access findAccessByServiceType ( List < Access > accessList , ServiceType type ) { 
for ( Access a : accessList ) { 
ServiceType stype = a . getService ( ) . getType ( ) ; 
if ( stype != null && stype . toString ( ) . equalsIgnoreCase ( type . toString ( ) ) ) 
} private Access findAccessByDataFormatType ( List < Access > accessList , DataFormatType type ) { 
DataFormatType has = a . getDataFormatType ( ) ; 
if ( has != null && type . toString ( ) . equalsIgnoreCase ( has . toString ( ) ) ) 
sbuff . append ( "PointObsDataset\n" ) ; 
public ArrayStructure readStructure ( int start , int count ) throws IOException , ucar . ma2 . InvalidRangeException { 
} public float [ ] readData ( RandomAccessFile raf , GribData . InterpolationMethod method ) throws IOException { 
Grib1Gds gds = getGDS ( ) ; 
Grib1DataReader reader = new Grib1DataReader ( pdss . getDecimalScale ( ) , gds . getScanMode ( ) , gds . getNxRaw ( ) , gds . getNyRaw ( ) , gds . getNpts ( ) , dataSection . getStartingPosition ( ) ) ; 
byte [ ] bm = ( bitmap == null ) ? null : bitmap . getBitmap ( raf ) ; 
float [ ] data = reader . getData ( raf , bm ) ; 
if ( gdss . isThin ( ) ) { 
data = QuasiRegular . convertQuasiGrid ( data , gds . getNptsInLine ( ) , gds . getNxRaw ( ) , gds . getNyRaw ( ) , method ) ; 
} public static float [ ] readData ( RandomAccessFile raf , long startPos ) throws IOException { 
Grib1Record gr = new Grib1Record ( raf ) ; 
return gr . readData ( raf ) ; 
} public GribData . Info getBinaryDataInfo ( RandomAccessFile raf ) throws IOException { 
GribData . Info info = dataSection . getBinaryDataInfo ( raf ) ; 
info . decimalScaleFactor = pdss . getDecimalScale ( ) ; 
info . bitmapLength = ( bitmap == null ) ? 0 : bitmap . getLength ( raf ) ; 
info . nPoints = getGDS ( ) . getNpts ( ) ; 
info . msgLength = is . getMessageLength ( ) ; 
if ( bitmap == null ) { 
info . ndataPoints = info . nPoints ; 
byte [ ] bm = bitmap . getBitmap ( raf ) ; 
if ( bm == null ) { 
info . ndataPoints = GribNumbers . countBits ( bm ) ; 
return info ; 
} public int [ ] readRawData ( RandomAccessFile raf ) throws IOException { 
return reader . getDataRaw ( raf , bm ) ; 
} private String forceChild ( String url ) 
String prefix = path ; 
if ( prefix . endsWith ( "/" ) ) 
prefix = path . substring ( 0 , path . length ( ) - 1 ) ; 
int j = url . substring ( 0 , url . length ( ) - 1 ) . lastIndexOf ( '/' ) ; 
if ( j >= 0 ) 
String ret = prefix + url . substring ( j ) ; 
assemble ( EnumSet < Parts > parts ) 
StringBuilder uri = new StringBuilder ( ) ; 
int useformat = ( parts . contains ( Parts . FORMAT ) ? 1 : 0 ) ; 
int usebase = ( parts . contains ( Parts . BASE ) ? 2 : 0 ) ; 
switch ( useformat + usebase ) { 
case 0 + 0 : 
case 1 + 0 : 
uri . append ( this . formatprotocol + ":" ) ; 
case 2 + 0 : 
uri . append ( this . baseprotocol + ":" ) ; 
case 2 + 1 : 
if ( ! this . baseprotocol . equals ( this . formatprotocol ) ) 
uri . append ( this . baseprotocol . equals ( "file" ) ? "/" : "//" ) ; 
if ( userinfo != null && parts . contains ( Parts . PWD ) ) 
uri . append ( this . userinfo + ":" ) ; 
if ( this . host != null && parts . contains ( Parts . HOST ) ) 
uri . append ( this . host ) ; 
if ( this . path != null && parts . contains ( Parts . PATH ) ) 
uri . append ( this . path ) ; 
if ( this . query != null && parts . contains ( Parts . QUERY ) ) 
uri . append ( "?" + this . query ) ; 
if ( this . frag != null && parts . contains ( Parts . FRAG ) ) 
uri . append ( "#" + this . frag ) ; 
canonical ( String s ) 
s = null ; 
if ( null == ncfile . findDimension ( "south_north" ) ) return false ; 
Attribute att = ncfile . findGlobalAttribute ( "DYN_OPT" ) ; 
if ( att != null ) { 
if ( att . getNumericValue ( ) . intValue ( ) != 2 ) return false ; 
att = ncfile . findGlobalAttribute ( "GRIDTYPE" ) ; 
if ( ! att . getStringValue ( ) . equalsIgnoreCase ( "C" ) && 
! att . getStringValue ( ) . equalsIgnoreCase ( "E" ) ) 
att = ncfile . findGlobalAttribute ( "MAP_PROJ" ) ; 
return att != null ; 
} public void augmentDataset ( NetcdfDataset ds , CancelTask cancelTask ) { 
Attribute att = ds . findGlobalAttribute ( "GRIDTYPE" ) ; 
gridE = att != null && att . getStringValue ( ) . equalsIgnoreCase ( "E" ) ; 
for ( Variable v : vlist ) { 
att = v . findAttributeIgnoreCase ( CDM . UNITS ) ; 
String units = att . getStringValue ( ) ; 
if ( units != null ) 
v . addAttribute ( new Attribute ( CDM . UNITS , normalize ( units ) ) ) ; 
att = ds . findGlobalAttribute ( "MAP_PROJ" ) ; 
boolean isLatLon = false ; 
if ( projType == 203 ) { 
Variable glat = ds . findVariable ( "GLAT" ) ; 
if ( glat == null ) { 
glat . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lat . toString ( ) ) ) ; 
if ( gridE ) glat . addAttribute ( new Attribute ( _Coordinate . Stagger , CDM . ARAKAWA_E ) ) ; 
glat . setCachedData ( convertToDegrees ( glat ) , false ) ; 
glat . addAttribute ( new Attribute ( CDM . UNITS , CDM . LAT_UNITS ) ) ; 
Variable glon = ds . findVariable ( "GLON" ) ; 
if ( glon == null ) { 
glon . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lon . toString ( ) ) ) ; 
if ( gridE ) glon . addAttribute ( new Attribute ( _Coordinate . Stagger , CDM . ARAKAWA_E ) ) ; 
glon . setCachedData ( convertToDegrees ( glon ) , false ) ; 
glon . addAttribute ( new Attribute ( CDM . UNITS , CDM . LON_UNITS ) ) ; 
VariableDS v = new VariableDS ( ds , null , null , "LatLonCoordSys" , DataType . CHAR , "" , null , null ) ; 
Variable dataVar = ds . findVariable ( "LANDMASK" ) ; 
dataVar . addAttribute ( new Attribute ( _Coordinate . Systems , "LatLonCoordSys" ) ) ; 
double lat1 = findAttributeDouble ( ds , "TRUELAT1" ) ; 
double lat2 = findAttributeDouble ( ds , "TRUELAT2" ) ; 
double centralLat = findAttributeDouble ( ds , "CEN_LAT" ) ; 
double centralLon = findAttributeDouble ( ds , "CEN_LON" ) ; 
double standardLon = findAttributeDouble ( ds , "STAND_LON" ) ; 
double standardLat = findAttributeDouble ( ds , "MOAD_CEN_LAT" ) ; 
ProjectionImpl proj = null ; 
proj = new FlatEarth ( ) ; 
projCT = new ProjectionCT ( "flat_earth" , "FGDC" , proj ) ; 
proj = new LambertConformal ( standardLat , standardLon , lat1 , lat2 , 0.0 , 0.0 , 6370 ) ; 
projCT = new ProjectionCT ( "Lambert" , "FGDC" , proj ) ; 
double lon0 = ( Double . isNaN ( standardLon ) ) ? centralLon : standardLon ; 
double lat0 = ( Double . isNaN ( centralLat ) ) ? lat2 : centralLat ; 
double scaleFactor = ( 1 + Math . abs ( Math . sin ( Math . toRadians ( lat1 ) ) ) ) / 2. ; 
proj = new Stereographic ( lat0 , lon0 , scaleFactor , 0.0 , 0.0 , 6370 ) ; 
projCT = new ProjectionCT ( "Stereographic" , "FGDC" , proj ) ; 
proj = new Mercator ( standardLon , lat1 , 0.0 , 0.0 , 6370 ) ; 
projCT = new ProjectionCT ( "Mercator" , "FGDC" , proj ) ; 
isLatLon = true ; 
if ( v . getShortName ( ) . startsWith ( "XLAT" ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lat . toString ( ) ) ) ; 
removeConstantTimeDim ( ds , v ) ; 
} else if ( v . getShortName ( ) . startsWith ( "XLONG" ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lon . toString ( ) ) ) ; 
} else if ( v . getShortName ( ) . equals ( "T" ) ) { 
} else if ( v . getShortName ( ) . equals ( "U" ) ) { 
} else if ( v . getShortName ( ) . equals ( "V" ) ) { 
} else if ( v . getShortName ( ) . equals ( "W" ) ) { 
if ( proj != null ) { 
LatLonPointImpl lpt1 = new LatLonPointImpl ( centralLat , centralLon ) ; 
ProjectionPoint ppt1 = proj . latLonToProj ( lpt1 , new ProjectionPointImpl ( ) ) ; 
centerX = ppt1 . getX ( ) ; 
centerY = ppt1 . getY ( ) ; 
System . out . println ( "centerX=" + centerX ) ; 
System . out . println ( "centerY=" + centerY ) ; 
if ( ! isLatLon ) { 
ds . addCoordinateAxis ( makeXCoordAxis ( ds , "x" , ds . findDimension ( "west_east" ) ) ) ; 
ds . addCoordinateAxis ( makeXCoordAxis ( ds , "x_stag" , ds . findDimension ( "west_east_stag" ) ) ) ; 
ds . addCoordinateAxis ( makeYCoordAxis ( ds , "y" , ds . findDimension ( "south_north" ) ) ) ; 
ds . addCoordinateAxis ( makeYCoordAxis ( ds , "y_stag" , ds . findDimension ( "south_north_stag" ) ) ) ; 
ds . addCoordinateAxis ( makeZCoordAxis ( ds , "z" , ds . findDimension ( "bottom_top" ) ) ) ; 
ds . addCoordinateAxis ( makeZCoordAxis ( ds , "z_stag" , ds . findDimension ( "bottom_top_stag" ) ) ) ; 
if ( gridE ) v . addAttribute ( new Attribute ( _Coordinate . Stagger , CDM . ARAKAWA_E ) ) ; 
if ( ds . findVariable ( "Time" ) == null ) { 
CoordinateAxis taxis = makeTimeCoordAxis ( ds , "Time" , ds . findDimension ( "Time" ) ) ; 
if ( taxis == null ) 
taxis = makeTimeCoordAxis ( ds , "Time" , ds . findDimension ( "Times" ) ) ; 
if ( taxis != null ) 
ds . addCoordinateAxis ( taxis ) ; 
ds . addCoordinateAxis ( makeSoilDepthCoordAxis ( ds , "ZS" ) ) ; 
} private String normalize ( String units ) { 
switch ( units ) { 
case "fraction" : 
units = "" ; 
case "dimensionless" : 
case "NA" : 
case "-" : 
units = StringUtil2 . substitute ( units , "**" , "^" ) ; 
units = StringUtil2 . remove ( units , '}' ) ; 
units = StringUtil2 . remove ( units , '{' ) ; 
} private CoordinateAxis makeLonCoordAxis ( NetcdfDataset ds , String axisName , Dimension dim ) { 
if ( dim == null ) return null ; 
double dx = 4 * findAttributeDouble ( ds , "DX" ) ; 
int nx = dim . getLength ( ) ; 
double startx = centerX - dx * ( nx - 1 ) / 2 ; 
v . setValues ( nx , startx , dx ) ; 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , "Lon" ) ) ; 
if ( ! axisName . equals ( dim . getShortName ( ) ) ) 
v . addAttribute ( new Attribute ( _Coordinate . AliasForDimension , dim . getShortName ( ) ) ) ; 
super . assignCoordinateTransforms ( ncDataset ) ; 
List < CoordinateSystem > csys = ncDataset . getCoordinateSystems ( ) ; 
for ( CoordinateSystem cs : csys ) { 
if ( cs . getZaxis ( ) != null ) { 
String units = cs . getZaxis ( ) . getUnitsString ( ) ; 
if ( ( units == null ) || ( units . trim ( ) . length ( ) == 0 ) ) { 
VerticalCT vct = makeWRFEtaVerticalCoordinateTransform ( ncDataset , cs ) ; 
if ( vct != null ) 
cs . addCoordinateTransform ( vct ) ; 
} static public boolean dspMatch ( String path , DapContext context ) 
for ( String s : EXTENSIONS ) { 
if ( path . endsWith ( s ) ) return true ; 
} public DapDataset 
compile ( ) 
buildrootgroup ( this . ncid ) ; 
if ( this . dmr != null ) dmr . finish ( ) ; 
return this . dmr ; 
buildrootgroup ( int ncid ) 
int ret ; 
byte [ ] namep = new byte [ NC_MAX_NAME + 1 ] ; 
errcheck ( ret = nc4 . nc_inq_grpname ( ncid , namep ) ) ; 
String [ ] pieces = DapUtil . canonicalpath ( this . path ) . split ( "[/]" ) ; 
DapDataset g = factory . newDataset ( pieces [ pieces . length - 1 ] ) ; 
GroupNotes gi = ( GroupNotes ) Nc4Notes . factory ( NoteSort . GROUP , ncid , ncid , this . dsp ) ; 
gi . set ( g ) ; 
this . dsp . note ( gi ) ; 
this . dmr = g ; 
fillgroup ( ncid ) ; 
} int [ ] 
getGroups ( int gid ) 
int ret , n ; 
IntByReference ip = new IntByReference ( ) ; 
errcheck ( ret = nc4 . nc_inq_grps ( gid , ip , null ) ) ; 
n = ip . getValue ( ) ; 
int [ ] grpids = null ; 
if ( n > 0 ) { 
grpids = new int [ n ] ; 
errcheck ( ret = nc4 . nc_inq_grps ( gid , ip , grpids ) ) ; 
grpids = new int [ 0 ] ; 
return grpids ; 
errcheck ( int ret ) 
if ( ret != 0 ) { 
throw new DapException ( msg ) ; 
if ( init ) return ; 
init = true ; 
if ( xlinkHref == null ) return ; 
xlinkHref = xlinkHref . trim ( ) ; 
this . xlinkUri = dataset . getParentCatalog ( ) . resolveUri ( xlinkHref ) ; 
if ( converter == null ) { 
contentObject = converter . readMetadataContentFromURL ( dataset , xlinkUri ) ; 
if ( isThreddsMetadata ) 
tm = ( ThreddsMetadata ) contentObject ; 
} public synchronized Object get ( Object key ) { 
int index = keys . indexOf ( key ) ; 
if ( index != - 1 ) 
return elements . elementAt ( index ) ; 
} public synchronized Object put ( Object key , Object value ) throws NullPointerException { 
if ( key == null || value == null ) 
throw new NullPointerException ( ) ; 
if ( index != - 1 ) { 
Object prev = elements . elementAt ( index ) ; 
elements . setElementAt ( value , index ) ; 
return prev ; 
keys . addElement ( key ) ; 
elements . addElement ( value ) ; 
} public synchronized Object remove ( Object key ) { 
keys . removeElementAt ( index ) ; 
elements . removeElementAt ( index ) ; 
calendar . set ( Calendar . YEAR , year ) ; 
calendar . set ( Calendar . MONTH , month - 1 ) ; 
calendar . set ( Calendar . DAY_OF_MONTH , day ) ; 
calendar . set ( Calendar . HOUR_OF_DAY , hour ) ; 
calendar . set ( Calendar . MINUTE , minute ) ; 
assert ( this . ce != null ) ; 
printNode ( dmr ) ; 
printNode ( DapNode node ) 
if ( node == null ) 
DapSort sort = node . getSort ( ) ; 
String dmrname = sort . getName ( ) ; 
if ( ! this . ce . references ( node ) ) break ; 
printer . marginPrint ( "<" + dmrname ) ; 
int flags = ( sort == DapSort . DATASET ? PERLINE : NILFLAGS ) ; 
printXMLAttributes ( node , ce , flags ) ; 
printer . println ( ">" ) ; 
if ( group . getDimensions ( ) . size ( ) > 0 ) { 
for ( DapNode subnode : group . getDimensions ( ) ) { 
if ( ! this . ce . references ( subnode ) ) continue ; 
printNode ( subnode ) ; 
if ( group . getEnums ( ) . size ( ) > 0 ) { 
for ( DapNode subnode : group . getEnums ( ) ) { 
if ( group . getVariables ( ) . size ( ) > 0 ) 
for ( DapNode subnode : group . getVariables ( ) ) { 
printMetadata ( node ) ; 
if ( group . getGroups ( ) . size ( ) > 0 ) 
for ( DapNode subnode : group . getGroups ( ) ) { 
printer . marginPrint ( "</" + dmrname + ">" ) ; 
DapDimension dim = ( DapDimension ) node ; 
if ( ! dim . isShared ( ) ) break ; 
printXMLAttributes ( node , ce , NILFLAGS ) ; 
printXMLAttribute ( AbstractDSP . UCARTAGUNLIMITED , "1" , NILFLAGS ) ; 
if ( hasMetadata ( node ) ) { 
printer . print ( "/>" ) ; 
DapEnumeration en = ( DapEnumeration ) node ; 
printXMLAttributes ( en , ce , NILFLAGS ) ; 
List < String > econstnames = en . getNames ( ) ; 
for ( String econst : econstnames ) { 
DapEnumConst value = en . lookup ( econst ) ; 
assert ( value != null ) ; 
printer . marginPrintln ( 
Escape . entityEscape ( econst , null ) , value . getValue ( ) ) ) ; 
DapVariable var = ( DapVariable ) node ; 
DapType type = var . getBaseType ( ) ; 
printer . marginPrint ( "<" + type . getTypeSort ( ) . name ( ) ) ; 
if ( type . isAtomic ( ) ) { 
if ( ( hasMetadata ( node ) || hasDimensions ( var ) || hasMaps ( var ) ) ) { 
if ( hasDimensions ( var ) ) 
printDimrefs ( var ) ; 
if ( hasMetadata ( var ) ) 
printMetadata ( var ) ; 
if ( hasMaps ( var ) ) 
printMaps ( var ) ; 
printer . marginPrint ( "</" + type . getTypeSort ( ) . name ( ) + ">" ) ; 
} else if ( type . getTypeSort ( ) . isCompound ( ) ) { 
DapStructure struct = ( DapStructure ) type ; 
for ( DapVariable field : struct . getFields ( ) ) { 
if ( ! this . ce . references ( field ) ) continue ; 
printNode ( field ) ; 
printXMLAttributes ( DapNode node , CEConstraint ce , int flags ) 
if ( ( flags & PERLINE ) != 0 ) 
String name = node . getShortName ( ) ; 
if ( name != null && ( flags & NONAME ) == 0 ) { 
name = node . getShortName ( ) ; 
printXMLAttribute ( "name" , name , flags ) ; 
DapDataset dataset = ( DapDataset ) node ; 
printXMLAttribute ( "dapVersion" , dataset . getDapVersion ( ) , flags ) ; 
printXMLAttribute ( "dmrVersion" , dataset . getDMRVersion ( ) , flags ) ; 
printXMLAttribute ( "xmlns" , "http://xml.opendap.org/ns/DAP/4.0#" , flags ) ; 
printXMLAttribute ( "xmlns:dap" , "http://xml.opendap.org/ns/DAP/4.0#" , flags ) ; 
DapDimension orig = ( DapDimension ) node ; 
if ( orig . isShared ( ) ) { 
DapDimension actual = this . ce . getRedefDim ( orig ) ; 
if ( actual == null ) 
actual = orig ; 
long size = actual . getSize ( ) ; 
printXMLAttribute ( "size" , Long . toString ( size ) , flags ) ; 
printXMLAttribute ( "basetype" , ( ( DapEnumeration ) node ) . getBaseType ( ) . getTypeName ( ) , flags ) ; 
DapType basetype = var . getBaseType ( ) ; 
if ( basetype . isEnumType ( ) ) { 
printXMLAttribute ( "enum" , basetype . getTypeName ( ) , flags ) ; 
DapAttribute attr = ( DapAttribute ) node ; 
basetype = attr . getBaseType ( ) ; 
printXMLAttribute ( "type" , basetype . getTypeName ( ) , flags ) ; 
if ( attr . getBaseType ( ) . isEnumType ( ) ) { 
if ( ! this . testing ) 
printReserved ( node ) ; 
if ( ( flags & PERLINE ) != 0 ) { 
printXMLAttribute ( String name , String value , int flags ) 
if ( name == null ) return ; 
if ( ( flags & NONNIL ) == 0 
&& ( value == null || value . length ( ) == 0 ) ) 
printer . margin ( ) ; 
printer . print ( "\"" ) ; 
if ( ( flags & XMLESCAPED ) == 0 ) 
value = Escape . entityEscape ( value , "\"" ) ; 
printer . print ( value ) ; 
} static boolean isSpecial ( DapAttribute attr ) 
if ( attr . getParent ( ) . getSort ( ) == DapSort . DATASET ) { 
for ( String s : GROUPSPECIAL ) { 
if ( s . equals ( attr . getShortName ( ) ) ) 
} else if ( attr . getParent ( ) . getSort ( ) == DapSort . VARIABLE ) { 
for ( String s : VARSPECIAL ) { 
printDimrefs ( DapVariable var ) 
if ( var . getRank ( ) == 0 ) return ; 
List < DapDimension > dimset = this . ce . getConstrainedDimensions ( var ) ; 
assert var . getRank ( ) == dimset . size ( ) ; 
for ( int i = 0 ; i < var . getRank ( ) ; i ++ ) { 
printer . marginPrint ( "<Dim" ) ; 
String fqn = dim . getFQN ( ) ; 
fqn = fqnXMLEscape ( fqn ) ; 
printXMLAttribute ( "name" , fqn , XMLESCAPED ) ; 
long size = dim . getSize ( ) ; 
printXMLAttribute ( "size" , Long . toString ( size ) , NILFLAGS ) ; 
printer . println ( "/>" ) ; 
fqnXMLEscape ( String fqn ) 
StringBuilder xml = new StringBuilder ( ) ; 
String segment = null ; 
List < String > segments = Escape . backslashsplit ( fqn , '/' ) ; 
for ( int i = 1 ; i < segments . size ( ) - 1 ; i ++ ) { 
segment = segments . get ( i ) ; 
segment = Escape . backslashUnescape ( segment ) ; 
segment = Escape . entityEscape ( segment , "\"" ) ; 
segment = Escape . backslashEscape ( segment , "/." ) ; 
xml . append ( "/" ) ; 
xml . append ( segment ) ; 
segment = segments . get ( segments . size ( ) - 1 ) ; 
segments = Escape . backslashsplit ( segment , '.' ) ; 
for ( int i = 0 ; i < segments . size ( ) ; i ++ ) { 
if ( i > 0 ) xml . append ( "." ) ; 
return xml . toString ( ) ; 
} public boolean init ( String location , NetcdfFile ncfile ) throws AreaFileException { 
af = new AreaFile ( location ) ; 
dirBlock = af . getDir ( ) ; 
ad = af . getAreaDirectory ( ) ; 
int numElements = ad . getElements ( ) ; 
int numLines = ad . getLines ( ) ; 
int numBands = ad . getNumberOfBands ( ) ; 
bandMap = ad . getBands ( ) ; 
navBlock = af . getNav ( ) ; 
Date nomTime = ad . getNominalTime ( ) ; 
nav = AREAnav . makeAreaNav ( navBlock , af . getAux ( ) ) ; 
throw new AreaFileException ( me . getMessage ( ) ) ; 
int sensor = dirBlock [ AreaFile . AD_SENSORID ] ; 
String calName = McIDASUtil . intBitsToString ( dirBlock [ AreaFile . AD_CALTYPE ] ) ; 
int calType = getCalType ( calName ) ; 
if ( ( af . getCal ( ) != null ) 
&& CalibratorFactory . hasCalibrator ( sensor ) ) { 
calibrator = CalibratorFactory . getCalibrator ( sensor , calType , af . getCal ( ) ) ; 
} catch ( CalibratorException ce ) { 
calibrator = null ; 
calUnit = ad . getCalibrationUnitName ( ) ; 
calScale = ( 1.0f / ad . getCalibrationScaleFactor ( ) ) ; 
Dimension elements = new Dimension ( "elements" , numElements , true ) ; 
Dimension lines = new Dimension ( "lines" , numLines , true ) ; 
Dimension bands = new Dimension ( "bands" , numBands , true ) ; 
Dimension time = new Dimension ( "time" , 1 , true ) ; 
Dimension dirDim = new Dimension ( "dirSize" , AreaFile . AD_DIRSIZE , 
true ) ; 
Dimension navDim = new Dimension ( "navSize" , navBlock . length , true ) ; 
List < Dimension > image = new ArrayList < > ( ) ; 
image . add ( time ) ; 
image . add ( bands ) ; 
image . add ( lines ) ; 
image . add ( elements ) ; 
ncfile . addDimension ( null , elements ) ; 
ncfile . addDimension ( null , lines ) ; 
ncfile . addDimension ( null , bands ) ; 
ncfile . addDimension ( null , time ) ; 
ncfile . addDimension ( null , dirDim ) ; 
ncfile . addDimension ( null , navDim ) ; 
Variable timeVar = new Variable ( ncfile , null , null , "time" ) ; 
timeVar . setDataType ( DataType . INT ) ; 
timeVar . setDimensions ( "time" ) ; 
timeVar . addAttribute ( new Attribute ( CDM . UNITS , 
+ df . toDateTimeString ( nomTime ) ) ) ; 
timeVar . addAttribute ( new Attribute ( "long_name" , "time" ) ) ; 
varArray = new ArrayInt . D1 ( 1 , false ) ; 
( ( ArrayInt . D1 ) varArray ) . set ( 0 , 0 ) ; 
timeVar . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , timeVar ) ; 
Variable lineVar = new Variable ( ncfile , null , null , "lines" ) ; 
lineVar . setDataType ( DataType . INT ) ; 
lineVar . setDimensions ( "lines" ) ; 
lineVar . addAttribute ( new Attribute ( "standard_name" , 
"projection_y_coordinate" ) ) ; 
varArray = new ArrayInt . D1 ( numLines , false ) ; 
for ( int i = 0 ; i < numLines ; i ++ ) { 
int pos = nav . isFlippedLineCoordinates ( ) 
? i 
: numLines - i - 1 ; 
( ( ArrayInt . D1 ) varArray ) . set ( i , pos ) ; 
lineVar . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , lineVar ) ; 
Variable elementVar = new Variable ( ncfile , null , null , "elements" ) ; 
elementVar . setDataType ( DataType . INT ) ; 
elementVar . setDimensions ( "elements" ) ; 
elementVar . addAttribute ( new Attribute ( "standard_name" , 
"projection_x_coordinate" ) ) ; 
varArray = new ArrayInt . D1 ( numElements , false ) ; 
for ( int i = 0 ; i < numElements ; i ++ ) { 
( ( ArrayInt . D1 ) varArray ) . set ( i , i ) ; 
elementVar . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , elementVar ) ; 
Variable bandVar = new Variable ( ncfile , null , null , "bands" ) ; 
bandVar . setDataType ( DataType . INT ) ; 
bandVar . setDimensions ( "bands" ) ; 
bandVar . addAttribute ( new Attribute ( "long_name" , 
bandVar . addAttribute ( new Attribute ( "axis" , "Z" ) ) ; 
Array bandArray = new ArrayInt . D1 ( numBands , false ) ; 
for ( int i = 0 ; i < numBands ; i ++ ) { 
( ( ArrayInt . D1 ) bandArray ) . set ( i , bandMap [ i ] ) ; 
bandVar . setCachedData ( bandArray , false ) ; 
ncfile . addVariable ( null , bandVar ) ; 
Variable imageVar = new Variable ( ncfile , null , null , "image" ) ; 
imageVar . setDataType ( DataType . INT ) ; 
imageVar . setDimensions ( image ) ; 
setCalTypeAttributes ( imageVar , getCalType ( calName ) ) ; 
imageVar . addAttribute ( new Attribute ( getADDescription ( AreaFile . AD_CALTYPE ) , 
calName ) ) ; 
imageVar . addAttribute ( new Attribute ( "bands" , bandArray ) ) ; 
imageVar . addAttribute ( new Attribute ( "grid_mapping" , "AREAnav" ) ) ; 
ncfile . addVariable ( null , imageVar ) ; 
Variable dirVar = new Variable ( ncfile , null , null , "areaDirectory" ) ; 
dirVar . setDataType ( DataType . INT ) ; 
dirVar . setDimensions ( "dirSize" ) ; 
setAreaDirectoryAttributes ( dirVar ) ; 
ArrayInt . D1 dirArray = new ArrayInt . D1 ( AreaFile . AD_DIRSIZE , false ) ; 
for ( int i = 0 ; i < AreaFile . AD_DIRSIZE ; i ++ ) { 
dirArray . set ( i , dirBlock [ i ] ) ; 
dirVar . setCachedData ( dirArray , false ) ; 
ncfile . addVariable ( null , dirVar ) ; 
Variable navVar = new Variable ( ncfile , null , null , "navBlock" ) ; 
navVar . setDataType ( DataType . INT ) ; 
navVar . setDimensions ( "navSize" ) ; 
setNavBlockAttributes ( navVar ) ; 
ArrayInt . D1 navArray = new ArrayInt . D1 ( navBlock . length , false ) ; 
for ( int i = 0 ; i < navBlock . length ; i ++ ) { 
navArray . set ( i , navBlock [ i ] ) ; 
navVar . setCachedData ( navArray , false ) ; 
ncfile . addVariable ( null , navVar ) ; 
ProjectionImpl projection = new McIDASAreaProjection ( af ) ; 
Variable proj = new Variable ( ncfile , null , null , "AREAnav" ) ; 
proj . setDataType ( DataType . CHAR ) ; 
proj . setDimensions ( "" ) ; 
for ( Parameter p : projection . getProjectionParameters ( ) ) { 
proj . addAttribute ( new Attribute ( p ) ) ; 
proj . addAttribute ( new Attribute ( "grid_mapping_name" , McIDASAreaProjection . GRID_MAPPING_NAME ) ) ; 
varArray = new ArrayChar . D0 ( ) ; 
proj . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , proj ) ; 
ncfile . addAttribute ( null , new Attribute ( "Conventions" , "CF-1.0" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( CF . FEATURE_TYPE , FeatureType . GRID . toString ( ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "nominal_image_time" , df . toDateTimeString ( nomTime ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "history" , encStr ) ) ; 
} public static boolean isValidFile ( RandomAccessFile raf ) { 
String fileName = raf . getLocation ( ) ; 
AreaFile af = null ; 
af = new AreaFile ( fileName ) ; 
} catch ( AreaFileException e ) { 
if ( af != null ) af . close ( ) ; 
} public Array readVariable ( Variable v2 , Section section ) throws IOException , InvalidRangeException { 
Range bandRange = null ; 
Range geoXRange = null ; 
Range geoYRange = null ; 
if ( section == null ) { 
dataArray = Array . factory ( v2 . getDataType ( ) , v2 . getShape ( ) ) ; 
} else if ( section . getRank ( ) > 0 ) { 
if ( section . getRank ( ) > 3 ) { 
bandRange = section . getRange ( 1 ) ; 
geoYRange = section . getRange ( 2 ) ; 
geoXRange = section . getRange ( 3 ) ; 
} else if ( section . getRank ( ) > 2 ) { 
geoYRange = section . getRange ( 1 ) ; 
geoXRange = section . getRange ( 2 ) ; 
} else if ( section . getRank ( ) > 1 ) { 
geoYRange = section . getRange ( 0 ) ; 
geoXRange = section . getRange ( 1 ) ; 
dataArray = Array . factory ( v2 . getDataType ( ) , section . getShape ( ) ) ; 
String strRank = Integer . toString ( section . getRank ( ) ) ; 
throw new IndexOutOfBoundsException ( msg ) ; 
String varname = v2 . getFullName ( ) ; 
Index dataIndex = dataArray . getIndex ( ) ; 
if ( varname . equals ( "latitude" ) || varname . equals ( "longitude" ) ) { 
double [ ] [ ] pixel = new double [ 2 ] [ 1 ] ; 
double [ ] [ ] latLon ; 
assert geoXRange != null ; 
assert geoYRange != null ; 
for ( int i = 0 ; i < geoXRange . length ( ) ; i ++ ) { 
for ( int j = 0 ; j < geoYRange . length ( ) ; j ++ ) { 
pixel [ 0 ] [ 0 ] = ( double ) geoXRange . element ( i ) ; 
pixel [ 1 ] [ 0 ] = ( double ) geoYRange . element ( j ) ; 
latLon = nav . toLatLon ( pixel ) ; 
if ( varname . equals ( "lat" ) ) { 
dataArray . setFloat ( dataIndex . set ( j , i ) , ( float ) ( latLon [ 0 ] [ 0 ] ) ) ; 
dataArray . setFloat ( dataIndex . set ( j , i ) , ( float ) ( latLon [ 1 ] [ 0 ] ) ) ; 
if ( varname . equals ( "image" ) ) { 
int [ ] [ ] pixelData ; 
if ( bandRange != null ) { 
for ( int k = 0 ; k < bandRange . length ( ) ; k ++ ) { 
int bandIndex = bandRange . element ( k ) + 1 ; 
pixelData = af . getData ( geoYRange . element ( j ) , 
geoXRange . element ( i ) , 1 , 1 , 
bandIndex ) ; 
dataArray . setInt ( dataIndex . set ( 0 , k , j , i ) , 
( pixelData [ 0 ] [ 0 ] ) ) ; 
geoXRange . element ( i ) , 1 , 1 ) ; 
dataArray . setInt ( dataIndex . set ( 0 , j , i ) , 
} catch ( AreaFileException afe ) { 
throw new IOException ( afe . toString ( ) ) ; 
} private void setAreaDirectoryAttributes ( Variable v ) { 
if ( ( dirBlock == null ) || ( ad == null ) ) { 
for ( int i = 1 ; i < 14 ; i ++ ) { 
if ( i == 7 ) { 
v . addAttribute ( new Attribute ( getADDescription ( i ) , dirBlock [ i ] ) ) ; 
} private void setNavBlockAttributes ( Variable v ) { 
if ( ( navBlock == null ) || ( ad == null ) ) { 
"navigation_type" , McIDASUtil . intBitsToString ( navBlock [ 0 ] ) ) ) ; 
} private String getADDescription ( int index ) { 
String desc = "dir(" + index + ")" ; 
switch ( index ) { 
case AreaFile . AD_STATUS : 
case AreaFile . AD_VERSION : 
case AreaFile . AD_SENSORID : 
case AreaFile . AD_IMGDATE : 
case AreaFile . AD_IMGTIME : 
case AreaFile . AD_STLINE : 
case AreaFile . AD_STELEM : 
case AreaFile . AD_NUMLINES : 
case AreaFile . AD_NUMELEMS : 
case AreaFile . AD_DATAWIDTH : 
case AreaFile . AD_LINERES : 
case AreaFile . AD_ELEMRES : 
case AreaFile . AD_NUMBANDS : 
case AreaFile . AD_PFXSIZE : 
case AreaFile . AD_PROJNUM : 
case AreaFile . AD_CRDATE : 
case AreaFile . AD_CRTIME : 
case AreaFile . AD_BANDMAP : 
case AreaFile . AD_DATAOFFSET : 
case AreaFile . AD_NAVOFFSET : 
case AreaFile . AD_VALCODE : 
case AreaFile . AD_STARTDATE : 
case AreaFile . AD_STARTTIME : 
case AreaFile . AD_STARTSCAN : 
case AreaFile . AD_DOCLENGTH : 
case AreaFile . AD_CALLENGTH : 
case AreaFile . AD_LEVLENGTH : 
case AreaFile . AD_SRCTYPE : 
case AreaFile . AD_CALTYPE : 
case AreaFile . AD_SRCTYPEORIG : 
case AreaFile . AD_CALTYPEUNIT : 
case AreaFile . AD_CALTYPESCALE : 
case AreaFile . AD_AUXOFFSET : 
case AreaFile . AD_CALOFFSET : 
case AreaFile . AD_NUMCOMMENTS : 
desc = desc . replaceAll ( "\\s" , "_" ) ; 
return desc ; 
} private int getCalType ( String calName ) { 
int calTypeOut = Calibrator . CAL_NONE ; 
if ( calName . trim ( ) . equals ( "ALB" ) ) { 
calTypeOut = Calibrator . CAL_ALB ; 
} else if ( calName . trim ( ) . equals ( "BRIT" ) ) { 
calTypeOut = Calibrator . CAL_BRIT ; 
} else if ( calName . trim ( ) . equals ( "RAD" ) ) { 
calTypeOut = Calibrator . CAL_RAD ; 
} else if ( calName . trim ( ) . equals ( "RAW" ) ) { 
calTypeOut = Calibrator . CAL_RAW ; 
} else if ( calName . trim ( ) . equals ( "TEMP" ) ) { 
calTypeOut = Calibrator . CAL_TEMP ; 
return calTypeOut ; 
} private void setCalTypeAttributes ( Variable image , int calType ) { 
switch ( calType ) { 
case Calibrator . CAL_ALB : 
longName = "albedo" ; 
case Calibrator . CAL_BRIT : 
case Calibrator . CAL_TEMP : 
longName = "temperature" ; 
case Calibrator . CAL_RAD : 
case Calibrator . CAL_RAW : 
image . addAttribute ( new Attribute ( "long_name" , longName ) ) ; 
if ( calUnit != null ) { 
image . addAttribute ( new Attribute ( CDM . UNITS , calUnit ) ) ; 
if ( calScale != 1.f ) { 
image . addAttribute ( new Attribute ( "scale_factor" , calScale ) ) ; 
} static public void findCoords ( TableConfig nt , NetcdfDataset ds , Predicate p ) { 
nt . lat = findCoordShortNameByType ( ds , AxisType . Lat , p ) ; 
nt . lon = findCoordShortNameByType ( ds , AxisType . Lon , p ) ; 
nt . time = findCoordShortNameByType ( ds , AxisType . Time , p ) ; 
nt . elev = findCoordShortNameByType ( ds , AxisType . Height , p ) ; 
if ( nt . elev == null ) 
nt . elev = findCoordShortNameByType ( ds , AxisType . Pressure , p ) ; 
} static public String findCoordNameByType ( NetcdfDataset ds , AxisType atype ) { 
CoordinateAxis coordAxis = findCoordByType ( ds , atype ) ; 
return coordAxis == null ? null : coordAxis . getFullName ( ) ; 
} static public CoordinateAxis findCoordByType ( NetcdfDataset ds , AxisType atype ) { 
return findCoordByType ( ds , atype , null ) ; 
} static public CoordinateAxis findCoordByType ( NetcdfDataset ds , AxisType atype , Predicate p ) { 
CoordinateSystem use = findBestCoordinateSystem ( ds ) ; 
if ( use == null ) return null ; 
CoordinateAxis result = findCoordByType ( use . getCoordinateAxes ( ) , atype , p ) ; 
return findCoordByType ( ds . getCoordinateAxes ( ) , atype , p ) ; 
} static public Dimension findDimensionByType ( NetcdfDataset ds , AxisType atype ) { 
CoordinateAxis axis = findCoordByType ( ds , atype ) ; 
if ( axis == null ) return null ; 
if ( axis . isScalar ( ) ) return null ; 
return axis . getDimension ( 0 ) ; 
} static private CoordinateSystem findBestCoordinateSystem ( NetcdfDataset ds ) { 
CoordinateSystem use = null ; 
for ( CoordinateSystem cs : ds . getCoordinateSystems ( ) ) { 
if ( use == null ) use = cs ; 
else if ( cs . getCoordinateAxes ( ) . size ( ) > use . getCoordinateAxes ( ) . size ( ) ) 
use = cs ; 
return use ; 
} private CoverageCoordAxis1D findDependent ( CoverageCoordAxis independentAxis , AxisType axisType ) { 
for ( CoverageCoordAxis axis : axes ) { 
if ( axis . getDependenceType ( ) == CoverageCoordAxis . DependenceType . dependent ) { 
for ( String axisName : axis . dependsOn ) { 
if ( axisName . equalsIgnoreCase ( independentAxis . getName ( ) ) && axis . getAxisType ( ) == axisType ) 
return ( CoverageCoordAxis1D ) axis ; 
super . setProject ( state , all ) ; 
if ( all ) 
for ( Enumeration e = vars . elements ( ) ; e . hasMoreElements ( ) ; ) { 
sm . setProject ( state , all ) ; 
} public Vector getRowVector ( ) throws NoSuchVariableException { 
if ( getRowCount ( ) == 0 ) { 
Vector rv = new Vector ( ) ; 
for ( int i = 0 ; i < elementCount ( false ) ; i ++ ) { 
rv . add ( getVar ( i ) ) ; 
addRow ( rv ) ; 
return ( getRow ( 0 ) ) ; 
if ( constrained && ! isProject ( ) ) 
super . printDecl ( os , space , print_semi , constrained ) ; 
Vector v = getRowVector ( ) ; 
for ( Enumeration e2 = v . elements ( ) ; e2 . hasMoreElements ( ) ; ) { 
BaseType bt = ( BaseType ) e2 . nextElement ( ) ; 
if ( ( ( ServerMethods ) bt ) . isProject ( ) ) { 
if ( ! firstPass ) 
bt . printVal ( os , "" , false ) ; 
for ( Enumeration e = varTemplate . elements ( ) ; e . hasMoreElements ( ) ; ) { 
} public void setAllReadFlags ( boolean state ) { 
ReadMe = state ; 
sm . setRead ( state ) ; 
boolean moreToRead = true ; 
while ( moreToRead ) { 
if ( ! isRead ( ) ) { 
moreToRead = read ( dataset , specialO ) ; 
writeMarker ( sink , START_OF_INSTANCE ) ; 
if ( sm . isProject ( ) ) { 
if ( moreToRead ) 
setAllReadFlags ( false ) ; 
writeMarker ( sink , END_OF_SEQUENCE ) ; 
} public void addVariable ( BaseType v , int part ) { 
varTemplate . addElement ( v ) ; 
if ( v instanceof DSequence ) 
( ( DSequence ) v ) . setLevel ( getLevel ( ) + 1 ) ; 
} public BaseType getVariable ( String name ) throws NoSuchVariableException { 
int dotIndex = name . indexOf ( '.' ) ; 
if ( dotIndex != - 1 ) { 
String aggregate = name . substring ( 0 , dotIndex ) ; 
String field = name . substring ( dotIndex + 1 ) ; 
BaseType aggRef = getVariable ( aggregate ) ; 
if ( aggRef instanceof DConstructor ) 
return ( ( DConstructor ) aggRef ) . getVariable ( field ) ; 
BaseType v = ( BaseType ) e . nextElement ( ) ; 
if ( v . getEncodedName ( ) . equals ( name ) ) 
} public BaseType getVar ( int index ) 
throws NoSuchVariableException { 
if ( index < varTemplate . size ( ) ) 
return ( ( BaseType ) varTemplate . elementAt ( index ) ) ; 
} public BaseType getVariable ( int row , String name ) throws NoSuchVariableException { 
Vector selectedRow = ( Vector ) allValues . elementAt ( row ) ; 
for ( Enumeration e = selectedRow . elements ( ) ; e . hasMoreElements ( ) ; ) { 
} public void checkSemantics ( boolean all ) 
throws BadSemanticsException { 
super . checkSemantics ( all ) ; 
Util . uniqueNames ( varTemplate , getEncodedName ( ) , getTypeName ( ) ) ; 
bt . checkSemantics ( true ) ; 
for ( Enumeration e1 = allValues . elements ( ) ; e1 . hasMoreElements ( ) ; ) { 
Vector v = ( Vector ) e1 . nextElement ( ) ; 
if ( e2 . hasMoreElements ( ) ) 
if ( e1 . hasMoreElements ( ) ) 
throws IOException , DataReadException { 
if ( sv != null && ( sv . getMajor ( ) < 2 || ( sv . getMajor ( ) == 2 && sv . getMinor ( ) < 15 ) ) ) { 
oldDeserialize ( source , sv , statusUI ) ; 
byte marker = readMarker ( source ) ; 
if ( marker == START_OF_INSTANCE ) 
deserializeSingle ( source , sv , statusUI ) ; 
else if ( marker == END_OF_SEQUENCE ) 
} private void oldDeserialize ( DataInputStream source , ServerVersion sv , 
catch ( EOFException e ) { 
} private void deserializeSingle ( DataInputStream source , ServerVersion sv , 
Vector newInstance = new Vector ( ) ; 
for ( int i = 0 ; i < varTemplate . size ( ) ; i ++ ) { 
BaseType bt = ( BaseType ) varTemplate . elementAt ( i ) ; 
newInstance . addElement ( bt . clone ( ) ) ; 
for ( Enumeration e = newInstance . elements ( ) ; e . hasMoreElements ( ) ; ) { 
if ( statusUI != null && statusUI . userCancelled ( ) ) 
ClientIO bt = ( ClientIO ) e . nextElement ( ) ; 
bt . deserialize ( source , sv , statusUI ) ; 
allValues . addElement ( newInstance ) ; 
} private byte readMarker ( DataInputStream source ) throws IOException { 
byte marker = source . readByte ( ) ; 
for ( int i = 0 ; i < 3 ; i ++ ) 
return marker ; 
} protected void writeMarker ( DataOutputStream sink , byte marker ) throws IOException { 
sink . writeByte ( marker ) ; 
sink . writeByte ( ( byte ) 0 ) ; 
for ( int i = 0 ; i < allValues . size ( ) ; i ++ ) { 
Vector rowVec = ( Vector ) allValues . elementAt ( i ) ; 
for ( int j = 0 ; j < rowVec . size ( ) ; j ++ ) { 
ClientIO bt = ( ClientIO ) rowVec . elementAt ( j ) ; 
bt . externalize ( sink ) ; 
DSequence s = ( DSequence ) super . cloneDAG ( map ) ; 
s . varTemplate = new Vector ( ) ; 
BaseType btclone = ( BaseType ) cloneDAG ( map , bt ) ; 
s . varTemplate . addElement ( btclone ) ; 
s . allValues = new Vector ( ) ; 
Vector newVec = new Vector ( ) ; 
BaseType bt = ( BaseType ) rowVec . elementAt ( j ) ; 
newVec . addElement ( ( BaseType ) cloneDAG ( map , bt ) ) ; 
s . allValues . addElement ( newVec ) ; 
} public boolean parse ( String document ) 
throws SAXException 
StringBuilder doc = new StringBuilder ( document . trim ( ) ) ; 
int index = doc . indexOf ( "<?xml" ) ; 
if ( index == 0 ) { 
index = doc . indexOf ( "?>" ) ; 
if ( index < 0 ) 
doc . delete ( 0 , index + 2 ) ; 
while ( doc . length ( ) > 0 && "\r\n" . indexOf ( doc . charAt ( 0 ) ) >= 0 ) 
doc . deleteCharAt ( 0 ) ; 
document = doc . toString ( ) ; 
this . document = document ; 
spf = SAXParserFactory . newInstance ( ) ; 
spf . setValidating ( false ) ; 
spf . setNamespaceAware ( true ) ; 
spf . setFeature ( LOAD_EXTERNAL_DTD , false ) ; 
saxparser = spf . newSAXParser ( ) ; 
input = new ByteArrayInputStream ( document . getBytes ( UTF8 ) ) ; 
saxparser . parse ( input , this ) ; 
throw new SAXException ( e ) ; 
public InputSource resolveEntity ( String publicId , String systemId ) 
public void fatalError ( SAXParseException e ) 
throw new SAXParseException ( 
this . locator ) ; 
locatedEvent ( SaxEvent token ) 
yyevent ( token ) ; 
} catch ( SAXException se ) { 
throw new SAXException ( locatedError ( se . getMessage ( ) ) ) ; 
} private static TimeSeries createDataset ( String name , double base , 
RegularTimePeriod start , int count ) { 
TimeSeries series = new TimeSeries ( name , start . getClass ( ) ) ; 
RegularTimePeriod period = start ; 
double value = base ; 
series . add ( period , value ) ; 
period = period . next ( ) ; 
value = value * ( 1 + ( Math . random ( ) - 0.495 ) / 10.0 ) ; 
return series ; 
MultipleAxisChart demo = new MultipleAxisChart ( 
dataset1 ) ; 
demo . finish ( new java . awt . Dimension ( 600 , 270 ) ) ; 
frame . getContentPane ( ) . add ( demo , BorderLayout . CENTER ) ; 
frame . setSize ( 640 , 480 ) ; 
frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ) ; 
} public String [ ] getJavaArrayString ( StructureMembers . Member m ) { 
Array data = getArray ( m ) ; 
int n = m . getSize ( ) ; 
String [ ] result = new String [ n ] ; 
for ( int i = 0 ; i < result . length ; i ++ ) 
result [ i ] = ( String ) data . getObject ( i ) ; 
} else if ( m . getDataType ( ) == DataType . CHAR ) { 
ArrayChar data = ( ArrayChar ) getArray ( m ) ; 
ArrayChar . StringIterator iter = data . getStringIterator ( ) ; 
String [ ] result = new String [ iter . getNumElems ( ) ] ; 
result [ count ++ ] = iter . next ( ) ; 
} public DoradePARM [ ] getParamList ( ) { 
int paramCount = 0 ; 
for ( int i = 0 ; i < nSensors ; i ++ ) 
paramCount += myRADDs [ i ] . getNParams ( ) ; 
DoradePARM [ ] list = new DoradePARM [ paramCount ] ; 
int next = 0 ; 
for ( int i = 0 ; i < nSensors ; i ++ ) { 
int nParams = myRADDs [ i ] . getNParams ( ) ; 
System . arraycopy ( myRADDs [ i ] . getParamList ( ) , 0 , list , next , nParams ) ; 
next += nParams ; 
} private void makeMyUI ( ) { 
AbstractAction incrFontAction = new AbstractAction ( ) { 
stnRender . incrFontSize ( ) ; 
redraw ( ) ; 
AbstractAction decrFontAction = new AbstractAction ( ) { 
stnRender . decrFontSize ( ) ; 
JCheckBox declutCB = new JCheckBox ( "Declutter" , true ) ; 
declutCB . addActionListener ( e -> { 
setDeclutter ( ( ( JCheckBox ) e . getSource ( ) ) . isSelected ( ) ) ; 
AbstractAction bbAction = new AbstractAction ( ) { 
geoSelectionMode = ! geoSelectionMode ; 
np . setGeoSelectionMode ( geoSelectionMode ) ; 
bbAction . putValue ( BAMutil . STATE , geoSelectionMode ? Boolean . TRUE : Boolean . FALSE ) ; 
if ( regionSelect ) { 
minmaxPP = new PrefPanel ( null , null ) ; 
minLonField = minmaxPP . addDoubleField ( "minLon" , "minLon" , geoSelection . getMinX ( ) , nfracDig , 0 , 0 , null ) ; 
maxLonField = minmaxPP . addDoubleField ( "maxLon" , "maxLon" , geoSelection . getMaxX ( ) , nfracDig , 2 , 0 , null ) ; 
minLatField = minmaxPP . addDoubleField ( "minLat" , "minLat" , geoSelection . getMinY ( ) , nfracDig , 4 , 0 , null ) ; 
maxLatField = minmaxPP . addDoubleField ( "maxLat" , "maxLat" , geoSelection . getMaxY ( ) , nfracDig , 6 , 0 , null ) ; 
minmaxPP . finish ( true , BorderLayout . EAST ) ; 
minmaxPP . addActionListener ( e -> { 
double minLon = minLonField . getDouble ( ) ; 
double minLat = minLatField . getDouble ( ) ; 
double maxLon = maxLonField . getDouble ( ) ; 
double maxLat = maxLatField . getDouble ( ) ; 
LatLonRect llbb = new LatLonRect ( new LatLonPointImpl ( minLat , minLon ) , 
new LatLonPointImpl ( maxLat , maxLon ) ) ; 
setGeoSelection ( llbb ) ; 
setLayout ( new BorderLayout ( ) ) ; 
if ( stationSelect ) { 
BAMutil . addActionToContainer ( toolPanel , incrFontAction ) ; 
BAMutil . addActionToContainer ( toolPanel , decrFontAction ) ; 
toolPanel . add ( declutCB ) ; 
if ( regionSelect ) BAMutil . addActionToContainer ( toolPanel , bbAction ) ; 
if ( dateSelect ) BAMutil . addActionToContainer ( toolPanel , dateAction ) ; 
JPanel upperPanel = new JPanel ( new BorderLayout ( ) ) ; 
if ( regionSelect ) upperPanel . add ( minmaxPP , BorderLayout . NORTH ) ; 
upperPanel . add ( toolPanel , BorderLayout . SOUTH ) ; 
JPanel statusPanel = new JPanel ( new BorderLayout ( ) ) ; 
statusPanel . setBorder ( new EtchedBorder ( ) ) ; 
JLabel positionLabel = new JLabel ( "position" ) ; 
statusPanel . add ( positionLabel , BorderLayout . CENTER ) ; 
np . setPositionLabel ( positionLabel ) ; 
add ( upperPanel , BorderLayout . NORTH ) ; 
add ( np , BorderLayout . CENTER ) ; 
add ( statusPanel , BorderLayout . SOUTH ) ; 
} public void setStations ( java . util . List stns ) { 
stnRender . setStations ( stns ) ; 
redraw ( true ) ; 
} public void setSelectedStation ( String id ) { 
stnRender . setSelectedStation ( id ) ; 
selectedStation = stnRender . getSelectedStation ( ) ; 
assert selectedStation != null ; 
np . setLatLonCenterMapArea ( selectedStation . getLatitude ( ) , selectedStation . getLongitude ( ) ) ; 
} protected void redraw ( ) { 
java . awt . Graphics2D gNP = np . getBufferedImageGraphics ( ) ; 
if ( gNP == null ) 
gNP . setBackground ( np . getBackgroundColor ( ) ) ; 
java . awt . Rectangle r = gNP . getClipBounds ( ) ; 
gNP . clearRect ( r . x , r . y , r . width , r . height ) ; 
if ( regionSelect && geoSelectionMode ) { 
if ( geoSelection != null ) drawBB ( gNP , geoSelection , Color . cyan ) ; 
if ( geoBounds != null ) drawBB ( gNP , geoBounds , null ) ; 
if ( geoSelection != null ) { 
Navigation navigate = np . getNavigation ( ) ; 
double handleSize = RubberbandRectangleHandles . handleSizePixels / navigate . getPixPerWorld ( ) ; 
Rectangle2D rect = new Rectangle2D . Double ( geoSelection . getX ( ) , geoSelection . getY ( ) , geoSelection . getWidth ( ) , geoSelection . getHeight ( ) ) ; 
RubberbandRectangleHandles . drawHandledRect ( gNP , rect , handleSize ) ; 
for ( int i = 0 ; i < renderers . size ( ) ; i ++ ) { 
ucar . nc2 . ui . util . Renderer rend = ( Renderer ) renderers . get ( i ) ; 
rend . draw ( gNP , atI ) ; 
gNP . dispose ( ) ; 
long tend = System . currentTimeMillis ( ) ; 
np . repaint ( ) ; 
} public void setTrajectoryInfo ( Config trajConfig ) 
if ( timeDim != null ) 
this . trajectoryId = trajConfig . getTrajectoryId ( ) ; 
this . timeDim = trajConfig . getTimeDim ( ) ; 
this . timeVar = trajConfig . getTimeVar ( ) ; 
this . latVar = trajConfig . getLatVar ( ) ; 
this . lonVar = trajConfig . getLonVar ( ) ; 
this . elevVar = trajConfig . getElevVar ( ) ; 
trajectoryNumPoint = this . timeDim . getLength ( ) ; 
timeVarUnitsString = this . timeVar . findAttribute ( "units" ) . getStringValue ( ) ; 
if ( DateUnit . getStandardDate ( timeVarUnitsString ) == null ) 
String latVarUnitsString = this . latVar . findAttribute ( "units" ) . getStringValue ( ) ; 
if ( ! SimpleUnit . isCompatible ( latVarUnitsString , "degrees_north" ) ) 
String lonVarUnitsString = this . lonVar . findAttribute ( "units" ) . getStringValue ( ) ; 
if ( ! SimpleUnit . isCompatible ( lonVarUnitsString , "degrees_east" ) ) 
String elevVarUnitsString = this . elevVar . findAttribute ( "units" ) . getStringValue ( ) ; 
if ( ! SimpleUnit . isCompatible ( elevVarUnitsString , "meters" ) ) 
elevVarUnitsConversionFactor = getMetersConversionFactor ( elevVarUnitsString ) ; 
catch ( Exception e ) 
if ( this . netcdfDataset . hasUnlimitedDimension ( ) && this . netcdfDataset . getUnlimitedDimension ( ) . equals ( timeDim ) ) 
Object result = this . netcdfDataset . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
if ( ( result != null ) && ( Boolean ) result ) 
this . recordVar = ( Structure ) this . netcdfDataset . getRootGroup ( ) . findVariable ( "record" ) ; 
this . recordVar = new StructurePseudo ( this . netcdfDataset , null , "record" , timeDim ) ; 
Variable elevVarInRecVar = this . recordVar . findVariable ( this . elevVar . getFullNameEscaped ( ) ) ; 
if ( ! elevVarUnitsString . equals ( elevVarInRecVar . findAttribute ( "units" ) . getStringValue ( ) ) ) 
elevVarInRecVar . addAttribute ( new Attribute ( "units" , elevVarUnitsString ) ) ; 
trajectoryVarsMap = new HashMap ( ) ; 
for ( Iterator it = this . netcdfDataset . getRootGroup ( ) . getVariables ( ) . iterator ( ) ; it . hasNext ( ) ; ) 
Variable curVar = ( Variable ) it . next ( ) ; 
if ( curVar . getRank ( ) > 0 && 
! curVar . equals ( this . timeVar ) && 
! curVar . equals ( this . latVar ) && 
! curVar . equals ( this . lonVar ) && 
! curVar . equals ( this . elevVar ) && 
( this . recordVar == null ? true : ! curVar . equals ( this . recordVar ) ) ) 
MyTypedDataVariable typedVar = new MyTypedDataVariable ( new VariableDS ( null , curVar , true ) ) ; 
dataVariables . add ( typedVar ) ; 
trajectoryVarsMap . put ( typedVar . getShortName ( ) , typedVar ) ; 
trajectory = new SingleTrajectory ( this . trajectoryId , trajectoryNumPoint , 
this . timeVar , timeVarUnitsString , 
this . latVar , this . lonVar , this . elevVar , 
dataVariables , trajectoryVarsMap ) ; 
startDate = trajectory . getTime ( 0 ) ; 
( ( SingleTrajectory ) trajectory ) . setStartDate ( startDate ) ; 
( ( SingleTrajectory ) trajectory ) . setEndDate ( endDate ) ; 
} static public DapType lookup ( TypeSort atomic ) 
if ( atomic == TypeSort . Enum ) 
return typemap . get ( atomic ) ; 
double fromLat_r = Math . toRadians ( fromLat ) ; 
if ( ( Math . abs ( 90.0 - Math . abs ( fromLat ) ) ) < TOLERANCE ) { 
toX = A * Math . toRadians ( LatLonPointImpl . range180 ( fromLon - this . lon0 ) ) ; 
toY = A * SpecialMathFunction . atanh ( Math . sin ( fromLat_r ) ) ; 
double toLon = Math . toDegrees ( fromX / A ) + lon0 ; 
double e = Math . exp ( - fromY / A ) ; 
double toLat = Math . toDegrees ( Math . PI / 2 - 2 * Math . atan ( e ) ) ; 
} public void writeXML ( Catalog catalog , OutputStream os , boolean raw ) throws IOException { 
} public void writeXML ( Catalog catalog , OutputStream os ) throws IOException { 
XMLOutputter fmt = new XMLOutputter ( org . jdom2 . output . Format . getPrettyFormat ( ) ) ; 
fmt . output ( writeCatalog ( catalog ) , os ) ; 
} protected void writeInheritedMetadata ( Element elem , Dataset ds ) { 
Element mdataElem = new Element ( "metadata" , Catalog . defNS ) ; 
ThreddsMetadata tmi = ( ThreddsMetadata ) ds . getLocalField ( Dataset . ThreddsMetadataInheritable ) ; 
if ( tmi == null ) return ; 
} public void add ( ProjectionRect r ) { 
double x1 = Math . min ( getMinX ( ) , r . getMinX ( ) ) ; 
double x2 = Math . max ( getMaxX ( ) , r . getMaxX ( ) ) ; 
double y1 = Math . min ( getMinY ( ) , r . getMinY ( ) ) ; 
double y2 = Math . max ( getMaxY ( ) , r . getMaxY ( ) ) ; 
setRect ( x1 , y1 , x2 - x1 , y2 - y1 ) ; 
} public void add ( double newx , double newy ) { 
double x1 = Math . min ( getMinX ( ) , newx ) ; 
double x2 = Math . max ( getMaxX ( ) , newx ) ; 
double y1 = Math . min ( getMinY ( ) , newy ) ; 
double y2 = Math . max ( getMaxY ( ) , newy ) ; 
} public static void intersect ( ProjectionRect src1 , ProjectionRect src2 , ProjectionRect dest ) { 
double x1 = Math . max ( src1 . getMinX ( ) , src2 . getMinX ( ) ) ; 
double y1 = Math . max ( src1 . getMinY ( ) , src2 . getMinY ( ) ) ; 
double x2 = Math . min ( src1 . getMaxX ( ) , src2 . getMaxX ( ) ) ; 
double y2 = Math . min ( src1 . getMaxY ( ) , src2 . getMaxY ( ) ) ; 
dest . setRect ( x1 , y1 , x2 - x1 , y2 - y1 ) ; 
} public boolean contains ( ProjectionPoint point ) { 
return DoubleMath . fuzzyCompare ( point . getX ( ) , getMinX ( ) , 1e-6 ) >= 0 && 
DoubleMath . fuzzyCompare ( point . getX ( ) , getMaxX ( ) , 1e-6 ) <= 0 && 
DoubleMath . fuzzyCompare ( point . getY ( ) , getMinY ( ) , 1e-6 ) >= 0 && 
DoubleMath . fuzzyCompare ( point . getY ( ) , getMaxY ( ) , 1e-6 ) <= 0 ; 
} private void readObject ( ObjectInputStream s ) 
throws IOException , ClassNotFoundException { 
double x = s . readDouble ( ) ; 
double y = s . readDouble ( ) ; 
double w = s . readDouble ( ) ; 
double h = s . readDouble ( ) ; 
setRect ( x , y , w , h ) ; 
} private void writeObject ( ObjectOutputStream s ) throws IOException { 
s . writeDouble ( getX ( ) ) ; 
s . writeDouble ( getY ( ) ) ; 
s . writeDouble ( getWidth ( ) ) ; 
s . writeDouble ( getHeight ( ) ) ; 
} public boolean nearlyEquals ( ProjectionRect other , double maxRelDiff ) { 
return this . getLowerLeftPoint ( ) . nearlyEquals ( other . getLowerLeftPoint ( ) , maxRelDiff ) && 
this . getUpperRightPoint ( ) . nearlyEquals ( other . getUpperRightPoint ( ) , maxRelDiff ) ; 
} public void add ( final UnitDBImpl that ) throws UnitExistsException { 
unitSet . addAll ( that . unitSet ) ; 
nameMap . putAll ( that . nameMap ) ; 
symbolMap . putAll ( that . symbolMap ) ; 
} public void addUnit ( final Unit unit ) throws UnitExistsException , 
NameException { 
if ( unit . getName ( ) == null ) { 
addByName ( unit . getName ( ) , unit ) ; 
addByName ( unit . getPlural ( ) , unit ) ; 
addBySymbol ( unit . getSymbol ( ) , unit ) ; 
unitSet . add ( unit ) ; 
} public final void addAlias ( final String alias , final String name ) 
throws NoSuchUnitException , UnitExistsException { 
addAlias ( alias , name , null ) ; 
} public final void addSymbol ( final String symbol , final String name ) 
addAlias ( null , name , symbol , null ) ; 
} public final void addAlias ( final String alias , final String name , 
final String symbol , final String plural ) 
addAlias ( UnitID . newUnitID ( alias , plural , symbol ) , name ) ; 
} public final void addAlias ( final UnitID alias , final String name ) 
final Unit unit = getByName ( name ) ; 
if ( unit == null ) { 
throw new NoSuchUnitException ( name ) ; 
addByName ( alias . getName ( ) , unit ) ; 
addByName ( alias . getPlural ( ) , unit ) ; 
addBySymbol ( alias . getSymbol ( ) , unit ) ; 
} public Unit get ( final String id ) { 
Unit unit = getBySymbol ( id ) ; 
unit = getByName ( id ) ; 
} private final void addByName ( final String name , final Unit newUnit ) 
throws UnitExistsException { 
addUnique ( nameMap , canonicalize ( name ) , newUnit ) ; 
} private final void addBySymbol ( final String symbol , final Unit newUnit ) 
if ( symbol != null ) { 
addUnique ( symbolMap , symbol , newUnit ) ; 
} private static final void addUnique ( final Map < String , Unit > map , 
final String key , final Unit newUnit ) throws UnitExistsException { 
final Unit oldUnit = map . put ( key , newUnit ) ; 
if ( oldUnit != null && ! oldUnit . equals ( newUnit ) ) { 
throw new UnitExistsException ( oldUnit , newUnit ) ; 
buildFileList ( Root rootinfo ) 
File root = new File ( rootinfo . getFullPath ( ) ) ; 
if ( ! root . isDirectory ( ) ) 
if ( ! root . canRead ( ) ) 
File [ ] candidates = root . listFiles ( ) ; 
List < FileSource > activesources = new ArrayList < FileSource > ( ) ; 
for ( FileSource src : SOURCES ) { 
List < File > matches = new ArrayList < File > ( ) ; 
for ( File candidate : candidates ) { 
String name = candidate . getName ( ) ; 
boolean excluded = false ; 
for ( String exclude : expatterns ) { 
if ( name . indexOf ( exclude ) >= 0 ) { 
excluded = true ; 
if ( excluded ) continue ; 
if ( ! name . endsWith ( src . ext ) ) continue ; 
if ( ! candidate . canRead ( ) ) { 
matches . add ( candidate ) ; 
if ( matches . size ( ) > 0 ) { 
matches . sort ( new Comparator < File > ( ) { 
public int compare ( File f1 , File f2 ) { 
return f1 . getName ( ) . compareTo ( f2 . getName ( ) ) ; 
} } ) ; 
if ( DUMPFILELIST ) { 
for ( File x : matches ) { 
FileSource clone = new FileSource ( src . ext , src . tag ) ; 
clone . files = matches ; 
activesources . add ( clone ) ; 
rootinfo . setFiles ( activesources ) ; 
} public void addToMenu ( final JMenu menu ) { 
final UIManager . LookAndFeelInfo [ ] plafInfo = UIManager . getInstalledLookAndFeels ( ) ; 
for ( UIManager . LookAndFeelInfo aPlafInfo : plafInfo ) { 
addToMenu ( aPlafInfo . getName ( ) , aPlafInfo . getClassName ( ) , menu ) ; 
final LookAndFeel current = UIManager . getLookAndFeel ( ) ; 
} public static boolean nameIsGlobal ( String name ) { 
String lcName = name . toLowerCase ( ) ; 
boolean global = false ; 
if ( lcName . indexOf ( "global" ) >= 0 ) 
global = true ; 
if ( lcName . indexOf ( "dods" ) >= 0 ) 
return ( global ) ; 
} public static String fancyTypeName ( BaseType bt ) { 
if ( bt instanceof DByte ) 
if ( bt instanceof DUInt16 ) 
if ( bt instanceof DInt16 ) 
if ( bt instanceof DUInt32 ) 
if ( bt instanceof DInt32 ) 
if ( bt instanceof DFloat32 ) 
if ( bt instanceof DFloat64 ) 
if ( bt instanceof DURL ) 
return ( "URL" ) ; 
if ( bt instanceof DString ) 
return ( "String" ) ; 
if ( bt instanceof DArray ) { 
DArray a = ( DArray ) bt ; 
StringBuilder type = new StringBuilder ( ) ; 
type . append ( fancyTypeName ( a . getPrimitiveVector ( ) . getTemplate ( ) ) ) ; 
Enumeration e = a . getDimensions ( ) ; 
DArrayDimension dad = ( DArrayDimension ) e . nextElement ( ) ; 
type . append ( "[" ) ; 
type . append ( dad . getEncodedName ( ) ) ; 
type . append ( dad . getSize ( ) - 1 ) ; 
type . append ( "]" ) ; 
type . append ( "\n" ) ; 
return ( type . toString ( ) ) ; 
if ( bt instanceof DStructure ) 
return ( "Structure" ) ; 
if ( bt instanceof DSequence ) 
return ( "Sequence" ) ; 
if ( bt instanceof DGrid ) 
return ( "Grid" ) ; 
return ( "UNKNOWN" ) ; 
public static Grib2Record findRecordByDrspos ( RandomAccessFile raf , long drsPos ) throws IOException { 
long pos = Math . max ( 0 , drsPos - ( 20 * 1000 ) ) ; 
Grib2RecordScanner scan = new Grib2RecordScanner ( raf , pos ) ; 
ucar . nc2 . grib . grib2 . Grib2Record gr = scan . next ( ) ; 
Grib2SectionDataRepresentation drs = gr . getDataRepresentationSection ( ) ; 
if ( drsPos == drs . getStartingPosition ( ) ) return gr ; 
if ( raf . getFilePointer ( ) > drsPos ) break ; 
} private boolean nextRepeating ( ) throws IOException { 
raf . seek ( repeatPos ) ; 
GribNumbers . int4 ( raf ) ; 
int section = raf . read ( ) ; 
if ( section == 2 ) { 
repeatRecord . setLus ( new Grib2SectionLocalUse ( raf ) ) ; 
repeatRecord . setGdss ( new Grib2SectionGridDefinition ( raf ) ) ; 
repeatRecord . setPdss ( new Grib2SectionProductDefinition ( raf ) ) ; 
repeatRecord . setDrs ( new Grib2SectionDataRepresentation ( raf ) ) ; 
repeatRecord . setBms ( new Grib2SectionBitMap ( raf ) , false ) ; 
repeatRecord . setDataSection ( new Grib2SectionData ( raf ) ) ; 
repeatRecord . repeat = section ; 
} else if ( section == 3 ) { 
} else if ( section == 4 ) { 
lastPos = repeatPos ; 
repeatPos = - 1 ; 
repeatRecord = null ; 
repeatBms = null ; 
Grib2SectionBitMap bms = repeatRecord . getBitmapSection ( ) ; 
if ( bms . getBitMapIndicator ( ) == 254 ) { 
if ( repeatBms == null ) 
repeatRecord . setBms ( repeatBms , true ) ; 
repeatRecord . repeat += 1000 ; 
} else if ( bms . getBitMapIndicator ( ) == 0 ) { 
repeatBms = repeatRecord . getBitmapSection ( ) ; 
if ( ( section == 2 ) || ( section == 3 ) ) { 
Grib2SectionGridDefinition gds = repeatRecord . getGDSsection ( ) ; 
long crc = gds . calcCRC ( ) ; 
Grib2SectionGridDefinition gdsCached = gdsMap . get ( crc ) ; 
if ( gdsCached != null ) 
repeatRecord . setGdss ( gdsCached ) ; 
gdsMap . put ( crc , gds ) ; 
long pos = raf . getFilePointer ( ) ; 
long ending = repeatRecord . getIs ( ) . getEndPos ( ) ; 
if ( pos + 34 < ending ) { 
repeatPos = pos ; 
raf . seek ( ending - 4 ) ; 
if ( raf . read ( ) != 55 ) { 
String clean = StringUtil2 . cleanup ( header ) ; 
if ( clean . length ( ) > 40 ) clean = clean . substring ( 0 , 40 ) + "..." ; 
lastPos = raf . getFilePointer ( ) ; 
} public boolean read ( String datasetName , Object specialO ) throws NoSuchVariableException , 
IOException { 
StructureData sdata = ncVar . readStructure ( ) ; 
setData ( sdata ) ; 
} public void setData ( StructureData sdata ) { 
StructureMembers sm = sdata . getStructureMembers ( ) ; 
java . util . Enumeration vars = getVariables ( ) ; 
while ( vars . hasMoreElements ( ) ) { 
HasNetcdfVariable hasNetcdf = ( HasNetcdfVariable ) vars . nextElement ( ) ; 
StructureMembers . Member m = sm . getMember ( count ++ ) ; 
Array data = sdata . getArray ( m ) ; 
hasNetcdf . setData ( data ) ; 
setRead ( true ) ; 
if ( org == null ) { 
super . serialize ( dataset , sink , ce , specialO ) ; 
java . util . Enumeration vars = org . getVariables ( ) ; 
HasNetcdfVariable sm_org = ( HasNetcdfVariable ) vars . nextElement ( ) ; 
boolean isProjected = ( ( ServerMethods ) sm_org ) . isProject ( ) ; 
if ( isProjected ) { 
StructureMembers . Member m = sm . getMember ( count ) ; 
sm_org . serialize ( sink , sdata , m ) ; 
} public float [ ] getParamValues ( DoradeRDAT rdat , float [ ] workingArray ) 
throws DescriptorException { 
if ( ! paramName . equals ( rdat . getParamName ( ) ) ) 
byte [ ] paramData = rdat . getRawData ( ) ; 
int nCells = myRADD . getNCells ( ) ; 
float [ ] values ; 
if ( workingArray != null && workingArray . length == nCells ) { 
values = workingArray ; 
values = new float [ nCells ] ; 
short [ ] svalues = null ; 
if ( myRADD . getCompressionScheme ( ) == DoradeRADD . COMPRESSION_HRD ) { 
if ( binaryFormat != DoradePARM . FORMAT_16BIT_INT ) { 
binaryFormat ) ; 
svalues = uncompressHRD ( paramData , nCells ) ; 
for ( int cell = 0 ; cell < nCells ; cell ++ ) { 
switch ( binaryFormat ) { 
case DoradePARM . FORMAT_8BIT_INT : 
byte bval = paramData [ cell ] ; 
values [ cell ] = ( bval == badDataFlag ) ? 
BAD_VALUE : ( bval - bias ) / scale ; 
case DoradePARM . FORMAT_16BIT_INT : 
short sval = ( svalues != null ) ? 
svalues [ cell ] : grabShort ( paramData , 2 * cell ) ; 
values [ cell ] = ( sval == badDataFlag ) ? 
BAD_VALUE : ( sval - bias ) / scale ; 
case DoradePARM . FORMAT_32BIT_INT : 
int ival = grabInt ( paramData , 4 * cell ) ; 
values [ cell ] = ( ival == badDataFlag ) ? 
BAD_VALUE : ( ival - bias ) / scale ; 
case DoradePARM . FORMAT_32BIT_FLOAT : 
float fval = grabFloat ( paramData , 4 * cell ) ; 
values [ cell ] = ( fval == badDataFlag ) ? 
BAD_VALUE : ( fval - bias ) / scale ; 
case DoradePARM . FORMAT_16BIT_FLOAT : 
binaryFormat + ")" ) ; 
} private short [ ] uncompressHRD ( byte [ ] compressedData , int nCells ) 
short [ ] svalues = new short [ nCells ] ; 
int cPos = 0 ; 
int nextCell = 0 ; 
int runLength ; 
for ( ; ; nextCell += runLength ) { 
short runDescriptor = grabShort ( compressedData , cPos ) ; 
cPos += 2 ; 
boolean runHasGoodValues = ( ( runDescriptor & 0x8000 ) != 0 ) ; 
runLength = runDescriptor & 0x7fff ; 
if ( runLength == 1 ) 
if ( ( nextCell + runLength ) > nCells ) 
for ( int cell = nextCell ; cell < nextCell + runLength ; cell ++ ) { 
if ( runHasGoodValues ) { 
svalues [ cell ] = grabShort ( compressedData , cPos ) ; 
svalues [ cell ] = ( short ) badDataFlag ; 
for ( int cell = nextCell ; cell < nCells ; cell ++ ) 
return svalues ; 
ProjectionImpl result = new VerticalPerspectiveView ( getOriginLat ( ) , getOriginLon ( ) , R , getHeight ( ) , false_east , false_north ) ; 
sinLat0 = Math . sin ( lat0 ) ; 
cosLat0 = Math . cos ( lat0 ) ; 
lon0Degrees = Math . toDegrees ( lon0 ) ; 
P = 1.0 + H / R ; 
maxR = .99 * R * Math . sqrt ( ( P - 1 ) / ( P + 1 ) ) ; 
double lonDiff = Math . toRadians ( LatLonPointImpl . lonNormal ( fromLon 
- lon0Degrees ) ) ; 
double cosc = sinLat0 * Math . sin ( fromLat ) 
+ cosLat0 * Math . cos ( fromLat ) * Math . cos ( lonDiff ) ; 
double ksp = ( P - 1.0 ) / ( P - cosc ) ; 
if ( cosc < 1.0 / P ) { 
toX = false_east 
+ R * ksp * Math . cos ( fromLat ) * Math . sin ( lonDiff ) ; 
toY = false_north 
+ R * ksp 
* ( cosLat0 * Math . sin ( fromLat ) 
- sinLat0 * Math . cos ( fromLat ) * Math . cos ( lonDiff ) ) ; 
fromX = fromX - false_east ; 
fromY = fromY - false_north ; 
double rho = Math . sqrt ( fromX * fromX + fromY * fromY ) ; 
double r = rho / R ; 
double con = P - 1.0 ; 
double com = P + 1.0 ; 
double c = Math . asin ( ( P - Math . sqrt ( 1.0 - ( r * r * com ) / con ) ) 
/ ( con / r + r / con ) ) ; 
toLon = lon0 ; 
double temp = 0 ; 
if ( Math . abs ( rho ) > TOLERANCE ) { 
toLat = Math . asin ( Math . cos ( c ) * sinLat0 
+ ( fromY * Math . sin ( c ) * cosLat0 / rho ) ) ; 
if ( Math . abs ( lat0 - PI_OVER_4 ) > TOLERANCE ) { 
temp = rho * cosLat0 * Math . cos ( c ) 
- fromY * sinLat0 * Math . sin ( c ) ; 
toLon = lon0 + Math . atan ( fromX * Math . sin ( c ) / temp ) ; 
} else if ( Double . compare ( lat0 , PI_OVER_4 ) == 0 ) { 
toLon = lon0 + Math . atan ( fromX / - fromY ) ; 
temp = - fromY ; 
toLon = lon0 + Math . atan ( fromX / fromY ) ; 
temp = fromY ; 
toLat = lat0 ; 
toLat = Math . toDegrees ( toLat ) ; 
toLon = Math . toDegrees ( toLon ) ; 
if ( temp < 0 ) { 
toLon += 180 ; 
} private void readXml ( Version version ) throws IOException { 
try ( InputStream ios = WmoTemplateTables . class . getResourceAsStream ( version . getResourceName ( ) ) ) { 
if ( ios == null ) { 
doc = builder . build ( ios ) ; 
Map < String , TemplateTable > map = new HashMap < > ( ) ; 
String [ ] elems = version . getElemNames ( ) ; 
assert elems != null ; 
assert elems . length > 3 ; 
List < Element > featList = root . getChildren ( elems [ 0 ] ) ; 
for ( Element elem : featList ) { 
String desc = elem . getChildTextNormalize ( elems [ 1 ] ) ; 
String octet = elem . getChildTextNormalize ( "OctetNo" ) ; 
String content = elem . getChildTextNormalize ( elems [ 3 ] ) ; 
String status = elem . getChildTextNormalize ( "Status" ) ; 
String note = elem . getChildTextNormalize ( elems [ 2 ] ) ; 
TemplateTable template = map . computeIfAbsent ( desc , name -> new TemplateTable ( name ) ) ; 
template . add ( octet , content , status , note ) ; 
List < TemplateTable > tlist = new ArrayList < > ( map . values ( ) ) ; 
for ( TemplateTable t : tlist ) { 
if ( t . m1 == 3 ) { 
t . add ( 5 , 1 , "Section" ) ; 
} else if ( t . m1 == 4 ) { 
Collections . sort ( t . flds ) ; 
this . templateTables = map . values ( ) . stream ( ) . sorted ( ) . collect ( ImmutableList . toImmutableList ( ) ) ; 
ImmutableMap . Builder < String , TemplateTable > builder = ImmutableMap . builder ( ) ; 
map . values ( ) . forEach ( t -> builder . put ( t . getId ( ) , t ) ) ; 
this . templateMap = builder . build ( ) ; 
} public void draw ( java . awt . Graphics2D g , java . awt . geom . AffineTransform normal2Device ) { 
if ( ( project == null ) || ! posWasCalc ) return ; 
AffineTransform world2Device = g . getTransform ( ) ; 
g . setTransform ( normal2Device ) ; 
AffineTransform world2Normal ; 
world2Normal = normal2Device . createInverse ( ) ; 
world2Normal . concatenate ( world2Device ) ; 
normal2Device ) ; 
Object saveHint = g . getRenderingHint ( RenderingHints . KEY_ANTIALIASING ) ; 
g . setStroke ( new java . awt . BasicStroke ( 1.0f ) ) ; 
g . setFont ( textFont . getFont ( ) ) ; 
g . setColor ( color ) ; 
int npts = obsUIlist . size ( ) ; 
ObservationUI s = ( ObservationUI ) obsUIlist . get ( i ) ; 
s . calcPos ( world2Normal ) ; 
s . draw ( g ) ; 
if ( Double . isNaN ( s . screenPos . getX ( ) ) ) { 
if ( count == 0 ) 
path . moveTo ( ( float ) s . screenPos . getX ( ) , ( float ) s . screenPos . getY ( ) ) ; 
path . lineTo ( ( float ) s . screenPos . getX ( ) , ( float ) s . screenPos . getY ( ) ) ; 
if ( drawConnectingLine ) 
g . draw ( path ) ; 
if ( selected != null ) 
selected . draw ( g ) ; 
g . setTransform ( world2Device ) ; 
g . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , saveHint ) ; 
} public ThreddsDataFactory . Result openFeatureDataset ( String urlString , ucar . nc2 . util . CancelTask task ) throws IOException { 
ThreddsDataFactory . Result result = new ThreddsDataFactory . Result ( ) ; 
InvDataset invDataset = processLocation ( urlString , task , result ) ; 
if ( result . fatalError ) 
return openFeatureDataset ( null , invDataset , task , result ) ; 
} public ThreddsDataFactory . Result openFeatureDataset ( InvDataset invDataset , ucar . nc2 . util . CancelTask task ) throws IOException { 
return openFeatureDataset ( null , invDataset , task , new Result ( ) ) ; 
} public ThreddsDataFactory . Result openFeatureDataset ( InvAccess access , ucar . nc2 . util . CancelTask task ) throws IOException { 
InvDataset invDataset = access . getDataset ( ) ; 
ThreddsDataFactory . Result result = new Result ( ) ; 
if ( invDataset . getDataType ( ) == null ) { 
return openFeatureDataset ( invDataset . getDataType ( ) , access , task , result ) ; 
} public NetcdfDataset openDataset ( InvDataset invDataset , boolean acquire , ucar . nc2 . util . CancelTask task , Formatter log ) throws IOException { 
NetcdfDataset ncd = openDataset ( invDataset , acquire , task , result ) ; 
return ( result . fatalError ) ? null : ncd ; 
} public InvAccess chooseDatasetAccess ( List < InvAccess > accessList ) { 
InvAccess access = null ; 
access = findAccessByServiceType ( accessList , ServiceType . FILE ) ; 
access = findAccessByServiceType ( accessList , ServiceType . NETCDF ) ; 
InvAccess tryAccess = findAccessByServiceType ( accessList , ServiceType . HTTPServer ) ; 
if ( tryAccess == null ) 
tryAccess = findAccessByServiceType ( accessList , ServiceType . HTTP ) ; 
if ( tryAccess != null ) { 
DataFormatType format = tryAccess . getDataFormatType ( ) ; 
if ( ( DataFormatType . BUFR == format ) || ( DataFormatType . GINI == format ) || ( DataFormatType . GRIB1 == format ) 
|| ( DataFormatType . GRIB2 == format ) || ( DataFormatType . HDF5 == format ) || ( DataFormatType . NCML == format ) 
|| ( DataFormatType . NETCDF == format ) || ( DataFormatType . NEXRAD2 == format ) || ( DataFormatType . NIDS == format ) ) { 
access = tryAccess ; 
access = findAccessByServiceType ( accessList , ServiceType . RESOLVER ) ; 
} public static void annotate ( InvDataset ds , NetcdfDataset ncDataset ) { 
ncDataset . setId ( ds . getID ( ) ) ; 
for ( InvProperty p : ds . getProperties ( ) ) { 
} private InvAccess getImageAccess ( InvDataset invDataset , ucar . nc2 . util . CancelTask task , Result result ) { 
List < InvAccess > accessList = new ArrayList < > ( invDataset . getAccess ( ) ) ; 
InvAccess access = chooseImageAccess ( accessList ) ; 
if ( access != null ) return access ; 
access = invDataset . getAccess ( ServiceType . RESOLVER ) ; 
InvDatasetImpl rds = openResolver ( datasetLocation , task , result ) ; 
accessList = new ArrayList < > ( invDataset . getAccess ( ) ) ; 
} private InvAccess findAccessByServiceType ( List < InvAccess > accessList , ServiceType type ) { 
for ( InvAccess a : accessList ) { 
if ( type . toString ( ) . equalsIgnoreCase ( a . getService ( ) . getServiceType ( ) . toString ( ) ) ) 
} private InvAccess findAccessByDataFormatType ( List < InvAccess > accessList , DataFormatType type ) { 
if ( type . toString ( ) . equalsIgnoreCase ( a . getDataFormatType ( ) . toString ( ) ) ) 
} public static List < Property > removeDups ( List < Property > org ) { 
List < Property > result = new ArrayList < > ( org . size ( ) ) ; 
for ( Property p : org ) 
if ( ! result . contains ( p ) ) 
result . add ( p ) ; 
} void addPartition ( int partno , int groupno , int varno , int ndups , int nrecords , int nmissing , 
GribCollectionMutable . VariableIndex vi ) { 
if ( partList == null ) partList = new ArrayList < > ( nparts ) ; 
partList . add ( new PartitionForVariable2D ( partno , groupno , varno ) ) ; 
this . ndups += ndups ; 
this . nrecords += nrecords ; 
this . nmissing += nmissing ; 
} public GribCollectionImmutable getGribCollection ( ) throws IOException { 
String path = getIndexFilenameInCache ( ) ; 
if ( path == null ) { 
if ( Grib . debugIndexOnly ) { 
File orgParentDir = new File ( directory ) ; 
File currentFile = new File ( PartitionCollectionMutable . this . indexFilename ) ; 
File currentParent = currentFile . getParentFile ( ) ; 
File currentParentWithDir = new File ( currentParent , orgParentDir . getName ( ) ) ; 
File nestedIndex = isPartitionOfPartitions ? new File ( currentParentWithDir , filename ) : new File ( currentParent , filename ) ; 
path = nestedIndex . getPath ( ) ; 
return ( GribCollectionImmutable ) PartitionCollectionImmutable . partitionCollectionFactory . open ( new DatasetUrl ( null , path ) , - 1 , null , this ) ; 
public GribCollectionMutable makeGribCollection ( ) { 
GribCollectionMutable result = GribCdmIndex . openMutableGCFromIndex ( dcm . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) , config , false , true , logger ) ; 
lastModified = result . lastModified ; 
fileSize = result . fileSize ; 
if ( result . masterRuntime != null ) 
partitionDate = result . masterRuntime . getFirstDate ( ) ; 
} public static 
RegExpAndDurationTimeCoverageEnhancer 
getInstanceToMatchOnDatasetName ( String matchPattern , 
String substitutionPattern , 
String duration ) 
return new RegExpAndDurationTimeCoverageEnhancer ( 
matchPattern , substitutionPattern , 
duration , MatchTarget . DATASET_NAME ) ; 
} public static RegExpAndDurationTimeCoverageEnhancer 
getInstanceToMatchOnDatasetPath ( String matchPattern , 
duration , MatchTarget . DATASET_PATH ) ; 
} public QueryCapability readXML ( String uriString ) throws IOException { 
uri = new URI ( uriString ) ; 
throw new MalformedURLException ( e . getMessage ( ) ) ; 
if ( diskCache != null ) { 
File file = diskCache . getCacheFile ( uriString ) ; 
if ( file != null ) { 
HttpURLConnection conn = null ; 
conn = ( HttpURLConnection ) url . openConnection ( ) ; 
conn . setRequestMethod ( "GET" ) ; 
conn . setIfModifiedSince ( file . lastModified ( ) ) ; 
int code = conn . getResponseCode ( ) ; 
if ( code == HttpURLConnection . HTTP_OK ) { 
java . io . InputStream is = conn . getInputStream ( ) ; 
try ( FileOutputStream fout = new FileOutputStream ( file ) ) { 
IO . copyB ( is , fout , buffer_size ) ; 
try ( InputStream fin = new BufferedInputStream ( new FileInputStream ( file ) , 50000 ) ) { 
return readXML ( fin , uri ) ; 
try ( FileInputStream fin = new FileInputStream ( file ) ) { 
if ( conn != null ) 
conn . disconnect ( ) ; 
IO . readURLtoFileWithExceptions ( uriString , file , buffer_size ) ; 
try ( InputStream fin = new BufferedInputStream ( 
new FileInputStream ( file ) , 50000 ) ) { 
warnMessages . setLength ( 0 ) ; 
errMessages . setLength ( 0 ) ; 
fatalMessages . setLength ( 0 ) ; 
Document doc = null ; 
doc = builder . build ( uriString ) ; 
fatalMessages . append ( e . getMessage ( ) ) ; 
return readXML ( doc , uri ) ; 
} public QueryCapability readXML ( InputStream docIs , URI uri ) throws IOException { 
doc = builder . build ( docIs ) ; 
} private QueryCapability readXML ( org . jdom2 . Document doc , URI uri ) throws IOException { 
if ( doc == null ) { 
QueryCapability dqc = new QueryCapability ( ) ; 
if ( fatalMessages . length ( ) > 0 ) 
dqc . appendErrorMessage ( fatalMessages . toString ( ) , true ) ; 
if ( errMessages . length ( ) > 0 ) 
dqc . appendErrorMessage ( errMessages . toString ( ) , false ) ; 
dqc . appendErrorMessage ( warnMessages . toString ( ) , false ) ; 
return dqc ; 
String namespace = root . getNamespaceURI ( ) ; 
DqcConvertIF fac = namespaceToDqcConverterHash . get ( namespace ) ; 
if ( fac == null ) { 
fac = defaultConverter ; 
if ( debugVersion ) 
} else if ( debugVersion ) 
QueryCapability dqc = fac . parseXML ( this , doc , uri ) ; 
} public String writeXML ( QueryCapability dqc ) throws IOException { 
ByteArrayOutputStream os = new ByteArrayOutputStream ( 10000 ) ; 
writeXML ( dqc , os ) ; 
return os . toString ( CDM . utf8Charset . name ( ) ) ; 
} public void writeXML ( QueryCapability dqc , OutputStream os ) throws IOException { 
String ns = versionToNamespaceHash . get ( dqc . getVersion ( ) ) ; 
DqcConvertIF fac = namespaceToDqcConverterHash . get ( ns ) ; 
fac . writeXML ( dqc , os ) ; 
} public boolean writeXML ( QueryCapability dqc , String filename ) { 
BufferedOutputStream os = new BufferedOutputStream ( new FileOutputStream ( filename ) ) ; 
} private static void doOne ( DqcFactory fac , String url ) { 
QueryCapability dqc = fac . readXML ( url ) ; 
fac . writeXML ( dqc , System . out ) ; 
} public void setProjection ( int start , int stride , int stop ) throws InvalidDimensionException 
if ( projection != null ) { 
if ( getSize ( ) != start || getStride ( ) != stride || getStop ( ) != stop ) { 
if ( start < 0 ) 
if ( stride <= 0 ) 
if ( stop < 0 ) 
if ( start < decl . start ) 
if ( stop >= decl . size ) 
if ( stop < start ) 
projection = new Slice ( start , stride , stop ) ; 
DArrayDimension d = ( DArrayDimension ) super . cloneDAG ( map ) ; 
if ( container != null ) d . container = ( DArray ) cloneDAG ( map , container ) ; 
} private ucar . ma2 . ArrayStructure readStructureData ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException , InvalidRangeException { 
H4header . Vinfo vinfo = ( H4header . Vinfo ) s . getSPobject ( ) ; 
vinfo . setLayoutInfo ( ) ; 
int recsize = vinfo . elemSize ; 
H4header . Minfo minfo = ( H4header . Minfo ) v2 . getSPobject ( ) ; 
m . setDataParam ( minfo . offset ) ; 
members . setStructureSize ( recsize ) ; 
ArrayStructureBB structureArray = new ArrayStructureBB ( members , section . getShape ( ) ) ; 
if ( ! vinfo . isLinked && ! vinfo . isCompressed ) { 
Layout layout = new LayoutRegular ( vinfo . start , recsize , s . getShape ( ) , section ) ; 
IospHelper . readData ( raf , layout , DataType . STRUCTURE , result , - 1 , true ) ; 
} else if ( vinfo . isLinked && ! vinfo . isCompressed ) { 
InputStream is = new LinkedInputStream ( vinfo ) ; 
PositioningDataInputStream dataSource = new PositioningDataInputStream ( is ) ; 
Layout layout = new LayoutRegular ( 0 , recsize , s . getShape ( ) , section ) ; 
IospHelper . readData ( dataSource , layout , DataType . STRUCTURE , result ) ; 
} else if ( ! vinfo . isLinked && vinfo . isCompressed ) { 
InputStream is = getCompressedInputStream ( vinfo ) ; 
} else if ( vinfo . isLinked && vinfo . isCompressed ) { 
InputStream is = getLinkedCompressedInputStream ( vinfo ) ; 
} public void setPicture ( URL filenameURL , String legendParam , double rotation ) { 
legend = legendParam ; 
centerWhenScaled = true ; 
sclPic . setScaleSize ( getSize ( ) ) ; 
sclPic . stopLoadingExcept ( filenameURL ) ; 
sclPic . loadAndScalePictureInThread ( filenameURL , Thread . MAX_PRIORITY , rotation ) ; 
} public void setBufferedImage ( BufferedImage img , String statusMessage ) { 
legend = statusMessage ; 
Dimension dim = getSize ( ) ; 
sclPic . setScaleSize ( dim ) ; 
SourcePicture source = new SourcePicture ( ) ; 
source . setSourceBufferedImage ( img , statusMessage ) ; 
sclPic . setSourcePicture ( source ) ; 
if ( ! scaleToFit ) 
sclPic . setScaleFactor ( 1.0 ) ; 
sclPic . scalePicture ( ) ; 
} public void zoomIn ( ) { 
double OldScaleFactor = sclPic . getScaleFactor ( ) ; 
double NewScaleFactor = OldScaleFactor * 1.5 ; 
if ( ( OldScaleFactor < 1 ) && ( NewScaleFactor > 1 ) ) 
NewScaleFactor = 1 ; 
if ( ( sclPic . getOriginalWidth ( ) * sclPic . getScaleFactor ( ) < maximumPictureSize ) 
&& ( sclPic . getOriginalHeight ( ) * sclPic . getScaleFactor ( ) < maximumPictureSize ) ) { 
sclPic . setScaleFactor ( NewScaleFactor ) ; 
sclPic . createScaledPictureInThread ( Thread . MAX_PRIORITY ) ; 
} public void zoomToFit ( ) { 
if ( sclPic . getStatusCode ( ) == sclPic . LOADED 
|| sclPic . getStatusCode ( ) == sclPic . READY ) { 
} public void centerImage ( ) { 
if ( sclPic . getOriginalImage ( ) != null ) { 
setCenterLocation ( ( int ) sclPic . getOriginalWidth ( ) / 2 , ( int ) sclPic . getOriginalHeight ( ) / 2 ) ; 
} public void scrollUp ( ) { 
if ( ( ( sclPic . getOriginalHeight ( ) - focusPoint . y ) * sclPic . getScaleFactor ( ) ) + getSize ( ) . height / 2 > getSize ( ) . height ) { 
focusPoint . y = focusPoint . y + ( int ) ( getSize ( ) . height * 0.1 / sclPic . getScaleFactor ( ) ) ; 
} public void scrollDown ( ) { 
if ( getSize ( ) . height / 2 - focusPoint . y * sclPic . getScaleFactor ( ) < 0 ) { 
focusPoint . y = focusPoint . y - ( int ) ( getSize ( ) . height * 0.1 / sclPic . getScaleFactor ( ) ) ; 
} public void scrollLeft ( ) { 
if ( ( ( sclPic . getOriginalWidth ( ) - focusPoint . x ) * sclPic . getScaleFactor ( ) ) + getSize ( ) . width / 2 > getSize ( ) . width ) { 
focusPoint . x = focusPoint . x + ( int ) ( getSize ( ) . width * 0.1 / sclPic . getScaleFactor ( ) ) ; 
} public void scrollRight ( ) { 
if ( getSize ( ) . width / 2 - focusPoint . x * sclPic . getScaleFactor ( ) < 0 ) { 
focusPoint . x = focusPoint . x - ( int ) ( getSize ( ) . width * 0.1 / sclPic . getScaleFactor ( ) ) ; 
} public void setCenterLocation ( int Xparameter , int Yparameter ) { 
focusPoint . setLocation ( Xparameter , Yparameter ) ; 
int WindowWidth = getSize ( ) . width ; 
int WindowHeight = getSize ( ) . height ; 
if ( Dragging == false ) { 
setCursor ( new Cursor ( Cursor . WAIT_CURSOR ) ) ; 
if ( sclPic . getScaledPicture ( ) != null ) { 
Graphics2D g2d = ( Graphics2D ) g ; 
int X_Offset = ( int ) ( ( double ) ( WindowWidth / 2 ) - ( focusPoint . x * sclPic . getScaleFactor ( ) ) ) ; 
int Y_Offset = ( int ) ( ( double ) ( WindowHeight / 2 ) - ( focusPoint . y * sclPic . getScaleFactor ( ) ) ) ; 
Rectangle clipBounds = g2d . getClipBounds ( ) ; 
g2d . setColor ( Color . black ) ; 
g2d . fillRect ( clipBounds . x , clipBounds . y , clipBounds . width , clipBounds . height ) ; 
g2d . drawRenderedImage ( sclPic . getScaledPicture ( ) , AffineTransform . getTranslateInstance ( X_Offset , Y_Offset ) ) ; 
if ( showInfo ) { 
g2d . setColor ( Color . white ) ; 
g2d . drawString ( legend , infoPoint . x , infoPoint . y ) ; 
g . setClip ( 0 , 0 , WindowWidth , WindowHeight ) ; 
g . fillRect ( 0 , 0 , WindowWidth , WindowHeight ) ; 
setCursor ( new Cursor ( Cursor . DEFAULT_CURSOR ) ) ; 
} public void scalableStatusChange ( int pictureStatusCode , String pictureStatusMessage ) { 
if ( pictureStatusCode == ScalablePicture . READY ) { 
pictureStatusMessage = legend ; 
if ( centerWhenScaled ) { 
centerImage ( ) ; 
Enumeration e = picturePaneListeners . elements ( ) ; 
( ( ScalablePictureListener ) e . nextElement ( ) ) 
. scalableStatusChange ( pictureStatusCode , pictureStatusMessage ) ; 
} public static int [ ] TG_FTOI ( int [ ] iftime , int start ) { 
int [ ] intdtf = new int [ 3 ] ; 
if ( iftime [ start ] < 100000000 ) { 
intdtf [ 0 ] = iftime [ start ] ; 
intdtf [ 1 ] = iftime [ start + 1 ] ; 
intdtf [ 2 ] = 0 ; 
intdtf [ 0 ] = iftime [ start ] / 10000 ; 
intdtf [ 1 ] = iftime [ start ] - intdtf [ 0 ] * 10000 ; 
int mmdd = intdtf [ 0 ] / 100 ; 
int iyyy = intdtf [ 0 ] - mmdd * 100 ; 
intdtf [ 0 ] = iyyy * 10000 + mmdd ; 
intdtf [ 2 ] = iftime [ start + 1 ] ; 
return intdtf ; 
} public static String TG_ITOC ( int [ ] intdtf ) { 
String gdattim = "" ; 
if ( ( intdtf [ 0 ] == 0 ) && ( intdtf [ 1 ] == 0 ) && ( intdtf [ 2 ] == 0 ) ) { 
return gdattim ; 
gdattim = TI_CDTM ( intdtf [ 0 ] , intdtf [ 1 ] ) ; 
if ( intdtf [ 2 ] != 0 ) { 
String [ ] timeType = TG_CFTM ( intdtf [ 2 ] ) ; 
String ftype = timeType [ 0 ] ; 
String ftime = timeType [ 1 ] ; 
gdattim = gdattim . substring ( 0 , 11 ) + ftype + ftime ; 
} public static String [ ] TG_CFTM ( int ifcast ) { 
String ftype = "" ; 
String ftime = "" ; 
if ( ifcast < 0 ) { 
return new String [ ] { ftype , ftime } ; 
int iftype = ifcast / 100000 ; 
if ( iftype == 0 ) { 
ftype = "A" ; 
} else if ( iftype == 1 ) { 
ftype = "F" ; 
} else if ( iftype == 2 ) { 
ftype = "G" ; 
} else if ( iftype == 3 ) { 
ftype = "I" ; 
int iftime = ifcast - iftype * 100000 ; 
int ietime = iftime + 100000 ; 
String fff = ST_INCH ( ietime ) ; 
if ( ietime % 100 == 0 ) { 
ftime = fff . substring ( 1 , 4 ) ; 
ftime = fff . substring ( 1 ) ; 
} public static String TI_CDTM ( int idate , int itime ) { 
String dattim ; 
int [ ] idtarr = new int [ 5 ] ; 
idtarr [ 0 ] = idate / 10000 ; 
idtarr [ 1 ] = ( idate - idtarr [ 0 ] * 10000 ) / 100 ; 
idtarr [ 2 ] = idate % 100 ; 
idtarr [ 3 ] = itime / 100 ; 
idtarr [ 4 ] = itime % 100 ; 
dattim = TI_ITOC ( idtarr ) ; 
return dattim ; 
} public static String TI_ITOC ( int [ ] idtarr ) { 
String date , time ; 
int iyear = idtarr [ 0 ] ; 
int imonth = idtarr [ 1 ] ; 
int iday = idtarr [ 2 ] ; 
int ihour = idtarr [ 3 ] ; 
int iminut = idtarr [ 4 ] ; 
iyear = iyear % 100 ; 
int idate = iyear * 10000 + imonth * 100 + iday ; 
int itime = ihour * 100 + iminut ; 
date = StringUtil2 . padZero ( idate , 6 ) ; 
time = StringUtil2 . padZero ( itime , 4 ) ; 
dattim = date + "/" + time ; 
} public static int TI_DAYM ( int iyear , int imon ) { 
int iday = 0 ; 
if ( ( imon > 0 ) && ( imon < 13 ) ) { 
iday = month [ imon - 1 ] ; 
if ( ( imon == 2 ) && LEAP ( iyear ) ) { 
iday = iday + 1 ; 
return iday ; 
} public static String ST_ITOC ( int value ) { 
byte [ ] bval = new byte [ 4 ] ; 
bval [ 0 ] = ( byte ) ( ( value & 0xff000000 ) > > > 24 ) ; 
bval [ 1 ] = ( byte ) ( ( value & 0x00ff0000 ) > > > 16 ) ; 
bval [ 2 ] = ( byte ) ( ( value & 0x0000ff00 ) > > > 8 ) ; 
bval [ 3 ] = ( byte ) ( ( value & 0x000000ff ) ) ; 
return new String ( bval , CDM . utf8Charset ) ; 
} public static String ST_ITOC ( int [ ] values ) { 
for ( int value : values ) { 
sb . append ( ST_ITOC ( value ) ) ; 
} public static String LV_CCRD ( int ivcord ) { 
String vcoord = "" ; 
if ( ( ivcord >= 0 ) && ( ivcord < vertCoords . length ) ) { 
vcoord = vertCoords [ ivcord ] ; 
} else if ( ivcord > 100 ) { 
vcoord = ST_ITOC ( ivcord ) ; 
return vcoord ; 
} public static int [ ] swp4 ( int [ ] values , int startIndex , int number ) { 
for ( int i = startIndex ; i < startIndex + number ; i ++ ) { 
values [ i ] = Integer . reverseBytes ( values [ i ] ) ; 
} public static String getGridPackingName ( int pktyp ) { 
String packingType = "UNKNOWN" ; 
switch ( pktyp ) { 
case GempakConstants . MDGNON : 
packingType = "MDGNON" ; 
case GempakConstants . MDGGRB : 
packingType = "MDGGRB" ; 
case GempakConstants . MDGNMC : 
packingType = "MDGNMC" ; 
case GempakConstants . MDGDIF : 
packingType = "MDGDIF" ; 
case GempakConstants . MDGDEC : 
packingType = "MDGDEC" ; 
case GempakConstants . MDGRB2 : 
packingType = "MDGRB2" ; 
return packingType ; 
} public static String getDataType ( int typrt ) { 
String dataType = "" + typrt ; 
switch ( typrt ) { 
case GempakConstants . MDREAL : 
dataType = "MDREAL" ; 
case GempakConstants . MDINTG : 
dataType = "MDINTG" ; 
case GempakConstants . MDCHAR : 
dataType = "MDCHAR" ; 
case GempakConstants . MDRPCK : 
dataType = "MDRPCK" ; 
case GempakConstants . MDGRID : 
dataType = "MDGRID" ; 
return dataType ; 
} public void readData ( InputStream is , StatusUI statusUI ) 
throws IOException , EOFException , DAP2Exception { 
BufferedInputStream bufferedIS = new BufferedInputStream ( is ) ; 
DataInputStream dataIS = new DataInputStream ( bufferedIS ) ; 
for ( Enumeration e = getVariables ( ) ; e . hasMoreElements ( ) ; ) { 
bt . deserialize ( dataIS , ver , statusUI ) ; 
statusUI . finished ( ) ; 
} private long copy ( InputStream in , OutputStream out ) throws IOException { 
long totalBytesRead = 0 ; 
byte [ ] buffer = new byte [ 8000 ] ; 
int bytesRead = in . read ( buffer ) ; 
totalBytesRead += bytesRead ; 
return totalBytesRead ; 
} public void printVal ( PrintWriter pw ) { 
bt . printVal ( pw , "" , true ) ; 
pw . println ( ) ; 
} public final void externalize ( OutputStream os , boolean compress , boolean headers ) 
if ( headers ) { 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( os , Util . UTF8 ) ) ; 
if ( compress ) { 
OutputStream bufferedOS ; 
bufferedOS = new BufferedOutputStream ( new DeflaterOutputStream ( os ) ) ; 
bufferedOS = new BufferedOutputStream ( os ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( bufferedOS , Util . UTF8 ) ) ; 
print ( pw ) ; 
bufferedOS . write ( "\nData:\n" . getBytes ( CDM . utf8Charset ) ) ; 
bufferedOS . flush ( ) ; 
DataOutputStream dataOS = new DataOutputStream ( bufferedOS ) ; 
bt . externalize ( dataOS ) ; 
dataOS . close ( ) ; 
} public static TagEnum getTag ( short code ) { 
TagEnum te = hash . get ( code ) ; 
if ( te == null ) te = new TagEnum ( "UNKNOWN" , "UNKNOWN" , code ) ; 
return te ; 
String args1 [ ] = new String [ args . length - 1 ] ; 
System . arraycopy ( args , 1 , args1 , 0 , args . length - 1 ) ; 
for ( i = 0 ; i < args . length ; i ++ ) { 
Getopts opts = new Getopts ( args [ 0 ] , args1 ) ; 
Enumeration names = opts . swList ( ) ; 
i = 0 ; 
while ( names . hasMoreElements ( ) ) { 
OptSwitch cs = opts . getSwitch ( ( Character ) names . nextElement ( ) ) ; 
String argp [ ] = opts . argList ( ) ; 
for ( i = 0 ; i < argp . length ; i ++ ) { 
catch ( InvalidSwitch e ) { 
System . out . print ( e ) ; 
} public BufferedImage open ( String location ) throws java . io . IOException { 
log = new StringBuffer ( ) ; 
if ( location . startsWith ( "http:" ) ) { 
URL url = new URL ( location ) ; 
currentFile = null ; 
return javax . imageio . ImageIO . read ( url ) ; 
log . append ( e . getMessage ( ) ) ; 
if ( location . startsWith ( "file:)" ) ) 
location = location . substring ( 5 ) ; 
File f = new File ( location ) ; 
if ( ! f . exists ( ) ) { 
currentFile = f ; 
currentDir = null ; 
return javax . imageio . ImageIO . read ( f ) ; 
} public BufferedImage getNextImage ( boolean forward ) { 
if ( grid != null ) { 
if ( forward ) { 
this . time ++ ; 
if ( this . time >= this . ntimes ) this . time = 0 ; 
this . time -- ; 
if ( this . time < 0 ) this . time = this . ntimes - 1 ; 
data = grid . readDataSlice ( this . time , 0 , - 1 , - 1 ) ; 
return ImageArrayAdapter . makeGrayscaleImage ( data , grid ) ; 
if ( currentFile == null ) 
if ( currentDir == null ) { 
currentDirFileNo = 0 ; 
currentDir = currentFile . getParentFile ( ) ; 
currentDirFileList = new ArrayList < > ( ) ; 
addToList ( currentDir , currentDirFileList ) ; 
for ( int i = 0 ; i < currentDirFileList . size ( ) ; i ++ ) { 
File file = currentDirFileList . get ( i ) ; 
if ( file . equals ( currentFile ) ) 
currentDirFileNo = i ; 
currentDirFileNo ++ ; 
if ( currentDirFileNo >= currentDirFileList . size ( ) ) 
currentDirFileNo -- ; 
if ( currentDirFileNo < 0 ) 
currentDirFileNo = currentDirFileList . size ( ) - 1 ; 
File nextFile = currentDirFileList . get ( currentDirFileNo ) ; 
return javax . imageio . ImageIO . read ( nextFile ) ; 
return getNextImage ( forward ) ; 
} static public int 
size ( DapType type ) 
switch ( type . getTypeSort ( ) ) { 
return 2 ; 
return 4 ; 
return 8 ; 
return size ( ( ( DapEnumeration ) type ) . getBaseType ( ) ) ; 
if ( srcatomtype == dstatomtype ) 
int len = 0 ; 
char [ ] csrc ; 
byte [ ] bsrc ; 
short [ ] shsrc ; 
int [ ] isrc ; 
long [ ] lsrc ; 
float [ ] fsrc ; 
double [ ] dsrc ; 
char [ ] cresult ; 
byte [ ] bresult ; 
short [ ] shresult ; 
int [ ] iresult ; 
long [ ] lresult ; 
float [ ] fresult ; 
double [ ] dresult ; 
BigInteger bi ; 
boolean srcunsigned = srcatomtype . isUnsigned ( ) ; 
boolean dstunsigned = dstatomtype . isUnsigned ( ) ; 
switch ( srcatomtype ) { 
csrc = ( char [ ] ) src ; 
len = csrc . length ; 
switch ( dstatomtype ) { 
result = ( shresult = new short [ len ] ) ; 
for ( i = 0 ; i < len ; i ++ ) { 
shresult [ i ] = ( short ) ( ( ( int ) csrc [ i ] ) & 0xFF ) ; 
result = ( iresult = new int [ len ] ) ; 
iresult [ i ] = ( int ) ( ( ( int ) csrc [ i ] ) & 0xFF ) ; 
result = ( lresult = new long [ len ] ) ; 
lresult [ i ] = ( long ) ( ( ( int ) csrc [ i ] ) & 0xFF ) ; 
result = ( fresult = new float [ len ] ) ; 
fresult [ i ] = ( float ) ( ( ( int ) csrc [ i ] ) & 0xFF ) ; 
result = ( dresult = new double [ len ] ) ; 
dresult [ i ] = ( double ) ( ( ( int ) csrc [ i ] ) & 0xFF ) ; 
ok = false ; 
bsrc = ( byte [ ] ) src ; 
len = bsrc . length ; 
result = ( cresult = new char [ len ] ) ; 
cresult [ i ] = ( char ) ( ( ( int ) bsrc [ i ] ) & 0xFF ) ; 
shresult [ i ] = ( short ) bsrc [ i ] ; 
if ( dstunsigned ) { 
shresult [ i ] &= ( short ) 0xFF ; 
iresult [ i ] = ( int ) bsrc [ i ] ; 
iresult [ i ] &= 0xFF ; 
lresult [ i ] = ( long ) bsrc [ i ] ; 
lresult [ i ] &= 0xFFL ; 
fresult [ i ] = ( float ) bsrc [ i ] ; 
dresult [ i ] = ( double ) bsrc [ i ] ; 
shresult [ i ] = ( short ) ( ( ( int ) bsrc [ i ] ) & 0xFF ) ; 
iresult [ i ] = ( ( int ) bsrc [ i ] ) & 0xFF ; 
lresult [ i ] = ( ( long ) bsrc [ i ] ) & 0xFFL ; 
fresult [ i ] = ( float ) ( ( int ) bsrc [ i ] & 0xFF ) ; 
dresult [ i ] = ( double ) ( ( int ) bsrc [ i ] & 0xFF ) ; 
shsrc = ( short [ ] ) src ; 
len = shsrc . length ; 
cresult [ i ] = ( char ) ( ( ( int ) shsrc [ i ] ) & 0xFF ) ; 
result = ( bresult = new byte [ len ] ) ; 
bresult [ i ] = ( byte ) shsrc [ i ] ; 
iresult [ i ] = ( int ) shsrc [ i ] ; 
iresult [ i ] &= 0xFFFF ; 
lresult [ i ] = ( long ) shsrc [ i ] ; 
lresult [ i ] &= 0xFFFFL ; 
fresult [ i ] = ( float ) shsrc [ i ] ; 
dresult [ i ] = ( double ) shsrc [ i ] ; 
iresult [ i ] = ( ( int ) shsrc [ i ] ) & 0xFFFF ; 
lresult [ i ] = ( ( long ) shsrc [ i ] ) & 0xFFFFL ; 
fresult [ i ] = ( float ) ( ( int ) shsrc [ i ] & 0xFFFF ) ; 
dresult [ i ] = ( double ) ( ( int ) shsrc [ i ] & 0xFFFF ) ; 
isrc = ( int [ ] ) src ; 
len = isrc . length ; 
cresult [ i ] = ( char ) ( isrc [ i ] & 0xFF ) ; 
bresult [ i ] = ( byte ) isrc [ i ] ; 
shresult [ i ] = ( short ) isrc [ i ] ; 
lresult [ i ] = ( long ) isrc [ i ] ; 
fresult [ i ] = ( float ) isrc [ i ] ; 
dresult [ i ] = ( double ) isrc [ i ] ; 
cresult [ i ] = ( char ) ( ( ( int ) isrc [ i ] ) & 0xFF ) ; 
lresult [ i ] &= 0xFFFFFFFFL ; 
fresult [ i ] = ( float ) ( ( int ) isrc [ i ] & 0xFFFF ) ; 
dresult [ i ] = ( double ) ( ( int ) isrc [ i ] & 0xFFFF ) ; 
lsrc = ( long [ ] ) src ; 
len = lsrc . length ; 
cresult [ i ] = ( char ) ( lsrc [ i ] & 0xFF ) ; 
bresult [ i ] = ( byte ) lsrc [ i ] ; 
shresult [ i ] = ( short ) lsrc [ i ] ; 
iresult [ i ] = ( int ) lsrc [ i ] ; 
fresult [ i ] = ( float ) lsrc [ i ] ; 
dresult [ i ] = ( double ) lsrc [ i ] ; 
cresult [ i ] = ( char ) ( lsrc [ i ] & 0xFFL ) ; 
bi = BigInteger . valueOf ( lsrc [ i ] ) ; 
bi = bi . and ( DapUtil . BIG_UMASK64 ) ; 
fresult [ i ] = bi . floatValue ( ) ; 
dresult [ i ] = bi . doubleValue ( ) ; 
fsrc = ( float [ ] ) src ; 
len = fsrc . length ; 
cresult [ i ] = ( char ) ( ( ( int ) fsrc [ i ] ) & 0xFF ) ; 
bresult [ i ] = ( byte ) fsrc [ i ] ; 
if ( fsrc [ i ] < 0 ) { 
shresult [ i ] = ( short ) fsrc [ i ] ; 
iresult [ i ] = ( int ) fsrc [ i ] ; 
BigDecimal bd = new BigDecimal ( fsrc [ i ] ) ; 
lresult [ i ] = bd . toBigInteger ( ) . longValue ( ) ; 
dresult [ i ] = ( double ) fsrc [ i ] ; 
dsrc = ( double [ ] ) src ; 
len = dsrc . length ; 
cresult [ i ] = ( char ) ( ( ( int ) dsrc [ i ] ) & 0xFF ) ; 
bresult [ i ] = ( byte ) dsrc [ i ] ; 
shresult [ i ] = ( short ) dsrc [ i ] ; 
iresult [ i ] = ( int ) dsrc [ i ] ; 
BigDecimal bd = new BigDecimal ( dsrc [ i ] ) ; 
if ( dsrc [ i ] < 0 ) { 
fresult [ i ] = ( float ) dsrc [ i ] ; 
} private static int sumArray ( int [ ] arr ) { 
int sum = 0 ; 
for ( int i = 0 ; i < arr . length ; i ++ ) { 
if ( arr [ i ] <= 0 ) { 
sum += arr [ i ] ; 
return sum ; 
} public void setGrid ( Rectangle2D bbox , double width , double height ) { 
offsetX = bbox . getX ( ) ; 
offsetY = bbox . getY ( ) ; 
countX = Math . min ( nx , ( int ) ( bbox . getWidth ( ) / ( scaleOverlap * width ) ) ) ; 
countY = Math . min ( ny , ( int ) ( bbox . getHeight ( ) / ( scaleOverlap * height ) ) ) ; 
gridWidth = bbox . getWidth ( ) / countX ; 
gridHeight = bbox . getHeight ( ) / countY ; 
} public void setOverlap ( int overlap ) { 
double dover = Math . max ( 0.0 , Math . min ( .01 * overlap , .50 ) ) ; 
scaleOverlap = 1.0 - dover ; 
for ( int y = 0 ; y < countY ; y ++ ) 
for ( int x = 0 ; x < countX ; x ++ ) 
gridArray [ y ] [ x ] . used = false ; 
} public boolean markIfClear ( Rectangle2D rect , Object o ) { 
double centerX = rect . getX ( ) + rect . getWidth ( ) / 2 ; 
double centerY = rect . getY ( ) + rect . getHeight ( ) / 2 ; 
int indexX = ( int ) ( ( centerX - offsetX ) / gridWidth ) ; 
int indexY = ( int ) ( ( centerY - offsetY ) / gridHeight ) ; 
if ( debugMark ) 
if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) 
GridCell gwant = gridArray [ indexY ] [ indexX ] ; 
if ( gwant . used ) 
if ( null != findIntersection ( rect ) ) 
gwant . used = true ; 
gwant . objectBB = rect ; 
gwant . o = o ; 
} public Object findIntersection ( Rectangle2D rect ) { 
for ( int y = Math . max ( 0 , indexY - 1 ) ; y <= Math . min ( countY - 1 , indexY + 1 ) ; y ++ ) { 
for ( int x = Math . max ( 0 , indexX - 1 ) ; x <= Math . min ( countX - 1 , indexX + 1 ) ; x ++ ) { 
GridCell gtest = gridArray [ y ] [ x ] ; 
if ( ! gtest . used ) 
if ( intersectsOverlap ( rect , gtest . objectBB ) ) 
return gtest . o ; 
} public Object findIntersection ( Point2D p ) { 
int indexX = ( int ) ( ( p . getX ( ) - offsetX ) / gridWidth ) ; 
int indexY = ( int ) ( ( p . getY ( ) - offsetY ) / gridHeight ) ; 
if ( gtest . objectBB . contains ( p . getX ( ) , p . getY ( ) ) ) 
} public Object findClosest ( Point2D pt ) { 
Object o = null ; 
int indexX = ( int ) ( ( pt . getX ( ) - offsetX ) / gridWidth ) ; 
int indexY = ( int ) ( ( pt . getY ( ) - offsetY ) / gridHeight ) ; 
if ( debugClosest ) 
return gwant . o ; 
for ( int p = 1 ; p < Math . max ( countX - 1 , countY - 1 ) ; p ++ ) 
if ( null != ( o = findClosestAlongPerimeter ( pt , indexX , indexY , p ) ) ) 
} private Object findClosestAlongPerimeter ( Point2D pt , int centerX , int centerY , int perimeter ) { 
Object closestO = null ; 
double closestD = MAX_DOUBLE ; 
for ( int y = centerY - perimeter ; y <= centerY + perimeter ; y += 2 * perimeter ) 
for ( int x = centerX - perimeter ; x <= centerX + perimeter ; x ++ ) { 
double distance = distanceSq ( pt , x , y ) ; 
if ( distance < closestD ) { 
closestO = gridArray [ y ] [ x ] . o ; 
closestD = distance ; 
for ( int y = centerY - perimeter + 1 ; y <= centerY + perimeter - 1 ; y ++ ) 
for ( int x = centerX - perimeter ; x <= centerX + perimeter ; x += 2 * perimeter ) { 
return closestO ; 
} private double distanceSq ( Point2D pt , int indexX , int indexY ) { 
return MAX_DOUBLE ; 
GridCell gtest = gridArray [ indexY ] [ indexX ] ; 
Rectangle2D rect = gtest . objectBB ; 
double dx = rect . getX ( ) + rect . getWidth ( ) / 2 - pt . getX ( ) ; 
double dy = rect . getY ( ) + rect . getHeight ( ) / 2 - pt . getY ( ) ; 
return ( dx * dx + dy * dy ) ; 
} public void setTrajectoryInfo ( Dimension trajDim , Variable trajVar , 
Dimension timeDim , Variable timeVar , 
Variable latVar , Variable lonVar , Variable elevVar ) 
this . trajDim = trajDim ; 
this . trajVar = trajVar ; 
this . timeDim = timeDim ; 
this . timeVar = timeVar ; 
this . latVar = latVar ; 
this . lonVar = lonVar ; 
this . elevVar = elevVar ; 
this . netcdfDataset . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
Variable latVarInRecVar = this . recordVar . findVariable ( this . latVar . getFullNameEscaped ( ) ) ; 
Attribute latVarUnitsAtt = latVarInRecVar . findAttribute ( "units" ) ; 
if ( latVarUnitsAtt != null && ! latVarUnitsString . equals ( latVarUnitsAtt . getStringValue ( ) ) ) 
latVarInRecVar . addAttribute ( new Attribute ( "units" , latVarUnitsString ) ) ; 
Variable lonVarInRecVar = this . recordVar . findVariable ( this . lonVar . getFullNameEscaped ( ) ) ; 
Attribute lonVarUnitsAtt = lonVarInRecVar . findAttribute ( "units" ) ; 
if ( lonVarUnitsAtt != null && ! lonVarUnitsString . equals ( lonVarUnitsAtt . getStringValue ( ) ) ) 
lonVarInRecVar . addAttribute ( new Attribute ( "units" , lonVarUnitsString ) ) ; 
Attribute elevVarUnitsAtt = elevVarInRecVar . findAttribute ( "units" ) ; 
if ( elevVarUnitsAtt != null && ! elevVarUnitsString . equals ( elevVarUnitsAtt . getStringValue ( ) ) ) 
if ( curVar . getRank ( ) >= 2 && 
Range startPointRange = null ; 
Range endPointRange = null ; 
startPointRange = new Range ( 0 , 0 ) ; 
endPointRange = new Range ( trajectoryNumPoint - 1 , trajectoryNumPoint - 1 ) ; 
catch ( InvalidRangeException e ) 
ioe . initCause ( e ) ; 
throw ( ioe ) ; 
List section0 = new ArrayList ( 1 ) ; 
List section1 = new ArrayList ( 1 ) ; 
section0 . add ( startPointRange ) ; 
section1 . add ( endPointRange ) ; 
Array startTimeArray ; 
Array endTimeArray ; 
startTimeArray = this . timeVar . read ( section0 ) ; 
endTimeArray = this . timeVar . read ( section1 ) ; 
String startTimeString ; 
String endTimeString ; 
if ( this . timeVar . getDataType ( ) . equals ( DataType . DOUBLE ) ) 
else if ( this . timeVar . getDataType ( ) . equals ( DataType . FLOAT ) ) 
else if ( this . timeVar . getDataType ( ) . equals ( DataType . INT ) ) 
throw new IllegalArgumentException ( tmpMsg ) ; 
startDate = DateUnit . getStandardDate ( startTimeString ) ; 
endDate = DateUnit . getStandardDate ( endTimeString ) ; 
trajectoryIds = new ArrayList ( ) ; 
trajectories = new ArrayList ( ) ; 
trajectoriesMap = new HashMap ( ) ; 
Array trajArray = this . trajVar . read ( ) ; 
Index index = trajArray . getIndex ( ) ; 
for ( int i = 0 ; i < trajArray . getSize ( ) ; i ++ ) 
String curTrajId ; 
if ( this . trajVar . getDataType ( ) . equals ( DataType . STRING ) ) 
curTrajId = ( String ) trajArray . getObject ( index . set ( i ) ) ; 
else if ( this . trajVar . getDataType ( ) . equals ( DataType . DOUBLE ) ) 
curTrajId = String . valueOf ( trajArray . getDouble ( index . set ( i ) ) ) ; 
else if ( this . trajVar . getDataType ( ) . equals ( DataType . FLOAT ) ) 
curTrajId = String . valueOf ( trajArray . getFloat ( index . set ( i ) ) ) ; 
else if ( this . trajVar . getDataType ( ) . equals ( DataType . INT ) ) 
curTrajId = String . valueOf ( trajArray . getInt ( index . set ( i ) ) ) ; 
throw new IllegalStateException ( tmpMsg ) ; 
MultiTrajectory curTraj = new MultiTrajectory ( curTrajId , i , trajectoryNumPoint , startDate , endDate , 
this . trajVar , this . timeVar , timeVarUnitsString , 
trajectoryIds . add ( curTrajId ) ; 
trajectories . add ( curTraj ) ; 
trajectoriesMap . put ( curTrajId , curTraj ) ; 
} public static String canonicalURL ( String urlName ) { 
return SCHEME + urlName . substring ( 5 ) ; 
} public static InputStream sendQuery ( HTTPSession session , String remoteURI , String query ) throws IOException { 
StringBuilder sbuff = new StringBuilder ( remoteURI ) ; 
sbuff . append ( "?" ) ; 
sbuff . append ( query ) ; 
HTTPMethod method = HTTPFactory . Get ( session , sbuff . toString ( ) ) ; 
int statusCode = method . execute ( ) ; 
if ( statusCode == 404 ) { 
} else if ( statusCode >= 400 ) { 
InputStream stream = method . getResponseBodyAsStream ( ) ; 
return stream ; 
method . close ( ) ; 
Array eta = readArray ( etaVar , timeIndex ) ; 
Array sigma = readArray ( sVar , timeIndex ) ; 
Array depth = readArray ( depthVar , timeIndex ) ; 
int nz = ( int ) sigma . getSize ( ) ; 
Index sIndex = sigma . getIndex ( ) ; 
double sigmaVal = sigma . getDouble ( sIndex . set ( z ) ) ; 
double etaVal = eta . getDouble ( etaIndex . set ( y , x ) ) ; 
double depthVal = depth . getDouble ( depthIndex . set ( y , x ) ) ; 
height . set ( z , y , x , 
etaVal + sigmaVal * ( depthVal + etaVal ) ) ; 
ArrayDouble . D1 height = new ArrayDouble . D1 ( nz ) ; 
double etaVal = eta . getDouble ( etaIndex . set ( yIndex , xIndex ) ) ; 
double depthVal = depth . getDouble ( depthIndex . set ( yIndex , xIndex ) ) ; 
height . set ( z , etaVal + sigmaVal * ( depthVal + etaVal ) ) ; 
} public static synchronized BaseUnit getOrCreate ( final UnitName id , 
final BaseQuantity baseQuantity ) throws NameException , 
BaseUnit baseUnit ; 
final BaseUnit nameUnit = nameMap . get ( id ) ; 
final BaseUnit quantityUnit = quantityMap . get ( baseQuantity ) ; 
if ( nameUnit != null || quantityUnit != null ) { 
baseUnit = nameUnit != null 
? nameUnit 
: quantityUnit ; 
if ( ( nameUnit != null && ! baseQuantity . equals ( nameUnit 
. getBaseQuantity ( ) ) ) 
|| ( quantityUnit != null && ! id . equals ( quantityUnit 
. getUnitName ( ) ) ) ) { 
throw new UnitExistsException ( 
+ baseUnit + '"' ) ; 
baseUnit = new BaseUnit ( id , baseQuantity ) ; 
quantityMap . put ( baseQuantity , baseUnit ) ; 
nameMap . put ( id , baseUnit ) ; 
return baseUnit ; 
final BaseUnit meter = new BaseUnit ( UnitName . newUnitName ( "meter" , null , 
"m" ) , BaseQuantity . LENGTH ) ; 
. println ( "meter.getBaseQuantity()=" + meter . getBaseQuantity ( ) ) ; 
. println ( "meter.toDerivedUnit(1.)=" + meter . toDerivedUnit ( 1. ) ) ; 
+ meter . toDerivedUnit ( new float [ ] { 2 } , new float [ 1 ] ) [ 0 ] ) ; 
System . out . println ( "meter.fromDerivedUnit(1.)=" 
+ meter . fromDerivedUnit ( 1. ) ) ; 
+ meter . fromDerivedUnit ( new float [ ] { 3 } , new float [ 1 ] ) [ 0 ] ) ; 
System . out . println ( "meter.isCompatible(meter)=" 
+ meter . isCompatible ( meter ) ) ; 
final BaseUnit radian = new BaseUnit ( UnitName . newUnitName ( "radian" , 
null , "rad" ) , BaseQuantity . PLANE_ANGLE ) ; 
System . out . println ( "meter.isCompatible(radian)=" 
+ meter . isCompatible ( radian ) ) ; 
. println ( "meter.isDimensionless()=" + meter . isDimensionless ( ) ) ; 
System . out . println ( "radian.isDimensionless()=" 
+ radian . isDimensionless ( ) ) ; 
} static public CollectionManager open ( String collectionName , String collectionSpec , String olderThan , Formatter errlog ) throws IOException { 
if ( collectionSpec . startsWith ( CATALOG ) ) 
return new CollectionManagerCatalog ( collectionName , collectionSpec , olderThan , errlog ) ; 
return MFileCollectionManager . open ( collectionName , collectionSpec , olderThan , errlog ) ; 
} public void putMetadata ( MFile file , String key , byte [ ] value ) { 
if ( store == null ) initMM ( ) ; 
if ( store != null ) store . put ( file . getPath ( ) + "#" + key , value ) ; 
} static public List < String > getProtocols ( String url ) { 
List < String > allprotocols = new ArrayList < > ( ) ; 
StringBuilder buf = new StringBuilder ( url ) ; 
int slashpos = buf . indexOf ( "/" ) ; 
if ( url . startsWith ( "file:" ) && "/\\" . indexOf ( url . charAt ( 5 ) ) < 0 ) { 
allprotocols . add ( "file" ) ; 
} else if ( slashpos >= 0 ) { 
buf . delete ( slashpos + 1 , buf . length ( ) ) ; 
int index = buf . indexOf ( ":" ) ; 
if ( index < 0 ) break ; 
if ( ! validateprotocol ( url , 0 , index ) ) 
String protocol = buf . substring ( 0 , index ) ; 
allprotocols . add ( protocol ) ; 
buf . delete ( 0 , index + 1 ) ; 
return allprotocols ; 
} static public DatasetUrl findDatasetUrl ( String orgLocation ) throws IOException { 
ServiceType svctype = null ; 
String location = StringUtil2 . replace ( orgLocation . trim ( ) , '\\' , "/" ) ; 
List < String > allprotocols = DatasetUrl . getProtocols ( location ) ; 
String trueurl = location ; 
String leadprotocol ; 
if ( allprotocols . size ( ) == 0 ) { 
leadprotocol = "file" ; 
leadprotocol = allprotocols . get ( 0 ) ; 
String fragment = null ; 
int pos = trueurl . lastIndexOf ( '#' ) ; 
if ( pos >= 0 ) { 
fragment = trueurl . substring ( pos + 1 , trueurl . length ( ) ) ; 
trueurl = trueurl . substring ( 0 , pos ) ; 
pos = location . lastIndexOf ( '?' ) ; 
String query = null ; 
query = trueurl . substring ( pos + 1 , trueurl . length ( ) ) ; 
if ( fragment != null ) 
svctype = searchFragment ( fragment ) ; 
if ( svctype == null ) 
svctype = decodeLeadProtocol ( leadprotocol ) ; 
svctype = searchPath ( trueurl ) ; 
if ( svctype == null ) { 
if ( leadprotocol . equals ( "file" ) ) { 
svctype = decodePathExtension ( trueurl ) ; 
if ( svctype == null && checkIfNcml ( new File ( location ) ) ) { 
svctype = ServiceType . NCML ; 
svctype = disambiguateHttp ( trueurl ) ; 
if ( ( svctype == null || svctype == ServiceType . HTTPServer ) ) { 
if ( checkIfRemoteNcml ( trueurl ) ) { 
if ( svctype == ServiceType . NCML ) { 
trueurl = ( allprotocols . size ( ) == 0 ? "file:" + trueurl : location ) ; 
if ( query != null || fragment != null ) { 
StringBuilder buf = new StringBuilder ( trueurl ) ; 
if ( query != null ) { 
buf . append ( '?' ) ; 
buf . append ( query ) ; 
if ( fragment != null ) { 
buf . append ( '#' ) ; 
buf . append ( fragment ) ; 
trueurl = buf . toString ( ) ; 
return new DatasetUrl ( svctype , trueurl ) ; 
} static private ServiceType searchFragment ( String fragment ) { 
if ( fragment . length ( ) == 0 ) 
Map < String , String > map = parseFragment ( fragment ) ; 
if ( map == null ) return null ; 
String protocol = map . get ( "protocol" ) ; 
if ( protocol == null ) { 
for ( String p : FRAGPROTOCOLS ) { 
if ( map . get ( p ) != null ) { protocol = p ; break ; } 
if ( protocol != null ) { 
if ( protocol . equalsIgnoreCase ( "dap" ) || protocol . equalsIgnoreCase ( "dods" ) ) 
return ServiceType . OPENDAP ; 
if ( protocol . equalsIgnoreCase ( "dap4" ) ) 
return ServiceType . DAP4 ; 
if ( protocol . equalsIgnoreCase ( "cdmremote" ) ) 
return ServiceType . CdmRemote ; 
if ( protocol . equalsIgnoreCase ( "thredds" ) ) 
return ServiceType . THREDDS ; 
if ( protocol . equalsIgnoreCase ( "ncml" ) ) 
return ServiceType . NCML ; 
} static private Map < String , String > parseFragment ( String fragment ) { 
if ( fragment != null && fragment . length ( ) >= 0 ) { 
if ( fragment . charAt ( 0 ) == '#' ) 
fragment = fragment . substring ( 1 ) ; 
for ( String pair : pairs ) { 
switch ( pieces . length ) { 
map . put ( EscapeStrings . unescapeURL ( pieces [ 0 ] ) . toLowerCase ( ) , "true" ) ; 
map . put ( EscapeStrings . unescapeURL ( pieces [ 0 ] ) . toLowerCase ( ) , 
EscapeStrings . unescapeURL ( pieces [ 1 ] ) . toLowerCase ( ) ) ; 
} static private ServiceType searchPath ( String url ) { 
url = url . toLowerCase ( ) ; 
for ( int i = 0 ; i < FRAGPROTOCOLS . length ; i ++ ) { 
String p = FRAGPROTOCOLS [ i ] ; 
if ( url . indexOf ( "/thredds/" + p . toLowerCase ( ) + "/" ) >= 0 ) { 
return FRAGPROTOSVCTYPE [ i ] ; 
} static private ServiceType decodePathExtension ( String path ) { 
if ( path . endsWith ( ".dds" ) || path . endsWith ( ".das" ) || path . endsWith ( ".dods" ) ) 
if ( path . endsWith ( ".dmr" ) || path . endsWith ( ".dap" ) || path . endsWith ( ".dsr" ) ) 
if ( path . endsWith ( ".xml" ) || path . endsWith ( ".ncml" ) ) 
static private ServiceType decodeLeadProtocol ( String protocol ) throws IOException { 
if ( protocol . equals ( "dods" ) ) 
else if ( protocol . equals ( "dap4" ) ) 
else if ( protocol . equals ( "httpserver" ) || protocol . equals ( "nodods" ) ) 
return ServiceType . HTTPServer ; 
else if ( protocol . equals ( CdmRemote . PROTOCOL ) ) 
else if ( protocol . equals ( DataFactory . PROTOCOL ) ) 
static private ServiceType disambiguateHttp ( String location ) throws IOException { 
boolean checkDap2 = false , checkDap4 = false , checkCdmr = false ; 
if ( location . contains ( "cdmremote" ) ) { 
ServiceType result = checkIfCdmr ( location ) ; 
checkCdmr = true ; 
if ( location . contains ( "dodsC" ) ) { 
ServiceType result = checkIfDods ( location ) ; 
checkDap2 = true ; 
if ( location . contains ( "dap4" ) ) { 
ServiceType result = checkIfDap4 ( location ) ; 
checkDap4 = true ; 
if ( ! checkDap2 ) { 
if ( result != null ) 
if ( ! checkDap4 ) { 
if ( ! checkCdmr ) { 
} static private ServiceType checkIfCdmr ( String location ) throws IOException { 
try ( HTTPMethod method = HTTPFactory . Head ( location + "?req=header" ) ) { 
if ( statusCode >= 300 ) { 
if ( statusCode == HttpStatus . SC_UNAUTHORIZED || statusCode == HttpStatus . SC_FORBIDDEN ) 
Header h = method . getResponseHeader ( "Content-Description" ) ; 
if ( ( h != null ) && ( h . getValue ( ) != null ) ) { 
String v = h . getValue ( ) ; 
if ( v . equalsIgnoreCase ( "ncstream" ) ) 
} static private ServiceType checkIfDods ( String location ) throws IOException { 
int len = location . length ( ) ; 
if ( location . endsWith ( ".dds" ) ) 
location = location . substring ( 0 , len - ".dds" . length ( ) ) ; 
if ( location . endsWith ( ".das" ) ) 
location = location . substring ( 0 , len - ".das" . length ( ) ) ; 
if ( location . endsWith ( ".dods" ) ) 
location = location . substring ( 0 , len - ".dods" . length ( ) ) ; 
HTTPMethod method = HTTPFactory . Get ( location + ".dds" ) ) { 
int status = method . execute ( ) ; 
if ( status == 200 ) { 
if ( v . equalsIgnoreCase ( "dods-dds" ) || v . equalsIgnoreCase ( "dods_dds" ) ) 
if ( status == HttpStatus . SC_UNAUTHORIZED || status == HttpStatus . SC_FORBIDDEN ) 
} static private ServiceType checkIfDap4 ( String location ) throws IOException { 
if ( location . endsWith ( ".dap" ) ) 
location = location . substring ( 0 , location . length ( ) - ".dap" . length ( ) ) ; 
else if ( location . endsWith ( ".dmr" ) ) 
location = location . substring ( 0 , location . length ( ) - ".dmr" . length ( ) ) ; 
else if ( location . endsWith ( ".dmr.xml" ) ) 
location = location . substring ( 0 , location . length ( ) - ".dmr.xml" . length ( ) ) ; 
else if ( location . endsWith ( ".dsr" ) ) 
location = location . substring ( 0 , location . length ( ) - ".dsr" . length ( ) ) ; 
try ( HTTPMethod method = HTTPFactory . Get ( location + ".dmr.xml" ) ) { 
Header h = method . getResponseHeader ( "Content-Type" ) ; 
if ( v . startsWith ( "application/vnd.opendap.org" ) ) 
} public long sendData2 ( Variable v , Section section , OutputStream out , NcStreamCompression compress ) throws IOException , InvalidRangeException { 
boolean isVlen = v . isVariableLength ( ) ; 
if ( isVlen ) 
v . read ( section ) ; 
NcStreamDataCol encoder = new NcStreamDataCol ( ) ; 
NcStreamProto . DataCol dataProto = encoder . encodeData2 ( v . getFullName ( ) , isVlen , section , v . read ( section ) ) ; 
size += writeBytes ( out , NcStream . MAGIC_DATA2 ) ; 
byte [ ] datab = dataProto . toByteArray ( ) ; 
size += NcStream . writeVInt ( out , datab . length ) ; 
size += writeBytes ( out , datab ) ; 
} static public String fqnSuffix ( String fqn ) 
int structindex = fqn . lastIndexOf ( '.' ) ; 
int groupindex = fqn . lastIndexOf ( '/' ) ; 
if ( structindex >= 0 ) 
return fqn . substring ( structindex + 1 , fqn . length ( ) ) ; 
return fqn . substring ( groupindex + 1 , fqn . length ( ) ) ; 
} static public String fqnPrefix ( String fqn ) 
return fqn . substring ( 0 , structindex ) ; 
return fqn . substring ( 0 , groupindex ) ; 
locateFile ( String filename , String abspath , boolean wantdir ) 
Deque < String > q = new ArrayDeque < String > ( ) ; 
filename = filename . trim ( ) . replace ( '\\' , '/' ) ; 
abspath = abspath . trim ( ) . replace ( '\\' , '/' ) ; 
if ( filename . charAt ( 0 ) == '/' ) filename = filename . substring ( 1 ) ; 
if ( filename . endsWith ( "/" ) ) filename = filename . substring ( 0 , filename . length ( ) - 1 ) ; 
if ( abspath . endsWith ( "/" ) ) abspath = abspath . substring ( 0 , abspath . length ( ) - 1 ) ; 
q . addFirst ( abspath ) ; 
String currentpath = q . poll ( ) ; 
if ( currentpath == null ) break ; 
File current = new File ( currentpath ) ; 
File [ ] contents = current . listFiles ( ) ; 
for ( File subfile : contents ) { 
if ( ! subfile . getName ( ) . equals ( filename ) ) continue ; 
if ( ( wantdir && subfile . isDirectory ( ) ) 
|| ( ! wantdir && subfile . isFile ( ) ) ) { 
return DapUtil . canonicalpath ( subfile . getAbsolutePath ( ) ) ; 
if ( subfile . isDirectory ( ) ) 
q . addFirst ( currentpath + "/" + subfile . getName ( ) ) ; 
locateRelative ( String relpath , String abspath , boolean wantdir ) 
relpath = relpath . trim ( ) . replace ( '\\' , '/' ) ; 
if ( relpath . charAt ( 0 ) == '/' ) relpath = relpath . substring ( 1 ) ; 
if ( relpath . endsWith ( "/" ) ) relpath = relpath . substring ( 0 , relpath . length ( ) - 1 ) ; 
String [ ] pieces = relpath . split ( "[/]" ) ; 
String partial = abspath ; 
for ( int i = 0 ; i < pieces . length - 1 ; i ++ ) { 
String nextdir = locateFile ( pieces [ i ] , abspath , true ) ; 
if ( nextdir == null ) return null ; 
partial = nextdir ; 
String finalpath = locateFile ( pieces [ pieces . length - 1 ] , partial , wantdir ) ; 
return finalpath ; 
canonicalpath ( String path ) 
if ( path == null ) return null ; 
path = path . trim ( ) ; 
path = path . replace ( '\\' , '/' ) ; 
if ( path . endsWith ( "/" ) ) 
path = path . substring ( 0 , path . length ( ) - 1 ) ; 
boolean abs = ( path . length ( ) > 0 && path . charAt ( 0 ) == '/' ) ; 
if ( abs ) path = path . substring ( 1 ) ; 
if ( DapUtil . hasDriveLetter ( path ) ) { 
path = path . substring ( 0 , 1 ) . toLowerCase ( ) + path . substring ( 1 ) ; 
} else if ( abs ) 
path = "/" + path ; 
} static public byte [ ] extract ( ByteBuffer buf ) 
int len = buf . limit ( ) ; 
byte [ ] bytes = new byte [ len ] ; 
buf . rewind ( ) ; 
buf . get ( bytes ) ; 
return bytes ; 
} static public List < DapVariable > 
getStructurePath ( DapVariable var ) 
List < DapNode > path = var . getPath ( ) ; 
List < DapVariable > structpath = new ArrayList < DapVariable > ( ) ; 
for ( int i = 0 ; i < path . size ( ) ; i ++ ) { 
DapNode node = path . get ( i ) ; 
structpath . add ( ( DapVariable ) node ) ; 
return structpath ; 
nullify ( String path ) 
return ( path != null && path . length ( ) == 0 ? null : path ) ; 
isWhole ( List < Slice > slices , List < DapDimension > dimset ) 
if ( slices . size ( ) != dimset . size ( ) ) 
for ( int i = 0 ; i < slices . size ( ) ; i ++ ) { 
if ( slice . getStride ( ) != 1 || slice . getFirst ( ) != 0 || slice . getCount ( ) != dim . getSize ( ) ) 
join ( String [ ] array , String sep , int from , int upto ) 
if ( sep == null ) sep = "" ; 
if ( from < 0 || upto > array . length ) 
if ( upto <= from ) 
for ( int i = from ; i < upto ; i ++ , first = false ) { 
if ( ! first ) result . append ( sep ) ; 
result . append ( array [ i ] ) ; 
hasDriveLetter ( String path ) 
boolean hasdr = false ; 
if ( path != null && path . length ( ) >= 2 ) { 
hasdr = ( DRIVELETTERS . indexOf ( path . charAt ( 0 ) ) >= 0 && path . charAt ( 1 ) == ':' ) ; 
return hasdr ; 
} static public List < String > 
getProtocols ( String url , int [ ] breakpoint ) 
int protosize = 0 ; 
if ( index == 1 
&& "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" 
. indexOf ( buf . charAt ( 0 ) ) >= 0 ) break ; 
protosize += ( index + 1 ) ; 
if ( buf . indexOf ( "/" ) == 0 ) 
breakpoint [ 0 ] = protosize ; 
indexToSlices ( Index indices , DapVariable template ) 
List < DapDimension > dims = template . getDimensions ( ) ; 
List < Slice > slices = indexToSlices ( indices , dims ) ; 
offsetToSlices ( long offset , DapVariable template ) 
long [ ] dimsizes = DapUtil . getDimSizes ( dims ) ; 
return indexToSlices ( offsetToIndex ( offset , dimsizes ) , template ) ; 
} static public Index 
offsetToIndex ( long offset , long [ ] dimsizes ) 
long [ ] indices = new long [ dimsizes . length ] ; 
for ( int i = dimsizes . length - 1 ; i >= 0 ; i -- ) { 
indices [ i ] = offset % dimsizes [ i ] ; 
offset = ( offset - indices [ i ] ) / dimsizes [ i ] ; 
return new Index ( indices , dimsizes ) ; 
indexToSlices ( Index indices ) 
if ( indices . getRank ( ) == 0 ) 
return Slice . SCALARSLICES ; 
List < Slice > slices = new ArrayList < > ( indices . rank ) ; 
for ( int i = 0 ; i < indices . rank ; i ++ ) { 
long isize = indices . indices [ i ] ; 
slices . add ( new Slice ( isize , isize + 1 , 1 , indices . dimsizes [ i ] ) ) ; 
isContiguous ( List < Slice > slices ) 
for ( Slice sl : slices ) { 
if ( sl . getStride ( ) != 1 ) return false ; 
isSinglePoint ( List < Slice > slices ) 
if ( sl . getCount ( ) != 1 ) return false ; 
slicesToIndex ( List < Slice > slices ) 
long [ ] positions = new long [ slices . size ( ) ] ; 
long [ ] dimsizes = new long [ slices . size ( ) ] ; 
for ( int i = 0 ; i < positions . length ; i ++ ) { 
Slice s = slices . get ( i ) ; 
if ( s . getCount ( ) != 1 ) 
positions [ i ] = s . getFirst ( ) ; 
dimsizes [ i ] = s . getMax ( ) ; 
return new Index ( positions , dimsizes ) ; 
} public DataResult readData ( InputStream is , NetcdfFile ncfile , String location ) throws IOException { 
int bytesRead = NcStream . readFully ( is , b ) ; 
if ( bytesRead < b . length ) 
throw new EOFException ( location ) ; 
if ( NcStream . test ( b , NcStream . MAGIC_DATA ) ) return readData1 ( is , ncfile ) ; 
if ( NcStream . test ( b , NcStream . MAGIC_DATA2 ) ) return readData2 ( is ) ; 
} public StructureDataIterator getStructureIterator ( InputStream is , NetcdfFile ncfile ) throws IOException { 
if ( ! NcStream . readAndTest ( is , NcStream . MAGIC_DATA ) ) 
int psize = NcStream . readVInt ( is ) ; 
byte [ ] dp = new byte [ psize ] ; 
NcStream . readFully ( is , dp ) ; 
NcStreamProto . Data dproto = NcStreamProto . Data . parseFrom ( dp ) ; 
Structure s = ( Structure ) ncfile . findVariable ( dproto . getVarName ( ) ) ; 
ArrayStructureBB . setOffsets ( members ) ; 
ByteOrder bo = NcStream . decodeDataByteOrder ( dproto ) ; 
return new StreamDataIterator ( is , members , bo ) ; 
} private NetcdfFile proto2nc ( NcStreamProto . Header proto , NetcdfFile ncfile ) throws InvalidProtocolBufferException { 
ncfile = new NetcdfFileSubclass ( ) ; 
ncfile . setLocation ( proto . getLocation ( ) ) ; 
if ( proto . getId ( ) . length ( ) > 0 ) ncfile . setId ( proto . getId ( ) ) ; 
if ( proto . getTitle ( ) . length ( ) > 0 ) ncfile . setTitle ( proto . getTitle ( ) ) ; 
NcStreamProto . Group root = proto . getRoot ( ) ; 
NcStream . readGroup ( root , ncfile , ncfile . getRootGroup ( ) ) ; 
} public Document makeDocument ( ) { 
Element rootElem = new Element ( "pointConfig" ) ; 
if ( tableConfigurerClass != null ) 
rootElem . addContent ( new Element ( "tableConfigurer" ) . setAttribute ( "class" , tableConfigurerClass ) ) ; 
if ( tc . featureType != null ) 
rootElem . setAttribute ( "featureType" , tc . featureType . toString ( ) ) ; 
rootElem . addContent ( writeTable ( tc ) ) ; 
} private boolean writeIndex2 ( String bufrFilename , BufrConfig config , File indexFile ) throws IOException { 
if ( indexFile . exists ( ) ) { 
if ( ! indexFile . delete ( ) ) 
try ( RandomAccessFile raf = new RandomAccessFile ( indexFile . getPath ( ) , "rw" ) ) { 
raf . write ( MAGIC_START . getBytes ( CDM . utf8Charset ) ) ; 
raf . writeInt ( version ) ; 
BufrCdmIndexProto . BufrIndex . Builder indexBuilder = BufrCdmIndexProto . BufrIndex . newBuilder ( ) ; 
indexBuilder . setFilename ( bufrFilename ) ; 
root = buildField ( config . getRootConverter ( ) ) ; 
indexBuilder . setRoot ( root ) ; 
indexBuilder . setStart ( config . getStart ( ) ) ; 
indexBuilder . setEnd ( config . getEnd ( ) ) ; 
indexBuilder . setNobs ( config . getNobs ( ) ) ; 
Map < String , BufrConfig . BufrStation > smaps = config . getStationMap ( ) ; 
if ( smaps != null ) { 
List < BufrConfig . BufrStation > stations = new ArrayList < BufrConfig . BufrStation > ( smaps . values ( ) ) ; 
Collections . sort ( stations ) ; 
for ( BufrConfig . BufrStation s : stations ) { 
indexBuilder . addStations ( buildStation ( s ) ) ; 
BufrCdmIndexProto . BufrIndex index = indexBuilder . build ( ) ; 
NcStream . writeVInt ( raf , b . length ) ; 
raf . write ( b ) ; 
} static ArrayDouble factory ( Index index , double [ ] storage ) { 
return new ArrayDouble . D0 ( index , storage ) ; 
return new ArrayDouble . D1 ( index , storage ) ; 
return new ArrayDouble . D2 ( index , storage ) ; 
return new ArrayDouble . D3 ( index , storage ) ; 
return new ArrayDouble . D4 ( index , storage ) ; 
return new ArrayDouble . D5 ( index , storage ) ; 
return new ArrayDouble . D6 ( index , storage ) ; 
return new ArrayDouble . D7 ( index , storage ) ; 
return new ArrayDouble ( index , storage ) ; 
double [ ] ja = ( double [ ] ) javaArray ; 
for ( double aJa : ja ) iter . setDoubleNext ( aJa ) ; 
} public void setStationInfo ( String stnIdVName , String stnDescVName , String stnIndexVName , StationHelper stationHelper ) { 
this . stnIndexVName = stnIndexVName ; 
this . stationHelper = stationHelper ; 
if ( stnIdVName != null ) { 
} public void setShortNames ( String latVName , String lonVName , String altVName , String obsTimeVName , String nomTimeVName ) { 
this . latVName = latVName ; 
this . lonVName = lonVName ; 
this . zcoordVName = altVName ; 
this . obsTimeVName = obsTimeVName ; 
this . nomTimeVName = nomTimeVName ; 
} public PointFeature factory ( StationImpl s , StructureData sdata , int recno ) { 
return new RecordPointObs ( sdata , recno ) ; 
return new RecordStationObs ( s , sdata , recno ) ; 
PrimitiveVector pv = getPrimitiveVector ( ) ; 
if ( pv instanceof BaseTypePrimitiveVector ) { 
BaseTypePrimitiveVector vals = ( BaseTypePrimitiveVector ) pv ; 
ServerMethods sm ; 
int len = vals . getLength ( ) ; 
sm = ( ServerMethods ) vals . getValue ( i ) ; 
( ( BaseType ) sm ) . printVal ( os , "" , false ) ; 
sm = ( ServerMethods ) vals . getValue ( len - 1 ) ; 
} public static boolean read ( InputStream ios , BufrTables . Tables tables ) throws IOException { 
if ( ios == null ) 
if ( tables . b == null ) 
tables . b = new TableB ( "fake" , "fake" ) ; 
if ( tables . d == null ) 
tables . d = new TableD ( "fake" , "fake" ) ; 
HashMap < String , String > number = new HashMap < > ( ) ; 
HashMap < String , String > desc = new HashMap < > ( ) ; 
HashMap < String , String > mnseq = new HashMap < > ( ) ; 
BufferedReader dataIS = new BufferedReader ( new InputStreamReader ( ios , CDM . utf8Charset ) ) ; 
Matcher m ; 
if ( line . contains ( "MNEMONIC" ) ) break ; 
if ( line . contains ( "----" ) ) continue ; 
if ( line . startsWith ( "*" ) ) continue ; 
m = fields3 . matcher ( line ) ; 
if ( m . find ( ) ) { 
String mnu = m . group ( 1 ) . trim ( ) ; 
String fxy = m . group ( 2 ) . trim ( ) ; 
if ( fxy . startsWith ( "3" ) ) { 
number . put ( mnu , fxy ) ; 
} else if ( fxy . startsWith ( "0" ) ) { 
} else if ( fxy . startsWith ( "A" ) ) { 
} else if ( debugTable ) { 
m = fields2 . matcher ( line ) ; 
if ( mnseq . containsKey ( mnu ) ) { 
String value = mnseq . get ( mnu ) ; 
mnseq . put ( mnu , value ) ; 
mnseq . put ( mnu , m . group ( 2 ) ) ; 
for ( Map . Entry < String , String > ent : mnseq . entrySet ( ) ) { 
String seq = ent . getValue ( ) ; 
seq = seq . replaceAll ( "\\>" , "" ) ; 
seq = seq . replaceAll ( "\\}" , "" ) ; 
seq = seq . replaceAll ( "\\)" , "" ) ; 
List < Short > list = new ArrayList < > ( ) ; 
String mn = stoke . nextToken ( ) ; 
if ( mn . charAt ( 1 ) == '-' ) { 
list . add ( Descriptor . getFxy ( mn ) ) ; 
m = ints6 . matcher ( mn ) ; 
String F = mn . substring ( 0 , 1 ) ; 
String X = removeLeading0 ( mn . substring ( 1 , 3 ) ) ; 
String Y = removeLeading0 ( mn . substring ( 3 ) ) ; 
list . add ( Descriptor . getFxy ( F + "-" + X + "-" + Y ) ) ; 
if ( mn . startsWith ( "\"" ) ) { 
int idx = mn . lastIndexOf ( '"' ) ; 
String count = mn . substring ( idx + 1 ) ; 
list . add ( Descriptor . getFxy ( "1-1-" + count ) ) ; 
mn = mn . substring ( 1 , idx ) ; 
if ( mn . startsWith ( "." ) ) { 
String des = mn . substring ( mn . length ( ) - 4 ) ; 
mn = mn . replace ( des , "...." ) ; 
String fxy = number . get ( mn ) ; 
String F = fxy . substring ( 0 , 1 ) ; 
String X = removeLeading0 ( fxy . substring ( 1 , 3 ) ) ; 
String Y = removeLeading0 ( fxy . substring ( 3 ) ) ; 
String fxy = number . get ( ent . getKey ( ) ) ; 
if ( XlocalCutoff > Integer . parseInt ( X ) && YlocalCutoff > Integer . parseInt ( Y ) ) 
short seqX = Short . parseShort ( X . trim ( ) ) ; 
short seqY = Short . parseShort ( Y . trim ( ) ) ; 
tables . d . addDescriptor ( seqX , seqY , ent . getKey ( ) , list ) ; 
list . add ( Descriptor . getFxy ( "1-1-0" ) ) ; 
list . add ( Descriptor . getFxy ( "0-31-2" ) ) ; 
tables . d . addDescriptor ( ( short ) 60 , ( short ) 1 , "" , list ) ; 
list . add ( Descriptor . getFxy ( "0-31-1" ) ) ; 
tables . d . addDescriptor ( ( short ) 60 , ( short ) 2 , "" , list ) ; 
tables . d . addDescriptor ( ( short ) 60 , ( short ) 3 , "" , list ) ; 
list . add ( Descriptor . getFxy ( "0-31-0" ) ) ; 
tables . d . addDescriptor ( ( short ) 60 , ( short ) 4 , "" , list ) ; 
m = fields5 . matcher ( line ) ; 
if ( m . group ( 1 ) . equals ( "" ) ) { 
} else if ( number . containsKey ( m . group ( 1 ) . trim ( ) ) ) { 
String fxy = number . get ( m . group ( 1 ) . trim ( ) ) ; 
String X = fxy . substring ( 1 , 3 ) ; 
String Y = fxy . substring ( 3 ) ; 
String descr = desc . get ( mnu ) ; 
short x = Short . parseShort ( X . trim ( ) ) ; 
short y = Short . parseShort ( Y . trim ( ) ) ; 
if ( XlocalCutoff > x && YlocalCutoff > y ) 
int scale = Integer . parseInt ( m . group ( 2 ) . trim ( ) ) ; 
int refVal = Integer . parseInt ( m . group ( 3 ) . trim ( ) ) ; 
int width = Integer . parseInt ( m . group ( 4 ) . trim ( ) ) ; 
String units = m . group ( 5 ) . trim ( ) ; 
tables . b . addDescriptor ( x , y , scale , refVal , width , mnu , units , descr ) ; 
} private static void readSubCategories ( String fileIn , PrintStream out , String token ) throws IOException { 
System . out . printf ( "%s%n" , fileIn ) ; 
try ( FileInputStream in = new FileInputStream ( fileIn ) ) { 
BufferedReader dataIS = new BufferedReader ( new InputStreamReader ( in , 
CDM . utf8Charset ) ) ; 
int posb = line . indexOf ( "DISCONTINUED" ) ; 
if ( posb > 0 ) continue ; 
int pos = line . indexOf ( token ) ; 
if ( pos < 0 ) continue ; 
System . out . printf ( "%s%n" , line ) ; 
boolean is31 = token . equals ( "031-" ) ; 
String subline = is31 ? line . substring ( pos ) : line . substring ( pos + token . length ( ) ) ; 
String catS = subline . substring ( 0 , pos2 ) ; 
String desc = subline . substring ( pos2 + 1 ) ; 
int cat = Integer . parseInt ( catS . substring ( 0 , 3 ) ) ; 
int subcat = Integer . parseInt ( catS . substring ( 4 , 7 ) ) ; 
desc = StringUtil2 . remove ( desc , '|' ) . trim ( ) ; 
} public HTTPFormBuilder 
add ( String fieldname , String text ) 
if ( fieldname == null || text == null || fieldname . length ( ) == 0 ) 
Field f = new Field ( Sort . TEXT , fieldname , text , null ) ; 
parts . put ( fieldname , f ) ; 
} public FeatureCollectionConfig readConfigFromFile ( String filename ) { 
return readConfig ( doc . getRootElement ( ) ) ; 
} public FeatureCollectionConfig readConfigFromCatalog ( String catalogAndPath ) { 
String catFilename ; 
String fcName = null ; 
int pos = catalogAndPath . indexOf ( "#" ) ; 
catFilename = catalogAndPath . substring ( 0 , pos ) ; 
fcName = catalogAndPath . substring ( pos + 1 ) ; 
catFilename = catalogAndPath ; 
File cat = new File ( catFilename ) ; 
doc = builder . build ( cat ) ; 
List < Element > fcElems = new ArrayList < > ( ) ; 
findFeatureCollection ( doc . getRootElement ( ) , fcName , fcElems ) ; 
if ( fcElems . size ( ) > 0 ) 
return readConfig ( fcElems . get ( 0 ) ) ; 
addDecl ( DapNode newdecl ) 
DapSort newsort = newdecl . getSort ( ) ; 
String newname = newdecl . getShortName ( ) ; 
boolean suppress = false ; 
if ( newsort != DapSort . DIMENSION || newname != null ) { 
for ( DapNode decl : decls ) { 
if ( newsort == decl . getSort ( ) 
&& newname . equals ( decl . getShortName ( ) ) ) 
DapDimension anon = ( DapDimension ) newdecl ; 
assert ( newsort == DapSort . DIMENSION && newname == null ) ; 
for ( DapDimension dim : dimensions ) { 
if ( ! dim . isShared ( ) && dim . getSize ( ) == anon . getSize ( ) ) { 
if ( ! found && ! isTopLevel ( ) ) getDataset ( ) . addDecl ( anon ) ; 
suppress = found || ! isTopLevel ( ) ; 
if ( ! suppress ) { 
decls . add ( newdecl ) ; 
newdecl . setParent ( this ) ; 
switch ( newdecl . getSort ( ) ) { 
super . addAttribute ( ( DapAttribute ) newdecl ) ; 
if ( ! suppress ) 
dimensions . add ( ( DapDimension ) newdecl ) ; 
enums . add ( ( DapEnumeration ) newdecl ) ; 
case ATOMICTYPE : 
compounds . add ( ( DapStructure ) newdecl ) ; 
variables . add ( ( DapVariable ) newdecl ) ; 
if ( this != ( DapGroup ) newdecl ) 
groups . add ( ( DapGroup ) newdecl ) ; 
throw new ClassCastException ( newdecl . getShortName ( ) ) ; 
updateGroups ( List < DapGroup > groups ) 
for ( DapGroup g : groups ) { 
if ( ! this . groups . contains ( g ) ) 
findByFQN ( String fqn , DapSort ... sortset ) 
if ( fqn . charAt ( 0 ) != '/' ) { 
String prefix = this . getFQN ( ) ; 
fqn = prefix + '/' + fqn ; 
return getDataset ( ) . lookup ( fqn , sortset ) ; 
} public DapVariable 
findVariable ( String name ) 
DapNode var = findInGroup ( name , DapSort . VARIABLE ) ; 
return ( DapVariable ) var ; 
} private boolean compareGroups ( Group org , Group copy , ObjFilter filter ) { 
if ( ! org . getShortName ( ) . equals ( copy . getShortName ( ) ) ) { 
ok &= checkDimensions ( org . getDimensions ( ) , copy . getDimensions ( ) ) ; 
ok &= checkDimensions ( copy . getDimensions ( ) , org . getDimensions ( ) ) ; 
ok &= checkAttributes ( null , org . getAttributes ( ) , copy . getAttributes ( ) , filter ) ; 
ok &= checkEnums ( org , copy ) ; 
for ( Variable orgV : org . getVariables ( ) ) { 
Variable copyVar = copy . findVariable ( orgV . getShortName ( ) ) ; 
if ( copyVar == null ) { 
ok &= compareVariables ( orgV , copyVar , filter , compareData , true ) ; 
for ( Variable copyV : copy . getVariables ( ) ) { 
Variable orgV = org . findVariable ( copyV . getShortName ( ) ) ; 
if ( orgV == null ) { 
List groups = new ArrayList ( ) ; 
String name = org . isRoot ( ) ? "root" : org . getFullName ( ) ; 
ok &= checkAll ( name , org . getGroups ( ) , copy . getGroups ( ) , groups ) ; 
for ( int i = 0 ; i < groups . size ( ) ; i += 2 ) { 
Group orgGroup = ( Group ) groups . get ( i ) ; 
Group copyGroup = ( Group ) groups . get ( i + 1 ) ; 
ok &= compareGroups ( orgGroup , copyGroup , filter ) ; 
} private boolean checkAttributes ( Variable v , List < Attribute > list1 , List < Attribute > list2 , ObjFilter filter ) { 
for ( Attribute att1 : list1 ) { 
if ( filter == null || filter . attCheckOk ( v , att1 ) ) 
ok &= checkEach ( name , att1 , "file1" , list1 , "file2" , list2 , null ) ; 
for ( Attribute att2 : list2 ) { 
if ( filter == null || filter . attCheckOk ( v , att2 ) ) 
ok &= checkEach ( name , att2 , "file2" , list2 , "file1" , list1 , null ) ; 
} private boolean checkEnums ( Group org , Group copy ) { 
for ( EnumTypedef enum1 : org . getEnumTypedefs ( ) ) { 
EnumTypedef enum2 = copy . findEnumeration ( enum1 . getShortName ( ) ) ; 
if ( enum2 == null ) { 
if ( ! enum1 . equals ( enum2 ) ) { 
for ( EnumTypedef enum2 : copy . getEnumTypedefs ( ) ) { 
EnumTypedef enum1 = org . findEnumeration ( enum2 . getShortName ( ) ) ; 
if ( enum1 == null ) { 
} private boolean checkAll ( String what , List list1 , List list2 , List result ) { 
for ( Object aList1 : list1 ) { 
ok &= checkEach ( what , aList1 , "file1" , list1 , "file2" , list2 , result ) ; 
for ( Object aList2 : list2 ) { 
ok &= checkEach ( what , aList2 , "file2" , list2 , "file1" , list1 , null ) ; 
} private boolean checkEach ( String what , Object want1 , String name1 , List list1 , String name2 , List list2 , List result ) { 
int index2 = list2 . indexOf ( want1 ) ; 
if ( index2 < 0 ) { 
Object want2 = list2 . get ( index2 ) ; 
int index1 = list1 . indexOf ( want2 ) ; 
if ( index1 < 0 ) { 
Object want = list1 . get ( index1 ) ; 
if ( ! want . equals ( want1 ) ) { 
if ( showEach ) 
result . add ( want1 ) ; 
result . add ( want2 ) ; 
} public static boolean isMine ( String hasName ) { 
if ( hasName . equalsIgnoreCase ( "COARDS" ) ) return true ; 
List < String > names = breakupConventionNames ( hasName ) ; 
if ( name . equalsIgnoreCase ( "COARDS" ) ) return true ; 
} protected AxisType getAxisType ( NetcdfDataset ncDataset , VariableEnhanced v ) { 
String unit = v . getUnitsString ( ) ; 
if ( unit == null ) 
if ( unit . equalsIgnoreCase ( "degrees_east" ) || 
unit . equalsIgnoreCase ( "degrees_E" ) || 
unit . equalsIgnoreCase ( "degreesE" ) || 
unit . equalsIgnoreCase ( "degree_east" ) || 
unit . equalsIgnoreCase ( "degree_E" ) || 
unit . equalsIgnoreCase ( "degreeE" ) ) 
if ( unit . equalsIgnoreCase ( "degrees_north" ) || 
unit . equalsIgnoreCase ( "degrees_N" ) || 
unit . equalsIgnoreCase ( "degreesN" ) || 
unit . equalsIgnoreCase ( "degree_north" ) || 
unit . equalsIgnoreCase ( "degree_N" ) || 
unit . equalsIgnoreCase ( "degreeN" ) ) 
if ( SimpleUnit . isCompatible ( "mbar" , unit ) ) 
return AxisType . Pressure ; 
if ( unit . equalsIgnoreCase ( "level" ) || unit . equalsIgnoreCase ( "layer" ) || unit . equalsIgnoreCase ( "sigma_level" ) ) 
return AxisType . GeoZ ; 
String positive = ncDataset . findAttValueIgnoreCase ( ( Variable ) v , CF . POSITIVE , null ) ; 
if ( SimpleUnit . isCompatible ( "m" , unit ) ) 
public static GribStatType getStatType ( int timeRangeIndicator ) { 
switch ( timeRangeIndicator ) { 
case 51 : 
case 113 : 
case 115 : 
case 120 : 
case 123 : 
return GribStatType . Average ; 
case 116 : 
case 124 : 
return GribStatType . Accumulation ; 
return GribStatType . DifferenceFromEnd ; 
case 118 : 
return GribStatType . Covariance ; 
case 125 : 
return GribStatType . StandardDeviation ; 
} public Optional < HorizCoordSys > subset ( SubsetParams params ) { 
LatLonRect llbb = ( LatLonRect ) params . get ( SubsetParams . latlonBB ) ; 
ProjectionRect projbb = ( ProjectionRect ) params . get ( SubsetParams . projBB ) ; 
LatLonPoint latlon = ( LatLonPoint ) params . get ( SubsetParams . latlonPoint ) ; 
Integer horizStride = ( Integer ) params . get ( SubsetParams . horizStride ) ; 
if ( horizStride == null || horizStride < 1 ) horizStride = 1 ; 
CoverageCoordAxis1D xaxisSubset = null , yaxisSubset = null ; 
CoverageCoordAxis lataxisSubset = null , lonaxisSubset = null ; 
Optional < CoverageCoordAxis > opt ; 
Optional < CoverageCoordAxisBuilder > optb ; 
Formatter errMessages = new Formatter ( ) ; 
if ( latlon != null ) { 
if ( isProjection ) { 
CoordAxisHelper xhelper = new CoordAxisHelper ( xAxis ) ; 
CoordAxisHelper yhelper = new CoordAxisHelper ( yAxis ) ; 
ProjectionImpl proj = transform . getProjection ( ) ; 
ProjectionPoint pp = proj . latLonToProj ( latlon ) ; 
optb = xhelper . subsetContaining ( pp . getX ( ) ) ; 
if ( optb . isPresent ( ) ) xaxisSubset = new CoverageCoordAxis1D ( optb . get ( ) ) ; 
optb = yhelper . subsetContaining ( pp . getY ( ) ) ; 
if ( optb . isPresent ( ) ) yaxisSubset = new CoverageCoordAxis1D ( optb . get ( ) ) ; 
CoordAxisHelper xhelper = new CoordAxisHelper ( lonAxis ) ; 
CoordAxisHelper yhelper = new CoordAxisHelper ( latAxis ) ; 
double lonNormal = LatLonPointImpl . lonNormalFrom ( latlon . getLongitude ( ) , lonAxis . getStartValue ( ) ) ; 
optb = xhelper . subsetContaining ( lonNormal ) ; 
if ( optb . isPresent ( ) ) lonaxisSubset = new CoverageCoordAxis1D ( optb . get ( ) ) ; 
optb = yhelper . subsetContaining ( latlon . getLatitude ( ) ) ; 
if ( optb . isPresent ( ) ) lataxisSubset = new CoverageCoordAxis1D ( optb . get ( ) ) ; 
} else if ( projbb != null ) { 
opt = xAxis . subset ( projbb . getMinX ( ) , projbb . getMaxX ( ) , horizStride ) ; 
if ( opt . isPresent ( ) ) xaxisSubset = ( CoverageCoordAxis1D ) opt . get ( ) ; 
opt = yAxis . subset ( projbb . getMinY ( ) , projbb . getMaxY ( ) , horizStride ) ; 
if ( opt . isPresent ( ) ) yaxisSubset = ( CoverageCoordAxis1D ) opt . get ( ) ; 
} else if ( llbb != null ) { 
LatLonRect full = calcLatLonBoundingBox ( ) ; 
assert full != null ; 
if ( ! full . containedIn ( llbb ) ) { 
ProjectionRect prect = proj . latLonToProjBB ( llbb ) ; 
opt = xAxis . subset ( prect . getMinX ( ) , prect . getMaxX ( ) , horizStride ) ; 
opt = yAxis . subset ( prect . getMinY ( ) , prect . getMaxY ( ) , horizStride ) ; 
opt = subsetLon ( llbb , horizStride ) ; 
if ( opt . isPresent ( ) ) lonaxisSubset = opt . get ( ) ; 
opt = latAxis . subset ( llbb . getLatMin ( ) , llbb . getLatMax ( ) , horizStride ) ; 
if ( opt . isPresent ( ) ) lataxisSubset = opt . get ( ) ; 
} else if ( horizStride > 1 ) { 
opt = xAxis . subsetByIndex ( xAxis . getRange ( ) . setStride ( horizStride ) ) ; 
opt = yAxis . subsetByIndex ( yAxis . getRange ( ) . setStride ( horizStride ) ) ; 
opt = lonAxis . subsetByIndex ( lonAxis . getRange ( ) . setStride ( horizStride ) ) ; 
opt = latAxis . subsetByIndex ( latAxis . getRange ( ) . setStride ( horizStride ) ) ; 
errMessages . format ( "%s;%n" , e . getMessage ( ) ) ; 
String errs = errMessages . toString ( ) ; 
if ( errs . length ( ) > 0 ) 
return Optional . empty ( errs ) ; 
if ( xaxisSubset == null && xAxis != null ) xaxisSubset = ( CoverageCoordAxis1D ) xAxis . copy ( ) ; 
if ( yaxisSubset == null && yAxis != null ) yaxisSubset = ( CoverageCoordAxis1D ) yAxis . copy ( ) ; 
if ( lataxisSubset == null && latAxis != null ) lataxisSubset = latAxis . copy ( ) ; 
if ( lonaxisSubset == null && lonAxis != null ) lonaxisSubset = lonAxis . copy ( ) ; 
return Optional . of ( new HorizCoordSys ( xaxisSubset , yaxisSubset , lataxisSubset , lonaxisSubset , transform ) ) ; 
} private Optional < CoverageCoordAxis > subsetLon ( LatLonRect llbb , int stride ) throws InvalidRangeException { 
double wantMin = LatLonPointImpl . lonNormalFrom ( llbb . getLonMin ( ) , lonAxis . getStartValue ( ) ) ; 
double wantMax = LatLonPointImpl . lonNormalFrom ( llbb . getLonMax ( ) , lonAxis . getStartValue ( ) ) ; 
double start = lonAxis . getStartValue ( ) ; 
double end = lonAxis . getEndValue ( ) ; 
List < MAMath . MinMax > lonIntvs = subsetLonIntervals ( wantMin , wantMax , start , end ) ; 
if ( lonIntvs . size ( ) == 0 ) 
return Optional . empty ( String . format ( 
if ( lonIntvs . size ( ) == 1 ) { 
MAMath . MinMax lonIntv = lonIntvs . get ( 0 ) ; 
return lonAxis . subset ( lonIntv . min , lonIntv . max , stride ) ; 
return lonAxis . subsetByIntervals ( lonIntvs , stride ) ; 
} private List < MAMath . MinMax > subsetLonIntervals ( double wantMin , double wantMax , double start , double end ) { 
if ( wantMin <= wantMax ) { 
if ( wantMin > end && wantMax > end ) 
if ( wantMin < end && wantMax < end ) 
return Lists . newArrayList ( new MAMath . MinMax ( wantMin , wantMax ) ) ; 
if ( wantMin < end && wantMax > end ) 
return Lists . newArrayList ( new MAMath . MinMax ( wantMin , end ) ) ; 
return Lists . newArrayList ( new MAMath . MinMax ( start , end ) ) ; 
if ( wantMin < end && wantMax < end ) { 
return Lists . newArrayList ( new MAMath . MinMax ( wantMin , end ) , new MAMath . MinMax ( start , wantMax ) ) ; 
} public List < RangeIterator > getRanges ( ) { 
List < RangeIterator > result = new ArrayList < > ( ) ; 
result . add ( getYAxis ( ) . getRange ( ) ) ; 
RangeIterator lonRange = getXAxis ( ) . getRangeIterator ( ) ; 
if ( lonRange == null ) lonRange = getXAxis ( ) . getRange ( ) ; 
result . add ( lonRange ) ; 
} public ProjectionRect calcProjectionBoundingBox ( ) { 
if ( ! isProjection ) return null ; 
double minX = Math . min ( xAxis . getCoordEdgeFirst ( ) , xAxis . getCoordEdgeLast ( ) ) ; 
double minY = Math . min ( yAxis . getCoordEdgeFirst ( ) , yAxis . getCoordEdgeLast ( ) ) ; 
double width = Math . abs ( xAxis . getCoordEdgeLast ( ) - xAxis . getCoordEdgeFirst ( ) ) ; 
double height = Math . abs ( yAxis . getCoordEdgeLast ( ) - yAxis . getCoordEdgeFirst ( ) ) ; 
return new ProjectionRect ( new ProjectionPointImpl ( minX , minY ) , width , height ) ; 
} public LatLonRect calcLatLonBoundingBox ( ) { 
for ( LatLonPointNoNormalize boundaryPoint : calcConnectedLatLonBoundaryPoints ( ) ) { 
minLat = Math . min ( minLat , boundaryPoint . getLatitude ( ) ) ; 
minLon = Math . min ( minLon , boundaryPoint . getLongitude ( ) ) ; 
maxLat = Math . max ( maxLat , boundaryPoint . getLatitude ( ) ) ; 
maxLon = Math . max ( maxLon , boundaryPoint . getLongitude ( ) ) ; 
return new LatLonRect ( new LatLonPointImpl ( minLat , minLon ) , new LatLonPointImpl ( maxLat , maxLon ) ) ; 
} public List < LatLonPointNoNormalize > calcConnectedLatLonBoundaryPoints ( int maxPointsInYEdge , int maxPointsInXEdge ) { 
List < LatLonPoint > points ; 
points = calcLatLonBoundaryPointsFromProjection ( maxPointsInYEdge , maxPointsInXEdge ) ; 
} else if ( isLatLon1D ) { 
points = calcLatLon1DBoundaryPoints ( maxPointsInYEdge , maxPointsInXEdge ) ; 
} else if ( isLatLon2D ) { 
points = calcLatLon2DBoundaryPoints ( maxPointsInYEdge , maxPointsInXEdge ) ; 
return connectLatLonPoints ( points ) ; 
} public List < ProjectionPoint > calcProjectionBoundaryPoints ( int maxPointsInYEdge , int maxPointsInXEdge ) { 
if ( ! isProjection ) { 
checkMaxPointsInEdges ( maxPointsInYEdge , maxPointsInXEdge ) ; 
int numYtotal = yAxis . getNcoords ( ) ; 
int numXtotal = xAxis . getNcoords ( ) ; 
int strideY = calcStride ( numYtotal , maxPointsInYEdge ) ; 
int strideX = calcStride ( numXtotal , maxPointsInXEdge ) ; 
List < ProjectionPoint > points = new LinkedList < > ( ) ; 
for ( int i = 0 ; i < numXtotal ; i += strideX ) { 
points . add ( new ProjectionPointImpl ( xAxis . getCoordEdge1 ( i ) , yAxis . getCoordEdgeFirst ( ) ) ) ; 
for ( int j = 0 ; j < numYtotal ; j += strideY ) { 
points . add ( new ProjectionPointImpl ( xAxis . getCoordEdgeLast ( ) , yAxis . getCoordEdge1 ( j ) ) ) ; 
for ( int i = numXtotal - 1 ; i >= 0 ; i -= strideX ) { 
points . add ( new ProjectionPointImpl ( xAxis . getCoordEdge2 ( i ) , yAxis . getCoordEdgeLast ( ) ) ) ; 
for ( int j = numYtotal - 1 ; j >= 0 ; j -= strideY ) { 
points . add ( new ProjectionPointImpl ( xAxis . getCoordEdgeFirst ( ) , yAxis . getCoordEdge2 ( j ) ) ) ; 
assertNotExceedingMaxBoundaryPoints ( points . size ( ) , maxPointsInYEdge , maxPointsInXEdge ) ; 
return points ; 
} public static List < LatLonPointNoNormalize > connectLatLonPoints ( List < LatLonPoint > points ) { 
LinkedList < LatLonPointNoNormalize > connectedPoints = new LinkedList < > ( ) ; 
for ( LatLonPoint point : points ) { 
double curLat = point . getLatitude ( ) ; 
double curLon = point . getLongitude ( ) ; 
if ( ! connectedPoints . isEmpty ( ) ) { 
double prevLon = connectedPoints . getLast ( ) . getLongitude ( ) ; 
curLon = LatLonPointImpl . lonNormal ( curLon , prevLon ) ; 
connectedPoints . add ( new LatLonPointNoNormalize ( curLat , curLon ) ) ; 
return connectedPoints ; 
} public String getLatLonBoundaryAsWKT ( int maxPointsInYEdge , int maxPointsInXEdge ) { 
List < LatLonPointNoNormalize > points = calcConnectedLatLonBoundaryPoints ( maxPointsInYEdge , maxPointsInXEdge ) ; 
StringBuilder sb = new StringBuilder ( "POLYGON((" ) ; 
for ( LatLonPointNoNormalize point : points ) { 
sb . delete ( sb . length ( ) - 2 , sb . length ( ) ) ; 
sb . append ( "))" ) ; 
} static synchronized protected void setDefaults ( Map < Prop , Object > props ) 
props . put ( Prop . HANDLE_AUTHENTICATION , Boolean . TRUE ) ; 
props . put ( Prop . HANDLE_REDIRECTS , Boolean . TRUE ) ; 
props . put ( Prop . ALLOW_CIRCULAR_REDIRECTS , Boolean . TRUE ) ; 
props . put ( Prop . MAX_REDIRECTS , ( Integer ) DFALTREDIRECTS ) ; 
props . put ( Prop . SO_TIMEOUT , ( Integer ) DFALTSOTIMEOUT ) ; 
props . put ( Prop . CONN_TIMEOUT , ( Integer ) DFALTCONNTIMEOUT ) ; 
props . put ( Prop . CONN_REQ_TIMEOUT , ( Integer ) DFALTCONNREQTIMEOUT ) ; 
props . put ( Prop . USER_AGENT , DFALTUSERAGENT ) ; 
} static synchronized public void setGlobalConnectionTimeout ( int timeout ) 
if ( timeout >= 0 ) { 
globalsettings . put ( Prop . CONN_TIMEOUT , ( Integer ) timeout ) ; 
globalsettings . put ( Prop . CONN_REQ_TIMEOUT , ( Integer ) timeout ) ; 
} static synchronized public void 
setGlobalCompression ( String compressors ) 
if ( globalsettings . get ( Prop . COMPRESSION ) != null ) 
removeGlobalCompression ( ) ; 
String compresslist = checkCompressors ( compressors ) ; 
if ( HTTPUtil . nullify ( compresslist ) == null ) 
globalsettings . put ( Prop . COMPRESSION , compresslist ) ; 
HttpResponseInterceptor hrsi ; 
if ( compresslist . contains ( "gzip" ) ) { 
hrsi = new GZIPResponseInterceptor ( ) ; 
rspintercepts . add ( hrsi ) ; 
if ( compresslist . contains ( "deflate" ) ) { 
hrsi = new DeflateResponseInterceptor ( ) ; 
setGlobalCredentials ( Credentials creds , AuthScope scope ) 
assert ( creds != null ) ; 
if ( scope == null ) scope = AuthScope . ANY ; 
CredentialsProvider provider = new BasicCredentialsProvider ( ) ; 
provider . setCredentials ( scope , creds ) ; 
setGlobalCredentialsProvider ( provider , scope ) ; 
} static protected void 
setInterceptors ( HttpClientBuilder cb ) 
for ( HttpRequestInterceptor hrq : reqintercepts ) { 
cb . addInterceptorLast ( hrq ) ; 
for ( HttpResponseInterceptor hrs : rspintercepts ) { 
cb . addInterceptorLast ( hrs ) ; 
for ( HttpRequestInterceptor hrq : dbgreq ) { 
cb . addInterceptorFirst ( hrq ) ; 
for ( HttpResponseInterceptor hrs : dbgrsp ) { 
cb . addInterceptorFirst ( hrs ) ; 
cb . addInterceptorFirst ( CEKILL ) ; 
} public String getSessionID ( ) 
String sid = null ; 
String jsid = null ; 
List < Cookie > cookies = this . sessioncontext . getCookieStore ( ) . getCookies ( ) ; 
if ( cookie . getName ( ) . equalsIgnoreCase ( "sessionid" ) ) 
sid = cookie . getValue ( ) ; 
if ( cookie . getName ( ) . equalsIgnoreCase ( "jsessionid" ) ) 
jsid = cookie . getValue ( ) ; 
return ( sid == null ? jsid : sid ) ; 
} public HTTPSession setMaxRedirects ( int n ) 
if ( n < 0 ) 
throw new IllegalArgumentException ( "setMaxRedirects" ) ; 
localsettings . put ( Prop . MAX_REDIRECTS , n ) ; 
this . cachevalid = false ; 
} public HTTPSession setFollowRedirects ( boolean tf ) 
localsettings . put ( Prop . HANDLE_REDIRECTS , ( Boolean ) tf ) ; 
} public HTTPSession setUseSessions ( boolean tf ) 
localsettings . put ( Prop . USESESSIONS , ( Boolean ) tf ) ; 
} synchronized public void close ( ) 
if ( this . closed ) 
for ( HTTPMethod m : this . methods ) { 
m . close ( ) ; 
methods . clear ( ) ; 
} public HTTPSession setCredentialsProvider ( CredentialsProvider provider , AuthScope scope ) 
if ( provider == null ) 
throw new NullPointerException ( this . getClass ( ) . getName ( ) ) ; 
if ( scope == null ) 
scope = AuthScope . ANY ; 
localcreds . put ( scope , provider ) ; 
} public HTTPSession 
setCredentials ( Credentials creds , AuthScope scope ) 
setCredentialsProvider ( provider , scope ) ; 
} synchronized 
setAuthenticationAndProxy ( HttpClientBuilder cb ) 
cb . setSSLSocketFactory ( ( SSLConnectionSocketFactory ) authcontrols . get ( AuthProp . SSLFACTORY ) ) ; 
AuthScope bestMatch = HTTPAuthUtil . bestmatch ( scope , localcreds . keySet ( ) ) ; 
CredentialsProvider cp = null ; 
if ( bestMatch != null ) { 
cp = localcreds . get ( bestMatch ) ; 
bestMatch = HTTPAuthUtil . bestmatch ( scope , globalcredfactories . keySet ( ) ) ; 
HTTPProviderFactory factory = globalcredfactories . get ( bestMatch ) ; 
cp = factory . getProvider ( bestMatch ) ; 
Credentials proxycreds = null ; 
AuthScope proxyscope = null ; 
String user = ( String ) authcontrols . get ( AuthProp . PROXYUSER ) ; 
String pwd = ( String ) authcontrols . get ( AuthProp . PROXYPWD ) ; 
HttpHost httpproxy = ( HttpHost ) authcontrols . get ( AuthProp . HTTPPROXY ) ; 
HttpHost httpsproxy = ( HttpHost ) authcontrols . get ( AuthProp . HTTPSPROXY ) ; 
if ( user != null && ( httpproxy != null || httpsproxy != null ) ) { 
if ( httpproxy != null ) 
proxyscope = HTTPAuthUtil . hostToAuthScope ( httpproxy ) ; 
proxyscope = HTTPAuthUtil . hostToAuthScope ( httpsproxy ) ; 
proxycreds = new UsernamePasswordCredentials ( user , pwd ) ; 
if ( cp == null && proxycreds != null && proxyscope != null ) { 
cp = new BasicCredentialsProvider ( ) ; 
cp . setCredentials ( proxyscope , proxycreds ) ; 
} else if ( cp != null && proxycreds != null && proxyscope != null ) { 
if ( cp != null ) 
this . sessioncontext . setCredentialsProvider ( cp ) ; 
} public Map < Prop , Object > mergedSettings ( ) 
Map < Prop , Object > merged ; 
merged = HTTPUtil . merge ( globalsettings , localsettings ) ; 
return Collections . unmodifiableMap ( merged ) ; 
} static String getCanonicalURL ( String legalurl ) 
if ( legalurl == null ) return null ; 
int index = legalurl . indexOf ( '?' ) ; 
if ( index >= 0 ) legalurl = legalurl . substring ( 0 , index ) ; 
return HTTPUtil . canonicalpath ( legalurl ) ; 
} static protected synchronized void track ( HTTPSession session ) 
if ( ! TESTING ) throw new UnsupportedOperationException ( ) ; 
if ( sessionList == null ) 
sessionList = new ConcurrentSkipListSet < HTTPSession > ( ) ; 
sessionList . add ( session ) ; 
clearkeystore ( ) 
authcontrols . setReadOnly ( false ) ; 
authcontrols . remove ( AuthProp . KEYSTORE ) ; 
authcontrols . remove ( AuthProp . KEYPASSWORD ) ; 
authcontrols . remove ( AuthProp . TRUSTSTORE ) ; 
authcontrols . remove ( AuthProp . TRUSTPASSWORD ) ; 
authcontrols . setReadOnly ( true ) ; 
rebuildkeystore ( String path , String pwd ) 
KeyStore newks = buildkeystore ( path , pwd ) ; 
authcontrols . put ( AuthProp . KEYSTORE , newks ) ; 
static public void 
setGlobalCredentialsProvider ( AuthScope scope , CredentialsProvider provider ) 
} static protected synchronized void kill ( ) 
if ( sessionList != null ) { 
for ( HTTPSession session : sessionList ) { 
session . close ( ) ; 
sessionList . clear ( ) ; 
connmgr . close ( ) ; 
setGlobalCredentialsProvider ( CredentialsProvider provider , AuthScope scope ) 
HTTPProviderFactory factory = new SingleProviderFactory ( provider ) ; 
setCredentialsProviderFactory ( factory , scope ) ; 
} void validate ( String urlString ) { 
if ( urlString == null ) return ; 
uri = new URI ( urlString ) ; 
catch ( URISyntaxException e ) { 
String contents = getText ( ) ; 
ByteArrayInputStream is = new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) ; 
CatalogBuilder catFactory = new CatalogBuilder ( ) ; 
Catalog cat = catFactory . buildFromLocation ( urlString , null ) ; 
boolean isValid = ! catFactory . hasFatalError ( ) ; 
javax . swing . JOptionPane . showMessageDialog ( this , 
} static public Index factory ( int [ ] shape ) { 
int rank = shape . length ; 
switch ( rank ) { 
return new Index0D ( ) ; 
return new Index1D ( shape ) ; 
return new Index2D ( shape ) ; 
return new Index3D ( shape ) ; 
return new Index4D ( shape ) ; 
return new Index5D ( shape ) ; 
return new Index6D ( shape ) ; 
return new Index7D ( shape ) ; 
return new Index ( shape ) ; 
} static private long computeStrides ( int [ ] shape , int [ ] stride ) { 
long product = 1 ; 
for ( int ii = shape . length - 1 ; ii >= 0 ; ii -- ) { 
final int thisDim = shape [ ii ] ; 
if ( thisDim < 0 ) 
stride [ ii ] = ( int ) product ; 
product *= thisDim ; 
return product ; 
} Index flip ( int index ) { 
if ( ( index < 0 ) || ( index >= rank ) ) 
Index i = ( Index ) this . clone ( ) ; 
if ( shape [ index ] >= 0 ) { 
i . offset += stride [ index ] * ( shape [ index ] - 1 ) ; 
i . stride [ index ] = - stride [ index ] ; 
i . fastIterator = false ; 
i . precalc ( ) ; 
} Index section ( List < Range > ranges ) throws InvalidRangeException { 
if ( ranges . size ( ) != rank ) 
for ( int ii = 0 ; ii < rank ; ii ++ ) { 
Range r = ranges . get ( ii ) ; 
if ( r == Range . VLEN ) 
if ( ( r . first ( ) < 0 ) || ( r . first ( ) >= shape [ ii ] ) ) 
if ( ( r . last ( ) < 0 ) || ( r . last ( ) >= shape [ ii ] ) ) 
int reducedRank = rank ; 
for ( Range r : ranges ) { 
if ( ( r != null ) && ( r . length ( ) == 1 ) ) 
reducedRank -- ; 
Index newindex = Index . factory ( reducedRank ) ; 
newindex . offset = offset ; 
int newDim = 0 ; 
if ( r == null ) { 
newindex . shape [ newDim ] = shape [ ii ] ; 
newindex . stride [ newDim ] = stride [ ii ] ; 
newDim ++ ; 
} else if ( r . length ( ) != 1 ) { 
newindex . shape [ newDim ] = r . length ( ) ; 
newindex . stride [ newDim ] = stride [ ii ] * r . stride ( ) ; 
newindex . offset += stride [ ii ] * r . first ( ) ; 
newindex . size = computeSize ( newindex . shape ) ; 
newindex . fastIterator = fastIterator && ( newindex . size == size ) ; 
newindex . precalc ( ) ; 
return newindex ; 
} Index reduce ( ) { 
Index c = this ; 
for ( int ii = 0 ; ii < rank ; ii ++ ) 
if ( shape [ ii ] == 1 ) { 
Index newc = c . reduce ( ii ) ; 
return newc . reduce ( ) ; 
} Index reduce ( int dim ) { 
if ( ( dim < 0 ) || ( dim >= rank ) ) 
if ( shape [ dim ] != 1 ) 
Index newindex = Index . factory ( rank - 1 ) ; 
if ( ii != dim ) { 
newindex . shape [ count ] = shape [ ii ] ; 
newindex . stride [ count ] = stride [ ii ] ; 
newindex . fastIterator = fastIterator ; 
} Index transpose ( int index1 , int index2 ) { 
if ( ( index1 < 0 ) || ( index1 >= rank ) ) 
if ( ( index2 < 0 ) || ( index2 >= rank ) ) 
Index newIndex = ( Index ) this . clone ( ) ; 
newIndex . stride [ index1 ] = stride [ index2 ] ; 
newIndex . stride [ index2 ] = stride [ index1 ] ; 
newIndex . shape [ index1 ] = shape [ index2 ] ; 
newIndex . shape [ index2 ] = shape [ index1 ] ; 
newIndex . fastIterator = false ; 
newIndex . precalc ( ) ; 
return newIndex ; 
} Index permute ( int [ ] dims ) { 
if ( dims . length != shape . length ) 
for ( int dim : dims ) 
boolean isPermuted = false ; 
for ( int i = 0 ; i < dims . length ; i ++ ) { 
newIndex . stride [ i ] = stride [ dims [ i ] ] ; 
newIndex . shape [ i ] = shape [ dims [ i ] ] ; 
if ( i != dims [ i ] ) isPermuted = true ; 
newIndex . fastIterator = fastIterator && ! isPermuted ; 
} IndexIterator getIndexIterator ( Array maa ) { 
if ( fastIterator ) 
return new IteratorFast ( size , maa ) ; 
return new IteratorImpl ( maa ) ; 
} public int currentElement ( ) { 
int value = offset ; 
if ( shape [ ii ] < 0 ) break ; 
value += current [ ii ] * stride [ ii ] ; 
} public void setCurrentCounter ( int currElement ) { 
currElement -= offset ; 
if ( shape [ ii ] < 0 ) { 
current [ ii ] = - 1 ; 
current [ ii ] = currElement / stride [ ii ] ; 
currElement -= current [ ii ] * stride [ ii ] ; 
set ( current ) ; 
} public Index set ( int [ ] index ) { 
if ( index . length != rank ) 
throw new ArrayIndexOutOfBoundsException ( ) ; 
if ( rank == 0 ) return this ; 
int prefixrank = ( hasvlen ? rank : rank - 1 ) ; 
System . arraycopy ( index , 0 , current , 0 , prefixrank ) ; 
if ( hasvlen ) current [ prefixrank ] = - 1 ; 
} public void setDim ( int dim , int value ) { 
if ( value < 0 || value >= shape [ dim ] ) 
if ( shape [ dim ] >= 0 ) 
current [ dim ] = value ; 
} public Index set ( int v0 , int v1 , int v2 ) { 
setDim ( 0 , v0 ) ; 
setDim ( 1 , v1 ) ; 
setDim ( 2 , v2 ) ; 
StringBuilder sbuff = new StringBuilder ( 100 ) ; 
sbuff . setLength ( 0 ) ; 
sbuff . append ( shape [ ii ] ) ; 
sbuff . append ( stride [ ii ] ) ; 
sbuff . append ( current [ ii ] ) ; 
} public String getTimeIntervalName ( ) { 
int firstValue = - 1 ; 
for ( TimeCoordIntvValue tinv : timeIntervals ) { 
int value = ( tinv . getBounds2 ( ) - tinv . getBounds1 ( ) ) ; 
if ( firstValue < 0 ) firstValue = value ; 
else if ( value != firstValue ) return MIXED_INTERVALS ; 
firstValue = ( firstValue * timeUnit . getValue ( ) ) ; 
return firstValue + "_" + timeUnit . getField ( ) . toString ( ) ; 
public CalendarDateRange makeCalendarDateRange ( ucar . nc2 . time . Calendar cal ) { 
CalendarDateUnit cdu = CalendarDateUnit . of ( cal , timeUnit . getField ( ) , refDate ) ; 
CalendarDate start = cdu . makeCalendarDate ( timeUnit . getValue ( ) * timeIntervals . get ( 0 ) . getBounds2 ( ) ) ; 
CalendarDate end = cdu . makeCalendarDate ( timeUnit . getValue ( ) * timeIntervals . get ( getSize ( ) - 1 ) . getBounds2 ( ) ) ; 
return CalendarDateRange . of ( start , end ) ; 
if ( ! super . init ( fullCheck ) ) { 
if ( ( dmLabel . kftype != MFSN ) && ( dmLabel . kftype != MFSF ) ) { 
} protected boolean readStationsAndTimes ( boolean uniqueTimes ) { 
for ( DMPart apart : parts ) { 
List < GempakParameter > params = makeParams ( apart ) ; 
partParamMap . put ( apart . kprtnm , params ) ; 
dateTimeKeys = getDateTimeKeys ( ) ; 
if ( ( dateTimeKeys == null ) || dateTimeKeys . isEmpty ( ) ) { 
stationKeys = findStationKeys ( ) ; 
if ( ( stationKeys == null ) || stationKeys . isEmpty ( ) ) { 
stations = getStationList ( ) ; 
makeFileSubType ( ) ; 
dates = null ; 
dateList = makeDateList ( uniqueTimes ) ; 
} private List < Key > getDateTimeKeys ( ) { 
Key date = findKey ( DATE ) ; 
Key time = findKey ( TIME ) ; 
if ( ( date == null ) || ( time == null ) 
|| ! date . type . equals ( time . type ) ) { 
List < Key > dt = new ArrayList < > ( 2 ) ; 
dt . add ( date ) ; 
dt . add ( time ) ; 
return dt ; 
} protected List < String > makeDateList ( boolean unique ) { 
Key date = dateTimeKeys . get ( 0 ) ; 
Key time = dateTimeKeys . get ( 1 ) ; 
List < int [ ] > toCheck ; 
if ( date . type . equals ( ROW ) ) { 
toCheck = headers . rowHeaders ; 
toCheck = headers . colHeaders ; 
List < String > fileDates = new ArrayList < > ( ) ; 
for ( int [ ] header : toCheck ) { 
if ( header [ 0 ] != IMISSD ) { 
int idate = header [ date . loc + 1 ] ; 
int itime = header [ time . loc + 1 ] ; 
String dateTime = GempakUtil . TI_CDTM ( idate , itime ) ; 
fileDates . add ( dateTime ) ; 
if ( unique && ! fileDates . isEmpty ( ) ) { 
SortedSet < String > uniqueTimes = 
Collections . synchronizedSortedSet ( new TreeSet < String > ( ) ) ; 
uniqueTimes . addAll ( fileDates ) ; 
fileDates . clear ( ) ; 
fileDates . addAll ( uniqueTimes ) ; 
return fileDates ; 
} private List < GempakParameter > makeParams ( DMPart part ) { 
List < GempakParameter > gemparms = new ArrayList < > ( part . kparms ) ; 
for ( DMParam param : part . params ) { 
String name = param . kprmnm ; 
GempakParameter parm = GempakParameters . getParameter ( name ) ; 
if ( parm == null ) { 
parm = new GempakParameter ( 1 , name , name , "" , 0 ) ; 
gemparms . add ( parm ) ; 
return gemparms ; 
} private List < GempakStation > getStationList ( ) { 
Key slat = findKey ( GempakStation . SLAT ) ; 
if ( slat == null ) { 
if ( slat . type . equals ( ROW ) ) { 
List < GempakStation > fileStations = new ArrayList < > ( ) ; 
GempakStation station = makeStation ( header ) ; 
if ( station != null ) { 
station . setIndex ( i + 1 ) ; 
fileStations . add ( station ) ; 
return fileStations ; 
} private GempakStation makeStation ( int [ ] header ) { 
GempakStation newStation = new GempakStation ( ) ; 
for ( Key key : stationKeys ) { 
int loc = key . loc + 1 ; 
switch ( key . name ) { 
newStation . setSTID ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
newStation . setSTNM ( header [ loc ] ) ; 
newStation . setSLAT ( header [ loc ] ) ; 
newStation . setSLON ( header [ loc ] ) ; 
newStation . setSELV ( header [ loc ] ) ; 
newStation . setSPRI ( header [ loc ] ) ; 
newStation . setSTAT ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
newStation . setCOUN ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
newStation . setSWFO ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
newStation . setWFO2 ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
newStation . setSTD2 ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; 
return newStation ; 
} public List < String > getStationKeyNames ( ) { 
List < String > keys = new ArrayList < > ( ) ; 
if ( ( stationKeys != null ) && ! stationKeys . isEmpty ( ) ) { 
keys . add ( key . name ) ; 
} private List < Key > findStationKeys ( ) { 
Key stid = findKey ( GempakStation . STID ) ; 
Key stnm = findKey ( GempakStation . STNM ) ; 
Key slon = findKey ( GempakStation . SLON ) ; 
Key selv = findKey ( GempakStation . SELV ) ; 
Key stat = findKey ( GempakStation . STAT ) ; 
Key coun = findKey ( GempakStation . COUN ) ; 
Key std2 = findKey ( GempakStation . STD2 ) ; 
Key spri = findKey ( GempakStation . SPRI ) ; 
Key swfo = findKey ( GempakStation . SWFO ) ; 
Key wfo2 = findKey ( GempakStation . WFO2 ) ; 
if ( ( slat == null ) || ( slon == null ) 
|| ! slat . type . equals ( slon . type ) ) { 
String tslat = slat . type ; 
List < Key > stKeys = new ArrayList < > ( ) ; 
stKeys . add ( slat ) ; 
stKeys . add ( slon ) ; 
if ( ( stid != null ) && ! stid . type . equals ( tslat ) ) { 
} else if ( ( stnm != null ) && ! stnm . type . equals ( tslat ) ) { 
} else if ( ( selv != null ) && ! selv . type . equals ( tslat ) ) { 
} else if ( ( stat != null ) && ! stat . type . equals ( tslat ) ) { 
} else if ( ( coun != null ) && ! coun . type . equals ( tslat ) ) { 
} else if ( ( std2 != null ) && ! std2 . type . equals ( tslat ) ) { 
} else if ( ( spri != null ) && ! spri . type . equals ( tslat ) ) { 
} else if ( ( swfo != null ) && ! swfo . type . equals ( tslat ) ) { 
} else if ( ( wfo2 != null ) && ! wfo2 . type . equals ( tslat ) ) { 
if ( stid != null ) { 
stKeys . add ( stid ) ; 
if ( stnm != null ) { 
stKeys . add ( stnm ) ; 
if ( selv != null ) { 
stKeys . add ( selv ) ; 
stKeys . add ( stat ) ; 
if ( coun != null ) { 
stKeys . add ( coun ) ; 
if ( std2 != null ) { 
stKeys . add ( std2 ) ; 
if ( spri != null ) { 
stKeys . add ( spri ) ; 
if ( swfo != null ) { 
stKeys . add ( swfo ) ; 
if ( wfo2 != null ) { 
stKeys . add ( wfo2 ) ; 
return stKeys ; 
} public List < Date > getDates ( ) { 
if ( ( dates == null || dates . isEmpty ( ) ) && ! dateList . isEmpty ( ) ) { 
dates = new ArrayList < > ( dateList . size ( ) ) ; 
dateFmt . setTimeZone ( TimeZone . getTimeZone ( "GMT" ) ) ; 
for ( String dateString : dateList ) { 
Date d = dateFmt . parse ( dateString , new ParsePosition ( 0 ) ) ; 
dates . add ( d ) ; 
return dates ; 
} public void printDates ( ) { 
builder . append ( "\nDates:\n" ) ; 
for ( String date : dateList ) { 
builder . append ( "\t" ) ; 
builder . append ( date ) ; 
builder . append ( "\n" ) ; 
System . out . println ( builder . toString ( ) ) ; 
} public void printStations ( boolean list ) { 
builder . append ( "\nStations:\n" ) ; 
if ( list ) { 
for ( GempakStation station : getStations ( ) ) { 
builder . append ( station ) ; 
builder . append ( getStations ( ) . size ( ) ) ; 
} public int findStationIndex ( String id ) { 
if ( station . getSTID ( ) . equals ( id ) ) { 
return station . getIndex ( ) ; 
} public String getFileType ( ) { 
String type = "Unknown" ; 
switch ( dmLabel . kftype ) { 
case MFSN : 
type = "Sounding" ; 
case MFSF : 
type = "Surface" ; 
if ( ! subType . equals ( "" ) ) { 
return type ; 
} public void indent ( int n ) 
depth += n ; 
if ( depth < 0 ) 
depth = 0 ; 
else if ( depth > MAXDEPTH ) 
depth = MAXDEPTH ; 
} public void setIndent ( int n ) 
depth = n ; 
} public void init ( CEEvaluator ceEval , 
List < AST > nodes ) 
this . ceEval = ceEval ; 
this . clauseFactory = clauseFactory ; 
this . factory = factory ; 
this . sdds = sdds ; 
this . root = this ; 
for ( AST node : nodes ) node . setRoot ( this ) ; 
} public void walkConstraint ( ) 
throws DAP2ServerSideException , DAP2Exception 
if ( projections != null ) 
for ( ASTprojection proj : projections ) { 
proj . walk ( ceEval ) ; 
getCeEval ( ) . markAll ( true ) ; 
if ( selections != null ) 
for ( ASTclause cl : selections ) { 
getCeEval ( ) . appendClause ( cl . translate ( ) ) ; 
} void walk ( CEEvaluator ceEval ) 
throws DAP2ServerSideException , DAP2Exception , 
NoSuchFunctionException , NoSuchVariableException 
if ( fcn != null ) { 
SubClause subclause = fcn . translate ( ) ; 
getCeEval ( ) . appendClause ( subclause ) ; 
Stack components = new Stack ( ) ; 
components = var . collect ( components ) ; 
markStackedVariables ( components ) ; 
} SubClause translate ( ) 
SubClause subclause = null ; 
Vector < SubClause > cvtargs = new Vector < SubClause > ( ) ; 
if ( args != null ) 
for ( ASTvalue arg : args ) 
cvtargs . addElement ( arg . translate ( ) ) ; 
subclause = getClauseFactory ( ) . newBTFunctionClause ( fcnname , cvtargs ) ; 
return subclause ; 
} Stack collect ( Stack components ) 
for ( ASTsegment segment : segments ) { 
components = segment . collect ( components ) ; 
return components ; 
BaseType bt = null ; 
ServerArrayMethods sam = null ; 
components = getSdds ( ) . search ( name , components ) ; 
if ( slices != null && slices . size ( ) > 0 ) { 
bt = ( BaseType ) components . peek ( ) ; 
} catch ( ClassCastException cce ) { 
throw new DAP2Exception ( DAP2Exception . MALFORMED_EXPR , msg ) ; 
DGrid grid = ( ( DGrid ) bt ) ; 
bt = grid . getArray ( ) ; 
sam = ( ServerArrayMethods ) bt ; 
ASTslice slice = slices . get ( i ) ; 
slice . walk ( sam , i ) ; 
bt = grid . getVar ( i + 1 ) ; 
slice . walk ( sam , 0 ) ; 
} else if ( bt instanceof ServerArrayMethods ) { 
} void walk ( ServerArrayMethods sam , int index ) 
throws InvalidDimensionException , SBHException 
sam . setProjection ( index , ( int ) start , ( int ) stride , ( int ) stop ) ; 
if ( constant != null ) { 
subclause = constant . translate ( ) ; 
} else if ( var != null ) { 
subclause = getClauseFactory ( ) . newValueClause ( ( BaseType ) components . pop ( ) , false ) ; 
} else if ( fcn != null ) { 
subclause = fcn . translate ( ) ; 
assert ( false ) ; 
switch ( tag ) { 
case ExprParserConstants . INTCONST : { 
String s = String . format ( "%d" , intvalue ) ; 
DInt32 i = getFactory ( ) . newDInt32 ( s ) ; 
i . setValue ( ( int ) intvalue ) ; 
( ( ServerMethods ) i ) . setRead ( true ) ; 
( ( ServerMethods ) i ) . setProject ( true ) ; 
subclause = getClauseFactory ( ) . newValueClause ( i , false ) ; 
case ExprParserConstants . FLOATCONST : { 
String s = String . format ( "%.1f" , floatvalue ) ; 
DFloat64 f = getFactory ( ) . newDFloat64 ( s ) ; 
f . setValue ( floatvalue ) ; 
subclause = getClauseFactory ( ) . newValueClause ( f , false ) ; 
case ExprParserConstants . STRINGCONST : { 
DString s = getFactory ( ) . newDString ( text ) ; 
s . setValue ( text ) ; 
( ( ServerMethods ) s ) . setRead ( true ) ; 
( ( ServerMethods ) s ) . setProject ( true ) ; 
subclause = getClauseFactory ( ) . newValueClause ( s , false ) ; 
} public Clause translate ( ) 
Clause clause = null ; 
if ( boolfcn != null ) 
clause = boolfcn . translate ( ) ; 
Vector < SubClause > cvtrhs = new Vector < SubClause > ( ) ; 
for ( ASTvalue v : rhs ) cvtrhs . addElement ( v . translate ( ) ) ; 
SubClause lhsclause = lhs . translate ( ) ; 
clause = getClauseFactory ( ) . newRelOpClause ( operator , lhsclause , cvtrhs ) ; 
return clause ; 
} public void setVariable ( Variable v ) throws IOException { 
AbstractIntervalXYDataset dataset = null ; 
Dimension dim = v . getDimension ( 0 ) ; 
String dimName = dim . getShortName ( ) ; 
Attribute title = file . findGlobalAttribute ( "title" ) ; 
if ( title != null ) 
chart . setTitle ( title . getStringValue ( ) ) ; 
Variable varXdim = file . findVariable ( null , dimName ) ; 
boolean hasXdim = false ; 
if ( varXdim != null ) 
hasXdim = true ; 
boolean xIsTime = false ; 
XYPlot p = chart . getXYPlot ( ) ; 
if ( hasXdim ) 
Attribute xUnit = varXdim . findAttribute ( "units" ) ; 
Attribute xAxis = varXdim . findAttribute ( "axis" ) ; 
if ( xUnit != null ) 
if ( xUnit . getStringValue ( ) . contains ( "since" ) ) 
xIsTime = true ; 
if ( xAxis != null ) 
if ( xAxis . getStringValue ( ) . equals ( "T" ) ) 
p . getDomainAxis ( ) . setLabel ( xUnit . getStringValue ( ) ) ; 
p . getDomainAxis ( ) . setLabel ( dimName ) ; 
int ax = 0 ; 
if ( p . getDatasetCount ( ) >= 1 ) 
if ( p . getDataset ( p . getDatasetCount ( ) - 1 ) != null ) 
ax = p . getDatasetCount ( ) ; 
if ( ax > 0 ) 
p . setRangeAxis ( ax , new NumberAxis ( ) ) ; 
final XYItemRenderer renderer = p . getRenderer ( ) ; 
if ( xIsTime ) 
final StandardXYToolTipGenerator g = new StandardXYToolTipGenerator ( StandardXYToolTipGenerator . DEFAULT_TOOL_TIP_FORMAT , new SimpleDateFormat ( "d-MMM-yyyy" ) , new DecimalFormat ( "0.00" ) ) ; 
renderer . setBaseToolTipGenerator ( g ) ; 
dataset = new TimeSeriesCollection ( ) ; 
final StandardXYToolTipGenerator g = new StandardXYToolTipGenerator ( StandardXYToolTipGenerator . DEFAULT_TOOL_TIP_FORMAT , new DecimalFormat ( "0.00" ) , new DecimalFormat ( "0.00" ) ) ; 
dataset = new XYSeriesCollection ( ) ; 
p . setDomainAxis ( new NumberAxis ( ) ) ; 
p . getRangeAxis ( ax ) . setAutoRange ( true ) ; 
Attribute vUnit = v . findAttribute ( "units" ) ; 
Attribute vfill = v . findAttribute ( "_FillValue" ) ; 
double dfill = Double . NaN ; 
if ( vfill != null ) 
dfill = vfill . getNumericValue ( ) . doubleValue ( ) ; 
if ( vUnit != null ) 
p . getRangeAxis ( ax ) . setLabel ( vUnit . getStringValue ( ) ) ; 
NetcdfDataset fds = new NetcdfDataset ( file ) ; 
CoordinateAxis1DTime tm = null ; 
List < CalendarDate > dates = null ; 
Array varXarray = null ; 
varXarray = varXdim . read ( ) ; 
tm = CoordinateAxis1DTime . factory ( fds , new VariableDS ( null , varXdim , true ) , null ) ; 
dates = tm . getCalendarDates ( ) ; 
Array a = v . read ( ) ; 
Index idx = a . getIndex ( ) ; 
idx . setCurrentCounter ( 0 ) ; 
int d2 = 1 ; 
int rank = idx . getRank ( ) ; 
for ( int k = 1 ; k < rank ; k ++ ) { 
d2 *= idx . getShape ( k ) ; 
double max = - 1000 ; 
double min = 1000 ; 
for ( int j = 0 ; j < d2 ; j ++ ) { 
if ( rank > 1 ) 
idx . set1 ( j ) ; 
if ( d2 > 1 ) 
name += "-" + j ; 
Series s1 ; 
s1 = new TimeSeries ( name ) ; 
s1 = new XYSeries ( name ) ; 
for ( int i = 0 ; i < idx . getShape ( 0 ) ; i ++ ) { 
idx . set0 ( i ) ; 
float f = a . getFloat ( idx ) ; 
if ( f != dfill ) { 
if ( ! Float . isNaN ( f ) ) 
max = Math . max ( max , f ) ; 
min = Math . min ( min , f ) ; 
Date ts = new Date ( dates . get ( i ) . getMillis ( ) ) ; 
( ( TimeSeries ) s1 ) . addOrUpdate ( new Second ( ts ) , f ) ; 
else if ( hasXdim ) 
( ( XYSeries ) s1 ) . addOrUpdate ( varXarray . getDouble ( i ) , f ) ; 
( ( XYSeries ) s1 ) . addOrUpdate ( i , f ) ; 
if ( dataset instanceof TimeSeriesCollection ) 
( ( TimeSeriesCollection ) dataset ) . addSeries ( ( TimeSeries ) s1 ) ; 
if ( dataset instanceof XYSeriesCollection ) 
( ( XYSeriesCollection ) dataset ) . addSeries ( ( XYSeries ) s1 ) ; 
final XYLineAndShapeRenderer renderer1 = new XYLineAndShapeRenderer ( true , false ) ; 
p . setRenderer ( ax , renderer1 ) ; 
p . setDataset ( ax , dataset ) ; 
p . mapDatasetToRangeAxis ( ax , ax ) ; 
p . getRangeAxis ( ax ) . setLowerBound ( min ) ; 
p . getRangeAxis ( ax ) . setUpperBound ( max ) ; 
public void setBounds ( Rectangle r ) { 
Rectangle screenSize = ScreenUtils . getScreenVirtualSize ( ) ; 
Rectangle result = r . intersection ( screenSize ) ; 
if ( ! result . isEmpty ( ) ) 
super . setBounds ( result ) ; 
} public static GribIndex readOrCreateIndexFromSingleFile ( boolean isGrib1 , MFile mfile , CollectionUpdateType force , org . slf4j . Logger logger ) throws IOException { 
GribIndex index = isGrib1 ? new Grib1Index ( ) : new Grib2Index ( ) ; 
if ( ! index . readIndex ( mfile . getPath ( ) , mfile . getLastModified ( ) , force ) ) { 
index . makeIndex ( mfile . getPath ( ) , null ) ; 
} else if ( debug ) { 
} static public MFileCollectionManager open ( String collectionName , String collectionSpec , String olderThan , Formatter errlog ) throws IOException { 
return new MFileCollectionManager ( collectionName , collectionSpec , olderThan , errlog ) ; 
} public void addDirectoryScan ( String dirName , String suffix , String regexpPatternString , String subdirsS , String olderS , Object auxInfo ) { 
CompositeMFileFilter filters = new CompositeMFileFilter ( ) ; 
if ( null != regexpPatternString ) 
filters . addIncludeFilter ( new RegExpMatchOnName ( regexpPatternString ) ) ; 
else if ( suffix != null ) 
filters . addIncludeFilter ( new WildcardMatchOnPath ( "*" + suffix + "$" ) ) ; 
if ( olderS != null ) { 
TimeDuration tu = new TimeDuration ( olderS ) ; 
filters . addAndFilter ( new LastModifiedLimit ( ( long ) ( 1000 * tu . getValueInSeconds ( ) ) ) ) ; 
boolean wantSubdirs = true ; 
if ( ( subdirsS != null ) && subdirsS . equalsIgnoreCase ( "false" ) ) 
wantSubdirs = false ; 
CollectionConfig mc = new CollectionConfig ( dirName , dirName , wantSubdirs , filters , auxInfo ) ; 
StringBuilder sb = new StringBuilder ( dirName ) ; 
if ( wantSubdirs ) 
sb . append ( "**/" ) ; 
sb . append ( regexpPatternString ) ; 
sb . append ( suffix ) ; 
sb . append ( "noFilter" ) ; 
collectionName = sb . toString ( ) ; 
scanList . add ( mc ) ; 
public boolean isScanNeeded ( ) { 
if ( recheck == null ) { 
if ( ! hasScans ( ) ) { 
if ( map == null && ! isStatic ( ) ) { 
Date now = new Date ( ) ; 
Date lastCheckedDate = new Date ( getLastScanned ( ) ) ; 
Date need = recheck . add ( lastCheckedDate ) ; 
if ( now . before ( need ) ) { 
} private boolean scanFirstTime ( ) throws IOException { 
Map < String , MFile > newMap = new HashMap < > ( ) ; 
map = newMap ; 
reallyScan ( newMap ) ; 
if ( olderThanInMsecs > 0 ) { 
long olderThan = System . currentTimeMillis ( ) - olderThanInMsecs ; 
Iterator < MFile > iter = newMap . values ( ) . iterator ( ) ; 
MFile newFile = iter . next ( ) ; 
String path = newFile . getPath ( ) ; 
if ( newFile . getLastModified ( ) > olderThan ) { 
this . lastScanned = System . currentTimeMillis ( ) ; 
this . lastChanged . set ( this . lastScanned ) ; 
return map . keySet ( ) . size ( ) > 0 ; 
} public static void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlags ) { 
debug = debugFlags . isSet ( "ncfileWriter2/debug" ) ; 
debugWrite = debugFlags . isSet ( "ncfileWriter2/debugWrite" ) ; 
debugChunk = debugFlags . isSet ( "ncfileWriter2/debugChunk" ) ; 
} public Variable addVariable ( Variable oldVar ) { 
List < Dimension > newDims = getNewDimensions ( oldVar ) ; 
Variable newVar ; 
if ( ( oldVar . getDataType ( ) . equals ( DataType . STRING ) ) && ( ! version . isExtendedModel ( ) ) ) { 
newVar = writer . addStringVariable ( null , oldVar , newDims ) ; 
newVar = writer . addVariable ( null , oldVar . getShortName ( ) , oldVar . getDataType ( ) , newDims ) ; 
varMap . put ( oldVar , newVar ) ; 
varList . add ( oldVar ) ; 
for ( Attribute orgAtt : oldVar . getAttributes ( ) ) 
writer . addVariableAttribute ( newVar , convertAttribute ( orgAtt ) ) ; 
return newVar ; 
} public NetcdfFile write ( CancelTask cancel ) throws IOException { 
if ( version . isExtendedModel ( ) ) 
addGroupExtended ( null , fileIn . getRootGroup ( ) ) ; 
addGroupClassic ( ) ; 
if ( cancel != null && cancel . isCancel ( ) ) return null ; 
writer . create ( ) ; 
double total = copyVarData ( varList , null , cancel ) ; 
writer . abort ( ) ; 
return writer . getNetcdfFile ( ) ; 
if ( records . length <= recno ) { 
FieldSet [ ] newrecs = new FieldSet [ ( int ) recno + 1 ] ; 
System . arraycopy ( records , 0 , newrecs , 0 , records . length ) ; 
records = newrecs ; 
FieldSet fs = records [ ( int ) recno ] ; 
if ( fs == null ) { 
records [ ( int ) recno ] = ( fs = new FieldSet ( this . nmembers ) ) ; 
getAtomicArray ( int index , StructureMembers . Member m ) 
Array dd = memberArray ( index , CDMArrayStructure . memberIndex ( m ) ) ; 
if ( dd . getDataType ( ) != DataType . STRUCTURE && dd . getDataType ( ) != DataType . SEQUENCE ) 
return ( CDMArrayAtomic ) dd ; 
} public String writeXML ( ) { 
return fmt . outputString ( makeDocument ( ) ) ; 
Element rootElem = new Element ( "netcdfDatasetInfo" ) ; 
rootElem . setAttribute ( "location" , ds . getLocation ( ) ) ; 
rootElem . addContent ( new Element ( "convention" ) . setAttribute ( "name" , getConventionUsed ( ) ) ) ; 
int nDataVariables = 0 ; 
int nOtherVariables = 0 ; 
List < CoordinateAxis > axes = ds . getCoordinateAxes ( ) ; 
int nCoordAxes = axes . size ( ) ; 
Element axisElem = new Element ( "axis" ) ; 
rootElem . addContent ( axisElem ) ; 
axisElem . setAttribute ( "name" , axis . getFullName ( ) ) ; 
axisElem . setAttribute ( "decl" , getDecl ( axis ) ) ; 
if ( axis . getAxisType ( ) != null ) 
axisElem . setAttribute ( "type" , axis . getAxisType ( ) . toString ( ) ) ; 
if ( axis . getUnitsString ( ) != null ) { 
axisElem . setAttribute ( CDM . UNITS , axis . getUnitsString ( ) ) ; 
axisElem . setAttribute ( "udunits" , isUdunits ( axis . getUnitsString ( ) ) ) ; 
if ( axis instanceof CoordinateAxis1D ) { 
CoordinateAxis1D axis1D = ( CoordinateAxis1D ) axis ; 
if ( axis1D . isRegular ( ) ) 
axisElem . setAttribute ( "regular" , ucar . unidata . util . Format . d ( axis1D . getIncrement ( ) , 5 ) ) ; 
List < CoordinateSystem > csList = ds . getCoordinateSystems ( ) ; 
for ( CoordinateSystem cs : csList ) { 
Element csElem ; 
if ( GridCoordSys . isGridCoordSys ( null , cs , null ) ) { 
GridCoordSys gcs = new GridCoordSys ( cs , null ) ; 
csElem = new Element ( "gridCoordSystem" ) ; 
csElem . setAttribute ( "name" , cs . getName ( ) ) ; 
csElem . setAttribute ( "horizX" , gcs . getXHorizAxis ( ) . getFullName ( ) ) ; 
csElem . setAttribute ( "horizY" , gcs . getYHorizAxis ( ) . getFullName ( ) ) ; 
if ( gcs . hasVerticalAxis ( ) ) 
csElem . setAttribute ( "vertical" , gcs . getVerticalAxis ( ) . getFullName ( ) ) ; 
if ( gcs . hasTimeAxis ( ) ) 
csElem . setAttribute ( "time" , cs . getTaxis ( ) . getFullName ( ) ) ; 
csElem = new Element ( "coordSystem" ) ; 
List < CoordinateTransform > coordTransforms = cs . getCoordinateTransforms ( ) ; 
for ( CoordinateTransform ct : coordTransforms ) { 
csElem . addContent ( ctElem ) ; 
ctElem . setAttribute ( "type" , ct . getTransformType ( ) . toString ( ) ) ; 
rootElem . addContent ( csElem ) ; 
List < CoordinateTransform > coordTransforms = ds . getCoordinateTransforms ( ) ; 
rootElem . addContent ( ctElem ) ; 
for ( Parameter pp : params ) { 
Element ppElem = new Element ( "param" ) ; 
ctElem . addContent ( ppElem ) ; 
ppElem . setAttribute ( "name" , pp . getName ( ) ) ; 
ppElem . setAttribute ( "value" , pp . getStringValue ( ) ) ; 
for ( Variable var : ds . getVariables ( ) ) { 
VariableEnhanced ve = ( VariableEnhanced ) var ; 
if ( ve instanceof CoordinateAxis ) continue ; 
GridCoordSys gcs = getGridCoordSys ( ve ) ; 
if ( null != gcs ) { 
nDataVariables ++ ; 
Element gridElem = new Element ( "grid" ) ; 
rootElem . addContent ( gridElem ) ; 
gridElem . setAttribute ( "name" , ve . getFullName ( ) ) ; 
gridElem . setAttribute ( "decl" , getDecl ( ve ) ) ; 
if ( ve . getUnitsString ( ) != null ) { 
gridElem . setAttribute ( CDM . UNITS , ve . getUnitsString ( ) ) ; 
gridElem . setAttribute ( "udunits" , isUdunits ( ve . getUnitsString ( ) ) ) ; 
gridElem . setAttribute ( "coordSys" , gcs . getName ( ) ) ; 
if ( null == gcs ) { 
nOtherVariables ++ ; 
Element elem = new Element ( "variable" ) ; 
rootElem . addContent ( elem ) ; 
elem . setAttribute ( "name" , ve . getFullName ( ) ) ; 
elem . setAttribute ( "decl" , getDecl ( ve ) ) ; 
elem . setAttribute ( CDM . UNITS , ve . getUnitsString ( ) ) ; 
elem . setAttribute ( "udunits" , isUdunits ( ve . getUnitsString ( ) ) ) ; 
elem . setAttribute ( "coordSys" , getCoordSys ( ve ) ) ; 
if ( nDataVariables > 0 ) { 
if ( nOtherVariables > 0 ) 
if ( nCoordAxes == 0 ) 
String userAdvice = getUserAdvice ( ) ; 
if ( userAdvice . length ( ) > 0 ) { 
StringTokenizer toker = new StringTokenizer ( userAdvice , "\n" ) ; 
while ( toker . hasMoreTokens ( ) ) 
rootElem . addContent ( new Element ( "userAdvice" ) . addContent ( toker . nextToken ( ) ) ) ; 
String url = "C:/data/badmodels/RUC_CONUS_80km_20051211_1900.nc" ; 
try ( NetcdfDatasetInfo info = new NetcdfDatasetInfo ( url ) ) { 
String infoString = info . writeXML ( ) ; 
} public static void marshalPointDataset ( FeatureDatasetPoint fdPoint , OutputStream outputStream ) 
throws IOException , XmlException { 
marshalPointDataset ( fdPoint , fdPoint . getDataVariables ( ) , outputStream ) ; 
} public static void validate ( XmlObject doc , boolean strict ) throws XmlException { 
Set < XmlError > validationErrors = new HashSet < > ( ) ; 
XmlOptions validationOptions = new XmlOptions ( ) ; 
validationOptions . setErrorListener ( validationErrors ) ; 
final boolean isValid = doc . validate ( validationOptions ) ; 
if ( ! isValid && ! strict ) { 
validationErrors = filterToOnlySerious ( validationErrors ) ; 
if ( ! validationErrors . isEmpty ( ) ) { 
throw new XmlException ( createErrorMessage ( validationErrors ) ) ; 
public String toConstraintString ( ) 
buf . append ( "[" ) ; 
for ( Slice sub : this . subslices ) { 
if ( ! first ) buf . append ( "," ) ; 
if ( ( sub . stop - sub . first ) == 0 ) { 
buf . append ( "0" ) ; 
} else if ( sub . stride == 1 ) { 
if ( ( sub . stop - sub . first ) == 1 ) 
buf . append ( sub . first ) ; 
buf . append ( String . format ( "%d:%d" , sub . first , sub . stop - 1 ) ) ; 
buf . append ( String . format ( "%d:%d:%d" , sub . first , sub . stride , sub . stop - 1 ) ) ; 
buf . append ( "]" ) ; 
public Structure select ( List < String > memberNames ) { 
StructureDS result = new StructureDS ( getParentGroup ( ) , orgVar ) ; 
List < Variable > members = new ArrayList < > ( ) ; 
for ( String name : memberNames ) { 
Variable m = findVariable ( name ) ; 
if ( null != m ) members . add ( m ) ; 
result . setMemberVariables ( members ) ; 
result . isSubset = true ; 
} public void setOriginalVariable ( ucar . nc2 . Variable orgVar ) { 
if ( ! ( orgVar instanceof Structure ) ) 
this . orgVar = ( Structure ) orgVar ; 
if ( hasCachedData ( ) ) 
result = super . reallyRead ( client , cancelTask ) ; 
else if ( orgVar != null ) 
result = orgVar . read ( ) ; 
return convert ( result , null ) ; 
if ( section . computeSize ( ) == getSize ( ) ) 
result = super . reallyRead ( client , section , cancelTask ) ; 
result = orgVar . read ( section ) ; 
return convert ( result , section ) ; 
} private boolean convertNeeded ( StructureMembers smData ) { 
if ( v instanceof VariableDS ) { 
VariableDS vds = ( VariableDS ) v ; 
if ( vds . needConvert ( ) ) 
} else if ( v instanceof StructureDS ) { 
StructureDS nested = ( StructureDS ) v ; 
if ( nested . convertNeeded ( null ) ) 
if ( ( smData != null ) && ! varHasData ( v , smData ) ) 
} protected ArrayStructure convert ( Array data , Section section ) throws IOException { 
ArrayStructure orgAS = ( ArrayStructure ) data ; 
if ( ! convertNeeded ( orgAS . getStructureMembers ( ) ) ) { 
convertMemberInfo ( orgAS . getStructureMembers ( ) ) ; 
return orgAS ; 
ArrayStructure newAS = ArrayStructureMA . factoryMA ( orgAS ) ; 
for ( StructureMembers . Member m : newAS . getMembers ( ) ) { 
VariableEnhanced v2 = ( VariableEnhanced ) findVariable ( m . getName ( ) ) ; 
if ( ( v2 == null ) && ( orgVar != null ) ) 
v2 = findVariableFromOrgName ( m . getName ( ) ) ; 
if ( v2 == null ) continue ; 
if ( v2 instanceof VariableDS ) { 
VariableDS vds = ( VariableDS ) v2 ; 
if ( vds . needConvert ( ) ) { 
Array mdata = newAS . extractMemberArray ( m ) ; 
mdata = vds . convert ( mdata , vds . getEnhanceMode ( ) ) ; 
newAS . setMemberArray ( m , mdata ) ; 
} else if ( v2 instanceof StructureDS ) { 
StructureDS innerStruct = ( StructureDS ) v2 ; 
if ( innerStruct . convertNeeded ( null ) ) { 
if ( innerStruct . getDataType ( ) == DataType . SEQUENCE ) { 
ArrayObject . D1 seqArray = ( ArrayObject . D1 ) newAS . extractMemberArray ( m ) ; 
ArrayObject . D1 newSeq = ( ArrayObject . D1 ) Array . factory ( DataType . SEQUENCE , new int [ ] { ( int ) seqArray . getSize ( ) } ) ; 
m . setDataArray ( newSeq ) ; 
for ( int i = 0 ; i < seqArray . getSize ( ) ; i ++ ) { 
ArraySequence innerSeq = ( ArraySequence ) seqArray . get ( i ) ; 
newSeq . set ( i , new SequenceConverter ( innerStruct , innerSeq ) ) ; 
mdata = innerStruct . convert ( mdata , null ) ; 
innerStruct . convertMemberInfo ( m . getStructureMembers ( ) ) ; 
StructureMembers sm = newAS . getStructureMembers ( ) ; 
convertMemberInfo ( sm ) ; 
if ( ! varHasData ( v , sm ) ) { 
Variable completeVar = getParentGroup ( ) . findVariable ( v . getShortName ( ) ) ; 
Array mdata = completeVar . read ( section ) ; 
StructureMembers . Member m = sm . addMember ( v . getShortName ( ) , v . getDescription ( ) , v . getUnitsString ( ) , v . getDataType ( ) , v . getShape ( ) ) ; 
return newAS ; 
} protected StructureData convert ( StructureData orgData , int recno ) throws IOException { 
if ( ! convertNeeded ( orgData . getStructureMembers ( ) ) ) { 
convertMemberInfo ( orgData . getStructureMembers ( ) ) ; 
return orgData ; 
StructureMembers smResult = new StructureMembers ( orgData . getStructureMembers ( ) ) ; 
StructureDataW result = new StructureDataW ( smResult ) ; 
for ( StructureMembers . Member m : orgData . getMembers ( ) ) { 
if ( v2 == null ) { 
findVariableFromOrgName ( m . getName ( ) ) ; 
StructureMembers . Member mResult = smResult . findMember ( m . getName ( ) ) ; 
Array mdata = orgData . getArray ( m ) ; 
result . setMemberData ( mResult , mdata ) ; 
if ( v2 instanceof StructureDS ) { 
Array a = orgData . getArray ( m ) ; 
if ( a instanceof ArrayObject . D1 ) { 
ArrayObject . D1 seqArray = ( ArrayObject . D1 ) a ; 
mResult . setDataArray ( newSeq ) ; 
ArraySequence seqArray = ( ArraySequence ) a ; 
result . setMemberData ( mResult , new SequenceConverter ( innerStruct , seqArray ) ) ; 
innerStruct . convertMemberInfo ( mResult . getStructureMembers ( ) ) ; 
StructureMembers sm = result . getStructureMembers ( ) ; 
Array mdata = completeVar . read ( new Section ( ) . appendRange ( recno , recno ) ) ; 
result . setMemberData ( m , mdata ) ; 
} private void convertMemberInfo ( StructureMembers wrapperSm ) { 
for ( StructureMembers . Member m : wrapperSm . getMembers ( ) ) { 
Variable v = findVariable ( m . getName ( ) ) ; 
if ( ( v == null ) && ( orgVar != null ) ) 
v = ( Variable ) findVariableFromOrgName ( m . getName ( ) ) ; 
m . setVariableInfo ( v . getShortName ( ) , v . getDescription ( ) , v . getUnitsString ( ) , v . getDataType ( ) ) ; 
if ( v instanceof StructureDS ) { 
StructureDS innerStruct = ( StructureDS ) v ; 
} private VariableEnhanced findVariableFromOrgName ( String orgName ) { 
for ( Variable vTop : getVariables ( ) ) { 
Variable v = vTop ; 
while ( v instanceof VariableEnhanced ) { 
if ( ( ve . getOriginalName ( ) != null ) && ( ve . getOriginalName ( ) . equals ( orgName ) ) ) 
return ( VariableEnhanced ) vTop ; 
v = ve . getOriginalVariable ( ) ; 
} private boolean varHasData ( Variable v , StructureMembers sm ) { 
if ( sm . findMember ( v . getShortName ( ) ) != null ) return true ; 
if ( sm . findMember ( ve . getOriginalName ( ) ) != null ) return true ; 
} public void enhance ( Set < NetcdfDataset . Enhance > mode ) { 
} public NetcdfFile openNetcdfFile ( HttpServletRequest req , HttpServletResponse res , String reqPath ) throws IOException { 
if ( reqPath == null ) 
if ( reqPath . startsWith ( "/" ) ) 
reqPath = reqPath . substring ( 1 ) ; 
if ( ! resourceControlOk ( req , res , reqPath ) ) 
String ncml = datasetTracker . findNcml ( reqPath ) ; 
if ( ncml != null ) { 
NetcdfFile ncfile = NetcdfDataset . acquireFile ( new NcmlFileFactory ( ncml ) , null , DatasetUrl . findDatasetUrl ( reqPath ) , - 1 , null , null ) ; 
if ( ncfile == null ) throw new FileNotFoundException ( reqPath ) ; 
DataRootManager . DataRootMatch match = dataRootManager . findDataRootMatch ( reqPath ) ; 
if ( ( match != null ) && ( match . dataRoot . getFeatureCollection ( ) != null ) ) { 
FeatureCollectionRef featCollection = match . dataRoot . getFeatureCollection ( ) ; 
InvDatasetFeatureCollection fc = featureCollectionCache . get ( featCollection ) ; 
NetcdfFile ncfile = fc . getNetcdfDataset ( match . remaining ) ; 
NetcdfFile ncfile = null ; 
for ( DatasetSource datasetSource : datasetSources ) { 
if ( datasetSource . isMine ( req ) ) { 
ncfile = datasetSource . getNetcdfFile ( req , res ) ; 
if ( ncfile != null ) return ncfile ; 
if ( match != null ) { 
org . jdom2 . Element netcdfElem = null ; 
if ( match . dataRoot != null ) { 
if ( dscan != null ) 
netcdfElem = dscan . getNcmlElement ( ) ; 
String location = dataRootManager . getLocationFromRequestPath ( reqPath ) ; 
if ( location == null ) 
throw new FileNotFoundException ( reqPath ) ; 
if ( netcdfElem != null ) { 
String ncmlLocation = "DatasetScan#" + location ; 
NetcdfDataset ncd = NcMLReader . readNcML ( ncmlLocation , netcdfElem , "file:" + location , null ) ; 
return ncd ; 
ncfile = NetcdfDataset . acquireFile ( durl , null ) ; 
} public GridDataset openGridDataset ( HttpServletRequest req , HttpServletResponse res , String reqPath ) throws IOException { 
if ( ! resourceAuthorized ( req , res , match . dataRoot . getRestrict ( ) ) ) 
GridDataset gds = fc . getGridDataset ( match . remaining ) ; 
if ( gds == null ) throw new FileNotFoundException ( reqPath ) ; 
return gds ; 
NetcdfFile ncfile = openNetcdfFile ( req , res , reqPath ) ; 
if ( ncfile == null ) return null ; 
NetcdfDataset ncd = null ; 
ncd = NetcdfDataset . wrap ( ncfile , NetcdfDataset . getDefaultEnhanceMode ( ) ) ; 
return new ucar . nc2 . dt . grid . GridDataset ( ncd ) ; 
if ( ncd == null ) 
if ( t instanceof IOException ) 
throw ( IOException ) t ; 
throw new IOException ( msg + t . getMessage ( ) ) ; 
} public CoverageCollection openCoverageDataset ( HttpServletRequest req , HttpServletResponse res , String reqPath ) throws IOException { 
CoverageCollection gds = fc . getGridCoverage ( match . remaining ) ; 
String location = getLocationFromRequestPath ( reqPath ) ; 
if ( location != null ) { 
Optional < FeatureDatasetCoverage > opt = CoverageDatasetFactory . openCoverageDataset ( location ) ; 
if ( ! opt . isPresent ( ) ) 
return opt . get ( ) . getSingleCoverageCollection ( ) ; 
Optional < FeatureDatasetCoverage > opt = CoverageDatasetFactory . openNcmlString ( ncml ) ; 
} public boolean resourceControlOk ( HttpServletRequest req , HttpServletResponse res , String reqPath ) { 
if ( null == reqPath ) 
reqPath = TdsPathUtils . extractPath ( req , null ) ; 
String rc = null ; 
rc = match . dataRoot . getRestrict ( ) ; 
if ( rc == null ) { 
rc = datasetTracker . findResourceControl ( reqPath ) ; 
return resourceAuthorized ( req , res , rc ) ; 
} public void registerDatasetSource ( String className ) { 
Class vClass ; 
vClass = DatasetManager . class . getClassLoader ( ) . loadClass ( className ) ; 
if ( ! ( DatasetSource . class . isAssignableFrom ( vClass ) ) ) { 
instance = vClass . newInstance ( ) ; 
registerDatasetSource ( ( DatasetSource ) instance ) ; 
os . print ( function . getName ( ) + "(" ) ; 
Iterator it = children . iterator ( ) ; 
ValueClause vc = ( ValueClause ) it . next ( ) ; 
if ( ! first ) os . print ( "," ) ; 
vc . printConstraint ( os ) ; 
os . print ( ")" ) ; 
if ( ! super . isValidFile ( raf ) ) { 
return gemreader . getFileSubType ( ) . equals ( GempakSoundingFileReader . MERGED ) || 
gemreader . getFileSubType ( ) . equals ( GempakSoundingFileReader . UNMERGED ) ; 
} public Array readData ( Variable v2 , Section section ) throws IOException , InvalidRangeException { 
return readSoundingData ( v2 , section , gemreader . getFileSubType ( ) . equals ( GempakSoundingFileReader . MERGED ) ) ; 
} private Array readSoundingData ( Variable v2 , Section section , boolean isMerged ) throws IOException { 
Array array = null ; 
Range stationRange = section . getRange ( 0 ) ; 
Range timeRange = section . getRange ( 1 ) ; 
int size = stationRange . length ( ) * timeRange . length ( ) ; 
Structure pdata = ( Structure ) v2 ; 
StructureMembers members = pdata . makeStructureMembers ( ) ; 
ArrayStructureBB abb = new ArrayStructureBB ( members , new int [ ] { size } ) ; 
ByteBuffer buf = abb . getByteBuffer ( ) ; 
for ( int stnIdx : stationRange ) { 
List < String > parts = ( isMerged ) ? ( ( GempakSoundingFileReader ) gemreader ) . getMergedParts ( ) 
: ( ( GempakSoundingFileReader ) gemreader ) . getUnmergedParts ( ) ; 
boolean allMissing = true ; 
List < GempakParameter > params = gemreader . getParameters ( part ) ; 
GempakFileReader . RData vals = gemreader . DM_RDTR ( timeIdx + 1 , stnIdx + 1 , part ) ; 
ArraySequence aseq ; 
Sequence seq = ( Sequence ) pdata . findVariable ( part ) ; 
if ( vals == null ) { 
aseq = makeEmptySequence ( seq ) ; 
allMissing = false ; 
aseq = makeArraySequence ( seq , params , vals . data ) ; 
int index = abb . addObjectToHeap ( aseq ) ; 
buf . putInt ( index ) ; 
buf . put ( ( byte ) ( allMissing ? 1 : 0 ) ) ; 
array = abb ; 
} private ArraySequence makeEmptySequence ( Sequence seq ) { 
StructureMembers members = seq . makeStructureMembers ( ) ; 
return new ArraySequence ( members , new EmptyStructureDataIterator ( ) , - 1 ) ; 
} private ArraySequence makeArraySequence ( Sequence seq , List < GempakParameter > params , float [ ] values ) { 
return makeEmptySequence ( seq ) ; 
int numLevels = values . length / params . size ( ) ; 
int offset = ArrayStructureBB . setOffsets ( members ) ; 
int size = offset * numLevels ; 
ByteBuffer buf = ByteBuffer . wrap ( bytes ) ; 
ArrayStructureBB abb = new ArrayStructureBB ( members , new int [ ] { numLevels } , buf , 0 ) ; 
int var = 0 ; 
for ( int i = 0 ; i < numLevels ; i ++ ) { 
if ( members . findMember ( param . getName ( ) ) != null ) { 
buf . putFloat ( values [ var ] ) ; 
var ++ ; 
return new ArraySequence ( members , new SequenceIterator ( numLevels , abb ) , numLevels ) ; 
} protected void fillNCFile ( ) throws IOException { 
String fileType = gemreader . getFileSubType ( ) ; 
buildFile ( fileType . equals ( GempakSoundingFileReader . MERGED ) ) ; 
} private void buildFile ( boolean isMerged ) { 
List < GempakStation > stations = gemreader . getStations ( ) ; 
Dimension station = new Dimension ( "station" , stations . size ( ) , true ) ; 
ncfile . addDimension ( null , station ) ; 
ncfile . addDimension ( null , DIM_LEN8 ) ; 
ncfile . addDimension ( null , DIM_LEN4 ) ; 
ncfile . addDimension ( null , DIM_LEN2 ) ; 
List < Variable > stationVars = makeStationVars ( stations , station ) ; 
for ( Variable stnVar : stationVars ) { 
ncfile . addVariable ( null , stnVar ) ; 
List < Date > timeList = gemreader . getDates ( ) ; 
int numTimes = timeList . size ( ) ; 
Dimension times = new Dimension ( TIME_VAR , numTimes , true ) ; 
ncfile . addDimension ( null , times ) ; 
Variable timeVar = new Variable ( ncfile , null , null , TIME_VAR , DataType . DOUBLE , TIME_VAR ) ; 
timeVar . addAttribute ( new Attribute ( "long_name" , TIME_VAR ) ) ; 
varArray = new ArrayDouble . D1 ( numTimes ) ; 
for ( Date date : timeList ) { 
( ( ArrayDouble . D1 ) varArray ) . set ( i , date . getTime ( ) / 1000.d ) ; 
List < Dimension > stationTime = new ArrayList < > ( ) ; 
stationTime . add ( station ) ; 
stationTime . add ( times ) ; 
String structName = ( isMerged ) ? GempakSoundingFileReader . MERGED : GempakSoundingFileReader . UNMERGED ; 
structName = structName + "Sounding" ; 
Structure sVar = new Structure ( ncfile , null , null , structName ) ; 
sVar . setDimensions ( stationTime ) ; 
List < String > sequenceNames ; 
if ( isMerged ) { 
sequenceNames = new ArrayList < > ( ) ; 
sequenceNames . add ( GempakSoundingFileReader . SNDT ) ; 
sequenceNames = ( ( GempakSoundingFileReader ) gemreader ) . getUnmergedParts ( ) ; 
for ( String seqName : sequenceNames ) { 
Sequence paramData = makeSequence ( sVar , seqName , false ) ; 
if ( paramData == null ) { 
sVar . addMemberVariable ( paramData ) ; 
ncfile . addAttribute ( null , new Attribute ( "CF:featureType" , CF . FeatureType . timeSeriesProfile . toString ( ) ) ) ; 
ncfile . addVariable ( null , sVar ) ; 
} protected Sequence makeSequence ( Structure parent , String partName , boolean includeMissing ) { 
Sequence sVar = new Sequence ( ncfile , null , parent , partName ) ; 
sVar . setDimensions ( "" ) ; 
Variable v = makeParamVariable ( param , null ) ; 
addVerticalCoordAttribute ( v ) ; 
sVar . addMemberVariable ( v ) ; 
} private void addVerticalCoordAttribute ( Variable v ) { 
GempakSoundingFileReader gsfr = ( GempakSoundingFileReader ) gemreader ; 
int vertType = gsfr . getVerticalCoordinate ( ) ; 
String pName = v . getFullName ( ) ; 
if ( gemreader . getFileSubType ( ) . equals ( GempakSoundingFileReader . MERGED ) ) { 
if ( ( vertType == GempakSoundingFileReader . PRES_COORD ) && pName . equals ( "PRES" ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Pressure . name ( ) ) ) ; 
} else if ( ( vertType == GempakSoundingFileReader . HGHT_COORD ) && ( pName . equals ( "HGHT" ) || pName . equals ( "MHGT" ) || pName . equals ( "DHGT" ) ) ) { 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Height . name ( ) ) ) ; 
} else if ( pName . equals ( "PRES" ) ) { 
} public void readXMLasynch ( String uriString , CatalogSetCallback callback ) { 
InvCatalogImpl cat = readXML ( uriString ) ; 
callback . setCatalog ( cat ) ; 
} public InvCatalogImpl readXML ( String uriString ) { 
InvCatalogImpl cat = new InvCatalogImpl ( uriString , null , null ) ; 
return readXML ( uri ) ; 
} public InvCatalogImpl readXML ( URI uri ) { 
org . jdom2 . Document jdomDoc ; 
jdomDoc = saxBuilder . build ( uri . toURL ( ) ) ; 
InvCatalogImpl cat = new InvCatalogImpl ( uri . toString ( ) , null , null ) ; 
if ( is != null ) try 
if ( fatalMessages . length ( ) > 0 ) { 
fatalMessages . toString ( ) + "\n" , true ) ; 
return readXML ( jdomDoc , uri ) ; 
} public InvCatalogImpl readXML ( String catAsString , URI baseUri ) 
return readXML ( new StringReader ( catAsString ) , baseUri ) ; 
} public InvCatalogImpl readXML ( StringReader catAsStringReader , URI baseUri ) 
XMLEntityResolver resolver = new XMLEntityResolver ( false ) ; 
SAXBuilder builder = resolver . getSAXBuilder ( ) ; 
Document inDoc ; 
inDoc = builder . build ( catAsStringReader ) ; 
InvCatalogImpl cat = new InvCatalogImpl ( baseUri . toString ( ) , null , null ) ; 
return readXML ( inDoc , baseUri ) ; 
} public InvCatalogImpl readXML ( InputStream docIs , URI uri ) { 
jdomDoc = saxBuilder . build ( docIs ) ; 
InvCatalogImpl cat = new InvCatalogImpl ( uri . toString ( ) , null , uri ) ; 
} public InvCatalogImpl readXML ( org . jdom2 . Document jdomDoc , URI uri ) { 
Element root = jdomDoc . getRootElement ( ) ; 
if ( ! root . getName ( ) . equalsIgnoreCase ( "catalog" ) ) { 
InvCatalogConvertIF fac = converters . get ( namespace ) ; 
InvCatalogImpl cat = fac . parseXML ( this , jdomDoc , uri ) ; 
cat . setCreateFrom ( uri . toString ( ) ) ; 
cat . finish ( ) ; 
cat . appendErrorMessage ( fatalMessages . toString ( ) , true ) ; 
cat . appendErrorMessage ( errMessages . toString ( ) , false ) ; 
if ( warnMessages . length ( ) > 0 ) 
cat . appendErrorMessage ( warnMessages . toString ( ) , false ) ; 
InvCatalogConvertIF converter = this . getCatalogConverter ( XMLEntityResolver . CATALOG_NAMESPACE_10 ) ; 
converter . writeXML ( catalog , os , raw ) ; 
} public void writeXML ( InvCatalogImpl catalog , String filename ) throws IOException { 
writeXML ( catalog , os , false ) ; 
} public String writeXML ( InvCatalogImpl catalog ) throws IOException { 
} public MetadataConverterIF getMetadataConverter ( String key ) { 
if ( key == null ) return null ; 
return metadataConverters . get ( key ) ; 
} private static InvCatalogImpl doOne ( InvCatalogFactory fac , String urlString , boolean show ) { 
InvCatalogImpl cat = fac . readXML ( new URI ( urlString ) ) ; 
boolean isValid = cat . check ( buff , false ) ; 
} private static UnitName dimensionlessID ( ) { 
UnitName id ; 
id = UnitName . newUnitName ( "1" , "1" , "1" ) ; 
Unit result ; 
if ( dimension . getRank ( ) == 0 ) { 
result = that ; 
if ( ! ( that instanceof DerivedUnit ) ) { 
result = that . multiplyBy ( this ) ; 
final UnitDimension thatDimension = ( ( DerivedUnit ) that ) 
. getDimension ( ) ; 
result = thatDimension . getRank ( ) == 0 
? this 
: new DerivedUnitImpl ( dimension 
. multiplyBy ( thatDimension ) ) ; 
result = that . raiseTo ( - 1 ) ; 
result = that . divideInto ( this ) ; 
: new DerivedUnitImpl ( dimension . divideBy ( thatDimension ) ) ; 
} public final float [ ] toDerivedUnit ( final float [ ] input , final float [ ] output ) { 
if ( input != output ) { 
System . arraycopy ( input , 0 , output , 0 , input . length ) ; 
public final boolean isCompatible ( final Unit that ) { 
final DerivedUnit unit = that . getDerivedUnit ( ) ; 
return equals ( unit ) || isReciprocalOf ( unit ) ; 
final BaseUnit second = BaseUnit . getOrCreate ( UnitName . newUnitName ( 
"second" , null , "s" ) , BaseQuantity . TIME ) ; 
final DerivedUnitImpl meterSecond = ( DerivedUnitImpl ) meter 
. myMultiplyBy ( second ) ; 
final DerivedUnitImpl meterPerSecond = ( DerivedUnitImpl ) meter 
. myDivideBy ( second ) ; 
final DerivedUnitImpl secondPerMeter = ( DerivedUnitImpl ) second 
. myDivideBy ( meter ) ; 
System . out . println ( "meterPerSecond.isReciprocalOf(secondPerMeter)=" 
+ meterPerSecond . isReciprocalOf ( secondPerMeter ) ) ; 
System . out . println ( "meter.toDerivedUnit(1.0)=" 
+ meter . toDerivedUnit ( 1.0 ) ) ; 
+ meter . toDerivedUnit ( new double [ ] { 1 , 2 , 3 } , 
new double [ 3 ] ) [ 1 ] ) ; 
System . out . println ( "meter.fromDerivedUnit(1.0)=" 
+ meter . fromDerivedUnit ( 1.0 ) ) ; 
+ meter . fromDerivedUnit ( new double [ ] { 1 , 2 , 3 } , 
new double [ 3 ] ) [ 2 ] ) ; 
System . out . println ( "meter.isCompatible(second)=" 
+ meter . isCompatible ( second ) ) ; 
System . out . println ( "meter.equals(meter)=" + meter . equals ( meter ) ) ; 
System . out . println ( "meter.equals(second)=" + meter . equals ( second ) ) ; 
final Unit sPerS = second . myDivideBy ( second ) ; 
. println ( "sPerS.isDimensionless()=" + sPerS . isDimensionless ( ) ) ; 
meterPerSecond . raiseTo ( 2 ) ; 
meter . myDivideBy ( meterPerSecond ) ; 
} public String writeFeature ( SimpleGeometry geom ) { 
if ( geom instanceof Point ) return writePoint ( ( Point ) geom ) ; 
else if ( geom instanceof Line ) return writeLine ( ( Line ) geom ) ; 
else if ( geom instanceof Polygon ) return writePolygon ( ( Polygon ) geom ) ; 
} private String writePoint ( Point point ) { 
String xml = "" ; 
+ "</gml:Point>" ; 
return xml ; 
} private String writeLine ( Line line ) { 
xml += "<gml:LineString><gml:posList>" ; 
for ( Point point : line . getPoints ( ) ) { 
xml += "</gml:posList></gml:LineString>" ; 
} private String writePolygon ( Polygon poly ) { 
xml += "<gml:Polygon>" ; 
Polygon polygon = poly ; 
if ( ! polygon . getInteriorRing ( ) ) { 
xml += "<gml:exterior><gml:LinearRing><gml:posList>" ; 
for ( Point point : polygon . getPoints ( ) ) { 
xml += "</gml:posList></gml:LinearRing></gml:exterior>" ; 
xml += "<gml:interior><gml:LinearRing><gml:posList>" ; 
xml += "</gml:posList></gml:LinearRing></gml:interior>" ; 
xml += "</gml:Polygon>" ; 
} public boolean 
parse ( String input ) 
DocumentBuilderFactory domfactory = DocumentBuilderFactory . newInstance ( ) ; 
DocumentBuilder dombuilder = domfactory . newDocumentBuilder ( ) ; 
StringReader rdr = new StringReader ( input ) ; 
InputSource src = new InputSource ( rdr ) ; 
Document doc = dombuilder . parse ( src ) ; 
doc . getDocumentElement ( ) . normalize ( ) ; 
rdr . close ( ) ; 
parseresponse ( doc . getDocumentElement ( ) ) ; 
} catch ( ParserConfigurationException | IOException e ) { 
pull ( Node n , String name ) 
NamedNodeMap map = n . getAttributes ( ) ; 
Node attr = map . getNamedItem ( name ) ; 
if ( attr == null ) 
return attr . getNodeValue ( ) ; 
makeAttribute ( DapSort sort , String name , DapType basetype , List < String > nslist ) 
DapAttribute attr = factory . newAttribute ( name , basetype ) ; 
} List < Node > 
getSubnodes ( Node parent ) 
List < Node > subs = new ArrayList < > ( ) ; 
NodeList nodes = parent . getChildNodes ( ) ; 
for ( int i = 0 ; i < nodes . getLength ( ) ; i ++ ) { 
Node n = nodes . item ( i ) ; 
if ( n . getNodeType ( ) == Node . ELEMENT_NODE ) 
subs . add ( n ) ; 
return subs ; 
parseresponse ( Node root ) 
String elemname = root . getNodeName ( ) ; 
if ( elemname . equalsIgnoreCase ( "Error" ) ) { 
parseerror ( root ) ; 
} else if ( elemname . equalsIgnoreCase ( "Dataset" ) ) { 
parsedataset ( root ) ; 
passReserved ( Node node , DapNode dap ) 
NamedNodeMap attrs = node . getAttributes ( ) ; 
for ( int i = 0 ; i < attrs . getLength ( ) ; i ++ ) { 
Node n = attrs . item ( i ) ; 
String key = n . getNodeName ( ) ; 
String value = n . getNodeValue ( ) ; 
dap . addXMLAttribute ( key , value ) ; 
} public static String getSubsetString ( Variable var , int beginInd , int endInd , int id ) { 
if ( var == null ) return null ; 
String subStr = "" ; 
List < Dimension > dimList = var . getDimensions ( ) ; 
if ( dimList . size ( ) > 2 || dimList . size ( ) < 1 ) { 
for ( int i = 0 ; i < dimList . size ( ) ; i ++ ) { 
Dimension dim = dimList . get ( i ) ; 
if ( dim == null ) continue ; 
if ( ! CF . TIME . equalsIgnoreCase ( dim . getShortName ( ) ) && ! CF . TIME . equalsIgnoreCase ( dim . getFullNameEscaped ( ) ) ) { 
subStr += id ; 
if ( beginInd < 0 || endInd < 0 ) subStr += ":" ; 
else subStr += ( beginInd + ":" + endInd ) ; 
if ( i < dimList . size ( ) - 1 ) { 
subStr += "," ; 
return subStr ; 
} static public ArrayStructureMA factoryMA ( ArrayStructure from ) throws IOException { 
if ( from instanceof ArrayStructureMA ) 
return ( ArrayStructureMA ) from ; 
if ( from . getSize ( ) > 0 ) { 
ArrayStructureMA to = new ArrayStructureMA ( new StructureMembers ( from . getStructureMembers ( ) ) , from . getShape ( ) ) ; 
for ( StructureMembers . Member m : from . getMembers ( ) ) { 
to . setMemberArray ( m . getName ( ) , from . extractMemberArray ( m ) ) ; 
int numRecords = - 1 ; 
Map < String , Array > memberArrayMap = new LinkedHashMap < > ( ) ; 
Array array = from . extractMemberArray ( m ) ; 
int firstDimLen = array . getShape ( ) [ 0 ] ; 
if ( numRecords == - 1 ) { 
numRecords = firstDimLen ; 
memberArrayMap . put ( m . getName ( ) , array ) ; 
int [ ] shape ; 
shape = new int [ ] { 0 } ; 
shape = new int [ ] { numRecords } ; 
ArrayStructureMA to = new ArrayStructureMA ( new StructureMembers ( from . getStructureMembers ( ) ) , shape ) ; 
for ( Map . Entry < String , Array > entry : memberArrayMap . entrySet ( ) ) { 
to . setMemberArray ( entry . getKey ( ) , entry . getValue ( ) ) ; 
} public void setMemberArray ( String memberName , Array data ) { 
} static public ArrayStructureMA factoryMA ( Structure from , int [ ] shape ) throws IOException { 
StructureMembers sm = from . makeStructureMembers ( ) ; 
for ( Variable v : from . getVariables ( ) ) { 
if ( v instanceof Sequence ) { 
data = Array . factory ( DataType . SEQUENCE , shape ) ; 
} else if ( v instanceof Structure ) 
data = ArrayStructureMA . factoryMA ( ( Structure ) v , combine ( shape , v . getShape ( ) ) ) ; 
data = Array . factory ( v . getDataType ( ) , combine ( shape , v . getShape ( ) ) ) ; 
StructureMembers . Member m = sm . findMember ( v . getShortName ( ) ) ; 
return new ArrayStructureMA ( sm , shape ) ; 
} public Polygon readPolygon ( String name , int index ) { 
Variable polyvar = ds . findVariable ( name ) ; 
if ( polyvar == null ) return null ; 
Polygon poly = null ; 
if ( ds . findGlobalAttribute ( CF . CONVENTIONS ) != null ) 
if ( ucar . nc2 . dataset . conv . CF1Convention . getVersion ( ds . findGlobalAttribute ( CF . CONVENTIONS ) . getStringValue ( ) ) >= 8 ) 
poly = new CFPolygon ( ) ; 
if ( poly == null ) return null ; 
else return poly . setupPolygon ( ds , polyvar , index ) ; 
} public Line readLine ( String name , int index ) { 
Variable linevar = ds . findVariable ( name ) ; 
if ( linevar == null ) return null ; 
Line line = null ; 
line = new CFLine ( ) ; 
if ( line == null ) return null ; 
else return line . setupLine ( ds , linevar , index ) ; 
} public Point readPoint ( String name , int index ) { 
Variable pointvar = ds . findVariable ( name ) ; 
if ( pointvar == null ) return null ; 
Point pt = null ; 
pt = new CFPoint ( ) ; 
if ( pt == null ) return pt ; 
else return pt . setupPoint ( ds , pointvar , index ) ; 
} public GeometryType getGeometryType ( String name ) { 
Variable geometryVar = ds . findVariable ( name ) ; 
if ( geometryVar == null ) return null ; 
Attribute geometryTypeAttr = null ; 
String geometry_type = null ; 
geometryTypeAttr = geometryVar . findAttribute ( CF . GEOMETRY_TYPE ) ; 
if ( geometryTypeAttr == null ) return null ; 
geometry_type = geometryTypeAttr . getStringValue ( ) ; 
switch ( geometry_type ) 
case CF . POLYGON : 
return GeometryType . POLYGON ; 
case CF . LINE : 
return GeometryType . LINE ; 
case CF . POINT : 
return GeometryType . POINT ; 
} public StationTimeSeriesFeature makeStation ( StructureData stationData , int recnum ) { 
StationFeature s = ft . makeStation ( stationData ) ; 
if ( s == null ) return null ; 
return new StandardStationFeatureImpl ( s , timeUnit , stationData , recnum ) ; 
compileAST ( CEAST ast ) 
switch ( ast . sort ) { 
case CONSTRAINT : 
for ( CEAST clause : ast . clauses ) { 
compileAST ( clause ) ; 
this . ce . expand ( ) ; 
this . ce . finish ( ) ; 
case PROJECTION : 
scopestack . clear ( ) ; 
compileAST ( ast . tree ) ; 
case SEGMENT : 
compilesegment ( ast ) ; 
case SELECTION : 
compileselection ( ast ) ; 
case DEFINE : 
dimredef ( ast ) ; 
compilefilter ( DapVariable var , DapSequence seq , CEAST expr ) 
if ( expr == null ) 
if ( expr . sort == CEAST . Sort . SEGMENT ) { 
if ( expr . subnodes != null ) 
DapVariable field = seq . findByName ( expr . name ) ; 
expr . field = field ; 
} else if ( expr . sort == CEAST . Sort . EXPR ) { 
if ( expr . lhs != null ) 
compilefilter ( var , seq , expr . lhs ) ; 
if ( expr . rhs != null ) 
compilefilter ( var , seq , expr . rhs ) ; 
if ( expr . lhs != null && expr . rhs != null ) { 
boolean leftvar = ( expr . lhs . sort == CEAST . Sort . SEGMENT ) ; 
boolean rightvar = ( expr . rhs . sort == CEAST . Sort . SEGMENT ) ; 
if ( rightvar && ! leftvar ) { 
CEAST tmp = expr . lhs ; 
expr . lhs = expr . rhs ; 
expr . rhs = tmp ; 
switch ( expr . op ) { 
case LT : 
expr . op = CEAST . Operator . GT ; 
case LE : 
expr . op = CEAST . Operator . GE ; 
case GT : 
expr . op = CEAST . Operator . LT ; 
case GE : 
expr . op = CEAST . Operator . LE ; 
} else if ( expr . sort == CEAST . Sort . CONSTANT ) { 
dimredef ( CEAST node ) 
DapDimension dim = ( DapDimension ) dataset . findByFQN ( node . name , DapSort . DIMENSION ) ; 
if ( dim == null ) 
Slice slice = node . slice ; 
slice . finish ( ) ; 
ce . addRedef ( dim , slice ) ; 
} static ArrayObject factory ( DataType dtype , Class elemType , boolean isVlen , Index index ) { 
return ArrayObject . factory ( dtype , elemType , isVlen , index , null ) ; 
} static ArrayObject factory ( DataType dtype , Class elemType , boolean isVlen , Index index , Object [ ] storage ) { 
return new ArrayObject . D0 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D1 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D2 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D3 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D4 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D5 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D6 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject . D7 ( dtype , elemType , isVlen , index , storage ) ; 
return new ArrayObject ( dtype , elemType , isVlen , index , storage ) ; 
} protected Array createView ( Index index ) { 
return ArrayObject . factory ( dataType , elementType , isVlen , index , storage ) ; 
Object [ ] ja = ( Object [ ] ) javaArray ; 
for ( Object aJa : ja ) iter . setObjectNext ( aJa ) ; 
} public boolean nearlyEquals ( LatLonRect other , double maxRelDiff ) { 
} public boolean contains ( double lat , double lon ) { 
double eps = 1.0e-9 ; 
if ( ( lat + eps < lowerLeft . getLatitude ( ) ) || ( lat - eps > upperRight . getLatitude ( ) ) ) { 
if ( allLongitude ) 
if ( crossDateline ) { 
return ( ( lon >= lowerLeft . getLongitude ( ) ) || ( lon <= upperRight . getLongitude ( ) ) ) ; 
return ( ( lon >= lowerLeft . getLongitude ( ) ) && ( lon <= upperRight . getLongitude ( ) ) ) ; 
} public boolean containedIn ( LatLonRect b ) { 
return ( b . getWidth ( ) >= width ) && b . contains ( upperRight ) 
&& b . contains ( lowerLeft ) ; 
} public void extend ( LatLonPoint p ) { 
if ( contains ( p ) ) 
double lat = p . getLatitude ( ) ; 
double lon = p . getLongitude ( ) ; 
if ( lat > upperRight . getLatitude ( ) ) { 
upperRight . setLatitude ( lat ) ; 
if ( lat < lowerLeft . getLatitude ( ) ) { 
lowerLeft . setLatitude ( lat ) ; 
if ( allLongitude ) { 
} else if ( crossDateline ) { 
double d1 = lon - upperRight . getLongitude ( ) ; 
double d2 = lowerLeft . getLongitude ( ) - lon ; 
if ( ( d1 > 0.0 ) && ( d2 > 0.0 ) ) { 
if ( d1 > d2 ) { 
lowerLeft . setLongitude ( lon ) ; 
upperRight . setLongitude ( lon ) ; 
if ( lon > upperRight . getLongitude ( ) ) { 
if ( lon - upperRight . getLongitude ( ) > lowerLeft . getLongitude ( ) - lon + 360 ) { 
crossDateline = true ; 
} else if ( lon < lowerLeft . getLongitude ( ) ) { 
if ( lowerLeft . getLongitude ( ) - lon > lon + 360.0 - upperRight . getLongitude ( ) ) { 
width = upperRight . getLongitude ( ) - lowerLeft . getLongitude ( ) ; 
lon0 = ( upperRight . getLongitude ( ) + lowerLeft . getLongitude ( ) ) / 2 ; 
width += 360 ; 
lon0 -= 180 ; 
this . allLongitude = this . allLongitude || ( this . width >= 360.0 ) ; 
} public void extend ( LatLonRect r ) { 
Preconditions . checkNotNull ( r ) ; 
double latMin = r . getLatMin ( ) ; 
double latMax = r . getLatMax ( ) ; 
if ( latMax > upperRight . getLatitude ( ) ) { 
upperRight . setLatitude ( latMax ) ; 
if ( latMin < lowerLeft . getLatitude ( ) ) { 
lowerLeft . setLatitude ( latMin ) ; 
double lonMin = getLonMin ( ) ; 
double lonMax = getLonMax ( ) ; 
double nlonMin = LatLonPointImpl . lonNormal ( r . getLonMin ( ) , lonMin ) ; 
double nlonMax = nlonMin + r . getWidth ( ) ; 
lonMin = Math . min ( lonMin , nlonMin ) ; 
lonMax = Math . max ( lonMax , nlonMax ) ; 
width = lonMax - lonMin ; 
allLongitude = width >= 360.0 ; 
width = 360.0 ; 
lonMin = - 180.0 ; 
lonMin = LatLonPointImpl . lonNormal ( lonMin ) ; 
lowerLeft . setLongitude ( lonMin ) ; 
upperRight . setLongitude ( lonMin + width ) ; 
lon0 = lonMin + width / 2 ; 
crossDateline = lowerLeft . getLongitude ( ) > upperRight . getLongitude ( ) ; 
} public LatLonRect intersect ( LatLonRect clip ) { 
double latMin = Math . max ( getLatMin ( ) , clip . getLatMin ( ) ) ; 
double latMax = Math . min ( getLatMax ( ) , clip . getLatMax ( ) ) ; 
double deltaLat = latMax - latMin ; 
if ( deltaLat < 0 ) 
double lon1min = getLonMin ( ) ; 
double lon1max = getLonMax ( ) ; 
double lon2min = clip . getLonMin ( ) ; 
double lon2max = clip . getLonMax ( ) ; 
if ( ! intersect ( lon1min , lon1max , lon2min , lon2max ) ) { 
lon2min = clip . getLonMin ( ) + 360 ; 
lon2max = clip . getLonMax ( ) + 360 ; 
lon2min = clip . getLonMin ( ) - 360 ; 
lon2max = clip . getLonMax ( ) - 360 ; 
double lonMin = Math . max ( lon1min , lon2min ) ; 
double lonMax = Math . min ( lon1max , lon2max ) ; 
double deltaLon = lonMax - lonMin ; 
if ( deltaLon < 0 ) 
return new LatLonRect ( new LatLonPointImpl ( latMin , lonMin ) , deltaLat , deltaLon ) ; 
} public String toString2 ( ) { 
} public static Array add ( Array a , Array b ) throws IllegalArgumentException { 
Array result = Array . factory ( a . getDataType ( ) , a . getShape ( ) ) ; 
if ( a . getElementType ( ) == double . class ) { 
addDouble ( result , a , b ) ; 
} public static void addDouble ( Array result , Array a , Array b ) 
throws IllegalArgumentException { 
if ( ! conformable ( result , a ) || ! conformable ( a , b ) ) 
IndexIterator iterR = result . getIndexIterator ( ) ; 
IndexIterator iterA = a . getIndexIterator ( ) ; 
IndexIterator iterB = b . getIndexIterator ( ) ; 
iterR . setDoubleNext ( iterA . getDoubleNext ( ) + iterB . getDoubleNext ( ) ) ; 
} public static boolean conformable ( Array a , Array b ) { 
return conformable ( a . getShape ( ) , b . getShape ( ) ) ; 
} public static boolean conformable ( int [ ] shapeA , int [ ] shapeB ) { 
if ( reducedRank ( shapeA ) != reducedRank ( shapeB ) ) 
int rankB = shapeB . length ; 
int dimB = 0 ; 
for ( int aShapeA : shapeA ) { 
if ( aShapeA == 1 ) 
while ( dimB < rankB ) 
if ( shapeB [ dimB ] == 1 ) dimB ++ ; 
else break ; 
if ( aShapeA != shapeB [ dimB ] ) 
dimB ++ ; 
} public static Array convert ( Array org , DataType wantType ) { 
if ( org == null ) return null ; 
Class wantClass = wantType . getPrimitiveClassType ( ) ; 
if ( org . getElementType ( ) . equals ( wantClass ) ) 
return org ; 
Array result = Array . factory ( wantType , org . getShape ( ) ) ; 
copy ( wantType , org . getIndexIterator ( ) , result . getIndexIterator ( ) ) ; 
} public static void copy ( DataType dataType , IndexIterator from , IndexIterator to ) throws IllegalArgumentException { 
while ( from . hasNext ( ) ) 
to . setDoubleNext ( from . getDoubleNext ( ) ) ; 
to . setFloatNext ( from . getFloatNext ( ) ) ; 
to . setLongNext ( from . getLongNext ( ) ) ; 
to . setIntNext ( from . getIntNext ( ) ) ; 
to . setShortNext ( from . getShortNext ( ) ) ; 
to . setCharNext ( from . getCharNext ( ) ) ; 
to . setByteNext ( from . getByteNext ( ) ) ; 
} else if ( dataType == DataType . BOOLEAN ) { 
to . setBooleanNext ( from . getBooleanNext ( ) ) ; 
to . setObjectNext ( from . getObjectNext ( ) ) ; 
} public static void copy ( Array result , Array a ) throws IllegalArgumentException { 
Class classType = a . getElementType ( ) ; 
copyDouble ( result , a ) ; 
copyFloat ( result , a ) ; 
copyLong ( result , a ) ; 
copyInt ( result , a ) ; 
copyShort ( result , a ) ; 
copyChar ( result , a ) ; 
copyByte ( result , a ) ; 
copyBoolean ( result , a ) ; 
copyObject ( result , a ) ; 
} public static void copyDouble ( Array result , Array a ) throws IllegalArgumentException { 
if ( ! conformable ( a , result ) ) 
iterR . setDoubleNext ( iterA . getDoubleNext ( ) ) ; 
} public static void copyFloat ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setFloatNext ( iterA . getFloatNext ( ) ) ; 
} public static void copyLong ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setLongNext ( iterA . getLongNext ( ) ) ; 
} public static void copyInt ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setIntNext ( iterA . getIntNext ( ) ) ; 
} public static void copyShort ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setShortNext ( iterA . getShortNext ( ) ) ; 
} public static void copyChar ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setCharNext ( iterA . getCharNext ( ) ) ; 
} public static void copyByte ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setByteNext ( iterA . getByteNext ( ) ) ; 
} public static void copyBoolean ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setBooleanNext ( iterA . getBooleanNext ( ) ) ; 
} public static void copyObject ( Array result , Array a ) throws IllegalArgumentException { 
iterR . setObjectNext ( iterA . getObjectNext ( ) ) ; 
} public static MAMath . MinMax getMinMax ( Array a ) { 
double max = - Double . MAX_VALUE ; 
double min = Double . MAX_VALUE ; 
double val = iter . getDoubleNext ( ) ; 
if ( Double . isNaN ( val ) ) continue ; 
if ( val > max ) 
max = val ; 
if ( val < min ) 
min = val ; 
return new MinMax ( min , max ) ; 
} public static void setDouble ( Array result , double val ) { 
IndexIterator iter = result . getIndexIterator ( ) ; 
iter . setDoubleNext ( val ) ; 
} public static double sumDouble ( Array a ) { 
double sum = 0 ; 
sum += iterA . getDoubleNext ( ) ; 
} public static double sumDoubleSkipMissingData ( Array a , double missingValue ) { 
double val = iterA . getDoubleNext ( ) ; 
if ( ( val == missingValue ) || Double . isNaN ( val ) ) 
sum += val ; 
} public static MAMath . ScaleOffset calcScaleOffsetSkipMissingData ( Array a , double missingValue , int nbits ) { 
MAMath . MinMax minmax = getMinMaxSkipMissingData ( a , missingValue ) ; 
if ( a . isUnsigned ( ) ) { 
long size = ( 1L << nbits ) - 1 ; 
double offset = minmax . min ; 
double scale = ( minmax . max - minmax . min ) / size ; 
return new ScaleOffset ( scale , offset ) ; 
long size = ( 1L << nbits ) - 2 ; 
double offset = ( minmax . max + minmax . min ) / 2 ; 
} public static boolean nearlyEquals ( Array data1 , Array data2 ) { 
if ( data1 == data2 ) { 
} else if ( data1 == null || data2 == null ) { 
if ( data1 . getSize ( ) != data2 . getSize ( ) ) return false ; 
if ( data1 . isUnsigned ( ) != data2 . isUnsigned ( ) ) return false ; 
DataType dt = DataType . getType ( data1 ) ; 
IndexIterator iter1 = data1 . getIndexIterator ( ) ; 
IndexIterator iter2 = data2 . getIndexIterator ( ) ; 
if ( dt == DataType . DOUBLE ) { 
while ( iter1 . hasNext ( ) && iter2 . hasNext ( ) ) { 
double v1 = iter1 . getDoubleNext ( ) ; 
double v2 = iter2 . getDoubleNext ( ) ; 
if ( ! Misc . nearlyEquals ( v1 , v2 , Misc . defaultMaxRelativeDiffDouble ) ) 
} else if ( dt == DataType . FLOAT ) { 
float v1 = iter1 . getFloatNext ( ) ; 
float v2 = iter2 . getFloatNext ( ) ; 
if ( ! Misc . nearlyEquals ( v1 , v2 , Misc . defaultMaxRelativeDiffFloat ) ) 
} else if ( dt . getPrimitiveClassType ( ) == int . class ) { 
int v1 = iter1 . getIntNext ( ) ; 
int v2 = iter2 . getIntNext ( ) ; 
if ( v1 != v2 ) return false ; 
} else if ( dt . getPrimitiveClassType ( ) == byte . class ) { 
short v1 = iter1 . getShortNext ( ) ; 
short v2 = iter2 . getShortNext ( ) ; 
} else if ( dt . getPrimitiveClassType ( ) == short . class ) { 
byte v1 = iter1 . getByteNext ( ) ; 
byte v2 = iter2 . getByteNext ( ) ; 
} else if ( dt . getPrimitiveClassType ( ) == long . class ) { 
long v1 = iter1 . getLongNext ( ) ; 
long v2 = iter2 . getLongNext ( ) ; 
if ( ! Objects . equals ( iter1 . next ( ) , iter2 . next ( ) ) ) { 
public CalendarDateRange getCalendarDateRange ( ) { 
if ( getTimeAxis ( ) != null ) 
return getTimeAxis ( ) . getCalendarDateRange ( ) ; 
else if ( getRunTimeAxis ( ) != null ) 
return getRunTimeAxis ( ) . getCalendarDateRange ( ) ; 
} public CatalogBuilder makeCatalogBuilder ( ) { 
CatalogBuilder builder = new CatalogBuilder ( this ) ; 
for ( Dataset ds : getDatasetsLocal ( ) ) { 
builder . addDataset ( makeDatasetBuilder ( null , ds ) ) ; 
} public final AttributeTable getAttributeTable ( String name ) throws NoSuchAttributeException 
AttributeTable at = null ; 
at = a . getContainer ( ) ; 
return ( at ) ; 
} public final AttributeTable getAttributeTableN ( String name ) 
at = a . getContainerN ( ) ; 
} public void resolveAliases ( ) throws MalformedAliasException , UnresolvedAliasException , NoSuchAttributeException 
resolveAliases ( this ) ; 
Enumeration e = getNames ( ) ; 
if ( Debug . isSet ( "DAS" ) ) { 
Attribute at = getAttribute ( aName ) ; 
if ( at == null || ! at . isContainer ( ) ) { 
} private void resolveAliases ( AttributeTable at ) throws MalformedAliasException , UnresolvedAliasException , NoSuchAttributeException 
AttributeTable cacheAT = currentAT ; 
currentAT = at ; 
DAPNode . log . debug ( "DAS.resolveAliases(at=" + at + ")" ) ; 
Enumeration aNames = at . getNames ( ) ; 
while ( aNames . hasMoreElements ( ) ) { 
String aName = ( String ) aNames . nextElement ( ) ; 
opendap . dap . Attribute thisA = currentAT . getAttribute ( aName ) ; 
if ( thisA . isAlias ( ) ) { 
resolveAlias ( ( Alias ) thisA ) ; 
} else if ( thisA . isContainer ( ) ) { 
resolveAliases ( thisA . getContainer ( ) ) ; 
currentAT = cacheAT ; 
} private void resolveAlias ( Alias alias ) throws MalformedAliasException , UnresolvedAliasException 
String name = alias . getClearName ( ) ; 
String attribute = alias . getAliasedToAttributeFieldAsClearString ( ) ; 
Enumeration e = null ; 
currentAlias = alias ; 
if ( attribute . equals ( "" ) ) { 
Vector aNames = opendap . dap . DDS . tokenizeAliasField ( attribute ) ; 
e = aNames . elements ( ) ; 
String aname = ( String ) e . nextElement ( ) ; 
opendap . dap . Attribute targetAT = null ; 
boolean isAbsolutePath = aNames . get ( 0 ) . equals ( "." ) ; 
if ( isAbsolutePath ) { 
if ( aNames . size ( ) == 1 ) { 
aNames . remove ( 0 ) ; 
targetAT = getAliasAttribute ( this , aNames ) ; 
alias . setMyAttribute ( targetAT ) ; 
} private opendap . dap . Attribute getAliasAttribute ( AttributeTable att , Vector aNames ) 
throws MalformedAliasException , UnresolvedAliasException 
String aName = ( String ) aNames . get ( 0 ) ; 
Enumeration e = att . getNames ( ) ; 
String atName = ( String ) e . nextElement ( ) ; 
opendap . dap . Attribute a = att . getAttribute ( atName ) ; 
String normName = opendap . dap . DDS . normalize ( a . getEncodedName ( ) ) ; 
if ( normName . equals ( aName ) ) { 
if ( a . isAlias ( ) ) { 
if ( aNames . size ( ) == 0 ) { 
} else if ( a . isContainer ( ) ) { 
return ( getAliasAttribute ( a . getContainer ( ) , aNames ) ) ; 
aName ) ; 
DAS das = ( DAS ) super . cloneDAG ( map ) ; 
return das ; 
} public static Grib1Gds factory ( int template , byte [ ] data ) { 
return new LatLon ( data , 0 ) ; 
return new Mercator ( data , 1 ) ; 
return new LambertConformal ( data , 3 ) ; 
return new GaussianLatLon ( data , 4 ) ; 
return new PolarStereographic ( data , 5 ) ; 
return new RotatedLatLon ( data , 10 ) ; 
return new SphericalHarmonicCoefficients ( data , 50 ) ; 
return new UnknownGds ( data , template ) ; 
} protected int getOctet3 ( int start ) { 
return GribNumbers . int3 ( getOctet ( start ) , getOctet ( start + 1 ) , getOctet ( start + 2 ) ) ; 
} public void sendDIR ( ReqState rs ) 
throws opendap . dap . DAP2Exception , ParseException { 
String ddsCacheDir = rs . getDDSCache ( rs . getRootPath ( ) ) ; 
String thisServer = rs . getRequest ( ) . getRequestURL ( ) . toString ( ) ; 
pw . println ( "<html>" ) ; 
pw . println ( "<head>" ) ; 
pw . println ( "</head>" ) ; 
pw . println ( "<h2>" + thisServer + "</h2>" ) ; 
printDIR ( pw , ddsCacheDir , "DDS" , thisServer ) ; 
pw . println ( "</html>" ) ; 
} catch ( FileNotFoundException fnfe ) { 
} static public ProjectionImpl factory ( Projection proj ) { 
if ( proj instanceof ProjectionImpl ) { 
return ( ProjectionImpl ) proj ; 
return new ProjectionAdapter ( proj ) ; 
} public ProjectionPoint latLonToProj ( LatLonPoint latlon , 
return proj . latLonToProj ( latlon , result ) ; 
return proj . projToLatLon ( world , result ) ; 
public Iterator < StationProfileFeature > iterator ( ) { 
PointFeatureCCIterator pfIterator = getNestedPointFeatureCollectionIterator ( ) ; 
return new NestedCollectionIteratorAdapter < > ( pfIterator ) ; 
} public static String unescapeDAPIdentifier ( String id ) { 
String s ; 
s = unescapeString ( id ) ; 
} public static String urlDecode ( String s ) { 
s = URLDecoder . decode ( s , "UTF-8" ) ; 
} public static String unescapeURL ( String url ) { 
String newurl ; 
newurl = urlDecode ( url ) ; 
return newurl ; 
} static public String backslashEscape ( String x , String reservedChars ) { 
if ( x == null ) { 
} else if ( reservedChars == null ) { 
return x ; 
for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { 
char c = x . charAt ( pos ) ; 
if ( reservedChars . indexOf ( c ) >= 0 ) { 
if ( ok ) return x ; 
StringBuilder sb = new StringBuilder ( x ) ; 
for ( int pos = 0 ; pos < sb . length ( ) ; pos ++ ) { 
char c = sb . charAt ( pos ) ; 
if ( reservedChars . indexOf ( c ) < 0 ) { 
sb . setCharAt ( pos , '\\' ) ; 
pos ++ ; 
sb . insert ( pos , c ) ; 
} static public String backslashUnescape ( String x ) { 
if ( ! x . contains ( "\\" ) ) return x ; 
StringBuilder sb = new StringBuilder ( x . length ( ) ) ; 
c = x . charAt ( ++ pos ) ; 
sb . append ( c ) ; 
} public static List < String > tokenizeEscapedName ( String escapedName ) { 
pos = escapedName . indexOf ( sep , pos + 1 ) ; 
if ( pos <= 0 ) break ; 
if ( ( pos > 0 ) && escapedName . charAt ( pos - 1 ) != '\\' ) { 
result . add ( escapedName . substring ( start , pos ) ) ; 
start = pos + 1 ; 
result . add ( escapedName . substring ( start , escapedName . length ( ) ) ) ; 
} public static int indexOf ( String escapedName , char c ) { 
pos = escapedName . indexOf ( c , pos + 1 ) ; 
if ( pos <= 0 ) return pos ; 
if ( ( pos > 0 ) && escapedName . charAt ( pos - 1 ) != '\\' ) return pos ; 
} public static String backslashToDAP ( String bs ) { 
int len = bs . length ( ) ; 
char c = bs . charAt ( i ) ; 
if ( i < ( len - 1 ) && c == '\\' ) { 
c = bs . charAt ( ++ i ) ; 
if ( _allowableInDAP . indexOf ( c ) < 0 ) { 
buf . append ( _URIEscape ) ; 
String ashex = Integer . toHexString ( ( int ) c ) ; 
if ( ashex . length ( ) < 2 ) buf . append ( '0' ) ; 
buf . append ( ashex ) ; 
buf . append ( c ) ; 
} static public String backslashEscapeDapString ( String s ) { 
if ( true ) { 
case '\n' : case '\r' : case '\t' : case '\f' : 
if ( c == '"' ) { 
} else if ( c == '\\' ) { 
} static public String backslashEscapeCDMString ( String s , String toescape ) 
if ( toescape == null || toescape . length ( ) == 0 ) return s ; 
if ( s == null || s . length ( ) == 0 ) return s ; 
if ( toescape . indexOf ( c ) >= 0 ) { 
buf . append ( '\\' ) ; 
assert ( this . scheme == scheme . ATOMIC ) ; 
Notes n = ( ( Nc4DSP ) this . dsp ) . find ( this . template ) ; 
VarNotes vn = ( VarNotes ) n ; 
TypeNotes ti = vn . getBaseType ( ) ; 
if ( getContainer ( ) == null ) { 
result = readAtomicScalar ( vn , ti ) ; 
result = readAtomicVector ( vn , ti , count , slices ) ; 
long elemsize = ( ( DapType ) ti . get ( ) ) . getSize ( ) ; 
assert ( this . container != null ) ; 
long trueoffset = computeTrueOffset ( this ) ; 
Nc4Pointer varmem = getMemory ( ) ; 
Nc4Pointer mem = varmem . share ( trueoffset , count * elemsize ) ; 
result = getatomicdata ( ti . getType ( ) , count , elemsize , mem ) ; 
readAtomicScalar ( VarNotes vi , TypeNotes ti ) 
Nc4prototypes nc4 = ( ( Nc4DSP ) this . dsp ) . getJNI ( ) ; 
DapType basetype = ti . getType ( ) ; 
if ( basetype . isFixedSize ( ) ) { 
long memsize = ( ( DapType ) ti . get ( ) ) . getSize ( ) ; 
Nc4Pointer mem = Nc4Pointer . allocate ( memsize ) ; 
readcheck ( nc4 , ret = nc4 . nc_get_var ( vi . gid , vi . id , mem . p ) ) ; 
setMemory ( mem ) ; 
result = getatomicdata ( ti . getType ( ) , 1 , mem . size , mem ) ; 
} else if ( basetype . isStringType ( ) ) { 
String [ ] s = new String [ 1 ] ; 
readcheck ( nc4 , ret = nc4 . nc_get_var_string ( vi . gid , vi . id , s ) ) ; 
result = s ; 
} else if ( basetype . isOpaqueType ( ) ) { 
Nc4Pointer mem = Nc4Pointer . allocate ( ti . getSize ( ) ) ; 
ByteBuffer [ ] buf = new ByteBuffer [ 1 ] ; 
buf [ 0 ] = mem . p . getByteBuffer ( 0 , ti . getSize ( ) ) ; 
result = buf ; 
getOffset ( ) 
DapVariable dv = ( DapVariable ) getTemplate ( ) ; 
Notes n = ( ( Nc4DSP ) this . dsp ) . find ( dv ) ; 
return n . getOffset ( ) ; 
} protected long 
getElementSize ( TypeNotes ti ) 
DapType type = ti . getType ( ) ; 
case Structure : 
case Sequence : 
return ti . getSize ( ) ; 
return Pointer . SIZE ; 
return getElementSize ( ( TypeNotes ) ( ( Nc4DSP ) getDSP ( ) ) . find ( ti . enumbase , NoteSort . TYPE ) ) ; 
return type . getSize ( ) ; 
} long 
computeTrueOffset ( Nc4Cursor f ) 
List < Nc4Cursor > path = getCursorPath ( f ) ; 
long totaloffset = 0 ; 
Nc4Cursor current ; 
for ( int i = 1 ; i < ( path . size ( ) - 1 ) ; i ++ ) { 
current = path . get ( i ) ; 
DapVariable template = ( DapVariable ) current . getTemplate ( ) ; 
VarNotes vi = ( VarNotes ) ( ( Nc4DSP ) getDSP ( ) ) . find ( template ) ; 
long size = vi . getSize ( ) ; 
long offset = current . getOffset ( ) ; 
switch ( current . getScheme ( ) ) { 
pos = current . getIndex ( ) . index ( ) ; 
pos = 0 ; 
long delta = size * pos + offset ; 
totaloffset += delta ; 
assert path . get ( path . size ( ) - 1 ) == f ; 
totaloffset += f . getOffset ( ) ; 
return totaloffset ; 
} static List < Nc4Cursor > 
getCursorPath ( Nc4Cursor cursor ) 
List < Nc4Cursor > path = new ArrayList < > ( ) ; 
if ( ! cursor . getScheme ( ) . isCompoundArray ( ) ) 
path . add ( 0 , cursor ) ; 
if ( cursor . getScheme ( ) == Scheme . SEQUENCE ) { 
Nc4Cursor next = ( Nc4Cursor ) cursor . getContainer ( ) ; 
if ( next == null ) { 
assert cursor . getTemplate ( ) . isTopLevel ( ) ; 
assert next . getTemplate ( ) . getSort ( ) == DapSort . VARIABLE ; 
cursor = next ; 
} public TypeNotes 
getVlenType ( DapVariable v ) 
DapType t = v . getBaseType ( ) ; 
if ( t . getSort ( ) != DapSort . SEQUENCE 
|| ( ( DapSequence ) t ) . getFields ( ) . size ( ) != 1 ) 
throw new IllegalArgumentException ( t . getFQN ( ) ) ; 
DapSequence ds = ( DapSequence ) t ; 
DapVariable f0 = ds . getField ( 0 ) ; 
DapType f0type = f0 . getBaseType ( ) ; 
return ( TypeNotes ) ( ( Nc4DSP ) this . dsp ) . find ( f0type ) ; 
public File saveObjectToFile ( S3URI s3uri , File file ) throws IOException { 
Optional < File > cachedFile = objectFileCache . getIfPresent ( s3uri ) ; 
if ( cachedFile == null ) { 
if ( ! cachedFile . isPresent ( ) ) { 
} else if ( ! cachedFile . get ( ) . exists ( ) ) { 
objectFileCache . invalidate ( s3uri ) ; 
} else if ( ! cachedFile . get ( ) . equals ( file ) ) { 
Files . copy ( cachedFile . get ( ) , file ) ; 
objectFileCache . put ( s3uri , Optional . of ( file ) ) ; 
cachedFile = Optional . fromNullable ( threddsS3Client . saveObjectToFile ( s3uri , file ) ) ; 
objectFileCache . put ( s3uri , cachedFile ) ; 
return cachedFile . orNull ( ) ; 
} public static < T extends JComponent > List < T > getDescendantsOfType ( 
Class < T > clazz , Container container ) { 
return getDescendantsOfType ( clazz , container , true ) ; 
Class < T > clazz , Container container , boolean nested ) { 
List < T > tList = new ArrayList < T > ( ) ; 
for ( Component component : container . getComponents ( ) ) { 
if ( clazz . isAssignableFrom ( component . getClass ( ) ) ) { 
tList . add ( clazz . cast ( component ) ) ; 
if ( nested || ! clazz . isAssignableFrom ( component . getClass ( ) ) ) { 
tList . addAll ( SwingUtils . < T > getDescendantsOfType ( clazz , 
( Container ) component , nested ) ) ; 
return tList ; 
} public static < T extends JComponent > T getDescendantOfType ( Class < T > clazz , 
Container container , String property , Object value , boolean nested ) 
List < T > list = getDescendantsOfType ( clazz , container , nested ) ; 
return getComponentFromList ( clazz , list , property , value ) ; 
} public static < T extends JComponent > T getDescendantOfClass ( Class < T > clazz , 
Container container , String property , Object value ) 
return getDescendantOfClass ( clazz , container , property , value , true ) ; 
List < T > list = getDescendantsOfClass ( clazz , container , nested ) ; 
} public static Map < JComponent , List < JComponent > > getComponentMap ( 
JComponent container , boolean nested ) { 
HashMap < JComponent , List < JComponent > > retVal = 
new HashMap < JComponent , List < JComponent > > ( ) ; 
for ( JComponent component : getDescendantsOfType ( JComponent . class , 
container , false ) ) { 
if ( ! retVal . containsKey ( container ) ) { 
retVal . put ( container , 
new ArrayList < JComponent > ( ) ) ; 
retVal . get ( container ) . add ( component ) ; 
if ( nested ) { 
retVal . putAll ( getComponentMap ( component , nested ) ) ; 
} public static UIDefaults getUIDefaultsOfClass ( Class clazz ) { 
String name = clazz . getName ( ) ; 
name = name . substring ( name . lastIndexOf ( "." ) + 2 ) ; 
return getUIDefaultsOfClass ( name ) ; 
} public static UIDefaults getUIDefaultsOfClass ( String className ) { 
UIDefaults retVal = new UIDefaults ( ) ; 
UIDefaults defaults = UIManager . getLookAndFeelDefaults ( ) ; 
List < ? > listKeys = Collections . list ( defaults . keys ( ) ) ; 
for ( Object key : listKeys ) { 
if ( key instanceof String && ( ( String ) key ) . startsWith ( className ) ) { 
String stringKey = ( String ) key ; 
String property = stringKey ; 
if ( stringKey . contains ( "." ) ) { 
property = stringKey . substring ( stringKey . indexOf ( "." ) + 1 ) ; 
retVal . put ( property , defaults . get ( key ) ) ; 
} public static Object getUIDefaultOfClass ( Class clazz , String property ) { 
Object retVal = null ; 
UIDefaults defaults = getUIDefaultsOfClass ( clazz ) ; 
List < Object > listKeys = Collections . list ( defaults . keys ( ) ) ; 
if ( key . equals ( property ) ) { 
return defaults . get ( key ) ; 
if ( key . toString ( ) . equalsIgnoreCase ( property ) ) { 
retVal = defaults . get ( key ) ; 
} public static Map < Object , Object > getProperties ( JComponent component ) { 
Map < Object , Object > retVal = new HashMap < Object , Object > ( ) ; 
Class < ? > clazz = component . getClass ( ) ; 
Method [ ] methods = clazz . getMethods ( ) ; 
Object value = null ; 
for ( Method method : methods ) { 
if ( method . getName ( ) . matches ( "^(is|get).*" ) && 
method . getParameterTypes ( ) . length == 0 ) { 
Class returnType = method . getReturnType ( ) ; 
if ( returnType != void . class && 
! returnType . getName ( ) . startsWith ( "[" ) && 
! setExclude . contains ( method . getName ( ) ) ) { 
String key = method . getName ( ) ; 
value = method . invoke ( component ) ; 
if ( value != null && ! ( value instanceof Component ) ) { 
retVal . put ( key , value ) ; 
} catch ( InvocationTargetException ex ) { 
} public static < T extends JComponent > Class getJClass ( T component ) { 
while ( ! clazz . getName ( ) . matches ( "javax.swing.J[^.]*$" ) ) { 
clazz = clazz . getSuperclass ( ) ; 
return clazz ; 
assert ( this . dataset != null && this . databuffer != null ) ; 
for ( DapVariable vv : this . dataset . getTopVariables ( ) ) { 
D4Cursor data = compileVar ( vv , null ) ; 
this . dsp . addVariableData ( vv , data ) ; 
} protected D4Cursor 
compileStructureArray ( DapVariable var , D4Cursor container ) 
DapStructure dapstruct = ( DapStructure ) var . getBaseType ( ) ; 
D4Cursor structarray = new D4Cursor ( Scheme . STRUCTARRAY , this . dsp , var , container ) 
. setOffset ( getPos ( this . databuffer ) ) ; 
long dimproduct = DapUtil . dimProduct ( dimset ) ; 
D4Cursor [ ] instances = new D4Cursor [ ( int ) dimproduct ] ; 
Odometer odom = Odometer . factory ( DapUtil . dimsetToSlices ( dimset ) , dimset ) ; 
D4Cursor instance = compileStructure ( var , dapstruct , structarray ) ; 
instance . setIndex ( index ) ; 
instances [ ( int ) index . index ( ) ] = instance ; 
structarray . setElements ( instances ) ; 
return structarray ; 
compileStructure ( DapVariable var , DapStructure dapstruct , D4Cursor container ) 
int pos = getPos ( this . databuffer ) ; 
D4Cursor d4ds = new D4Cursor ( Scheme . STRUCTURE , ( D4DSP ) this . dsp , var , container ) 
. setOffset ( pos ) ; 
List < DapVariable > dfields = dapstruct . getFields ( ) ; 
for ( int m = 0 ; m < dfields . size ( ) ; m ++ ) { 
DapVariable dfield = dfields . get ( m ) ; 
D4Cursor dvfield = compileVar ( dfield , d4ds ) ; 
d4ds . addField ( m , dvfield ) ; 
assert dfield . getParent ( ) != null ; 
return d4ds ; 
compileSequenceArray ( DapVariable var , D4Cursor container ) 
DapSequence dapseq = ( DapSequence ) var . getBaseType ( ) ; 
D4Cursor seqarray = new D4Cursor ( Scheme . SEQARRAY , this . dsp , var , container ) 
D4Cursor instance = compileSequence ( var , dapseq , seqarray ) ; 
seqarray . setElements ( instances ) ; 
return seqarray ; 
compileSequence ( DapVariable var , DapSequence dapseq , D4Cursor container ) 
D4Cursor seq = new D4Cursor ( Scheme . SEQUENCE , this . dsp , var , container ) 
List < DapVariable > dfields = dapseq . getFields ( ) ; 
long nrecs = getCount ( this . databuffer ) ; 
for ( int r = 0 ; r < nrecs ; r ++ ) { 
pos = getPos ( this . databuffer ) ; 
D4Cursor rec = ( D4Cursor ) new D4Cursor ( D4Cursor . Scheme . RECORD , this . dsp , var , container ) 
. setOffset ( pos ) . setRecordIndex ( r ) ; 
D4Cursor dvfield = compileVar ( dfield , rec ) ; 
rec . addField ( m , dvfield ) ; 
seq . addRecord ( rec ) ; 
} protected int 
extractChecksum ( ByteBuffer data ) 
assert ChecksumMode . DAP . enabled ( this . checksummode ) ; 
if ( data . remaining ( ) < DapUtil . CHECKSUMSIZE ) 
return data . getInt ( ) ; 
} public final void readLEDoubles ( double [ ] d , int n ) throws IOException { 
int nLeft = n ; 
int dCount = 0 ; 
int nToRead = kLongs ; 
while ( nLeft > 0 ) { 
if ( nToRead > nLeft ) 
nToRead = nLeft ; 
readLELongs ( longWorkSpace , nToRead ) ; 
for ( int i = 0 ; i < nToRead ; i ++ ) { 
d [ dCount ++ ] = Double . longBitsToDouble ( longWorkSpace [ i ] ) ; 
nLeft -= nToRead ; 
} public long readLELong ( ) throws IOException { 
readFully ( w , 0 , 8 ) ; 
( long ) ( w [ 7 ] & 0xff ) << 56 | 
( long ) ( w [ 6 ] & 0xff ) << 48 | 
( long ) ( w [ 5 ] & 0xff ) << 40 | 
( long ) ( w [ 4 ] & 0xff ) << 32 | 
( long ) ( w [ 3 ] & 0xff ) << 24 | 
( long ) ( w [ 2 ] & 0xff ) << 16 | 
( long ) ( w [ 1 ] & 0xff ) << 8 | 
( long ) ( w [ 0 ] & 0xff ) ; 
} public final void readLELongs ( long lbuf [ ] , int n ) throws IOException { 
int lCount = 0 ; 
readFully ( byteWorkSpace , 0 , 8 * nToRead ) ; 
lbuf [ lCount ++ ] = 
( long ) ( byteWorkSpace [ j ] & 0xff ) | 
( long ) ( byteWorkSpace [ j + 1 ] & 0xff ) << 8 | 
( long ) ( byteWorkSpace [ j + 2 ] & 0xff ) << 16 | 
( long ) ( byteWorkSpace [ j + 3 ] & 0xff ) << 24 | 
( long ) ( byteWorkSpace [ j + 4 ] & 0xff ) << 32 | 
( long ) ( byteWorkSpace [ j + 5 ] & 0xff ) << 40 | 
( long ) ( byteWorkSpace [ j + 6 ] & 0xff ) << 48 | 
( long ) ( byteWorkSpace [ j + 7 ] & 0xff ) << 56 ; 
j += 8 ; 
} protected String matchAxisTypeAndDimension ( NetcdfDataset ds , AxisType type , final Dimension outer , final Dimension inner ) { 
Variable var = CoordSysEvaluator . findCoordByType ( ds , type , new CoordSysEvaluator . Predicate ( ) { 
public boolean match ( CoordinateAxis axis ) { 
return ( ( axis . getRank ( ) == 2 ) && outer . equals ( axis . getDimension ( 0 ) ) && inner . equals ( axis . getDimension ( 1 ) ) ) ; 
return var . getShortName ( ) ; 
static Grib1Collection readFromIndex ( String name , RandomAccessFile raf , 
FeatureCollectionConfig config , org . slf4j . Logger logger ) { 
Grib1CollectionBuilderFromIndex builder = new Grib1CollectionBuilderFromIndex ( name , config , logger ) ; 
if ( ! builder . readIndex ( raf ) ) 
if ( builder . gc . getFiles ( ) . size ( ) == 0 ) { 
return new Grib1Collection ( builder . gc ) ; 
} public void addActionListener ( ActionListener l ) { 
listenerList . add ( java . awt . event . ActionListener . class , l ) ; 
} public void removeActionListener ( ActionListener l ) { 
listenerList . remove ( java . awt . event . ActionListener . class , l ) ; 
} public boolean accept ( ) { 
for ( Object o : flds . values ( ) ) 
ok &= ( ( Field ) o ) . accept ( buff ) ; 
if ( ! ok ) { 
try { JOptionPane . showMessageDialog ( PrefPanel . findActiveFrame ( ) , buff . toString ( ) ) ; } 
catch ( HeadlessException e ) { } 
fireEvent ( new ActionEvent ( this , 0 , "Accept" ) ) ; 
} public Field getField ( String name ) { 
Field fld = flds . get ( name ) ; 
if ( fld == null ) return null ; 
return ( fld instanceof FieldResizable ) ? ( ( FieldResizable ) fld ) . getDelegate ( ) : fld ; 
} public Object getFieldValue ( String name ) { 
Field fld = getField ( name ) ; 
return fld . getValue ( ) ; 
} public void setFieldValue ( String name , Object value ) { 
fld . setValue ( value ) ; 
} public Field addField ( Field fld ) { 
addField ( fld , cursorCol , cursorRow , null ) ; 
cursorRow ++ ; 
return fld ; 
} public Field . CheckBox addCheckBoxField ( String fldName , String label , boolean defValue ) { 
Field . CheckBox fld = new Field . CheckBox ( fldName , label , defValue , storeData ) ; 
addField ( fld ) ; 
} public Field . Date addDateField ( String fldName , String label , Date defValue ) { 
Field . Date fld = new Field . Date ( fldName , label , defValue , storeData ) ; 
addField ( new FieldResizable ( fld , this ) ) ; 
} public Field . Double addDoubleField ( String fldName , String label , double defValue ) { 
Field . Double fld = new Field . Double ( fldName , label , defValue , - 1 , storeData ) ; 
} public Field . Int addIntField ( String fldName , String label , int defValue ) { 
Field . Int fld = new Field . Int ( fldName , label , defValue , storeData ) ; 
} public Field . Password addPasswordField ( String fldName , String label , String defValue ) { 
Field . Password fld = new Field . Password ( fldName , label , defValue , storeData ) ; 
} public Field . Text addTextField ( String fldName , String label , String defValue ) { 
Field . Text fld = new Field . Text ( fldName , label , defValue , storeData ) ; 
} public Field . TextCombo addTextComboField ( String fldName , String label , java . util . Collection defValues , int nKeep , boolean editable ) { 
Field . TextCombo fld = new Field . TextCombo ( fldName , label , defValues , nKeep , storeData ) ; 
fld . setEditable ( editable ) ; 
} public Field . TextArea addTextAreaField ( String fldName , String label , String def , int nrows ) { 
Field . TextArea fld = new Field . TextArea ( fldName , label , def , nrows , storeData ) ; 
} public void addHeading ( String heading , int row ) { 
layoutComponents . add ( new LayoutComponent ( heading , 0 , row , null ) ) ; 
} public void addComponent ( Component comp , int col , int row , String constraint ) { 
layoutComponents . add ( new LayoutComponent ( comp , col , row , constraint ) ) ; 
} public void addEmptyRow ( int row , int size ) { 
layoutComponents . add ( new LayoutComponent ( null , size , row , null ) ) ; 
} public void finish ( boolean addButtons , String where ) { 
if ( finished ) 
Collections . sort ( layoutComponents , new Comparator < LayoutComponent > ( ) { 
public int compare ( LayoutComponent o1 , LayoutComponent o2 ) { 
return o1 . col - o2 . col ; 
public boolean equals ( Object o1 ) { return o1 == this ; } 
int currCol = - 1 ; 
Iterator iter = layoutComponents . iterator ( ) ; 
LayoutComponent lc = ( LayoutComponent ) iter . next ( ) ; 
if ( lc . col > currCol ) { 
if ( currCol >= 0 ) 
currCol += 2 ; 
lc . ccLabel . gridX = 2 * lc . col + 2 ; 
lc . cc . gridX = 2 * lc . col + 4 ; 
String colSpec = sbuff . toString ( ) ; 
int ncols = 2 * currCol ; 
return o1 . row - o2 . row ; 
int incr = 0 ; 
iter = layoutComponents . iterator ( ) ; 
if ( ( lc . comp instanceof String ) && ( lc . row > 0 ) ) 
incr ++ ; 
lc . cc . gridY = lc . row + incr + 1 ; 
lc . ccLabel . gridY = lc . cc . gridY ; 
int currRow = - 1 ; 
while ( lc . row > currRow ) { 
if ( ( lc . comp instanceof String ) && ( lc . row > 0 ) ) { 
} else if ( ( lc . comp == null ) ) { 
sbuff . append ( "default" ) ; 
currRow ++ ; 
String rowSpec = sbuff . toString ( ) ; 
FormLayout layout = new FormLayout ( colSpec , rowSpec ) ; 
PanelBuilder builder = new PanelBuilder ( layout ) ; 
builder . setDefaultDialogBorder ( ) ; 
CellConstraints cc = new CellConstraints ( ) ; 
if ( lc . comp instanceof Field ) { 
Field fld = ( Field ) lc . comp ; 
builder . addLabel ( fld . getLabel ( ) + ":" , lc . ccLabel ) ; 
Component comp = fld . getEditComponent ( ) ; 
if ( lc . comp instanceof Field . TextArea ) 
comp = new JScrollPane ( comp ) ; 
builder . add ( comp , lc . cc ) ; 
} else if ( lc . comp instanceof String ) { 
String header = ( String ) lc . comp ; 
builder . addSeparator ( header , cc . xyw ( 1 , lc . cc . gridY , ncols ) ) ; 
} else if ( lc . comp instanceof Component ) { 
builder . add ( ( Component ) lc . comp , lc . cc ) ; 
mainPanel = builder . getPanel ( ) ; 
JPanel buttPanel = new JPanel ( ) ; 
JButton acceptButton = new JButton ( "Apply" ) ; 
buttPanel . add ( acceptButton , null ) ; 
for ( JComponent auxButton : auxButtons ) 
buttPanel . add ( auxButton , null ) ; 
acceptButton . addActionListener ( new ActionListener ( ) { 
public void actionPerformed ( ActionEvent evt ) { 
accept ( ) ; 
add ( mainPanel , BorderLayout . CENTER ) ; 
if ( addButtons ) { 
if ( where . equals ( BorderLayout . SOUTH ) ) { 
JPanel south = new JPanel ( ) ; 
south . setLayout ( new BoxLayout ( south , BoxLayout . Y_AXIS ) ) ; 
south . add ( new JSeparator ( SwingConstants . HORIZONTAL ) ) ; 
south . add ( buttPanel ) ; 
add ( south , BorderLayout . SOUTH ) ; 
add ( buttPanel , where ) ; 
finished = true ; 
} static public Frame findActiveFrame ( ) { 
Frame [ ] frames = JFrame . getFrames ( ) ; 
for ( Frame frame : frames ) { 
if ( frame . isVisible ( ) ) 
return frame ; 
if ( localVal == null ) 
setValue ( localVal ) ; 
} public float getCellSpacing ( ) throws DescriptorException { 
float [ ] cellRanges = myCELV . getCellRanges ( ) ; 
float cellSpacing = cellRanges [ 1 ] - cellRanges [ 0 ] ; 
for ( int i = 2 ; i < cellRanges . length ; i ++ ) { 
float space = cellRanges [ i ] - cellRanges [ i - 1 ] ; 
if ( ! Misc . nearlyEquals ( space , cellSpacing ) && ( Math . abs ( space / cellSpacing - 1.0 ) > 0.01 ) ) { 
return cellSpacing ; 
} public final Factor [ ] getFactors ( ) { 
final Factor [ ] factors = new Factor [ _factors . length ] ; 
System . arraycopy ( _factors , 0 , factors , 0 , factors . length ) ; 
return factors ; 
} protected Factor [ ] mult ( final Dimension that ) { 
final Factor [ ] factors1 = _factors ; 
final Factor [ ] factors2 = that . _factors ; 
int i1 = 0 ; 
int i2 = 0 ; 
int k = 0 ; 
Factor [ ] newFactors = new Factor [ factors1 . length + factors2 . length ] ; 
if ( i1 == factors1 . length ) { 
final int n = factors2 . length - i2 ; 
System . arraycopy ( factors2 , i2 , newFactors , k , n ) ; 
k += n ; 
if ( i2 == factors2 . length ) { 
final int n = factors1 . length - i1 ; 
System . arraycopy ( factors1 , i1 , newFactors , k , n ) ; 
final Factor f1 = factors1 [ i1 ] ; 
final Factor f2 = factors2 [ i2 ] ; 
final int comp = f1 . getID ( ) . compareTo ( f2 . getID ( ) ) ; 
if ( comp < 0 ) { 
newFactors [ k ++ ] = f1 ; 
i1 ++ ; 
else if ( comp == 0 ) { 
final int exponent = f1 . getExponent ( ) + f2 . getExponent ( ) ; 
if ( exponent != 0 ) { 
newFactors [ k ++ ] = new Factor ( f1 , exponent ) ; 
i2 ++ ; 
newFactors [ k ++ ] = f2 ; 
if ( k < newFactors . length ) { 
final Factor [ ] tmp = new Factor [ k ] ; 
System . arraycopy ( newFactors , 0 , tmp , 0 , k ) ; 
newFactors = tmp ; 
return newFactors ; 
} protected Factor [ ] pow ( final int power ) { 
Factor [ ] factors ; 
if ( power == 0 ) { 
factors = new Factor [ 0 ] ; 
factors = getFactors ( ) ; 
if ( power != 1 ) { 
for ( int i = factors . length ; -- i >= 0 ; ) { 
factors [ i ] = factors [ i ] . pow ( power ) ; 
} public final boolean isReciprocalOf ( final Dimension that ) { 
final Factor [ ] theseFactors = _factors ; 
final Factor [ ] thoseFactors = that . _factors ; 
boolean isReciprocalOf ; 
if ( theseFactors . length != thoseFactors . length ) { 
isReciprocalOf = false ; 
for ( i = theseFactors . length ; -- i >= 0 ; ) { 
if ( ! theseFactors [ i ] . isReciprocalOf ( thoseFactors [ i ] ) ) { 
isReciprocalOf = i < 0 ; 
return isReciprocalOf ; 
} public final boolean isDimensionless ( ) { 
for ( int i = _factors . length ; -- i >= 0 ; ) { 
if ( ! _factors [ i ] . isDimensionless ( ) ) { 
} public static OMObservationPropertyType initObservationMember ( OMObservationPropertyType observationMember , 
NcOMObservationType . initOmObservation ( observationMember . addNewOMObservation ( ) , stationFeat , dataVar ) ; 
return observationMember ; 
} protected void fireTreeNodesChanged ( Object source , Object [ ] path , 
int [ ] childIndices , 
Object [ ] children ) { 
TreeModelEvent e = null ; 
for ( int i = listeners . length - 2 ; i >= 0 ; i -= 2 ) { 
if ( listeners [ i ] == TreeModelListener . class ) { 
if ( e == null ) 
e = new TreeModelEvent ( source , path , 
childIndices , children ) ; 
( ( TreeModelListener ) listeners [ i + 1 ] ) . treeNodesChanged ( e ) ; 
} protected void fireTreeNodesInserted ( Object source , Object [ ] path , 
( ( TreeModelListener ) listeners [ i + 1 ] ) . treeNodesInserted ( e ) ; 
} protected void fireTreeNodesRemoved ( Object source , Object [ ] path , 
( ( TreeModelListener ) listeners [ i + 1 ] ) . treeNodesRemoved ( e ) ; 
} public void persistWrite ( ) throws IOException { 
if ( diskCache2 == null ) 
String cacheName = getCacheName ( ) ; 
if ( cacheName == null ) return ; 
if ( cacheName . startsWith ( "file:" ) ) 
cacheName = cacheName . substring ( 5 ) ; 
File cacheFile = diskCache2 . getCacheFile ( cacheName ) ; 
if ( cacheFile == null ) throw new IllegalStateException ( ) ; 
if ( ! cacheDirty && cacheFile . exists ( ) ) 
FileChannel channel = null ; 
File dir = cacheFile . getParentFile ( ) ; 
if ( ! dir . mkdirs ( ) ) 
FileOutputStream fos = new FileOutputStream ( cacheFile ) ; 
channel = fos . getChannel ( ) ; 
lock = channel . tryLock ( ) ; 
} catch ( OverlappingFileLockException e ) { 
if ( lock == null ) return ; 
PrintWriter out = new PrintWriter ( new OutputStreamWriter ( fos , CDM . utf8Charset ) ) ; 
if ( dimName != null ) 
if ( datasetManager . getRecheck ( ) != null ) 
out . print ( ">\n" ) ; 
for ( Dataset dataset : nestedDatasets ) { 
DatasetOuterDimension dod = ( DatasetOuterDimension ) dataset ; 
for ( CacheVar pv : cacheList ) { 
Array data = pv . getData ( dod . getId ( ) ) ; 
while ( data . hasNext ( ) ) 
out . print ( "</cache>\n" ) ; 
if ( logger . isDebugEnabled ( ) ) 
out . print ( "</aggregation>\n" ) ; 
long time = datasetManager . getLastScanned ( ) ; 
if ( time == 0 ) time = System . currentTimeMillis ( ) ; 
if ( ! cacheFile . setLastModified ( time ) ) 
cacheDirty = false ; 
if ( channel != null ) 
} protected void persistRead ( ) { 
if ( diskCache2 == null ) return ; 
if ( ! cacheFile . exists ( ) ) 
long lastWritten = cacheFile . lastModified ( ) ; 
Element aggElem ; 
aggElem = ucar . nc2 . util . xml . Parse . readRootElement ( "file:" + cacheFile . getPath ( ) ) ; 
String version = aggElem . getAttributeValue ( "version" ) ; 
if ( ( version == null ) || ! version . equals ( "3" ) ) return ; 
Map < String , Dataset > map = new HashMap < String , Dataset > ( ) ; 
for ( Dataset ds : getDatasets ( ) ) { 
map . put ( ds . getId ( ) , ds ) ; 
List < Element > ncList = aggElem . getChildren ( "netcdf" , Catalog . ncmlNS ) ; 
for ( Element netcdfElemNested : ncList ) { 
String id = netcdfElemNested . getAttributeValue ( "id" ) ; 
DatasetOuterDimension dod = ( DatasetOuterDimension ) map . get ( id ) ; 
if ( null == dod ) { 
MFile mfile = dod . getMFile ( ) ; 
if ( mfile != null && mfile . getLastModified ( ) > lastWritten ) { 
if ( dod . ncoord == 0 ) { 
String ncoordsS = netcdfElemNested . getAttributeValue ( "ncoords" ) ; 
dod . ncoord = Integer . parseInt ( ncoordsS ) ; 
List < Element > cacheElemList = netcdfElemNested . getChildren ( "cache" , Catalog . ncmlNS ) ; 
for ( Element cacheElemNested : cacheElemList ) { 
String varName = cacheElemNested . getAttributeValue ( "varName" ) ; 
CacheVar pv = findCacheVariable ( varName ) ; 
if ( pv != null ) { 
String sdata = cacheElemNested . getText ( ) ; 
if ( sdata . length ( ) == 0 ) continue ; 
Array data = Array . makeArray ( pv . dtype , vals ) ; 
pv . putData ( id , data ) ; 
countCacheUse ++ ; 
} private String getCacheName ( ) { 
String cacheName = ncDataset . getLocation ( ) ; 
if ( cacheName == null ) cacheName = ncDataset . getCacheName ( ) ; 
return cacheName ; 
} static int makeKey ( int center , int subcenter , int version ) { 
if ( center < 0 ) center = 255 ; 
if ( subcenter < 0 ) subcenter = 255 ; 
if ( version < 0 ) version = 255 ; 
return center * 1000 * 1000 + subcenter * 1000 + version ; 
} public static Grib1ParamTables factory ( String paramTablePath , String lookupTablePath ) throws IOException { 
if ( paramTablePath == null && lookupTablePath == null ) return new Grib1ParamTables ( ) ; 
Lookup lookup = null ; 
Grib1ParamTableReader override = null ; 
Grib1ParamTableReader table ; 
if ( paramTablePath != null ) { 
table = localTableHash . get ( paramTablePath ) ; 
if ( table == null ) { 
table = new Grib1ParamTableReader ( paramTablePath ) ; 
localTableHash . put ( paramTablePath , table ) ; 
override = table ; 
if ( lookupTablePath != null ) { 
lookup = new Lookup ( ) ; 
if ( ! lookup . readLookupTable ( lookupTablePath ) ) 
return new Grib1ParamTables ( lookup , override ) ; 
} public static Grib1ParamTables factory ( org . jdom2 . Element paramTableElem ) { 
if ( paramTableElem == null ) return new Grib1ParamTables ( ) ; 
return new Grib1ParamTables ( null , new Grib1ParamTableReader ( paramTableElem ) ) ; 
} public Grib1ParamTableReader getParameterTable ( int center , int subcenter , int tableVersion ) { 
Grib1ParamTableReader result = null ; 
if ( lookup != null ) 
result = lookup . getParameterTable ( center , subcenter , tableVersion ) ; 
result = standardLookup . getParameterTable ( center , subcenter , tableVersion ) ; 
} public static boolean addParameterTableLookup ( String lookupFilename ) throws IOException { 
Lookup lookup = new Lookup ( ) ; 
if ( ! lookup . readLookupTable ( lookupFilename ) ) 
standardLookup . tables . addAll ( standardTablesStart , lookup . tables ) ; 
standardTablesStart += lookup . tables . size ( ) ; 
} public static void addParameterTable ( int center , int subcenter , int tableVersion , String tableFilename ) { 
Grib1ParamTableReader table = new Grib1ParamTableReader ( center , subcenter , tableVersion , tableFilename ) ; 
standardLookup . tables . add ( standardTablesStart , table ) ; 
standardTablesStart ++ ; 
if ( ! that . isDimensionless ( ) ) { 
throw new MultiplyException ( that ) ; 
? new ScaledUnit ( ( ( ScaledUnit ) that ) . getScale ( ) , this ) 
: this ; 
protected Unit myDivideBy ( final Unit that ) throws DivideException { 
throw new DivideException ( that ) ; 
? new ScaledUnit ( 1.0 / ( ( ScaledUnit ) that ) . getScale ( ) , this ) 
return DerivedUnitImpl . DIMENSIONLESS ; 
if ( power == 1 ) { 
throw new RaiseException ( this ) ; 
output [ i ] = ( float ) ( Math . exp ( input [ i ] * lnBase ) ) ; 
return reference . toDerivedUnit ( output , output ) ; 
} public float [ ] fromDerivedUnit ( final float [ ] input , final float [ ] output ) 
reference . fromDerivedUnit ( input , output ) ; 
output [ i ] = ( float ) ( Math . log ( output [ i ] ) / lnBase ) ; 
String got = raf . readString ( V5D . length ( ) ) ; 
if ( got . equals ( V5D ) ) { 
V5DStruct vv ; 
vv = V5DStruct . v5dOpenFile ( raf ) ; 
} catch ( BadFormException bfe ) { 
vv = null ; 
return vv != null ; 
if ( unitTable == null ) { 
initUnitTable ( ) ; 
if ( v5dstruct == null ) { 
makeFile ( raf , ncfile , cancelTask ) ; 
} private void makeFile ( RandomAccessFile raf , NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { 
ncfile . empty ( ) ; 
int [ ] sizes = new int [ 5 ] ; 
int [ ] map_proj = new int [ 1 ] ; 
String [ ] varnames = new String [ MAXVARS ] ; 
String [ ] varunits = new String [ MAXVARS ] ; 
int [ ] n_levels = new int [ MAXVARS ] ; 
int [ ] vert_sys = new int [ 1 ] ; 
float [ ] vertargs = new float [ MAXVERTARGS ] ; 
double [ ] times = new double [ MAXTIMES ] ; 
float [ ] projargs = new float [ MAXPROJARGS ] ; 
v5dstruct = V5DStruct . v5d_open ( raf , sizes , n_levels , varnames , 
varunits , map_proj , projargs , 
vert_sys , vertargs , times ) ; 
+ bfe . getMessage ( ) ) ; 
if ( sizes [ 0 ] < 1 ) { 
int nr = sizes [ 0 ] ; 
int nc = sizes [ 1 ] ; 
int nl = sizes [ 2 ] ; 
int ntimes = sizes [ 3 ] ; 
int nvars = sizes [ 4 ] ; 
Dimension time = new Dimension ( TIME , ntimes , true ) ; 
Dimension row = new Dimension ( ROW , nr , true ) ; 
Dimension col = new Dimension ( COLUMN , nc , true ) ; 
ncfile . addDimension ( null , row ) ; 
ncfile . addDimension ( null , col ) ; 
Variable timeVar = new Variable ( ncfile , null , null , TIME ) ; 
timeVar . setDataType ( DataType . DOUBLE ) ; 
timeVar . setDimensions ( TIME ) ; 
timeVar . addAttribute ( 
timeVar . addAttribute ( new Attribute ( "long_name" , TIME ) ) ; 
Array varArray = new ArrayDouble . D1 ( ntimes ) ; 
for ( int i = 0 ; i < ntimes ; i ++ ) { 
( ( ArrayDouble . D1 ) varArray ) . set ( i , times [ i ] ) ; 
Variable rowVar = new Variable ( ncfile , null , null , ROW ) ; 
rowVar . setDataType ( DataType . INT ) ; 
rowVar . setDimensions ( ROW ) ; 
varArray = new ArrayInt . D1 ( nr , false ) ; 
for ( int i = 0 ; i < nr ; i ++ ) { 
rowVar . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , rowVar ) ; 
Variable colVar = new Variable ( ncfile , null , null , COLUMN ) ; 
colVar . setDataType ( DataType . INT ) ; 
colVar . setDimensions ( COLUMN ) ; 
varArray = new ArrayInt . D1 ( nc , false ) ; 
for ( int i = 0 ; i < nc ; i ++ ) { 
colVar . setCachedData ( varArray , false ) ; 
ncfile . addVariable ( null , colVar ) ; 
Hashtable < Integer , Object > var_table = new Hashtable < > ( ) ; 
boolean have3D = false ; 
for ( int i = 0 ; i < nvars ; i ++ ) { 
int nlevs = n_levels [ i ] ; 
if ( ! have3D && ( nlevs > 1 ) ) { 
have3D = true ; 
var_table . put ( nlevs , new Object ( ) ) ; 
int n_var_groups = var_table . size ( ) ; 
if ( n_var_groups > 2 ) { 
throw new IOException ( 
} else if ( n_var_groups == 0 ) { 
Variable vert = null ; 
if ( have3D ) { 
Dimension lev = new Dimension ( LEVEL , nl , true ) ; 
ncfile . addDimension ( null , lev ) ; 
vert = makeVerticalVariable ( vert_sys [ 0 ] , nl , vertargs ) ; 
if ( vert != null ) { 
ncfile . addVariable ( null , vert ) ; 
varTable = new Hashtable < > ( ) ; 
String coords3D = "unknown" ; 
Variable v = new Variable ( ncfile , null , null , varnames [ i ] ) ; 
if ( n_levels [ i ] > 1 ) { 
v . setDimensions ( dim3D ) ; 
v . addAttribute ( new Attribute ( CF . COORDINATES , coords3D ) ) ; 
v . setDimensions ( dim2D ) ; 
v . addAttribute ( new Attribute ( CF . COORDINATES , coords2D ) ) ; 
v . setDataType ( DataType . FLOAT ) ; 
String units = varunits [ i ] . trim ( ) ; 
if ( units . equals ( "" ) ) { 
String key = varnames [ i ] . trim ( ) . toLowerCase ( ) ; 
units = unitTable . get ( key ) ; 
if ( varTable . get ( v ) == null ) { 
varTable . put ( v , i ) ; 
double [ ] [ ] proj_args = Set . floatToDouble ( new float [ ] [ ] { 
projargs 
addLatLonVariables ( map_proj [ 0 ] , proj_args [ 0 ] , nr , nc ) ; 
Integer varIdx = varTable . get ( v2 ) ; 
if ( varIdx == null ) { 
int [ ] shape = v2 . getShape ( ) ; 
boolean haveZ = shape . length == 4 ; 
int nt = shape [ count ++ ] ; 
int nz = haveZ 
? shape [ count ++ ] 
int ny = shape [ count ++ ] ; 
int nx = shape [ count ] ; 
Range timeRange = section . getRange ( count ++ ) ; 
Range zRange = haveZ 
? section . getRange ( count ++ ) 
: null ; 
Range yRange = section . getRange ( count ++ ) ; 
Range xRange = section . getRange ( count ) ; 
int grid_size = nx * ny * nz ; 
float [ ] data = new float [ grid_size ] ; 
float [ ] ranges = new float [ 2 ] ; 
v5dstruct . v5d_read ( timeIdx , varIdx , ranges , data ) ; 
if ( ( ranges [ 0 ] >= 0.99E30 ) && ( ranges [ 1 ] <= - 0.99E30 ) ) { 
} else if ( ranges [ 0 ] > ranges [ 1 ] ) { 
+ v2 . getFullName ( ) ) ; 
float [ ] tmp_data = new float [ grid_size ] ; 
if ( zRange == null ) { 
for ( int mm = 0 ; mm < ny ; mm ++ ) { 
int start = ( mm + 1 ) * nx - 1 ; 
for ( int nn = 0 ; nn < nx ; nn ++ ) { 
tmp_data [ cnt ++ ] = data [ start -- ] ; 
for ( int ll = 0 ; ll < nz ; ll ++ ) { 
int start = ( ( mm + 1 ) * nx - 1 ) + nx * ny * ll ; 
data = tmp_data ; 
for ( float aData : data ) { 
ii . setFloatNext ( aData ) ; 
} private static void initUnitTable ( ) { 
unitTable = new Hashtable < > ( ) ; 
unitTable . put ( "t" , "K" ) ; 
unitTable . put ( "td" , "K" ) ; 
unitTable . put ( "thte" , "K" ) ; 
unitTable . put ( "u" , "m/s" ) ; 
unitTable . put ( "v" , "m/s" ) ; 
unitTable . put ( "w" , "m/s" ) ; 
unitTable . put ( "p" , "hPa" ) ; 
unitTable . put ( "mmsl" , "hPa" ) ; 
unitTable . put ( "rh" , "%" ) ; 
unitTable . put ( "rhfz" , "%" ) ; 
unitTable . put ( "zagl" , "m" ) ; 
} private Variable makeVerticalVariable ( int vert_sys , int n_levels , 
float [ ] vert_args ) 
String vert_unit = null ; 
String vert_type ; 
ArrayFloat . D1 data = new ArrayFloat . D1 ( n_levels ) ; 
AxisType axisType = null ; 
switch ( vert_sys ) { 
case ( 0 ) : 
vert_unit = null ; 
vert_type = "height" ; 
case ( 1 ) : 
case ( 2 ) : 
vert_unit = "km" ; 
vert_type = "altitude" ; 
case ( 3 ) : 
vert_unit = "mbar" ; 
vert_type = "pressure" ; 
Variable vertVar = new Variable ( ncfile , null , null , vert_type ) ; 
vertVar . setDimensions ( LEVEL ) ; 
vertVar . setDataType ( DataType . FLOAT ) ; 
if ( vert_unit != null ) { 
vertVar . addAttribute ( new Attribute ( CDM . UNITS , vert_unit ) ) ; 
if ( axisType != null ) { 
vertVar . addAttribute ( new Attribute ( _Coordinate . AxisType , 
for ( int i = 0 ; i < n_levels ; i ++ ) { 
data . set ( i , vert_args [ 0 ] + vert_args [ 1 ] * i ) ; 
data . set ( i , vert_args [ i ] ) ; 
Vis5DVerticalSystem . Vis5DVerticalCoordinateSystem vert_cs = 
new Vis5DVerticalSystem . Vis5DVerticalCoordinateSystem ( ) ; 
float [ ] [ ] pressures = new float [ 1 ] [ n_levels ] ; 
System . arraycopy ( vert_args , 0 , pressures [ 0 ] , 0 , n_levels ) ; 
pressures [ 0 ] [ i ] *= 1000 ; 
pressures = vert_cs . fromReference ( pressures ) ; 
data . set ( i , pressures [ 0 ] [ i ] ) ; 
} catch ( VisADException ve ) { 
vertVar . setCachedData ( data , false ) ; 
return vertVar ; 
} private void addLatLonVariables ( int map_proj , double [ ] proj_args , int nr , 
int nc ) 
Vis5DGridDefRecord vgd = new Vis5DGridDefRecord ( map_proj , proj_args , nr , nc ) ; 
GridHorizCoordSys ghc = new GridHorizCoordSys ( vgd , new Vis5DLookup ( ) , null ) ; 
Vis5DCoordinateSystem coord_sys ; 
coord_sys = new Vis5DCoordinateSystem ( map_proj , proj_args , nr , 
nc ) ; 
Variable lat = new Variable ( ncfile , null , null , LAT ) ; 
lat . setDataType ( DataType . DOUBLE ) ; 
lat . addAttribute ( new Attribute ( "long_name" , "latitude" ) ) ; 
lat . addAttribute ( new Attribute ( CDM . UNITS , CDM . LAT_UNITS ) ) ; 
lat . addAttribute ( new Attribute ( CF . STANDARD_NAME , "latitude" ) ) ; 
lat . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lat . toString ( ) ) ) ; 
ncfile . addVariable ( null , lat ) ; 
Variable lon = new Variable ( ncfile , null , null , LON ) ; 
lon . setDataType ( DataType . DOUBLE ) ; 
lon . addAttribute ( new Attribute ( CDM . UNITS , CDM . LON_UNITS ) ) ; 
lon . addAttribute ( new Attribute ( "long_name" , "longitude" ) ) ; 
lon . addAttribute ( new Attribute ( CF . STANDARD_NAME , "longitude" ) ) ; 
lon . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Lon . toString ( ) ) ) ; 
ncfile . addVariable ( null , lon ) ; 
int [ ] shape = new int [ ] { nc , nr } ; 
Array latArray = Array . factory ( DataType . DOUBLE , shape ) ; 
Array lonArray = Array . factory ( DataType . DOUBLE , shape ) ; 
double [ ] [ ] rowcol = new double [ 2 ] [ nr * nc ] ; 
for ( int x = 0 ; x < nc ; x ++ ) { 
for ( int y = 0 ; y < nr ; y ++ ) { 
int index = x * nr + y ; 
rowcol [ 0 ] [ index ] = y ; 
rowcol [ 1 ] [ index ] = x ; 
double [ ] [ ] latlon = coord_sys . toReference ( rowcol ) ; 
Index latIndex = latArray . getIndex ( ) ; 
Index lonIndex = lonArray . getIndex ( ) ; 
latArray . setDouble ( index , latlon [ 0 ] [ index ] ) ; 
lonArray . setDouble ( index , latlon [ 1 ] [ index ] ) ; 
lat . setCachedData ( latArray , false ) ; 
lon . setCachedData ( lonArray , false ) ; 
} protected byte [ ] readDescriptor ( RandomAccessFile file , 
boolean littleEndianData , 
String expectedName ) 
this . file = file ; 
this . littleEndianData = littleEndianData ; 
this . expectedName = expectedName ; 
verbose = getDefaultVerboseState ( expectedName ) ; 
byte [ ] data ; 
findNext ( file ) ; 
long startpos = file . getFilePointer ( ) ; 
byte [ ] header = new byte [ 8 ] ; 
file . readFully ( header ) ; 
descName = new String ( header , 0 , 4 , CDM . utf8Charset ) ; 
int size = grabInt ( header , 4 ) ; 
file . seek ( startpos ) ; 
data = new byte [ size ] ; 
file . readFully ( data ) ; 
} catch ( java . io . IOException ex ) { 
throw new DescriptorException ( ex ) ; 
if ( ! descName . equals ( expectedName ) ) 
expectedName + "'" ) ; 
} protected static void skipDescriptor ( RandomAccessFile file , 
boolean littleEndianData ) 
throws DescriptorException , java . io . IOException { 
file . readFully ( new byte [ 4 ] ) ; 
byte [ ] lenBytes = new byte [ 4 ] ; 
file . readFully ( lenBytes ) ; 
int descLen = grabInt ( lenBytes , 0 , littleEndianData ) ; 
file . readFully ( new byte [ descLen - 8 ] ) ; 
} catch ( java . io . EOFException eofex ) { 
} protected static String peekName ( RandomAccessFile file ) 
long filepos = file . getFilePointer ( ) ; 
byte [ ] nameBytes = new byte [ 4 ] ; 
if ( file . read ( nameBytes ) == - 1 ) 
file . seek ( filepos ) ; 
return new String ( nameBytes , CDM . utf8Charset ) ; 
} catch ( IOException ex ) { 
} public static boolean sweepfileIsLittleEndian ( RandomAccessFile file ) 
int descLen ; 
file . seek ( 0 ) ; 
byte [ ] bytes = new byte [ 4 ] ; 
file . readFully ( bytes ) ; 
descLen = file . readInt ( ) ; 
return ( descLen < 0 || descLen > 0xffffff ) ; 
} protected short grabShort ( byte [ ] bytes , int offset ) { 
int ndx0 = offset + ( littleEndianData ? 1 : 0 ) ; 
int ndx1 = offset + ( littleEndianData ? 0 : 1 ) ; 
return ( short ) ( bytes [ ndx0 ] << 8 | ( bytes [ ndx1 ] & 0xff ) ) ; 
} protected static int grabInt ( byte [ ] bytes , int offset , 
boolean littleEndianData ) { 
int ndx0 = offset + ( littleEndianData ? 3 : 0 ) ; 
int ndx1 = offset + ( littleEndianData ? 2 : 1 ) ; 
int ndx2 = offset + ( littleEndianData ? 1 : 2 ) ; 
int ndx3 = offset + ( littleEndianData ? 0 : 3 ) ; 
return ( bytes [ ndx0 ] << 24 | 
( bytes [ ndx1 ] & 0xff ) << 16 | 
( bytes [ ndx2 ] & 0xff ) << 8 | 
( bytes [ ndx3 ] & 0xff ) ) ; 
} protected float grabFloat ( byte [ ] bytes , int offset ) 
byte [ ] src ; 
if ( littleEndianData ) { 
src = new byte [ 4 ] ; 
src [ 0 ] = bytes [ offset + 3 ] ; 
src [ 1 ] = bytes [ offset + 2 ] ; 
src [ 2 ] = bytes [ offset + 1 ] ; 
src [ 3 ] = bytes [ offset ] ; 
src = bytes ; 
DataInputStream stream = 
new DataInputStream ( new ByteArrayInputStream ( src , offset , 4 ) ) ; 
return stream . readFloat ( ) ; 
} protected double grabDouble ( byte [ ] bytes , int offset ) 
src = new byte [ 8 ] ; 
src [ 0 ] = bytes [ offset + 7 ] ; 
src [ 1 ] = bytes [ offset + 6 ] ; 
src [ 2 ] = bytes [ offset + 5 ] ; 
src [ 3 ] = bytes [ offset + 4 ] ; 
src [ 4 ] = bytes [ offset + 3 ] ; 
src [ 5 ] = bytes [ offset + 2 ] ; 
src [ 6 ] = bytes [ offset + 1 ] ; 
src [ 7 ] = bytes [ offset ] ; 
new DataInputStream ( new ByteArrayInputStream ( src , offset , 8 ) ) ; 
return stream . readDouble ( ) ; 
} public static boolean getDefaultVerboseState ( String descriptorName ) { 
Boolean classVerboseState = classVerboseStates . get ( descriptorName . toUpperCase ( ) ) ; 
if ( classVerboseState != null ) 
return classVerboseState ; 
return defaultVerboseState ; 
} public static synchronized StandardUnitDB instance ( ) throws UnitDBException { 
instance = new StandardUnitDB ( ) ; 
} private void au ( final String name , final String definition ) 
throws UnitExistsException , NoSuchUnitException , 
UnitParseException , SpecificationException , UnitDBException , 
PrefixDBException , OperationException , NameException , 
UnitSystemException { 
au ( name , definition , null ) ; 
} private void au ( final String name , final String definition , 
final Unit unit = format . parse ( definition , this ) ; 
throw new NoSuchUnitException ( definition ) ; 
addUnit ( unit . clone ( UnitName . newUnitName ( name , plural , symbol ) ) ) ; 
} private void aa ( final String alias , final String name ) 
aa ( alias , name , null ) ; 
} private void as ( final String symbol , final String name ) 
addSymbol ( symbol , name ) ; 
final UnitDB db = StandardUnitDB . instance ( ) ; 
System . out . println ( "db.get(\"meter\")=" + db . get ( "meter" ) ) ; 
System . out . println ( "db.get(\"meters\")=" + db . get ( "meters" ) ) ; 
System . out . println ( "db.get(\"metre\")=" + db . get ( "metre" ) ) ; 
System . out . println ( "db.get(\"metres\")=" + db . get ( "metres" ) ) ; 
System . out . println ( "db.get(\"m\")=" + db . get ( "m" ) ) ; 
System . out . println ( "db.get(\"newton\")=" + db . get ( "newton" ) ) ; 
System . out . println ( "db.get(\"Cel\")=" + db . get ( "Cel" ) ) ; 
System . out . println ( "db.get(\"Roentgen\")=" + db . get ( "Roentgen" ) ) ; 
System . out . println ( "db.get(\"rad\")=" + db . get ( "rad" ) ) ; 
System . out . println ( "db.get(\"rd\")=" + db . get ( "rd" ) ) ; 
System . out . println ( "db.get(\"perches\")=" + db . get ( "perches" ) ) ; 
System . out . println ( "db.get(\"jiffies\")=" + db . get ( "jiffies" ) ) ; 
System . out . println ( "db.get(\"foo\")=" + db . get ( "foo" ) ) ; 
} static public String canonicalizeWrite ( String location ) { 
URI refURI = URI . create ( location ) ; 
if ( refURI . isAbsolute ( ) ) 
return location ; 
return "file:" + location ; 
} public static String resolve ( String baseUri , String relativeUri ) { 
if ( ( baseUri == null ) || ( relativeUri == null ) ) 
return relativeUri ; 
if ( relativeUri . startsWith ( "file:" ) ) 
if ( baseUri . startsWith ( "file:" ) ) { 
URI uriRelative = URI . create ( relativeUri ) ; 
if ( uriRelative . isAbsolute ( ) ) 
if ( ( relativeUri . length ( ) > 0 ) && ( relativeUri . charAt ( 0 ) == '#' ) ) 
return baseUri + relativeUri ; 
if ( ( relativeUri . length ( ) > 0 ) && ( relativeUri . charAt ( 0 ) == '/' ) ) 
baseUri = StringUtil2 . substitute ( baseUri , "\\" , "/" ) ; 
int pos = baseUri . lastIndexOf ( '/' ) ; 
String baseDir = baseUri . substring ( 0 , pos + 1 ) ; 
if ( relativeUri . equals ( "." ) ) { 
return baseDir ; 
return baseDir + relativeUri ; 
URI relativeURI = URI . create ( relativeUri ) ; 
if ( relativeURI . isAbsolute ( ) ) 
URI baseURI = URI . create ( baseUri ) ; 
URI resolvedURI = baseURI . resolve ( relativeURI ) ; 
return resolvedURI . toASCIIString ( ) ; 
} public static Converter 
create ( Unit fromUnit , Unit toUnit ) 
throws ConversionException 
return fromUnit . getConverterTo ( toUnit ) ; 
} public void writeRecord ( PointFeature sobs , StructureData sdata ) throws IOException { 
writeRecord ( sobs . getObservationTime ( ) , sobs . getObservationTimeAsCalendarDate ( ) , sobs . getLocation ( ) , sdata ) ; 
} public void addListSelectionListener ( ListSelectionListener l ) { 
listeners . add ( javax . swing . event . ListSelectionListener . class , l ) ; 
} public void removeListSelectionListener ( ListSelectionListener l ) { 
listeners . remove ( javax . swing . event . ListSelectionListener . class , l ) ; 
} public void setStructureData ( List < StructureData > structureData ) throws IOException { 
dataModel = new StructureDataModel ( structureData ) ; 
initTable ( dataModel ) ; 
} public void setPointFeatureData ( List < PointFeature > obsData ) throws IOException { 
dataModel = new PointFeatureDataModel ( obsData ) ; 
} public void draw ( java . awt . Graphics2D g , AffineTransform pixelAT ) { 
g . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , RenderingHints . VALUE_ANTIALIAS_OFF ) ; 
Iterator siter = getShapes ( g , pixelAT ) ; 
} protected Iterator getShapes ( java . awt . Graphics2D g , AffineTransform normal2device ) { 
if ( shapeList != null ) 
return shapeList . iterator ( ) ; 
if ( Debug . isSet ( "projection/LatLonShift" ) ) 
ProjectionImpl dataProject = getDataProjection ( ) ; 
List featList = getFeatures ( ) ; 
shapeList = new ArrayList ( featList . size ( ) ) ; 
Iterator iter = featList . iterator ( ) ; 
AbstractGisFeature feature = ( AbstractGisFeature ) iter . next ( ) ; 
Shape shape ; 
if ( dataProject == null ) 
shape = feature . getShape ( ) ; 
else if ( dataProject . isLatLon ( ) ) { 
shape = feature . getProjectedShape ( displayProject ) ; 
} else if ( dataProject == displayProject ) { 
shape = feature . getProjectedShape ( dataProject , displayProject ) ; 
shapeList . add ( shape ) ; 
} public static DocumentMetadataType initDocumentMetadata ( DocumentMetadataType documentMetadata ) { 
String id = MarshallingUtil . createIdForType ( DocumentMetadataType . class ) ; 
documentMetadata . setId ( id ) ; 
DateTime generationDate = MarshallingUtil . fixedGenerationDate ; 
if ( generationDate == null ) { 
generationDate = new DateTime ( ) ; 
documentMetadata . setGenerationDate ( generationDate . toGregorianCalendar ( ) ) ; 
return documentMetadata ; 
} private void makeUniqueTimeCoordinate2D ( NetcdfFile ncfile , Group g , CoordinateTime2D time2D ) { 
CoordinateRuntime runtime = time2D . getRuntimeCoordinate ( ) ; 
int countU = 0 ; 
for ( int run = 0 ; run < time2D . getNruns ( ) ; run ++ ) { 
CoordinateTimeAbstract timeCoord = time2D . getTimeCoordinate ( run ) ; 
countU += timeCoord . getSize ( ) ; 
int ntimes = countU ; 
String tcName = time2D . getName ( ) ; 
ncfile . addDimension ( g , new Dimension ( tcName , ntimes ) ) ; 
Variable v = ncfile 
. addVariable ( g , new Variable ( ncfile , g , null , tcName , DataType . DOUBLE , tcName ) ) ; 
String units = runtime . getUnit ( ) ; 
v . addAttribute ( new Attribute ( CF . STANDARD_NAME , CF . TIME ) ) ; 
v . addAttribute ( new Attribute ( CDM . LONG_NAME , Grib . GRIB_VALID_TIME ) ) ; 
v . addAttribute ( new Attribute ( CF . CALENDAR , Calendar . proleptic_gregorian . toString ( ) ) ) ; 
if ( ! time2D . isTimeInterval ( ) ) { 
v . setSPobject ( new Time2Dinfo ( Time2DinfoType . offU , time2D , null ) ) ; 
v . setSPobject ( new Time2Dinfo ( Time2DinfoType . intvU , time2D , null ) ) ; 
String bounds_name = tcName + "_bounds" ; 
Variable bounds = ncfile . addVariable ( g , 
v . addAttribute ( new Attribute ( CF . BOUNDS , bounds_name ) ) ; 
bounds . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; 
bounds . setSPobject ( new Time2Dinfo ( Time2DinfoType . boundsU , time2D , null ) ) ; 
if ( runtime . getNCoords ( ) != 1 ) { 
String refName = "ref" + tcName ; 
if ( g . findVariable ( refName ) == null ) { 
Variable vref = ncfile 
. addVariable ( g , new Variable ( ncfile , g , null , refName , DataType . DOUBLE , tcName ) ) ; 
vref . addAttribute ( new Attribute ( CF . STANDARD_NAME , CF . TIME_REFERENCE ) ) ; 
vref . addAttribute ( new Attribute ( CDM . LONG_NAME , Grib . GRIB_RUNTIME ) ) ; 
vref . addAttribute ( new Attribute ( CF . CALENDAR , Calendar . proleptic_gregorian . toString ( ) ) ) ; 
vref . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; 
vref . setSPobject ( new Time2Dinfo ( Time2DinfoType . isUniqueRuntime , time2D , null ) ) ; 
} private void makeTimeCoordinate2D ( NetcdfFile ncfile , Group g , CoordinateTime2D time2D , 
GribCollectionImmutable . Type gctype ) { 
int ntimes = time2D . getNtimes ( ) ; 
int dimLength = ntimes ; 
ncfile . addDimension ( g , new Dimension ( tcName , dimLength ) ) ; 
. addVariable ( g , new Variable ( ncfile , g , null , tcName , DataType . DOUBLE , dims ) ) ; 
v . setSPobject ( new Time2Dinfo ( Time2DinfoType . off , time2D , null ) ) ; 
v . setSPobject ( new Time2Dinfo ( Time2DinfoType . intv , time2D , null ) ) ; 
Variable bounds = ncfile 
bounds . setSPobject ( new Time2Dinfo ( Time2DinfoType . bounds , time2D , null ) ) ; 
} private Array makeLazyTime1Darray ( Variable v2 , Time2Dinfo info ) { 
int length = info . time1D . getSize ( ) ; 
double [ ] data = new double [ length ] ; 
data [ i ] = Double . NaN ; 
switch ( info . which ) { 
case reftime : 
CoordinateRuntime rtc = ( CoordinateRuntime ) info . time1D ; 
for ( double val : rtc . getOffsetsInTimeUnits ( ) ) { 
data [ count ++ ] = val ; 
return Array . factory ( DataType . DOUBLE , v2 . getShape ( ) , data ) ; 
case timeAuxRef : 
CoordinateTimeAbstract time = ( CoordinateTimeAbstract ) info . time1D ; 
List < Double > masterOffsets = gribCollection . getMasterRuntime ( ) . getOffsetsInTimeUnits ( ) ; 
for ( int masterIdx : time . getTime2runtime ( ) ) { 
data [ count ++ ] = masterOffsets . get ( masterIdx - 1 ) ; 
} private Array makeLazyTime2Darray ( Variable coord , Time2Dinfo info ) { 
CoordinateTime2D time2D = info . time2D ; 
CalendarPeriod timeUnit = time2D . getTimeUnit ( ) ; 
int nruns = time2D . getNruns ( ) ; 
int length = ( int ) coord . getSize ( ) ; 
if ( info . which == Time2DinfoType . bounds ) { 
length *= 2 ; 
int count ; 
case off : 
for ( int runIdx = 0 ; runIdx < nruns ; runIdx ++ ) { 
CoordinateTime coordTime = ( CoordinateTime ) time2D . getTimeCoordinate ( runIdx ) ; 
int timeIdx = 0 ; 
for ( int val : coordTime . getOffsetSorted ( ) ) { 
data [ runIdx * ntimes + timeIdx ] = timeUnit . getValue ( ) * val + time2D . getOffset ( runIdx ) ; 
timeIdx ++ ; 
case offU : 
data [ count ++ ] = timeUnit . getValue ( ) * val + time2D . getOffset ( runIdx ) ; 
case intv : 
CoordinateTimeIntv timeIntv = ( CoordinateTimeIntv ) time2D . getTimeCoordinate ( runIdx ) ; 
for ( TimeCoordIntvValue tinv : timeIntv . getTimeIntervals ( ) ) { 
data [ runIdx * ntimes + timeIdx ] = timeUnit . getValue ( ) * tinv . getBounds2 ( ) + time2D 
. getOffset ( runIdx ) ; 
case intvU : 
data [ count ++ ] = timeUnit . getValue ( ) * tinv . getBounds2 ( ) + time2D 
case is1Dtime : 
for ( double val : runtime . getOffsetsInTimeUnits ( ) ) { 
case isUniqueRuntime : 
CoordinateRuntime runtimeU = time2D . getRuntimeCoordinate ( ) ; 
List < Double > runOffsets = runtimeU . getOffsetsInTimeUnits ( ) ; 
for ( int time = 0 ; time < timeCoord . getNCoords ( ) ; time ++ ) { 
data [ count ++ ] = runOffsets . get ( run ) ; 
case bounds : 
data [ runIdx * ntimes * 2 + timeIdx ] = 
timeUnit . getValue ( ) * tinv . getBounds1 ( ) + time2D . getOffset ( runIdx ) ; 
data [ runIdx * ntimes * 2 + timeIdx + 1 ] = 
timeUnit . getValue ( ) * tinv . getBounds2 ( ) + time2D . getOffset ( runIdx ) ; 
timeIdx += 2 ; 
case boundsU : 
data [ count ++ ] = timeUnit . getValue ( ) * tinv . getBounds1 ( ) + time2D . getOffset ( runIdx ) ; 
data [ count ++ ] = timeUnit . getValue ( ) * tinv . getBounds2 ( ) + time2D . getOffset ( runIdx ) ; 
return Array . factory ( DataType . DOUBLE , coord . getShape ( ) , data ) ; 
if ( v2 . getSPobject ( ) instanceof Time2Dinfo ) { 
Time2Dinfo info = ( Time2Dinfo ) v2 . getSPobject ( ) ; 
Array data = makeLazyCoordinateData ( v2 , info ) ; 
Section sectionFilled = Section . fill ( section , v2 . getShape ( ) ) ; 
return data . sectionNoReduce ( sectionFilled . getRanges ( ) ) ; 
GribCollectionImmutable . VariableIndex vindex = ( GribCollectionImmutable . VariableIndex ) v2 
. getSPobject ( ) ; 
GribDataReader dataReader = GribDataReader . factory ( gribCollection , vindex ) ; 
SectionIterable sectionIter = new SectionIterable ( section , v2 . getShape ( ) ) ; 
result = dataReader . readData ( sectionIter ) ; 
File input = new File ( filename ) ; 
try ( InputStream is = new FileInputStream ( input ) ) { 
processStream ( is ) ; 
} public void processStream ( InputStream is ) throws IOException { 
Buffer b = null ; 
b = ( pos < 0 ) ? readBuffer ( is ) : readBuffer ( is , b , pos ) ; 
pos = processBuffer ( b , is ) ; 
if ( b . done ) break ; 
} private boolean readBuffer ( InputStream is , byte [ ] dest , int start , int want ) throws IOException { 
int done = 0 ; 
while ( done < want ) { 
int got = is . read ( dest , start + done , want - done ) ; 
if ( got < 0 ) 
done += got ; 
bytesRead += done ; 
} private Buffer readBuffer ( InputStream is ) throws IOException { 
Buffer b = new Buffer ( ) ; 
int want = BUFFSIZE ; 
while ( b . have < want ) { 
int got = is . read ( b . buff , b . have , want - b . have ) ; 
if ( got < 0 ) { 
b . done = true ; 
b . have += got ; 
bytesRead += b . have ; 
} private Buffer readBuffer ( InputStream is , Buffer prev , int pos ) throws IOException { 
int remain = prev . have - pos ; 
System . arraycopy ( prev . buff , pos , b . buff , 0 , remain ) ; 
b . have = remain ; 
} private void getMoreBytes ( ) throws IOException { 
currentOffset = 0 ; 
int lookingFor = 0 ; 
for ( ; bytesRead < lineBuf . length ; bytesRead ++ ) { 
int c = in . read ( ) ; 
if ( c == - 1 ) 
lineBuf [ bytesRead ] = ( byte ) c ; 
if ( lineBuf [ bytesRead ] == endSequence [ lookingFor ] ) { 
lookingFor ++ ; 
if ( lookingFor == endSequence . length ) { 
endFound = true ; 
} else if ( lineBuf [ bytesRead ] == endSequence [ 0 ] ) { 
lookingFor = 1 ; 
lookingFor = 0 ; 
bytesRemaining = bytesRead ; 
} public int read ( byte b [ ] , int off , int len ) throws IOException { 
int c = read ( ) ; 
b [ off ] = ( byte ) c ; 
for ( ; i < len ; i ++ ) { 
c = read ( ) ; 
if ( c == - 1 ) { 
b [ off + i ] = ( byte ) c ; 
} public long skip ( long n ) { 
if ( bytesRemaining >= n ) { 
bytesRemaining -= n ; 
int oldBytesRemaining = bytesRemaining ; 
bytesRemaining = 0 ; 
return oldBytesRemaining ; 
mySweep = new DoradeSweep ( raf . getRandomAccessFile ( ) ) ; 
headerParser = new Doradeheader ( ) ; 
headerParser . read ( mySweep , ncfile , null ) ; 
new QuantityDimension ( ) + '"' ) ; 
QuantityDimension timeDimension = 
new QuantityDimension ( BaseQuantity . TIME ) ; 
QuantityDimension lengthDimension = 
new QuantityDimension ( BaseQuantity . LENGTH ) ; 
QuantityDimension hertzDimension = timeDimension . raiseTo ( - 1 ) ; 
Array orogArray = readArray ( orogVar , timeIndex ) ; 
int [ ] shape2D = orogArray . getShape ( ) ; 
Index orogIndex = orogArray . getIndex ( ) ; 
double az = aArray . getDouble ( aIndex . set ( z ) ) ; 
double orog = orogArray . getDouble ( orogIndex . set ( y , x ) ) ; 
height . set ( z , y , x , az + bz * orog ) ; 
double orog = orogArray . getDouble ( orogIndex . set ( yIndex , xIndex ) ) ; 
height . set ( z , az + bz * orog ) ; 
List < LevelCoord > levelList = new ArrayList < LevelCoord > ( records . size ( ) ) ; 
LevelCoord lc = new LevelCoord ( record . getLevel1 ( ) , record . getLevel2 ( ) ) ; 
if ( ! levelList . contains ( lc ) ) { 
levelList . add ( lc ) ; 
if ( ! isVertDimensionUsed ( ) ) 
if ( coordValues != null ) 
nlevs = coordValues . length ; 
ncfile . addDimension ( g , new Dimension ( getVariableName ( ) , nlevs , true ) ) ; 
if ( ! isVertDimensionUsed ( ) ) { 
typicalRecord = null ; 
Variable v = new Variable ( ncfile , g , null , getVariableName ( ) ) ; 
String desc = getLevelDesc ( ) ; 
v . addAttribute ( new Attribute ( "units" , lookup . getLevelUnit ( typicalRecord ) ) ) ; 
addExtraAttributes ( v ) ; 
v . addAttribute ( new Attribute ( _Coordinate . AxisType , axisType . toString ( ) ) ) ; 
if ( coordValues == null ) { 
coordValues = new double [ levels . size ( ) ] ; 
LevelCoord lc = ( LevelCoord ) levels . get ( i ) ; 
coordValues [ i ] = lc . mid ; 
Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { coordValues . length } , coordValues ) ; 
v . setDimensions ( getVariableName ( ) ) ; 
v . setCachedData ( dataArray , true ) ; 
if ( usesBounds ) { 
Dimension bd = ucar . nc2 . dataset . DatasetConstructor . getBoundsDimension ( ncfile ) ; 
String bname = getVariableName ( ) + "_bounds" ; 
v . addAttribute ( new Attribute ( "bounds" , bname ) ) ; 
v . addAttribute ( new Attribute ( _Coordinate . ZisLayer , "true" ) ) ; 
Variable b = new Variable ( ncfile , g , null , bname ) ; 
b . setDataType ( DataType . DOUBLE ) ; 
b . addAttribute ( new Attribute ( "long_name" , 
b . addAttribute ( new Attribute ( "units" , 
lookup . getLevelUnit ( typicalRecord ) ) ) ; 
Array boundsArray = Array . factory ( DataType . DOUBLE , 
new int [ ] { coordValues . length , 
2 } ) ; 
ucar . ma2 . Index ima = boundsArray . getIndex ( ) ; 
for ( int i = 0 ; i < coordValues . length ; i ++ ) { 
boundsArray . setDouble ( ima . set ( i , 0 ) , lc . value1 ) ; 
boundsArray . setDouble ( ima . set ( i , 1 ) , lc . value2 ) ; 
b . setCachedData ( boundsArray , true ) ; 
ncfile . addVariable ( g , b ) ; 
if ( factors != null ) { 
if ( g . findVariable ( "hybrida" ) != null ) 
v . addAttribute ( new Attribute ( "standard_name" , "atmosphere_hybrid_sigma_pressure_coordinate" ) ) ; 
Variable ha = new Variable ( ncfile , g , null , "hybrida" ) ; 
ha . setDataType ( DataType . DOUBLE ) ; 
ha . addAttribute ( new Attribute ( "long_name" , "level_a_factor" ) ) ; 
ha . addAttribute ( new Attribute ( "units" , "" ) ) ; 
ha . setDimensions ( getVariableName ( ) ) ; 
int middle = factors . length / 2 ; 
double [ ] adata ; 
double [ ] bdata ; 
if ( levels . size ( ) < middle ) { 
adata = new double [ levels . size ( ) ] ; 
bdata = new double [ levels . size ( ) ] ; 
adata = new double [ middle ] ; 
bdata = new double [ middle ] ; 
for ( int i = 0 ; i < middle && i < levels . size ( ) ; i ++ ) 
adata [ i ] = factors [ i ] ; 
Array haArray = Array . factory ( DataType . DOUBLE , new int [ ] { adata . length } , adata ) ; 
ha . setCachedData ( haArray , true ) ; 
ncfile . addVariable ( g , ha ) ; 
Variable hb = new Variable ( ncfile , g , null , "hybridb" ) ; 
hb . setDataType ( DataType . DOUBLE ) ; 
hb . addAttribute ( new Attribute ( "long_name" , "level_b_factor" ) ) ; 
hb . addAttribute ( new Attribute ( "units" , "" ) ) ; 
hb . setDimensions ( getVariableName ( ) ) ; 
bdata [ i ] = factors [ i + middle ] ; 
Array hbArray = Array . factory ( DataType . DOUBLE , new int [ ] { bdata . length } , bdata ) ; 
hb . setCachedData ( hbArray , true ) ; 
ncfile . addVariable ( g , hb ) ; 
} private int coordIndex ( GridRecord record ) { 
double val = record . getLevel1 ( ) ; 
double val2 = record . getLevel2 ( ) ; 
if ( usesBounds && ( val > val2 ) ) { 
val = record . getLevel2 ( ) ; 
val2 = record . getLevel1 ( ) ; 
if ( ucar . nc2 . util . Misc . nearlyEquals ( lc . value1 , val ) && ucar . nc2 . util . Misc . nearlyEquals ( lc . value2 , val2 ) ) { 
if ( ucar . nc2 . util . Misc . nearlyEquals ( lc . value1 , val ) ) { 
NOWRadheader localHeader = new NOWRadheader ( ) ; 
return ( localHeader . isValidFile ( raf ) ) ; 
} public void open ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile file , 
ucar . nc2 . util . CancelTask cancelTask ) 
headerParser = new NOWRadheader ( ) ; 
headerParser . read ( this . raf , ncfile ) ; 
pcode = 0 ; 
Array outputData ; 
byte [ ] vdata = null ; 
NOWRadheader . Vinfo vinfo ; 
ByteBuffer bos ; 
vinfo = ( NOWRadheader . Vinfo ) v2 . getSPobject ( ) ; 
vdata = headerParser . getData ( ( int ) vinfo . hoff ) ; 
bos = ByteBuffer . wrap ( vdata ) ; 
data = readOneScanData ( bos , vinfo , v2 . getShortName ( ) ) ; 
outputData = Array . factory ( v2 . getDataType ( ) , v2 . getShape ( ) , data ) ; 
outputData = outputData . flip ( 1 ) ; 
return ( outputData . sectionNoReduce ( ranges ) . copy ( ) ) ; 
} public Object readOneScanData ( ByteBuffer bos , NOWRadheader . Vinfo vinfo , String vName ) 
int doff = ( int ) vinfo . hoff ; 
int npixel = vinfo . yt * vinfo . xt ; 
byte [ ] rdata = null ; 
byte [ ] ldata = new byte [ vinfo . xt ] ; 
byte [ ] pdata = new byte [ npixel ] ; 
byte [ ] b2 = new byte [ 2 ] ; 
bos . position ( doff ) ; 
if ( ( DataType . unsignedByteToShort ( bos . get ( ) ) != 0xF0 ) || ( bos . get ( ) != 0x0C ) ) { 
int ecode ; 
int color ; 
int datapos ; 
int roffset = 0 ; 
boolean newline = true ; 
int linenum = 0 ; 
if ( newline ) { 
bos . get ( b2 ) ; 
linenum = ( DataType . unsignedByteToShort ( b2 [ 1 ] ) << 8 ) + DataType . unsignedByteToShort ( b2 [ 0 ] ) ; 
short b = DataType . unsignedByteToShort ( bos . get ( ) ) ; 
color = b & 0xF ; 
ecode = b > > 4 ; 
datapos = bos . position ( ) ; 
int datarun ; 
if ( ecode == 0xF ) { 
byte bb1 = bos . get ( datapos - 2 ) ; 
byte bb2 = bos . get ( datapos ) ; 
if ( ( color == 0x0 ) && ( bb1 == 0x00 ) && ( bb2 == 0x00 ) ) { 
datapos += 1 ; 
bos . position ( datapos ) ; 
datarun = 0 ; 
} else if ( ecode == 0xE ) { 
byte b0 = bos . get ( datapos ) ; 
datarun = DataType . unsignedByteToShort ( b0 ) + 1 ; 
} else if ( ecode == 0xD ) { 
b2 [ 0 ] = bos . get ( datapos ) ; 
b2 [ 1 ] = bos . get ( datapos + 1 ) ; 
datarun = ( DataType . unsignedByteToShort ( b2 [ 1 ] ) << 8 ) + DataType . unsignedByteToShort ( b2 [ 0 ] ) + 1 ; 
datapos += 2 ; 
datarun = ecode + 1 ; 
rdata = new byte [ datarun ] ; 
for ( int i = 0 ; i < datarun ; i ++ ) { 
rdata [ i ] = ( byte ) color ; 
System . arraycopy ( rdata , 0 , ldata , roffset , datarun ) ; 
roffset = roffset + datarun ; 
short c0 = DataType . unsignedByteToShort ( bos . get ( ) ) ; 
if ( c0 == 0x00 ) { 
short c1 = DataType . unsignedByteToShort ( bos . get ( ) ) ; 
short c2 = DataType . unsignedByteToShort ( bos . get ( ) ) ; 
if ( ( c0 == 0x00 ) && ( c1 == 0xF0 ) && ( c2 == 0x0C ) ) { 
System . arraycopy ( ldata , 0 , pdata , offset , roffset ) ; 
offset = offset + vinfo . xt ; 
roffset = 0 ; 
newline = true ; 
ldata = new byte [ vinfo . xt ] ; 
} else if ( ( c1 == 0xF0 ) && ( c2 == 0x02 ) ) { 
datapos = bos . position ( ) - 3 ; 
newline = false ; 
bos . position ( datapos - 1 ) ; 
return pdata ; 
} public byte [ ] readOneRowData ( byte [ ] ddata , int rLen , int xt ) throws IOException , InvalidRangeException { 
int run ; 
byte [ ] bdata = new byte [ xt ] ; 
int nbin = 0 ; 
for ( run = 0 ; run < rLen ; run ++ ) { 
int drun = DataType . unsignedByteToShort ( ddata [ run ] ) > > 4 ; 
byte dcode1 = ( byte ) ( DataType . unsignedByteToShort ( ddata [ run ] ) & 0Xf ) ; 
for ( int i = 0 ; i < drun ; i ++ ) { 
bdata [ nbin ++ ] = dcode1 ; 
if ( total < xt ) { 
for ( run = total ; run < xt ; run ++ ) { 
bdata [ run ] = 0 ; 
return bdata ; 
} private void createFromDataset ( NetcdfDataset ncd ) { 
for ( CoordinateAxis axis : ncd . getCoordinateAxes ( ) ) { 
coordvars . put ( axis . getShortName ( ) , axis ) ; 
ddsvars = new ArrayList < > ( 50 ) ; 
for ( Variable v : ncd . getVariables ( ) ) { 
if ( coordvars . containsKey ( v . getShortName ( ) ) ) continue ; 
ddsvars . add ( v ) ; 
boolean isgridarray = ( v . getRank ( ) > 1 ) && ( v . getDataType ( ) != DataType . STRUCTURE ) && ( v . getParentStructure ( ) == null ) ; 
if ( ! isgridarray ) continue ; 
List < Dimension > dimset = v . getDimensions ( ) ; 
int rank = dimset . size ( ) ; 
for ( int i = 0 ; isgridarray && i < rank ; i ++ ) { 
if ( dim . getShortName ( ) == null ) 
isgridarray = false ; 
Variable gv = coordvars . get ( dim . getShortName ( ) ) ; 
if ( gv == null ) 
if ( isgridarray ) { 
gridarrays . put ( v . getFullName ( ) , v ) ; 
if ( gv != null ) 
used . put ( gv . getFullName ( ) , gv ) ; 
for ( Variable cv : ncd . getCoordinateAxes ( ) ) { 
BaseType bt = createVariable ( ncd , cv ) ; 
addVariable ( bt ) ; 
for ( Variable cv : ddsvars ) { 
} private BaseType createVariable ( NetcdfFile ncfile , Variable v ) { 
BaseType bt ; 
if ( v . getRank ( ) == 0 ) 
bt = createScalarVariable ( ncfile , v ) ; 
else if ( v . getDataType ( ) == DataType . CHAR ) { 
if ( v . getRank ( ) > 1 ) 
bt = new NcSDCharArray ( v ) ; 
bt = new NcSDString ( v ) ; 
} else if ( v . getDataType ( ) == DataType . STRING ) { 
bt = new NcSDArray ( v , new NcSDString ( v ) ) ; 
bt = createArray ( ncfile , v ) ; 
throws CloneNotSupportedException { 
NcDDS d = ( NcDDS ) super . cloneDAG ( map ) ; 
d . coordvars = coordvars ; 
} void fireMapAreaEvent ( ) { 
if ( project . isLatLon ( ) ) { 
LatLonProjection llproj = ( LatLonProjection ) project ; 
ProjectionRect box = getMapArea ( ) ; 
double center = llproj . getCenterLon ( ) ; 
double lonBeg = LatLonPointImpl . lonNormal ( box . getMinX ( ) , center ) ; 
double lonEnd = lonBeg + box . getMaxX ( ) - box . getMinX ( ) ; 
boolean showShift = Debug . isSet ( "projection/LatLonShift" ) || debugNewProjection ; 
if ( ( lonBeg < center - 180 ) || ( lonEnd > center + 180 ) ) { 
double wx0 = box . getX ( ) + box . getWidth ( ) / 2 ; 
llproj . setCenterLon ( wx0 ) ; 
double newWx0 = llproj . getCenterLon ( ) ; 
setWorldCenterX ( newWx0 ) ; 
if ( showShift ) 
lmProject . sendEvent ( new NewProjectionEvent ( this , llproj ) ) ; 
lmMapArea . sendEvent ( new NewMapAreaEvent ( this , getMapArea ( ) ) ) ; 
} public void setMapArea ( ProjectionRect ma ) { 
navigate . setMapArea ( ma ) ; 
} public void setMapArea ( LatLonRect llbb ) { 
navigate . setMapArea ( project . latLonToProjBB ( llbb ) ) ; 
} public void setLatLonCenterMapArea ( double lat , double lon ) { 
ProjectionPoint center = project . latLonToProj ( lat , lon ) ; 
ProjectionRect ma = getMapArea ( ) ; 
ma . setX ( center . getX ( ) - ma . getWidth ( ) / 2 ) ; 
ma . setY ( center . getY ( ) - ma . getHeight ( ) / 2 ) ; 
setMapArea ( ma ) ; 
} public void setProjectionImpl ( ProjectionImpl p ) { 
LatLonRect geoLL = project . projToLatLonBB ( geoSelection ) ; 
setGeoSelection ( p . latLonToProjBB ( geoLL ) ) ; 
project = p ; 
navigate . setMapArea ( project . getDefaultMapArea ( ) ) ; 
if ( Debug . isSet ( "projection/set" ) || debugNewProjection ) 
if ( hasReference ) { 
refWorld . setLocation ( project . latLonToProj ( refLatLon ) ) ; 
} public void addActionsToMenu ( JMenu menu ) { 
BAMutil . addActionToMenu ( menu , zoomIn ) ; 
BAMutil . addActionToMenu ( menu , zoomOut ) ; 
BAMutil . addActionToMenu ( menu , zoomBack ) ; 
BAMutil . addActionToMenu ( menu , zoomDefault ) ; 
menu . addSeparator ( ) ; 
BAMutil . addActionToMenu ( menu , moveUp ) ; 
BAMutil . addActionToMenu ( menu , moveDown ) ; 
BAMutil . addActionToMenu ( menu , moveRight ) ; 
BAMutil . addActionToMenu ( menu , moveLeft ) ; 
BAMutil . addActionToMenu ( menu , setReferenceAction ) ; 
} private void redrawLater ( int delay ) { 
boolean already = ( redrawTimer != null ) && ( redrawTimer . isRunning ( ) ) ; 
if ( redrawTimer == null ) { 
redrawTimer = new javax . swing . Timer ( 0 , new ActionListener ( ) { 
drawG ( ) ; 
redrawTimer . stop ( ) ; 
redrawTimer . setDelay ( delay ) ; 
} public void setChangeable ( boolean mode ) { 
if ( mode == changeable ) 
changeable = mode ; 
if ( toolbar != null ) 
toolbar . setEnabled ( mode ) ; 
} public void repaint ( long tm , int x , int y , int width , int height ) { 
repaintCount ++ ; 
super . repaint ( tm , x , y , width , height ) ; 
draw ( ( Graphics2D ) g ) ; 
navigate . getMapArea ( boundingBox ) ; 
g2 . setTransform ( navigate . getTransform ( ) ) ; 
Rectangle2D hr = new Rectangle2D . Double ( ) ; 
hr . setRect ( boundingBox . getX ( ) , boundingBox . getY ( ) , boundingBox . getWidth ( ) , boundingBox . getHeight ( ) ) ; 
g2 . setClip ( hr ) ; 
} public AffineTransform calcTransform ( boolean rotate , double displayX , double displayY , 
double displayWidth , double displayHeight ) { 
return navigate . calcTransform ( rotate , displayX , displayY , displayWidth , displayHeight ) ; 
} private void newScreenSize ( Rectangle b ) { 
boolean sameSize = ( b . width == myBounds . width ) && ( b . height == myBounds . height ) ; 
if ( sameSize && ( b . x == myBounds . x ) && ( b . y == myBounds . y ) ) 
myBounds . setBounds ( b ) ; 
if ( sameSize ) 
if ( ( b . width > 0 ) && ( b . height > 0 ) ) { 
bImage = new BufferedImage ( b . width , b . height , BufferedImage . TYPE_INT_RGB ) ; 
bImage = null ; 
navigate . setScreenSize ( b . width , b . height ) ; 
} public void drawG ( ) { 
Graphics g = getGraphics ( ) ; 
if ( null != g ) { 
g . dispose ( ) ; 
} public void setSelected ( VariableIF v ) { 
if ( v == null ) { return ; } 
final List < VariableIF > vchain = new ArrayList < > ( ) ; 
vchain . add ( v ) ; 
VariableIF vp = v ; 
while ( vp . isMemberOfStructure ( ) ) { 
vp = vp . getParentStructure ( ) ; 
vchain . add ( 0 , vp ) ; 
final List < Group > gchain = new ArrayList < > ( ) ; 
Group gp = vp . getParentGroup ( ) ; 
gchain . add ( gp ) ; 
while ( gp . getParentGroup ( ) != null ) { 
gp = gp . getParentGroup ( ) ; 
gchain . add ( 0 , gp ) ; 
final List < Object > pathList = new ArrayList < > ( ) ; 
GroupNode gnode = ( GroupNode ) model . getRoot ( ) ; 
pathList . add ( gnode ) ; 
Group parentGroup = gchain . get ( 0 ) ; 
for ( int i = 1 ; i < gchain . size ( ) ; i ++ ) { 
parentGroup = gchain . get ( i ) ; 
gnode = gnode . findNestedGroup ( parentGroup ) ; 
assert gnode != null ; 
vp = vchain . get ( 0 ) ; 
VariableNode vnode = gnode . findNestedVariable ( vp ) ; 
if ( vnode == null ) { return ; } 
pathList . add ( vnode ) ; 
for ( int i = 1 ; i < vchain . size ( ) ; i ++ ) { 
vp = vchain . get ( i ) ; 
vnode = vnode . findNestedVariable ( vp ) ; 
final Object [ ] paths = pathList . toArray ( ) ; 
final TreePath treePath = new TreePath ( paths ) ; 
tree . setSelectionPath ( treePath ) ; 
tree . scrollPathToVisible ( treePath ) ; 
} public Class 
getElementType ( ) 
DataType dt = CDMTypeFcns . daptype2cdmtype ( this . basetype ) ; 
if ( dt == null ) 
return CDMTypeFcns . cdmElementClass ( dt ) ; 
} public double getDouble ( int offset ) 
DapVariable d4var = ( DapVariable ) getTemplate ( ) ; 
long [ ] dimsizes = DapUtil . getDimSizes ( d4var . getDimensions ( ) ) ; 
return getDouble ( DapUtil . offsetToIndex ( offset , dimsizes ) ) ; 
} protected double getDouble ( dap4 . core . util . Index idx ) 
assert data . getScheme ( ) == Scheme . ATOMIC ; 
Object value = data . read ( idx ) ; 
value = Convert . convert ( DapType . FLOAT64 , this . basetype , value ) ; 
return ( Double ) java . lang . reflect . Array . get ( value , 0 ) ; 
throw new IndexOutOfBoundsException ( ioe . getMessage ( ) ) ; 
} protected Object getObject ( dap4 . core . util . Index idx ) 
value = java . lang . reflect . Array . get ( value , 0 ) ; 
} String gini_GetSectorID ( int ent_id ) { 
switch ( ent_id ) { 
name = "Supernational" ; 
case 15 : 
name = "Unknown-ID" ; 
} String gini_GetEntityID ( int ent_id ) { 
name = "Miscellaneous" ; 
name = "JERS" ; 
name = "ERS/QuikSCAT/Scatterometer" ; 
name = "POES/NPOESS" ; 
name = "Composite" ; 
case 16 : 
case 17 : 
case 18 : 
case 19 : 
case 99 : 
name = "Unknown" ; 
} String gini_GetPhysElemID ( int phys_elem , int ent_id ) { 
switch ( phys_elem ) { 
name = "VIS" ; 
name = "IR_WV" ; 
name = "IR" ; 
name = "LI" ; 
name = "PW" ; 
name = "SFC_T" ; 
name = "CAPE" ; 
name = "T" ; 
case 21 : 
name = "WINDEX" ; 
case 22 : 
name = "DMPI" ; 
case 23 : 
name = "MDPI" ; 
case 25 : 
if ( ent_id == 99 ) 
name = "HHC" ; 
name = "Volcano_imagery" ; 
case 26 : 
name = "EchoTops" ; 
case 27 : 
name = "Reflectivity" ; 
name = "CTP" ; 
case 28 : 
name = "Cloud_Amount" ; 
case 29 : 
name = "VIL" ; 
name = "Precipitation" ; 
case 41 : 
case 42 : 
case 43 : 
case 44 : 
case 45 : 
case 46 : 
case 47 : 
case 48 : 
case 49 : 
case 52 : 
case 53 : 
case 54 : 
case 55 : 
case 56 : 
case 57 : 
case 58 : 
name = "sounder_imagery" ; 
case 59 : 
name = "VIS_sounder" ; 
} String getPhysElemLongName ( int phys_elem , int ent_id ) { 
case 24 : 
return "Volcano_imagery" ; 
case 32 : 
case 33 : 
case 34 : 
case 35 : 
case 36 : 
case 37 : 
case 38 : 
case 39 : 
} private double readScaledInt ( ByteBuffer buf ) { 
short s1 = buf . getShort ( ) ; 
short s2 = DataType . unsignedByteToShort ( buf . get ( ) ) ; 
int posneg = 1 - ( ( s1 & 0x8000 ) > > 14 ) ; 
int nn = ( ( ( s1 & 0x7FFF ) << 8 ) | s2 ) * posneg ; 
return ( double ) nn / 10000.0 ; 
} public Parameter findParameterIgnoreCase ( String name ) { 
for ( Parameter a : params ) { 
if ( name . equalsIgnoreCase ( a . getName ( ) ) ) 
public boolean 
hasNext ( ) 
if ( this . current >= odomset . size ( ) ) 
Odometer ocurrent = odomset . get ( this . current ) ; 
if ( ocurrent . hasNext ( ) ) 
this . current ++ ; 
return hasNext ( ) ; 
public long 
totalSize ( ) 
long size = 1 ; 
for ( int i = 0 ; i < this . rank ; i ++ ) { 
size *= slice ( i ) . getCount ( ) ; 
} private void parseDDF ( int maxLines ) throws IOException { 
variableList = new ArrayList < > ( ) ; 
dimList = new ArrayList < > ( ) ; 
attrList = new ArrayList < > ( ) ; 
try ( BufferedReader r = new BufferedReader ( new InputStreamReader ( new FileInputStream ( ddFile ) , CDM . utf8Charset ) ) ) { 
boolean inVarSection = false ; 
boolean inEnsSection = false ; 
String original ; 
GradsDimension curDim = null ; 
while ( ( original = r . readLine ( ) ) != null ) { 
if ( count > maxLines ) { 
error = true ; 
original = original . trim ( ) ; 
if ( original . isEmpty ( ) ) { 
line = original . toLowerCase ( ) ; 
attrList . add ( GradsAttribute . parseAttribute ( original ) ) ; 
if ( line . startsWith ( "*" ) ) { 
if ( inEnsSection ) { 
if ( line . startsWith ( ENDEDEF . toLowerCase ( ) ) ) { 
inEnsSection = false ; 
if ( inVarSection ) { 
if ( line . startsWith ( ENDVARS . toLowerCase ( ) ) ) { 
inVarSection = false ; 
GradsVariable var = new GradsVariable ( original ) ; 
int numLevels = var . getNumLevels ( ) ; 
if ( numLevels == 0 ) { 
numLevels = 1 ; 
gridsPerTimeStep += numLevels ; 
variableList . add ( var ) ; 
StringTokenizer st = new StringTokenizer ( original ) ; 
String label = st . nextToken ( ) ; 
if ( label . equalsIgnoreCase ( OPTIONS ) ) { 
curDim = null ; 
String token = st . nextToken ( ) ; 
if ( token . equalsIgnoreCase ( BIG_ENDIAN ) ) { 
bigEndian = true ; 
} else if ( token . equalsIgnoreCase ( LITTLE_ENDIAN ) ) { 
bigEndian = false ; 
} else if ( token . equalsIgnoreCase ( BYTESWAPPED ) ) { 
swapByteOrder ( ) ; 
} else if ( token . equalsIgnoreCase ( YREV ) ) { 
yReversed = true ; 
} else if ( token . equalsIgnoreCase ( TEMPLATE ) ) { 
isTemplate = true ; 
} else if ( token . equalsIgnoreCase ( SEQUENTIAL ) ) { 
isSequential = true ; 
} else if ( label . equalsIgnoreCase ( CHSUB ) ) { 
int start = Integer . parseInt ( st . nextToken ( ) ) ; 
int end = Integer . parseInt ( st . nextToken ( ) ) ; 
String sub = st . nextToken ( ) ; 
addChsub ( new Chsub ( start , end , sub ) ) ; 
} else if ( label . equalsIgnoreCase ( DSET ) ) { 
dataFile = st . nextToken ( ) ; 
} else if ( label . equalsIgnoreCase ( UNDEF ) ) { 
missingData = Double . parseDouble ( st . nextToken ( ) ) ; 
} else if ( label . equalsIgnoreCase ( XYHEADER ) ) { 
xyHeaderBytes = Integer . parseInt ( st . nextToken ( ) ) ; 
} else if ( label . equalsIgnoreCase ( FILEHEADER ) ) { 
fileHeaderBytes = Integer . parseInt ( st . nextToken ( ) ) ; 
} else if ( label . equalsIgnoreCase ( XDEF ) ) { 
int xSize = Integer . valueOf ( st . nextToken ( ) ) ; 
String xMapping = st . nextToken ( ) ; 
xDim = new GradsDimension ( label , xSize , xMapping ) ; 
curDim = xDim ; 
dimList . add ( xDim ) ; 
} else if ( label . equalsIgnoreCase ( YDEF ) ) { 
int ySize = Integer . valueOf ( st . nextToken ( ) ) ; 
String yMapping = st . nextToken ( ) ; 
yDim = new GradsDimension ( label , ySize , yMapping ) ; 
curDim = yDim ; 
dimList . add ( yDim ) ; 
} else if ( label . equalsIgnoreCase ( ZDEF ) ) { 
int zSize = Integer . valueOf ( st . nextToken ( ) ) ; 
String zMapping = st . nextToken ( ) ; 
zDim = new GradsDimension ( label , zSize , zMapping ) ; 
curDim = zDim ; 
dimList . add ( zDim ) ; 
} else if ( label . equalsIgnoreCase ( TDEF ) ) { 
int tSize = Integer . valueOf ( st . nextToken ( ) ) ; 
String tMapping = st . nextToken ( ) ; 
tDim = new GradsTimeDimension ( label , tSize , tMapping ) ; 
curDim = tDim ; 
dimList . add ( tDim ) ; 
} else if ( label . equalsIgnoreCase ( EDEF ) ) { 
int eSize = Integer . valueOf ( st . nextToken ( ) ) ; 
if ( st . nextToken ( ) . equalsIgnoreCase ( GradsEnsembleDimension . NAMES ) ) { 
String eMapping = GradsEnsembleDimension . NAMES ; 
eDim = new GradsEnsembleDimension ( label , eSize , eMapping ) ; 
curDim = eDim ; 
dimList . add ( curDim ) ; 
inEnsSection = true ; 
} else if ( label . equalsIgnoreCase ( PDEF ) ) { 
hasProjection = true ; 
} else if ( label . equalsIgnoreCase ( VARS ) ) { 
inVarSection = true ; 
} else if ( label . equalsIgnoreCase ( DTYPE ) ) { 
dataType = st . nextToken ( ) ; 
} else if ( label . equalsIgnoreCase ( TITLE ) ) { 
} else if ( curDim != null ) { 
curDim . addLevel ( label ) ; 
if ( curDim != null ) { 
curDim . addLevel ( st . nextToken ( ) ) ; 
if ( zDim != null ) { 
for ( GradsAttribute attr : attrList ) { 
if ( attr . getVariable ( ) . equalsIgnoreCase ( ZDEF ) && 
attr . getType ( ) . equalsIgnoreCase ( GradsAttribute . STRING ) && 
attr . getName ( ) . equalsIgnoreCase ( "units" ) ) { 
zDim . setUnit ( attr . getValue ( ) ) ; 
} private void swapByteOrder ( ) { 
String arch = System . getProperty ( "os.arch" ) ; 
if ( arch . equals ( "x86" ) || 
arch . equals ( "arm" ) || 
arch . equals ( "x86_64" ) || 
arch . equals ( "amd64" ) || 
arch . equals ( "alpha" ) ) { 
} public int [ ] getTimeStepsPerFile ( String filename ) { 
if ( chsubs != null ) { 
for ( Chsub ch : chsubs ) { 
if ( filename . contains ( ch . subString ) ) { 
return new int [ ] { ch . numTimes , ch . startTimeIndex } ; 
return new int [ ] { timeStepsPerFile , 0 } ; 
} public String getFileName ( int eIndex , int tIndex ) { 
String dataFilePath = dataFile ; 
if ( ( getTemplateType ( ) == ENS_TEMPLATE ) || ( getTemplateType ( ) == ENS_TIME_TEMPLATE ) ) { 
dataFilePath = getEnsembleDimension ( ) . replaceFileTemplate ( dataFilePath , eIndex ) ; 
dataFilePath = getTimeDimension ( ) . replaceFileTemplate ( dataFilePath , tIndex ) ; 
if ( ( chsubs != null ) && ( dataFilePath . contains ( CHSUB_TEMPLATE_ID ) ) ) { 
if ( ( tIndex >= ch . startTimeIndex ) && ( tIndex <= ch . endTimeIndex ) ) { 
dataFilePath = dataFilePath . replace ( CHSUB_TEMPLATE_ID , ch . subString ) ; 
return getFullPath ( dataFilePath ) ; 
} private List < String > getFileNames ( ) throws IOException { 
if ( fileNames == null ) { 
fileNames = new ArrayList < > ( ) ; 
timeStepsPerFile = tDim . getSize ( ) ; 
if ( ! isTemplate ( ) ) { 
fileNames . add ( getFullPath ( getDataFile ( ) ) ) ; 
List < String > fileSet = new ArrayList < > ( ) ; 
String template = getDataFile ( ) ; 
if ( GradsTimeDimension . hasTimeTemplate ( template ) ) { 
if ( template . contains ( GradsEnsembleDimension . ENS_TEMPLATE_ID ) ) { 
templateType = ENS_TIME_TEMPLATE ; 
templateType = TIME_TEMPLATE ; 
templateType = ENS_TEMPLATE ; 
if ( templateType == ENS_TEMPLATE ) { 
for ( int e = 0 ; e < eDim . getSize ( ) ; e ++ ) { 
fileSet . add ( 
getFullPath ( 
eDim . replaceFileTemplate ( template , e ) ) ) ; 
} else if ( ( templateType == TIME_TEMPLATE ) 
|| ( templateType == ENS_TIME_TEMPLATE ) ) { 
int numens = ( templateType == TIME_TEMPLATE ) 
: eDim . getSize ( ) ; 
for ( int t = 0 ; t < tDim . getSize ( ) ; t ++ ) { 
for ( int e = 0 ; e < numens ; e ++ ) { 
String file = getFileName ( e , t ) ; 
if ( ! fileSet . contains ( file ) ) { 
fileSet . add ( file ) ; 
timeStepsPerFile = tDim . getSize ( ) 
/ ( fileSet . size ( ) / numens ) ; 
fileNames . addAll ( fileSet ) ; 
for ( String file : fileNames ) { 
File f = new File ( file ) ; 
return fileNames ; 
} private String getDDFPath ( ) { 
if ( pathToDDF == null ) { 
int lastSlash = ddFile . lastIndexOf ( "/" ) ; 
if ( lastSlash < 0 ) { 
lastSlash = ddFile . lastIndexOf ( File . separator ) ; 
pathToDDF = ( lastSlash < 0 ) 
? "" 
: ddFile . substring ( 0 , lastSlash + 1 ) ; 
return pathToDDF ; 
} private String getFullPath ( String filename ) { 
String file ; 
String ddfPath = getDDFPath ( ) ; 
if ( filename . startsWith ( "^" ) ) { 
file = filename . replace ( "^" , "" ) ; 
file = ddfPath + file ; 
if ( ! f . isAbsolute ( ) ) { 
file = ddfPath + filename ; 
file = filename ; 
} private void addChsub ( Chsub sub ) { 
if ( chsubs == null ) { 
chsubs = new ArrayList < > ( ) ; 
chsubs . add ( sub ) ; 
} public void writeDataAll ( DataOutputStream stream ) throws IOException { 
for ( Vinfo vinfo : vinfoList ) { 
if ( ! vinfo . isRecord ) { 
Variable v = vinfo . v ; 
assert filePos == vinfo . offset ; 
int nbytes = writeDataFast ( v , stream , v . read ( ) ) ; 
filePos += nbytes ; 
filePos += pad ( stream , nbytes , ( byte ) 0 ) ; 
boolean useRecordDimension = ncfile . hasUnlimitedDimension ( ) ; 
if ( useRecordDimension ) { 
ncfile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
int nrec = 0 ; 
Structure recordVar = ( Structure ) ncfile . findVariable ( "record" ) ; 
if ( vinfo . isRecord ) { 
int nbytes = writeDataFast ( v , stream , sdata . getArray ( v . getShortName ( ) ) ) ; 
count += nbytes ; 
count += pad ( stream , nbytes , ( byte ) 0 ) ; 
if ( first && debugWriteData ) { 
nrec ++ ; 
stream . flush ( ) ; 
ncfile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_REMOVE_RECORD_STRUCTURE ) ; 
} private long writeData ( Variable v , DataOutputStream stream , Array values ) throws java . io . IOException { 
DataType dataType = v . getDataType ( ) ; 
if ( dataType == DataType . BYTE ) { 
while ( ii . hasNext ( ) ) 
stream . write ( ii . getByteNext ( ) ) ; 
return values . getSize ( ) ; 
} else if ( dataType == DataType . SHORT ) { 
stream . writeShort ( ii . getShortNext ( ) ) ; 
return 2 * values . getSize ( ) ; 
} else if ( dataType == DataType . INT ) { 
stream . writeInt ( ii . getIntNext ( ) ) ; 
return 4 * values . getSize ( ) ; 
stream . writeFloat ( ii . getFloatNext ( ) ) ; 
stream . writeDouble ( ii . getDoubleNext ( ) ) ; 
return 8 * values . getSize ( ) ; 
} public TimeCoordIntvValue convertReferenceDate ( CalendarDate refDate , CalendarPeriod timeUnit ) { 
if ( timeUnit == null ) { 
int startOffset = timeUnit . getOffset ( refDate , start ) ; 
int endOffset = timeUnit . getOffset ( refDate , end ) ; 
return new TimeCoordIntvValue ( startOffset , endOffset ) ; 
} static ArrayBoolean factory ( Index index , boolean [ ] storage ) { 
return new ArrayBoolean . D0 ( index , storage ) ; 
return new ArrayBoolean . D1 ( index , storage ) ; 
return new ArrayBoolean . D2 ( index , storage ) ; 
return new ArrayBoolean . D3 ( index , storage ) ; 
return new ArrayBoolean . D4 ( index , storage ) ; 
return new ArrayBoolean . D5 ( index , storage ) ; 
return new ArrayBoolean . D6 ( index , storage ) ; 
return new ArrayBoolean . D7 ( index , storage ) ; 
return new ArrayBoolean ( index , storage ) ; 
boolean [ ] ja = ( boolean [ ] ) javaArray ; 
for ( boolean aJa : ja ) iter . setBooleanNext ( aJa ) ; 
long t = raf . length ( ) ; 
if ( t == 0 ) { 
int p = this . readWMO ( raf ) ; 
if ( p == 0 ) return false ; 
} int readWMO ( ucar . unidata . io . RandomAccessFile raf ) throws IOException 
if ( rc != readLen ) 
int iarr2_1 = bytesToInt ( b [ 0 ] , b [ 1 ] , false ) ; 
int iarr2_16 = bytesToInt ( b [ 30 ] , b [ 31 ] , false ) ; 
int iarr2_10 = bytesToInt ( b [ 18 ] , b [ 19 ] , false ) ; 
int iarr2_7 = bytesToInt ( b [ 12 ] , b [ 13 ] , false ) ; 
if ( ( iarr2_1 == iarr2_16 ) && 
( ( iarr2_1 >= 16 ) && ( iarr2_1 <= 299 ) ) && 
( iarr2_10 == - 1 ) && 
( iarr2_7 < 10000 ) ) { 
noHeader = true ; 
String pib = new String ( b , CDM . utf8Charset ) ; 
if ( pib . indexOf ( "SDUS" ) != - 1 ) { 
noHeader = false ; 
} else if ( raf . getLocation ( ) . indexOf ( ".nids" ) != - 1 ) { 
} public byte [ ] getUncompData ( int offset , int len ) { 
if ( len == 0 ) len = uncompdata . length - offset ; 
byte [ ] data = new byte [ len ] ; 
System . arraycopy ( uncompdata , offset , data , 0 , len ) ; 
} void read ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile ) throws IOException { 
int hedsiz ; 
int hoff = 0 ; 
int type ; 
int zlibed ; 
boolean isZ = false ; 
int encrypt ; 
long actualSize ; 
int readLen ; 
readWMO ( raf ) ; 
actualSize = raf . length ( ) ; 
readLen = ( int ) actualSize ; 
if ( ! noHeader ) { 
String pib = new String ( b , 0 , 100 , CDM . utf8Charset ) ; 
type = 0 ; 
pos = pib . indexOf ( "\r\r\n" ) ; 
while ( pos != - 1 ) { 
hoff = pos + 3 ; 
type ++ ; 
pos = pib . indexOf ( "\r\r\n" , pos + 1 ) ; 
raf . seek ( hoff ) ; 
System . arraycopy ( b , hoff , b2 , 0 , 2 ) ; 
zlibed = isZlibHed ( b2 ) ; 
if ( zlibed == 0 ) { 
encrypt = IsEncrypt ( b2 ) ; 
if ( encrypt == 1 ) { 
byte [ ] b3 = new byte [ 3 ] ; 
System . arraycopy ( b , hoff - 6 , b3 , 0 , 3 ) ; 
stationId = new String ( b3 , CDM . utf8Charset ) ; 
NexradStationDB . init ( ) ; 
NexradStationDB . Station station = NexradStationDB . get ( "K" + stationId ) ; 
stationName = station . name ; 
if ( zlibed == 1 ) { 
isZ = true ; 
uncompdata = GetZlibedNexr ( b , readLen , hoff ) ; 
if ( uncompdata == null ) { 
uncompdata = new byte [ b . length - hoff ] ; 
System . arraycopy ( b , hoff , uncompdata , 0 , b . length - hoff ) ; 
uncompdata = new byte [ b . length ] ; 
System . arraycopy ( b , 0 , uncompdata , 0 , b . length ) ; 
ByteBuffer bos = ByteBuffer . wrap ( uncompdata ) ; 
rc = read_msghead ( bos , 0 ) ; 
hedsiz = 18 ; 
Pinfo pinfo = read_proddesc ( bos , hedsiz ) ; 
hedsiz += 102 ; 
int prod_type = code_typelookup ( pinfo . pcode ) ; 
setProductInfo ( prod_type , pinfo ) ; 
int pcode1Number = 0 ; 
int pcode2Number = 0 ; 
int pcode8Number = 0 ; 
int pcode4Number = 0 ; 
int pcode5Number = 0 ; 
int pcode10Number = 0 ; 
int pcode6Number = 0 ; 
int pcode25Number = 0 ; 
int pcode12Number = 0 ; 
int pcode13Number = 0 ; 
int pcode14Number = 0 ; 
int pcode15Number = 0 ; 
int pcode16Number = 0 ; 
int pcode19Number = 0 ; 
int pcode20Number = 0 ; 
int pkcode1Doff [ ] = null ; 
int pkcode2Doff [ ] = null ; 
int pkcode8Doff [ ] = null ; 
int pkcode1Size [ ] = null ; 
int pkcode2Size [ ] = null ; 
int pkcode8Size [ ] = null ; 
int pkcode4Doff [ ] = null ; 
int pkcode5Doff [ ] = null ; 
int pkcode10Doff [ ] = null ; 
int pkcode10Dlen [ ] = null ; 
int pkcode6Doff [ ] = null ; 
int pkcode6Dlen [ ] = null ; 
int pkcode25Doff [ ] = null ; 
int pkcode12Doff [ ] = null ; 
int pkcode13Doff [ ] = null ; 
int pkcode14Doff [ ] = null ; 
int pkcode12Dlen [ ] = null ; 
int pkcode13Dlen [ ] = null ; 
int pkcode14Dlen [ ] = null ; 
int pkcode15Dlen [ ] = null ; 
int pkcode15Doff [ ] = null ; 
int pkcode16Dlen [ ] = null ; 
int pkcode16Doff [ ] = null ; 
int pkcode19Dlen [ ] = null ; 
int pkcode19Doff [ ] = null ; 
int pkcode20Dlen [ ] = null ; 
int pkcode20Doff [ ] = null ; 
ifloop : if ( pinfo . offsetToSymbologyBlock != 0 ) { 
if ( pinfo . p8 == 1 ) { 
int size = shortsToInt ( pinfo . p9 , pinfo . p10 , false ) ; 
uncompdata = uncompressed ( bos , hedsiz , size ) ; 
bos = ByteBuffer . wrap ( uncompdata ) ; 
Sinfo sinfo = read_dividlen ( bos , hedsiz ) ; 
if ( rc == 0 || pinfo . divider != - 1 ) 
if ( sinfo . id != 1 ) 
if ( pinfo . pcode == 82 ) { 
read_SATab ( bos , hedsiz ) ; 
break ifloop ; 
hedsiz += 10 ; 
int klayer = pinfo . offsetToSymbologyBlock * 2 + 10 ; 
for ( int i = 0 ; i < sinfo . nlayers ; i ++ ) { 
hedsiz = klayer ; 
bos . position ( hedsiz ) ; 
short Divlen_divider = bos . getShort ( ) ; 
hedsiz += 2 ; 
int Divlen_length = bos . getInt ( ) ; 
hedsiz += 4 ; 
if ( Divlen_divider != - 1 ) { 
int icount = 0 ; 
int plen ; 
while ( icount < Divlen_length ) { 
int boff = klayer + icount + 6 ; 
bos . position ( boff ) ; 
int pkcode = getUInt ( b2 , 2 ) ; 
boff += 2 ; 
switch ( pkcode ) 
hedsiz += 8 ; 
plen = pcode_DPA ( bos , boff , hoff , hedsiz , isZ , i , pkcode ) ; 
if ( pkcode10Doff == null ) { 
pkcode10Doff = new int [ 250 ] ; 
pkcode10Dlen = new int [ 250 ] ; 
plen = bos . getShort ( ) ; 
pkcode10Doff [ pcode10Number ] = boff + 2 ; 
pkcode10Dlen [ pcode10Number ] = ( plen - 2 ) / 8 ; 
pcode10Number ++ ; 
if ( pkcode1Doff == null ) { 
pkcode1Doff = new int [ 250 ] ; 
pkcode1Size = new int [ 250 ] ; 
pkcode1Doff [ pcode1Number ] = boff + 2 ; 
pkcode1Size [ pcode1Number ] = plen - 4 ; 
pcode1Number ++ ; 
if ( pkcode2Doff == null ) { 
pkcode2Doff = new int [ 250 ] ; 
pkcode2Size = new int [ 250 ] ; 
pkcode2Doff [ pcode2Number ] = boff + 2 ; 
pkcode2Size [ pcode2Number ] = plen - 4 ; 
pcode2Number ++ ; 
if ( pkcode8Doff == null ) { 
pkcode8Doff = new int [ 550 ] ; 
pkcode8Size = new int [ 550 ] ; 
pkcode8Doff [ pcode8Number ] = boff + 2 ; 
pkcode8Size [ pcode8Number ] = plen - 6 ; 
pcode8Number ++ ; 
if ( pkcode25Doff == null ) { 
pkcode25Doff = new int [ 250 ] ; 
pkcode25Doff [ pcode25Number ] = boff + 2 ; 
pcode25Number ++ ; 
if ( pkcode12Doff == null ) { 
pkcode12Doff = new int [ 250 ] ; 
pkcode12Dlen = new int [ 250 ] ; 
pkcode12Doff [ pcode12Number ] = boff + 2 ; 
pkcode12Dlen [ pcode12Number ] = plen / 4 ; 
pcode12Number ++ ; 
if ( pkcode13Doff == null ) { 
pkcode13Doff = new int [ 250 ] ; 
pkcode13Dlen = new int [ 250 ] ; 
pkcode13Doff [ pcode13Number ] = boff + 2 ; 
pkcode13Dlen [ pcode13Number ] = plen / 4 ; 
pcode13Number ++ ; 
if ( pkcode14Doff == null ) { 
pkcode14Doff = new int [ 250 ] ; 
pkcode14Dlen = new int [ 250 ] ; 
pkcode14Doff [ pcode14Number ] = boff + 2 ; 
pkcode14Dlen [ pcode14Number ] = plen / 4 ; 
pcode14Number ++ ; 
if ( pkcode15Doff == null ) { 
pkcode15Doff = new int [ 250 ] ; 
pkcode15Dlen = new int [ 250 ] ; 
pkcode15Doff [ pcode15Number ] = boff + 2 ; 
pkcode15Dlen [ pcode15Number ] = plen / 6 ; 
pcode15Number ++ ; 
case 166 : 
if ( pkcode16Doff == null ) { 
pkcode16Doff = new int [ 250 ] ; 
pkcode16Dlen = new int [ 250 ] ; 
pkcode16Doff [ pcode16Number ] = boff + 2 ; 
pkcode16Dlen [ pcode16Number ] = plen / 4 ; 
pcode16Number ++ ; 
if ( pkcode19Doff == null ) { 
pkcode19Doff = new int [ 250 ] ; 
pkcode19Dlen = new int [ 250 ] ; 
pkcode19Doff [ pcode19Number ] = boff + 2 ; 
pkcode19Dlen [ pcode19Number ] = plen / 10 ; 
pcode19Number ++ ; 
if ( pkcode20Doff == null ) { 
pkcode20Doff = new int [ 250 ] ; 
pkcode20Dlen = new int [ 250 ] ; 
pkcode20Doff [ pcode20Number ] = boff + 2 ; 
pkcode20Dlen [ pcode20Number ] = plen / 8 ; 
pcode20Number ++ ; 
if ( pkcode4Doff == null ) { 
pkcode4Doff = new int [ 1000 ] ; 
pkcode4Doff [ pcode4Number ] = boff + 2 ; 
pcode4Number ++ ; 
if ( pkcode5Doff == null ) { 
pkcode5Doff = new int [ 1000 ] ; 
pkcode5Doff [ pcode5Number ] = boff + 2 ; 
pcode5Number ++ ; 
int poff = 2 ; 
while ( poff < plen ) { 
int pcode = bos . getShort ( ) ; 
int len = bos . getShort ( ) ; 
switch ( pcode ) 
pkcode2Doff [ pcode2Number ] = boff + poff + 4 ; 
pkcode2Size [ pcode2Number ] = len - 4 ; 
if ( pkcode6Doff == null ) { 
pkcode6Doff = new int [ 250 ] ; 
pkcode6Dlen = new int [ 250 ] ; 
pkcode6Doff [ pcode6Number ] = boff + poff + 4 ; 
pkcode6Dlen [ pcode6Number ] = ( len - 6 ) / 4 ; 
pcode6Number ++ ; 
pkcode25Doff [ pcode25Number ] = boff + poff + 4 ; 
+ pcode ) ; 
poff = poff + len + 4 ; 
bos . position ( bos . position ( ) + len ) ; 
case 0x0802 : 
Divlen_divider = bos . getShort ( ) ; 
if ( Divlen_divider != 0x0002 ) { 
plen = 2 ; 
case 0x0E03 : 
if ( Divlen_divider != 0x8000 ) { 
bos . getShort ( ) ; 
plen = 6 + bos . getShort ( ) ; 
if ( pkcode == 0xAF1F || pkcode == 16 ) { 
hedsiz += pcode_radial ( bos , hoff , hedsiz , isZ , uncompdata , pinfo . threshold ) ; 
plen = Divlen_length ; 
else if ( pkcode == 28 ) { 
hedsiz += pcode_generic ( bos , hoff , hedsiz , isZ , uncompdata , pinfo . threshold ) ; 
else if ( pkcode == 0xBA0F || pkcode == 0xBA07 ) 
hedsiz += pcode_raster ( bos , ( short ) pkcode , hoff , hedsiz , isZ , uncompdata ) ; 
icount = icount + plen + 4 ; 
klayer = klayer + Divlen_length + 6 ; 
if ( pkcode8Doff != null ) { 
pcode_128 ( pkcode8Doff , pkcode8Size , 8 , hoff , pcode8Number , "textStruct_code8" , "" , isZ ) ; 
if ( pkcode1Doff != null ) { 
pcode_128 ( pkcode1Doff , pkcode1Size , 1 , hoff , pcode1Number , "textStruct_code1" , "" , isZ ) ; 
if ( pkcode2Doff != null ) { 
pcode_128 ( pkcode2Doff , pkcode2Size , 2 , hoff , pcode2Number , "textStruct_code2" , "" , isZ ) ; 
if ( pkcode10Doff != null ) { 
pcode_10n9 ( pkcode10Doff , pkcode10Dlen , hoff , pcode10Number , isZ ) ; 
if ( pkcode4Doff != null ) { 
pcode_4 ( pkcode4Doff , hoff , pcode4Number , isZ ) ; 
if ( pkcode5Doff != null ) { 
pcode_5 ( pkcode5Doff , hoff , pcode5Number , isZ ) ; 
if ( pkcode6Doff != null ) { 
pcode_6n7 ( pkcode6Doff , pkcode6Dlen , hoff , pcode6Number , isZ , "linkedVector" , 6 ) ; 
if ( pkcode25Doff != null ) { 
pcode_25 ( pkcode25Doff , hoff , pcode25Number , isZ ) ; 
if ( pkcode12Doff != null ) { 
pcode_12n13n14 ( pkcode12Doff , pkcode12Dlen , hoff , pcode12Number , isZ , "TVS" , 12 ) ; 
if ( pkcode13Doff != null ) { 
pcode_12n13n14 ( pkcode13Doff , pkcode13Dlen , hoff , pcode13Number , isZ , "hailPositive" , 13 ) ; 
if ( pkcode14Doff != null ) { 
pcode_12n13n14 ( pkcode14Doff , pkcode14Dlen , hoff , pcode14Number , isZ , "hailProbable" , 14 ) ; 
if ( pkcode19Doff != null ) { 
pcode_12n13n14 ( pkcode19Doff , pkcode19Dlen , hoff , pcode19Number , isZ , "hailIndex" , 19 ) ; 
if ( pkcode20Doff != null ) { 
pcode_12n13n14 ( pkcode20Doff , pkcode20Dlen , hoff , pcode20Number , isZ , "mesocyclone" , 20 ) ; 
if ( pinfo . offsetToTabularBlock != 0 ) { 
int tlayer = pinfo . offsetToTabularBlock * 2 ; 
bos . position ( tlayer ) ; 
if ( bos . hasRemaining ( ) ) { 
short tab_divider = bos . getShort ( ) ; 
if ( tab_divider != - 1 ) { 
short tab_bid = bos . getShort ( ) ; 
int tblen = bos . getInt ( ) ; 
bos . position ( tlayer + 116 ) ; 
int inc = bos . getInt ( ) ; 
bos . position ( tlayer + 128 ) ; 
tab_divider = bos . getShort ( ) ; 
int npage = bos . getShort ( ) ; 
int ppos = bos . position ( ) ; 
ArrayList dims = new ArrayList ( ) ; 
Dimension tbDim = new Dimension ( "pageNumber" , npage ) ; 
ncfile . addDimension ( null , tbDim ) ; 
dims . add ( tbDim ) ; 
Variable ppage = new Variable ( ncfile , null , null , "TabMessagePage" ) ; 
ppage . setDimensions ( dims ) ; 
ppage . setDataType ( DataType . STRING ) ; 
ncfile . addVariable ( null , ppage ) ; 
ppage . setSPobject ( new Vinfo ( npage , 0 , tblen , 0 , hoff , ppos , isR , isZ , null , null , tab_bid , 0 ) ) ; 
if ( pinfo . offsetToGraphicBlock != 0 ) { 
int gpkcode1Doff [ ] = null ; 
int gpkcode2Doff [ ] = null ; 
int gpkcode10Doff [ ] = null ; 
int gpkcode10Dlen [ ] = null ; 
int gpkcode8Doff [ ] = null ; 
int gpkcode1Size [ ] = null ; 
int gpkcode2Size [ ] = null ; 
int gpkcode8Size [ ] = null ; 
int gpcode1Number = 0 ; 
int gpcode10Number = 0 ; 
int gpcode8Number = 0 ; 
int gpcode2Number = 0 ; 
int tlayer = pinfo . offsetToGraphicBlock * 2 ; 
short graphic_divider = bos . getShort ( ) ; 
short graphic_bid = bos . getShort ( ) ; 
if ( graphic_divider != - 1 || graphic_bid != 2 ) { 
int blen = bos . getInt ( ) ; 
int clen = 0 ; 
int lpage ; 
int ipage = 0 ; 
while ( ( clen < blen ) && ( ipage < npage ) ) { 
ipage = bos . getShort ( ) ; 
lpage = bos . getShort ( ) ; 
int icnt = 0 ; 
ppos = ppos + 4 ; 
while ( icnt < lpage ) 
bos . position ( ppos + icnt ) ; 
int pkcode = bos . getShort ( ) ; 
if ( pkcode == 8 ) { 
if ( gpkcode8Doff == null ) { 
gpkcode8Doff = new int [ 550 ] ; 
gpkcode8Size = new int [ 550 ] ; 
gpkcode8Doff [ gpcode8Number ] = ppos + 4 + icnt ; 
gpkcode8Size [ gpcode8Number ] = plen - 6 ; 
icnt += plen + 4 ; 
gpcode8Number ++ ; 
else if ( pkcode == 1 ) { 
if ( gpkcode1Doff == null ) { 
gpkcode1Doff = new int [ 550 ] ; 
gpkcode1Size = new int [ 550 ] ; 
gpkcode1Doff [ gpcode1Number ] = ppos + 4 + icnt ; 
gpkcode1Size [ gpcode1Number ] = plen - 4 ; 
gpcode1Number ++ ; 
else if ( pkcode == 10 ) { 
if ( gpkcode10Doff == null ) { 
gpkcode10Doff = new int [ 250 ] ; 
gpkcode10Dlen = new int [ 250 ] ; 
gpkcode10Doff [ gpcode10Number ] = ppos + 4 + icnt ; 
gpkcode10Dlen [ gpcode10Number ] = ( plen - 2 ) / 8 ; 
gpcode10Number ++ ; 
ppos = ppos + lpage + 4 ; 
clen = clen + lpage + 4 ; 
if ( gpkcode8Doff != null ) { 
pcode_128 ( gpkcode8Doff , gpkcode8Size , 8 , hoff , gpcode8Number , "textStruct_code8g" , "g" , isZ ) ; 
if ( gpkcode2Doff != null ) { 
pcode_128 ( gpkcode2Doff , gpkcode2Size , 2 , hoff , gpcode8Number , "textStruct_code2g" , "g" , isZ ) ; 
if ( gpkcode1Doff != null ) { 
pcode_128 ( gpkcode1Doff , gpkcode1Size , 1 , hoff , gpcode1Number , "textStruct_code1g" , "g" , isZ ) ; 
if ( gpkcode10Doff != null ) { 
pcode_10n9 ( gpkcode10Doff , gpkcode10Dlen , hoff , gpcode10Number , isZ ) ; 
} int pcode_12n13n14 ( int [ ] pos , int [ ] dlen , int hoff , int len , boolean isZ , String structName , int code ) 
int vlen = 0 ; 
vlen = vlen + dlen [ i ] ; 
Dimension sDim = new Dimension ( "graphicSymbolSize" , vlen ) ; 
ncfile . addDimension ( null , sDim ) ; 
dims . add ( sDim ) ; 
Structure dist = new Structure ( ncfile , null , null , structName ) ; 
dist . setDimensions ( dims ) ; 
ncfile . addVariable ( null , dist ) ; 
Variable i0 = new Variable ( ncfile , null , dist , "x_start" ) ; 
i0 . setDimensions ( ( String ) null ) ; 
i0 . setDataType ( DataType . FLOAT ) ; 
i0 . addAttribute ( new Attribute ( CDM . UNITS , "KM" ) ) ; 
dist . addMemberVariable ( i0 ) ; 
Variable j0 = new Variable ( ncfile , null , dist , "y_start" ) ; 
j0 . setDimensions ( ( String ) null ) ; 
j0 . setDataType ( DataType . FLOAT ) ; 
j0 . addAttribute ( new Attribute ( CDM . UNITS , "KM" ) ) ; 
dist . addMemberVariable ( j0 ) ; 
int [ ] pos1 = new int [ len ] ; 
int [ ] dlen1 = new int [ len ] ; 
System . arraycopy ( dlen , 0 , dlen1 , 0 , len ) ; 
System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; 
dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , dlen1 , code , 0 ) ) ; 
} int pcode_25 ( int [ ] pos , int hoff , int len , boolean isZ ) 
Dimension sDim = new Dimension ( "circleSize" , len ) ; 
Structure dist = new Structure ( ncfile , null , null , "circleStruct" ) ; 
Variable ii0 = new Variable ( ncfile , null , dist , "x_center" ) ; 
ii0 . setDimensions ( ( String ) null ) ; 
ii0 . setDataType ( DataType . SHORT ) ; 
dist . addMemberVariable ( ii0 ) ; 
Variable ii1 = new Variable ( ncfile , null , dist , "y_center" ) ; 
ii1 . setDimensions ( ( String ) null ) ; 
ii1 . setDataType ( DataType . SHORT ) ; 
dist . addMemberVariable ( ii1 ) ; 
Variable jj0 = new Variable ( ncfile , null , dist , "radius" ) ; 
jj0 . setDimensions ( ( String ) null ) ; 
jj0 . setDataType ( DataType . SHORT ) ; 
dist . addMemberVariable ( jj0 ) ; 
dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , null , 25 , 0 ) ) ; 
} int checkMsgHeader ( ucar . unidata . io . RandomAccessFile raf ) throws IOException 
ByteBuffer bos = ByteBuffer . wrap ( b ) ; 
return read_msghead ( bos , 0 ) ; 
} int pcode_5 ( int [ ] pos , int hoff , int len , boolean isZ ) 
Dimension sDim = new Dimension ( "windBarbSize" , len ) ; 
Structure dist = new Structure ( ncfile , null , null , "vectorArrow" ) ; 
i0 . setDataType ( DataType . SHORT ) ; 
j0 . setDataType ( DataType . SHORT ) ; 
Variable direct = new Variable ( ncfile , null , dist , "direction" ) ; 
direct . setDimensions ( ( String ) null ) ; 
direct . setDataType ( DataType . SHORT ) ; 
direct . addAttribute ( new Attribute ( CDM . UNITS , "degree" ) ) ; 
dist . addMemberVariable ( direct ) ; 
Variable speed = new Variable ( ncfile , null , dist , "arrowLength" ) ; 
speed . setDimensions ( ( String ) null ) ; 
speed . setDataType ( DataType . SHORT ) ; 
speed . addAttribute ( new Attribute ( CDM . UNITS , "pixels" ) ) ; 
dist . addMemberVariable ( speed ) ; 
Variable speed1 = new Variable ( ncfile , null , dist , "arrowHeadLength" ) ; 
speed1 . setDimensions ( ( String ) null ) ; 
speed1 . setDataType ( DataType . SHORT ) ; 
speed1 . addAttribute ( new Attribute ( CDM . UNITS , "pixels" ) ) ; 
dist . addMemberVariable ( speed1 ) ; 
dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , null , 4 , 0 ) ) ; 
} int pcode_128 ( int [ ] pos , int [ ] size , int code , int hoff , int len , String structName , String abbre , boolean isZ ) 
Dimension sDim = new Dimension ( "textStringSize" + abbre + code , len ) ; 
Structure dist = new Structure ( ncfile , null , null , structName + abbre ) ; 
if ( code == 8 ) { 
Variable strVal = new Variable ( ncfile , null , dist , "strValue" ) ; 
strVal . setDimensions ( ( String ) null ) ; 
strVal . setDataType ( DataType . SHORT ) ; 
strVal . addAttribute ( new Attribute ( CDM . UNITS , "" ) ) ; 
dist . addMemberVariable ( strVal ) ; 
Variable tstr = new Variable ( ncfile , null , dist , "textString" ) ; 
tstr . setDimensions ( ( String ) null ) ; 
tstr . setDataType ( DataType . STRING ) ; 
tstr . addAttribute ( new Attribute ( CDM . UNITS , "" ) ) ; 
dist . addMemberVariable ( tstr ) ; 
dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , size , code , 0 ) ) ; 
} int pcode_10n9 ( int [ ] pos , int [ ] dlen , int hoff , int len , boolean isZ ) 
Variable v ; 
Dimension sDim = new Dimension ( "unlinkedVectorSize" , vlen ) ; 
Structure dist = new Structure ( ncfile , null , null , "unlinkedVectorStruct" ) ; 
v = new Variable ( ncfile , null , null , "iValue" ) ; 
v . setDataType ( DataType . SHORT ) ; 
dist . addMemberVariable ( v ) ; 
Variable ii0 = new Variable ( ncfile , null , dist , "x_start" ) ; 
Variable ii1 = new Variable ( ncfile , null , dist , "y_start" ) ; 
Variable jj0 = new Variable ( ncfile , null , dist , "x_end" ) ; 
Variable jj1 = new Variable ( ncfile , null , dist , "y_end" ) ; 
jj1 . setDimensions ( ( String ) null ) ; 
jj1 . setDataType ( DataType . SHORT ) ; 
dist . addMemberVariable ( jj1 ) ; 
dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , dlen1 , 10 , 0 ) ) ; 
} int pcode_DPA ( ByteBuffer bos , int pos , int hoff , int hedsiz , boolean isZ , int slayer , int code ) 
int soff ; 
bos . position ( pos ) ; 
bos . get ( b2 , 0 , 2 ) ; 
short numBox = ( short ) getInt ( b2 , 2 ) ; 
short numRow = ( short ) getInt ( b2 , 2 ) ; 
soff = 8 ; 
numY0 = 0 ; 
numX0 = 0 ; 
numX = numBox ; 
numY = numRow ; 
if ( slayer == 0 ) { 
Dimension jDim = new Dimension ( "y" , numY ) ; 
Dimension iDim = new Dimension ( "x" , numX ) ; 
Variable v = new Variable ( ncfile , null , null , cname + "_" + slayer ) ; 
v . setSPobject ( new Vinfo ( numX , numX0 , numY , numY0 , hoff , hedsiz , isR , isZ , null , null , code , 0 ) ) ; 
v . addAttribute ( new Attribute ( CDM . MISSING_VALUE , 255 ) ) ; 
for ( int row = 0 ; row < numRow ; row ++ ) { 
int runLen = bos . getShort ( ) ; 
byte [ ] rdata = new byte [ runLen ] ; 
bos . get ( rdata , 0 , runLen ) ; 
if ( runLen < 2 ) { 
return soff ; 
soff += runLen + 2 ; 
double ddx = code_reslookup ( pcode ) ; 
Variable xaxis = new Variable ( ncfile , null , null , "x" ) ; 
xaxis . setDimensions ( "x" ) ; 
xaxis . addAttribute ( new Attribute ( CDM . UNITS , "km" ) ) ; 
xaxis . addAttribute ( new Attribute ( _Coordinate . AxisType , "GeoX" ) ) ; 
for ( int i = 0 ; i < numX ; i ++ ) 
data1 [ i ] = numX0 + i * ddx ; 
Variable yaxis = new Variable ( ncfile , null , null , "y" ) ; 
yaxis . setDimensions ( "y" ) ; 
yaxis . addAttribute ( new Attribute ( CDM . UNITS , "km" ) ) ; 
yaxis . addAttribute ( new Attribute ( _Coordinate . AxisType , "GeoY" ) ) ; 
for ( int i = 0 ; i < numY ; i ++ ) 
data1 [ i ] = numY0 + i * ddx ; 
ProjectionImpl projection = new FlatEarth ( lat_min , lon_max ) ; 
Variable ct = new Variable ( ncfile , null , null , projection . getClassName ( ) ) ; 
ct . setDataType ( DataType . CHAR ) ; 
ct . setDimensions ( "" ) ; 
List params = projection . getProjectionParameters ( ) ; 
for ( int i = 0 ; i < params . size ( ) ; i ++ ) { 
Parameter p = ( Parameter ) params . get ( i ) ; 
ct . addAttribute ( new Attribute ( p ) ) ; 
ct . addAttribute ( new Attribute ( _Coordinate . TransformType , "Projection" ) ) ; 
dataA = Array . factory ( DataType . CHAR , new int [ ] { } ) ; 
ct . setCachedData ( dataA , false ) ; 
ncfile . addVariable ( null , ct ) ; 
} int pcode_raster ( ByteBuffer bos , short pkcode , int hoff , int hedsiz , boolean isZ , byte [ ] data ) 
int iscale = 1 ; 
int ival ; 
ival = convertShort2unsignedInt ( threshold [ 0 ] ) ; 
if ( ( ival & ( 1 << 13 ) ) != 0 ) iscale = 20 ; 
if ( ( ival & ( 1 << 12 ) ) != 0 ) iscale = 10 ; 
short [ ] rasp_code = new short [ 3 ] ; 
rasp_code [ 0 ] = pkcode ; 
rasp_code [ 1 ] = ( short ) getInt ( b2 , 2 ) ; 
rasp_code [ 2 ] = ( short ) getInt ( b2 , 2 ) ; 
short rasp_xscale = ( short ) getInt ( b2 , 2 ) ; 
short num_rows = ( short ) getInt ( b2 , 2 ) ; 
soff = 20 ; 
hedsiz = hedsiz + soff ; 
int nlevel = code_levelslookup ( pcode ) ; 
int [ ] levels = getLevels ( nlevel , threshold ) ; 
numX = num_rows ; 
numY = num_rows ; 
Dimension jDim = new Dimension ( "y" , numY , true , false , false ) ; 
Dimension iDim = new Dimension ( "x" , numX , true , false , false ) ; 
if ( cname . startsWith ( "Precip" ) ) { 
ncfile . addAttribute ( null , new Attribute ( "isRadial" , new Integer ( 3 ) ) ) ; 
ddx = ddx * rasp_xscale ; 
Variable v = new Variable ( ncfile , null , null , cname + "_RAW" ) ; 
v . setSPobject ( new Vinfo ( numX , numX0 , numY , numY0 , hoff , hedsiz , isR , isZ , null , null , pkcode , 0 ) ) ; 
if ( cname . startsWith ( "VertLiquid" ) ) { 
addVariable ( cname , ctitle , ncfile , dims , coordinates , DataType . FLOAT , 
cunit , hoff , hedsiz , isZ , nlevel , levels , iscale ) ; 
else if ( cname . startsWith ( "EchoTop" ) ) { 
else if ( cname . startsWith ( "BaseReflectivityComp" ) || cname . startsWith ( "LayerCompReflect" ) ) { 
else if ( cname . startsWith ( "Precip" ) ) { 
} int pcode_radial ( ByteBuffer bos , int hoff , int hedsiz , boolean isZ , byte [ ] data , short [ ] threshold ) throws IOException 
short first_bin = ( short ) getInt ( b2 , 2 ) ; 
short num_bin = ( short ) ( getUInt ( b2 , 2 ) ) ; 
if ( this . pcode == 94 || this . pcode == 99 ) 
num_bin = addBinSize ( num_bin ) ; 
short radp_scale = ( short ) getInt ( b2 , 2 ) ; 
if ( this . pcode == 134 || this . pcode == 135 ) 
radp_scale = ( short ) ( radp_scale * 1000 ) ; 
short num_radials = ( short ) getInt ( b2 , 2 ) ; 
soff = 12 ; 
numY = num_radials ; 
numX0 = first_bin ; 
numX = num_bin ; 
int [ ] levels ; 
ncfile . addAttribute ( null , new Attribute ( "cdm_data_type" , FeatureType . RADIAL . toString ( ) ) ) ; 
Dimension radialDim = new Dimension ( "azimuth" , num_radials ) ; 
ncfile . addDimension ( null , radialDim ) ; 
Dimension binDim = new Dimension ( "gate" , num_bin ) ; 
ncfile . addDimension ( null , binDim ) ; 
dims . add ( radialDim ) ; 
dims . add ( binDim ) ; 
ArrayList dims1 = new ArrayList ( ) ; 
ArrayList dims2 = new ArrayList ( ) ; 
dims1 . add ( radialDim ) ; 
dims2 . add ( binDim ) ; 
isR = true ; 
String vName = "elevation" ; 
Attribute att = new Attribute ( _Coordinate . AxisType , AxisType . RadialElevation . toString ( ) ) ; 
addParameter ( vName , lName , ncfile , dims1 , att , DataType . FLOAT , "degrees" , hoff , hedsiz , isZ , p3 ) ; 
vName = "azimuth" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . RadialAzimuth . toString ( ) ) ; 
addParameter ( vName , lName , ncfile , dims1 , att , DataType . FLOAT , "degrees" , hoff , hedsiz , isZ , 0 ) ; 
vName = "gate" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . RadialDistance . toString ( ) ) ; 
addParameter ( vName , lName , ncfile , dims2 , att , DataType . FLOAT , "meters" , hoff , hedsiz , isZ , radp_scale ) ; 
vName = "latitude" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . Lat . toString ( ) ) ; 
vName = "longitude" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . Lon . toString ( ) ) ; 
vName = "altitude" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . Height . toString ( ) ) ; 
addParameter ( vName , lName , ncfile , dims1 , att , DataType . FLOAT , "meters" , hoff , hedsiz , isZ , 0 ) ; 
vName = "rays_time" ; 
att = new Attribute ( _Coordinate . AxisType , AxisType . Time . toString ( ) ) ; 
, hoff , hedsiz , isZ , 0 ) ; 
if ( pcode == 182 || pcode == 99 ) { 
levels = getTDWRLevels ( nlevel , threshold ) ; 
iscale = 10 ; 
} else if ( pcode == 186 || pcode == 94 ) { 
threshold [ 0 ] = - 320 ; 
threshold [ 1 ] = 5 ; 
threshold [ 2 ] = 254 ; 
} else if ( pcode == 32 ) { 
levels = getTDWRLevels1 ( nlevel , threshold ) ; 
} else if ( pcode == 138 ) { 
iscale = 100 ; 
} else if ( pcode == 134 || pcode == 135 ) { 
levels = getTDWRLevels2 ( nlevel , threshold ) ; 
iscale = 1 ; 
} else if ( pcode == 159 || pcode == 161 || pcode == 163 
|| pcode == 170 || pcode == 172 || pcode == 173 
|| pcode == 174 || pcode == 175 
|| pcode == 165 || pcode == 177 ) { 
levels = getDualpolLevels ( threshold ) ; 
levels = getLevels ( nlevel , threshold ) ; 
v . setDataType ( DataType . UBYTE ) ; 
v . setSPobject ( new Vinfo ( numX , numX0 , numY , numY0 , hoff , hedsiz , isR , isZ , null , levels , 0 , nlevel ) ) ; 
if ( cname . startsWith ( "CorrelationCoefficient" ) || cname . startsWith ( "HydrometeorClassification" ) || 
cname . startsWith ( "DifferentialReflectivity" ) || cname . startsWith ( "DifferentialPhase" ) 
|| cname . startsWith ( "HypridHydrometeorClassification" ) ) { 
} else if ( cname . startsWith ( "OneHourAccumulation" ) || cname . startsWith ( "DigitalAccumulationArray" ) || 
cname . startsWith ( "StormTotalAccumulation" ) || cname . startsWith ( "DigitalStormTotalAccumulation" ) || 
cname . startsWith ( "Accumulation3Hour" ) || cname . startsWith ( "Accumulation24Hour" ) || 
cname . startsWith ( "Digital1HourDifferenceAccumulation" ) || 
cname . startsWith ( "DigitalInstantaneousPrecipitationRate" ) || 
cname . startsWith ( "DigitalTotalDifferenceAccumulation" ) ) { 
else if ( cname . startsWith ( "BaseReflectivity" ) || cname . endsWith ( "Reflectivity" ) || 
cname . startsWith ( "SpectrumWidth" ) ) { 
else if ( cname . startsWith ( "RadialVelocity" ) || cname . startsWith ( "StormMeanVelocity" ) || 
cname . startsWith ( "BaseVelocity" ) ) { 
else if ( cname . startsWith ( "Precip" ) || cname . endsWith ( "Precip" ) || 
cname . startsWith ( "EnhancedEchoTop" ) || cname . startsWith ( "DigitalIntegLiquid" ) ) { 
} public List parseComponents ( ByteBuffer datainput ) 
ArrayList arraylist = null ; 
int i = datainput . getInt ( ) ; 
if ( i != 0 ) 
i = datainput . getInt ( ) ; 
for ( int j = 0 ; j < i ; j ++ ) 
datainput . getInt ( ) ; 
int type = datainput . getInt ( ) ; 
arraylist = parseData ( datainput ) ; 
return arraylist ; 
} public ArrayList parseData ( ByteBuffer datainput ) 
ArrayList arraylist = new ArrayList ( ) ; 
int numRadials ; 
int numBins ; 
int dataOffset ; 
readInString ( datainput ) ; 
datainput . getFloat ( ) ; 
float rangeToFirstBin = datainput . getFloat ( ) ; 
numRadials = datainput . getInt ( ) ; 
dataOffset = datainput . position ( ) ; 
numBins = datainput . getInt ( ) ; 
arraylist . add ( numBins ) ; 
arraylist . add ( numRadials ) ; 
arraylist . add ( rangeToFirstBin ) ; 
arraylist . add ( dataOffset ) ; 
} public List parseParameters ( ByteBuffer datainput ) 
if ( i > 0 ) 
arraylist . add ( readInString ( datainput ) ) ; 
HashMap hm = addAttributePairs ( readInString ( datainput ) ) ; 
arraylist . add ( hm ) ; 
} public HashMap addAttributePairs ( String s ) 
java . util . regex . Pattern PARAM_PATTERN = 
java . util . regex . Pattern . compile ( "([\\w*\\s*?]*)\\=([(\\<|\\{|\\[|\\()?\\w*\\s*?\\.?\\,?\\-?\\/?\\%?(\\>|\\}|\\]|\\))?]*)" ) ; 
HashMap attributes = new HashMap ( ) ; 
for ( java . util . regex . Matcher matcher = PARAM_PATTERN . matcher ( s ) ; 
matcher . find ( ) ; attributes . put ( matcher . group ( 1 ) . trim ( ) , matcher . group ( 2 ) . trim ( ) ) ) ; 
} public static String readInString ( ByteBuffer datainput ) 
StringBuffer stringbuffer = new StringBuffer ( ) ; 
char c = ( char ) ( datainput . get ( ) & 0xff ) ; 
stringbuffer . append ( c ) ; 
int k = i % 4 ; 
if ( k != 0 ) 
k = 4 - k ; 
for ( int l = 0 ; l < k ; l ++ ) 
datainput . get ( ) ; 
return stringbuffer . toString ( ) ; 
} int pcode_generic ( ByteBuffer bos , int hoff , int hedsiz , boolean isZ , byte [ ] data , short [ ] threshold ) throws IOException 
int soff = 0 ; 
readInString ( bos ) ; 
bos . getInt ( ) ; 
bos . getFloat ( ) ; 
float eleAngle = bos . getFloat ( ) ; 
p3 = ( short ) eleAngle ; 
bos . getDouble ( ) ; 
parseParameters ( bos ) ; 
List cc = parseComponents ( bos ) ; 
if ( cc == null ) { 
int num_radials = ( Integer ) cc . get ( 1 ) ; 
int num_bin = ( Integer ) cc . get ( 0 ) ; 
float rangeToFirstBin = ( Float ) cc . get ( 2 ) ; 
int dataOffset = ( Integer ) cc . get ( 3 ) ; 
numX0 = ( int ) rangeToFirstBin ; 
short radp_scale = 1000 ; 
hedsiz = dataOffset ; 
if ( pcode == 176 ) { 
v . setDataType ( DataType . USHORT ) ; 
if ( cname . startsWith ( "DigitalInstantaneousPrecipitationRate" ) ) { 
} public int [ ] getLevels ( int nlevel , short [ ] th ) { 
int [ ] levels = new int [ nlevel ] ; 
int isign ; 
for ( int i = 0 ; i < nlevel ; i ++ ) { 
ival = convertShort2unsignedInt ( th [ i ] ) ; 
if ( ( ival & 0x00008000 ) == 0 ) { 
isign = - 1 ; 
if ( ( ival & 0x00000100 ) == 0 ) isign = 1 ; 
levels [ i ] = isign * ( ival & 0x000000FF ) ; 
levels [ i ] = - 9999 + ( ival & 0x000000FF ) ; 
return levels ; 
} public int [ ] getTDWRLevels ( int nlevel , short [ ] th ) { 
int inc = th [ 1 ] ; 
levels [ 0 ] = - 9866 ; 
levels [ 1 ] = - 9866 ; 
for ( int i = 2 ; i < nlevel ; i ++ ) { 
levels [ i ] = th [ 0 ] + ( i - 2 ) * inc ; 
} public int [ ] getTDWRLevels1 ( int nlevel , short [ ] th ) { 
levels [ i ] = th [ 0 ] + ( i ) * inc ; 
} public int [ ] getDualpolLevels ( short [ ] th ) { 
int inc = th . length ; 
int [ ] levels = new int [ inc ] ; 
for ( int i = 0 ; i < inc ; i ++ ) { 
levels [ i ] = th [ i ] ; 
} public int [ ] getTDWRLevels2 ( int nlevel , short [ ] th ) { 
} void addVariable ( String pName , String longName , NetcdfFile nc , ArrayList dims , String coordinates , 
DataType dtype , String ut , long hoff , long hedsiz , boolean isZ , int nlevel , int [ ] levels , int iscale ) 
Variable v = new Variable ( nc , null , null , pName ) ; 
v . setDataType ( dtype ) ; 
v . addAttribute ( new Attribute ( CDM . UNITS , ut ) ) ; 
v . setSPobject ( new Vinfo ( numX , numX0 , numY , numY0 , hoff , hedsiz , isR , isZ , null , levels , iscale , nlevel ) ) ; 
} void addParameter ( String pName , String longName , NetcdfFile nc , ArrayList dims , Attribute att , 
DataType dtype , String ut , long hoff , long doff , boolean isZ , int y0 ) 
String vName = pName ; 
Variable vVar = new Variable ( nc , null , null , vName ) ; 
vVar . setDataType ( dtype ) ; 
if ( dims != null ) vVar . setDimensions ( dims ) ; 
else vVar . setDimensions ( "" ) ; 
if ( att != null ) vVar . addAttribute ( att ) ; 
vVar . addAttribute ( new Attribute ( CDM . UNITS , ut ) ) ; 
vVar . addAttribute ( new Attribute ( CDM . LONG_NAME , longName ) ) ; 
nc . addVariable ( null , vVar ) ; 
vVar . setSPobject ( new Vinfo ( numX , numX0 , numY , y0 , hoff , doff , isR , isZ , null , null , 0 , 0 ) ) ; 
} private int getProductLevel ( int prod_elevation ) { 
int level = 0 ; 
if ( prod_elevation == 5 ) 
level = 0 ; 
else if ( prod_elevation == 9 ) 
level = 1 ; 
else if ( prod_elevation == 13 || prod_elevation == 15 ) 
level = 2 ; 
else if ( prod_elevation == 18 ) 
level = 3 ; 
else if ( prod_elevation == 24 ) 
level = 4 ; 
else if ( prod_elevation == 31 ) 
level = 6 ; 
return level ; 
} void setProductInfo ( int prod_type , Pinfo pinfo ) 
short prod_max = pinfo . p4 ; 
short prod_min = 0 ; 
int prod_elevation = 0 ; 
int prod_top ; 
int radial = 0 ; 
java . util . Date endDate ; 
java . util . Date startDate ; 
String dstring ; 
double t1 = 124.0 * 1.853 / 111.26 ; 
double t2 = 230 / ( 111.26 * Math . cos ( Math . toRadians ( latitude ) ) ) ; 
lat_min = latitude - t1 ; 
lat_max = latitude + t1 ; 
lon_min = longitude + t2 ; 
lon_max = longitude - t2 ; 
startDate = getDate ( volumeScanDate , volumeScanTime * 1000 ) ; 
endDate = getDate ( volumeScanDate , volumeScanTime * 1000 ) ; 
if ( prod_type == SPECTRUM ) { 
radial = 1 ; 
prod_elevation = pinfo . p3 ; 
ctilt = pname_lookup ( pcode , prod_elevation / 10 ) ; 
cname = "SpectrumWidth" ; 
if ( pcode == 28 ) { 
t1 = t1 * 0.25 ; 
t2 = t2 * 0.25 ; 
else if ( prod_type == DigitalDifferentialReflectivity ) { 
int pLevel = getProductLevel ( prod_elevation ) ; 
ctilt = pname_lookup ( 15 , pLevel ) ; 
cunit = "dBz" ; 
cname = "DifferentialReflectivity" ; 
else if ( prod_type == DigitalCorrelationCoefficient ) { 
ctilt = pname_lookup ( 16 , pLevel ) ; 
cname = "CorrelationCoefficient" ; 
else if ( prod_type == DigitalDifferentialPhase ) { 
ctilt = pname_lookup ( 17 , pLevel ) ; 
cunit = "Degree/km" ; 
cname = "DifferentialPhase" ; 
else if ( prod_type == HydrometeorClassification ) { 
ctilt = pname_lookup ( 18 , pLevel ) ; 
cname = "HydrometeorClassification" ; 
else if ( prod_type == HypridHydrometeorClassification ) { 
cname = "HypridHydrometeorClassification" ; 
else if ( prod_type == OneHourAccumulation ) { 
ctilt = "OHA" ; 
cunit = "IN" ; 
cname = "OneHourAccumulation" ; 
else if ( prod_type == DigitalAccumulationArray ) { 
ctilt = "DAA" ; 
cname = "DigitalAccumulationArray" ; 
else if ( prod_type == StormTotalAccumulation ) { 
ctilt = "PTA" ; 
cname = "StormTotalAccumulation" ; 
else if ( prod_type == DigitalStormTotalAccumulation ) { 
ctilt = "DTA" ; 
cname = "DigitalStormTotalAccumulation" ; 
else if ( prod_type == Accumulation3Hour ) { 
cname = "Accumulation3Hour" ; 
else if ( prod_type == Digital1HourDifferenceAccumulation ) { 
ctilt = "DOD" ; 
cname = "Digital1HourDifferenceAccumulation" ; 
else if ( prod_type == DigitalTotalDifferenceAccumulation ) { 
ctilt = "DSD" ; 
cname = "DigitalTotalDifferenceAccumulation" ; 
else if ( prod_type == DigitalInstantaneousPrecipitationRate ) { 
ctilt = "DPR" ; 
cunit = "IN/Hour" ; 
cname = "DigitalInstantaneousPrecipitationRate" ; 
else if ( prod_type == BaseReflectivityDR ) { 
ctilt = pname_lookup ( 94 , pLevel ) ; 
cname = "BaseReflectivityDR" ; 
else if ( prod_type == BaseVelocityDV ) { 
ctilt = pname_lookup ( 99 , pLevel ) ; 
cunit = "m/s" ; 
cname = "BaseVelocityDV" ; 
} else if ( prod_type == DigitalVert_Liquid ) { 
ctilt = pname_lookup ( 134 , prod_elevation / 10 ) ; 
cunit = "kg/m^2" ; 
cname = "DigitalIntegLiquid" ; 
else if ( prod_type == DigitalHybridReflect ) { 
ctilt = pname_lookup ( 19 , prod_elevation / 10 ) ; 
cname = "DigitalHybridReflectivity" ; 
} else if ( prod_type == Base_Reflect || prod_type == Reflect1 ) { 
if ( prod_type == Reflect1 ) { 
ctilt = "R" + prod_elevation / 10 ; 
cname = "BaseReflectivity" ; 
} else if ( prod_type == BaseReflect248 ) { 
ctilt = pname_lookup ( 20 , prod_elevation / 10 ) ; 
cname = "BaseReflectivity248" ; 
t1 = 248.0 * 1.853 / 111.26 ; 
t2 = 460 / ( 111.26 * Math . cos ( Math . toRadians ( latitude ) ) ) ; 
} else if ( prod_type == Comp_Reflect ) { 
radial = 3 ; 
prod_elevation = - 1 ; 
ctilt = pname_lookup ( pinfo . pcode , elevationNumber ) ; 
if ( pinfo . pcode == 36 || pinfo . pcode == 38 ) { 
t1 = t1 * 2 ; 
t2 = t2 * 2 ; 
cname = "BaseReflectivityComp" ; 
} else if ( prod_type == Layer_Reflect_Avg || 
prod_type == Layer_Reflect_Max ) { 
prod_elevation = pinfo . p5 ; 
prod_top = pinfo . p6 ; 
ctilt = pname_lookup ( pcode , 0 ) ; 
t1 = t1 * 4 ; 
t2 = t2 * 4 ; 
cname = "LayerCompReflect" ; 
} else if ( prod_type == EnhancedEcho_Tops ) { 
ctilt = pname_lookup ( 135 , elevationNumber ) ; 
cname = "EnhancedEchoTop" ; 
} else if ( prod_type == Echo_Tops ) { 
ctilt = pname_lookup ( 41 , elevationNumber ) ; 
cname = "EchoTop" ; 
} else if ( prod_type == Precip_1 ) { 
prod_max /= 10 ; 
endDate = getDate ( pinfo . p7 , pinfo . p8 * 60 * 1000 ) ; 
ctilt = pname_lookup ( 78 , elevationNumber ) ; 
cname = "Precip1hr" ; 
} else if ( prod_type == Precip_3 ) { 
ctilt = pname_lookup ( 79 , elevationNumber ) ; 
cname = "Precip3hr" ; 
} else if ( prod_type == DigitalStormTotalPrecip ) { 
ctilt = pname_lookup ( 80 , elevationNumber ) ; 
cname = "DigitalPrecip" ; 
} else if ( prod_type == Precip_Accum ) { 
cname = "PrecipAccum" ; 
} else if ( prod_type == Precip_Array ) { 
ctilt = pname_lookup ( 81 , elevationNumber ) ; 
cunit = "dBA" ; 
cname = "PrecipArray" ; 
} else if ( prod_type == Vert_Liquid ) { 
ctilt = pname_lookup ( 57 , elevationNumber ) ; 
cname = "VertLiquid" ; 
} else if ( prod_type == Velocity || prod_type == Velocity1 ) { 
prod_min = pinfo . p4 ; 
prod_max = pinfo . p5 ; 
if ( prod_type == Velocity ) { 
ctilt = pname_lookup ( pinfo . pcode , prod_elevation / 10 ) ; 
ctilt = "V" + prod_elevation / 10 ; 
if ( pinfo . pcode == 25 ) { 
t1 = 32.0 * 1.853 / 111.26 ; 
t2 = 64 / ( 111.26 * Math . cos ( Math . toRadians ( latitude ) ) ) ; 
cname = "RadialVelocity" ; 
} else if ( prod_type == StrmRelMeanVel ) { 
ctilt = pname_lookup ( 56 , prod_elevation / 10 ) ; 
cunit = "KT" ; 
cname = "StormMeanVelocity" ; 
} else if ( prod_type == VAD ) { 
radial = 0 ; 
ctilt = pname_lookup ( 48 , elevationNumber ) ; 
cname = "VADWindSpeed" ; 
lat_min = latitude ; 
lat_max = latitude ; 
lon_min = longitude ; 
lon_max = longitude ; 
summary ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "keywords_vocabulary" , ctilt ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "format" , "Level3/NIDS" ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_lat_min" , new Float ( lat_min ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_lat_max" , new Float ( lat_max ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_lon_min" , new Float ( lon_min ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_lon_max" , new Float ( lon_max ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_vertical_min" , new Float ( height ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "geospatial_vertical_max" , new Float ( height ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "RadarElevationNumber" , new Integer ( prod_elevation ) ) ) ; 
dstring = formatter . toDateTimeStringISO ( startDate ) ; 
ncfile . addAttribute ( null , new Attribute ( "time_coverage_start" , dstring ) ) ; 
dstring = formatter . toDateTimeStringISO ( endDate ) ; 
ncfile . addAttribute ( null , new Attribute ( "time_coverage_end" , dstring ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "data_min" , new Float ( prod_min ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "data_max" , new Float ( prod_max ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "isRadial" , new Integer ( radial ) ) ) ; 
} byte [ ] uncompressed ( ByteBuffer buf , int offset , int uncomplen ) throws IOException 
byte [ ] header = new byte [ offset ] ; 
buf . get ( header ) ; 
byte [ ] out = new byte [ offset + uncomplen ] ; 
System . arraycopy ( header , 0 , out , 0 , offset ) ; 
int numCompBytes = buf . remaining ( ) ; 
byte [ ] bufc = new byte [ numCompBytes ] ; 
buf . get ( bufc , 0 , numCompBytes ) ; 
ByteArrayInputStream bis = new ByteArrayInputStream ( bufc , 2 , numCompBytes - 2 ) ; 
if ( obuff . length >= 0 ) 
System . arraycopy ( obuff , 0 , out , offset , total ) ; 
} Sinfo read_dividlen ( ByteBuffer buf , int offset ) 
byte [ ] b4 = new byte [ 4 ] ; 
short D_divider ; 
short D_id ; 
Short tShort ; 
buf . position ( offset ) ; 
buf . get ( b2 , 0 , 2 ) ; 
tShort = ( Short ) convert ( b2 , DataType . SHORT , - 1 ) ; 
D_divider = tShort . shortValue ( ) ; 
D_id = ( short ) getInt ( b2 , 2 ) ; 
buf . get ( b4 , 0 , 4 ) ; 
block_length = getInt ( b4 , 4 ) ; 
number_layers = ( short ) getInt ( b2 , 2 ) ; 
return new Sinfo ( D_divider , D_id , block_length , number_layers ) ; 
} int read_msghead ( ByteBuffer buf , int offset ) 
mcode = ( short ) getInt ( b2 , 2 ) ; 
mdate = ( short ) getInt ( b2 , 2 ) ; 
mtime = getInt ( b4 , 4 ) ; 
mlength = getInt ( b4 , 4 ) ; 
msource = ( short ) getInt ( b2 , 2 ) ; 
if ( stationId == null || stationName == null ) { 
NexradStationDB . Station station = NexradStationDB . getByIdNumber ( "000" + Short . toString ( msource ) ) ; 
stationId = station . id ; 
mdestId = ( short ) getInt ( b2 , 2 ) ; 
mNumOfBlock = ( short ) getInt ( b2 , 2 ) ; 
} int getUInt ( byte [ ] b , int num ) 
int base = 1 ; 
int word = 0 ; 
int bv [ ] = new int [ num ] ; 
for ( i = 0 ; i < num ; i ++ ) 
bv [ i ] = convertunsignedByte2Short ( b [ i ] ) ; 
for ( i = num - 1 ; i >= 0 ; i -- ) { 
word += base * bv [ i ] ; 
base *= 256 ; 
return word ; 
} int getInt ( byte [ ] b , int num ) 
if ( bv [ 0 ] > 127 ) 
bv [ 0 ] -= 128 ; 
base = - 1 ; 
} Pinfo read_proddesc ( ByteBuffer buf , int offset ) { 
int off = offset ; 
Integer tInt ; 
divider = tShort . shortValue ( ) ; 
ncfile . addAttribute ( null , new Attribute ( "Divider" , tShort ) ) ; 
tInt = ( Integer ) convert ( b4 , DataType . INT , - 1 ) ; 
latitude = tInt . intValue ( ) / 1000.0 ; 
longitude = tInt . intValue ( ) / 1000.0 ; 
height = getInt ( b2 , 2 ) * 0.3048 ; 
if ( useStationDB ) { 
latitude = station . lat ; 
longitude = station . lon ; 
height = station . elev ; 
ncfile . addAttribute ( null , new Attribute ( "RadarLatitude" , new Double ( latitude ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "RadarLongitude" , new Double ( longitude ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "RadarAltitude" , new Double ( height ) ) ) ; 
pcode = ( short ) getInt ( b2 , 2 ) ; 
if ( stationId != null ) ncfile . addAttribute ( null , new Attribute ( "ProductStation" , stationId ) ) ; 
if ( stationName != null ) ncfile . addAttribute ( null , new Attribute ( "ProductStationName" , stationName ) ) ; 
opmode = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "OperationalMode" , new Short ( opmode ) ) ) ; 
volumnScanPattern = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "VolumeCoveragePatternName" , new Short ( volumnScanPattern ) ) ) ; 
sequenceNumber = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "SequenceNumber" , new Short ( sequenceNumber ) ) ) ; 
volumeScanNumber = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "VolumeScanNumber" , new Short ( volumeScanNumber ) ) ) ; 
volumeScanDate = ( short ) getUInt ( b2 , 2 ) ; 
volumeScanTime = getUInt ( b4 , 4 ) ; 
productDate = ( short ) getUInt ( b2 , 2 ) ; 
productTime = getUInt ( b4 , 4 ) ; 
java . util . Date pDate = getDate ( productDate , productTime * 1000 ) ; 
String dstring = formatter . toDateTimeStringISO ( pDate ) ; 
ncfile . addAttribute ( null , new Attribute ( "DateCreated" , dstring ) ) ; 
p1 = ( short ) getInt ( b2 , 2 ) ; 
p2 = ( short ) getInt ( b2 , 2 ) ; 
elevationNumber = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "ElevationNumber" , new Short ( elevationNumber ) ) ) ; 
p3 = ( short ) getInt ( b2 , 2 ) ; 
off += 40 ; 
if ( pcode == 182 || pcode == 186 || pcode == 32 
|| pcode == 94 || pcode == 99 ) { 
for ( int i = 0 ; i < 16 ; i ++ ) { 
threshold [ i ] = ( short ) bytesToInt ( b2 [ 0 ] , b2 [ 1 ] , false ) ; 
|| pcode == 174 || pcode == 175 ) { 
byte [ ] b44 = { b4 [ 3 ] , b4 [ 2 ] , b4 [ 1 ] , b4 [ 0 ] } ; 
threshold [ 0 ] = ( short ) ( java . nio . ByteBuffer . wrap ( b44 ) . order ( java . nio . ByteOrder . LITTLE_ENDIAN ) . getFloat ( ) * 100 ) ; 
byte [ ] b45 = { b4 [ 3 ] , b4 [ 2 ] , b4 [ 1 ] , b4 [ 0 ] } ; 
threshold [ 1 ] = ( short ) ( java . nio . ByteBuffer . wrap ( b45 ) . order ( java . nio . ByteOrder . LITTLE_ENDIAN ) . getFloat ( ) * 100 ) ; 
threshold [ 2 ] = 0 ; 
for ( int i = 3 ; i < 6 ; i ++ ) { 
} else if ( pcode == 176 ) { 
threshold [ 0 ] = ( short ) ( java . nio . ByteBuffer . wrap ( b44 ) . order ( java . nio . ByteOrder . LITTLE_ENDIAN ) . getFloat ( ) ) ; 
threshold [ 1 ] = ( short ) ( java . nio . ByteBuffer . wrap ( b45 ) . order ( java . nio . ByteOrder . LITTLE_ENDIAN ) . getFloat ( ) ) ; 
threshold [ i ] = ( short ) getInt ( b2 , 2 ) ; 
off += 32 ; 
p4 = ( short ) getInt ( b2 , 2 ) ; 
p5 = ( short ) getInt ( b2 , 2 ) ; 
p6 = ( short ) getInt ( b2 , 2 ) ; 
p7 = ( short ) getInt ( b2 , 2 ) ; 
p8 = ( short ) getInt ( b2 , 2 ) ; 
p9 = ( short ) getInt ( b2 , 2 ) ; 
p10 = ( short ) getUInt ( b2 , 2 ) ; 
off += 14 ; 
numberOfMaps = ( short ) getInt ( b2 , 2 ) ; 
ncfile . addAttribute ( null , new Attribute ( "NumberOfMaps" , new Short ( numberOfMaps ) ) ) ; 
off += 2 ; 
offsetToSymbologyBlock = getInt ( b4 , 4 ) ; 
off += 4 ; 
offsetToGraphicBlock = getInt ( b4 , 4 ) ; 
offsetToTabularBlock = getInt ( b4 , 4 ) ; 
return new Pinfo ( divider , latitude , longitude , height , pcode , opmode , threshold , 
sequenceNumber , volumeScanNumber , volumeScanDate , volumeScanTime , 
productDate , productTime , p1 , p2 , p3 , p4 , p5 , p6 , p7 , p8 , p9 , p10 , 
elevationNumber , numberOfMaps , offsetToSymbologyBlock , 
offsetToGraphicBlock , offsetToTabularBlock ) ; 
} protected Object convert ( byte [ ] barray , DataType dataType , int nelems , int byteOrder ) { 
return barray ; 
if ( dataType == DataType . CHAR ) { 
return IospHelper . convertByteToChar ( barray ) ; 
ByteBuffer bbuff = ByteBuffer . wrap ( barray ) ; 
if ( byteOrder >= 0 ) 
bbuff . order ( byteOrder == ucar . unidata . io . RandomAccessFile . LITTLE_ENDIAN ? ByteOrder . LITTLE_ENDIAN : ByteOrder . BIG_ENDIAN ) ; 
if ( dataType == DataType . SHORT ) { 
ShortBuffer tbuff = bbuff . asShortBuffer ( ) ; 
short [ ] pa = new short [ nelems ] ; 
tbuff . get ( pa ) ; 
IntBuffer tbuff = bbuff . asIntBuffer ( ) ; 
int [ ] pa = new int [ nelems ] ; 
FloatBuffer tbuff = bbuff . asFloatBuffer ( ) ; 
float [ ] pa = new float [ nelems ] ; 
DoubleBuffer tbuff = bbuff . asDoubleBuffer ( ) ; 
double [ ] pa = new double [ nelems ] ; 
} protected Object convert ( byte [ ] barray , DataType dataType , int byteOrder ) { 
return new Byte ( barray [ 0 ] ) ; 
return new Character ( ( char ) barray [ 0 ] ) ; 
return new Short ( tbuff . get ( ) ) ; 
return new Integer ( tbuff . get ( ) ) ; 
} else if ( dataType == DataType . LONG ) { 
LongBuffer tbuff = bbuff . asLongBuffer ( ) ; 
return new Long ( tbuff . get ( ) ) ; 
return new Float ( tbuff . get ( ) ) ; 
return new Double ( tbuff . get ( ) ) ; 
} int isZlibHed ( byte [ ] buf ) { 
short b0 = convertunsignedByte2Short ( buf [ 0 ] ) ; 
short b1 = convertunsignedByte2Short ( buf [ 1 ] ) ; 
if ( ( b0 & 0xf ) == Z_DEFLATED ) { 
if ( ( b0 > > 4 ) + 8 <= DEF_WBITS ) { 
if ( ( ( ( b0 << 8 ) + b1 ) % 31 ) == 0 ) { 
} int IsEncrypt ( byte [ ] buf ) 
String b = new String ( buf , CDM . utf8Charset ) ; 
if ( b . startsWith ( "R3" ) ) { 
} byte [ ] GetZlibedNexr ( byte [ ] buf , int buflen , int hoff ) throws IOException 
int doff ; 
int numin ; 
numin = buflen - hoff ; 
if ( numin <= 0 ) 
System . arraycopy ( buf , hoff , buf , hoff , numin - 4 ) ; 
int resultLength ; 
byte [ ] tmp ; 
int uncompLen = 24500 ; 
byte [ ] uncomp = new byte [ uncompLen ] ; 
Inflater inflater = new Inflater ( false ) ; 
inflater . setInput ( buf , hoff , numin - 4 ) ; 
int limit = 20000 ; 
while ( inflater . getRemaining ( ) > 0 ) 
resultLength = inflater . inflate ( uncomp , offset , 4000 ) ; 
catch ( DataFormatException ex ) { 
throw new IOException ( ex . getMessage ( ) , ex ) ; 
offset = offset + resultLength ; 
result = result + resultLength ; 
if ( result > limit ) { 
tmp = new byte [ result ] ; 
System . arraycopy ( uncomp , 0 , tmp , 0 , result ) ; 
uncompLen = uncompLen + 10000 ; 
uncomp = new byte [ uncompLen ] ; 
System . arraycopy ( tmp , 0 , uncomp , 0 , result ) ; 
if ( resultLength == 0 ) { 
int tt = inflater . getRemaining ( ) ; 
System . arraycopy ( buf , hoff + numin - 4 - tt , b2 , 0 , 2 ) ; 
if ( result + tt > uncompLen ) { 
if ( isZlibHed ( b2 ) == 0 ) { 
System . arraycopy ( buf , hoff + numin - 4 - tt , uncomp , result , tt ) ; 
result = result + tt ; 
inflater . reset ( ) ; 
inflater . setInput ( buf , hoff + numin - 4 - tt , tt ) ; 
inflater . end ( ) ; 
doff = 2 * ( ( ( uncomp [ 0 ] & 0x3f ) << 8 ) | ( uncomp [ 1 ] & 0xFF ) ) ; 
while ( ( doff < result ) && ( uncomp [ doff ] != '\n' ) ) doff ++ ; 
doff ++ ; 
byte [ ] data = new byte [ result - doff ] ; 
System . arraycopy ( uncomp , doff , data , 0 , result - doff ) ; 
} static int code_typelookup ( int code ) 
final int [ ] types = { 
Other , Other , Other , Other , Other , 
Other , Base_Reflect , Base_Reflect , Base_Reflect , Base_Reflect , 
BaseReflect248 , Base_Reflect , Velocity , 
Velocity , Velocity , Velocity , Velocity , Velocity , SPECTRUM , SPECTRUM , 
SPECTRUM , Other , DigitalHybridReflect , Other , Other , 
Comp_Reflect , Comp_Reflect , Comp_Reflect , Comp_Reflect , Other , 
Other , Echo_Tops , Other , Other , Other , 
Other , Other , Other , VAD , Other , 
StrmRelMeanVel , StrmRelMeanVel , Vert_Liquid , Other , Other , 
Other , Other , Other , Layer_Reflect_Avg , 
Layer_Reflect_Avg , Layer_Reflect_Max , 
Layer_Reflect_Max , Other , Other , Other , 
Other , Other , Other , Precip_1 , Precip_3 , 
Precip_Accum , Precip_Array , Other , 
Other , Other , Other , Other , Other , Other , Layer_Reflect_Avg , 
BaseReflectivityDR , Other , Other , Other , Other , BaseVelocityDV , 
Other , Other , Other , Other , DigitalVert_Liquid , 
EnhancedEcho_Tops , Other , Other , DigitalStormTotalPrecip , Other , 
Other , Other , Other , Other , DigitalDifferentialReflectivity , 
Other , DigitalCorrelationCoefficient , Other , DigitalDifferentialPhase , Other , 
HydrometeorClassification , Other , Other , Other , OneHourAccumulation , 
DigitalAccumulationArray , StormTotalAccumulation , DigitalStormTotalAccumulation , 
Accumulation3Hour , Digital1HourDifferenceAccumulation , 
DigitalTotalDifferenceAccumulation , DigitalInstantaneousPrecipitationRate , 
HypridHydrometeorClassification , Other , Other , 
Reflect1 , Reflect1 , Velocity1 , Velocity1 , Other , 
SPECTRUM1 , Reflect1 , Reflect1 , Other , Other , 
if ( code < 0 || code > 189 ) 
type = Other ; 
type = types [ code ] ; 
} static String pname_lookup ( int code , int elevation ) 
String pname = null ; 
if ( elevation == 1 ) 
pname = "NAX" ; 
else if ( elevation == 3 ) 
pname = "NBX" ; 
pname = "N" + elevation / 2 + "X" ; 
pname = "NAC" ; 
pname = "NBC" ; 
pname = "N" + elevation / 2 + "C" ; 
pname = "NAK" ; 
pname = "NBK" ; 
pname = "N" + elevation / 2 + "K" ; 
pname = "NAH" ; 
pname = "NBH" ; 
pname = "N" + elevation / 2 + "H" ; 
pname = "N" + elevation + "R" ; 
pname = "N0Z" ; 
pname = "N0W" ; 
pname = "N" + elevation + "V" ; 
pname = "NSP" ; 
pname = "NSW" ; 
pname = "NCO" ; 
pname = "NCR" ; 
pname = "NCZ" ; 
pname = "NET" ; 
pname = "NVW" ; 
pname = "N" + elevation + "S" ; 
pname = "NVL" ; 
case 65 : 
pname = "NLL" ; 
case 66 : 
pname = "NML" ; 
case 78 : 
pname = "N1P" ; 
case 79 : 
pname = "N3P" ; 
case 80 : 
pname = "NTP" ; 
case 81 : 
pname = "DPA" ; 
pname = "NHL" ; 
case 94 : 
pname = "NAQ" ; 
pname = "NBQ" ; 
pname = "N" + elevation / 2 + "Q" ; 
pname = "NAU" ; 
pname = "NBU" ; 
pname = "N" + elevation / 2 + "U" ; 
case 134 : 
pname = "DVL" ; 
case 135 : 
pname = "EET" ; 
case 182 : 
pname = "DV" ; 
case 187 : 
case 181 : 
pname = "R" ; 
case 186 : 
case 180 : 
pname = "DR" ; 
case 183 : 
pname = "V" ; 
case 185 : 
pname = "SW" ; 
return pname ; 
} static double code_reslookup ( int code ) 
double data_res ; 
final double [ ] res = { 
0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 
0 , 0 , 0 , 0 , 0 , 0 , 1 , 2 , 4 , 1 , 
2 , 4 , 0.25 , 0.5 , 1 , 0.25 , 0.5 , 1 , 0.25 , 0 , 
1 , 0 , 1 , 0 , 0 , 1 , 4 , 1 , 4 , 0 , 
0 , 4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 
0 , 0 , 0 , 0 , 0 , 0.5 , 1 , 4 , 0 , 0 , 
0 , 0 , 0 , 4 , 4 , 4 , 4 , 0 , 0 , 0 , 
0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 
1 , 4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 4 , 
4 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0.25 , 
0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 0 , 
0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0.25 , 
0 , 0.25 , 0 , 0.25 , 0 , 0.25 , 0 , 0 , 0 , 2 , 
0.25 , 2 , 0.25 , 0.25 , 0.25 , 0.25 , 0.25 , 0.25 , 0 , 0 , 
0 , 150.0 , 150.0 , 0 , 0 , 0 , 300.0 , 0 , 0 , 0 , 
data_res = 0 ; 
data_res = res [ code ] ; 
return data_res ; 
} static int code_levelslookup ( int code ) 
int level ; 
final int [ ] levels = { 
0 , 0 , 0 , 0 , 0 , 0 , 8 , 8 , 8 , 16 , 
16 , 16 , 8 , 8 , 8 , 16 , 16 , 16 , 8 , 0 , 
8 , 0 , 256 , 0 , 0 , 8 , 8 , 16 , 16 , 0 , 
0 , 16 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 
0 , 0 , 0 , 0 , 0 , 16 , 16 , 16 , 0 , 0 , 
0 , 0 , 0 , 8 , 8 , 8 , 8 , 0 , 0 , 0 , 
0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 16 , 16 , 
16 , 256 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 8 , 
8 , 0 , 0 , 0 , 256 , 0 , 0 , 0 , 0 , 256 , 
0 , 0 , 0 , 0 , 256 , 199 , 0 , 0 , 256 , 0 , 
0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 256 , 
0 , 256 , 0 , 256 , 0 , 256 , 0 , 0 , 0 , 16 , 
256 , 16 , 256 , 256 , 0 , 0 , 0 , 16 , 0 , 0 , 
0 , 16 , 256 , 0 , 0 , 0 , 256 , 0 , 0 , 0 , 
level = levels [ code ] ; 
org . slf4j . Logger logServerStartup = org . slf4j . LoggerFactory . getLogger ( "serverStartup" ) ; 
initialize ( ) ; 
handleRequest ( HttpServletRequest req , HttpServletResponse res ) 
if ( ! this . initialized ) initialize ( ) ; 
DapRequest daprequest = getRequestState ( req , res ) ; 
String url = daprequest . getOriginalURL ( ) ; 
StringBuilder info = new StringBuilder ( "doGet():" ) ; 
info . append ( url ) ; 
DapContext dapcxt = new DapContext ( ) ; 
dapcxt . put ( HttpServletRequest . class , req ) ; 
dapcxt . put ( HttpServletResponse . class , res ) ; 
dapcxt . put ( DapRequest . class , daprequest ) ; 
ByteOrder order = daprequest . getOrder ( ) ; 
ChecksumMode checksummode = daprequest . getChecksumMode ( ) ; 
dapcxt . put ( Dap4Util . DAP4ENDIANTAG , order ) ; 
dapcxt . put ( Dap4Util . DAP4CSUMTAG , checksummode ) ; 
Map < String , String > queries = daprequest . getQueries ( ) ; 
for ( Map . Entry < String , String > entry : queries . entrySet ( ) ) { 
if ( dapcxt . get ( entry . getKey ( ) ) == null ) { 
dapcxt . put ( entry . getKey ( ) , entry . getValue ( ) ) ; 
if ( url . endsWith ( FAVICON ) ) { 
doFavicon ( FAVICON , dapcxt ) ; 
String datasetpath = DapUtil . nullify ( DapUtil . canonicalpath ( daprequest . getDataset ( ) ) ) ; 
if ( datasetpath == null ) { 
doCapabilities ( daprequest , dapcxt ) ; 
RequestMode mode = daprequest . getMode ( ) ; 
if ( mode == null ) 
switch ( mode ) { 
case DMR : 
doDMR ( daprequest , dapcxt ) ; 
case DAP : 
doData ( daprequest , dapcxt ) ; 
case DSR : 
doDSR ( daprequest , dapcxt ) ; 
int code = HttpServletResponse . SC_BAD_REQUEST ; 
if ( t instanceof DapException ) { 
DapException e = ( DapException ) t ; 
code = e . getCode ( ) ; 
if ( code <= 0 ) 
code = DapCodes . SC_BAD_REQUEST ; 
e . setCode ( code ) ; 
} else if ( t instanceof FileNotFoundException ) 
code = DapCodes . SC_NOT_FOUND ; 
else if ( t instanceof UnsupportedOperationException ) 
code = DapCodes . SC_FORBIDDEN ; 
else if ( t instanceof MalformedURLException ) 
else if ( t instanceof IOException ) 
code = DapCodes . SC_INTERNAL_SERVER_ERROR ; 
senderror ( daprequest , code , t ) ; 
doDSR ( DapRequest drq , DapContext cxt ) 
DapDSR dsrbuilder = new DapDSR ( ) ; 
String dsr = dsrbuilder . generate ( drq . getURL ( ) ) ; 
addCommonHeaders ( drq ) ; 
ByteOrder order = ( ByteOrder ) cxt . get ( Dap4Util . DAP4ENDIANTAG ) ; 
ChunkWriter cw = new ChunkWriter ( out , RequestMode . DSR , order ) ; 
cw . writeDSR ( dsr ) ; 
cw . close ( ) ; 
. setCode ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR ) ; 
doDMR ( DapRequest drq , DapContext cxt ) 
String realpath = getResourcePath ( drq , drq . getDatasetPath ( ) ) ; 
DSP dsp = DapCache . open ( realpath , cxt ) ; 
DapDataset dmr = dsp . getDMR ( ) ; 
setEndianness ( dmr , order ) ; 
CEConstraint ce = null ; 
String sce = drq . queryLookup ( DapProtocol . CONSTRAINTTAG ) ; 
ce = CEConstraint . compile ( sce , dmr ) ; 
setConstraint ( dmr , ce ) ; 
PrintWriter pw = new PrintWriter ( sw ) ; 
DMRPrinter dapprinter = new DMRPrinter ( dmr , ce , pw , drq . getFormat ( ) ) ; 
if ( cxt . get ( Dap4Util . DAP4TESTTAG ) != null ) 
dapprinter . testprint ( ) ; 
dapprinter . print ( ) ; 
pw . close ( ) ; 
String sdmr = sw . toString ( ) ; 
ChunkWriter cw = new ChunkWriter ( out , RequestMode . DMR , order ) ; 
cw . cacheDMR ( sdmr ) ; 
doData ( DapRequest drq , DapContext cxt ) 
if ( dsp == null ) 
if ( DUMPDMR ) { 
printDMR ( dmr ) ; 
System . err . println ( printDMR ( dmr ) ) ; 
if ( DEBUG || DUMPDMR ) 
ChunkWriter cw = new ChunkWriter ( out , RequestMode . DAP , order ) ; 
cw . setWriteLimit ( getBinaryWriteLimit ( ) ) ; 
cw . flush ( ) ; 
switch ( drq . getFormat ( ) ) { 
case TEXT : 
case XML : 
case HTML : 
DapSerializer writer = new DapSerializer ( dsp , ce , cw , order , drq . getChecksumMode ( ) ) ; 
writer . write ( dsp . getDMR ( ) ) ; 
byte [ ] data = cw . getDump ( ) ; 
if ( data != null ) 
DapDump . dumpbytestream ( data , cw . getWriteOrder ( ) , "ChunkWriter.write" ) ; 
addCommonHeaders ( DapRequest drq ) 
ResponseFormat format = drq . getFormat ( ) ; 
if ( format == null ) 
format = ResponseFormat . NONE ; 
DapProtocol . ContentType contentheaders = DapProtocol . contenttypes . get ( drq . getMode ( ) ) ; 
String header = contentheaders . getFormat ( format ) ; 
if ( header != null ) { 
drq . setResponseHeader ( "Content-Type" , header ) ; 
} protected DapRequest 
getRequestState ( HttpServletRequest rq , HttpServletResponse rsp ) 
return new DapRequest ( this , rq , rsp ) ; 
senderror ( DapRequest drq , int httpcode , Throwable t ) 
if ( httpcode == 0 ) httpcode = HttpServletResponse . SC_BAD_REQUEST ; 
ErrorResponse err = new ErrorResponse ( ) ; 
err . setCode ( httpcode ) ; 
PrintWriter p = new PrintWriter ( sw ) ; 
t . printStackTrace ( p ) ; 
p . close ( ) ; 
err . setMessage ( sw . toString ( ) ) ; 
err . setContext ( drq . getURL ( ) ) ; 
String errormsg = err . buildXML ( ) ; 
drq . getResponse ( ) . sendError ( httpcode , errormsg ) ; 
setEndianness ( DapDataset dmr , ByteOrder order ) 
DapAttribute a = dmr . findAttribute ( DapUtil . LITTLEENDIANATTRNAME ) ; 
a = new DapAttribute ( DapUtil . LITTLEENDIANATTRNAME , DapType . UINT8 ) ; 
dmr . addAttribute ( a ) ; 
String oz = ( order == ByteOrder . BIG_ENDIAN ? "0" : "1" ) ; 
a . setValues ( new String [ ] { oz } ) ; 
setConstraint ( DapDataset dmr , CEConstraint ce ) 
if ( ce == null ) return ; 
if ( ce . isUniversal ( ) ) return ; 
DapAttribute a = dmr . findAttribute ( DapUtil . CEATTRNAME ) ; 
a = new DapAttribute ( DapUtil . CEATTRNAME , DapType . STRING ) ; 
String sce = ce . toConstraintString ( ) ; 
a . setValues ( new String [ ] { sce } ) ; 
} public boolean anchor ( Point p ) { 
firstStretch = true ; 
anchorPt . x = p . x ; 
anchorPt . y = p . y ; 
stretchedPt . x = lastPt . x = anchorPt . x ; 
stretchedPt . y = lastPt . y = anchorPt . y ; 
} public void stretch ( Point p ) { 
lastPt . x = stretchedPt . x ; 
lastPt . y = stretchedPt . y ; 
stretchedPt . x = p . x ; 
stretchedPt . y = p . y ; 
Graphics2D g = ( Graphics2D ) component . getGraphics ( ) ; 
if ( g != null ) { 
g . setXORMode ( component . getBackground ( ) ) ; 
if ( firstStretch == true ) 
firstStretch = false ; 
drawLast ( g ) ; 
drawNext ( g ) ; 
} public void end ( Point p ) { 
lastPt . x = endPt . x = p . x ; 
lastPt . y = endPt . y = p . y ; 
} public void done ( ) { 
} public Rectangle getBounds ( ) { 
return new Rectangle ( stretchedPt . x < anchorPt . x ? 
stretchedPt . x : anchorPt . x , 
stretchedPt . y < anchorPt . y ? 
stretchedPt . y : anchorPt . y , 
Math . abs ( stretchedPt . x - anchorPt . x ) , 
Math . abs ( stretchedPt . y - anchorPt . y ) ) ; 
} public Rectangle lastBounds ( ) { 
return new Rectangle ( 
lastPt . x < anchorPt . x ? lastPt . x : anchorPt . x , 
lastPt . y < anchorPt . y ? lastPt . y : anchorPt . y , 
Math . abs ( lastPt . x - anchorPt . x ) , 
Math . abs ( lastPt . y - anchorPt . y ) ) ; 
public Date getISODate ( String text ) { 
Date result ; 
result = stdDateTimeFormat ( text ) ; 
result = isoDateTimeFormat ( text ) ; 
result = isoDateNoSecsFormat ( text ) ; 
result = stdDateNoSecsFormat ( text ) ; 
result = dateOnlyFormat ( text ) ; 
} private Date stdDateTimeFormat ( String text ) throws java . text . ParseException { 
text = ( text == null ) ? "" : text . trim ( ) ; 
stdDateTimeFormat ( ) ; 
return stdDateTimeFormat . parse ( text ) ; 
} private Date stdDateNoSecsFormat ( String text ) throws java . text . ParseException { 
stdDateNoSecsFormat ( ) ; 
return stdDateNoSecsFormat . parse ( text ) ; 
} private Date isoDateTimeFormat ( String text ) throws java . text . ParseException { 
isoDateTimeFormat ( ) ; 
return isoDateTimeFormat . parse ( text ) ; 
} private Date isoDateNoSecsFormat ( String text ) throws java . text . ParseException { 
isoDateNoSecsFormat ( ) ; 
return isoDateNoSecsFormat . parse ( text ) ; 
} private Date dateOnlyFormat ( String text ) throws java . text . ParseException { 
dateOnlyFormat ( ) ; 
return dateOnlyFormat . parse ( text ) ; 
} public String toDateTimeString ( Date date ) { 
if ( date == null ) return "Unknown" ; 
return stdDateTimeFormat . format ( date ) + "Z" ; 
} protected void replaceDataVars ( StructureMembers sm ) { 
VariableSimpleIF org = this . cols . get ( m . getName ( ) ) ; 
int rank = org . getRank ( ) ; 
List < Dimension > orgDims = org . getDimensions ( ) ; 
int n = m . getShape ( ) . length ; 
List < Dimension > dims = orgDims . subList ( rank - n , rank ) ; 
VariableSimpleImpl result = new VariableSimpleImpl ( org . getShortName ( ) , org . getDescription ( ) , org . getUnitsString ( ) , org . getDataType ( ) , dims ) ; 
for ( Attribute att : org . getAttributes ( ) ) result . add ( att ) ; 
this . cols . put ( m . getName ( ) , result ) ; 
} public static void ensureArraySizeOkay ( long tSize , String attributeTo ) { 
if ( tSize >= Integer . MAX_VALUE ) 
MessageFormat . format ( memoryArraySize , "" + tSize , "" + Integer . MAX_VALUE ) + 
} public static int roundToInt ( double d ) { 
return d > Integer . MAX_VALUE || d <= Integer . MIN_VALUE - 0.5 || ! isFinite ( d ) ? 
Integer . MAX_VALUE : 
( int ) Math . round ( d ) ; 
String tablePath = config . getPath ( ) ; 
ClassLoader cl = KmaLocalTables . class . getClassLoader ( ) ; 
try ( InputStream is = cl . getResourceAsStream ( tablePath ) ) { 
List < TableParser . Record > recs = TableParser . readTable ( is , "41,112,124i,136i,148i,160" , 1000 ) ; 
String name = ( String ) record . get ( 0 ) ; 
int disc = ( Integer ) record . get ( 2 ) ; 
int cat = ( Integer ) record . get ( 3 ) ; 
int param = ( Integer ) record . get ( 4 ) ; 
String unit = ( String ) record . get ( 5 ) ; 
Grib2Parameter s = new Grib2Parameter ( disc , cat , param , name , unit , null , null ) ; 
local . put ( makeParamId ( disc , cat , param ) , s ) ; 
} public static int int2 ( RandomAccessFile raf ) throws IOException { 
int a = raf . read ( ) ; 
int b = raf . read ( ) ; 
return int2 ( a , b ) ; 
} public static int uint ( RandomAccessFile raf ) throws IOException { 
return ( int ) DataType . unsignedByteToShort ( ( byte ) a ) ; 
} public static int int3 ( RandomAccessFile raf ) throws IOException { 
int c = raf . read ( ) ; 
return int3 ( a , b , c ) ; 
} public static int uint2 ( RandomAccessFile raf ) throws IOException { 
return uint2 ( a , b ) ; 
} public static int uint3 ( RandomAccessFile raf ) throws IOException { 
return uint3 ( a , b , c ) ; 
} public static float float4 ( RandomAccessFile raf ) throws IOException { 
int d = raf . read ( ) ; 
return float4 ( a , b , c , d ) ; 
} public static float float4 ( int a , int b , int c , int d ) { 
int sgn , mant , exp ; 
mant = b << 16 | c << 8 | d ; 
if ( mant == 0 ) { 
return 0.0f ; 
sgn = - ( ( ( a & 128 ) > > 6 ) - 1 ) ; 
exp = ( a & 127 ) - 64 ; 
return ( float ) ( sgn * Math . pow ( 16.0 , exp - 6 ) * mant ) ; 
} public static long int8 ( RandomAccessFile raf ) throws IOException { 
int e = raf . read ( ) ; 
int f = raf . read ( ) ; 
int g = raf . read ( ) ; 
int h = raf . read ( ) ; 
return ( 1 - ( ( a & 128 ) > > 6 ) ) 
* ( ( long ) ( a & 127 ) << 56 | ( long ) b << 48 | ( long ) c << 40 | ( long ) d << 32 | e << 24 
| f << 16 | g << 8 | h ) ; 
} public static int countBits ( byte [ ] bitmap ) { 
int bits = 0 ; 
for ( byte b : bitmap ) { 
short s = DataType . unsignedByteToShort ( b ) ; 
bits += Long . bitCount ( s ) ; 
return bits ; 
ProjectionImpl result = new LambertConformal ( getOriginLat ( ) , getOriginLon ( ) , getParallelOne ( ) , getParallelTwo ( ) , 
getFalseEasting ( ) , getFalseNorthing ( ) , earth_radius ) ; 
if ( Math . abs ( lat0 ) > PI_OVER_2 ) { 
if ( Math . abs ( par1 ) >= 90.0 ) { 
if ( Math . abs ( par2 ) >= 90.0 ) { 
if ( Math . abs ( par1 - 90.0 ) < TOLERANCE ) { 
if ( Math . abs ( par1 + 90.0 ) < TOLERANCE ) { 
if ( Math . abs ( par2 - 90.0 ) < TOLERANCE ) { 
if ( Math . abs ( par2 + 90.0 ) < TOLERANCE ) { 
double t1 = Math . tan ( Math . PI / 4 + par1r / 2 ) ; 
double t2 = Math . tan ( Math . PI / 4 + par2r / 2 ) ; 
n = Math . log ( Math . cos ( par1r ) / Math . cos ( par2r ) ) 
/ Math . log ( t2 / t1 ) ; 
double t1n = Math . pow ( t1 , n ) ; 
F = Math . cos ( par1r ) * t1n / n ; 
earthRadiusTimesF = earth_radius * F ; 
double t0n = Math . pow ( Math . tan ( Math . PI / 4 + lat0 / 2 ) , n ) ; 
rho = earthRadiusTimesF / t0n ; 
} public String toWKS ( ) { 
sbuff . append ( "PROJCS[\"" ) . append ( getName ( ) ) . append ( "\"," ) ; 
sbuff . append ( "DATUM[\"unknown\"," ) ; 
sbuff . append ( "SPHEROID[\"sphere\",6371007,0]]," ) ; 
sbuff . append ( "DATUM[\"WGS_1984\"," ) ; 
sbuff . append ( "TOWGS84[0,0,0,0,0,0,0]]," ) ; 
sbuff . append ( "PRIMEM[\"Greenwich\",0]," ) ; 
sbuff . append ( "UNIT[\"degree\",0.0174532925199433]]," ) ; 
sbuff . append ( "PROJECTION[\"Lambert_Conformal_Conic_1SP\"]," ) ; 
sbuff . append ( "PARAMETER[\"latitude_of_origin\"," ) . append ( getOriginLat ( ) ) . append ( "]," ) ; 
sbuff . append ( "PARAMETER[\"central_meridian\"," ) . append ( getOriginLon ( ) ) . append ( "]," ) ; 
sbuff . append ( "PARAMETER[\"scale_factor\",1]," ) ; 
sbuff . append ( "PARAMETER[\"false_easting\"," ) . append ( falseEasting ) . append ( "]," ) ; 
sbuff . append ( "PARAMETER[\"false_northing\"," ) . append ( falseNorthing ) . append ( "]," ) ; 
double t = Math . tan ( Math . PI / 4 + lat / 2 ) ; 
double tn = Math . pow ( t , n ) ; 
double r1 = n * F ; 
double r2 = Math . cos ( lat ) * tn ; 
return r1 / r2 ; 
double dlon = LatLonPointImpl . lonNormal ( fromLon - lon0Degrees ) ; 
double theta = n * Math . toRadians ( dlon ) ; 
double tn = Math . pow ( Math . tan ( PI_OVER_4 + fromLat / 2 ) , n ) ; 
double r = earthRadiusTimesF / tn ; 
toX = r * Math . sin ( theta ) ; 
toY = rho - r * Math . cos ( theta ) ; 
double rhop = rho ; 
rhop *= - 1.0 ; 
double yd = ( rhop - fromY ) ; 
double r = Math . sqrt ( fromX * fromX + yd * yd ) ; 
r *= - 1.0 ; 
toLon = ( Math . toDegrees ( theta / n + lon0 ) ) ; 
if ( Math . abs ( r ) < TOLERANCE ) { 
toLat = ( ( n < 0.0 ) 
? - 90.0 
: 90.0 ) ; 
double rn = Math . pow ( earth_radius * F / r , 1 / n ) ; 
toLat = Math . toDegrees ( 2.0 * Math . atan ( rn ) - Math . PI / 2 ) ; 
resultXA [ i ] = ( float ) ( toX + falseEasting ) ; 
resultYA [ i ] = ( float ) ( toY + falseNorthing ) ; 
entityEscape ( String s , String wrt ) 
if ( wrt == null ) 
wrt = ENTITYESCAPES ; 
StringBuilder escaped = new StringBuilder ( ) ; 
char c = s . charAt ( i ) ; 
int index = wrt . indexOf ( c ) ; 
escaped . append ( c ) ; 
else switch ( c ) { 
case '&' : 
escaped . append ( '&' + ENTITY_AMP + ';' ) ; 
case '<' : 
escaped . append ( '&' + ENTITY_LT + ';' ) ; 
case '>' : 
escaped . append ( '&' + ENTITY_GT + ';' ) ; 
escaped . append ( '&' + ENTITY_QUOT + ';' ) ; 
escaped . append ( '&' + ENTITY_APOS + ';' ) ; 
case '\0' : 
return escaped . toString ( ) ; 
backslashEscape ( String s , String wrt ) 
wrt = BACKSLASHESCAPE ; 
escaped . append ( '\\' ) ; 
c = 'r' ; 
c = 'n' ; 
c = 't' ; 
c = 'f' ; 
escaped . append ( 'x' ) ; 
escaped . append ( Escape . toHex ( ( int ) c ) ) ; 
} else if ( c == '\\' || wrt . indexOf ( c ) >= 0 ) 
backslashUnescape ( String s ) 
StringBuilder clear = new StringBuilder ( ) ; 
for ( int i = 0 ; i < s . length ( ) ; ) { 
char c = s . charAt ( i ++ ) ; 
c = s . charAt ( i ++ ) ; 
clear . append ( c ) ; 
return clear . toString ( ) ; 
backslashsplit ( String s , char sep ) 
List < String > path = new ArrayList < String > ( ) ; 
StringBuilder piece = new StringBuilder ( ) ; 
for ( ; i <= len - 1 ; i ++ ) { 
if ( c == '\\' && i < ( len - 1 ) ) { 
piece . append ( c ) ; 
piece . append ( s . charAt ( ++ i ) ) ; 
} else if ( c == sep ) { 
path . add ( piece . toString ( ) ) ; 
piece . setLength ( 0 ) ; 
cleanString ( String s ) 
int index = s . indexOf ( ( char ) 0 ) ; 
s = s . substring ( 0 , index ) ; 
} @ RequestMapping ( value = "/**" , method = RequestMethod . GET , params = "req=featureType" ) 
public ResponseEntity < String > handleFeatureTypeRequest ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
if ( ! allowedServices . isAllowed ( StandardService . cdmrFeatureGrid ) ) 
throw new ServiceNotAllowed ( StandardService . cdmrFeatureGrid . toString ( ) ) ; 
String datasetPath = TdsPathUtils . extractPath ( request , StandardService . cdmrFeatureGrid . getBase ( ) ) ; 
try ( CoverageCollection cc = TdsRequestedDataset . getCoverageCollection ( request , response , datasetPath ) ) { 
if ( cc == null ) return null ; 
HttpHeaders responseHeaders = new HttpHeaders ( ) ; 
responseHeaders . set ( ContentType . HEADER , ContentType . text . getContentHeader ( ) ) ; 
return new ResponseEntity < > ( cc . getCoverageType ( ) . toString ( ) , responseHeaders , HttpStatus . OK ) ; 
} public static Fmrc open ( String collection , Formatter errlog ) throws IOException { 
if ( collection . startsWith ( MFileCollectionManager . CATALOG ) ) { 
CollectionManagerCatalog manager = new CollectionManagerCatalog ( collection , collection , null , errlog ) ; 
return new Fmrc ( manager , new FeatureCollectionConfig ( ) ) ; 
} else if ( collection . endsWith ( ".ncml" ) ) { 
NcmlCollectionReader ncmlCollection = NcmlCollectionReader . open ( collection , errlog ) ; 
if ( ncmlCollection == null ) return null ; 
Fmrc fmrc = new Fmrc ( ncmlCollection . getCollectionManager ( ) , new FeatureCollectionConfig ( ) ) ; 
fmrc . setNcml ( ncmlCollection . getNcmlOuter ( ) , ncmlCollection . getNcmlInner ( ) ) ; 
return fmrc ; 
return new Fmrc ( collection , errlog ) ; 
} private FmrcInv makeFmrcInv ( Formatter debug ) throws IOException { 
Map < CalendarDate , FmrInv > fmrMap = new HashMap < > ( ) ; 
List < FmrInv > fmrList = new ArrayList < > ( ) ; 
for ( MFile f : manager . getFilesSorted ( ) ) { 
Map < String , String > filesRunDateMap = ( ( MFileCollectionManager ) manager ) . getFilesRunDateMap ( ) ; 
CalendarDate runDate ; 
if ( ! filesRunDateMap . isEmpty ( ) ) { 
runDate = CalendarDate . parseISOformat ( null , filesRunDateMap . get ( f . getPath ( ) ) ) ; 
Element element = new Element ( "netcdf" , ncNSHttps ) ; 
Element runDateAttr = ncmlWriter . makeAttributeElement ( new Attribute ( _Coordinate . ModelRunDate , runDate . toString ( ) ) ) ; 
config . innerNcml = element . addContent ( runDateAttr ) ; 
GridDatasetInv inv ; 
inv = GridDatasetInv . open ( manager , f , config . innerNcml ) ; 
runDate = inv . getRunDate ( ) ; 
FmrInv fmr = fmrMap . get ( runDate ) ; 
if ( fmr == null ) { 
fmr = new FmrInv ( runDate ) ; 
fmrMap . put ( runDate , fmr ) ; 
fmrList . add ( fmr ) ; 
fmr . addDataset ( inv , debug ) ; 
if ( debug != null ) debug . format ( "%n" ) ; 
Collections . sort ( fmrList ) ; 
for ( FmrInv fmr : fmrList ) { 
fmr . finish ( ) ; 
return new FmrcInv ( "fmrc:" + manager . getCollectionName ( ) , fmrList , config . fmrcConfig . regularize ) ; 
logger . error ( "makeFmrcInv" , t ) ; 
throw new RuntimeException ( t ) ; 
} static public String getServiceSpecial ( String path ) { 
String ss = null ; 
if ( path . startsWith ( "/dqcServlet" ) ) 
ss = "dqcServlet" ; 
else if ( path . startsWith ( "/cdmvalidator" ) ) 
ss = "cdmvalidator" ; 
return ss ; 
} public File getFile ( String path ) { 
String workPath = StringUtils . cleanPath ( path ) ; 
if ( workPath . startsWith ( "../" ) ) 
if ( new File ( workPath ) . isAbsolute ( ) ) 
File file = new File ( this . rootDirectory , workPath ) ; 
} public int elementCount ( boolean leaves ) { 
if ( ! leaves ) 
return mapVars . size ( ) + 1 ; 
count += bt . elementCount ( leaves ) ; 
count += arrayVar . elementCount ( leaves ) ; 
if ( ! ( v instanceof DArray ) ) throw new IllegalArgumentException ( 
switch ( part ) { 
case ARRAY : 
arrayVar = ( DArray ) v ; 
case MAPS : 
mapVars . addElement ( v ) ; 
throws NoSuchVariableException 
return ( arrayVar ) ; 
int i = index - 1 ; 
if ( i < mapVars . size ( ) ) 
return ( ( BaseType ) mapVars . elementAt ( i ) ) ; 
} public void checkSemantics ( boolean all ) throws BadSemanticsException { 
Util . uniqueNames ( mapVars , getEncodedName ( ) , getTypeName ( ) ) ; 
if ( arrayVar == null ) 
+ getEncodedName ( ) + "'" ) ; 
arrayVar . checkSemantics ( all ) ; 
if ( mapVars . size ( ) != arrayVar . numDimensions ( ) ) 
+ arrayVar . getEncodedName ( ) + "'" ) ; 
Enumeration emap = mapVars . elements ( ) ; 
Enumeration edims = arrayVar . getDimensions ( ) ; 
int dim = 0 ; 
while ( emap . hasMoreElements ( ) && edims . hasMoreElements ( ) ) { 
DArray thisMapArray = ( DArray ) emap . nextElement ( ) ; 
Enumeration ema = thisMapArray . getDimensions ( ) ; 
DArrayDimension thisMapDim = ( DArrayDimension ) ema . nextElement ( ) ; 
DArrayDimension thisArrayDim = ( DArrayDimension ) edims . nextElement ( ) ; 
if ( thisMapDim . getSize ( ) != thisArrayDim . getSize ( ) ) { 
getEncodedName ( ) + 
arrayVar . getEncodedName ( ) + 
thisMapArray . getEncodedName ( ) + "." ) ; 
dim ++ ; 
arrayVar . externalize ( sink ) ; 
} public int projectedComponents ( boolean constrained ) { 
int comp ; 
if ( constrained ) { 
comp = ( ( DArray ) arrayVar ) . isProject ( ) ? 1 : 0 ; 
if ( ( ( DArray ) e . nextElement ( ) ) . isProject ( ) ) 
comp ++ ; 
comp = 1 + mapVars . size ( ) ; 
} public boolean projectionYieldsGrid ( boolean constrained ) { 
if ( ! constrained ) return true ; 
boolean valid = true ; 
if ( ! ( ( SDArray ) arrayVar ) . isProject ( ) ) 
int nadims = arrayVar . numDimensions ( ) ; 
int nmaps = getVarCount ( ) - 1 ; 
if ( nadims != nmaps ) 
valid = false ; 
else for ( int d = 0 ; d < nadims ; d ++ ) { 
DArrayDimension thisDim = arrayVar . getDimension ( d ) ; 
SDArray mapArray = ( SDArray ) getVar ( d + 1 ) ; 
DArrayDimension mapDim = mapArray . getFirstDimension ( ) ; 
if ( thisDim . getSize ( ) > 0 ) { 
if ( mapArray . isProject ( ) ) { 
valid = valid && mapDim . getStart ( ) == thisDim . getStart ( ) ; 
valid = valid && mapDim . getStop ( ) == thisDim . getStop ( ) ; 
valid = valid && mapDim . getStride ( ) == thisDim . getStride ( ) ; 
valid = ! mapArray . isProject ( ) ; 
return valid ; 
DGrid g = ( DGrid ) super . cloneDAG ( map ) ; 
g . arrayVar = ( DArray ) cloneDAG ( map , arrayVar ) ; 
g . mapVars = new Vector ( ) ; 
for ( int i = 0 ; i < mapVars . size ( ) ; i ++ ) { 
BaseType bt = ( BaseType ) mapVars . elementAt ( i ) ; 
g . mapVars . addElement ( btclone ) ; 
if ( levels . size ( ) != size ) { 
double [ ] vals = new double [ size ] ; 
if ( mapping . equalsIgnoreCase ( LEVELS ) ) { 
vals [ i ] = Double . parseDouble ( levels . get ( i ) ) ; 
} else if ( mapping . equalsIgnoreCase ( LINEAR ) ) { 
double start = 0 ; 
double inc = 0 ; 
start = Double . parseDouble ( levels . get ( 0 ) ) ; 
inc = Double . parseDouble ( levels . get ( 1 ) ) ; 
vals [ i ] = start + i * inc ; 
} else if ( mapping . toLowerCase ( ) . startsWith ( "gaus" ) ) { 
vals = GradsUtil . getGaussianLatitudes ( mapping , 
( int ) Double . parseDouble ( levels . get ( 0 ) ) , size ) ; 
if ( name . equals ( GradsDataDescriptorFile . ZDEF ) ) { 
double val = vals [ i ] ; 
if ( val > 1050 ) { 
unitName = "Pa" ; 
} else if ( val < 10 ) { 
unitName = "" ; 
CEAST 
constraint ( CEAST . NodeList clauses ) 
CEAST node = new CEAST ( CEAST . Sort . CONSTRAINT ) ; 
node . clauses = clauses ; 
node . dimdefs = dimdefs ; 
this . constraint = node ; 
selection ( CEAST projection , CEAST filter ) 
CEAST node = new CEAST ( CEAST . Sort . SELECTION ) ; 
node . projection = projection ; 
node . filter = filter ; 
CEAST . NodeList 
nodelist ( CEAST . NodeList list , CEAST ast ) 
if ( list == null ) list = new CEAST . NodeList ( ) ; 
if ( ast != null ) list . add ( ast ) ; 
} public final CalendarDate getReferenceTime ( ) { 
int sec = ( second < 0 || second > 59 ) ? 0 : second ; 
return CalendarDate . of ( null , year , month , day , hour , minute , sec ) ; 
} static public ArrayStructureBB factory ( ArrayStructureBB org , Section section ) { 
if ( section == null || section . computeSize ( ) == org . getSize ( ) ) 
return new ArrayStructureBBsection ( org . getStructureMembers ( ) , org . getShape ( ) , org . getByteBuffer ( ) , section ) ; 
} public Document makeDocument ( File f ) throws java . io . FileNotFoundException { 
Document doc = new Document ( ) ; 
doc . add ( new Field ( "path" , f . getPath ( ) , Field . Store . YES , Field . Index . UN_TOKENIZED ) ) ; 
doc . add ( new Field ( "modified" , 
DateTools . timeToString ( f . lastModified ( ) , DateTools . Resolution . MINUTE ) , 
Field . Store . YES , Field . Index . UN_TOKENIZED ) ) ; 
} public static void main1 ( String [ ] args ) { 
if ( INDEX_DIR . exists ( ) ) { 
LuceneIndexer indexer = new LuceneIndexer ( ) ; 
Date start = new Date ( ) ; 
IndexWriter writer = new IndexWriter ( INDEX_DIR , new StandardAnalyzer ( ) , true ) ; 
indexer . indexDocs ( writer , DOC_DIR ) ; 
System . out . println ( "Optimizing..." ) ; 
writer . optimize ( ) ; 
Date end = new Date ( ) ; 
} private Grib1Record readRecord ( Grib1IndexProto . Grib1Record p ) { 
Grib1SectionIndicator is = new Grib1SectionIndicator ( p . getGribMessageStart ( ) , p . getGribMessageLength ( ) ) ; 
Grib1SectionProductDefinition pds = new Grib1SectionProductDefinition ( p . getPds ( ) . toByteArray ( ) ) ; 
Grib1SectionGridDefinition gds = pds . gdsExists ( ) ? gdsList . get ( p . getGdsIdx ( ) ) : new Grib1SectionGridDefinition ( pds ) ; 
Grib1SectionBitMap bms = pds . bmsExists ( ) ? new Grib1SectionBitMap ( p . getBmsPos ( ) ) : null ; 
Grib1SectionBinaryData dataSection = new Grib1SectionBinaryData ( p . getDataPos ( ) , p . getDataLen ( ) ) ; 
return new Grib1Record ( p . getHeader ( ) . toByteArray ( ) , is , gds , pds , bms , dataSection ) ; 
} public boolean makeIndex ( String filename , RandomAccessFile dataRaf ) throws IOException { 
String idxPath = filename ; 
if ( ! idxPath . endsWith ( GBX9_IDX ) ) idxPath += GBX9_IDX ; 
File idxFile = GribIndexCache . getFileOrCache ( idxPath ) ; 
File idxFileTmp = GribIndexCache . getFileOrCache ( idxPath + ".tmp" ) ; 
try ( FileOutputStream fout = new FileOutputStream ( idxFileTmp ) ) { 
fout . write ( MAGIC_START . getBytes ( CDM . utf8Charset ) ) ; 
NcStream . writeVInt ( fout , version ) ; 
Map < Long , Integer > gdsMap = new HashMap < > ( ) ; 
gdsList = new ArrayList < > ( ) ; 
records = new ArrayList < > ( 200 ) ; 
Grib1IndexProto . Grib1Index . Builder rootBuilder = Grib1IndexProto . Grib1Index . newBuilder ( ) ; 
rootBuilder . setFilename ( filename ) ; 
if ( dataRaf == null ) { 
raf = RandomAccessFile . acquire ( filename ) ; 
dataRaf = raf ; 
Grib1RecordScanner scan = new Grib1RecordScanner ( dataRaf ) ; 
Grib1Record r = scan . next ( ) ; 
if ( r == null ) break ; 
records . add ( r ) ; 
Grib1SectionGridDefinition gdss = r . getGDSsection ( ) ; 
Integer index = gdsMap . get ( gdss . calcCRC ( ) ) ; 
if ( gdss . getPredefinedGridDefinition ( ) >= 0 ) 
index = 0 ; 
else if ( index == null ) { 
gdsList . add ( gdss ) ; 
index = gdsList . size ( ) - 1 ; 
gdsMap . put ( gdss . calcCRC ( ) , index ) ; 
rootBuilder . addGdsList ( makeGdsProto ( gdss ) ) ; 
rootBuilder . addRecords ( makeRecordProto ( r , index ) ) ; 
ucar . nc2 . grib . grib1 . Grib1IndexProto . Grib1Index index = rootBuilder . build ( ) ; 
NcStream . writeVInt ( fout , b . length ) ; 
fout . write ( b ) ; 
RandomAccessFile . eject ( idxFile . getPath ( ) ) ; 
boolean deleteOk = ! idxFile . exists ( ) || idxFile . delete ( ) ; 
boolean renameOk = idxFileTmp . renameTo ( idxFile ) ; 
if ( ! deleteOk ) 
if ( ! renameOk ) 
File file ; 
for ( DescendantFileSource curLocator : chain ) { 
file = curLocator . getFile ( path ) ; 
if ( file != null ) 
return ( null != ncfile . findGlobalAttribute ( "XORIG" ) ) 
&& ( null != ncfile . findGlobalAttribute ( "YORIG" ) ) 
&& ( null != ncfile . findGlobalAttribute ( "XCELL" ) ) 
&& ( null != ncfile . findGlobalAttribute ( "YCELL" ) ) 
&& ( null != ncfile . findGlobalAttribute ( "NCOLS" ) ) 
&& ( null != ncfile . findGlobalAttribute ( "NROWS" ) ) ; 
} private CoordinateTransform makeUTMProjection ( NetcdfDataset ds ) { 
int zone = ( int ) findAttributeDouble ( ds , "P_ALP" ) ; 
double ycent = findAttributeDouble ( ds , "YCENT" ) ; 
boolean isNorth = true ; 
if ( ycent < 0 ) 
isNorth = false ; 
UtmProjection utm = new UtmProjection ( zone , isNorth ) ; 
return new ProjectionCT ( "UTM" , "EPSG" , utm ) ; 
} protected AxisType getAxisType ( NetcdfDataset ds , VariableEnhanced ve ) { 
Variable v = ( Variable ) ve ; 
String vname = v . getShortName ( ) ; 
if ( vname . equalsIgnoreCase ( "x" ) ) 
return AxisType . GeoX ; 
if ( vname . equalsIgnoreCase ( "y" ) ) 
return AxisType . GeoY ; 
if ( vname . equalsIgnoreCase ( "lat" ) ) 
if ( vname . equalsIgnoreCase ( "lon" ) ) 
if ( vname . equalsIgnoreCase ( "time" ) ) 
if ( vname . equalsIgnoreCase ( "level" ) ) 
if ( areaReader == null ) 
areaReader = new AreaReader ( ) ; 
areaReader . init ( raf . getLocation ( ) , ncfile ) ; 
return areaReader . readVariable ( v2 , section ) ; 
} public void reacquire ( ) throws IOException { 
areaReader . af = new AreaFile ( location ) ; 
} public boolean before ( Date d ) { 
if ( isPresent ( ) ) return false ; 
return date . isBefore ( CalendarDate . of ( d ) ) ; 
} public boolean before ( DateType d ) { 
if ( d . isPresent ( ) ) return true ; 
return date . isBefore ( d . getCalendarDate ( ) ) ; 
} public boolean after ( Date d ) { 
if ( isPresent ( ) ) return true ; 
return date . isAfter ( CalendarDate . of ( d ) ) ; 
} private static void doOne ( String s ) { 
DateType d = new DateType ( s , null , null ) ; 
} public ConfigCatalog getCatalog ( File baseDir , String matchRemaining , String filename , CatalogReader reader ) throws IOException { 
String relLocation = ( matchRemaining . length ( ) >= 1 ) ? location + "/" + matchRemaining : location ; 
File absLocation = new File ( baseDir , relLocation ) ; 
ConfigCatalog cc = reader . getFromAbsolutePath ( absLocation + "/" + filename ) ; 
if ( cc == null ) 
return cc ; 
} public CatalogBuilder makeCatalogFromDirectory ( File baseDir , String matchRemaining , URI baseURI ) throws IOException { 
String name = ( matchRemaining . length ( ) >= 1 ) ? getName ( ) + "/" + matchRemaining : getName ( ) ; 
Path wantDir = absLocation . toPath ( ) ; 
CatalogBuilder catBuilder = new CatalogBuilder ( ) ; 
catBuilder . setBaseURI ( baseURI ) ; 
assert this . getParentCatalog ( ) != null ; 
top . transferMetadata ( this , true ) ; 
top . put ( Dataset . Id , null ) ; 
catBuilder . addDataset ( top ) ; 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( wantDir , "*.xml" ) ) { 
for ( Path p : ds ) { 
if ( ! Files . isDirectory ( p ) ) { 
String pfilename = p . getFileName ( ) . toString ( ) ; 
String urlPath = pfilename ; 
CatalogRefBuilder catref = new CatalogRefBuilder ( top ) ; 
catref . setTitle ( urlPath ) ; 
catref . setHref ( urlPath ) ; 
top . addDataset ( catref ) ; 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( wantDir ) ) { 
for ( Path dir : ds ) { 
if ( Files . isDirectory ( dir ) ) { 
String dfilename = dir . getFileName ( ) . toString ( ) ; 
String urlPath = ( matchRemaining . length ( ) >= 1 ) ? dfilename + "/" + matchRemaining : dfilename ; 
catref . setHref ( urlPath + "/" + CATSCAN ) ; 
catref . addToList ( Dataset . Properties , new Property ( "CatalogScan" , "true" ) ) ; 
return catBuilder ; 
} public static CollectionType findType ( String name ) { 
for ( CollectionType m : members ) { 
} public static CollectionType getType ( String name ) { 
CollectionType type = findType ( name ) ; 
return type != null ? type : new CollectionType ( name , false ) ; 
} public final void setValue ( int i , BaseType newVal ) { 
vals [ i ] = newVal ; 
BaseType parent = ( BaseType ) getTemplate ( ) . getParent ( ) ; 
vals [ i ] . setParent ( parent ) ; 
vals [ i ] = ( BaseType ) getTemplate ( ) . clone ( ) ; 
( ( ClientIO ) vals [ i ] ) . deserialize ( source , sv , statusUI ) ; 
( ( ClientIO ) vals [ i ] ) . externalize ( sink ) ; 
} public void addCoordinateSystem ( CoordinateSystem cs ) { 
if ( cs == null ) 
if ( coordSys == null ) coordSys = new ArrayList < > ( 5 ) ; 
coordSys . add ( cs ) ; 
} public String getDescription ( ) { 
if ( ( desc == null ) && ( forVar != null ) ) { 
Attribute att = forVar . findAttributeIgnoreCase ( CDM . LONG_NAME ) ; 
if ( ( att != null ) && att . isString ( ) ) 
desc = att . getStringValue ( ) ; 
if ( desc == null ) { 
att = forVar . findAttributeIgnoreCase ( "description" ) ; 
att = forVar . findAttributeIgnoreCase ( CDM . TITLE ) ; 
att = forVar . findAttributeIgnoreCase ( CF . STANDARD_NAME ) ; 
return ( desc == null ) ? null : desc . trim ( ) ; 
} public void setUnitsString ( String units ) { 
this . units = units ; 
forVar . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; 
String result = units ; 
if ( ( result == null ) && ( forVar != null ) ) { 
Attribute att = forVar . findAttribute ( CDM . UNITS ) ; 
if ( att == null ) att = forVar . findAttributeIgnoreCase ( CDM . UNITS ) ; 
result = att . getStringValue ( ) ; 
return ( result == null ) ? null : result . trim ( ) ; 
} public synchronized void init ( ReadMode readMode , PreferencesExt prefs ) { 
if ( readMode == null ) 
readMode = defaultReadMode ; 
this . prefs = prefs ; 
trackerNumber = prefs . getLong ( "trackerNumber" , 1 ) ; 
numberCatalogs = prefs . getInt ( "numberCatalogs" , 10 ) ; 
nextCatId = prefs . getLong ( "nextCatId" , 1 ) ; 
makeDebugActions ( ) ; 
this . contentRootPath = this . tdsContext . getThreddsDirectory ( ) ; 
this . contextPath = tdsContext . getContextPath ( ) ; 
reread ( readMode , true ) ; 
} public synchronized boolean reread ( ReadMode readMode , boolean isStartup ) { 
readNow = System . currentTimeMillis ( ) ; 
logCatalogInit . info ( "=========================================================================================\n" + 
catPathMap = new HashSet < > ( ) ; 
fcNameMap = new HashMap < > ( ) ; 
if ( ccc != null ) ccc . invalidateAll ( ) ; 
if ( fcCache != null ) fcCache . invalidateAll ( ) ; 
if ( ! isStartup && readMode == ReadMode . always ) trackerNumber ++ ; 
if ( ! isDebugMode || this . datasetTracker == null ) 
this . datasetTracker = new DatasetTrackerChronicle ( trackerDir , maxDatasets , trackerNumber ) ; 
boolean databaseAlreadyExists = datasetTracker . exists ( ) ; 
if ( ! databaseAlreadyExists ) { 
readMode = ReadMode . always ; 
if ( this . callback == null ) 
this . callback = new StatCallback ( readMode ) ; 
allowedServices . clearGlobalServices ( ) ; 
switch ( readMode ) { 
if ( databaseAlreadyExists ) { 
this . datasetTracker . close ( ) ; 
this . datasetTracker . reinit ( ) ; 
this . catalogTracker = new CatalogTracker ( trackerDir , true , numberCatalogs , nextCatId ) ; 
this . dataRootTracker = new DataRootTracker ( trackerDir , true , callback ) ; 
this . dataRootPathMatcher = new DataRootPathMatcher ( ccc , dataRootTracker ) ; 
readRootCatalogs ( readMode ) ; 
case check : 
this . catalogTracker = new CatalogTracker ( trackerDir , false , numberCatalogs , nextCatId ) ; 
this . dataRootTracker = new DataRootTracker ( trackerDir , false , callback ) ; 
checkExistingCatalogs ( readMode ) ; 
case triggerOnly : 
numberCatalogs = catalogTracker . size ( ) ; 
nextCatId = catalogTracker . getNextCatId ( ) ; 
if ( prefs != null ) { 
prefs . putLong ( "trackerNumber" , trackerNumber ) ; 
prefs . putLong ( "nextCatId" , nextCatId ) ; 
prefs . putInt ( "numberCatalogs" , numberCatalogs ) ; 
callback . finish ( ) ; 
datasetTracker . save ( ) ; 
catalogTracker . save ( ) ; 
dataRootTracker . save ( ) ; 
if ( dataRootManager != null ) 
dataRootManager . setDataRootPathMatcher ( dataRootPathMatcher ) ; 
if ( datasetManager != null ) 
datasetManager . setDatasetTracker ( datasetTracker ) ; 
if ( ! isStartup && readMode == ReadMode . always ) { 
DatasetTrackerChronicle . cleanupBefore ( trackerDir , trackerNumber ) ; 
long took = System . currentTimeMillis ( ) - readNow ; 
catPathMap = null ; 
fcNameMap = null ; 
catalogTracker = null ; 
} private void checkCatalogToRead ( ReadMode readMode , String catalogRelPath , boolean isRoot , long lastRead ) throws IOException { 
if ( exceedLimit ) return ; 
catalogRelPath = StringUtils . cleanPath ( catalogRelPath ) ; 
File catalogFile = new File ( this . contentRootPath , catalogRelPath ) ; 
if ( ! catalogFile . exists ( ) ) { 
catalogTracker . removeCatalog ( catalogRelPath ) ; 
long lastModified = catalogFile . lastModified ( ) ; 
if ( ! isRoot && readMode != ReadMode . always && lastModified < lastRead ) return ; 
if ( ! isRoot && readMode == ReadMode . triggerOnly ) return ; 
if ( catPathMap . contains ( catalogRelPath ) ) { 
catPathMap . add ( catalogRelPath ) ; 
Set < String > idSet = new HashSet < > ( ) ; 
ConfigCatalog cat = readCatalog ( catalogRelPath , catalogFile . getPath ( ) ) ; 
if ( cat == null ) { 
long catId = catalogTracker . put ( new CatalogExt ( 0 , catalogRelPath , isRoot , readNow ) ) ; 
if ( isRoot ) { 
if ( ccc != null ) ccc . put ( catalogRelPath , cat ) ; 
allowedServices . addGlobalServices ( cat . getServices ( ) ) ; 
if ( readMode == ReadMode . triggerOnly ) return ; 
if ( callback != null ) callback . hasCatalogRef ( cat ) ; 
for ( DatasetRootConfig p : cat . getDatasetRoots ( ) ) 
dataRootPathMatcher . addRoot ( p , catalogRelPath , readMode == ReadMode . always ) ; 
if ( callback == null ) { 
List < String > disallowedServices = allowedServices . getDisallowedServices ( cat . getServices ( ) ) ; 
if ( ! disallowedServices . isEmpty ( ) ) { 
allowedServices . getDisallowedServices ( cat . getServices ( ) ) ; 
dataRootPathMatcher . extractDataRoots ( catalogRelPath , cat . getDatasetsLocal ( ) , readMode == ReadMode . always , fcNameMap ) ; 
int pos = catalogRelPath . lastIndexOf ( "/" ) ; 
String dirPath = ( pos > 0 ) ? catalogRelPath . substring ( 0 , pos + 1 ) : "" ; 
processDatasets ( catId , readMode , dirPath , cat . getDatasetsLocal ( ) , idSet ) ; 
for ( CatalogScan catScan : cat . getCatalogScans ( ) ) { 
Path relLocation = Paths . get ( dirPath , catScan . getLocation ( ) ) ; 
Path absLocation = Paths . get ( catalogFile . getParent ( ) , catScan . getLocation ( ) ) ; 
readCatsInDirectory ( readMode , relLocation . toString ( ) , absLocation ) ; 
} private ConfigCatalog readCatalog ( String catalogRelPath , String catalogFullPath ) { 
uri = new URI ( this . contextPath + "/catalog/" + catalogRelPath ) ; 
ConfigCatalogBuilder builder = new ConfigCatalogBuilder ( ) ; 
ConfigCatalog cat = ( ConfigCatalog ) builder . buildFromLocation ( catalogFullPath , uri ) ; 
if ( builder . hasFatalError ( ) ) { 
if ( builder . getErrorMessage ( ) . length ( ) > 0 ) 
logCatalogInit . debug ( builder . getErrorMessage ( ) ) ; 
} private void processDatasets ( long catId , ReadMode readMode , String dirPath , List < Dataset > datasets , Set < String > idMap ) throws IOException { 
for ( Dataset ds : datasets ) { 
if ( datasetTracker . trackDataset ( catId , ds , callback ) ) countDatasets ++ ; 
if ( maxDatasetsProcess > 0 && countDatasets > maxDatasetsProcess ) exceedLimit = true ; 
String id = ds . getID ( ) ; 
if ( idMap . contains ( id ) ) { 
idMap . add ( id ) ; 
if ( ( ds instanceof DatasetScan ) || ( ds instanceof FeatureCollectionRef ) ) continue ; 
if ( ds instanceof CatalogScan ) continue ; 
if ( ds instanceof CatalogRef ) { 
CatalogRef catref = ( CatalogRef ) ds ; 
String href = catref . getXlinkHref ( ) ; 
if ( ! href . startsWith ( "http:" ) ) { 
if ( href . startsWith ( "./" ) ) { 
href = href . substring ( 2 ) ; 
String path ; 
String contextPathPlus = this . contextPath + "/" ; 
if ( href . startsWith ( contextPathPlus ) ) { 
path = href . substring ( contextPathPlus . length ( ) ) ; 
} else if ( href . startsWith ( "/" ) ) { 
path = dirPath + href ; 
CatalogExt ext = catalogTracker . get ( path ) ; 
long lastRead = ( ext == null ) ? 0 : ext . getLastRead ( ) ; 
checkCatalogToRead ( readMode , path , false , lastRead ) ; 
processDatasets ( catId , readMode , dirPath , ds . getDatasetsLocal ( ) , idMap ) ; 
} private void readCatsInDirectory ( ReadMode readMode , String dirPath , Path directory ) throws IOException { 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( directory , "*.xml" ) ) { 
String filename = p . getFileName ( ) . toString ( ) ; 
String path = dirPath . length ( ) == 0 ? filename : dirPath + "/" + filename ; 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( directory ) ) { 
String dirPathChild = dirPath + "/" + dir . getFileName ( ) . toString ( ) ; 
readCatsInDirectory ( readMode , dirPathChild , dir ) ; 
} public void makeDebugActions ( ) { 
DebugCommands . Category debugHandler = debugCommands . findCategory ( "Catalogs" ) ; 
DebugCommands . Action act ; 
public void doAction ( DebugCommands . Event e ) { 
CatalogTracker catalogTracker = new CatalogTracker ( trackerDir , false , numberCatalogs , 0 ) ; 
for ( CatalogExt cat : catalogTracker . getCatalogs ( ) ) { 
debugHandler . addAction ( act ) ; 
synchronized ( ConfigCatalogInitialization . this ) { 
for ( String catPath : rootCatalogKeys ) { 
e . pw . println ( ) ; 
e . pw . println ( Escape . html ( sbuff . toString ( ) ) ) ; 
if ( callback != null ) 
e . pw . printf ( "%n%s%n" , Escape . html ( callback . toString ( ) ) ) ; 
e . pw . printf ( "N/A%n" ) ; 
} static public boolean betweenLon ( double lon , double lonBeg , double lonEnd ) { 
lonBeg = lonNormal ( lonBeg , lon ) ; 
lonEnd = lonNormal ( lonEnd , lon ) ; 
return ( lon >= lonBeg ) && ( lon <= lonEnd ) ; 
} static public double lonNormalFrom ( double lon , double start ) { 
while ( lon < start ) lon += 360 ; 
while ( lon > start + 360 ) lon -= 360 ; 
return lon ; 
} static public String latToString ( double lat , int ndec ) { 
boolean is_north = ( lat >= 0.0 ) ; 
if ( ! is_north ) 
lat = - lat ; 
String f = "%." + ndec + "f" ; 
Formatter latBuff = new Formatter ( ) ; 
latBuff . format ( f , lat ) ; 
latBuff . format ( "%s" , is_north ? "N" : "S" ) ; 
return latBuff . toString ( ) ; 
} static public String lonToString ( double lon , int ndec ) { 
double wlon = lonNormal ( lon ) ; 
boolean is_east = ( wlon >= 0.0 ) ; 
if ( ! is_east ) 
wlon = - wlon ; 
latBuff . format ( f , wlon ) ; 
latBuff . format ( "%s" , is_east ? "E" : "W" ) ; 
} public int compareTo ( final BaseQuantity that ) { 
if ( this == that ) { 
comp = 0 ; 
comp = getName ( ) . compareToIgnoreCase ( that . getName ( ) ) ; 
if ( comp == 0 && getSymbol ( ) != null ) { 
comp = getSymbol ( ) . compareTo ( that . getSymbol ( ) ) ; 
} public static void main ( final String [ ] args ) { 
+ AMOUNT_OF_SUBSTANCE . getName ( ) ) ; 
+ LUMINOUS_INTENSITY . getSymbol ( ) ) ; 
+ PLANE_ANGLE . getSymbol ( ) ) ; 
+ LENGTH . equals ( PLANE_ANGLE ) ) ; 
+ PLANE_ANGLE . equals ( PLANE_ANGLE ) ) ; 
+ PLANE_ANGLE . equals ( SOLID_ANGLE ) ) ; 
+ LENGTH . compareTo ( LENGTH ) ) ; 
+ LENGTH . compareTo ( PLANE_ANGLE ) ) ; 
+ PLANE_ANGLE . compareTo ( PLANE_ANGLE ) ) ; 
+ PLANE_ANGLE . compareTo ( SOLID_ANGLE ) ) ; 
} public DatasetNode getSelectedDataset ( ) { 
InvCatalogTreeNode tnode = getSelectedNode ( ) ; 
return tnode == null ? null : tnode . ds ; 
} public void setSelectedDataset ( Dataset ds ) { 
if ( ds == null ) return ; 
TreePath path = makePath ( ds ) ; 
if ( path == null ) return ; 
tree . setSelectionPath ( path ) ; 
tree . scrollPathToVisible ( path ) ; 
} TreePath makeTreePath ( TreeNode node ) { 
ArrayList < TreeNode > path = new ArrayList < > ( ) ; 
path . add ( node ) ; 
TreeNode parent = node . getParent ( ) ; 
while ( parent != null ) { 
path . add ( 0 , parent ) ; 
parent = parent . getParent ( ) ; 
Object [ ] paths = path . toArray ( ) ; 
return new TreePath ( paths ) ; 
} public void openAll ( boolean includeCatref ) { 
if ( catalog == null ) return ; 
open ( ( InvCatalogTreeNode ) model . getRoot ( ) , includeCatref ) ; 
tree . repaint ( ) ; 
} public void setCatalog ( String location ) { 
CatalogBuilder builder = new CatalogBuilder ( ) ; 
Catalog cat = builder . buildFromLocation ( location , null ) ; 
setCatalog ( cat ) ; 
} public void setCatalog ( Catalog catalog ) { 
String catalogName = catalog . getBaseURI ( ) . toString ( ) ; 
this . catalog = catalog ; 
setCatalogURL ( catalogName ) ; 
model = new InvCatalogTreeModel ( catalog ) ; 
tree . setModel ( model ) ; 
if ( debugTree ) { 
showNode ( tree . getModel ( ) , tree . getModel ( ) . getRoot ( ) ) ; 
int pos = catalogName . indexOf ( '#' ) ; 
String id = catalogName . substring ( pos + 1 ) ; 
Dataset dataset = catalog . findDatasetByID ( id ) ; 
if ( dataset != null ) { 
setSelectedDataset ( dataset ) ; 
firePropertyChangeEvent ( new PropertyChangeEvent ( this , "Selection" , null , dataset ) ) ; 
firePropertyChangeEvent ( new PropertyChangeEvent ( this , "Catalog" , null , catalogName ) ) ; 
} private void showNode ( TreeModel tree , Object node ) { 
if ( node == null ) return ; 
InvCatalogTreeNode tnode = ( InvCatalogTreeNode ) node ; 
DatasetNode cp = tnode . ds ; 
for ( int i = 0 ; i < tree . getChildCount ( node ) ; i ++ ) 
showNode ( tree , tree . getChild ( node , i ) ) ; 
} public void showInfo ( Formatter f , Grib1Customizer cust1 ) { 
GribRecordStats all = new GribRecordStats ( ) ; 
for ( VariableBag vb : gribvars ) { 
vb . coordND . showInfo ( f , all ) ; 
f . format ( "%n" ) ; 
protected void findCoordinateAxes ( NetcdfDataset ds ) { 
if ( vp . isCoordinateVariable ) continue ; 
Variable ncvar = vp . v ; 
if ( ! ( ncvar instanceof VariableDS ) ) continue ; 
String dimName = findAlias ( ds , ncvar ) ; 
if ( dimName . length ( ) == 0 ) 
Dimension dim = ds . findDimension ( dimName ) ; 
if ( null != dim ) { 
vp . isCoordinateAxis = true ; 
super . findCoordinateAxes ( ds ) ; 
findCoordinateAxesForce ( ds ) ; 
} private String findAlias ( NetcdfDataset ds , Variable v ) { 
String alias = ds . findAttValueIgnoreCase ( v , "coord_axis" , null ) ; 
if ( alias == null ) 
alias = ds . findAttValueIgnoreCase ( v , "coord_alias" , "" ) ; 
return alias ; 
} public final void writeInt ( int v ) throws IOException { 
write ( int3 ( v ) ) ; 
write ( int2 ( v ) ) ; 
write ( int1 ( v ) ) ; 
write ( int0 ( v ) ) ; 
} public int writeVInt ( int i ) throws IOException { 
while ( ( i & ~ 0x7F ) != 0 ) { 
writeByte ( ( byte ) ( ( i & 0x7f ) | 0x80 ) ) ; 
i >>>= 7 ; 
writeByte ( ( byte ) i ) ; 
return count + 1 ; 
} public int writeVLong ( long i ) throws IOException { 
} public int writeString ( String s ) throws IOException { 
int length = s . length ( ) ; 
int count = writeVInt ( length ) ; 
count += writeChars ( s , 0 , length ) ; 
} public int writeChars ( String s , int start , int length ) throws IOException { 
final int end = start + length ; 
for ( int i = start ; i < end ; i ++ ) { 
final int code = ( int ) s . charAt ( i ) ; 
if ( code >= 0x01 && code <= 0x7F ) { 
writeByte ( ( byte ) code ) ; 
} else if ( ( ( code >= 0x80 ) && ( code <= 0x7FF ) ) || code == 0 ) { 
writeByte ( ( byte ) ( 0xC0 | ( code > > 6 ) ) ) ; 
writeByte ( ( byte ) ( 0x80 | ( code & 0x3F ) ) ) ; 
count += 2 ; 
writeByte ( ( byte ) ( 0xE0 | ( code > > > 12 ) ) ) ; 
writeByte ( ( byte ) ( 0x80 | ( ( code > > 6 ) & 0x3F ) ) ) ; 
count += 3 ; 
} public String readString ( ) throws IOException { 
int length = readVInt ( ) ; 
char [ ] chars = new char [ length ] ; 
readChars ( chars , 0 , length ) ; 
return new String ( chars , 0 , length ) ; 
} public void readChars ( char [ ] buffer , int start , int length ) throws IOException { 
byte b = readByte ( ) ; 
if ( ( b & 0x80 ) == 0 ) 
buffer [ i ] = ( char ) ( b & 0x7F ) ; 
else if ( ( b & 0xE0 ) != 0xE0 ) { 
buffer [ i ] = ( char ) ( ( ( b & 0x1F ) << 6 ) 
| ( readByte ( ) & 0x3F ) ) ; 
buffer [ i ] = ( char ) ( ( ( b & 0x0F ) << 12 ) 
| ( ( readByte ( ) & 0x3F ) << 6 ) 
} public void readData ( RandomAccessFile raf , Range gateRange , IndexIterator ii ) throws IOException { 
final int REC_SIZE = 6144 ; 
byte [ ] data = new byte [ bins ] ; 
float [ ] dd = new float [ bins ] ; 
byte d ; 
int nb = 0 ; 
short a00 ; 
if ( dataRead > 0 ) { 
for ( int i = 0 ; i < dataRead ; i ++ ) { 
d = raf . readByte ( ) ; 
dd [ i ] = SigmetIOServiceProvider . calcData ( SigmetIOServiceProvider . recHdr , getDataType ( ) , d ) ; 
nb ++ ; 
raf . seek ( offset1 ) ; 
int cur_len = offset1 ; 
while ( nb < ( int ) bins ) { 
a00 = raf . readShort ( ) ; 
cur_len = cur_len + 2 ; 
if ( a00 == ( short ) 1 ) { 
for ( int uk = 0 ; uk < ( int ) bins ; uk ++ ) { 
dd [ uk ] = - 999.99f ; 
if ( a00 < 0 ) { 
int nwords = a00 & 0x7fff ; 
int dataRead1 = nwords * 2 ; 
if ( cur_len % REC_SIZE == 0 ) { 
raf . seek ( cur_len ) ; 
for ( int i = 0 ; i < dataRead1 ; i ++ ) { 
dd [ nb ] = SigmetIOServiceProvider . calcData ( SigmetIOServiceProvider . recHdr , getDataType ( ) , d ) ; 
nb = nb + 1 ; 
cur_len = cur_len + 1 ; 
if ( nb % REC_SIZE == 0 ) { 
pos = i + 1 ; 
} else if ( a00 > 0 & a00 != 1 ) { 
int num_zero = a00 * 2 ; 
int dataRead1 = num_zero ; 
for ( int k = 0 ; k < dataRead1 ; k ++ ) { 
dd [ nb + k ] = SigmetIOServiceProvider . calcData ( SigmetIOServiceProvider . recHdr , getDataType ( ) , ( byte ) 0 ) ; 
nb = nb + dataRead1 ; 
if ( gateIdx >= bins ) 
ii . setFloatNext ( Float . NaN ) ; 
ii . setFloatNext ( dd [ gateIdx ] ) ; 
} public static void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) { 
debugRead = debugFlag . isSet ( "Grib/showRead" ) ; 
debugIndexOnly = debugFlag . isSet ( "Grib/indexOnly" ) ; 
debugIndexOnlyShow = debugFlag . isSet ( "Grib/indexOnlyShow" ) ; 
debugGbxIndexOnly = debugFlag . isSet ( "Grib/debugGbxIndexOnly" ) ; 
} public TableConfig getConfig ( FeatureType wantFeatureType , NetcdfDataset ds , Formatter errlog ) { 
Dimension obsDim = ds . getUnlimitedDimension ( ) ; 
if ( obsDim == null ) { 
CoordinateAxis axis = CoordSysEvaluator . findCoordByType ( ds , AxisType . Time ) ; 
if ( ( axis != null ) && axis . isScalar ( ) ) 
obsDim = axis . getDimension ( 0 ) ; 
boolean hasStruct = Evaluator . hasNetcdf3RecordStructure ( ds ) ; 
if ( ( wantFeatureType == FeatureType . POINT ) ) { 
TableConfig nt = new TableConfig ( Table . Type . Structure , hasStruct ? "record" : obsDim . getShortName ( ) ) ; 
nt . structName = "record" ; 
nt . structureType = hasStruct ? TableConfig . StructureType . Structure : TableConfig . StructureType . PsuedoStructure ; 
nt . featureType = FeatureType . POINT ; 
CoordSysEvaluator . findCoords ( nt , ds , null ) ; 
return nt ; 
TableConfig nt = new TableConfig ( Table . Type . Top , "station" ) ; 
nt . featureType = FeatureType . STATION ; 
nt . lat = CoordSysEvaluator . findCoordNameByType ( ds , AxisType . Lat ) ; 
nt . lon = CoordSysEvaluator . findCoordNameByType ( ds , AxisType . Lon ) ; 
nt . stnId = ds . findAttValueIgnoreCase ( null , "station" , null ) ; 
nt . stnDesc = ds . findAttValueIgnoreCase ( null , "description" , null ) ; 
if ( nt . stnDesc == null ) 
nt . stnDesc = ds . findAttValueIgnoreCase ( null , "comment" , null ) ; 
TableConfig obs = new TableConfig ( Table . Type . Structure , hasStruct ? "record" : obsDim . getShortName ( ) ) ; 
obs . structName = "record" ; 
obs . structureType = hasStruct ? TableConfig . StructureType . Structure : TableConfig . StructureType . PsuedoStructure ; 
obs . dimName = obsDim . getShortName ( ) ; 
obs . time = CoordSysEvaluator . findCoordNameByType ( ds , AxisType . Time ) ; 
nt . addChild ( obs ) ; 
Array ps = readArray ( psVar , timeIndex ) ; 
Index psIndex = ps . getIndex ( ) ; 
int nz = sigma . length ; 
int [ ] shape2D = ps . getShape ( ) ; 
ArrayDouble . D3 result = new ArrayDouble . D3 ( nz , ny , nx ) ; 
double psVal = ps . getDouble ( psIndex . set ( y , x ) ) ; 
result . set ( z , y , x , ptop + sigma [ z ] * ( psVal - ptop ) ) ; 
ArrayDouble . D1 result = new ArrayDouble . D1 ( nz ) ; 
double psVal = ps . getDouble ( psIndex . set ( yIndex , xIndex ) ) ; 
result . set ( z , ptop + sigma [ z ] * ( psVal - ptop ) ) ; 
} public void addMember ( Member m ) { 
members . add ( m ) ; 
if ( memberHash != null ) 
memberHash . put ( m . getName ( ) , m ) ; 
} public int hideMember ( Member m ) { 
if ( m == null ) return - 1 ; 
int index = members . indexOf ( m ) ; 
members . remove ( m ) ; 
if ( memberHash != null ) memberHash . remove ( m . getName ( ) ) ; 
} public java . util . List < String > getMemberNames ( ) { 
List < String > memberNames = new ArrayList < > ( ) ; 
for ( Member m : members ) { 
memberNames . add ( m . getName ( ) ) ; 
return memberNames ; 
} public Member findMember ( String memberName ) { 
if ( memberName == null ) return null ; 
if ( memberHash == null ) { 
int initial_capacity = ( int ) ( members . size ( ) / .75 ) + 1 ; 
memberHash = new HashMap < > ( initial_capacity ) ; 
for ( Member m : members ) 
return memberHash . get ( memberName ) ; 
if ( startingPosition <= 0 ) { 
int length = GribNumbers . uint3 ( raf ) ; 
raf . read ( ) ; 
int bm = raf . readShort ( ) ; 
if ( bm != 0 ) { 
if ( length <= 6 || length > 10e6 ) { 
int n = length - 6 ; 
byte [ ] data = new byte [ n ] ; 
} public void restoreState ( PreferencesExt store ) { 
if ( store == null ) 
int ncols = table . getColumnCount ( ) ; 
int [ ] modelIndex = ( int [ ] ) store . getBean ( "ColumnOrder" , null ) ; 
if ( ( modelIndex != null ) && ( modelIndex . length == ncols ) ) { 
boolean [ ] visible = new boolean [ ncols ] ; 
for ( int aModelIndex : modelIndex ) 
if ( aModelIndex < ncols ) 
visible [ aModelIndex ] = true ; 
for ( int i = 0 ; i < ncols ; i ++ ) 
if ( ! visible [ i ] ) { 
acts [ i ] . hideColumn ( ) ; 
acts [ i ] . putValue ( BAMutil . STATE , new Boolean ( false ) ) ; 
TableColumnModel tcm = table . getColumnModel ( ) ; 
int n = Math . min ( modelIndex . length , table . getColumnCount ( ) ) ; 
TableColumn tc = tcm . getColumn ( i ) ; 
tc . setModelIndex ( modelIndex [ i ] ) ; 
String name = model . getColumnName ( modelIndex [ i ] ) ; 
tc . setHeaderValue ( name ) ; 
tc . setIdentifier ( name ) ; 
if ( useThreads && ( modelIndex [ i ] == threadCol ) ) { 
threadHeaderRenderer = new ThreadHeaderRenderer ( threadCol ) ; 
tc . setHeaderRenderer ( threadHeaderRenderer ) ; 
tc . setHeaderRenderer ( new SortedHeaderRenderer ( name , modelIndex [ i ] ) ) ; 
Object colWidths = store . getBean ( "ColumnWidths" , null ) ; 
if ( colWidths == null ) 
int [ ] size = ( int [ ] ) colWidths ; 
setColumnWidths ( size ) ; 
for ( int aSize : size ) 
boolean isThreadsOn = store . getBoolean ( "isThreadsOn" , false ) ; 
if ( useThreads ) { 
model . setThreadsOn ( isThreadsOn ) ; 
threadHeaderRenderer . setOn ( isThreadsOn ) ; 
int colNo = store . getInt ( "SortOnCol" , 0 ) ; 
boolean reverse = store . getBoolean ( "SortReverse" , false ) ; 
model . setSortCol ( colNo ) ; 
model . setReverse ( reverse ) ; 
setSortCol ( colNo , reverse ) ; 
model . sort ( ) ; 
table . fireDataChanged ( ) ; 
private void setColumnWidths ( int [ ] sizes ) { 
for ( int i = 0 ; i < table . getColumnCount ( ) ; i ++ ) { 
int maxw = ( ( sizes == null ) || ( i >= sizes . length ) ) ? 10 : sizes [ i ] ; 
tc . setPreferredWidth ( maxw ) ; 
public void setColOn ( int colno , boolean state , int pos ) { 
acts [ colno ] . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; 
if ( state ) 
acts [ colno ] . addAtPos ( pos ) ; 
acts [ colno ] . hideColumn ( ) ; 
} public void saveState ( PreferencesExt store ) { 
int [ ] size = new int [ ncols ] ; 
int [ ] modelIndex = new int [ ncols ] ; 
for ( int i = 0 ; i < ncols ; i ++ ) { 
size [ i ] = tc . getWidth ( ) ; 
modelIndex [ i ] = tc . getModelIndex ( ) ; 
store . putBeanObject ( "ColumnWidths" , size ) ; 
store . putBeanObject ( "ColumnOrder" , modelIndex ) ; 
store . putInt ( "SortOnCol" , model . getSortCol ( ) ) ; 
store . putBoolean ( "SortReverse" , model . getReverse ( ) ) ; 
store . putBoolean ( "isThreadsOn" , model . isThreadsOn ( ) ) ; 
} public Iterator getSelectedRows ( ) { 
TreePath [ ] paths = table . getSelectionPaths ( ) ; 
if ( ( paths == null ) || ( paths . length < 1 ) ) 
HashSet set = new HashSet ( 2 * paths . length ) ; 
for ( TreePath path : paths ) { 
model . addRowsToSetFromPath ( table . getTree ( ) , path , set ) ; 
return set . iterator ( ) ; 
} public void setSelectedRow ( int rowno ) { 
if ( ( rowno < 0 ) || ( rowno >= model . getRowCount ( ) ) ) 
selectedRow = model . getRow ( rowno ) ; 
TreePath path = model . getPath ( selectedRow ) ; 
if ( path != null ) table . setSelectionPath ( path ) ; 
invokeSetPath ( ) ; 
ensureRowIsVisible ( rowno ) ; 
} public int [ ] getModelIndex ( ) { 
int [ ] modelIndex = new int [ model . getColumnCount ( ) ] ; 
for ( int i = 0 ; i < model . getColumnCount ( ) ; i ++ ) { 
} catch ( java . lang . ArrayIndexOutOfBoundsException e ) { 
return modelIndex ; 
} private void ensureRowIsVisible ( int nRow ) { 
Rectangle visibleRect = table . getCellRect ( nRow , 0 , true ) ; 
if ( visibleRect != null ) { 
visibleRect . x = scrollPane . getViewport ( ) . getViewPosition ( ) . x ; 
table . scrollRectToVisible ( visibleRect ) ; 
table . repaint ( ) ; 
} public void setMemberData ( StructureMembers . Member m , Array data ) { 
if ( data == null ) 
memberData . put ( m , data ) ; 
} public Array getArray ( StructureMembers . Member m ) { 
return memberData . get ( m ) ; 
} public double getScalarDouble ( StructureMembers . Member m ) { 
return data . getDouble ( Index . scalarIndexImmutable ) ; 
} public double [ ] getJavaArrayDouble ( StructureMembers . Member m ) { 
return ( double [ ] ) data . getStorage ( ) ; 
} public float getScalarFloat ( StructureMembers . Member m ) { 
return data . getFloat ( Index . scalarIndexImmutable ) ; 
} public float [ ] getJavaArrayFloat ( StructureMembers . Member m ) { 
return ( float [ ] ) data . getStorage ( ) ; 
} public byte getScalarByte ( StructureMembers . Member m ) { 
return data . getByte ( Index . scalarIndexImmutable ) ; 
} public byte [ ] getJavaArrayByte ( StructureMembers . Member m ) { 
return ( byte [ ] ) data . getStorage ( ) ; 
} public int getScalarInt ( StructureMembers . Member m ) { 
return data . getInt ( Index . scalarIndexImmutable ) ; 
} public int [ ] getJavaArrayInt ( StructureMembers . Member m ) { 
return ( int [ ] ) data . getStorage ( ) ; 
} public short getScalarShort ( StructureMembers . Member m ) { 
return data . getShort ( Index . scalarIndexImmutable ) ; 
} public short [ ] getJavaArrayShort ( StructureMembers . Member m ) { 
return ( short [ ] ) data . getStorage ( ) ; 
} public long getScalarLong ( StructureMembers . Member m ) { 
return data . getLong ( Index . scalarIndexImmutable ) ; 
} public long [ ] getJavaArrayLong ( StructureMembers . Member m ) { 
return ( long [ ] ) data . getStorage ( ) ; 
} public char getScalarChar ( StructureMembers . Member m ) { 
return data . getChar ( Index . scalarIndexImmutable ) ; 
} public char [ ] getJavaArrayChar ( StructureMembers . Member m ) { 
return ( char [ ] ) data . getStorage ( ) ; 
} public String getScalarString ( StructureMembers . Member m ) { 
data = getArray ( m ) ; 
return ( String ) data . getObject ( 0 ) ; 
char [ ] ba = getJavaArrayChar ( m ) ; 
while ( count < ba . length ) { 
if ( 0 == ba [ count ] ) break ; 
return new String ( ba , 0 , count ) ; 
} public StructureData getScalarStructure ( StructureMembers . Member m ) { 
ArrayStructure data = ( ArrayStructure ) getArray ( m ) ; 
return data . getStructureData ( 0 ) ; 
} public void writeDatasetEntries ( InvCatalogImpl cat , String fileDir , StringBuilder mess ) { 
this . fileDir = fileDir ; 
this . messBuffer = mess ; 
File dir = new File ( fileDir ) ; 
assert ret ; 
CatalogCrawler . Listener listener = new CatalogCrawler . Listener ( ) { 
public void getDataset ( InvDataset ds , Object context ) { 
doOneDataset ( ds ) ; 
public boolean getCatalogRef ( InvCatalogRef dd , Object context ) { return true ; } 
ByteArrayOutputStream bis = new ByteArrayOutputStream ( ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( bis , CDM . utf8Charset ) ) ; 
CatalogCrawler crawler = new CatalogCrawler ( CatalogCrawler . USE_ALL , true , listener ) ; 
crawler . crawl ( cat , null , pw , null ) ; 
mess . append ( "\n*********************\n" ) ; 
mess . append ( new String ( bis . toByteArray ( ) , CDM . utf8Charset ) ) ; 
} public void doOneDataset ( InvDataset ds ) { 
if ( isDatasetUseable ( ds , messBuffer ) ) { 
String id = StringUtil2 . replace ( ds . getID ( ) , "/" , "-" ) ; 
String fileOutName = fileDir + "/" + id + ".dif.xml" ; 
OutputStream out = new BufferedOutputStream ( new FileOutputStream ( fileOutName ) ) ; 
writeOneEntry ( ds , out , messBuffer ) ; 
} public boolean isDatasetUseable ( InvDataset ds , StringBuilder sbuff ) { 
if ( ! ds . isHarvest ( ) ) { 
if ( ds . getName ( ) == null ) { 
if ( ds . getUniqueID ( ) == null ) { 
ThreddsMetadata . Variables vs = ds . getVariables ( "DIF" ) ; 
if ( ( vs == null ) || ( vs . getVariableList ( ) . size ( ) == 0 ) ) 
vs = ds . getVariables ( "GRIB-1" ) ; 
vs = ds . getVariables ( "GRIB-2" ) ; 
if ( ( vs == null ) || ( vs . getVariableList ( ) . size ( ) == 0 ) ) { 
List list = ds . getPublishers ( ) ; 
if ( ( list == null ) || ( list . size ( ) == 0 ) ) { 
String summary = ds . getDocumentation ( "summary" ) ; 
if ( summary == null ) { 
} public static void addToList ( Map < String , Object > flds , String fldName , Object fldValue ) { 
if ( fldValue == null ) return ; 
Object prevVal = flds . get ( fldName ) ; 
if ( prevVal == null ) { 
flds . put ( fldName , fldValue ) ; 
List prevList ; 
if ( prevVal instanceof List ) { 
prevList = ( List ) prevVal ; 
prevList = new ArrayList ( 5 ) ; 
prevList . add ( prevVal ) ; 
flds . put ( fldName , prevList ) ; 
if ( fldValue instanceof List ) { 
prevList . addAll ( ( List ) fldValue ) ; 
prevList . add ( fldValue ) ; 
} public Dataset copyDataset ( DatasetNode parent ) { 
return new Dataset ( parent , name , flds , accessBuilders , datasetBuilders ) ; 
} public void transferMetadata ( DatasetNode from , boolean parentsAlso ) { 
if ( parentsAlso ) { 
ThreddsMetadata inherit = getInheritableMetadata ( ) ; 
inheritMetadata ( from , inherit . getFlds ( ) ) ; 
for ( Map . Entry < String , Object > entry : from . getFldIterator ( ) ) { 
if ( parentsAlso && entry . getKey ( ) . equals ( Dataset . ThreddsMetadataInheritable ) ) continue ; 
if ( Dataset . listFlds . contains ( entry . getKey ( ) ) ) 
addToNewList ( flds , entry . getKey ( ) , entry . getValue ( ) ) ; 
flds . put ( entry . getKey ( ) , entry . getValue ( ) ) ; 
ThreddsMetadata tmiOld = ( ThreddsMetadata ) get ( Dataset . ThreddsMetadataInheritable ) ; 
if ( tmiOld != null && tmiOld . isImmutable ( ) ) { 
ThreddsMetadata tmiNew = new ThreddsMetadata ( tmiOld ) ; 
flds . put ( Dataset . ThreddsMetadataInheritable , tmiNew ) ; 
} public void transferInheritedMetadata ( DatasetNode from ) { 
ThreddsMetadata tmi = getInheritableMetadata ( ) ; 
inheritMetadata ( from , tmi . getFlds ( ) ) ; 
} public ThreddsMetadata getInheritableMetadata ( ) { 
ThreddsMetadata tmi = ( ThreddsMetadata ) get ( Dataset . ThreddsMetadataInheritable ) ; 
if ( tmi == null ) { 
tmi = new ThreddsMetadata ( ) ; 
put ( Dataset . ThreddsMetadataInheritable , tmi ) ; 
return tmi ; 
} void addProduct ( GridRecord record ) { 
if ( firstRecord == null ) { 
firstRecord = record ; 
} protected void addExtraAttributes ( GridParameter param , Variable v ) { 
int icf = hcs . getGds ( ) . getInt ( GridDefRecord . VECTOR_COMPONENT_FLAG ) ; 
String flag = GridCF . VectorComponentFlag . of ( icf ) ; 
v . addAttribute ( new Attribute ( GridDefRecord . VECTOR_COMPONENT_FLAG , flag ) ) ; 
} Variable makeVariable ( NetcdfFile ncfile , Group g , String useName , RandomAccessFile raf ) { 
this . nlevels = getVertNlevels ( ) ; 
this . ntimes = tcs . getNTimes ( ) ; 
if ( vname == null ) { 
this . vname = useName ; 
Variable v = new Variable ( ncfile , g , null , vname ) ; 
Formatter dims = new Formatter ( ) ; 
if ( hasEnsemble ( ) ) { 
if ( getVertIsUsed ( ) ) { 
hasVert = true ; 
v . setDimensions ( dims . toString ( ) ) ; 
GridParameter param = lookup . getParameter ( firstRecord ) ; 
if ( param == null ) return null ; 
String unit = param . getUnit ( ) ; 
if ( unit == null ) unit = "" ; 
v . addAttribute ( new Attribute ( "units" , unit ) ) ; 
v . addAttribute ( new Attribute ( "long_name" , makeLongName ( ) ) ) ; 
v . addAttribute ( new Attribute ( "missing_value" , lookup . getFirstMissingValue ( ) ) ) ; 
if ( GridServiceProvider . addLatLon ) 
v . addAttribute ( new Attribute ( "grid_mapping" , hcs . getGridName ( ) ) ) ; 
addExtraAttributes ( param , v ) ; 
v . setSPobject ( this ) ; 
int nrecs = ntimes * nlevels ; 
if ( hasEnsemble ( ) ) nrecs *= ecs . getNEnsembles ( ) ; 
recordTracker = new GridRecord [ nrecs ] ; 
boolean oneSent = false ; 
for ( GridRecord p : records ) { 
int level = getVertIndex ( p ) ; 
if ( ! getVertIsUsed ( ) && ( level > 0 ) ) { 
int time = tcs . findIndex ( p ) ; 
if ( level < 0 ) { 
+ p . getLevel1 ( ) + "," + p . getLevel2 ( ) + "\n" ) ; 
getVertIndex ( p ) ; 
if ( time < 0 ) { 
+ p . getValidTime ( ) + "\n" ) ; 
tcs . findIndex ( p ) ; 
oneSent = trackRecords ( time , level , p , raf , oneSent ) ; 
records . clear ( ) ; 
} public void showRecord ( int recnum , Formatter f ) { 
if ( ( recnum < 0 ) || ( recnum > recordTracker . length - 1 ) ) { 
GridRecord gr = recordTracker [ recnum ] ; 
int ens = recnum / ( nlevels * ntimes ) ; 
int tmp = recnum - ens * ( nlevels * ntimes ) ; 
int time = tmp / nlevels ; 
int level = tmp % nlevels ; 
int time = recnum / nlevels ; 
int level = recnum % nlevels ; 
} public void showMissing ( Formatter f ) { 
int count = 0 , total = 0 ; 
for ( int j = 0 ; j < nlevels ; j ++ ) { 
boolean missing = recordTracker [ i * nlevels + j ] == null ; 
f . format ( "%s" , missing ? "-" : "X" ) ; 
if ( missing ) count ++ ; 
} public int showMissingSummary ( Formatter f ) { 
int total = recordTracker . length ; 
if ( recordTracker [ i ] == null ) 
} public GridRecord findRecord ( int ens , int time , int level ) { 
return recordTracker [ ens * ( ntimes * nlevels ) + ( time * nlevels ) + level ] ; 
return recordTracker [ time * nlevels + level ] ; 
} public String dump ( ) { 
if ( null != record . getValidTime ( ) ) 
sbuff . format ( "%n" ) ; 
} protected String makeLongName ( ) { 
f . format ( "%s" , param . getDescription ( ) ) ; 
String levelName = makeLevelName ( firstRecord , lookup ) ; 
if ( levelName . length ( ) != 0 ) 
} static public void registerFactory ( FeatureType datatype , String className ) throws ClassNotFoundException { 
} static public void registerFactory ( FeatureType datatype , Class c ) { 
if ( ! ( TypedDatasetFactoryIF . class . isAssignableFrom ( c ) ) ) 
transformList . add ( 0 , new Factory ( datatype , c , ( TypedDatasetFactoryIF ) instance ) ) ; 
transformList . add ( new Factory ( datatype , c , ( TypedDatasetFactoryIF ) instance ) ) ; 
} static public TypedDataset open ( FeatureType datatype , String location , ucar . nc2 . util . CancelTask task , StringBuilder errlog ) throws IOException { 
return open ( datatype , ncd , task , errlog ) ; 
} static public TypedDataset open ( FeatureType datatype , NetcdfDataset ncd , ucar . nc2 . util . CancelTask task , StringBuilder errlog ) throws IOException { 
Class useClass = null ; 
for ( Factory fac : transformList ) { 
if ( ( datatype != null ) && ( datatype != fac . datatype ) ) continue ; 
if ( fac . instance . isMine ( ncd ) ) { 
useClass = fac . c ; 
if ( null == useClass ) { 
if ( datatype == FeatureType . POINT ) { 
return open ( FeatureType . STATION , ncd , task , errlog ) ; 
if ( datatype == FeatureType . GRID ) { 
if ( null == datatype ) { 
ucar . nc2 . dt . grid . GridDataset gds = new ucar . nc2 . dt . grid . GridDataset ( ncd ) ; 
if ( gds . getGrids ( ) . size ( ) > 0 ) 
TypedDatasetFactoryIF builder = null ; 
builder = ( TypedDatasetFactoryIF ) useClass . newInstance ( ) ; 
errlog . append ( e . getMessage ( ) ) . append ( "\n" ) ; 
return builder . open ( ncd , task , errlog ) ; 
} public static TVPDefaultMetadataPropertyType initDefaultPointMetadata ( 
TVPDefaultMetadataPropertyType defaultPointMetadata , VariableSimpleIF dataVar ) { 
DefaultTVPMeasurementMetadataDocument defaultTVPMeasurementMetadataDoc = 
DefaultTVPMeasurementMetadataDocument . Factory . newInstance ( ) ; 
NcTVPMeasurementMetadataType . initDefaultTVPMeasurementMetadata ( 
defaultTVPMeasurementMetadataDoc . addNewDefaultTVPMeasurementMetadata ( ) , dataVar ) ; 
defaultPointMetadata . set ( defaultTVPMeasurementMetadataDoc ) ; 
return defaultPointMetadata ; 
val = source . readByte ( ) ; 
sink . writeByte ( val ) ; 
} public boolean isAscending ( ) { 
loadValuesIfNeeded ( ) ; 
switch ( spacing ) { 
return getResolution ( ) > 0 ; 
return values [ 0 ] <= values [ ncoords - 1 ] ; 
return values [ 0 ] <= values [ ncoords ] ; 
return values [ 0 ] <= values [ 2 * ncoords - 1 ] ; 
} public Object getCoordObject ( int index ) { 
if ( axisType == AxisType . RunTime ) 
return makeDate ( getCoordMidpoint ( index ) ) ; 
if ( isInterval ( ) ) 
return new double [ ] { getCoordEdge1 ( index ) , getCoordEdge2 ( index ) } ; 
return getCoordMidpoint ( index ) ; 
} public Optional < CoverageCoordAxis > subsetByIntervals ( List < MAMath . MinMax > lonIntvs , int stride ) { 
if ( axisType != AxisType . Lon ) 
if ( ! isRegular ( ) ) 
CoordAxisHelper helper = new CoordAxisHelper ( this ) ; 
double start = Double . NaN ; 
List < RangeIterator > ranges = new ArrayList < > ( ) ; 
for ( MAMath . MinMax lonIntv : lonIntvs ) { 
if ( first ) start = lonIntv . min ; 
Optional < RangeIterator > opt = helper . makeRange ( lonIntv . min , lonIntv . max , stride ) ; 
return Optional . empty ( opt . getErrorMessage ( ) ) ; 
ranges . add ( opt . get ( ) ) ; 
RangeComposite compositeRange = new RangeComposite ( AxisType . Lon . toString ( ) , ranges ) ; 
int npts = compositeRange . length ( ) ; 
double end = start + npts * resolution ; 
CoverageCoordAxisBuilder builder = new CoverageCoordAxisBuilder ( this ) ; 
builder . subset ( npts , start , end , resolution , null ) ; 
builder . setRange ( null ) ; 
builder . setCompositeRange ( compositeRange ) ; 
return Optional . of ( new CoverageCoordAxis1D ( builder ) ) ; 
} protected Optional < CoverageCoordAxisBuilder > subsetBuilder ( SubsetParams params ) { 
if ( params == null ) 
return Optional . of ( new CoverageCoordAxisBuilder ( this ) ) ; 
switch ( getAxisType ( ) ) { 
case GeoZ : 
case Pressure : 
case Height : 
Double dval = params . getVertCoord ( ) ; 
if ( dval != null ) 
return Optional . of ( helper . subsetClosest ( dval ) ) ; 
double [ ] intv = params . getVertCoordIntv ( ) ; 
if ( intv != null ) 
return Optional . of ( helper . subsetClosest ( ( intv [ 0 ] + intv [ 1 ] ) / 2 ) ) ; 
double [ ] vertRange = params . getVertRange ( ) ; 
if ( vertRange != null ) 
return helper . subset ( vertRange [ 0 ] , vertRange [ 1 ] , 1 ) ; 
case Ensemble : 
Double eval = params . getDouble ( SubsetParams . ensCoord ) ; 
if ( eval != null ) { 
return Optional . of ( helper . subsetClosest ( eval ) ) ; 
case GeoX : 
case GeoY : 
case Lat : 
case Lon : 
case Time : 
return Optional . of ( helper . subsetLatest ( ) ) ; 
CalendarDate date = ( CalendarDate ) params . get ( SubsetParams . time ) ; 
if ( date != null ) 
return Optional . of ( helper . subsetClosest ( date ) ) ; 
Integer stride = ( Integer ) params . get ( SubsetParams . timeStride ) ; 
if ( stride == null || stride < 0 ) stride = 1 ; 
CalendarDateRange dateRange = ( CalendarDateRange ) params . get ( SubsetParams . timeRange ) ; 
if ( dateRange != null ) 
return helper . subset ( dateRange , stride ) ; 
Double timeOffset = params . getTimeOffset ( ) ; 
CalendarDate runtime = params . getRunTime ( ) ; 
if ( timeOffset != null ) { 
if ( runtime != null ) { 
date = makeDateInTimeUnits ( runtime , timeOffset ) ; 
return Optional . of ( helper . subsetClosest ( timeOffset ) ) ; 
double [ ] timeOffsetIntv = params . getTimeOffsetIntv ( ) ; 
if ( timeOffsetIntv != null && runtime != null ) { 
CalendarDate [ ] dateIntv = new CalendarDate [ 2 ] ; 
dateIntv [ 0 ] = makeDateInTimeUnits ( runtime , timeOffsetIntv [ 0 ] ) ; 
dateIntv [ 1 ] = makeDateInTimeUnits ( runtime , timeOffsetIntv [ 1 ] ) ; 
return Optional . of ( helper . subsetClosest ( dateIntv ) ) ; 
if ( stride != 1 ) 
return Optional . of ( helper . subsetByIndex ( getRange ( ) . setStride ( stride ) ) ) ; 
case RunTime : 
CalendarDate rundate = ( CalendarDate ) params . get ( SubsetParams . runtime ) ; 
return Optional . of ( helper . subsetClosest ( rundate ) ) ; 
if ( params . isTrue ( SubsetParams . runtimeAll ) ) 
case TimeOffset : 
Double oval = params . getDouble ( SubsetParams . timeOffset ) ; 
if ( oval != null ) { 
return Optional . of ( helper . subsetClosest ( oval ) ) ; 
timeOffsetIntv = params . getTimeOffsetIntv ( ) ; 
if ( timeOffsetIntv != null ) { 
return Optional . of ( helper . subsetClosest ( ( timeOffsetIntv [ 0 ] + timeOffsetIntv [ 1 ] ) / 2 ) ) ; 
if ( params . isTrue ( SubsetParams . timeOffsetFirst ) ) { 
return Optional . of ( helper . subsetByIndex ( new Range ( 1 ) ) ) ; 
vals [ i ] = source . readInt ( ) ; 
sink . writeInt ( vals [ i ] ) ; 
checkFileType ( ucar . unidata . io . RandomAccessFile raf ) 
int format = 0 ; 
byte [ ] magic = new byte [ MAGIC_NUMBER_LEN ] ; 
if ( raf . readBytes ( magic , 0 , MAGIC_NUMBER_LEN ) < MAGIC_NUMBER_LEN ) 
int hdrlen = 0 ; 
hdrlen = CDF1HEAD . length ; 
format = 0 ; 
if ( memequal ( CDF1HEAD , magic , CDF1HEAD . length ) ) 
format = NC_FORMAT_CLASSIC ; 
else if ( memequal ( CDF2HEAD , magic , CDF2HEAD . length ) ) 
format = NC_FORMAT_64BIT_OFFSET ; 
else if ( memequal ( CDF5HEAD , magic , CDF5HEAD . length ) ) 
format = NC_FORMAT_CDF5 ; 
else if ( memequal ( H4HEAD , magic , H4HEAD . length ) ) 
format = NC_FORMAT_HDF4 ; 
if ( format != 0 ) { 
raf . seek ( hdrlen ) ; 
return format ; 
long filePos = 0 ; 
long size = raf . length ( ) ; 
while ( ( filePos < size - 8 ) && ( filePos < MAXHEADERPOS ) ) { 
boolean match ; 
raf . seek ( filePos ) ; 
if ( memequal ( H5HEAD , magic , H5HEAD . length ) ) { 
format = NC_FORMAT_HDF5 ; 
filePos = ( filePos == 0 ) ? 512 : 2 * filePos ; 
if ( format != 0 ) 
raf . seek ( filePos + H5HEAD . length ) ; 
memequal ( byte [ ] b1 , byte [ ] b2 , int len ) 
if ( b1 == b2 ) return true ; 
if ( b1 == null || b2 == null ) return false ; 
if ( b1 . length < len || b2 . length < len ) return false ; 
if ( b1 [ i ] != b2 [ i ] ) return false ; 
int dims = numDimensions ( ) ; 
int shape [ ] = new int [ dims ] ; 
for ( Enumeration e = getDimensions ( ) ; e . hasMoreElements ( ) ; ) { 
DArrayDimension d = ( DArrayDimension ) e . nextElement ( ) ; 
shape [ i ++ ] = d . getSize ( ) ; 
} private int asciiArray ( PrintWriter os , boolean addName , String label , int index , int dims , int shape [ ] , 
int offset ) { 
if ( dims == 1 ) { 
os . print ( label ) ; 
for ( int i = 0 ; i < shape [ offset ] ; i ++ ) { 
BaseType bt = ( ( BaseTypePrimitiveVector ) pv ) . getValue ( index ++ ) ; 
os . println ( "" ) ; 
( ( toASCII ) bt ) . toASCII ( os , false , null , false ) ; 
pv . printSingleVal ( os , index ++ ) ; 
if ( addName ) os . print ( "\n" ) ; 
StringBuilder s = new StringBuilder ( ) ; 
s . append ( label ) ; 
s . append ( "[" ) ; 
s . append ( i ) ; 
s . append ( "]" ) ; 
if ( ( dims - 1 ) == 1 ) 
index = asciiArray ( os , addName , s . toString ( ) , index , dims - 1 , shape , offset + 1 ) ; 
public void setContext ( DapContext context ) 
this . context = context ; 
Object o = this . context . get ( Dap4Util . DAP4ENDIANTAG ) ; 
if ( o != null ) 
setOrder ( ( ByteOrder ) o ) ; 
o = this . context . get ( Dap4Util . DAP4CSUMTAG ) ; 
setChecksumMode ( ChecksumMode . modeFor ( o . toString ( ) ) ) ; 
} protected DapDataset 
parseDMR ( String document ) 
Dap4Parser parser ; 
parser = new DOM4Parser ( null ) ; 
if ( PARSEDEBUG ) 
parser . setDebugLevel ( 1 ) ; 
if ( ! parser . parse ( document ) ) 
throw new DapException ( se ) ; 
if ( parser . getErrorResponse ( ) != null ) 
DapDataset result = parser . getDMR ( ) ; 
processAttributes ( result ) ; 
processAttributes ( DapDataset dataset ) 
List < DapNode > nodes = dataset . getNodeList ( ) ; 
for ( DapNode node : nodes ) { 
Map < String , DapAttribute > attrs = node . getAttributes ( ) ; 
if ( attrs . size ( ) > 0 ) { 
List < DapAttribute > suppressed = new ArrayList < > ( ) ; 
for ( DapAttribute dattr : attrs . values ( ) ) { 
if ( suppress ( dattr . getShortName ( ) ) ) 
suppressed . add ( dattr ) ; 
for ( DapAttribute dattr : suppressed ) { 
node . removeAttribute ( dattr ) ; 
getEndianAttribute ( dataset ) ; 
if ( attrname . equals ( "_Unsigned" ) ) 
} public static Date getDateUsingSimpleDateFormat ( String dateString , String dateFormatString ) 
int smallestIndex = dateString . length ( ) ; 
if ( smallestIndex == 0 ) return null ; 
for ( int i = 0 ; i < 10 ; i ++ ) 
int curIndex = dateString . indexOf ( String . valueOf ( i ) ) ; 
if ( curIndex != - 1 && smallestIndex > curIndex ) 
smallestIndex = curIndex ; 
return getDateUsingCompleteDateFormatWithOffset ( dateString , dateFormatString , smallestIndex ) ; 
} public static Date getDateUsingDemarkatedCount ( String dateString , String dateFormatString , char demark ) 
int pos1 = dateFormatString . indexOf ( demark ) ; 
dateFormatString = dateFormatString . substring ( pos1 + 1 ) ; 
return getDateUsingCompleteDateFormatWithOffset ( dateString , dateFormatString , pos1 ) ; 
} public static Date getDateUsingDemarkatedMatch ( String dateString , String dateFormatString , char demark ) 
int pos2 = dateFormatString . indexOf ( demark , pos1 + 1 ) ; 
if ( ( pos1 < 0 ) || ( pos2 < 0 ) ) { 
String match = dateFormatString . substring ( pos1 + 1 , pos2 ) ; 
int pos3 = dateString . indexOf ( match ) ; 
if ( pos3 < 0 ) return null ; 
if ( pos1 > 0 ) { 
dateFormatString = dateFormatString . substring ( 0 , pos1 ) ; 
dateString = dateString . substring ( pos3 - dateFormatString . length ( ) , pos3 ) ; 
dateFormatString = dateFormatString . substring ( pos2 + 1 ) ; 
dateString = dateString . substring ( pos3 + match . length ( ) ) ; 
int posDot1 = 0 ; 
while ( dateFormatString . charAt ( posDot1 ) == '.' ) 
posDot1 ++ ; 
int posDot2 = dateFormatString . length ( ) ; 
while ( dateFormatString . charAt ( posDot2 - 1 ) == '.' ) 
posDot2 -- ; 
if ( posDot1 != 0 || posDot2 != dateFormatString . length ( ) ) { 
dateFormatString = dateFormatString . substring ( posDot1 , posDot2 ) ; 
dateString = dateString . substring ( posDot1 , posDot2 ) ; 
return getDateUsingCompleteDateFormatWithOffset ( dateString , dateFormatString , 0 ) ; 
} public static Date getDateUsingCompleteDateFormatWithOffset ( String dateString , String dateFormatString , int startIndex ) 
SimpleDateFormat dateFormat = new SimpleDateFormat ( dateFormatString , Locale . US ) ; 
dateFormat . setTimeZone ( TimeZone . getTimeZone ( "GMT" ) ) ; 
if ( startIndex + dateFormatString . length ( ) <= dateString . length ( ) ) 
s = dateString . substring ( startIndex , startIndex + dateFormatString . length ( ) ) ; 
s = dateString ; 
Date result = dateFormat . parse ( s ) ; 
} public static Date getDateUsingRegExp ( String dateString , 
String matchPattern , 
String substitutionPattern ) 
String dateFormatString = "yyyy-MM-dd'T'HH:mm" ; 
return getDateUsingRegExpAndDateFormat ( dateString , 
matchPattern , 
substitutionPattern , 
dateFormatString ) ; 
} public static Date getDateUsingRegExpAndDateFormat ( String dateString , 
String dateFormatString ) 
java . util . regex . Pattern pattern = java . util . regex . Pattern . compile ( matchPattern ) ; 
java . util . regex . Matcher matcher = pattern . matcher ( dateString ) ; 
if ( ! matcher . matches ( ) ) 
StringBuffer dateStringFormatted = new StringBuffer ( ) ; 
matcher . appendReplacement ( dateStringFormatted , substitutionPattern ) ; 
if ( dateStringFormatted . length ( ) == 0 ) 
return getDateUsingCompleteDateFormat ( dateStringFormatted . toString ( ) , dateFormatString ) ; 
public ProjectionPoint latLonToProj ( LatLonPoint latlon , ProjectionPointImpl result ) { 
double fromLat = Math . toRadians ( latlon . getLatitude ( ) ) ; 
double theta = Math . toRadians ( latlon . getLongitude ( ) ) ; 
if ( projectionLongitude != 0 && ! Double . isNaN ( theta ) ) { 
theta = MapMath . normalizeLongitude ( theta - projectionLongitude ) ; 
ProjectionPointImpl out = new ProjectionPointImpl ( ) ; 
project ( theta , fromLat , out ) ; 
result . setLocation ( totalScale * out . getX ( ) + falseEasting , totalScale * out . getY ( ) + falseNorthing ) ; 
ProjectionPointImpl pp = new ProjectionPointImpl ( ) ; 
projectInverse ( fromX , fromY , pp ) ; 
if ( pp . getX ( ) < - Math . PI ) { 
pp . setX ( - Math . PI ) ; 
} else if ( pp . getX ( ) > Math . PI ) { 
pp . setX ( Math . PI ) ; 
if ( projectionLongitude != 0 && ! Double . isNaN ( pp . getX ( ) ) ) { 
pp . setX ( MapMath . normalizeLongitude ( pp . getX ( ) + projectionLongitude ) ) ; 
result . setLatitude ( Math . toDegrees ( pp . getY ( ) ) ) ; 
result . setLongitude ( Math . toDegrees ( pp . getX ( ) ) ) ; 
} public void addCoords ( List < Coordinate > coords , PartitionCollectionMutable . Partition part ) { 
Coordinate runtime = null ; 
for ( Coordinate coord : coords ) { 
switch ( coord . getType ( ) ) { 
case runtime : 
CoordinateRuntime rtime = ( CoordinateRuntime ) coord ; 
if ( runtimeBuilder == null ) runtimeBuilder = new CoordinateRuntime . Builder2 ( rtime . getTimeUnits ( ) ) ; 
runtimeBuilder . addAll ( coord ) ; 
runtime = coord ; 
if ( debugPartitionErrors && ! duplicateRuntimeMessage && part != null ) 
testDuplicateRuntime ( rtime , part ) ; 
case time : 
CoordinateTime time = ( CoordinateTime ) coord ; 
if ( timeBuilder == null ) timeBuilder = new CoordinateTime . Builder2 ( coord . getCode ( ) , time . getTimeUnit ( ) , time . getRefDate ( ) ) ; 
timeBuilder . addAll ( coord ) ; 
case timeIntv : 
CoordinateTimeIntv timeIntv = ( CoordinateTimeIntv ) coord ; 
if ( timeIntvBuilder == null ) timeIntvBuilder = new CoordinateTimeIntv . Builder2 ( null , coord . getCode ( ) , timeIntv . getTimeUnit ( ) , timeIntv . getRefDate ( ) ) ; 
timeIntvBuilder . addAll ( intervalFilter ( ( CoordinateTimeIntv ) coord ) ) ; 
case time2D : 
CoordinateTime2D time2D = ( CoordinateTime2D ) coord ; 
if ( time2DBuilder == null ) time2DBuilder = new CoordinateTime2DUnionizer ( time2D . isTimeInterval ( ) , time2D . getTimeUnit ( ) , coord . getCode ( ) , false , logger ) ; 
time2DBuilder . addAll ( time2D ) ; 
CoordinateRuntime runtimeFrom2D = time2D . getRuntimeCoordinate ( ) ; 
if ( ! runtimeFrom2D . equals ( runtime ) ) 
case ens : 
if ( ensBuilder == null ) ensBuilder = new CoordinateEns . Builder2 ( coord . getCode ( ) ) ; 
ensBuilder . addAll ( coord ) ; 
case vert : 
CoordinateVert vertCoord = ( CoordinateVert ) coord ; 
if ( vertBuilder == null ) vertBuilder = new CoordinateVert . Builder2 ( coord . getCode ( ) , vertCoord . getVertUnit ( ) ) ; 
vertBuilder . addAll ( coord ) ; 
collectValues ( String text ) 
List < String > values = new ArrayList < String > ( ) ; 
text = text . trim ( ) + '\0' ; 
char c = text . charAt ( i ++ ) ; 
if ( c == '\0' ) break ; 
if ( c == '\'' ) { 
c = text . charAt ( i ++ ) ; 
if ( c == '\0' ) 
else if ( i >= 128 ) 
values . add ( buf . toString ( ) ) ; 
buf . setLength ( 0 ) ; 
if ( c == '\0' ) { 
} else if ( c == '"' ) break ; 
if ( c == 0 ) i -- ; 
headerParser = new FysatHeader ( ) ; 
headerParser . read ( raf , ncfile ) ; 
} private Array readData ( ucar . nc2 . Variable v2 , long dataPos , int [ ] origin , int [ ] shape , int [ ] stride ) throws IOException , InvalidRangeException { 
Vinfo vi = ( Vinfo ) v2 . getSPobject ( ) ; 
int data_size = vi . vsize ; 
Array array ; 
if ( vi . classType == DataType . BYTE . getPrimitiveClassType ( ) ) { 
array = Array . factory ( DataType . BYTE , v2 . getShape ( ) , data ) ; 
} else if ( vi . classType == DataType . SHORT . getPrimitiveClassType ( ) ) { 
EndianByteBuffer byteBuff = new EndianByteBuffer ( data , vi . byteOrder ) ; 
short [ ] sdata = byteBuff . getShortArray ( ) ; 
array = Array . factory ( DataType . SHORT , v2 . getShape ( ) , sdata ) ; 
} else if ( vi . classType == DataType . INT . getPrimitiveClassType ( ) ) { 
short [ ] idata = byteBuff . getShortArray ( ) ; 
array = Array . factory ( DataType . INT , v2 . getShape ( ) , idata ) ; 
throw new UnsupportedEncodingException ( ) ; 
return array . sectionNoReduce ( origin , shape , stride ) ; 
} public Array readCompressedData ( ucar . nc2 . Variable v2 , long dataPos , int [ ] origin , int [ ] shape , int [ ] stride ) throws IOException , InvalidRangeException { 
long length = raf . length ( ) ; 
int data_size = ( int ) ( length - dataPos ) ; 
Raster raster = image . getData ( ) ; 
DataBuffer db = raster . getDataBuffer ( ) ; 
byte [ ] udata = dbb . getData ( ) ; 
Array array = Array . factory ( DataType . BYTE , v2 . getShape ( ) , udata ) ; 
} private byte [ ] getGiniLine ( int nx , int ny , long doff , int lineNumber , int len , int stride ) throws IOException { 
raf . seek ( doff ) ; 
if ( lineNumber >= ny ) 
int offset = lineNumber * nx + ( int ) doff ; 
data [ i ] = raf . readByte ( ) ; 
offset = offset + stride ; 
} public void setGaussianLats ( int nparallels , float la1 , float la2 ) { 
int nlats = ( 2 * nparallels ) ; 
double diff = Math . abs ( gaussLats . latd [ i ] - la1 ) ; 
diff = Math . abs ( gaussLats . latd [ i ] - la2 ) ; 
if ( Math . abs ( bestEndIndex - bestStartIndex ) + 1 != nyRaw ) { 
nlats = nyRaw ; 
bestEndIndex = nyRaw - 1 ; 
float [ ] data = new float [ nyRaw ] ; 
float [ ] gaussw = new float [ nyRaw ] ; 
for ( int i = 0 ; i < nyRaw ; i ++ ) { 
data [ i ] = ( float ) gaussLats . latd [ useIndex ] ; 
gaussw [ i ] = ( float ) gaussLats . gaussw [ useIndex ] ; 
this . gaussLats = Array . factory ( DataType . FLOAT , new int [ ] { nyRaw } , data ) ; 
this . gaussw = Array . factory ( DataType . FLOAT , new int [ ] { nyRaw } , gaussw ) ; 
} protected void init ( double a , double f , int zone , boolean isNorth ) { 
A = a ; 
F = 1.0 / f ; 
this . axlon0_deg = ( zone * 6 - 183 ) ; 
this . axlon0 = axlon0_deg * RADIANS_PER_DEGREE ; 
double polx2b , polx3b , polx4b , polx5b ; 
Eps2 = ( F ) * ( 2.0 - F ) ; 
Eps25 = .25 * ( Eps2 ) ; 
Epps2 = ( Eps2 ) / ( 1.0 - Eps2 ) ; 
polx2b = Eps2 + 1.0 / 4.0 * Math . pow ( Eps2 , 2 ) 
+ 15.0 / 128.0 * Math . pow ( Eps2 , 3 ) 
- 455.0 / 4096.0 * Math . pow ( Eps2 , 4 ) ; 
polx2b = 3.0 / 8.0 * polx2b ; 
polx3b = Math . pow ( Eps2 , 2 ) + 3.0 / 4.0 * Math . pow ( Eps2 , 3 ) 
- 77.0 / 128.0 * Math . pow ( Eps2 , 4 ) ; 
polx3b = 15.0 / 256.0 * polx3b ; 
polx4b = Math . pow ( Eps2 , 3 ) - 41.0 / 32.0 * Math . pow ( Eps2 , 4 ) ; 
polx4b = polx4b * 35.0 / 3072.0 ; 
polx5b = - 315.0 / 131072.0 * Math . pow ( Eps2 , 4 ) ; 
poly1b = 1.0 - ( 1.0 / 4.0 * Eps2 ) - ( 3.0 / 64.0 * Math . pow ( Eps2 , 2 ) ) 
- ( 5.0 / 256.0 * Math . pow ( Eps2 , 3 ) ) 
- ( 175.0 / 16384.0 * Math . pow ( Eps2 , 4 ) ) ; 
poly2b = polx2b * - 2.0 + polx3b * 4.0 - polx4b * 6.0 + polx5b * 8.0 ; 
poly3b = polx3b * - 8.0 + polx4b * 32.0 - polx5b * 80.0 ; 
poly4b = polx4b * - 32.0 + polx5b * 192.0 ; 
poly5b = polx5b * - 128.0 ; 
} public static ParsedSectionSpec parseVariableSection ( NetcdfFile ncfile , String variableSection ) throws InvalidRangeException { 
List < String > tokes = EscapeStrings . tokenizeEscapedName ( variableSection ) ; 
if ( tokes . size ( ) == 0 ) 
String selector = tokes . get ( 0 ) ; 
ParsedSectionSpec outerV = parseVariableSelector ( ncfile , selector ) ; 
ParsedSectionSpec current = outerV ; 
for ( int i = 1 ; i < tokes . size ( ) ; i ++ ) { 
selector = tokes . get ( i ) ; 
current . child = parseVariableSelector ( current . v , selector ) ; 
return outerV ; 
} private static ParsedSectionSpec parseVariableSelector ( Object parent , String selector ) throws InvalidRangeException { 
String varNameEsc , indexSelect = null ; 
int pos1 = EscapeStrings . indexOf ( selector , '(' ) ; 
if ( pos1 < 0 ) { 
varNameEsc = selector ; 
varNameEsc = selector . substring ( 0 , pos1 ) ; 
int pos2 = selector . indexOf ( ')' , pos1 + 1 ) ; 
indexSelect = selector . substring ( pos1 , pos2 ) ; 
if ( debugSelector ) 
if ( parent instanceof NetcdfFile ) { 
NetcdfFile ncfile = ( NetcdfFile ) parent ; 
v = ncfile . findVariable ( varNameEsc ) ; 
} else if ( parent instanceof Structure ) { 
Structure s = ( Structure ) parent ; 
v = s . findVariable ( NetcdfFile . makeNameUnescaped ( varNameEsc ) ) ; 
if ( v == null ) 
if ( v . getDataType ( ) == DataType . SEQUENCE ) 
indexSelect = null ; 
Section section ; 
if ( indexSelect != null ) { 
section = new Section ( indexSelect ) ; 
section = Section . fill ( section , v . getShape ( ) ) ; 
section = v . getShapeAsSection ( ) ; 
return new ParsedSectionSpec ( v , section ) ; 
} public static String makeSectionSpecString ( Variable v , List < Range > ranges ) throws InvalidRangeException { 
makeSpec ( sb , v , ranges ) ; 
} private boolean containsOld ( double wantLat , double wantLon , int [ ] rectIndex ) { 
rectIndex [ 0 ] = Math . max ( Math . min ( rectIndex [ 0 ] , nrows - 1 ) , 0 ) ; 
rectIndex [ 1 ] = Math . max ( Math . min ( rectIndex [ 1 ] , ncols - 1 ) , 0 ) ; 
int row = rectIndex [ 0 ] ; 
int col = rectIndex [ 1 ] ; 
rectIndex [ 0 ] , rectIndex [ 1 ] , wantLat , wantLon , 
latEdge . get ( row , col ) , latEdge . get ( row + 1 , col ) , lonEdge . get ( row , col ) , lonEdge . get ( row , col + 1 ) ) ; 
if ( wantLat < latEdge . get ( row , col ) ) return false ; 
if ( wantLat > latEdge . get ( row + 1 , col ) ) return false ; 
if ( wantLon < lonEdge . get ( row , col ) ) return false ; 
if ( wantLon > lonEdge . get ( row , col + 1 ) ) return false ; 
} private boolean contains ( double wantLat , double wantLon , int [ ] rectIndex ) { 
double x1 = lonEdge . get ( row , col ) ; 
double y1 = latEdge . get ( row , col ) ; 
double x2 = lonEdge . get ( row , col + 1 ) ; 
double y2 = latEdge . get ( row , col + 1 ) ; 
double x3 = lonEdge . get ( row + 1 , col + 1 ) ; 
double y3 = latEdge . get ( row + 1 , col + 1 ) ; 
double x4 = lonEdge . get ( row + 1 , col ) ; 
double y4 = latEdge . get ( row + 1 , col ) ; 
boolean sign = detIsPositive ( x1 , y1 , x2 , y2 , wantLon , wantLat ) ; 
if ( sign != detIsPositive ( x2 , y2 , x3 , y3 , wantLon , wantLat ) ) return false ; 
if ( sign != detIsPositive ( x3 , y3 , x4 , y4 , wantLon , wantLat ) ) return false ; 
if ( sign != detIsPositive ( x4 , y4 , x1 , y1 , wantLon , wantLat ) ) return false ; 
} private boolean jump2 ( double wantLat , double wantLon , int [ ] rectIndex ) { 
int row = Math . max ( Math . min ( rectIndex [ 0 ] , nrows - 1 ) , 0 ) ; 
int col = Math . max ( Math . min ( rectIndex [ 1 ] , ncols - 1 ) , 0 ) ; 
double lat = latEdge . get ( row , col ) ; 
double lon = lonEdge . get ( row , col ) ; 
double diffLat = wantLat - lat ; 
double diffLon = wantLon - lon ; 
double dlatdy = latEdge . get ( row + 1 , col ) - lat ; 
double dlatdx = latEdge . get ( row , col + 1 ) - lat ; 
double dlondx = lonEdge . get ( row , col + 1 ) - lon ; 
double dlondy = lonEdge . get ( row + 1 , col ) - lon ; 
double dx = ( diffLon - dlondy * diffLat / dlatdy ) / ( dlondx - dlatdx * dlondy / dlatdy ) ; 
double dy = ( diffLat - dlatdx * dx ) / dlatdy ; 
row , col , dlondx , dlondy , dlatdx , dlatdy , 
diffLat , diffLon , dy , dx ) ; 
int drow = ( int ) Math . round ( dy ) ; 
int dcol = ( int ) Math . round ( dx ) ; 
if ( ( drow == 0 ) && ( dcol == 0 ) ) { 
return incr ( wantLat , wantLon , rectIndex ) ; 
rectIndex [ 0 ] = Math . max ( Math . min ( row + drow , nrows - 1 ) , 0 ) ; 
rectIndex [ 1 ] = Math . max ( Math . min ( col + dcol , ncols - 1 ) , 0 ) ; 
if ( ( row == rectIndex [ 0 ] ) && ( col == rectIndex [ 1 ] ) ) return false ; 
} private boolean box9 ( double wantLat , double wantLon , int [ ] rectIndex ) { 
int minrow = Math . max ( row - 1 , 0 ) ; 
int maxrow = Math . min ( row + 1 , nrows ) ; 
int mincol = Math . max ( col - 1 , 0 ) ; 
int maxcol = Math . min ( col + 1 , ncols ) ; 
for ( int i = minrow ; i <= maxrow ; i ++ ) 
for ( int j = mincol ; j <= maxcol ; j ++ ) { 
rectIndex [ 0 ] = i ; 
rectIndex [ 1 ] = j ; 
if ( contains ( wantLat , wantLon , rectIndex ) ) return true ; 
} public VerticalCT makeCoordinateTransform ( NetcdfDataset ds , AttributeContainer ctv ) { 
String formula_terms = getFormula ( ctv ) ; 
if ( null == formula_terms ) 
if ( values == null ) return null ; 
a = values [ 0 ] ; 
b = values [ 1 ] ; 
orog = values [ 2 ] ; 
VerticalCT rs = new VerticalCT ( "AtmHybridHeight_Transform_" + ctv . getName ( ) , getTransformName ( ) , VerticalCT . Type . HybridHeight , this ) ; 
rs . addParameter ( new Parameter ( "standard_name" , getTransformName ( ) ) ) ; 
rs . addParameter ( new Parameter ( "formula_terms" , formula_terms ) ) ; 
if ( ! addParameter ( rs , HybridHeight . A , ds , a ) ) { 
if ( ! addParameter ( rs , HybridHeight . B , ds , b ) ) { 
if ( ! addParameter ( rs , HybridHeight . OROG , ds , orog ) ) { 
} public synchronized void 
close ( ) 
if ( closed ) 
if ( methodstream != null ) { 
this . methodstream . close ( ) ; 
} catch ( IOException ioe ) { } 
this . methodstream = null ; 
if ( this . lastresponse != null ) { 
EntityUtils . consume ( this . lastresponse . getEntity ( ) ) ; 
HttpClientUtils . closeQuietly ( this . lastresponse ) ; 
} catch ( IOException ignore ) { } 
this . lastresponse = null ; 
session . removeMethod ( this ) ; 
if ( localsession ) { 
session = null ; 
this . lastrequest = null ; 
} public int execute ( ) 
HttpResponse res = executeRaw ( ) ; 
if ( res != null ) 
return res . getStatusLine ( ) . getStatusCode ( ) ; 
} public HttpResponse 
executeRaw ( ) 
if ( this . executed ) 
this . executed = true ; 
if ( this . methodurl == null ) 
if ( ! localsession && ! sessionCompatible ( this . methodurl ) ) 
this . settings = session . mergedSettings ( ) ; 
if ( this . range != null ) { 
this . headers . put ( "Range" , "bytes=" + range [ 0 ] + "-" + range [ 1 ] ) ; 
range = null ; 
RequestBuilder rb = getRequestBuilder ( ) ; 
setcontent ( rb ) ; 
setheaders ( rb , this . headers ) ; 
this . lastrequest = buildRequest ( rb , this . settings ) ; 
AuthScope methodscope = HTTPAuthUtil . uriToAuthScope ( this . methodurl ) ; 
AuthScope target = HTTPAuthUtil . authscopeUpgrade ( session . getSessionScope ( ) , methodscope ) ; 
HttpHost targethost = HTTPAuthUtil . authscopeToHost ( target ) ; 
HttpClientBuilder cb = HttpClients . custom ( ) ; 
configClient ( cb , this . settings ) ; 
session . setAuthenticationAndProxy ( cb ) ; 
HttpClient httpclient = cb . build ( ) ; 
if ( MOCKEXECUTOR != null ) { 
URI uri = this . lastrequest . getURI ( ) ; 
this . lastresponse = MOCKEXECUTOR . execute ( this . lastrequest ) ; 
this . lastresponse = httpclient . execute ( targethost , this . lastrequest , session . getContext ( ) ) ; 
if ( this . lastresponse == null ) 
return this . lastresponse ; 
throw new HTTPException ( ioe ) ; 
} protected TableConfig getPointConfig ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) throws IOException { 
if ( info . time . getRank ( ) != 1 ) { 
Dimension obsDim = info . time . getDimension ( 0 ) ; 
TableConfig obsTable = makeSingle ( ds , obsDim , errlog ) ; 
obsTable . featureType = FeatureType . POINT ; 
return obsTable ; 
} protected TableConfig getStationConfig ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) throws IOException { 
if ( ! identifyEncodingStation ( ds , info , CF . FeatureType . timeSeries , errlog ) ) 
TableConfig stnTable = makeStationTable ( ds , FeatureType . STATION , info , errlog ) ; 
if ( stnTable == null ) return null ; 
Dimension obsDim = info . childDim ; 
TableConfig obsTable = null ; 
switch ( info . encoding ) { 
case single : 
obsTable = makeSingle ( ds , obsDim , errlog ) ; 
case multidim : 
obsTable = makeMultidimInner ( ds , stnTable , info . childDim , info , errlog ) ; 
if ( info . time . getRank ( ) == 1 ) { 
obsTable . addJoin ( new JoinArray ( info . time , JoinArray . Type . raw , 0 ) ) ; 
obsTable . time = info . time . getFullName ( ) ; 
case raggedContiguous : 
stnTable . numRecords = info . ragged_rowSize . getFullName ( ) ; 
obsTable = makeRaggedContiguousChildTable ( ds , info . parentDim , info . childDim , info . childStruct , errlog ) ; 
case raggedIndex : 
obsTable = makeRaggedIndexChildTable ( ds , info . parentDim , info . childDim , info . ragged_parentIndex , errlog ) ; 
case flat : 
info . set ( Encoding . flat , obsDim ) ; 
obsTable = makeStructTable ( ds , FeatureType . STATION , info , errlog ) ; 
obsTable . parentIndex = ( info . instanceId == null ) ? null : info . instanceId . getFullName ( ) ; 
Variable stnIdVar = Evaluator . findVariableWithAttributeAndDimension ( ds , CF . CF_ROLE , CF . STATION_ID , obsDim , errlog ) ; 
if ( stnIdVar == null ) 
stnIdVar = Evaluator . findVariableWithAttributeAndDimension ( ds , CF . STANDARD_NAME , CF . STATION_ID , obsDim , errlog ) ; 
obsTable . stnId = ( stnIdVar == null ) ? null : stnIdVar . getFullName ( ) ; 
obsTable . stnDesc = Evaluator . findNameOfVariableWithAttributeValue ( ds , CF . STANDARD_NAME , CF . PLATFORM_NAME ) ; 
if ( obsTable . stnDesc == null ) 
obsTable . stnDesc = Evaluator . findNameOfVariableWithAttributeValue ( ds , CF . STANDARD_NAME , CF . STATION_DESC ) ; 
obsTable . stnWmoId = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . STATION_WMOID , obsDim , errlog ) ; 
obsTable . stnAlt = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . SURFACE_ALTITUDE , obsDim , errlog ) ; 
if ( obsTable . stnAlt == null ) 
obsTable . stnAlt = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . STATION_ALTITUDE , obsDim , errlog ) ; 
if ( obsTable == null ) return null ; 
stnTable . addChild ( obsTable ) ; 
return stnTable ; 
} protected TableConfig getProfileConfig ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) throws IOException { 
if ( ! identifyEncodingProfile ( ds , info , errlog ) ) return null ; 
TableConfig profileTable = makeStructTable ( ds , FeatureType . PROFILE , info , errlog ) ; 
if ( profileTable == null ) return null ; 
profileTable . feature_id = identifyIdVariableName ( ds , CF . FeatureType . profile ) ; 
if ( profileTable . feature_id == null ) { 
VariableDS z = CoordSysEvaluator . findCoordByType ( ds , AxisType . Height ) ; 
if ( z == null ) z = CoordSysEvaluator . findCoordByType ( ds , AxisType . Pressure ) ; 
if ( z == null ) z = CoordSysEvaluator . findCoordByType ( ds , AxisType . GeoZ ) ; 
if ( z == null ) { 
if ( info . childStruct == null ) 
info . childStruct = z . getParentStructure ( ) ; 
obsTable = makeSingle ( ds , info . childDim , errlog ) ; 
obsTable = makeMultidimInner ( ds , profileTable , info . childDim , info , errlog ) ; 
if ( z . getRank ( ) == 1 ) { 
obsTable . addJoin ( new JoinArray ( z , JoinArray . Type . raw , 0 ) ) ; 
obsTable . elev = z . getFullName ( ) ; 
profileTable . numRecords = info . ragged_rowSize . getFullName ( ) ; 
profileTable . addChild ( obsTable ) ; 
return profileTable ; 
} protected TableConfig getTrajectoryConfig ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) throws IOException { 
if ( ! identifyEncodingTraj ( ds , info , errlog ) ) return null ; 
TableConfig trajTable = makeStructTable ( ds , FeatureType . TRAJECTORY , info , errlog ) ; 
if ( trajTable == null ) return null ; 
trajTable . feature_id = identifyIdVariableName ( ds , CF . FeatureType . trajectory ) ; 
if ( trajTable . feature_id == null ) { 
TableConfig obsConfig = null ; 
obsConfig = makeSingle ( ds , info . childDim , errlog ) ; 
obsConfig = makeMultidimInner ( ds , trajTable , info . childDim , info , errlog ) ; 
obsConfig . addJoin ( new JoinArray ( info . time , JoinArray . Type . raw , 0 ) ) ; 
obsConfig . time = info . time . getFullName ( ) ; 
trajTable . numRecords = info . ragged_rowSize . getFullName ( ) ; 
obsConfig = makeRaggedContiguousChildTable ( ds , info . parentDim , info . childDim , info . childStruct , errlog ) ; 
obsConfig = makeRaggedIndexChildTable ( ds , info . parentDim , info . childDim , info . ragged_parentIndex , errlog ) ; 
if ( obsConfig == null ) return null ; 
trajTable . addChild ( obsConfig ) ; 
return trajTable ; 
} protected TableConfig getTimeSeriesProfileConfig ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) throws IOException { 
if ( ! identifyEncodingTimeSeriesProfile ( ds , info , CF . FeatureType . timeSeriesProfile , errlog ) ) return null ; 
VariableDS time = CoordSysEvaluator . findCoordByType ( ds , AxisType . Time ) ; 
if ( time == null ) return null ; 
if ( time . getRank ( ) == 0 && time . getParentStructure ( ) == null ) { 
TableConfig stationTable = makeStationTable ( ds , FeatureType . STATION_PROFILE , info , errlog ) ; 
if ( stationTable == null ) return null ; 
VariableDS z = info . alt ; 
case single : { 
if ( time . getRank ( ) == 2 ) { 
if ( z . getRank ( ) == 2 ) 
if ( z . getRank ( ) == 2 ) { 
TableConfig profileTable = makeStructTable ( ds , FeatureType . PROFILE , new EncodingInfo ( ) . set ( Encoding . multidim , info . childDim ) , errlog ) ; 
if ( time . getRank ( ) == 1 ) { 
profileTable . addJoin ( new JoinArray ( time , JoinArray . Type . level , 1 ) ) ; 
profileTable . time = time . getFullName ( ) ; 
stationTable . addChild ( profileTable ) ; 
TableConfig zTable = makeMultidimInner ( ds , profileTable , info . grandChildDim , info , errlog ) ; 
zTable . addJoin ( new JoinArray ( z , JoinArray . Type . raw , 0 ) ) ; 
zTable . elev = z . getFullName ( ) ; 
profileTable . addChild ( zTable ) ; 
case multidim : { 
if ( time . getRank ( ) == 3 ) { 
if ( z . getRank ( ) == 3 ) 
} else if ( time . getRank ( ) == 2 ) { 
if ( z . getRank ( ) == 3 ) { 
TableConfig profileTable = makeMultidimInner ( ds , stationTable , info . childDim , info , errlog ) ; 
TableConfig zTable = makeMultidimInner3D ( ds , stationTable , profileTable , info . grandChildDim , errlog ) ; 
case raggedIndex : { 
TableConfig profileTable = makeRaggedIndexChildTable ( ds , info . parentDim , info . childDim , info . ragged_parentIndex , errlog ) ; 
TableConfig obsTable = makeRaggedContiguousChildTable ( ds , info . childDim , info . grandChildDim , info . grandChildStruct , errlog ) ; 
return stationTable ; 
} protected boolean identifyEncodingStation ( NetcdfDataset ds , EncodingInfo info , CF . FeatureType ftype , Formatter errlog ) { 
Dimension obsDim = null ; 
if ( info . time . getRank ( ) > 0 ) 
obsDim = info . time . getDimension ( info . time . getRank ( ) - 1 ) ; 
else if ( info . time . getParentStructure ( ) != null ) { 
Structure parent = info . time . getParentStructure ( ) ; 
obsDim = parent . getDimension ( parent . getRank ( ) - 1 ) ; 
if ( info . lat . getRank ( ) == 0 ) { 
info . set ( Encoding . single , null , obsDim ) ; 
Dimension stnDim = info . lat . getDimension ( 0 ) ; 
if ( obsDim == stnDim ) { 
info . set ( Encoding . flat , null , obsDim ) ; 
if ( identifyRaggeds ( ds , info , stnDim , obsDim , errlog ) ) 
if ( info . lat . getRank ( ) == 1 ) { 
info . set ( Encoding . multidim , stnDim , obsDim ) ; 
} protected boolean identifyRaggeds ( NetcdfDataset ds , EncodingInfo info , Dimension instanceDim , Dimension sampleDim , Formatter errlog ) { 
Evaluator . VarAtt varatt = Evaluator . findVariableWithAttribute ( ds , CF . SAMPLE_DIMENSION ) ; 
if ( varatt == null ) varatt = Evaluator . findVariableWithAttribute ( ds , CF . RAGGED_ROWSIZE ) ; 
if ( varatt != null ) { 
Variable ragged_rowSize = varatt . var ; 
String sampleDimName = varatt . att . getStringValue ( ) ; 
if ( sampleDim != null && ! sampleDimName . equals ( sampleDim . getShortName ( ) ) ) { 
if ( sampleDim == null ) { 
sampleDim = ds . findDimension ( sampleDimName ) ; 
Dimension rrDim ; 
if ( ragged_rowSize . getRank ( ) > 0 ) 
rrDim = ragged_rowSize . getDimension ( 0 ) ; 
else if ( ragged_rowSize . getParentStructure ( ) != null ) { 
Structure parent = ragged_rowSize . getParentStructure ( ) ; 
rrDim = parent . getDimension ( 0 ) ; 
if ( instanceDim != null && instanceDim != rrDim ) { 
instanceDim = rrDim ; 
if ( ragged_rowSize . getDataType ( ) != DataType . INT ) { 
info . set ( Encoding . raggedContiguous , instanceDim , sampleDim ) ; 
info . ragged_rowSize = ragged_rowSize ; 
info . parentStruct = ragged_rowSize . getParentStructure ( ) ; 
varatt = Evaluator . findVariableWithAttribute ( ds , CF . INSTANCE_DIMENSION ) ; 
if ( varatt == null ) varatt = Evaluator . findVariableWithAttribute ( ds , CF . RAGGED_PARENTINDEX ) ; 
Variable ragged_parentIndex = varatt . var ; 
String instanceDimName = varatt . att . getStringValue ( ) ; 
if ( instanceDim != null && ! instanceDimName . equals ( instanceDim . getShortName ( ) ) ) { 
if ( instanceDim == null ) { 
instanceDim = ds . findDimension ( instanceDimName ) ; 
if ( ragged_parentIndex . getDataType ( ) != DataType . INT ) { 
if ( ragged_parentIndex . isMemberOfStructure ( ) ) { 
Structure s = ragged_parentIndex . getParentStructure ( ) ; 
if ( s . getRank ( ) == 0 || ! s . getDimension ( 0 ) . equals ( sampleDim ) ) { 
if ( ragged_parentIndex . getRank ( ) != 1 || ! ragged_parentIndex . getDimension ( 0 ) . equals ( sampleDim ) ) { 
info . set ( Encoding . raggedIndex , instanceDim , sampleDim ) ; 
info . ragged_parentIndex = ragged_parentIndex ; 
info . childStruct = ragged_parentIndex . getParentStructure ( ) ; 
} protected boolean identifyDoubleRaggeds ( NetcdfDataset ds , EncodingInfo info , Formatter errlog ) { 
Evaluator . VarAtt varatt = Evaluator . findVariableWithAttribute ( ds , CF . INSTANCE_DIMENSION ) ; 
if ( varatt == null ) return false ; 
Dimension stationDim = ds . findDimension ( instanceDimName ) ; 
if ( stationDim == null ) { 
if ( ragged_parentIndex . getRank ( ) != 1 && info . childStruct == null ) { 
Dimension profileDim = ( info . childDim != null ) ? info . childDim : ragged_parentIndex . getDimension ( 0 ) ; 
varatt = Evaluator . findVariableWithAttribute ( ds , CF . SAMPLE_DIMENSION ) ; 
String obsDimName = varatt . att . getStringValue ( ) ; 
Dimension obsDim = ds . findDimension ( obsDimName ) ; 
if ( obsDimName == null ) { 
if ( ! obsDimName . equals ( info . grandChildDim . getShortName ( ) ) ) { 
if ( info . childDim == null ) { 
Dimension profileDim2 = ragged_rowSize . getDimension ( 0 ) ; 
if ( profileDim2 != profileDim ) { 
info . set ( Encoding . raggedIndex , stationDim , profileDim , obsDim ) ; 
} private TableConfig makeStationTable ( NetcdfDataset ds , FeatureType ftype , EncodingInfo info , Formatter errlog ) throws IOException { 
Variable lat = CoordSysEvaluator . findCoordByType ( ds , AxisType . Lat ) ; 
Variable lon = CoordSysEvaluator . findCoordByType ( ds , AxisType . Lon ) ; 
if ( lat == null || lon == null ) { 
Table . Type stationTableType = Table . Type . Structure ; 
if ( info . encoding == Encoding . single ) stationTableType = Table . Type . Top ; 
if ( info . encoding == Encoding . flat ) stationTableType = Table . Type . Construct ; 
Dimension stationDim = ( info . encoding == Encoding . flat ) ? info . childDim : info . parentDim ; 
TableConfig stnTable = new TableConfig ( stationTableType , name ) ; 
stnTable . featureType = ftype ; 
Variable stnIdVar = Evaluator . findVariableWithAttributeAndDimension ( ds , CF . CF_ROLE , CF . TIMESERIES_ID , stationDim , errlog ) ; 
stnIdVar = Evaluator . findVariableWithAttributeAndDimension ( ds , CF . STANDARD_NAME , CF . STATION_ID , stationDim , errlog ) ; 
if ( stnIdVar == null ) { 
stnTable . stnId = stnIdVar . getFullName ( ) ; 
info . instanceId = stnIdVar ; 
stnTable . stnDesc = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . PLATFORM_NAME , stationDim , errlog ) ; 
if ( stnTable . stnDesc == null ) 
stnTable . stnDesc = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . STATION_DESC , stationDim , errlog ) ; 
stnTable . stnWmoId = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . PLATFORM_ID , stationDim , errlog ) ; 
if ( stnTable . stnWmoId == null ) 
stnTable . stnWmoId = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . STATION_WMOID , stationDim , errlog ) ; 
stnTable . stnAlt = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . SURFACE_ALTITUDE , stationDim , errlog ) ; 
if ( stnTable . stnAlt == null ) 
stnTable . stnAlt = Evaluator . findNameVariableWithStandardNameAndDimension ( ds , CF . STATION_ALTITUDE , stationDim , errlog ) ; 
stnTable . lat = lat . getFullName ( ) ; 
stnTable . lon = lon . getFullName ( ) ; 
if ( info . encoding != Encoding . single && stationDim != null ) { 
stnTable . dimName = stationDim . getShortName ( ) ; 
makeStructureInfo ( stnTable , ds , stnIdVar . getParentStructure ( ) , stationDim ) ; 
if ( stnTable . stnAlt == null ) { 
Variable alt = CoordSysEvaluator . findCoordByType ( ds , AxisType . Height ) ; 
if ( alt != null ) { 
if ( ( info . encoding == Encoding . single ) && alt . getRank ( ) == 0 ) 
stnTable . stnAlt = alt . getFullName ( ) ; 
if ( ( info . encoding != Encoding . single ) && ( lat . getRank ( ) == alt . getRank ( ) ) && alt . getRank ( ) > 0 && alt . getDimension ( 0 ) . equals ( stationDim ) ) 
} private TableConfig makeRaggedContiguousChildTable ( NetcdfDataset ds , Dimension parentDim , Dimension childDim , Structure childStruct , Formatter errlog ) throws IOException { 
TableConfig childTable = new TableConfig ( Table . Type . Contiguous , childDim . getShortName ( ) ) ; 
childTable . dimName = childDim . getShortName ( ) ; 
childTable . lat = matchAxisTypeAndDimension ( ds , AxisType . Lat , childDim ) ; 
childTable . lon = matchAxisTypeAndDimension ( ds , AxisType . Lon , childDim ) ; 
childTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Height , childDim ) ; 
if ( childTable . elev == null ) childTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Pressure , childDim ) ; 
if ( childTable . elev == null ) childTable . elev = matchAxisTypeAndDimension ( ds , AxisType . GeoZ , childDim ) ; 
childTable . time = matchAxisTypeAndDimension ( ds , AxisType . Time , childDim ) ; 
makeStructureInfo ( childTable , ds , childStruct , childDim ) ; 
return childTable ; 
} private TableConfig makeMultidimInner ( NetcdfDataset ds , TableConfig parentTable , Dimension obsDim , EncodingInfo info , Formatter errlog ) throws IOException { 
Dimension parentDim = ds . findDimension ( parentTable . dimName ) ; 
Table . Type obsTableType = ( parentTable . structureType == TableConfig . StructureType . PsuedoStructure ) ? Table . Type . MultidimInnerPsuedo : Table . Type . MultidimInner ; 
TableConfig obsTable = new TableConfig ( obsTableType , obsDim . getShortName ( ) ) ; 
obsTable . lat = matchAxisTypeAndDimension ( ds , AxisType . Lat , parentDim , obsDim ) ; 
obsTable . lon = matchAxisTypeAndDimension ( ds , AxisType . Lon , parentDim , obsDim ) ; 
obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Height , parentDim , obsDim ) ; 
if ( obsTable . elev == null ) obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Pressure , parentDim , obsDim ) ; 
if ( obsTable . elev == null ) obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . GeoZ , parentDim , obsDim ) ; 
obsTable . time = matchAxisTypeAndDimension ( ds , AxisType . Time , parentDim , obsDim ) ; 
List < String > obsVars ; 
List < Variable > vars = ds . getVariables ( ) ; 
List < String > parentVars = new ArrayList < > ( vars . size ( ) ) ; 
obsVars = new ArrayList < > ( vars . size ( ) ) ; 
for ( Variable orgV : vars ) { 
if ( orgV instanceof Structure ) continue ; 
Dimension dim0 = orgV . getDimension ( 0 ) ; 
if ( ( dim0 != null ) && dim0 . equals ( parentDim ) ) { 
if ( ( orgV . getRank ( ) == 1 ) || ( ( orgV . getRank ( ) == 2 ) && orgV . getDataType ( ) == DataType . CHAR ) ) { 
parentVars . add ( orgV . getShortName ( ) ) ; 
Dimension dim1 = orgV . getDimension ( 1 ) ; 
if ( ( dim1 != null ) && dim1 . equals ( obsDim ) ) 
obsVars . add ( orgV . getShortName ( ) ) ; 
parentTable . vars = parentVars ; 
obsTable . structureType = parentTable . structureType ; 
obsTable . outerName = parentDim . getShortName ( ) ; 
obsTable . innerName = obsDim . getShortName ( ) ; 
obsTable . dimName = ( parentTable . structureType == TableConfig . StructureType . PsuedoStructure ) ? obsTable . outerName : obsTable . innerName ; 
obsTable . structName = obsDim . getShortName ( ) ; 
obsTable . vars = obsVars ; 
} private TableConfig makeMultidimInner3D ( NetcdfDataset ds , TableConfig outerTable , TableConfig middleTable , Dimension innerDim , Formatter errlog ) throws IOException { 
Dimension outerDim = ds . findDimension ( outerTable . dimName ) ; 
Dimension middleDim = ds . findDimension ( middleTable . innerName ) ; 
Table . Type obsTableType = ( outerTable . structureType == TableConfig . StructureType . PsuedoStructure ) ? Table . Type . MultidimInnerPsuedo3D : Table . Type . MultidimInner3D ; 
TableConfig obsTable = new TableConfig ( obsTableType , innerDim . getShortName ( ) ) ; 
obsTable . structureType = TableConfig . StructureType . PsuedoStructure2D ; 
obsTable . dimName = outerTable . dimName ; 
obsTable . outerName = middleTable . innerName ; 
obsTable . innerName = innerDim . getShortName ( ) ; 
obsTable . structName = innerDim . getShortName ( ) ; 
obsTable . lat = matchAxisTypeAndDimension ( ds , AxisType . Lat , outerDim , middleDim , innerDim ) ; 
obsTable . lon = matchAxisTypeAndDimension ( ds , AxisType . Lon , outerDim , middleDim , innerDim ) ; 
obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Height , outerDim , middleDim , innerDim ) ; 
if ( obsTable . elev == null ) obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . Pressure , middleDim , innerDim ) ; 
if ( obsTable . elev == null ) obsTable . elev = matchAxisTypeAndDimension ( ds , AxisType . GeoZ , middleDim , innerDim ) ; 
obsTable . time = matchAxisTypeAndDimension ( ds , AxisType . Time , outerDim , middleDim , innerDim ) ; 
List < String > outerVars = new ArrayList < > ( vars . size ( ) ) ; 
List < String > middleVars = new ArrayList < > ( vars . size ( ) ) ; 
List < String > innerVars = new ArrayList < > ( vars . size ( ) ) ; 
if ( outerDim . equals ( orgV . getDimension ( 0 ) ) ) 
outerVars . add ( orgV . getShortName ( ) ) ; 
} else if ( orgV . getRank ( ) == 2 ) { 
if ( outerDim . equals ( orgV . getDimension ( 0 ) ) && middleDim . equals ( orgV . getDimension ( 1 ) ) ) 
middleVars . add ( orgV . getShortName ( ) ) ; 
} else if ( orgV . getRank ( ) == 3 ) { 
if ( outerDim . equals ( orgV . getDimension ( 0 ) ) && middleDim . equals ( orgV . getDimension ( 1 ) ) && innerDim . equals ( orgV . getDimension ( 2 ) ) ) 
innerVars . add ( orgV . getShortName ( ) ) ; 
outerTable . vars = outerVars ; 
middleTable . vars = middleVars ; 
obsTable . vars = innerVars ; 
} protected String matchAxisTypeAndDimension ( NetcdfDataset ds , AxisType type , final Dimension outer ) { 
if ( ( outer == null ) && ( axis . getRank ( ) == 0 ) ) 
if ( ( outer != null ) && ( axis . getRank ( ) == 1 ) && ( outer . equals ( axis . getDimension ( 0 ) ) ) ) 
if ( axis . getParentStructure ( ) != null ) { 
Structure parent = axis . getParentStructure ( ) ; 
if ( ( outer != null ) && ( parent . getRank ( ) == 1 ) && ( outer . equals ( parent . getDimension ( 0 ) ) ) ) 
return var . getFullName ( ) ; 
} public void setStream ( InputStream zStream ) { 
last = 0 ; 
origPtr = 0 ; 
blockSize100k = 0 ; 
blockRandomised = false ; 
bsBuff = 0 ; 
bsLive = 0 ; 
mCrc = new CRC ( ) ; 
nInUse = 0 ; 
bsStream = null ; 
streamEnd = false ; 
currentChar = - 1 ; 
currentState = START_BLOCK_STATE ; 
storedBlockCRC = storedCombinedCRC = 0 ; 
computedBlockCRC = computedCombinedCRC = 0 ; 
i2 = count = chPrev = ch2 = 0 ; 
i = tPos = 0 ; 
rNToGo = 0 ; 
rTPos = 0 ; 
j2 = 0 ; 
z = 0 ; 
bsSetStream ( zStream ) ; 
if ( ! streamEnd ) { 
initBlock ( ) ; 
setupBlock ( ) ; 
} public int read ( ) { 
if ( streamEnd ) { 
int retChar = currentChar ; 
switch ( currentState ) { 
case START_BLOCK_STATE : 
case RAND_PART_A_STATE : 
case RAND_PART_B_STATE : 
setupRandPartB ( ) ; 
case RAND_PART_C_STATE : 
setupRandPartC ( ) ; 
case NO_RAND_PART_A_STATE : 
case NO_RAND_PART_B_STATE : 
setupNoRandPartB ( ) ; 
case NO_RAND_PART_C_STATE : 
setupNoRandPartC ( ) ; 
return retChar ; 
} public void start ( java . awt . Component top , String taskName , int progressMaxCount ) { 
pm = new javax . swing . ProgressMonitor ( top , taskName , "" , 0 , progressMaxCount ) ; 
pm . setMillisToDecideToPopup ( millisToDecideToPopup ) ; 
pm . setMillisToPopup ( millisToPopup ) ; 
taskThread = new Thread ( task ) ; 
taskThread . start ( ) ; 
ActionListener watcher = new ActionListener ( ) { 
secs ++ ; 
if ( pm . isCanceled ( ) ) { 
task . cancel ( ) ; 
String note = task . getNote ( ) ; 
int progress = task . getProgress ( ) ; 
pm . setProgress ( progress <= 0 ? secs : progress ) ; 
if ( task . isDone ( ) ) { 
timer . stop ( ) ; 
pm . close ( ) ; 
if ( task . isError ( ) ) { 
javax . swing . JOptionPane . showMessageDialog ( null , task . getErrorMessage ( ) ) ; 
if ( task . isSuccess ( ) ) 
fireEvent ( new ActionEvent ( this , 0 , "success" ) ) ; 
else if ( task . isError ( ) ) 
fireEvent ( new ActionEvent ( this , 0 , "error" ) ) ; 
else if ( task . isCancel ( ) ) 
fireEvent ( new ActionEvent ( this , 0 , "cancel" ) ) ; 
fireEvent ( new ActionEvent ( this , 0 , "done" ) ) ; 
timer = new javax . swing . Timer ( 1000 , watcher ) ; 
timer . start ( ) ; 
} static public byte [ ] 
readbinaryfile ( File f ) 
try ( FileInputStream fis = new FileInputStream ( f ) ) { 
return readbinaryfile ( fis ) ; 
} static public URI 
parseToURI ( final String u ) 
throws URISyntaxException 
while ( i < u . length ( ) ) { 
char c = u . charAt ( i ) ; 
if ( i + 1 == u . length ( ) ) 
buf . append ( "%5c" ) ; 
c = u . charAt ( i ) ; 
buf . append ( String . format ( "%%%02x" , ( int ) c ) ) ; 
return new URI ( buf . toString ( ) ) ; 
} static URI 
uriExclude ( final URI uri , URIPart ... excludes ) 
URIBuilder urib = new URIBuilder ( ) ; 
EnumSet < URIPart > set = EnumSet . of ( excludes [ 0 ] , excludes ) ; 
for ( URIPart part : URIPart . values ( ) ) { 
if ( set . contains ( part ) ) continue ; 
case SCHEME : 
urib . setScheme ( uri . getScheme ( ) ) ; 
case USERINFO : 
urib . setUserInfo ( uri . getUserInfo ( ) ) ; 
case HOST : 
urib . setHost ( uri . getHost ( ) ) ; 
case PORT : 
urib . setPort ( uri . getPort ( ) ) ; 
case PATH : 
urib . setPath ( uri . getPath ( ) ) ; 
case QUERY : 
urib . setCustomQuery ( uri . getQuery ( ) ) ; 
case FRAGMENT : 
urib . setFragment ( uri . getFragment ( ) ) ; 
return urib . build ( ) ; 
} static public String nullify ( String s ) 
if ( s != null && s . length ( ) == 0 ) s = null ; 
canonjoin ( String prefix , String suffix ) 
if ( prefix == null ) prefix = "" ; 
if ( suffix == null ) suffix = "" ; 
prefix = HTTPUtil . canonicalpath ( prefix ) ; 
suffix = HTTPUtil . canonicalpath ( suffix ) ; 
result . append ( prefix ) ; 
int prelen = prefix . length ( ) ; 
if ( prelen > 0 && result . charAt ( prelen - 1 ) != '/' ) { 
result . append ( '/' ) ; 
prelen ++ ; 
if ( suffix . length ( ) > 0 && suffix . charAt ( 0 ) == '/' ) 
result . append ( suffix . substring ( 1 ) ) ; 
result . append ( suffix ) ; 
int len = result . length ( ) ; 
if ( len > 0 && result . charAt ( len - 1 ) == '/' ) { 
result . deleteCharAt ( len - 1 ) ; 
len -- ; 
StringBuilder b = new StringBuilder ( path ) ; 
canonicalpath ( b ) ; 
} static public String relpath ( String path ) 
if ( b . length ( ) > 0 ) { 
if ( b . charAt ( 0 ) == '/' ) 
b . deleteCharAt ( 0 ) ; 
if ( hasDriveLetter ( b ) ) 
b . delete ( 0 , 2 ) ; 
} static protected boolean 
hasDriveLetter ( StringBuilder path ) 
return ( path . length ( ) >= 2 
&& path . charAt ( 1 ) == ':' 
&& DRIVELETTERS . indexOf ( path . charAt ( 0 ) ) >= 0 ) ; 
} static public String abspath ( String path ) 
if ( path == null ) return "/" ; 
if ( b . charAt ( 0 ) != '/' || ! hasDriveLetter ( b ) ) 
b . insert ( 0 , '/' ) ; 
} public boolean accept ( CrawlableDataset dataset ) 
Date lastModDate = dataset . lastModified ( ) ; 
if ( lastModDate != null ) 
if ( now - lastModDate . getTime ( ) > lastModifiedLimitInMillis ) 
} static MFile makeIndexMFile ( String collectionName , File directory ) { 
return new GcMFile ( directory , nameNoBlanks + GribCdmIndex . NCX_SUFFIX , - 1 , - 1 , - 1 ) ; 
} void copyInfo ( GribCollectionMutable from ) { 
this . center = from . center ; 
this . subcenter = from . subcenter ; 
this . master = from . master ; 
this . local = from . local ; 
this . genProcessType = from . genProcessType ; 
this . genProcessId = from . genProcessId ; 
this . backProcessId = from . backProcessId ; 
} public List < String > getFilenames ( ) { 
for ( MFile file : fileMap . values ( ) ) 
result . add ( file . getPath ( ) ) ; 
Collections . sort ( result ) ; 
} void setIndexRaf ( RandomAccessFile indexRaf ) { 
this . indexRaf = indexRaf ; 
if ( indexRaf != null ) { 
this . indexFilename = indexRaf . getLocation ( ) ; 
} private String getIndexFilepathInCache ( ) { 
File indexFile = GribCdmIndex . makeIndexFile ( name , directory ) ; 
return GribIndexCache . getFileOrCache ( indexFile . getPath ( ) ) . getPath ( ) ; 
} File setOrgDirectory ( String orgDirectory ) { 
this . orgDirectory = orgDirectory ; 
directory = new File ( orgDirectory ) ; 
if ( ! directory . exists ( ) ) { 
File indexFile = new File ( indexFilename ) ; 
File parent = indexFile . getParentFile ( ) ; 
if ( parent . exists ( ) ) 
directory = parent ; 
return directory ; 
} public void close ( ) throws java . io . IOException { 
indexRaf . close ( ) ; 
indexRaf = null ; 
Enumeration ve = getVariables ( ) ; 
boolean hasAttributes = e . hasMoreElements ( ) ; 
boolean hasVariables = ve . hasMoreElements ( ) ; 
pw . print ( pad + "<" + getTypeName ( ) ) ; 
DDSXMLParser . normalizeToXML ( getClearName ( ) ) + "\"" ) ; 
if ( hasAttributes || hasVariables ) { 
while ( ve . hasMoreElements ( ) ) { 
BaseType bt = ( BaseType ) ve . nextElement ( ) ; 
bt . printXML ( pw , pad + "\t" , constrained ) ; 
pw . println ( pad + "</" + getTypeName ( ) + ">" ) ; 
pw . println ( "/>" ) ; 
} public int ncounters ( ) { 
if ( nested == null ) 
int ncounters = 0 ; 
for ( BitCounterCompressed [ ] counters : nested ) { 
if ( counters == null ) continue ; 
for ( BitCounterCompressed counter : counters ) 
if ( counter != null ) ncounters += counter . ncounters ( ) ; 
return ncounters ; 
} static public NetcdfFileWriteable openExisting ( String location , boolean fill ) throws IOException { 
return new NetcdfFileWriteable ( location , fill , true ) ; 
} static public NetcdfFileWriteable createNew ( String location , boolean fill ) throws IOException { 
return new NetcdfFileWriteable ( location , fill , false ) ; 
} public Dimension addDimension ( String dimName , int length ) { 
if ( ! defineMode ) 
if ( ! N3iosp . isValidNetcdfObjectName ( dimName ) ) 
Dimension dim = new Dimension ( dimName , length , true , false , false ) ; 
super . addDimension ( null , dim ) ; 
} public Dimension addDimension ( String dimName , int length , boolean isShared , boolean isUnlimited , boolean isVariableLength ) { 
Dimension dim = new Dimension ( dimName , length , isShared , isUnlimited , isVariableLength ) ; 
} public Dimension renameDimension ( String oldName , String newName ) { 
Dimension dim = findDimension ( oldName ) ; 
if ( null != dim ) dim . setName ( newName ) ; 
} public Attribute addGlobalAttribute ( Attribute att ) { 
if ( ! N3iosp . isValidNetcdfObjectName ( att . getShortName ( ) ) ) { 
String attName = N3iosp . makeValidNetcdfObjectName ( att . getShortName ( ) ) ; 
att = new Attribute ( attName , att . getValues ( ) ) ; 
return super . addAttribute ( null , att ) ; 
} public Attribute addGlobalAttribute ( String name , String value ) { 
return addGlobalAttribute ( new Attribute ( name , value ) ) ; 
} public Attribute addGlobalAttribute ( String name , Array values ) { 
return addGlobalAttribute ( new Attribute ( name , values ) ) ; 
} public Attribute deleteGlobalAttribute ( String attName ) { 
Attribute att = findGlobalAttribute ( attName ) ; 
if ( null == att ) return null ; 
rootGroup . remove ( att ) ; 
return att ; 
} public Attribute renameGlobalAttribute ( String oldName , String newName ) { 
Attribute att = findGlobalAttribute ( oldName ) ; 
att = new Attribute ( newName , att . getValues ( ) ) ; 
rootGroup . addAttribute ( att ) ; 
} public Variable addVariable ( String varName , DataType dataType , Dimension [ ] dims ) { 
ArrayList < Dimension > list = new ArrayList < Dimension > ( ) ; 
list . addAll ( Arrays . asList ( dims ) ) ; 
return addVariable ( varName , dataType , list ) ; 
} public Variable addVariable ( String varName , DataType dataType , String dims ) { 
StringTokenizer stoker = new StringTokenizer ( dims ) ; 
Dimension d = rootGroup . findDimension ( tok ) ; 
if ( null == d ) 
list . add ( d ) ; 
} public Variable addVariable ( String shortName , DataType dataType , List < Dimension > dims ) { 
if ( ! N3iosp . isValidNetcdfObjectName ( shortName ) ) 
if ( ! valid . contains ( dataType ) ) 
if ( d . isUnlimited ( ) ) 
if ( count != 0 ) 
Variable v = new Variable ( this , rootGroup , null , shortName ) ; 
long size = v . getSize ( ) * v . getElementSize ( ) ; 
if ( size > N3iosp . MAX_VARSIZE ) 
super . addVariable ( null , v ) ; 
} public Variable addStringVariable ( String varName , List < Dimension > dims , int max_strlen ) { 
if ( ! N3iosp . isValidNetcdfObjectName ( varName ) ) 
Variable v = new Variable ( this , rootGroup , null , varName ) ; 
Dimension d = addDimension ( varName + "_strlen" , max_strlen ) ; 
ArrayList < Dimension > sdims = new ArrayList < Dimension > ( dims ) ; 
sdims . add ( d ) ; 
v . setDimensions ( sdims ) ; 
} public Variable renameVariable ( String oldName , String newName ) { 
Variable v = findVariable ( oldName ) ; 
if ( null != v ) v . setName ( newName ) ; 
} public void addVariableAttribute ( String varName , Attribute att ) { 
Variable v = rootGroup . findVariable ( varName ) ; 
if ( null == v ) 
} public void addVariableAttribute ( String varName , String attName , String value ) { 
addVariableAttribute ( varName , new Attribute ( attName , value ) ) ; 
} public void addVariableAttribute ( String varName , String attName , Array value ) { 
Attribute att = new Attribute ( attName , value ) ; 
addVariableAttribute ( varName , att ) ; 
} public Attribute deleteVariableAttribute ( String varName , String attName ) { 
Variable v = findVariable ( varName ) ; 
Attribute att = v . findAttribute ( attName ) ; 
v . remove ( att ) ; 
} public Attribute renameVariableAttribute ( String varName , String attName , String newName ) { 
} public void updateAttribute ( ucar . nc2 . Variable v2 , Attribute att ) throws IOException { 
if ( defineMode ) 
spiw . updateAttribute ( v2 , att ) ; 
} public void create ( ) throws java . io . IOException { 
if ( cached_spiw == null ) { 
spi = SPFactory . getServiceProvider ( ) ; 
spiw = ( IOServiceProviderWriter ) spi ; 
spiw = cached_spiw ; 
spi = spiw ; 
spiw . setFill ( fill ) ; 
spiw . create ( location , this , extraHeader , preallocateSize , isLargeFile ) ; 
defineMode = false ; 
} private void rewrite ( ) throws IOException { 
spiw . flush ( ) ; 
spiw . close ( ) ; 
File prevFile = new File ( location ) ; 
File tmpFile = new File ( location + ".tmp" ) ; 
if ( tmpFile . exists ( ) ) tmpFile . delete ( ) ; 
if ( ! prevFile . renameTo ( tmpFile ) ) { 
NetcdfFile oldFile = NetcdfFile . open ( tmpFile . getPath ( ) ) ; 
Structure recordVar = null ; 
if ( oldFile . hasUnlimitedDimension ( ) ) { 
oldFile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
recordVar = ( Structure ) oldFile . findVariable ( "record" ) ; 
if ( recordVar != null ) { 
Boolean result = ( Boolean ) spiw . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
if ( ! result ) 
recordVar = null ; 
List < Variable > oldList = new ArrayList < Variable > ( getVariables ( ) . size ( ) ) ; 
Variable oldVar = oldFile . findVariable ( v . getFullNameEscaped ( ) ) ; 
oldList . add ( oldVar ) ; 
FileWriter . copyVarData ( this , oldList , recordVar , null ) ; 
flush ( ) ; 
oldFile . close ( ) ; 
if ( ! tmpFile . delete ( ) ) 
} public void write ( String fullNameEsc , Array values ) throws java . io . IOException , InvalidRangeException { 
write ( fullNameEsc , new int [ values . getRank ( ) ] , values ) ; 
} public void write ( String fullNameEsc , int [ ] origin , Array values ) throws java . io . IOException , InvalidRangeException { 
ucar . nc2 . Variable v2 = findVariable ( fullNameEsc ) ; 
if ( v2 == null ) 
spiw . writeData ( v2 , new Section ( origin , values . getShape ( ) ) , values ) ; 
v2 . invalidateCache ( ) ; 
} public void writeStringData ( String varName , Array values ) throws java . io . IOException , InvalidRangeException { 
writeStringData ( varName , new int [ values . getRank ( ) ] , values ) ; 
} public void writeStringData ( String fullNameEsc , int [ ] origin , Array values ) throws java . io . IOException , InvalidRangeException { 
if ( values . getElementType ( ) != String . class ) 
if ( v2 . getDataType ( ) != DataType . CHAR ) 
int rank = v2 . getRank ( ) ; 
int strlen = v2 . getShape ( rank - 1 ) ; 
ArrayChar cvalues = ArrayChar . makeFromStringArray ( ( ArrayObject ) values , strlen ) ; 
int [ ] corigin = new int [ rank ] ; 
System . arraycopy ( origin , 0 , corigin , 0 , rank - 1 ) ; 
write ( fullNameEsc , corigin , cvalues ) ; 
if ( spiw != null ) { 
spiw = null ; 
spi = null ; 
} public Variable addVariable ( String varName , Class componentType , Dimension [ ] dims ) { 
List < Dimension > list = new ArrayList < Dimension > ( ) ; 
return addVariable ( varName , DataType . getType ( componentType , false ) , list ) ; 
} public static GempakSurfaceFileReader getInstance ( RandomAccessFile raf , 
boolean fullCheck ) 
GempakSurfaceFileReader gsfr = new GempakSurfaceFileReader ( ) ; 
gsfr . init ( raf , fullCheck ) ; 
return gsfr ; 
if ( dmLabel . kftype != MFSF ) { 
int numParams = 0 ; 
String partType = ( ( dmLabel . kfsrce == 100 ) && ( dmLabel . kprt == 1 ) ) 
? SFTX 
: SFDT ; 
DMPart part = getPart ( partType ) ; 
numParams = part . kparms ; 
if ( ! readStationsAndTimes ( true ) ) { 
if ( subType . equals ( STANDARD ) ) rf . setBufferSize ( 256 ) ; 
} protected void makeFileSubType ( ) { 
Key key = findKey ( GempakStation . SLAT ) ; 
String latType = key . type ; 
Key dateKey = findKey ( DATE ) ; 
if ( dateKey != null && ! dateKey . type . equals ( latType ) ) { 
if ( latType . equals ( ROW ) ) { 
subType = CLIMATE ; 
subType = STANDARD ; 
subType = SHIP ; 
} public void printOb ( int row , int col ) { 
int stnIndex = ( getFileSubType ( ) . equals ( CLIMATE ) ) 
? row 
: col ; 
List < GempakStation > stations = getStations ( ) ; 
if ( stations . isEmpty ( ) || stnIndex > stations . size ( ) ) { 
GempakStation station = getStations ( ) . get ( stnIndex - 1 ) ; 
builder . append ( "\nStation:\n" ) ; 
builder . append ( station . toString ( ) ) ; 
builder . append ( "\nObs\n\t" ) ; 
List < GempakParameter > params = getParameters ( SFDT ) ; 
for ( GempakParameter parm : params ) { 
builder . append ( StringUtil2 . padLeft ( parm . getName ( ) , 7 ) ) ; 
RData rd ; 
rd = DM_RDTR ( row , col , SFDT ) ; 
rd = null ; 
if ( rd == null ) { 
float [ ] data = rd . data ; 
builder . append ( StringUtil2 . padLeft ( Format . formatDouble ( data [ i ] , 7 , 1 ) , 7 ) ) ; 
int [ ] header = rd . header ; 
if ( header . length > 0 ) { 
builder . append ( header [ 0 ] ) ; 
GempakParameters . addParameters ( 
"resources/nj22/tables/gempak/params.tbl" ) ; 
GempakSurfaceFileReader gsfr = getInstance ( getFile ( args [ 0 ] ) , true ) ; 
gsfr . printFileLabel ( ) ; 
gsfr . printKeys ( ) ; 
gsfr . printHeaders ( ) ; 
gsfr . printParts ( ) ; 
int row = 1 ; 
int col = 1 ; 
if ( args . length > 1 ) { 
row = Integer . parseInt ( args [ 1 ] ) ; 
if ( args . length > 2 ) { 
col = Integer . parseInt ( args [ 2 ] ) ; 
gsfr . printOb ( row , col ) ; 
} private void writeHeadersAndBB ( ) { 
+ "?request=DescribeFeatureType" + WFSXMLHelper . AMPERSAND + "service=wfs" + WFSXMLHelper . AMPERSAND + "version=2.0.0" + WFSXMLHelper . AMPERSAND + "typename=" 
+ WFSController . TDSNAMESPACE + "%3A" + ftName ) 
+ WFSXMLHelper . encQuotes ( String . valueOf ( geometries . size ( ) ) ) + ">" ; 
double [ ] boundLower ; 
double [ ] boundUpper ; 
if ( geometries . isEmpty ( ) ) { 
boundLower = new double [ 2 ] ; boundUpper = new double [ 2 ] ; 
boundLower [ 0 ] = - 180 ; boundLower [ 1 ] = - 90 ; 
boundUpper [ 0 ] = 180 ; boundUpper [ 1 ] = 90 ; 
boundLower = geometries . get ( 0 ) . getBBLower ( ) ; 
boundUpper = geometries . get ( 0 ) . getBBUpper ( ) ; 
for ( SimpleGeometry item : geometries ) { 
double [ ] low = item . getBBLower ( ) ; 
if ( boundLower [ 0 ] > low [ 0 ] ) boundLower [ 0 ] = low [ 0 ] ; 
if ( boundLower [ 1 ] > low [ 1 ] ) boundLower [ 1 ] = low [ 1 ] ; 
double [ ] upper = item . getBBUpper ( ) ; 
if ( boundUpper [ 0 ] < upper [ 0 ] ) boundUpper [ 0 ] = upper [ 0 ] ; 
if ( boundUpper [ 1 ] < upper [ 1 ] ) boundUpper [ 1 ] = upper [ 1 ] ; 
boundLower [ 0 ] -= 10 ; boundLower [ 1 ] -= 10 ; 
boundUpper [ 0 ] += 10 ; boundUpper [ 1 ] += 10 ; 
fileOutput += "<wfs:boundedBy>" 
+ "</wfs:Envelope>" 
+ "</wfs:boundedBy>" ; 
} public void writeMembers ( ) { 
int index = 1 ; 
GMLFeatureWriter writer = new GMLFeatureWriter ( ) ; 
for ( SimpleGeometry geometryItem : geometries ) { 
double [ ] lowerCorner = geometryItem . getBBLower ( ) ; 
double [ ] upperCorner = geometryItem . getBBUpper ( ) ; 
fileOutput 
+= "<wfs:member>" 
+ "<gml:boundedBy>" 
+ "</gml:Envelope>" 
+ "</gml:boundedBy>" 
+ "<" + WFSController . TDSNAMESPACE + ":geometryInformation>" ; 
fileOutput += writer . writeFeature ( geometryItem ) ; 
+= "</" + WFSController . TDSNAMESPACE + ":geometryInformation>" 
+ "</" + WFSController . TDSNAMESPACE + ":" + ftName + ">" 
+ "</wfs:member>" ; 
} public String writeStationObsDatasetXML ( ) { 
return fmt . outputString ( makeStationObsDatasetDocument ( ) ) ; 
} public String writeStationCollectionXML ( ) throws IOException { 
return fmt . outputString ( makeStationCollectionDocument ( ) ) ; 
} public Document makeStationCollectionDocument ( ) throws IOException { 
Element rootElem = new Element ( "stationCollection" ) ; 
List stns = sobs . getStations ( ) ; 
for ( int i = 0 ; i < stns . size ( ) ; i ++ ) { 
ucar . unidata . geoloc . Station s = ( ucar . unidata . geoloc . Station ) stns . get ( i ) ; 
Element sElem = new Element ( "station" ) ; 
sElem . setAttribute ( "name" , s . getName ( ) ) ; 
if ( s . getWmoId ( ) != null ) 
sElem . setAttribute ( "wmo_id" , s . getWmoId ( ) ) ; 
if ( s . getDescription ( ) != null ) 
sElem . addContent ( new Element ( "description" ) . addContent ( s . getDescription ( ) ) ) ; 
sElem . addContent ( new Element ( "longitude" ) . addContent ( ucar . unidata . util . Format . d ( s . getLongitude ( ) , 6 ) ) ) ; 
sElem . addContent ( new Element ( "latitide" ) . addContent ( ucar . unidata . util . Format . d ( s . getLatitude ( ) , 6 ) ) ) ; 
if ( ! Double . isNaN ( s . getAltitude ( ) ) ) 
sElem . addContent ( new Element ( "altitude" ) . addContent ( ucar . unidata . util . Format . d ( s . getAltitude ( ) , 6 ) ) ) ; 
rootElem . addContent ( sElem ) ; 
} public Document makeStationObsDatasetDocument ( ) { 
Element rootElem = new Element ( "stationObsDataset" ) ; 
rootElem . setAttribute ( "location" , sobs . getLocationURI ( ) ) ; 
List vars = sobs . getDataVariables ( ) ; 
VariableSimpleIF v = ( VariableSimpleIF ) vars . get ( i ) ; 
rootElem . addContent ( writeVariable ( v ) ) ; 
LatLonRect bb = sobs . getBoundingBox ( ) ; 
Date start = sobs . getStartDate ( ) ; 
Date end = sobs . getEndDate ( ) ; 
DateFormatter format = new DateFormatter ( ) ; 
dateRange . addContent ( new Element ( "begin" ) . addContent ( format . toDateTimeStringISO ( start ) ) ) ; 
dateRange . addContent ( new Element ( "end" ) . addContent ( format . toDateTimeStringISO ( end ) ) ) ; 
Element elem = new Element ( "AcceptList" ) ; 
elem . addContent ( new Element ( "accept" ) . addContent ( "raw" ) ) ; 
elem . addContent ( new Element ( "accept" ) . addContent ( "xml" ) ) ; 
elem . addContent ( new Element ( "accept" ) . addContent ( "csv" ) ) ; 
elem . addContent ( new Element ( "accept" ) . addContent ( "netcdf" ) ) ; 
elem . addContent ( new Element ( "accept" ) . addContent ( "netcdfStream" ) ) ; 
String url = "C:/data/metars/Surface_METAR_20060326_0000.nc" ; 
StationObsDataset ncd = ( StationObsDataset ) TypedDatasetFactory . open ( FeatureType . STATION , url , null , new StringBuilder ( ) ) ; 
StationObsDatasetInfo info = new StationObsDatasetInfo ( ncd , null ) ; 
FileOutputStream fos2 = new FileOutputStream ( "C:/TEMP/stationCollection.xml" ) ; 
GZIPOutputStream zout = new GZIPOutputStream ( fos2 ) ; 
info . writeStationObsDatasetXML ( System . out ) ; 
info . writeStationCollectionXML ( zout ) ; 
zout . close ( ) ; 
File f = new File ( "C:/TEMP/stationCollection.xml" ) ; 
writeDSR ( String dsr ) 
if ( dsr == null ) 
int len = dsr . length ( ) ; 
while ( len > 0 ) { 
char c = dsr . charAt ( len - 1 ) ; 
if ( c != '\r' && c != '\n' ) break ; 
if ( dsr . length ( ) == 0 ) 
dsr = dsr . substring ( 0 , len ) + DapUtil . CRLF ; 
dsr = XMLDOCUMENTHEADER + "\n" + dsr ; 
byte [ ] dsr8 = DapUtil . extract ( DapUtil . UTF8 . encode ( dsr ) ) ; 
sendDXR ( dsr8 ) ; 
cacheDMR ( String dmr ) 
if ( dmr == null ) 
int len = dmr . length ( ) ; 
char c = dmr . charAt ( len - 1 ) ; 
if ( dmr . length ( ) == 0 ) 
dmr = dmr . substring ( 0 , len ) + DapUtil . CRLF ; 
dmr = XMLDOCUMENTHEADER + "\n" + dmr ; 
this . dmr8 = DapUtil . extract ( DapUtil . UTF8 . encode ( dmr ) ) ; 
state = State . DMR ; 
sendDXR ( byte [ ] dxr8 ) 
if ( dxr8 == null || dxr8 . length == 0 ) 
if ( mode == RequestMode . DMR || mode == RequestMode . DSR ) { 
int flags = DapUtil . CHUNK_DATA ; 
if ( this . writeorder == ByteOrder . LITTLE_ENDIAN ) 
flags |= DapUtil . CHUNK_LITTLE_ENDIAN ; 
chunkheader ( dxr8 . length , flags , this . header ) ; 
output . write ( DapUtil . extract ( this . header ) ) ; 
output . write ( dxr8 ) ; 
output . flush ( ) ; 
writeError ( int httpcode , 
String msg , 
String cxt , 
String other ) 
dmr8 = null ; 
ErrorResponse response = new ErrorResponse ( httpcode , msg , cxt , other ) ; 
String errorbody = response . buildXML ( ) ; 
byte [ ] errbody8 = DapUtil . extract ( DapUtil . UTF8 . encode ( errorbody ) ) ; 
if ( mode == RequestMode . DMR ) { 
sendDXR ( errbody8 ) ; 
chunk . clear ( ) ; 
int flags = DapUtil . CHUNK_ERROR | DapUtil . CHUNK_END ; 
chunkheader ( errbody8 . length , flags , header ) ; 
output . write ( DapUtil . extract ( header ) ) ; 
output . write ( errbody8 ) ; 
} void writeChunk ( int flags ) 
if ( chunk == null ) 
chunk = ByteBuffer . allocate ( maxbuffersize ) ; 
int buffersize = chunk . position ( ) ; 
chunkheader ( buffersize , flags , header ) ; 
if ( buffersize > 0 ) 
output . write ( chunk . array ( ) , 0 , buffersize ) ; 
if ( dmr8 != null ) { 
sendDXR ( dmr8 ) ; 
if ( mode == RequestMode . DMR ) 
if ( chunk == null || chunk . position ( ) == 0 ) 
verifystate ( ) ; 
int flags = DapUtil . CHUNK_END ; 
writeChunk ( flags ) ; 
this . output . flush ( ) ; 
if ( this . saveoutput != null ) { 
this . saveoutput . write ( ( ( ByteArrayOutputStream ) this . output ) . toByteArray ( ) ) ; 
flush ( ) 
public void write ( byte [ ] b , int off , int len ) 
if ( writecount + len >= writelimit ) 
. setCode ( DapCodes . SC_REQUESTED_RANGE_NOT_SATISFIABLE ) ; 
chunk = ByteBuffer . allocate ( maxbuffersize ) . order ( getWriteOrder ( ) ) ; 
if ( state == State . DMR ) { 
assert ( state == State . DATA ) ; 
if ( b . length < off + len ) 
throw new BufferUnderflowException ( ) ; 
int left = len ; 
int offset = off ; 
while ( left > 0 ) { 
int avail = chunk . remaining ( ) ; 
if ( avail == 0 ) { 
writeChunk ( DapUtil . CHUNK_DATA ) ; 
avail = chunk . remaining ( ) ; 
int towrite = ( left < avail ? left : avail ) ; 
chunk . put ( b , off , towrite ) ; 
left -= towrite ; 
avail -= towrite ; 
} while ( left > 0 ) ; 
writecount += len ; 
ProjectionImpl result = ( saveParams == null ) ? new UtmProjection ( getZone ( ) , isNorth ( ) ) : new UtmProjection ( saveParams . a , saveParams . f , getZone ( ) , isNorth ( ) ) ; 
return convert2xy . latLonToProj ( fromLat , fromLon , result ) ; 
return convert2latlon . projToLatLon ( world . getX ( ) , world . getY ( ) , result ) ; 
} public static void main ( String arg [ ] ) { 
UtmProjection utm = new UtmProjection ( 17 , true ) ; 
LatLonPoint ll = utm . projToLatLon ( 577.8000000000001 , 2951.8 ) ; 
assert Misc . nearlyEquals ( ll . getLongitude ( ) , - 80.21802662821469 , 1.0e-8 ) ; 
assert Misc . nearlyEquals ( ll . getLatitude ( ) , 26.685132668190793 , 1.0e-8 ) ; 
} public void addObs ( StationObsDatatype sobs ) { 
if ( null == obsList ) obsList = new ArrayList < StationObsDatatype > ( ) ; 
obsList . add ( sobs ) ; 
} public void scheduleTasks ( FeatureCollectionConfig config , Logger logger ) { 
if ( disabled || failed ) return ; 
if ( logger == null ) logger = fcLogger ; 
FeatureCollectionConfig . UpdateConfig updateConfig = ( isTdm ) ? config . tdmConfig : config . updateConfig ; 
if ( updateConfig == null || updateConfig . updateType == CollectionUpdateType . never ) return ; 
String collectionName = config . getCollectionName ( ) ; 
org . quartz . JobDataMap map = new org . quartz . JobDataMap ( ) ; 
map . put ( EVENT_BUS , eventBus ) ; 
map . put ( COLLECTION_NAME , collectionName ) ; 
map . put ( LOGGER , logger ) ; 
JobDetail updateJob = JobBuilder . newJob ( UpdateCollectionJob . class ) 
. withIdentity ( collectionName , "UpdateCollection" ) 
. storeDurably ( ) 
. usingJobData ( map ) 
if ( ! scheduler . checkExists ( updateJob . getKey ( ) ) ) { 
scheduler . addJob ( updateJob , false ) ; 
if ( updateConfig . startupType != CollectionUpdateType . never ) { 
map = new org . quartz . JobDataMap ( ) ; 
map . put ( UpdateType , updateConfig . startupType ) ; 
map . put ( Source , "startup" ) ; 
Date runTime = new Date ( new Date ( ) . getTime ( ) + startupWait ) ; 
SimpleTrigger startupTrigger = ( SimpleTrigger ) TriggerBuilder . newTrigger ( ) 
. withIdentity ( collectionName , "startup" ) 
. startAt ( runTime ) 
. forJob ( updateJob ) 
scheduler . scheduleJob ( startupTrigger ) ; 
if ( updateConfig . rescan != null ) { 
map . put ( UpdateType , updateConfig . updateType ) ; 
map . put ( Source , "rescan" ) ; 
CronTrigger rescanTrigger = TriggerBuilder . newTrigger ( ) 
. withIdentity ( collectionName , "rescan" ) 
. withSchedule ( CronScheduleBuilder . cronSchedule ( updateConfig . rescan ) ) 
scheduler . scheduleJob ( rescanTrigger ) ; 
} public boolean contains ( int want ) { 
if ( want < first ( ) ) 
if ( want > last ( ) ) 
if ( stride == 1 ) return true ; 
return ( want - first ) % stride == 0 ; 
} public Range compose ( Range r ) throws InvalidRangeException { 
if ( ( length ( ) == 0 ) || ( r . length ( ) == 0 ) ) 
return EMPTY ; 
if ( this == VLEN || r == VLEN ) 
return VLEN ; 
int sr_stride = this . stride * r . stride ; 
int sr_first = element ( r . first ( ) ) ; 
int lastx = element ( r . last ( ) ) ; 
int sr_last = ( last ( ) < lastx ? last ( ) : lastx ) ; 
return new Range ( name , sr_first , sr_last , sr_stride ) ; 
} public Range compact ( ) throws InvalidRangeException { 
if ( stride == 1 ) return this ; 
int first = first ( ) / stride ; 
int last = first + length ( ) - 1 ; 
return new Range ( name , first , last , 1 ) ; 
} public int element ( int i ) throws InvalidRangeException { 
if ( i >= length ) 
return first + i * stride ; 
} public int index ( int want ) throws InvalidRangeException { 
if ( want < first ) 
int result = ( want - first ) / stride ; 
if ( result > length ) 
} public Range intersect ( Range r ) throws InvalidRangeException { 
int last = Math . min ( this . last ( ) , r . last ( ) ) ; 
int resultStride = stride * r . stride ( ) ; 
int useFirst ; 
if ( resultStride == 1 ) { 
useFirst = Math . max ( this . first ( ) , r . first ( ) ) ; 
} else if ( stride == 1 ) { 
if ( r . first ( ) >= first ( ) ) 
useFirst = r . first ( ) ; 
int incr = ( first ( ) - r . first ( ) ) / resultStride ; 
useFirst = r . first ( ) + incr * resultStride ; 
if ( useFirst < first ( ) ) useFirst += resultStride ; 
} else if ( r . stride == 1 ) { 
if ( first ( ) >= r . first ( ) ) 
useFirst = first ( ) ; 
int incr = ( r . first ( ) - first ( ) ) / resultStride ; 
useFirst = first ( ) + incr * resultStride ; 
if ( useFirst < r . first ( ) ) useFirst += resultStride ; 
if ( useFirst > last ) 
return new Range ( name , useFirst , last , resultStride ) ; 
} public boolean intersects ( Range r ) { 
} else if ( r . stride ( ) == 1 ) { 
return ( useFirst <= last ) ; 
} public Range shiftOrigin ( int origin ) throws InvalidRangeException { 
if ( this == VLEN ) 
int first = first ( ) - origin ; 
int last = last ( ) - origin ; 
return new Range ( name , first , last , stride ) ; 
} public Range union ( Range r ) throws InvalidRangeException { 
if ( length ( ) == 0 ) 
if ( r . length ( ) == 0 ) 
int first = Math . min ( this . first ( ) , r . first ( ) ) ; 
int last = Math . max ( this . last ( ) , r . last ( ) ) ; 
return new Range ( name , first , last ) ; 
} public int getFirstInInterval ( int start ) { 
if ( start > last ( ) ) return - 1 ; 
if ( start <= first ) return first ; 
if ( stride == 1 ) return start ; 
int offset = start - first ; 
int i = offset / stride ; 
i = ( offset % stride == 0 ) ? i : i + 1 ; 
} static ArrayLong factory ( Index index , boolean isUnsigned ) { 
return ArrayLong . factory ( index , isUnsigned , null ) ; 
long [ ] ja = ( long [ ] ) javaArray ; 
for ( long aJa : ja ) iter . setLongNext ( aJa ) ; 
} protected Object readData ( Layout index , DataType dataType ) throws java . io . IOException { 
return IospHelper . readDataFill ( raf , index , dataType , null , - 1 ) ; 
} protected long readData ( Layout index , DataType dataType , WritableByteChannel out ) throws java . io . IOException { 
long count = 0 ; 
count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , chunk . getNelems ( ) ) ; 
count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 2 * chunk . getNelems ( ) ) ; 
} else if ( dataType . getPrimitiveClassType ( ) == int . class || ( dataType == DataType . FLOAT ) ) { 
count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 4 * chunk . getNelems ( ) ) ; 
} else if ( ( dataType == DataType . DOUBLE ) || dataType . getPrimitiveClassType ( ) == long . class ) { 
count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 8 * chunk . getNelems ( ) ) ; 
} protected void writeData ( Array values , Layout index , DataType dataType ) throws java . io . IOException { 
if ( ( dataType == DataType . BYTE ) || ( dataType == DataType . CHAR ) ) { 
for ( int k = 0 ; k < chunk . getNelems ( ) ; k ++ ) 
raf . write ( ii . getByteNext ( ) ) ; 
for ( int k = 0 ; k < chunk . getNelems ( ) ; k ++ ) { 
String val = ( String ) ii . getObjectNext ( ) ; 
if ( val != null ) raf . write ( val . getBytes ( CDM . utf8Charset ) ) ; 
raf . writeShort ( ii . getShortNext ( ) ) ; 
raf . writeInt ( ii . getIntNext ( ) ) ; 
raf . writeFloat ( ii . getFloatNext ( ) ) ; 
raf . writeDouble ( ii . getDoubleNext ( ) ) ; 
Dimension obsDim = Evaluator . getDimension ( ds , "recNum" , errlog ) ; 
VNames vn = getVariableNames ( ds , errlog ) ; 
String levVarName = null ; 
String levDimName = null ; 
FeatureType ft = Evaluator . getFeatureType ( ds , ":thredds_data_type" , errlog ) ; 
if ( null == ft ) { 
if ( ( ds . findDimension ( "manLevel" ) != null ) && ( ds . findVariable ( "prMan" ) != null ) ) { 
ft = FeatureType . STATION_PROFILE ; 
levVarName = "prMan" ; 
levDimName = "manLevel" ; 
} else if ( ( ds . findDimension ( "level" ) != null ) && ( ds . findVariable ( "levels" ) != null ) ) { 
levVarName = "levels" ; 
levDimName = "level" ; 
if ( null == ft ) ft = FeatureType . POINT ; 
if ( ( wantFeatureType == FeatureType . POINT ) || ( ft == FeatureType . POINT ) ) { 
TableConfig ptTable = new TableConfig ( Table . Type . Structure , hasStruct ? "record" : obsDim . getShortName ( ) ) ; 
ptTable . structName = "record" ; 
ptTable . featureType = FeatureType . POINT ; 
ptTable . structureType = hasStruct ? TableConfig . StructureType . Structure : TableConfig . StructureType . PsuedoStructure ; 
ptTable . dimName = obsDim . getShortName ( ) ; 
ptTable . time = vn . obsTime ; 
ptTable . timeNominal = vn . nominalTime ; 
ptTable . lat = vn . lat ; 
ptTable . lon = vn . lon ; 
ptTable . elev = vn . elev ; 
return ptTable ; 
if ( ft == FeatureType . STATION ) { 
TableConfig stnTable = new TableConfig ( Table . Type . Construct , "station" ) ; 
stnTable . featureType = FeatureType . STATION ; 
TableConfig obs = new TableConfig ( Table . Type . ParentId , "record" ) ; 
obs . parentIndex = vn . stnId ; 
obs . dimName = Evaluator . getDimensionName ( ds , "recNum" , errlog ) ; 
obs . time = vn . obsTime ; 
obs . timeNominal = vn . nominalTime ; 
obs . stnId = vn . stnId ; 
obs . stnDesc = vn . stnDesc ; 
obs . lat = vn . lat ; 
obs . lon = vn . lon ; 
obs . elev = vn . elev ; 
stnTable . addChild ( obs ) ; 
else if ( ft == FeatureType . STATION_PROFILE ) { 
stnTable . featureType = FeatureType . STATION_PROFILE ; 
obs . stnAlt = vn . elev ; 
TableConfig lev = new TableConfig ( Table . Type . MultidimInner , "mandatory" ) ; 
lev . elev = levVarName ; 
lev . outerName = obs . dimName ; 
lev . innerName = levDimName ; 
obs . addChild ( lev ) ; 
boolean hasStride = false ; 
if ( debugRead ) { 
for ( int i = 0 ; i < numDimensions ( ) ; i ++ ) { 
DArrayDimension d = getDimension ( i ) ; 
int [ ] origin = new int [ n + 1 ] ; 
int [ ] shape = new int [ n + 1 ] ; 
origin [ i ] = getStart ( i ) ; 
shape [ i ] = getStop ( i ) - getStart ( i ) + 1 ; 
hasStride = hasStride || ( getStride ( i ) > 1 ) ; 
origin [ n ] = 0 ; 
shape [ n ] = strLen ; 
a = ncVar . read ( origin , shape ) ; 
if ( hasStride ) { 
int s = getStride ( i ) ; 
if ( s > 1 ) { 
ranges . add ( new Range ( 0 , shape [ i ] , s ) ) ; 
ranges . add ( null ) ; 
a = a . section ( ranges ) ; 
sink . writeBoolean ( vals [ i ] ) ; 
for ( int i = start ; i <= stop ; i += stride ) 
} public PrimitiveVector subset ( int start , int stop , int stride ) { 
BooleanPrimitiveVector n = new BooleanPrimitiveVector ( getTemplate ( ) ) ; 
stride = Math . max ( stride , 1 ) ; 
stop = Math . max ( start , stop ) ; 
int length = 1 + ( stop - start ) / stride ; 
n . setLength ( length ) ; 
n . setValue ( count , vals [ i ] ) ; 
BooleanPrimitiveVector v = ( BooleanPrimitiveVector ) super . cloneDAG ( map ) ; 
if ( vals != null ) { 
v . vals = new boolean [ vals . length ] ; 
System . arraycopy ( vals , 0 , v . vals , 0 , vals . length ) ; 
} static DataType setDataType ( short type , Variable v ) { 
DataType dt ; 
dt = DataType . UBYTE ; 
dt = DataType . CHAR ; 
dt = DataType . FLOAT ; 
dt = DataType . DOUBLE ; 
dt = DataType . BYTE ; 
dt = DataType . SHORT ; 
dt = DataType . USHORT ; 
dt = DataType . INT ; 
dt = DataType . UINT ; 
dt = DataType . LONG ; 
dt = DataType . ULONG ; 
v . setDataType ( dt ) ; 
} public Iterable < ? extends CatalogExt > getCatalogs ( ) { 
if ( catalogs == null ) readCatalogs ( ) ; 
List < CatalogExt > result = new ArrayList < > ( ) ; 
for ( CatalogExt ext : catalogs . values ( ) ) 
result . add ( ext ) ; 
Collections . sort ( result , ( o1 , o2 ) -> o1 . getCatRelLocation ( ) . compareTo ( o2 . getCatRelLocation ( ) ) ) ; 
public void addEntry ( String urlpath , String fileprefix ) 
String urlprefix = DapUtil . canonicalpath ( urlpath ) ; 
fileprefix = DapUtil . canonicalpath ( fileprefix ) ; 
url2path . put ( urlprefix , fileprefix ) ; 
path2url . put ( fileprefix , urlprefix ) ; 
} public void load ( String filepath ) 
String [ ] lines ; 
try ( InputStream is = new FileInputStream ( filepath ) ; ) { 
String content = DapUtil . readtextfile ( is ) ; 
lines = content . split ( "[\n]" ) ; 
String [ ] pieces = line . split ( "[=]" ) ; 
if ( pieces . length != 2 ) 
addEntry ( pieces [ 0 ] , pieces [ 1 ] ) ; 
public Result 
mapURL ( String urlpath ) 
urlpath = DapUtil . canonicalpath ( urlpath ) ; 
Result result = longestmatch ( url2path , urlpath ) ; 
} public static void cleanupBefore ( String pathname , long trackerNumber ) { 
for ( long tnum = trackerNumber - 1 ; tnum > 0 ; tnum -- ) { 
File oldDatabaseFile = new File ( pathname + datasetName + "." + tnum ) ; 
if ( ! oldDatabaseFile . exists ( ) ) break ; 
if ( oldDatabaseFile . delete ( ) ) { 
} public void setValues ( float [ ] values ) { 
vals = values ; 
proj = GempakUtil . ST_ITOC ( Float . floatToIntBits ( vals [ 1 ] ) ) . trim ( ) ; 
addParam ( PROJ , proj ) ; 
addParam ( GDS_KEY , this . toString ( ) ) ; 
setParams ( ) ; 
} private void setParams ( ) { 
String angle1 = String . valueOf ( vals [ 10 ] ) ; 
String angle2 = String . valueOf ( vals [ 11 ] ) ; 
String angle3 = String . valueOf ( vals [ 12 ] ) ; 
String lllat = String . valueOf ( vals [ 6 ] ) ; 
String lllon = String . valueOf ( vals [ 7 ] ) ; 
String urlat = String . valueOf ( vals [ 8 ] ) ; 
String urlon = String . valueOf ( vals [ 9 ] ) ; 
addParam ( NX , String . valueOf ( vals [ 4 ] ) ) ; 
addParam ( NY , String . valueOf ( vals [ 5 ] ) ) ; 
addParam ( LA1 , lllat ) ; 
addParam ( LO1 , lllon ) ; 
addParam ( LA2 , urlat ) ; 
addParam ( LO2 , urlon ) ; 
switch ( proj ) { 
case "STR" : 
case "NPS" : 
case "SPS" : 
addParam ( LOV , angle2 ) ; 
if ( proj . equals ( "SPS" ) ) { 
addParam ( "NpProj" , "false" ) ; 
case "LCC" : 
case "SCC" : 
addParam ( LATIN1 , angle1 ) ; 
addParam ( LATIN2 , angle3 ) ; 
case "MER" : 
case "MCD" : 
String standardLat ; 
if ( vals [ 10 ] == 0 ) { 
float lat = ( vals [ 8 ] + vals [ 6 ] ) / 2 ; 
standardLat = String . valueOf ( lat ) ; 
standardLat = angle1 ; 
addParam ( "Latin" , standardLat ) ; 
case "CED" : 
double lllatv = vals [ 6 ] ; 
double lllonv = vals [ 7 ] ; 
double urlatv = vals [ 8 ] ; 
double urlonv = vals [ 9 ] ; 
if ( urlonv <= lllonv ) { 
urlonv += 360. ; 
double dx = Math . abs ( ( urlonv - lllonv ) / ( vals [ 4 ] - 1 ) ) ; 
double dy = Math . abs ( ( urlatv - lllatv ) / ( vals [ 5 ] - 1 ) ) ; 
addParam ( DX , String . valueOf ( dx ) ) ; 
addParam ( DY , String . valueOf ( dy ) ) ; 
addParam ( LO2 , String . valueOf ( urlonv ) ) ; 
} public void writeGrid ( String gridDataset_filename , String gridName , int time , int level , boolean greyScale , LatLonRect pt ) throws IOException { 
try ( GridDataset dataset = ucar . nc2 . dt . grid . GridDataset . open ( gridDataset_filename ) ) { 
GridDatatype grid = dataset . findGridDatatype ( gridName ) ; 
if ( grid == null ) { 
ProjectionImpl proj = grid . getProjection ( ) ; 
if ( ! gcs . isRegularSpatial ( ) ) { 
Attribute att = dataset . findGlobalAttributeIgnoreCase ( "datasetId" ) ; 
if ( att != null && att . getStringValue ( ) . contains ( "DMSP" ) ) { 
writeSwathGrid ( gridDataset_filename , gridName , time , level , greyScale , pt ) ; 
CoordinateAxis1D xaxis = ( CoordinateAxis1D ) gcs . getXHorizAxis ( ) ; 
CoordinateAxis1D yaxis = ( CoordinateAxis1D ) gcs . getYHorizAxis ( ) ; 
if ( ! xaxis . isRegular ( ) || ! yaxis . isRegular ( ) ) { 
Array data = grid . readDataSlice ( time , level , - 1 , - 1 ) ; 
Array lon = xaxis . read ( ) ; 
Array lat = yaxis . read ( ) ; 
double scaler = ( xaxis . getUnitsString ( ) . equalsIgnoreCase ( "km" ) ) ? 1000.0 : 1.0 ; 
if ( yaxis . getCoordValue ( 0 ) < yaxis . getCoordValue ( 1 ) ) { 
data = data . flip ( 0 ) ; 
lat = lat . flip ( 0 ) ; 
if ( gcs . isLatLon ( ) ) { 
data = geoShiftDataAtLon ( data , lon ) ; 
lon = geoShiftLon ( lon ) ; 
LatLonPointImpl llp0 = pt . getLowerLeftPoint ( ) ; 
LatLonPointImpl llpn = pt . getUpperRightPoint ( ) ; 
double minLon = llp0 . getLongitude ( ) ; 
double minLat = llp0 . getLatitude ( ) ; 
double maxLon = llpn . getLongitude ( ) ; 
double maxLat = llpn . getLatitude ( ) ; 
int x1 ; 
int x2 ; 
int y1 ; 
int y2 ; 
double xStart ; 
double yStart ; 
if ( ! gcs . isLatLon ( ) ) { 
ProjectionPoint pjp0 = proj . latLonToProj ( maxLat , minLon ) ; 
x1 = getXIndex ( lon , pjp0 . getX ( ) , 0 ) ; 
y1 = getYIndex ( lat , pjp0 . getY ( ) , 0 ) ; 
yStart = pjp0 . getY ( ) * 1000.0 ; 
xStart = pjp0 . getX ( ) * 1000.0 ; 
ProjectionPoint pjpn = proj . latLonToProj ( minLat , maxLon ) ; 
x2 = getXIndex ( lon , pjpn . getX ( ) , 1 ) ; 
y2 = getYIndex ( lat , pjpn . getY ( ) , 1 ) ; 
xStart = minLon ; 
yStart = maxLat ; 
x1 = getLonIndex ( lon , minLon , 0 ) ; 
y1 = getLatIndex ( lat , maxLat , 0 ) ; 
x2 = getLonIndex ( lon , maxLon , 1 ) ; 
y2 = getLatIndex ( lat , minLat , 1 ) ; 
double xInc = xaxis . getIncrement ( ) * scaler ; 
double yInc = Math . abs ( yaxis . getIncrement ( ) ) * scaler ; 
Array data1 = getYXDataInBox ( data , x1 , x2 , y1 , y2 ) ; 
if ( pageNumber > 1 ) { 
geotiff . initTags ( ) ; 
writeGrid ( grid , data1 , greyScale , xStart , yStart , xInc , yInc , pageNumber ) ; 
pageNumber ++ ; 
} private void writeSwathGrid ( String fileName , String gridName , int time , int level , boolean greyScale , LatLonRect llr ) throws IOException { 
GridDataset dataset = ucar . nc2 . dt . grid . GridDataset . open ( fileName ) ; 
CoordinateAxis2D xaxis = ( CoordinateAxis2D ) gcs . getXHorizAxis ( ) ; 
CoordinateAxis2D yaxis = ( CoordinateAxis2D ) gcs . getYHorizAxis ( ) ; 
double [ ] swathInfo = getSwathLatLonInformation ( lat , lon ) ; 
double minLon ; 
double minLat ; 
double maxLon ; 
double maxLat ; 
double xInc = swathInfo [ 0 ] * scaler ; 
double yInc = swathInfo [ 1 ] * scaler ; 
if ( llr == null ) { 
minLon = swathInfo [ 4 ] ; 
minLat = swathInfo [ 2 ] ; 
maxLon = swathInfo [ 5 ] ; 
maxLat = swathInfo [ 3 ] ; 
x1 = 0 ; 
y1 = 0 ; 
x2 = ( int ) ( ( maxLon - minLon ) / xInc + 0.5 ) ; 
y2 = ( int ) ( ( maxLat - minLat ) / yInc + 0.5 ) ; 
LatLonPointImpl llp0 = llr . getLowerLeftPoint ( ) ; 
LatLonPointImpl llpn = llr . getUpperRightPoint ( ) ; 
minLon = ( llp0 . getLongitude ( ) < swathInfo [ 4 ] ) 
? swathInfo [ 4 ] 
: llp0 . getLongitude ( ) ; 
minLat = ( llp0 . getLatitude ( ) < swathInfo [ 2 ] ) 
? swathInfo [ 2 ] 
: llp0 . getLatitude ( ) ; 
maxLon = ( llpn . getLongitude ( ) > swathInfo [ 5 ] ) 
? swathInfo [ 5 ] 
: llpn . getLongitude ( ) ; 
maxLat = ( llpn . getLatitude ( ) > swathInfo [ 3 ] ) 
? swathInfo [ 3 ] 
: llpn . getLatitude ( ) ; 
LatLonPointImpl pUpLeft = new LatLonPointImpl ( swathInfo [ 3 ] , swathInfo [ 4 ] ) ; 
LatLonPointImpl pDownRight = new LatLonPointImpl ( swathInfo [ 2 ] , swathInfo [ 5 ] ) ; 
LatLonRect swathLLR = new LatLonRect ( pUpLeft , pDownRight ) ; 
LatLonRect bIntersect = swathLLR . intersect ( llr ) ; 
if ( bIntersect == null ) { 
x1 = ( int ) ( ( minLon - swathInfo [ 4 ] ) / xInc + 0.5 ) ; 
y1 = ( int ) Math . abs ( ( maxLat - swathInfo [ 3 ] ) / yInc + 0.5 ) ; 
x2 = ( int ) ( ( maxLon - swathInfo [ 4 ] ) / xInc + 0.5 ) ; 
y2 = ( int ) Math . abs ( ( minLat - swathInfo [ 3 ] ) / yInc + 0.5 ) ; 
yStart = pjp0 . getY ( ) * scaler ; 
xStart = pjp0 . getX ( ) * scaler ; 
Array targetImage = getTargetImagerFromSwath ( lat , lon , data , swathInfo ) ; 
Array interpolatedImage = interpolation ( targetImage ) ; 
Array clippedImage = getClippedImageFromInterpolation ( interpolatedImage , x1 , x2 , y1 , y2 ) ; 
writeGrid ( grid , clippedImage , greyScale , xStart , yStart , xInc , yInc , pageNumber ) ; 
} private Array interpolation ( Array arr ) { 
int [ ] orishape = arr . getShape ( ) ; 
int width = orishape [ 1 ] ; 
int height = orishape [ 0 ] ; 
int pixelNum = width * height ; 
Array interpolatedArray = Array . factory ( DataType . FLOAT , orishape ) ; 
for ( int i = 0 ; i < height ; i ++ ) { 
for ( int j = 0 ; j < width ; j ++ ) { 
int curIndex = i * width + j ; 
float curValue = arr . getFloat ( curIndex ) ; 
if ( curValue == 0 ) 
float tempPixelSum = 0 ; 
int numNeighborHasValue = 0 ; 
if ( ( curIndex - 1 >= 0 ) && ( curIndex - 1 < pixelNum ) ) { 
float left = arr . getFloat ( curIndex - 1 ) ; 
if ( left > 0 ) { 
tempPixelSum += left ; 
numNeighborHasValue ++ ; 
if ( ( curIndex + 1 >= 0 ) && ( curIndex + 1 < pixelNum ) ) { 
float right = arr . getFloat ( curIndex + 1 ) ; 
if ( right > 0 ) { 
tempPixelSum += right ; 
if ( ( curIndex - width >= 0 ) && ( curIndex - width < pixelNum ) ) { 
float up = arr . getFloat ( curIndex - width ) ; 
if ( up > 0 ) { 
tempPixelSum += up ; 
if ( ( curIndex + width >= 0 ) && ( curIndex + width < pixelNum ) ) { 
float down = arr . getFloat ( curIndex + width ) ; 
if ( down > 0 ) { 
tempPixelSum += down ; 
if ( ( curIndex - width - 1 >= 0 ) && ( curIndex - width - 1 < pixelNum ) ) { 
float upleft = arr . getFloat ( curIndex - width - 1 ) ; 
if ( upleft > 0 ) { 
tempPixelSum += upleft ; 
if ( ( curIndex - width + 1 >= 0 ) && ( curIndex - width + 1 < pixelNum ) ) { 
float upright = arr . getFloat ( curIndex - width + 1 ) ; 
if ( upright > 0 ) { 
tempPixelSum += upright ; 
if ( ( curIndex + width - 1 >= 0 ) && ( curIndex + width - 1 < pixelNum ) ) { 
float downleft = arr . getFloat ( curIndex + width - 1 ) ; 
if ( downleft > 0 ) { 
tempPixelSum += downleft ; 
if ( ( curIndex + width + 1 >= 0 ) && ( curIndex + width + 1 < pixelNum ) ) { 
float downright = arr . getFloat ( curIndex + width + 1 ) ; 
if ( downright > 0 ) { 
tempPixelSum += downright ; 
if ( tempPixelSum > 0 ) { 
float val = numNeighborHasValue == 0 ? 0 : tempPixelSum / numNeighborHasValue ; 
interpolatedArray . setFloat ( curIndex , val ) ; 
interpolatedArray . setFloat ( curIndex , curValue ) ; 
return interpolatedArray ; 
} private double [ ] getSwathLatLonInformation ( Array lat , Array lon ) { 
double increment [ ] = { 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 } ; 
IndexIterator latIter = lat . getIndexIterator ( ) ; 
IndexIterator lonIter = lon . getIndexIterator ( ) ; 
int numScan = ( lat . getShape ( ) ) [ 0 ] ; 
int numSample = ( lat . getShape ( ) ) [ 1 ] ; 
double maxLat = - 91 , 
minLat = 91 , 
maxLon = - 181 , 
minLon = 181 ; 
float firstLineStartLat = 0 ; 
float firstLineStartLon = 0 ; 
float firstLineEndLat = 0 ; 
float firstLineEndLon = 0 ; 
float lastLineStartLat = 0 ; 
float lastLineStartLon = 0 ; 
float lastLineEndLat = 0 ; 
float lastLineEndLon = 0 ; 
for ( int i = 0 ; i < numScan ; i ++ ) { 
for ( int j = 0 ; j < numSample ; j ++ ) { 
if ( latIter . hasNext ( ) && lonIter . hasNext ( ) ) { 
float curLat = latIter . getFloatNext ( ) ; 
float curLon = lonIter . getFloatNext ( ) ; 
if ( ( i == 0 ) && ( j == 0 ) ) { 
firstLineStartLat = curLat ; 
firstLineStartLon = curLon ; 
} else if ( ( i == 0 ) && ( j == numSample - 1 ) ) { 
firstLineEndLat = curLat ; 
firstLineEndLon = curLon ; 
} else if ( ( i == numScan - 1 ) && ( j == 0 ) ) { 
lastLineStartLat = curLat ; 
lastLineStartLon = curLon ; 
} else if ( ( i == numScan - 1 ) && ( j == numSample - 1 ) ) { 
lastLineEndLat = curLat ; 
lastLineEndLon = curLon ; 
double [ ] edgeLat = { firstLineStartLat , firstLineEndLat , lastLineStartLat , lastLineEndLat } ; 
double [ ] edgeLon = { firstLineStartLon , firstLineEndLon , lastLineStartLon , lastLineEndLon } ; 
for ( int i = 0 ; i < edgeLat . length ; i ++ ) { 
maxLat = ( ( maxLat > edgeLat [ i ] ) 
? maxLat 
: edgeLat [ i ] ) ; 
minLat = ( ( minLat < edgeLat [ i ] ) 
? minLat 
maxLon = ( ( maxLon > edgeLon [ i ] ) 
? maxLon 
: edgeLon [ i ] ) ; 
minLon = ( ( minLon < edgeLon [ i ] ) 
? minLon 
double xInc1 = Math . abs ( ( firstLineEndLon - firstLineStartLon ) / numSample ) ; 
double yInc1 = Math . abs ( ( lastLineStartLat - firstLineStartLat ) / numScan ) ; 
increment [ 0 ] = xInc1 ; 
increment [ 1 ] = yInc1 ; 
increment [ 2 ] = minLat ; 
increment [ 3 ] = maxLat ; 
increment [ 4 ] = minLon ; 
increment [ 5 ] = maxLon ; 
increment [ 6 ] = ( maxLon - minLon ) / xInc1 ; 
increment [ 7 ] = ( maxLat - minLat ) / yInc1 ; 
return increment ; 
} LayoutTiled . DataChunkIterator getDataChunkIteratorNoFilter ( Section want , int nChunkDim ) throws IOException { 
return new DataChunkIteratorNoFilter ( want , nChunkDim ) ; 
double [ ] [ ] xy = anav . toLinEle ( new double [ ] [ ] { { fromLat } , { fromLon } } ) ; 
if ( xy == null ) return null ; 
toX = xy [ 0 ] [ 0 ] ; 
toY = xy [ 1 ] [ 0 ] ; 
double [ ] [ ] latlon = anav . toLatLon ( new double [ ] [ ] { { fromX } , { fromY } } ) ; 
toLat = latlon [ 0 ] [ 0 ] ; 
toLon = latlon [ 1 ] [ 0 ] ; 
} public float [ ] [ ] latLonToProj ( float [ ] [ ] from , float [ ] [ ] to , int latIndex , int lonIndex ) { 
float [ ] [ ] xy = anav . toLinEle ( new float [ ] [ ] { fromLatA , fromLonA } ) ; 
to [ INDEX_X ] = xy [ 0 ] ; 
to [ INDEX_Y ] = xy [ 1 ] ; 
float [ ] [ ] latlon = anav . toLatLon ( new float [ ] [ ] { fromXA , fromYA } ) ; 
to [ INDEX_LAT ] = latlon [ 0 ] ; 
to [ INDEX_LON ] = latlon [ 1 ] ; 
if ( Double . isNaN ( pt1 . getX ( ) ) || Double . isNaN ( pt1 . getY ( ) ) || Double . isNaN ( pt2 . getX ( ) ) || Double . isNaN ( pt2 . getY ( ) ) ) { 
return ( pt1 . getX ( ) * pt2 . getX ( ) < 0 ) 
&& ( Math . abs ( pt1 . getX ( ) - pt2 . getX ( ) ) > 5000.0 ) ; 
} private double [ ] makeDoubleArray ( int [ ] ints ) { 
double [ ] newArray = new double [ ints . length ] ; 
for ( int i = 0 ; i < ints . length ; i ++ ) { 
newArray [ i ] = ints [ i ] ; 
} @ RequestMapping ( value = { "**/dataset.xml" , "**/pointDataset.xml" } ) 
public ModelAndView getDatasetDescriptionXml ( HttpServletRequest req , HttpServletResponse res ) throws IOException { 
String datasetPath = getDatasetPath ( req ) ; 
try ( CoverageCollection gcd = TdsRequestedDataset . getCoverageCollection ( req , res , datasetPath ) ) { 
if ( gcd == null ) return null ; 
String datasetUrlPath = buildDatasetUrl ( datasetPath ) ; 
CoverageDatasetCapabilities writer = new CoverageDatasetCapabilities ( gcd , "path" ) ; 
Document doc = writer . makeDatasetDescription ( ) ; 
root . setAttribute ( "location" , datasetUrlPath ) ; 
root . addContent ( makeAcceptXML ( SupportedOperation . GRID_REQUEST ) ) ; 
return new ModelAndView ( "threddsXmlView" , "Document" , doc ) ; 
} @ RequestMapping ( "**/datasetBoundaries.xml" ) 
public void getDatasetBoundaries ( NcssParamsBean params , HttpServletRequest req , HttpServletResponse res ) 
throws IOException , UnsupportedResponseFormatException { 
SupportedFormat format = SupportedOperation . DATASET_BOUNDARIES_REQUEST . getSupportedFormat ( params . getAccept ( ) ) ; 
case WKT : getDatasetBoundariesWKT ( req , res ) ; break ; 
case JSON : getDatasetBoundariesGeoJSON ( req , res ) ; break ; 
default : throw new IllegalArgumentException ( String . format ( 
} private void checkRequestedVars ( CoverageCollection gcd , NcssGridParamsBean params ) 
throws VariableNotContainedInDatasetException { 
if ( params . getVar ( ) . get ( 0 ) . equalsIgnoreCase ( "all" ) ) { 
params . setVar ( getAllGridNames ( gcd ) ) ; 
for ( String gridName : params . getVar ( ) ) { 
Coverage grid = gcd . findCoverage ( gridName ) ; 
if ( grid == null ) 
throw new VariableNotContainedInDatasetException ( 
} protected boolean checkVarsHaveSameVertAxis ( CoverageCollection gcd , NcssGridParamsBean params ) { 
String zaxisName = null ; 
CoverageCoordAxis zaxis = grid . getCoordSys ( ) . getZAxis ( ) ; 
if ( zaxis != null ) { 
if ( zaxisName == null ) 
zaxisName = zaxis . getName ( ) ; 
else if ( ! zaxisName . equals ( zaxis . getName ( ) ) ) 
} static public Stereographic factory ( double latt , double lont , double latTrue ) { 
double scale = ( 1.0 + Math . sin ( Math . toRadians ( latTrue ) ) ) / 2.0 ; 
return new Stereographic ( latt , lont , scale ) ; 
} private double getScaleFactor ( double lat_ts , boolean north ) { 
double e = 0.081819191 ; 
double tf = 1.0 , mf = 1.0 , k0 = 1.0 ; 
double root = ( 1 + e * Math . sin ( lat_ts ) ) / ( 1 - e * Math . sin ( lat_ts ) ) ; 
double power = e / 2 ; 
if ( north ) 
tf = Math . tan ( Math . PI / 4 - lat_ts / 2 ) * ( Math . pow ( root , power ) ) ; 
tf = Math . tan ( Math . PI / 4 + lat_ts / 2 ) / ( Math . pow ( root , power ) ) ; 
mf = Math . cos ( lat_ts ) / Math . sqrt ( 1 - e * e * Math . pow ( Math . sin ( lat_ts ) , 2 ) ) ; 
k0 = mf * Math . sqrt ( Math . pow ( 1 + e , 1 + e ) * Math . pow ( 1 - e , 1 - e ) ) / ( 2 * tf ) ; 
return Double . isNaN ( k0 ) ? 1.0 : k0 ; 
if ( ( Math . abs ( lat + latt ) <= TOLERANCE ) ) { 
lat = - latt * ( 1.0 - TOLERANCE ) ; 
double sdlon = Math . sin ( lon - lont ) ; 
double cdlon = Math . cos ( lon - lont ) ; 
double sinlat = Math . sin ( lat ) ; 
double coslat = Math . cos ( lat ) ; 
double k = 2.0 * scale 
/ ( 1.0 + sinlatt * sinlat + coslatt * coslat * cdlon ) ; 
toX = k * coslat * sdlon ; 
toY = k * ( coslatt * sinlat - sinlatt * coslat * cdlon ) ; 
double phi , lam ; 
double c = 2.0 * Math . atan2 ( rho , 2.0 * scale ) ; 
double sinc = Math . sin ( c ) ; 
double cosc = Math . cos ( c ) ; 
if ( Math . abs ( rho ) < TOLERANCE ) { 
phi = latt ; 
phi = Math . asin ( cosc * sinlatt + fromY * sinc * coslatt / rho ) ; 
toLat = Math . toDegrees ( phi ) ; 
if ( ( Math . abs ( fromX ) < TOLERANCE ) && ( Math . abs ( fromY ) < TOLERANCE ) ) { 
lam = lont ; 
} else if ( Math . abs ( coslatt ) < TOLERANCE ) { 
lam = lont + Math . atan2 ( fromX , ( ( latt > 0 ) 
? - fromY 
: fromY ) ) ; 
lam = lont + Math . atan2 ( fromX * sinc , rho * coslatt * cosc - fromY * sinc * sinlatt ) ; 
toLon = Math . toDegrees ( lam ) ; 
phi = Math . asin ( cosc * sinlatt 
+ fromY * sinc * coslatt / rho ) ; 
if ( ( Math . abs ( fromX ) < TOLERANCE ) 
&& ( Math . abs ( fromY ) < TOLERANCE ) ) { 
lam = lont 
+ Math . atan2 ( fromX * sinc , 
rho * coslatt * cosc 
- fromY * sinc * sinlatt ) ; 
} public double [ ] [ ] latLonToProj ( double [ ] [ ] from , double [ ] [ ] to , int latIndex , int lonIndex ) { 
} public static DatasetSourceStructure getStructure ( String name ) 
return ( DatasetSourceStructure ) hash . get ( name ) ; 
public String 
getResourcePath ( DapRequest drq , String location ) 
String realpath ; 
if ( TdsRequestedDataset . getDatasetManager ( ) != null ) { 
realpath = TdsRequestedDataset . getLocationFromRequestPath ( location ) ; 
assert TdsRequestedDataset . getDatasetManager ( ) == null ; 
String prefix = drq . getResourceRoot ( ) ; 
assert ( prefix != null ) ; 
realpath = DapUtil . canonjoin ( prefix , location ) ; 
if ( ! TESTING ) { 
if ( ! TdsRequestedDataset . resourceControlOk ( drq . getRequest ( ) , drq . getResponse ( ) , realpath ) ) 
. setCode ( DapCodes . SC_FORBIDDEN ) ; 
File f = new File ( realpath ) ; 
if ( ! f . exists ( ) || ! f . canRead ( ) ) 
. setCode ( DapCodes . SC_NOT_FOUND ) ; 
return realpath ; 
} public void open ( GridIndex index , GridTableLookup lookup , int version , 
NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { 
List < GridDefRecord > hcsList = index . getHorizCoordSys ( ) ; 
boolean needGroups = ( hcsList . size ( ) > 1 ) ; 
for ( GridDefRecord gds : hcsList ) { 
Group g = null ; 
if ( needGroups ) { 
g = new Group ( ncfile , null , gds . getGroupName ( ) ) ; 
ncfile . addGroup ( null , g ) ; 
GridHorizCoordSys hcs = makeGridHorizCoordSys ( gds , lookup , g ) ; 
hcsHash . put ( gds . getParam ( GridDefRecord . GDS_KEY ) , hcs ) ; 
GridRecord firstRecord = null ; 
List < GridRecord > records = index . getGridRecords ( ) ; 
for ( GridRecord gridRecord : records ) { 
firstRecord = gridRecord ; 
GridHorizCoordSys hcs = hcsHash . get ( gridRecord . getGridDefRecordId ( ) ) ; 
int cdmHash = gridRecord . cdmVariableHash ( ) ; 
GridVariable pv = hcs . varHash . get ( cdmHash ) ; 
if ( null == pv ) { 
String name = gridRecord . cdmVariableName ( lookup , true , true ) ; 
pv = makeGridVariable ( indexFilename , name , hcs , lookup ) ; 
hcs . varHash . put ( cdmHash , pv ) ; 
String simpleName = gridRecord . getParameterDescription ( ) ; 
List < GridVariable > plist = hcs . productHash . get ( simpleName ) ; 
if ( null == plist ) { 
plist = new ArrayList < > ( ) ; 
hcs . productHash . put ( simpleName , plist ) ; 
plist . add ( pv ) ; 
pv . addProduct ( gridRecord ) ; 
ncfile . addAttribute ( null , new Attribute ( "Conventions" , "CF-1.4" ) ) ; 
addExtraAttributes ( firstRecord , lookup , ncfile ) ; 
ncfile . addAttribute ( null , new Attribute ( "title" , lookup . getTitle ( ) ) ) ; 
if ( lookup . getInstitution ( ) != null ) 
ncfile . addAttribute ( null , new Attribute ( "institution" , lookup . getInstitution ( ) ) ) ; 
String source = lookup . getSource ( ) ; 
if ( source != null && ! source . startsWith ( "Unknown" ) ) 
ncfile . addAttribute ( null , new Attribute ( "source" , source ) ) ; 
if ( lookup . getComment ( ) != null ) 
ncfile . addAttribute ( null , new Attribute ( "comment" , lookup . getComment ( ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( "file_format" , lookup . getGridType ( ) ) ) ; 
ncfile . addAttribute ( null , new Attribute ( _Coordinate . ModelRunDate , 
formatter . toDateTimeStringISO ( lookup . getFirstBaseTime ( ) ) ) ) ; 
makeDenseCoordSys ( ncfile , lookup , cancelTask ) ; 
if ( GridServiceProvider . debugMissing ) { 
try ( Formatter f = new Formatter ( System . out ) ) { 
Collection < GridHorizCoordSys > hcset = hcsHash . values ( ) ; 
for ( GridHorizCoordSys hcs : hcset ) { 
List < GridVariable > gribvars = new ArrayList < > ( hcs . varHash . values ( ) ) ; 
for ( GridVariable gv : gribvars ) { 
count += gv . showMissingSummary ( f ) ; 
if ( GridServiceProvider . debugMissingDetails ) { 
String lastVertDesc = null ; 
Collections . sort ( gribvars , new CompareGridVariableByVertName ( ) ) ; 
String vertDesc = gv . getVertName ( ) ; 
if ( ! vertDesc . equals ( lastVertDesc ) ) { 
lastVertDesc = vertDesc ; 
gv . showMissing ( f ) ; 
} private void makeDenseCoordSys ( NetcdfFile ncfile , GridTableLookup lookup , CancelTask cancelTask ) throws IOException { 
List < GridTimeCoord > timeCoords = new ArrayList < > ( ) ; 
List < GridVertCoord > vertCoords = new ArrayList < > ( ) ; 
List < GridEnsembleCoord > ensembleCoords = new ArrayList < > ( ) ; 
if ( ( cancelTask != null ) && cancelTask . isCancel ( ) ) break ; 
List < GridRecord > recordList = gv . getRecords ( ) ; 
GridRecord record = recordList . get ( 0 ) ; 
String vname = gv . makeLevelName ( record , lookup ) ; 
GridVertCoord useVertCoord = null ; 
for ( GridVertCoord gvcs : vertCoords ) { 
if ( vname . equals ( gvcs . getLevelName ( ) ) ) { 
if ( gvcs . matchLevels ( recordList ) ) { 
useVertCoord = gvcs ; 
if ( useVertCoord == null ) { 
useVertCoord = makeGridVertCoord ( recordList , vname , lookup , hcs ) ; 
vertCoords . add ( useVertCoord ) ; 
gv . setVertCoord ( useVertCoord ) ; 
GridTimeCoord useTimeCoord = null ; 
for ( GridTimeCoord gtc : timeCoords ) { 
if ( gtc . matchTimes ( recordList ) ) { 
useTimeCoord = gtc ; 
if ( useTimeCoord == null ) { 
useTimeCoord = makeGridTimeCoord ( recordList , ncfile . getLocation ( ) ) ; 
timeCoords . add ( useTimeCoord ) ; 
gv . setTimeCoord ( useTimeCoord ) ; 
if ( gv . isEnsemble ( ) ) { 
GridEnsembleCoord useEnsembleCoord = addEnsembles ( ensembleCoords , recordList ) ; 
if ( useEnsembleCoord != null ) 
gv . setEnsembleCoord ( useEnsembleCoord ) ; 
Collections . sort ( timeCoords ) ; 
for ( GridTimeCoord tcs : timeCoords ) { 
tcs . setSequence ( count ++ ) ; 
tcs . addDimensionsToNetcdfFile ( ncfile , hcs . getGroup ( ) ) ; 
for ( GridEnsembleCoord gec : ensembleCoords ) { 
gec . setSequence ( seqno ++ ) ; 
gec . addDimensionsToNetcdfFile ( ncfile , hcs . getGroup ( ) ) ; 
hcs . addDimensionsToNetcdfFile ( ncfile ) ; 
Collections . sort ( vertCoords ) ; 
int vcIndex = 0 ; 
String listName = null ; 
for ( vcIndex = 0 ; vcIndex < vertCoords . size ( ) ; vcIndex ++ ) { 
GridVertCoord gvcs = vertCoords . get ( vcIndex ) ; 
String vname = gvcs . getLevelName ( ) ; 
if ( listName == null ) { 
listName = vname ; 
if ( ! vname . equals ( listName ) ) { 
makeVerticalDimensions ( vertCoords . subList ( start , vcIndex ) , ncfile , hcs . getGroup ( ) ) ; 
start = vcIndex ; 
List < List < GridVariable > > products = new ArrayList < > ( hcs . productHash . values ( ) ) ; 
for ( List < GridVariable > plist : products ) { 
if ( plist . size ( ) == 1 ) { 
GridVariable pv = plist . get ( 0 ) ; 
String name = pv . getFirstRecord ( ) . cdmVariableName ( lookup , false , false ) ; 
Variable v = pv . makeVariable ( ncfile , hcs . getGroup ( ) , name , raf ) ; 
ncfile . addVariable ( hcs . getGroup ( ) , v ) ; 
Map < GridVertCoord , VertCollection > vcMap = new HashMap < > ( ) ; 
for ( GridVariable gv : plist ) { 
VertCollection vc = vcMap . get ( gv . getVertCoord ( ) ) ; 
if ( vc == null ) { 
vc = new VertCollection ( gv ) ; 
vcMap . put ( gv . getVertCoord ( ) , vc ) ; 
vc . list . add ( gv ) ; 
List < VertCollection > vclist = new ArrayList < > ( vcMap . values ( ) ) ; 
Collections . sort ( vclist ) ; 
boolean firstVertCoord = true ; 
for ( VertCollection vc : vclist ) { 
boolean hasMultipleLevels = vc . vc . getNLevels ( ) > 1 ; 
boolean noLevelOk = firstVertCoord ; 
List < GridVariable > list = vc . list ; 
if ( list . size ( ) == 1 ) { 
GridVariable gv = list . get ( 0 ) ; 
String name = gv . getFirstRecord ( ) . cdmVariableName ( lookup , ! noLevelOk , false ) ; 
ncfile . addVariable ( hcs . getGroup ( ) , gv . makeVariable ( ncfile , hcs . getGroup ( ) , name , raf ) ) ; 
for ( GridVariable gv : list ) { 
String name = gv . getFirstRecord ( ) . cdmVariableName ( lookup , ! noLevelOk , true ) ; 
firstVertCoord = false ; 
tcs . addToNetcdfFile ( ncfile , hcs . getGroup ( ) ) ; 
for ( GridEnsembleCoord ens : ensembleCoords ) { 
ens . addToNetcdfFile ( ncfile , hcs . getGroup ( ) ) ; 
hcs . addToNetcdfFile ( ncfile ) ; 
gvcs . addToNetcdfFile ( ncfile , hcs . getGroup ( ) ) ; 
} private void makeVerticalDimensions ( List < GridVertCoord > vertCoordList , NetcdfFile ncfile , Group group ) { 
GridVertCoord gvcs0 = null ; 
int maxLevels = 0 ; 
for ( GridVertCoord gvcs : vertCoordList ) { 
if ( gvcs . getNLevels ( ) > maxLevels ) { 
gvcs0 = gvcs ; 
maxLevels = gvcs . getNLevels ( ) ; 
int seqno = 1 ; 
if ( gvcs != gvcs0 ) { 
gvcs . setSequence ( seqno ++ ) ; 
gvcs . addDimensionsToNetcdfFile ( ncfile , group ) ; 
} boolean readPIB ( RandomAccessFile raf ) throws IOException { 
this . firstHeader = new AwxFileFirstHeader ( ) ; 
byte [ ] buf = new byte [ FY_AWX_PIB_LEN ] ; 
int count = raf . read ( buf ) ; 
EndianByteBuffer byteBuffer ; 
if ( count == FY_AWX_PIB_LEN ) { 
byteBuffer = new EndianByteBuffer ( buf , this . firstHeader . byteOrder ) ; 
this . firstHeader . fillHeader ( byteBuffer ) ; 
if ( ! ( ( this . firstHeader . fileName . endsWith ( ".AWX" ) || this . firstHeader . fileName . endsWith ( ".awx" ) ) 
&& this . firstHeader . firstHeaderLength == FY_AWX_PIB_LEN ) ) { 
buf = new byte [ this . firstHeader . secondHeaderLength ] ; 
raf . readFully ( buf ) ; 
switch ( this . firstHeader . typeOfProduct ) { 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_UNDEFINED : 
throw new UnsupportedDatasetException ( ) ; 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GEOSAT_IMAGE : 
secondHeader = new AwxFileGeoSatelliteSecondHeader ( ) ; 
secondHeader . fillHeader ( byteBuffer ) ; 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_POLARSAT_IMAGE : 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GRID : 
secondHeader = new AwxFileGridProductSecondHeader ( ) ; 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_DISCREET : 
case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GRAPH_ANALIYSIS : 
java . util . Iterator iter ; 
authorityName = null ; 
dataType = null ; 
dataFormatType = null ; 
defaultService = null ; 
gc = null ; 
tc = null ; 
docs = new ArrayList < > ( ) ; 
metadata = new ArrayList < > ( ) ; 
properties = new ArrayList < > ( ) ; 
creators = new ArrayList < > ( ) ; 
contributors = new ArrayList < > ( ) ; 
dates = new ArrayList < > ( ) ; 
keywords = new ArrayList < > ( ) ; 
projects = new ArrayList < > ( ) ; 
publishers = new ArrayList < > ( ) ; 
variables = new ArrayList < > ( ) ; 
canonicalize ( ) ; 
transfer2PublicMetadata ( tm , true ) ; 
transfer2PublicMetadata ( tmi , true ) ; 
transferInheritable2PublicMetadata ( ( InvDatasetImpl ) getParent ( ) ) ; 
access = new ArrayList < > ( ) ; 
if ( ( urlPath != null ) && ( getServiceDefault ( ) != null ) ) { 
InvAccessImpl a = new InvAccessImpl ( this , urlPath , getServiceDefault ( ) ) ; 
a . setSize ( size ) ; 
a . finish ( ) ; 
addExpandedAccess ( a ) ; 
iter = accessLocal . iterator ( ) ; 
InvAccessImpl a = ( InvAccessImpl ) iter . next ( ) ; 
if ( ! ( this instanceof InvCatalogRef ) ) { 
for ( InvDataset invDataset : this . getDatasets ( ) ) { 
InvDatasetImpl curDs = ( InvDatasetImpl ) invDataset ; 
ok &= curDs . finish ( ) ; 
} private void transferInheritable2PublicMetadata ( InvDatasetImpl parent ) { 
if ( parent == null ) return ; 
transfer2PublicMetadata ( parent . getLocalMetadataInheritable ( ) , true ) ; 
transferInheritable2PublicMetadata ( ( InvDatasetImpl ) parent . getParent ( ) ) ; 
} private void transfer2PublicMetadata ( ThreddsMetadata tmd , boolean inheritAll ) { 
if ( tmd == null ) return ; 
if ( authorityName == null ) 
authorityName = tmd . getAuthority ( ) ; 
if ( dataType == null || ( dataType == FeatureType . ANY ) ) 
dataType = tmd . getDataType ( ) ; 
if ( dataFormatType == null || dataFormatType == DataFormatType . NONE ) 
dataFormatType = tmd . getDataFormatType ( ) ; 
if ( defaultService == null ) 
defaultService = findService ( tmd . getServiceName ( ) ) ; 
if ( gc == null ) { 
ThreddsMetadata . GeospatialCoverage tgc = tmd . getGeospatialCoverage ( ) ; 
if ( ( tgc != null ) && ! tgc . isEmpty ( ) ) 
gc = tgc ; 
DateRange ttc = tmd . getTimeCoverage ( ) ; 
if ( ttc != null ) { 
tc = ttc ; 
if ( tc == null ) 
tc = tmd . getTimeCoverage ( ) ; 
for ( InvProperty item : tmd . getProperties ( ) ) { 
properties . add ( item ) ; 
if ( variableMapLink == null ) 
variableMapLink = tmd . variableMapLink ; 
for ( InvMetadata meta : tmd . getMetadata ( ) ) { 
if ( meta . isInherited ( ) || inheritAll ) { 
if ( ! meta . isThreddsMetadata ( ) ) { 
metadata . add ( meta ) ; 
meta . finish ( ) ; 
transfer2PublicMetadata ( meta . getThreddsMetadata ( ) , inheritAll ) ; 
} public void transferMetadata ( InvDatasetImpl fromDs , boolean copyInheritedMetadataFromParents ) { 
if ( fromDs == null ) return ; 
if ( this != fromDs ) 
getLocalMetadata ( ) . add ( fromDs . getLocalMetadata ( ) , false ) ; 
transferInheritableMetadata ( fromDs , getLocalMetadataInheritable ( ) , copyInheritedMetadataFromParents ) ; 
setResourceControl ( fromDs . getRestrictAccess ( ) ) ; 
} private void transferInheritableMetadata ( InvDatasetImpl fromDs , ThreddsMetadata target , 
boolean copyInheritedMetadataFromParents ) { 
target . add ( fromDs . getLocalMetadataInheritable ( ) , true ) ; 
if ( copyInheritedMetadataFromParents ) 
transferInheritableMetadata ( ( InvDatasetImpl ) fromDs . getParent ( ) , target , true ) ; 
} protected void canonicalize ( ) { 
List < InvMetadata > whatsLeft = new ArrayList < > ( ) ; 
List < InvMetadata > original = new ArrayList < > ( tm . metadata ) ; 
tm . metadata = new ArrayList < > ( ) ; 
for ( InvMetadata m : original ) { 
if ( m . isThreddsMetadata ( ) && ! m . isInherited ( ) && ! m . hasXlink ( ) ) { 
ThreddsMetadata nested = m . getThreddsMetadata ( ) ; 
tm . add ( nested , false ) ; 
} else if ( m . isThreddsMetadata ( ) && m . isInherited ( ) && ! m . hasXlink ( ) ) { 
tmi . add ( nested , true ) ; 
whatsLeft . add ( m ) ; 
tm . metadata . addAll ( whatsLeft ) ; 
} public void setContributors ( List < ThreddsMetadata . Contributor > a ) { 
List < ThreddsMetadata . Contributor > dest = tm . getContributors ( ) ; 
for ( ThreddsMetadata . Contributor item : a ) { 
if ( ! dest . contains ( item ) ) 
dest . add ( item ) ; 
} public void addDataset ( int index , InvDatasetImpl ds ) { 
ds . setParent ( this ) ; 
datasets . add ( index , ds ) ; 
} public boolean removeDataset ( InvDatasetImpl ds ) { 
InvCatalogImpl cat = ( InvCatalogImpl ) getParentCatalog ( ) ; 
if ( cat != null ) 
cat . removeDatasetByID ( ds ) ; 
} public boolean replaceDataset ( InvDatasetImpl remove , InvDatasetImpl add ) { 
if ( cat != null ) { 
cat . removeDatasetByID ( remove ) ; 
cat . addDatasetByID ( add ) ; 
} public void addService ( InvService service ) { 
servicesLocal . add ( service ) ; 
services . add ( service ) ; 
for ( InvService nested : service . getServices ( ) ) { 
services . add ( nested ) ; 
} public void removeService ( InvService service ) { 
servicesLocal . remove ( service ) ; 
services . remove ( service ) ; 
services . remove ( nested ) ; 
} public void setServicesLocal ( java . util . List < InvService > s ) { 
this . services = new ArrayList < > ( ) ; 
this . servicesLocal = new ArrayList < > ( ) ; 
for ( InvService elem : s ) { 
addService ( elem ) ; 
} public boolean removeLocalMetadata ( InvMetadata metadata ) { 
InvDatasetImpl parentDataset = ( ( InvDatasetImpl ) metadata . getParentDataset ( ) ) ; 
List localMdata = parentDataset . getLocalMetadata ( ) . getMetadata ( ) ; 
if ( localMdata . contains ( metadata ) ) { 
if ( localMdata . remove ( metadata ) ) { 
} public Object getUserProperty ( Object key ) { 
if ( userMap == null ) return null ; 
return userMap . get ( key ) ; 
} static public void writeHtmlDescription ( StringBuilder buff , InvDatasetImpl ds , 
boolean complete , boolean isServer , 
boolean datasetEvents , boolean catrefEvents , 
boolean resolveRelativeUrls ) { 
if ( complete ) { 
. append ( "<html>\n" ) ; 
buff . append ( "<head>" ) ; 
buff . append ( "</head>" ) ; 
buff . append ( "<body>\n" ) ; 
if ( ( ds . getDataFormatType ( ) != null ) && ( ds . getDataFormatType ( ) != DataFormatType . NONE ) ) 
if ( ( ds . getDataSize ( ) != 0.0 ) && ! Double . isNaN ( ds . getDataSize ( ) ) ) 
if ( ( ds . getDataType ( ) != null ) && ( ds . getDataType ( ) != FeatureType . ANY ) ) 
if ( ( ds . getCollectionType ( ) != null ) && ( ds . getCollectionType ( ) != CollectionType . NONE ) ) 
if ( ds . isHarvest ( ) ) 
if ( ds . getAuthority ( ) != null ) 
if ( ds . getRestrictAccess ( ) != null ) 
InvCatalogRef catref = ( InvCatalogRef ) ds ; 
String href = resolveRelativeUrls || catrefEvents 
? resolve ( ds , catref . getXlinkHref ( ) ) 
: catref . getXlinkHref ( ) ; 
if ( catrefEvents ) href = "catref:" + href ; 
buff . append ( "</ul>\n" ) ; 
java . util . List < InvDocumentation > docs = ds . getDocumentation ( ) ; 
if ( docs . size ( ) > 0 ) { 
buff . append ( "<h3>Documentation:</h3>\n<ul>\n" ) ; 
for ( InvDocumentation doc : docs ) { 
String inline = doc . getInlineContent ( ) ; 
if ( ( inline != null ) && ( inline . length ( ) > 0 ) ) 
if ( doc . hasXlink ( ) ) { 
java . util . List < InvAccess > access = ds . getAccess ( ) ; 
if ( access . size ( ) > 0 ) { 
buff . append ( "<h3>Access:</h3>\n<ol>\n" ) ; 
for ( InvAccess a : access ) { 
String urlString = resolveRelativeUrls || datasetEvents 
? a . getStandardUrlName ( ) 
: a . getUnresolvedUrlName ( ) ; 
String fullUrlString = urlString ; 
if ( datasetEvents ) fullUrlString = "dataset:" + fullUrlString ; 
if ( isServer ) { 
ServiceType stype = s . getServiceType ( ) ; 
if ( ( stype == ServiceType . OPENDAP ) || ( stype == ServiceType . DODS ) ) 
fullUrlString = fullUrlString + ".html" ; 
else if ( stype == ServiceType . DAP4 ) 
fullUrlString = fullUrlString + ".dmr.xml" ; 
else if ( stype == ServiceType . WCS ) 
fullUrlString = fullUrlString + "?service=WCS&version=1.0.0&request=GetCapabilities" ; 
else if ( stype == ServiceType . WMS ) 
fullUrlString = fullUrlString + "?service=WMS&version=1.3.0&request=GetCapabilities" ; 
else if ( stype == ServiceType . NCML || stype == ServiceType . UDDC || stype == ServiceType . ISO ) { 
String catalogUrl = ds . getCatalogUrl ( ) ; 
String datasetId = ds . id ; 
if ( catalogUrl . indexOf ( '#' ) > 0 ) 
catalogUrl = catalogUrl . substring ( 0 , catalogUrl . lastIndexOf ( '#' ) ) ; 
catalogUrl = URLEncoder . encode ( catalogUrl , "UTF-8" ) ; 
datasetId = URLEncoder . encode ( datasetId , "UTF-8" ) ; 
fullUrlString = fullUrlString + "?catalog=" + catalogUrl + "&dataset=" + datasetId ; 
else if ( stype == ServiceType . NetcdfSubset ) 
fullUrlString = fullUrlString + "/dataset.html" ; 
else if ( ( stype == ServiceType . CdmRemote ) || ( stype == ServiceType . CdmrFeature ) ) 
fullUrlString = fullUrlString + "?req=form" ; 
buff . append ( "</ol>\n" ) ; 
java . util . List < ThreddsMetadata . Contributor > contributors = ds . getContributors ( ) ; 
if ( contributors . size ( ) > 0 ) { 
buff . append ( "<h3>Contributors:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Contributor t : contributors ) { 
java . util . List < ThreddsMetadata . Vocab > keywords = ds . getKeywords ( ) ; 
if ( keywords . size ( ) > 0 ) { 
buff . append ( "<h3>Keywords:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Vocab t : keywords ) { 
java . util . List < DateType > dates = ds . getDates ( ) ; 
if ( dates . size ( ) > 0 ) { 
buff . append ( "<h3>Dates:</h3>\n<ul>\n" ) ; 
for ( DateType d : dates ) { 
java . util . List < ThreddsMetadata . Vocab > projects = ds . getProjects ( ) ; 
if ( projects . size ( ) > 0 ) { 
buff . append ( "<h3>Projects:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Vocab t : projects ) { 
java . util . List < ThreddsMetadata . Source > creators = ds . getCreators ( ) ; 
if ( creators . size ( ) > 0 ) { 
buff . append ( "<h3>Creators:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Source t : creators ) { 
if ( t . getUrl ( ) != null ) { 
String newUrl = resolveRelativeUrls 
? makeHrefResolve ( ds , t . getUrl ( ) , null ) 
: makeHref ( t . getUrl ( ) , null ) ; 
java . util . List < ThreddsMetadata . Source > publishers = ds . getPublishers ( ) ; 
if ( publishers . size ( ) > 0 ) { 
buff . append ( "<h3>Publishers:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Source t : publishers ) { 
String urlLink = resolveRelativeUrls 
java . util . List < ThreddsMetadata . Variables > vars = ds . getVariables ( ) ; 
if ( vars . size ( ) > 0 ) { 
buff . append ( "<h3>Variables:</h3>\n<ul>\n" ) ; 
for ( ThreddsMetadata . Variables t : vars ) { 
if ( t . getVocabUri ( ) != null ) { 
URI uri = t . getVocabUri ( ) ; 
String vocabLink = resolveRelativeUrls 
? makeHrefResolve ( ds , uri . toString ( ) , t . getVocabulary ( ) ) 
: makeHref ( uri . toString ( ) , t . getVocabulary ( ) ) ; 
buff . append ( vocabLink ) ; 
buff . append ( StringUtil2 . quoteHtmlContent ( t . getVocabulary ( ) ) ) ; 
buff . append ( "]:\n<ul>\n" ) ; 
java . util . List < ThreddsMetadata . Variable > vlist = t . getVariableList ( ) ; 
if ( vlist . size ( ) > 0 ) { 
for ( ThreddsMetadata . Variable v : vlist ) { 
buff . append ( desc ) ; 
if ( v . getVocabularyName ( ) != null ) 
buff . append ( StringUtil2 . quoteHtmlContent ( v . getVocabularyName ( ) ) ) ; 
buff . append ( "\n" ) ; 
if ( ds . getVariableMapLink ( ) != null ) { 
buff . append ( "<h3>Variables:</h3>\n" ) ; 
buff . append ( "<ul><li>" + makeHref ( ds . getVariableMapLink ( ) , "VariableMap" ) + "</li></ul>\n" ) ; 
ThreddsMetadata . GeospatialCoverage gc = ds . getGeospatialCoverage ( ) ; 
if ( ( gc != null ) && ! gc . isEmpty ( ) ) { 
buff . append ( "<h3>GeospatialCoverage:</h3>\n<ul>\n" ) ; 
if ( gc . isGlobal ( ) ) 
if ( gc . getUpDownRange ( ) != null ) { 
java . util . List < ThreddsMetadata . Vocab > nlist = gc . getNames ( ) ; 
if ( ( nlist != null ) && ( nlist . size ( ) > 0 ) ) { 
for ( ThreddsMetadata . Vocab elem : nlist ) { 
CalendarDateRange tc = ds . getCalendarDateCoverage ( ) ; 
if ( tc != null ) { 
buff . append ( "<h3>TimeCoverage:</h3>\n<ul>\n" ) ; 
CalendarDate start = tc . getStart ( ) ; 
if ( start != null ) 
CalendarDate end = tc . getEnd ( ) ; 
if ( end != null ) { 
CalendarDuration duration = tc . getDuration ( ) ; 
if ( duration != null ) 
CalendarDuration resolution = tc . getResolution ( ) ; 
if ( resolution != null ) { 
java . util . List < InvMetadata > metadata = ds . getMetadata ( ) ; 
boolean gotSomeMetadata = false ; 
for ( InvMetadata m : metadata ) { 
if ( m . hasXlink ( ) ) gotSomeMetadata = true ; 
if ( gotSomeMetadata ) { 
buff . append ( "<h3>Metadata:</h3>\n<ul>\n" ) ; 
String type = ( m . getMetadataType ( ) == null ) ? "" : m . getMetadataType ( ) ; 
if ( m . hasXlink ( ) ) { 
String mdLink = resolveRelativeUrls 
? makeHrefResolve ( ds , m . getXlinkHref ( ) , title ) 
: makeHref ( m . getXlinkHref ( ) , title ) ; 
java . util . List < InvProperty > propsOrg = ds . getProperties ( ) ; 
java . util . List < InvProperty > props = new ArrayList < > ( ds . getProperties ( ) . size ( ) ) ; 
for ( InvProperty p : propsOrg ) { 
if ( ! p . getName ( ) . startsWith ( "viewer" ) ) 
props . add ( p ) ; 
if ( props . size ( ) > 0 ) { 
buff . append ( "<h3>Properties:</h3>\n<ul>\n" ) ; 
for ( InvProperty p : props ) { 
if ( p . getName ( ) . equals ( "attachments" ) ) 
String attachLink = resolveRelativeUrls 
? makeHrefResolve ( ds , p . getValue ( ) , p . getName ( ) ) 
: makeHref ( p . getValue ( ) , p . getName ( ) ) ; 
if ( complete ) buff . append ( "</body></html>" ) ; 
} static public String resolve ( InvDataset ds , String href ) { 
InvCatalog cat = ds . getParentCatalog ( ) ; 
java . net . URI uri = cat . resolveUri ( href ) ; 
href = uri . toString ( ) ; 
return href ; 
if ( this . msgLog . length ( ) > 0 ) { 
out . append ( this . msgLog ) ; 
this . isValid = false ; 
if ( this . getType ( ) == DatasetNamerType . REGULAR_EXPRESSION 
&& ( this . getMatchPattern ( ) == null || this . getSubstitutePattern ( ) == null ) ) 
if ( this . getType ( ) == DatasetNamerType . DODS_ATTRIBUTE 
&& ( this . getAttribContainer ( ) == null || this . getAttribName ( ) == null ) ) 
} public boolean nameDataset ( InvDatasetImpl dataset ) { 
if ( this . type == DatasetNamerType . REGULAR_EXPRESSION ) { 
return ( this . nameDatasetRegExp ( dataset ) ) ; 
} public boolean nameDatasetList ( java . util . List datasetList ) 
throws java . lang . Exception { 
boolean returnValue = false ; 
InvDatasetImpl curDataset = null ; 
for ( int i = 0 ; i < datasetList . size ( ) ; i ++ ) { 
curDataset = ( InvDatasetImpl ) datasetList . get ( i ) ; 
returnValue &= this . nameDataset ( curDataset ) ; 
return ( returnValue ) ; 
} public final List < String > getDescriptors ( ) { 
List < String > desc = new ArrayList < String > ( ) ; 
for ( short fxy : descriptors ) 
desc . add ( Descriptor . makeString ( fxy ) ) ; 
} private void init ( double a , double f , int zone , boolean hemisphere_north ) { 
this . zone = zone ; 
this . hemisphere_north = hemisphere_north ; 
EF = F / ( 2.0 - F ) ; 
Con2 = 2 / ( 1.0 - Eps2 ) ; 
Con6 = .166666666666667 ; 
Con24 = 4 * .0416666666666667 / ( 1 - Eps2 ) ; 
Con120 = .00833333333333333 ; 
Con720 = 4 * .00138888888888888 / ( 1 - Eps2 ) ; 
double polx1a = 1.0 - Eps2 / 4.0 - 3.0 / 64.0 * Math . pow ( Eps2 , 2 ) 
- 5.0 / 256.0 * Math . pow ( Eps2 , 3 ) 
- 175.0 / 16384.0 * Math . pow ( Eps2 , 4 ) ; 
conap = A * polx1a ; 
double polx2a = 3.0 / 2.0 * EF - 27.0 / 32.0 * Math . pow ( EF , 3 ) ; 
double polx4a = 21.0 / 16.0 * Math . pow ( EF , 2 ) 
- 55.0 / 32.0 * Math . pow ( EF , 4 ) ; 
double polx6a = 151.0 / 96.0 * Math . pow ( EF , 3 ) ; 
double polx8a = 1097.0 / 512.0 * Math . pow ( EF , 4 ) ; 
polx2b = polx2a * 2.0 + polx4a * 4.0 + polx6a * 6.0 + polx8a * 8.0 ; 
polx3b = polx4a * - 8.0 - polx6a * 32.0 - 80.0 * polx8a ; 
polx4b = polx6a * 32.0 + 192.0 * polx8a ; 
polx5b = - 128.0 * polx8a ; 
} public LogReader . Log nextLog ( BufferedReader dataIS ) throws IOException { 
ServletLog log = new ServletLog ( ) ; 
boolean haveLog = false ; 
dataIS . mark ( 20 * 1000 ) ; 
return haveLog ? log : null ; 
Matcher m = commonPattern . matcher ( line ) ; 
if ( haveLog ) { 
dataIS . reset ( ) ; 
return log ; 
haveLog = true ; 
log . date = convertDate ( m . group ( 1 ) ) ; 
log . reqTime = parseLong ( m . group ( 2 ) ) ; 
log . reqSeq = parseLong ( m . group ( 3 ) ) ; 
log . level = m . group ( 4 ) . intern ( ) ; 
log . where = m . group ( 5 ) ; 
String rest = m . group ( 6 ) ; 
Matcher m2 = donePattern . matcher ( rest . substring ( pos ) ) ; 
if ( m2 . matches ( ) ) { 
log . returnCode = parse ( m2 . group ( 1 ) ) ; 
log . sizeBytes = parseLong ( m2 . group ( 2 ) ) ; 
log . msecs = parseLong ( m2 . group ( 3 ) ) ; 
log . isDone = true ; 
log . addExtra ( rest ) ; 
Matcher m2 = startPattern . matcher ( rest . substring ( pos ) ) ; 
log . ip = m2 . group ( 1 ) ; 
log . verb = m2 . group ( 2 ) . intern ( ) ; 
log . path = EscapeStrings . urlDecode ( m2 . group ( 3 ) ) ; 
if ( m2 . groupCount ( ) > 4 ) 
log . http = m2 . group ( 4 ) . intern ( ) ; 
log . isStart = true ; 
log . addExtra ( line ) ; 
} public static String constructServerPath ( HttpServletRequest hsreq ) { 
return hsreq . getScheme ( ) + "://" + hsreq . getServerName ( ) + ":" + hsreq . getServerPort ( ) + "/thredds/wfs/" ; 
} private void getCapabilities ( PrintWriter out , HttpServletRequest hsreq , SimpleGeometryCSBuilder sgcs ) { 
WFSGetCapabilitiesWriter gcdw = new WFSGetCapabilitiesWriter ( out , WFSController . constructServerPath ( hsreq ) ) ; 
gcdw . startXML ( ) ; 
gcdw . addOperation ( WFSRequestType . GetCapabilities ) ; gcdw . addOperation ( WFSRequestType . DescribeFeatureType ) ; gcdw . addOperation ( WFSRequestType . GetFeature ) ; 
gcdw . writeOperations ( ) ; 
List < String > seriesNames = sgcs . getGeometrySeriesNames ( ) ; 
for ( String name : seriesNames ) { 
gcdw . addFeature ( new WFSFeature ( TDSNAMESPACE + ":" + name , name ) ) ; 
gcdw . writeFeatureTypes ( ) ; 
gcdw . finishXML ( ) ; 
} private WFSExceptionWriter getFeature ( PrintWriter out , HttpServletRequest hsreq , SimpleGeometryCSBuilder sgcs , String ftName , String fullFtName ) { 
List < SimpleGeometry > geometryList = new ArrayList < SimpleGeometry > ( ) ; 
GeometryType geoT = sgcs . getGeometryType ( ftName ) ; 
if ( geoT == null ) { 
switch ( geoT ) { 
case POINT : 
Point pt = sgcs . getPoint ( ftName , 0 ) ; 
while ( pt != null ) { 
geometryList . add ( pt ) ; 
pt = sgcs . getPoint ( ftName , j ) ; 
case LINE : 
Line line = sgcs . getLine ( ftName , 0 ) ; 
geometryList . add ( line ) ; 
k ++ ; 
line = sgcs . getLine ( ftName , k ) ; 
case POLYGON : 
Polygon poly = sgcs . getPolygon ( ftName , 0 ) ; 
while ( poly != null ) { 
geometryList . add ( poly ) ; 
poly = sgcs . getPolygon ( ftName , i ) ; 
catch ( ArrayIndexOutOfBoundsException aout ) { 
WFSGetFeatureWriter gfdw = new WFSGetFeatureWriter ( out , WFSController . constructServerPath ( hsreq ) , WFSController . getXMLNamespaceXMLNSValue ( hsreq ) , geometryList , ftName ) ; 
gfdw . startXML ( ) ; 
gfdw . writeMembers ( ) ; 
gfdw . finishXML ( ) ; 
} private WFSExceptionWriter checkParametersForError ( String request , String version , String service , String typeName ) { 
if ( service != null ) { 
if ( ! service . equalsIgnoreCase ( "WFS" ) ) { 
if ( request != null ) { 
if ( ! request . equalsIgnoreCase ( WFSRequestType . GetCapabilities . toString ( ) ) ) { 
if ( version != null ) { 
String [ ] versionParts = version . split ( "\\." ) ; 
for ( int ind = 0 ; ind < versionParts . length ; ind ++ ) { 
Integer . valueOf ( versionParts [ ind ] ) ; 
catch ( NumberFormatException excep ) { 
boolean validVersion = false ; 
if ( versionParts . length == 1 ) if ( versionParts [ 0 ] . equals ( "2" ) ) validVersion = true ; 
if ( versionParts . length >= 2 ) if ( versionParts [ 0 ] . equals ( "2" ) && versionParts [ 1 ] . equals ( "0" ) ) validVersion = true ; 
if ( ! validVersion ) { 
if ( typeName == null ) { 
WFSRequestType reqToProc = WFSRequestType . getWFSRequestType ( request ) ; 
} @ RequestMapping ( "**" ) 
public void httpHandler ( HttpServletRequest hsreq , HttpServletResponse hsres ) { 
PrintWriter wr = hsres . getWriter ( ) ; 
List < String > paramNames = new LinkedList < String > ( ) ; 
Enumeration < String > paramNamesE = hsreq . getParameterNames ( ) ; 
while ( paramNamesE . hasMoreElements ( ) ) paramNames . add ( paramNamesE . nextElement ( ) ) ; 
String request = null ; 
String version = null ; 
String service = null ; 
String typeNames = null ; 
String datasetReqPath = null ; 
String actualPath = null ; 
String actualFTName = null ; 
NetcdfDataset dataset = null ; 
if ( hsreq . getServletPath ( ) . length ( ) > 4 ) { 
datasetReqPath = hsreq . getServletPath ( ) . substring ( 4 , hsreq . getServletPath ( ) . length ( ) ) ; 
actualPath = TdsRequestedDataset . getLocationFromRequestPath ( datasetReqPath ) ; 
if ( actualPath != null ) dataset = NetcdfDataset . openDataset ( actualPath ) ; 
List < CoordinateSystem > csList = dataset . getCoordinateSystems ( ) ; 
SimpleGeometryCSBuilder cs = new SimpleGeometryCSBuilder ( dataset , csList . get ( 0 ) , null ) ; 
for ( String paramName : paramNames ) { 
if ( paramName . equalsIgnoreCase ( "REQUEST" ) ) { 
request = hsreq . getParameter ( paramName ) ; 
if ( paramName . equalsIgnoreCase ( "VERSION" ) ) { 
version = hsreq . getParameter ( paramName ) ; 
if ( paramName . equalsIgnoreCase ( "SERVICE" ) ) { 
service = hsreq . getParameter ( paramName ) ; 
if ( paramName . equalsIgnoreCase ( "TYPENAMES" ) || paramName . equalsIgnoreCase ( "TYPENAME" ) ) { 
typeNames = hsreq . getParameter ( paramName ) ; 
if ( typeNames != null ) if ( typeNames . length ( ) > TDSNAMESPACE . length ( ) ) { 
actualFTName = typeNames . substring ( TDSNAMESPACE . length ( ) + 1 , typeNames . length ( ) ) ; 
WFSExceptionWriter paramError = checkParametersForError ( request , version , service , typeNames ) ; 
WFSExceptionWriter requestProcessingError = null ; 
if ( paramError == null ) { 
switch ( reqToProc ) { 
case GetCapabilities : 
getCapabilities ( wr , hsreq , cs ) ; 
case DescribeFeatureType : 
describeFeatureType ( wr , hsreq , actualFTName ) ; 
case GetFeature : 
requestProcessingError = getFeature ( wr , hsreq , cs , actualFTName , typeNames ) ; 
paramError . write ( hsres ) ; 
if ( requestProcessingError != null ) { 
requestProcessingError . write ( hsres ) ; 
catch ( IOException io ) { 
} public boolean dspMatch ( String url , DapContext context ) 
XURI xuri = new XURI ( url ) ; 
for ( String scheme : DAP4SCHEMES ) { 
if ( scheme . equalsIgnoreCase ( xuri . getBaseProtocol ( ) ) 
|| scheme . equalsIgnoreCase ( xuri . getFormatProtocol ( ) ) ) { 
if ( ! found ) return false ; 
String formatproto = xuri . getFormatProtocol ( ) ; 
if ( DAP4PROTO . equalsIgnoreCase ( formatproto ) ) 
for ( String [ ] pair : DAP4QUERYMARKERS ) { 
String tag = xuri . getQueryFields ( ) . get ( pair [ 0 ] ) ; 
if ( tag != null 
&& ( pair [ 1 ] == null 
|| pair [ 1 ] . equalsIgnoreCase ( tag ) ) ) 
for ( String [ ] pair : DAP4FRAGMARKERS ) { 
String tag = xuri . getFragFields ( ) . get ( pair [ 0 ] ) ; 
build ( ) 
String methodurl = buildURL ( this . xuri . assemble ( XURI . URLONLY ) , DATASUFFIX , this . dmr , this . basece ) ; 
InputStream stream ; 
stream = callServer ( methodurl ) ; 
ChunkInputStream reader ; 
byte [ ] raw = DapUtil . readbinaryfile ( stream ) ; 
ByteArrayInputStream bis = new ByteArrayInputStream ( raw ) ; 
DapDump . dumpbytestream ( raw , getOrder ( ) , "httpdsp.build" ) ; 
reader = new ChunkInputStream ( bis , RequestMode . DAP , getOrder ( ) ) ; 
reader = new ChunkInputStream ( stream , RequestMode . DAP , getOrder ( ) ) ; 
String document = reader . readDMR ( ) ; 
byte [ ] bytes = DapUtil . readbinaryfile ( reader ) ; 
super . build ( document , bytes , getOrder ( ) ) ; 
throw new DapException ( t ) ; 
getCapabilities ( String url ) 
String saveurl = this . xuri . getOriginal ( ) ; 
parseURL ( url ) ; 
String fdsurl = buildURL ( this . xuri . assemble ( XURI . URLALL ) , DSRSUFFIX , null , null ) ; 
InputStream stream = callServer ( fdsurl ) ; 
byte [ ] bytes = DapUtil . readbinaryfile ( stream ) ; 
parseURL ( saveurl ) ; 
} static protected String 
buildURL ( String baseurl , String suffix , DapDataset template , String ce ) 
StringBuilder methodurl = new StringBuilder ( ) ; 
methodurl . append ( baseurl ) ; 
if ( suffix != null ) { 
methodurl . append ( '.' ) ; 
methodurl . append ( suffix ) ; 
if ( ce != null && ce . length ( ) > 0 ) { 
methodurl . append ( QUERYSTART ) ; 
methodurl . append ( CONSTRAINTTAG ) ; 
methodurl . append ( '=' ) ; 
methodurl . append ( ce ) ; 
return methodurl . toString ( ) ; 
public File getFile ( ) { 
return threddsS3Client . saveObjectToFile ( s3uri , s3uri . getTempFile ( ) ) ; 
public long length ( ) { 
S3ObjectSummary objectSummary = objectSummaryCache . getIfPresent ( s3uri ) ; 
if ( objectSummary != null ) { 
return objectSummary . getSize ( ) ; 
ObjectMetadata metadata = threddsS3Client . getObjectMetadata ( s3uri ) ; 
return metadata . getContentLength ( ) ; 
public Date lastModified ( ) { 
return objectSummary . getLastModified ( ) ; 
return metadata . getLastModified ( ) ; 
} @ ExceptionHandler ( NcssException . class ) 
public ResponseEntity < String > handle ( NcssException e ) { 
responseHeaders . setContentType ( MediaType . TEXT_PLAIN ) ; 
return new ResponseEntity < > ( e . getMessage ( ) , responseHeaders , HttpStatus . BAD_REQUEST ) ; 
} public static String getDatasetPath ( String path ) { 
if ( path . startsWith ( StandardService . netcdfSubsetGrid . getBase ( ) ) ) { 
path = path . substring ( StandardService . netcdfSubsetGrid . getBase ( ) . length ( ) ) ; 
} else if ( path . startsWith ( StandardService . netcdfSubsetPoint . getBase ( ) ) ) { 
path = path . substring ( StandardService . netcdfSubsetPoint . getBase ( ) . length ( ) ) ; 
for ( String ending : endings ) { 
if ( path . endsWith ( ending ) ) { 
int len = path . length ( ) - ending . length ( ) ; 
path = path . substring ( 0 , len ) ; 
generate ( CEConstraint ce , ChunkWriter cw , boolean withdmr , ChecksumMode mode ) 
begin ( ce , cw , withdmr , mode ) ; 
if ( this . withdmr ) 
generateDMR ( this . dmr ) ; 
dataset ( this . dmr ) ; 
dataset ( DapDataset dmr ) 
for ( DapVariable var : this . dmr . getTopVariables ( ) ) { 
if ( ! this . ce . references ( var ) ) 
variable ( var ) ; 
} public Point setupPoint ( NetcdfDataset set , Variable vari , int index ) 
Integer ind = ( int ) index ; 
boolean multi = false ; 
SimpleGeometryIndexFinder indexFinder = null ; 
List < CoordinateAxis > axes = set . getCoordinateAxes ( ) ; 
String node_c_str = vari . findAttValueIgnoreCase ( CF . NODE_COUNT , "" ) ; 
nodeCounts = set . findVariable ( node_c_str ) ; 
indexFinder = new SimpleGeometryIndexFinder ( nodeCounts ) ; 
multi = true ; 
if ( multi ) 
xPts = x . read ( indexFinder . getBeginning ( index ) + ":" + indexFinder . getEnd ( index ) ) . reduce ( ) ; 
yPts = y . read ( indexFinder . getBeginning ( index ) + ":" + indexFinder . getEnd ( index ) ) . reduce ( ) ; 
xPts = x . read ( ind . toString ( ) ) . reduce ( ) ; 
yPts = y . read ( ind . toString ( ) ) . reduce ( ) ; 
this . x = xPts . getDouble ( 0 ) ; 
this . y = yPts . getDouble ( 0 ) ; 
if ( ! multi ) { 
switch ( vari . getRank ( ) ) { 
this . setData ( vari . read ( CFSimpleGeometryHelper . getSubsetString ( vari , index ) ) . reduce ( ) ) ; 
this . setData ( vari . read ( "" + index ) ) ; 
Point point = this ; 
point . setX ( itrX . getDoubleNext ( ) ) ; 
point . setY ( itrY . getDoubleNext ( ) ) ; 
point . setData ( vari . read ( CFSimpleGeometryHelper . getSubsetString ( vari , index ) ) . reduce ( ) ) ; 
point . setData ( vari . read ( "" + index ) ) ; 
point . setNext ( new CFPoint ( ) ) ; 
point = point . getNext ( ) ; 
point = point . getPrev ( ) ; 
point . setNext ( null ) ; 
} catch ( InvalidDataseriesException e ) { 
} public static String formFilename ( String dirPath , String filePath ) { 
if ( ( dirPath == null ) || ( filePath == null ) ) 
if ( filePath . startsWith ( "/" ) ) 
filePath = filePath . substring ( 1 ) ; 
return dirPath . endsWith ( "/" ) ? dirPath + filePath : dirPath + "/" + filePath ; 
} public static void returnFile ( HttpServlet servlet , String contentPath , String path , 
HttpServletRequest req , HttpServletResponse res , String contentType ) throws IOException { 
String filename = ServletUtil . formFilename ( contentPath , path ) ; 
if ( filename == null ) { 
res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; 
if ( filename . contains ( ".." ) ) { 
res . sendError ( HttpServletResponse . SC_FORBIDDEN ) ; 
String upper = filename . toUpperCase ( ) ; 
if ( upper . contains ( "WEB-INF" ) || upper . contains ( "META-INF" ) ) { 
returnFile ( servlet , req , res , new File ( filename ) , contentType ) ; 
} public static void returnFile ( HttpServlet servlet , HttpServletRequest req , HttpServletResponse res , File file , String contentType ) 
if ( file == null ) { 
if ( ! file . exists ( ) ) { 
if ( ! file . isFile ( ) ) { 
String filename = file . getPath ( ) ; 
if ( null == contentType ) { 
if ( filename . endsWith ( ".html" ) ) 
contentType = ContentType . html . getContentHeader ( ) ; 
else if ( filename . endsWith ( ".xml" ) ) 
contentType = ContentType . xml . getContentHeader ( ) ; 
else if ( filename . endsWith ( ".txt" ) || ( filename . endsWith ( ".log" ) ) ) 
contentType = ContentType . text . getContentHeader ( ) ; 
else if ( filename . indexOf ( ".log." ) > 0 ) 
else if ( filename . endsWith ( ".nc" ) ) 
contentType = ContentType . netcdf . getContentHeader ( ) ; 
else if ( filename . endsWith ( ".nc4" ) ) 
else if ( servlet != null ) 
contentType = servlet . getServletContext ( ) . getMimeType ( filename ) ; 
if ( contentType == null ) contentType = ContentType . binary . getContentHeader ( ) ; 
returnFile ( req , res , file , contentType ) ; 
} public static void returnFile ( HttpServletRequest req , HttpServletResponse res , File file , String contentType ) throws IOException { 
res . setContentType ( contentType ) ; 
res . addDateHeader ( "Last-Modified" , file . lastModified ( ) ) ; 
boolean isRangeRequest = false ; 
long startPos = 0 , endPos = Long . MAX_VALUE ; 
String rangeRequest = req . getHeader ( "Range" ) ; 
if ( rangeRequest != null ) { 
int pos = rangeRequest . indexOf ( "=" ) ; 
int pos2 = rangeRequest . indexOf ( "-" ) ; 
if ( pos2 > 0 ) { 
String startString = rangeRequest . substring ( pos + 1 , pos2 ) ; 
String endString = rangeRequest . substring ( pos2 + 1 ) ; 
startPos = Long . parseLong ( startString ) ; 
if ( endString . length ( ) > 0 ) 
endPos = Long . parseLong ( endString ) + 1 ; 
isRangeRequest = true ; 
long fileSize = file . length ( ) ; 
long contentLength = fileSize ; 
if ( isRangeRequest ) { 
endPos = Math . min ( endPos , fileSize ) ; 
contentLength = endPos - startPos ; 
if ( contentLength > Integer . MAX_VALUE ) 
res . addHeader ( "Content-Length" , Long . toString ( contentLength ) ) ; 
res . setContentLength ( ( int ) contentLength ) ; 
if ( req . getMethod ( ) . equals ( "HEAD" ) ) { 
res . setStatus ( HttpServletResponse . SC_PARTIAL_CONTENT ) ; 
try ( RandomAccessFile craf = RandomAccessFile . acquire ( filename ) ) { 
IO . copyRafB ( craf , startPos , contentLength , res . getOutputStream ( ) , new byte [ 60000 ] ) ; 
ServletOutputStream out = res . getOutputStream ( ) ; 
IO . copyFileB ( file , out , 60 * 1000 ) ; 
catch ( FileNotFoundException e ) { 
if ( ! res . isCommitted ( ) ) res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; 
} catch ( java . net . SocketException e ) { 
String eName = e . getClass ( ) . getName ( ) ; 
if ( eName . equals ( "org.apache.catalina.connector.ClientAbortException" ) ) { 
} public static void returnString ( String contents , HttpServletResponse res ) 
IO . copy ( new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) , out ) ; 
} public static int setResponseContentLength ( HttpServletResponse response , String s ) throws UnsupportedEncodingException { 
int length = s . getBytes ( response . getCharacterEncoding ( ) ) . length ; 
response . setContentLength ( length ) ; 
} public static String getReletiveURL ( HttpServletRequest req ) { 
return req . getContextPath ( ) + req . getServletPath ( ) + req . getPathInfo ( ) ; 
} public static void forwardToCatalogServices ( HttpServletRequest req , HttpServletResponse res ) 
throws IOException , ServletException { 
String reqs = "catalog=" + getReletiveURL ( req ) ; 
if ( query != null ) 
reqs = reqs + "&" + query ; 
RequestForwardUtils . forwardRequestRelativeToCurrentContext ( "/catalog.html?" + reqs , req , res ) ; 
} public static String getRequestServer ( HttpServletRequest req ) { 
return req . getScheme ( ) + "://" + req . getServerName ( ) + ":" + req . getServerPort ( ) ; 
} public static URI getRequestURI ( HttpServletRequest req ) { 
return new URI ( getRequestBase ( req ) ) ; 
} public static String getRequestPath ( HttpServletRequest req ) { 
if ( req . getServletPath ( ) != null ) 
buff . append ( req . getServletPath ( ) ) ; 
if ( req . getPathInfo ( ) != null ) 
buff . append ( req . getPathInfo ( ) ) ; 
} public static String getRequest ( HttpServletRequest req ) { 
return getRequestBase ( req ) + ( query == null ? "" : "?" + query ) ; 
} public static String getParameterIgnoreCase ( HttpServletRequest req , String paramName ) { 
Enumeration e = req . getParameterNames ( ) ; 
String s = ( String ) e . nextElement ( ) ; 
if ( s . equalsIgnoreCase ( paramName ) ) 
return req . getParameter ( s ) ; 
} static public String showRequestDetail ( HttpServletRequest req ) { 
sbuff . append ( "\n" ) ; 
} catch ( java . net . UnknownHostException e ) { 
Enumeration params = req . getParameterNames ( ) ; 
while ( params . hasMoreElements ( ) ) { 
String name = ( String ) params . nextElement ( ) ; 
String values [ ] = req . getParameterValues ( name ) ; 
if ( values != null ) { 
Enumeration names = req . getHeaderNames ( ) ; 
String name = ( String ) names . nextElement ( ) ; 
Enumeration values = req . getHeaders ( name ) ; 
while ( values . hasMoreElements ( ) ) { 
String value = ( String ) values . nextElement ( ) ; 
} static public String showSecurity ( HttpServletRequest req , String role ) { 
} static public void showThreads ( PrintStream pw ) { 
Thread current = Thread . currentThread ( ) ; 
ThreadGroup group = current . getThreadGroup ( ) ; 
if ( group . getParent ( ) == null ) break ; 
showThreads ( pw , group , current ) ; 
String units = v . getUnitsString ( ) ; 
if ( units . equalsIgnoreCase ( CDM . LON_UNITS ) ) 
if ( units . equalsIgnoreCase ( CDM . LAT_UNITS ) ) 
if ( vname . equalsIgnoreCase ( "record" ) ) 
if ( ( dim != null ) && dim . getShortName ( ) . equalsIgnoreCase ( "record" ) ) 
if ( SimpleUnit . isCompatible ( "millibar" , unit ) ) 
if ( catListBox != null ) catListBox . save ( ) ; 
if ( fileChooser != null ) 
fileChooser . save ( ) ; 
if ( catgenFileChooser != null ) 
catgenFileChooser . save ( ) ; 
prefs . putInt ( HDIVIDER , split . getDividerLocation ( ) ) ; 
} public JDialog makeDialog ( RootPaneContainer parent , String title , boolean modal ) { 
return new Dialog ( parent , title , modal ) ; 
} public int writeDirectory ( HttpServletResponse res , File dir , String path ) throws IOException { 
if ( ! dir . exists ( ) || ! dir . isDirectory ( ) ) { 
String dirHtmlString = getDirectory ( path , dir ) ; 
thredds . servlet . ServletUtil . setResponseContentLength ( res , dirHtmlString ) ; 
writer . write ( dirHtmlString ) ; 
return dirHtmlString . length ( ) ; 
} static ArrayFloat factory ( Index index , float [ ] storage ) { 
return new ArrayFloat . D0 ( index , storage ) ; 
return new ArrayFloat . D1 ( index , storage ) ; 
return new ArrayFloat . D2 ( index , storage ) ; 
return new ArrayFloat . D3 ( index , storage ) ; 
return new ArrayFloat . D4 ( index , storage ) ; 
return new ArrayFloat . D5 ( index , storage ) ; 
return new ArrayFloat . D6 ( index , storage ) ; 
return new ArrayFloat . D7 ( index , storage ) ; 
return new ArrayFloat ( index , storage ) ; 
float [ ] ja = ( float [ ] ) javaArray ; 
for ( float aJa : ja ) iter . setFloatNext ( aJa ) ; 
} public static TimePositionType initTime ( TimePositionType time , PointFeature pointFeat ) { 
time . setStringValue ( pointFeat . getNominalTimeAsCalendarDate ( ) . toString ( ) ) ; 
return time ; 
} public static TimePositionType initBeginPosition ( 
TimePositionType beginPosition , CalendarDate date ) throws IOException { 
beginPosition . setStringValue ( date . toString ( ) ) ; 
return beginPosition ; 
} public static TimePositionType initEndPosition ( 
TimePositionType endPosition , CalendarDate date ) throws IOException { 
endPosition . setStringValue ( date . toString ( ) ) ; 
return endPosition ; 
} public static TimePositionType initTimePosition ( TimePositionType timePosition ) { 
DateTime resultTime = MarshallingUtil . fixedResultTime ; 
if ( resultTime == null ) { 
resultTime = new DateTime ( ) ; 
timePosition . setStringValue ( resultTime . toString ( ) ) ; 
return timePosition ; 
String format = ncd . findAttValueIgnoreCase ( null , "format" , null ) ; 
if ( format != null ) { 
if ( format . startsWith ( "nssl/netcdf" ) ) 
Dimension az = ncd . findDimension ( "Azimuth" ) ; 
Dimension gt = ncd . findDimension ( "Gate" ) ; 
if ( ( null != az ) && ( null != gt ) ) { 
} public void setBitOffset ( DataDescriptor dkey ) { 
if ( bitPosition == null ) 
bitPosition = new HashMap < DataDescriptor , Integer > ( 2 * parent . getSubKeys ( ) . size ( ) ) ; 
bitPosition . put ( dkey , bitOffset ) ; 
bitOffset += dkey . getBitWidth ( ) ; 
} public BitCounterUncompressed makeNested ( DataDescriptor subKey , int n , int row , int replicationCountSize ) { 
if ( subCounters == null ) 
subCounters = new HashMap < DataDescriptor , BitCounterUncompressed [ ] > ( 5 ) ; 
BitCounterUncompressed [ ] subCounter = subCounters . get ( subKey ) ; 
if ( subCounter == null ) { 
subCounter = new BitCounterUncompressed [ nrows ] ; 
subCounters . put ( subKey , subCounter ) ; 
BitCounterUncompressed rc = new BitCounterUncompressed ( subKey , n , replicationCountSize ) ; 
subCounter [ row ] = rc ; 
return rc ; 
} int countBits ( int startBit ) { 
countBits = replicationCountSize ; 
this . startBit = new int [ nrows ] ; 
this . startBit [ i ] = startBit + countBits ; 
for ( DataDescriptor nd : parent . subKeys ) { 
BitCounterUncompressed [ ] bitCounter = ( subCounters == null ) ? null : subCounters . get ( nd ) ; 
if ( bitCounter == null ) 
countBits += nd . getBitWidth ( ) ; 
countBits += bitCounter [ i ] . countBits ( startBit + countBits ) ; 
return countBits ; 
} private Map < Integer , Grib2Parameter > initLocalTable ( String resourcePath , @ Nullable Formatter f ) { 
Map < Integer , Grib2Parameter > result = new HashMap < > ( 100 ) ; 
try ( InputStream is = GribResourceReader . getInputStream ( resourcePath ) ) { 
TableParser parser = new TableParser ( "3i,7i,11i,15i,49,69,74," ) ; 
parser . setComment ( "!" ) ; 
List < TableParser . Record > recs = parser . readAllRecords ( is , 50000 ) ; 
int disc = ( Integer ) record . get ( 0 ) ; 
int cat = ( Integer ) record . get ( 1 ) ; 
int id = ( Integer ) record . get ( 2 ) ; 
int template = ( Integer ) record . get ( 3 ) ; 
String name = ( ( String ) record . get ( 4 ) ) . trim ( ) ; 
String units = ( ( String ) record . get ( 5 ) ) . trim ( ) ; 
String gname = ( ( String ) record . get ( 6 ) ) . trim ( ) ; 
String ids = disc + "-" + cat + "-" + id ; 
Grib2Parameter gp = new Grib2Parameter ( disc , cat , id , gname , units , null , name ) ; 
result . put ( Grib2Tables . makeParamId ( disc , cat , id ) , gp ) ; 
} public void appendLine ( String line ) { 
if ( count >= nlines ) { 
int remove = Math . max ( removeIncr , count - nlines ) ; 
int offset = ta . getLineEndOffset ( remove ) ; 
ta . replaceRange ( "" , 0 , offset ) ; 
count = nlines - removeIncr ; 
ta . append ( line ) ; 
ta . append ( "\n" ) ; 
ta . setCaretPosition ( ta . getText ( ) . length ( ) ) ; 
while ( token < 0 ) { 
if ( ( c = read ( ) ) <= 0 ) break ; 
while ( more && ( c = read ( ) ) > 0 ) { 
if ( c == '"' ) 
else if ( c == '\\' ) { 
token = SCAN_STRINGCONST ; 
} else if ( false && numchars1 . indexOf ( c ) >= 0 ) { 
boolean isnumber = false ; 
while ( ( c = read ( ) ) > 0 ) { 
if ( numcharsn . indexOf ( c ) < 0 ) { 
pushback ( c ) ; 
removetrailingblanks ( ) ; 
Double number = new Double ( yytext . toString ( ) ) ; 
isnumber = true ; 
isnumber = false ; 
if ( isnumber ) { 
if ( wordcharsn . indexOf ( c ) >= 0 ) { 
token = SCAN_WORD ; 
token = SCAN_NUMBERCONST ; 
if ( c != '\0' ) pushback ( c ) ; 
int dotpoint = yytext . toString ( ) . indexOf ( '.' ) ; 
if ( dotpoint >= 0 ) { 
for ( int i = 0 ; i < dotpoint ; i ++ ) { 
pushback ( yytext . charAt ( i ) ) ; 
yytext . setLength ( dotpoint ) ; 
} else if ( wordornumberchars1 . indexOf ( c ) >= 0 ) { 
if ( wordornumbercharsn . indexOf ( c ) < 0 ) { 
new Double ( yytext . toString ( ) ) ; 
if ( isnumber ) 
for ( int i = yytext . length ( ) - 1 ; i >= 0 ; i -- ) 
if ( dotpoint == 0 ) { 
token = '.' ; 
yytext . append ( ( char ) ( c = read ( ) ) ) ; 
for ( int i = 0 ; i < dotpoint ; i ++ ) 
if ( token < 0 ) { 
String text = yytext . toString ( ) ; 
if ( token == SCAN_WORD ) 
text = EscapeStrings . unescapeDAPIdentifier ( text ) ; 
lval = ( text . length ( ) == 0 ? ( String ) null : text ) ; 
if ( parsestate . getDebugLevel ( ) > 0 ) dumptoken ( token , ( String ) lval ) ; 
if ( yytext . length ( ) > 0 ) 
if ( parsestate . getURL ( ) != null ) Ceparse . log . error ( "\turl=" + parsestate . getURL ( ) ) ; 
Ceparse . log . error ( "\tconstraint=" + ( constraint == null ? "none" : constraint ) ) ; 
comp . setOpaque ( true ) ; 
comp . setBackground ( Color . white ) ; 
comp . setForeground ( Color . black ) ; 
comp . addMouseListener ( new MyMouseAdapter ( ) ) ; 
main . add ( comp ) ; 
findByName ( String shortname ) 
for ( DapVariable field : fields ) { 
if ( shortname . equals ( field . getShortName ( ) ) ) 
return field ; 
} public Document makeStationCollectionDocument ( LatLonRect bb , String [ ] names ) throws IOException { 
List < DsgFeatureCollection > list = fdp . getPointFeatureCollectionList ( ) ; 
DsgFeatureCollection fc = list . get ( 0 ) ; 
if ( ! ( fc instanceof StationTimeSeriesFeatureCollection ) ) { 
StationTimeSeriesFeatureCollection sobs = ( StationTimeSeriesFeatureCollection ) fc ; 
List < StationFeature > stations ; 
stations = sobs . getStationFeatures ( bb ) ; 
else if ( names != null ) 
stations = sobs . getStationFeatures ( Arrays . asList ( names ) ) ; 
stations = sobs . getStationFeatures ( ) ; 
for ( Station s : stations ) { 
if ( ( s . getDescription ( ) != null ) && ( s . getDescription ( ) . length ( ) > 0 ) ) 
sElem . addContent ( new Element ( "longitude" ) . addContent ( Double . toString ( s . getLongitude ( ) ) ) ) ; 
sElem . addContent ( new Element ( "latitide" ) . addContent ( Double . toString ( s . getLatitude ( ) ) ) ) ; 
sElem . addContent ( new Element ( "altitude" ) . addContent ( Double . toString ( s . getAltitude ( ) ) ) ) ; 
} public Document getCapabilitiesDocument ( ) { 
Element rootElem = new Element ( "capabilities" ) ; 
if ( null != path ) { 
rootElem . setAttribute ( "location" , path ) ; 
Element elem = new Element ( "featureDataset" ) ; 
FeatureType ft = fdp . getFeatureType ( ) ; 
elem . setAttribute ( "type" , ft . toString ( ) . toLowerCase ( ) ) ; 
String url = path . replace ( "dataset.xml" , ft . toString ( ) . toLowerCase ( ) + ".xml" ) ; 
elem . setAttribute ( "url" , url ) ; 
rootElem . addContent ( writeTimeUnit ( fc . getTimeUnit ( ) ) ) ; 
rootElem . addContent ( new Element ( "AltitudeUnits" ) . addContent ( fc . getAltUnits ( ) ) ) ; 
List < ? extends VariableSimpleIF > vars = fdp . getDataVariables ( ) ; 
LatLonRect bb = fc . getBoundingBox ( ) ; 
CalendarDateRange dateRange = fc . getCalendarDateRange ( ) ; 
if ( dateRange != null ) { 
Element drElem = new Element ( "TimeSpan" ) ; 
drElem . addContent ( new Element ( "begin" ) . addContent ( dateRange . getStart ( ) . toString ( ) ) ) ; 
drElem . addContent ( new Element ( "end" ) . addContent ( dateRange . getEnd ( ) . toString ( ) ) ) ; 
if ( dateRange . getResolution ( ) != null ) 
drElem . addContent ( new Element ( "resolution" ) . addContent ( dateRange . getResolution ( ) . toString ( ) ) ) ; 
rootElem . addContent ( drElem ) ; 
} static ArrayByte factory ( Index index , boolean isUnsigned ) { 
return ArrayByte . factory ( index , isUnsigned , null ) ; 
byte [ ] ja = ( byte [ ] ) javaArray ; 
for ( byte aJa : ja ) iter . setByteNext ( aJa ) ; 
} public double getDouble ( int index ) { 
byte val = storage [ index ] ; 
return ( double ) ( isUnsigned ( ) ? DataType . unsignedByteToShort ( val ) : val ) ; 
synchronized Record getRecordAt ( SubsetParams coords ) { 
int [ ] want = new int [ getRank ( ) ] ; 
int runIdx = - 1 ; 
for ( Coordinate coord : getCoordinates ( ) ) { 
int idx = - 1 ; 
CalendarDate runtimeCooord = coords . getRunTime ( ) ; 
idx = coord . getIndex ( runtimeCooord ) ; 
runIdx = idx ; 
double [ ] timeIntv = coords . getTimeOffsetIntv ( ) ; 
idx = coord . getIndex ( new TimeCoordIntvValue ( ( int ) timeIntv [ 0 ] , ( int ) timeIntv [ 1 ] ) ) ; 
Double timeOffset = coords . getTimeOffset ( ) ; 
int coordInt = timeOffset . intValue ( ) ; 
idx = coord . getIndex ( coordInt ) ; 
timeIntv = coords . getTimeOffsetIntv ( ) ; 
if ( timeIntv != null ) { 
TimeCoordIntvValue coordTinv = new TimeCoordIntvValue ( ( int ) timeIntv [ 0 ] , ( int ) timeIntv [ 1 ] ) ; 
idx = ( ( CoordinateTime2D ) coord ) . findTimeIndexFromVal ( runIdx , coordTinv ) ; 
Double timeCoord = coords . getTimeOffset ( ) ; 
if ( timeCoord != null ) { 
coordInt = timeCoord . intValue ( ) ; 
idx = ( ( CoordinateTime2D ) coord ) . findTimeIndexFromVal ( runIdx , coordInt ) ; 
if ( coord2D . getNtimes ( ) == 1 ) { 
idx = 0 ; 
double [ ] vertIntv = coords . getVertCoordIntv ( ) ; 
if ( vertIntv != null ) { 
VertCoordValue coordVert = new VertCoordValue ( vertIntv [ 0 ] , vertIntv [ 1 ] ) ; 
idx = coord . getIndex ( coordVert ) ; 
Double vertCoord = coords . getVertCoord ( ) ; 
if ( vertCoord != null ) { 
VertCoordValue coordVert = new VertCoordValue ( vertCoord ) ; 
Double ensVal = coords . getEnsCoord ( ) ; 
idx = ( ( CoordinateEns ) coord ) . getIndexByMember ( ensVal ) ; 
if ( idx < 0 ) { 
want [ count ++ ] = idx ; 
return sa . getContent ( want ) ; 
} public Coordinate getCoordinate ( int index ) { 
int grpIndex = coordIndex . get ( index ) ; 
return group . coords . get ( grpIndex ) ; 
} public DapAttribute 
newAttribute ( String name , DapType basetype ) 
DapAttribute node = new DapAttribute ( name , basetype ) ; 
} public void addItem ( Object item ) { 
if ( item == null ) return ; 
for ( int i = 0 ; i < getItemCount ( ) ; i ++ ) { 
if ( item . equals ( getItemAt ( i ) ) ) { 
setSelectedIndex ( 0 ) ; 
removeItemAt ( i ) ; 
insertItemAt ( item , 0 ) ; 
} public List < Object > getItemList ( ) { 
ArrayList < Object > list = new ArrayList < Object > ( ) ; 
for ( int i = 0 ; i < getItemCount ( ) && i < nkeep ; i ++ ) 
list . add ( getItemAt ( i ) ) ; 
public void setItemList ( Collection < Object > list ) { 
if ( list == null ) return ; 
setModel ( new DefaultComboBoxModel ( list . toArray ( ) ) ) ; 
if ( list . size ( ) > 0 ) 
public void setNkeep ( int nkeep ) { this . nkeep = nkeep ; } 
public int getNkeep ( ) { return nkeep ; } 
protected Object getStoreValue ( Object defValue ) { 
if ( prefs == null ) 
return defValue ; 
return ( ( PreferencesExt ) prefs ) . getBean ( LIST , defValue ) ; 
protected void setStoreValue ( List newValue ) { 
if ( prefs != null ) 
prefs . putList ( LIST , newValue ) ; 
private static long lastEvent ; 
public static void main ( String args [ ] ) throws IOException { 
JFrame frame = new JFrame ( "Test" ) ; 
final ComboBox cb = new ComboBox ( null ) ; 
cb . addActionListener ( e -> { 
if ( e . getActionCommand ( ) . equals ( "comboBoxChanged" ) ) { 
cb . addItem ( cb . getSelectedItem ( ) ) ; 
cb . getEditor ( ) . getEditorComponent ( ) . setForeground ( Color . red ) ; 
JPanel main = new JPanel ( ) ; 
main . add ( cb ) ; 
int nz = ( int ) pressure . getSize ( ) ; 
int [ ] shape2D = pressure . getShape ( ) ; 
IndexIterator ii = pressure . getIndexIterator ( ) ; 
double p = ii . getDoubleNext ( ) ; 
result . set ( z , y , x , p ) ; 
} @ ExceptionHandler ( Throwable . class ) 
public ResponseEntity < String > handle ( Throwable ex ) throws Throwable { 
if ( AnnotationUtils . findAnnotation ( ex . getClass ( ) , ResponseStatus . class ) != null ) 
String msg = ex . getMessage ( ) ; 
ex . printStackTrace ( p ) ; 
msg = sw . toString ( ) ; 
slice ( int i ) 
if ( i < 0 || i >= this . rank ) 
return this . slices . get ( i ) ; 
size *= this . slices . get ( i ) . getCount ( ) ; 
int stop = this . rank ; 
switch ( this . state ) { 
for ( i = stop - 1 ; i >= 0 ; i -- ) { 
if ( this . index . indices [ i ] <= this . endpoint [ i ] ) 
this . state = STATE . DONE ; 
step ( int firstpos , int lastpos ) 
for ( int i = lastpos - 1 ; i >= firstpos ; i -- ) { 
if ( this . index . indices [ i ] > this . endpoint [ i ] ) 
this . index . indices [ i ] = this . slices . get ( i ) . getFirst ( ) ; 
this . index . indices [ i ] += this . slices . get ( i ) . getStride ( ) ; 
public GribStatType getStatType ( int timeRangeIndicator ) { 
case 128 : 
case 129 : 
case 130 : 
case 131 : 
case 132 : 
case 133 : 
case 137 : 
case 138 : 
case 139 : 
case 140 : 
return GribStatType . RootMeanSquare ; 
case 136 : 
return super . getStatType ( timeRangeIndicator ) ; 
public static Map < Integer , String > getNcepGenProcess ( ) { 
if ( genProcessMap != null ) return genProcessMap ; 
String path = "resources/grib1/ncep/ncepTableA.xml" ; 
HashMap < Integer , String > result = new HashMap < > ( 200 ) ; 
List < Element > params = root . getChildren ( "parameter" ) ; 
int code = Integer . parseInt ( elem1 . getAttributeValue ( "code" ) ) ; 
result . put ( code , desc ) ; 
} catch ( IOException | JDOMException ioe ) { 
if ( code < 129 ) 
levelTypesMap = readTable3 ( "resources/grib1/ncep/ncepTable3.xml" ) ; 
} boolean writeIndex ( String name , File idxFile , CoordinateRuntime masterRuntime , List < Group > groups , List < MFile > files , 
GribCollectionImmutable . Type type , CalendarDateRange dateRange ) throws IOException { 
Grib2Record first = null ; 
boolean deleteOnClose = false ; 
if ( idxFile . exists ( ) ) { 
if ( ! idxFile . delete ( ) ) { 
try ( RandomAccessFile raf = new RandomAccessFile ( idxFile . getPath ( ) , "rw" ) ) { 
long lenPos = raf . getFilePointer ( ) ; 
raf . writeLong ( 0 ) ; 
long countBytes = 0 ; 
int countRecords = 0 ; 
Set < Integer > allFileSet = new HashSet < > ( ) ; 
g . fileSet = new HashSet < > ( ) ; 
for ( Grib2CollectionBuilder . VariableBag vb : g . gribVars ) { 
if ( first == null ) first = vb . first ; 
GribCollectionProto . SparseArray vr = writeSparseArray ( vb , g . fileSet ) ; 
byte [ ] b = vr . toByteArray ( ) ; 
vb . pos = raf . getFilePointer ( ) ; 
vb . length = b . length ; 
countBytes += b . length ; 
countRecords += vb . coordND . getSparseArray ( ) . countNotMissing ( ) ; 
allFileSet . addAll ( g . fileSet ) ; 
long bytesPerRecord = countBytes / ( ( countRecords == 0 ) ? 1 : countRecords ) ; 
if ( first == null ) { 
deleteOnClose = true ; 
raf . seek ( lenPos ) ; 
raf . writeLong ( countBytes ) ; 
GribCollectionProto . GribCollection . Builder indexBuilder = GribCollectionProto . GribCollection . newBuilder ( ) ; 
indexBuilder . setName ( name ) ; 
indexBuilder . setTopDir ( dcm . getRoot ( ) ) ; 
indexBuilder . setVersion ( currentVersion ) ; 
File directory = new File ( dcm . getRoot ( ) ) ; 
List < GcMFile > gcmfiles = GcMFile . makeFiles ( directory , files , allFileSet ) ; 
for ( GcMFile gcmfile : gcmfiles ) { 
GribCollectionProto . MFile . Builder b = GribCollectionProto . MFile . newBuilder ( ) ; 
b . setFilename ( gcmfile . getName ( ) ) ; 
b . setLastModified ( gcmfile . getLastModified ( ) ) ; 
b . setLength ( gcmfile . getLength ( ) ) ; 
b . setIndex ( gcmfile . index ) ; 
indexBuilder . addMfiles ( b . build ( ) ) ; 
indexBuilder . setMasterRuntime ( writeCoordProto ( masterRuntime ) ) ; 
for ( Object go : groups ) { 
Group g = ( Group ) go ; 
indexBuilder . addGds ( writeGdsProto ( g . gdss . getRawBytes ( ) , - 1 ) ) ; 
indexBuilder . addDataset ( writeDatasetProto ( type , groups ) ) ; 
Grib2SectionIdentification ids = first . getId ( ) ; 
indexBuilder . setCenter ( ids . getCenter_id ( ) ) ; 
indexBuilder . setSubcenter ( ids . getSubcenter_id ( ) ) ; 
indexBuilder . setMaster ( ids . getMaster_table_version ( ) ) ; 
indexBuilder . setLocal ( ids . getLocal_table_version ( ) ) ; 
Grib2Pds pds = first . getPDS ( ) ; 
indexBuilder . setGenProcessType ( pds . getGenProcessType ( ) ) ; 
indexBuilder . setGenProcessId ( pds . getGenProcessId ( ) ) ; 
indexBuilder . setBackProcessId ( pds . getBackProcessId ( ) ) ; 
indexBuilder . setStartTime ( dateRange . getStart ( ) . getMillis ( ) ) ; 
indexBuilder . setEndTime ( dateRange . getEnd ( ) . getMillis ( ) ) ; 
GribCollectionProto . GribCollection index = indexBuilder . build ( ) ; 
if ( deleteOnClose && ! idxFile . delete ( ) ) 
} private GribCollectionProto . SparseArray writeSparseArray ( Grib2CollectionBuilder . VariableBag vb , Set < Integer > fileSet ) { 
GribCollectionProto . SparseArray . Builder b = GribCollectionProto . SparseArray . newBuilder ( ) ; 
SparseArray < Grib2Record > sa = vb . coordND . getSparseArray ( ) ; 
for ( int size : sa . getShape ( ) ) 
b . addSize ( size ) ; 
for ( int track : sa . getTrack ( ) ) 
b . addTrack ( track ) ; 
for ( Grib2Record gr : sa . getContent ( ) ) { 
GribCollectionProto . Record . Builder br = GribCollectionProto . Record . newBuilder ( ) ; 
br . setFileno ( gr . getFile ( ) ) ; 
fileSet . add ( gr . getFile ( ) ) ; 
long startPos = gr . getIs ( ) . getStartPos ( ) ; 
br . setStartPos ( startPos ) ; 
if ( gr . isBmsReplaced ( ) ) { 
Grib2SectionBitMap bms = gr . getBitmapSection ( ) ; 
br . setBmsOffset ( ( int ) ( bms . getStartingPosition ( ) - startPos ) ) ; 
br . setDrsOffset ( ( int ) ( drs . getStartingPosition ( ) - startPos ) ) ; 
b . addRecords ( br ) ; 
b . setNdups ( sa . getNdups ( ) ) ; 
return b . build ( ) ; 
} public DatasetScanConfig readDatasetScanConfig ( Element dsElem ) { 
DatasetScanConfig result = new DatasetScanConfig ( ) ; 
result . name = dsElem . getAttributeValue ( "name" ) ; 
result . path = StringUtil2 . trim ( dsElem . getAttributeValue ( "path" ) , '/' ) ; 
if ( result . path == null ) { 
fatalError = true ; 
String scanDir = dsElem . getAttributeValue ( "location" ) ; 
if ( scanDir == null ) { 
result . scanDir = AliasTranslator . translateAlias ( scanDir ) ; 
File scanFile = new File ( result . scanDir ) ; 
if ( ! scanFile . exists ( ) ) { 
result . restrictAccess = dsElem . getAttributeValue ( "restrictAccess" ) ; 
Element ncmlElem = dsElem . getChild ( "netcdf" , Catalog . defNS ) ; 
if ( ncmlElem != null ) { 
ncmlElem . detach ( ) ; 
result . ncmlElement = ncmlElem ; 
Element filterElem = dsElem . getChild ( "filter" , Catalog . defNS ) ; 
result . filters = readDatasetScanFilter ( filterElem ) ; 
Element namerElem = dsElem . getChild ( "namer" , Catalog . defNS ) ; 
result . namers = readDatasetScanNamer ( namerElem ) ; 
Element filesSortElem = dsElem . getChild ( "filesSort" , Catalog . defNS ) ; 
if ( filesSortElem != null ) 
result . isSortIncreasing = readFilesSort ( filesSortElem ) ; 
Element sorterElem = dsElem . getChild ( "sort" , Catalog . defNS ) ; 
if ( ! result . isSortIncreasing . isPresent ( ) && sorterElem != null ) 
result . isSortIncreasing = readSort ( sorterElem ) ; 
String addLatestAttribute = dsElem . getAttributeValue ( "addLatest" ) ; 
Element addLatestElem = dsElem . getChild ( "addLatest" , Catalog . defNS ) ; 
Element addProxiesElem = dsElem . getChild ( "addProxies" , Catalog . defNS ) ; 
result . addLatest = readDatasetScanAddProxies ( addProxiesElem , addLatestElem , addLatestAttribute ) ; 
Element addTimeCovElem = dsElem . getChild ( "addTimeCoverage" , Catalog . defNS ) ; 
if ( addTimeCovElem != null ) { 
result . addTimeCoverage = readDatasetScanAddTimeCoverage ( addTimeCovElem ) ; 
} private List < DatasetScanConfig . Filter > readDatasetScanFilter ( Element filterElem ) { 
List < DatasetScanConfig . Filter > filters = new ArrayList < > ( ) ; 
if ( filterElem == null ) return null ; 
for ( Element curElem : filterElem . getChildren ( ) ) { 
String regExpAttVal = curElem . getAttributeValue ( "regExp" ) ; 
String wildcardAttVal = curElem . getAttributeValue ( "wildcard" ) ; 
String lastModLimitAttValS = curElem . getAttributeValue ( "lastModLimitInMillis" ) ; 
if ( regExpAttVal == null && wildcardAttVal == null && lastModLimitAttValS == null ) { 
String atomicAttVal = curElem . getAttributeValue ( "atomic" ) ; 
boolean atomic = ( atomicAttVal == null || ! atomicAttVal . equalsIgnoreCase ( "false" ) ) ; 
String collectionAttVal = curElem . getAttributeValue ( "collection" ) ; 
boolean notCollection = collectionAttVal == null || ! collectionAttVal . equalsIgnoreCase ( "true" ) ; 
boolean includer = true ; 
if ( curElem . getName ( ) . equals ( "exclude" ) ) { 
includer = false ; 
} else if ( ! curElem . getName ( ) . equals ( "include" ) ) { 
long lastModLimitAttVal = - 1 ; 
if ( lastModLimitAttValS != null ) { 
lastModLimitAttVal = Long . parseLong ( lastModLimitAttValS ) ; 
filters . add ( new DatasetScanConfig . Filter ( regExpAttVal , wildcardAttVal , lastModLimitAttVal , atomic , ! notCollection , includer ) ) ; 
return filters ; 
} protected List < DatasetScanConfig . Namer > readDatasetScanNamer ( Element namerElem ) { 
List < DatasetScanConfig . Namer > result = new ArrayList < > ( ) ; 
if ( namerElem == null ) return result ; 
for ( Element curElem : namerElem . getChildren ( ) ) { 
String regExp = curElem . getAttributeValue ( "regExp" ) ; 
String replaceString = curElem . getAttributeValue ( "replaceString" ) ; 
boolean onName = curElem . getName ( ) . equals ( "regExpOnName" ) ; 
boolean onPath = curElem . getName ( ) . equals ( "regExpOnPath" ) ; 
if ( ! onName && ! onPath ) { 
result . add ( new DatasetScanConfig . Namer ( onName , regExp , replaceString ) ) ; 
} protected Optional < Boolean > readFilesSort ( Element sorterElem ) { 
String increasingString = sorterElem . getAttributeValue ( "increasing" ) ; 
if ( increasingString != null ) { 
if ( increasingString . equalsIgnoreCase ( "true" ) ) 
return Optional . of ( true ) ; 
else if ( increasingString . equalsIgnoreCase ( "false" ) ) 
return Optional . of ( false ) ; 
return Optional . empty ( ) ; 
} protected DatasetScanConfig . AddTimeCoverage readDatasetScanAddTimeCoverage ( Element addTimeCovElem ) { 
boolean err = false ; 
if ( subst == null ) { 
err = true ; 
} else if ( duration == null ) { 
} else if ( matchName == null && matchPath == null ) { 
return err ? null : new DatasetScanConfig . AddTimeCoverage ( matchName , matchPath , subst , duration ) ; 
} public static FeatureType isCdmrfEndpoint ( String endpoint ) throws IOException { 
HTTPSession httpClient = HTTPFactory . newSession ( endpoint ) ; 
String url = endpoint + "?req=featureType" ; 
try ( HTTPMethod method = HTTPFactory . Get ( httpClient , url ) ) { 
if ( statusCode != 200 ) return null ; 
String content = method . getResponseAsString ( ) ; 
return FeatureType . getType ( content ) ; 
} public void SetHasValue ( int type ) { 
} public static TimePeriodType initTimePeriod ( 
TimePeriodType timePeriod , StationTimeSeriesFeature stationFeat ) throws IOException { 
String id = MarshallingUtil . createIdForType ( TimePeriodType . class ) ; 
timePeriod . setId ( id ) ; 
CollectionInfo info ; 
info = new DsgCollectionHelper ( stationFeat ) . calcBounds ( ) ; 
CalendarDateRange cdr = info . getCalendarDateRange ( stationFeat . getTimeUnit ( ) ) ; 
if ( cdr != null ) { 
NcTimePositionType . initBeginPosition ( timePeriod . addNewBeginPosition ( ) , cdr . getStart ( ) ) ; 
NcTimePositionType . initEndPosition ( timePeriod . addNewEndPosition ( ) , cdr . getEnd ( ) ) ; 
return timePeriod ; 
} public static Grib1Gds factory ( int center , int gridNumber ) { 
if ( center == 7 ) { 
return factoryNCEP ( gridNumber ) ; 
} private static Grib1Gds factoryNCEP ( int gridNumber ) { 
switch ( gridNumber ) { 
return new NcepLatLon ( gridNumber , 37 , 36 , 0.0F , 0.0F , 90.0F , 180.0F , 5.0F , 2.5F , ( byte ) 0x88 , ( byte ) 64 ) ; 
return new NcepLatLon ( gridNumber , 37 , 36 , 0.0F , - 180.0F , 90.0F , 0.0F , 5.0F , 2.5F , ( byte ) 0x88 , ( byte ) 64 ) ; 
return new NcepLatLon ( gridNumber , 37 , 36 , - 90.0F , 0.0F , 180.0F , 0.0F , 5.0F , 2.5F , ( byte ) 0x88 , ( byte ) 64 ) ; 
return new NcepLatLon ( gridNumber , 37 , 36 , - 90.0F , - 180.0F , 0.0F , 0.0F , 5.0F , 2.5F , ( byte ) 0x88 , ( byte ) 64 ) ; 
return new NcepLatLon ( gridNumber , 72 , 18 , 0.0F , 0.0F , 90.0F , 355.0F , 5.0F , 5.0F , ( byte ) 0x88 , ( byte ) 64 ) ; 
return new NcepLatLon ( gridNumber , 72 , 18 , - 90.0F , 0.0F , 0.0F , 355.0F , 5.0F , 5.0F , ( byte ) 0x88 , ( byte ) 64 ) ; 
case 61 : 
return new NcepLatLon ( gridNumber , 91 , 45 , 0.0F , 0.0F , 90.0F , 180.0F , 2.0F , 2.0F , ( byte ) 0x88 , ( byte ) 64 ) ; 
case 62 : 
return new NcepLatLon ( gridNumber , 91 , 45 , - 90.0F , 0.0F , 0.0F , 180.0F , 2.0F , 2.0F , ( byte ) 0x88 , ( byte ) 64 ) ; 
case 63 : 
case 64 : 
return new NcepLatLon ( gridNumber , 91 , 45 , - 90.0F , - 180.0F , 0.0F , 0.0F , 2.0F , 2.0F , ( byte ) 0x88 , ( byte ) 64 ) ; 
case 87 : 
return new NcepPS ( gridNumber , 81 , 62 , 22.8756F , 239.5089F , 255.0F , 68153.0F , 68153.0F , ( byte ) 0x08 , ( byte ) 64 ) ; 
} static public long copy2null ( InputStream in , int buffersize ) throws IOException { 
if ( buffersize <= 0 ) buffersize = default_file_buffersize ; 
byte [ ] buffer = new byte [ buffersize ] ; 
int n = in . read ( buffer ) ; 
if ( n == - 1 ) break ; 
totalBytesRead += n ; 
} static public long copy2null ( FileChannel in , int buffersize ) throws IOException { 
ByteBuffer buffer = ByteBuffer . allocate ( buffersize ) ; 
} static public long copyB ( InputStream in , OutputStream out , int bufferSize ) throws IOException { 
int done = 0 , next = 1 ; 
byte [ ] buffer = new byte [ bufferSize ] ; 
out . write ( buffer , 0 , n ) ; 
if ( showCopy ) { 
done += n ; 
if ( done > 1000 * 1000 * next ) { 
next ++ ; 
} static public String readContents ( InputStream is , String charset ) throws IOException { 
ByteArrayOutputStream bout = new ByteArrayOutputStream ( 10 * default_file_buffersize ) ; 
return bout . toString ( charset ) ; 
} static public byte [ ] readContentsToByteArray ( InputStream is ) throws IOException { 
return bout . toByteArray ( ) ; 
} static public void writeContents ( String contents , OutputStream os ) throws IOException { 
ByteArrayInputStream bin = new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) ; 
IO . copy ( bin , os ) ; 
} static public void copyFile ( String fileInName , String fileOutName ) throws IOException { 
try ( FileInputStream fin = new FileInputStream ( fileInName ) ; 
FileOutputStream fout = new FileOutputStream ( fileOutName ) ) { 
InputStream in = new BufferedInputStream ( fin ) ; 
OutputStream out = new BufferedOutputStream ( fout ) ; 
IO . copy ( in , out ) ; 
} static public void copyFile ( File fileIn , File fileOut ) throws IOException { 
try ( FileInputStream fin = new FileInputStream ( fileIn ) ; 
FileOutputStream fout = new FileOutputStream ( fileOut ) ) { 
} static public void copy2File ( byte [ ] src , String fileOut ) throws IOException { 
try ( FileOutputStream fout = new FileOutputStream ( fileOut ) ) { 
InputStream in = new BufferedInputStream ( new ByteArrayInputStream ( src ) ) ; 
} static public void copyFile ( String fileInName , OutputStream out ) throws IOException { 
copyFileB ( new File ( fileInName ) , out , default_file_buffersize ) ; 
} static public void copyFileB ( File fileIn , OutputStream out , int bufferSize ) throws IOException { 
try ( FileInputStream fin = new FileInputStream ( fileIn ) ) { 
IO . copyB ( in , out , bufferSize ) ; 
} static public long copyRafB ( ucar . unidata . io . RandomAccessFile raf , long offset , long length , OutputStream out , byte [ ] buffer ) throws IOException { 
int bufferSize = buffer . length ; 
long want = length ; 
while ( want > 0 ) { 
int len = ( int ) Math . min ( want , bufferSize ) ; 
int bytesRead = raf . read ( buffer , 0 , len ) ; 
if ( bytesRead <= 0 ) break ; 
want -= bytesRead ; 
return length - want ; 
} static public void copyDirTree ( String fromDirName , String toDirName ) throws IOException { 
File fromDir = new File ( fromDirName ) ; 
File toDir = new File ( toDirName ) ; 
if ( ! fromDir . exists ( ) ) 
if ( ! toDir . exists ( ) ) { 
if ( ! toDir . mkdirs ( ) ) { 
File [ ] files = fromDir . listFiles ( ) ; 
for ( File f : files ) { 
copyDirTree ( f . getAbsolutePath ( ) , toDir . getAbsolutePath ( ) + "/" + f . getName ( ) ) ; 
copyFile ( f . getAbsolutePath ( ) , toDir . getAbsolutePath ( ) + "/" + f . getName ( ) ) ; 
} static public byte [ ] readFileToByteArray ( String filename ) throws IOException { 
try ( FileInputStream fin = new FileInputStream ( filename ) ) { 
return readContentsToByteArray ( in ) ; 
} static public String readFile ( String filename ) throws IOException { 
InputStreamReader reader = new InputStreamReader ( fin , CDM . utf8Charset ) ; 
StringWriter swriter = new StringWriter ( 50000 ) ; 
UnsynchronizedBufferedWriter writer = new UnsynchronizedBufferedWriter ( swriter ) ; 
writer . write ( reader ) ; 
return swriter . toString ( ) ; 
} static public void writeToFile ( String contents , File file ) throws IOException { 
OutputStreamWriter fw = new OutputStreamWriter ( fout , CDM . utf8Charset ) ; 
UnsynchronizedBufferedWriter writer = new UnsynchronizedBufferedWriter ( fw ) ; 
writer . write ( contents ) ; 
} static public void writeToFile ( byte [ ] contents , File file ) throws IOException { 
try ( FileOutputStream fw = new FileOutputStream ( file ) ) { 
fw . write ( contents ) ; 
fw . flush ( ) ; 
} static public void writeToFile ( String contents , String fileOutName ) throws IOException { 
writeToFile ( contents , new File ( fileOutName ) ) ; 
} static public long writeToFile ( InputStream in , String fileOutName ) throws IOException { 
try ( FileOutputStream fout = new FileOutputStream ( fileOutName ) ) { 
return IO . copy ( in , out ) ; 
if ( null != in ) in . close ( ) ; 
} static public long copyUrlB ( String urlString , OutputStream out , int bufferSize ) throws IOException { 
long count ; 
URL url ; 
url = new URL ( urlString ) ; 
java . net . URLConnection connection = url . openConnection ( ) ; 
java . net . HttpURLConnection httpConnection = null ; 
if ( connection instanceof java . net . HttpURLConnection ) { 
httpConnection = ( java . net . HttpURLConnection ) connection ; 
httpConnection . addRequestProperty ( "Accept-Encoding" , "gzip" ) ; 
if ( showHeaders ) { 
showRequestHeaders ( urlString , connection ) ; 
if ( httpConnection != null ) { 
int responseCode = httpConnection . getResponseCode ( ) ; 
if ( responseCode / 100 != 2 ) 
+ "\n" + httpConnection . getResponseMessage ( ) + "\n" ) ; 
if ( showHeaders && ( httpConnection != null ) ) { 
int code = httpConnection . getResponseCode ( ) ; 
String response = httpConnection . getResponseMessage ( ) ; 
for ( int j = 1 ; ; j ++ ) { 
String header = connection . getHeaderField ( j ) ; 
String key = connection . getHeaderFieldKey ( j ) ; 
try ( InputStream is = connection . getInputStream ( ) ) { 
BufferedInputStream bis ; 
if ( "gzip" . equalsIgnoreCase ( connection . getContentEncoding ( ) ) ) { 
bis = new BufferedInputStream ( new GZIPInputStream ( is ) , 8000 ) ; 
bis = new BufferedInputStream ( is , 8000 ) ; 
if ( out == null ) 
count = IO . copy2null ( bis , bufferSize ) ; 
count = IO . copyB ( bis , out , bufferSize ) ; 
} catch ( java . net . ConnectException e ) { 
if ( showStackTrace ) e . printStackTrace ( ) ; 
} public void parseExceptionHandler ( ParseException pe , HttpServletResponse response ) 
if ( Debug . isSet ( "showException" ) ) { 
log . error ( pe . toString ( ) ) ; 
printThrowable ( pe ) ; 
BufferedOutputStream eOut = new BufferedOutputStream ( response . getOutputStream ( ) ) ; 
response . setHeader ( "Content-Description" , "dods-error" ) ; 
response . setHeader ( "Content-Encoding" , "" ) ; 
String msg = pe . getMessage ( ) . replace ( '\"' , '\'' ) ; 
DAP2Exception de2 = new DAP2Exception ( opendap . dap . DAP2Exception . CANNOT_READ_FILE , msg ) ; 
de2 . print ( eOut ) ; 
} public void dap2ExceptionHandler ( DAP2Exception de , HttpServletResponse response ) 
log . error ( de . toString ( ) ) ; 
printDODSException ( de ) ; 
switch ( de . getErrorCode ( ) ) { 
case DAP2Exception . NO_SUCH_FILE : 
case DAP2Exception . CANNOT_READ_FILE : 
response . setStatus ( HttpStatus . SC_NOT_FOUND ) ; 
case DAP2Exception . NO_AUTHORIZATION : 
response . setStatus ( HttpStatus . SC_UNAUTHORIZED ) ; 
case DAP2Exception . NO_SUCH_VARIABLE : 
case DAP2Exception . MALFORMED_EXPR : 
case DAP2Exception . UNKNOWN_ERROR : 
response . setStatus ( HttpStatus . SC_BAD_REQUEST ) ; 
de . print ( eOut ) ; 
} public void IOExceptionHandler ( IOException e , ReqState rs ) 
HttpServletResponse response = rs . getResponse ( ) ; 
String msg = e . getMessage ( ) ; 
if ( msg != null ) 
msg = msg . replace ( '\"' , '\'' ) ; 
log . error ( rs . toString ( ) ) ; 
if ( track ) { 
RequestDebug reqD = ( RequestDebug ) rs . getUserObject ( ) ; 
printThrowable ( e ) ; 
} public void sendDODSError ( ReqState rs , 
String clientMsg , 
String serverMsg ) 
rs . getResponse ( ) . setContentType ( "text/plain" ) ; 
rs . getResponse ( ) . setHeader ( "XDODS-Server" , getServerVersion ( ) ) ; 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-error" ) ; 
ServletOutputStream Out = rs . getResponse ( ) . getOutputStream ( ) ; 
DAP2Exception de = new DAP2Exception ( opendap . dap . DAP2Exception . UNKNOWN_ERROR , clientMsg ) ; 
de . print ( Out ) ; 
rs . getResponse ( ) . setStatus ( HttpServletResponse . SC_OK ) ; 
log . error ( serverMsg ) ; 
} public void doGetDDX ( ReqState rs ) 
GuardedDataset ds = null ; 
ds = getDataset ( rs ) ; 
if ( null == ds ) return ; 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-ddx" ) ; 
OutputStream Out = new BufferedOutputStream ( rs . getResponse ( ) . getOutputStream ( ) ) ; 
ServerDDS myDDS = ds . getDDS ( ) ; 
if ( rs . getConstraintExpression ( ) . equals ( "" ) ) { 
myDDS . printXML ( Out ) ; 
Out . flush ( ) ; 
CEEvaluator ce = new CEEvaluator ( myDDS ) ; 
ce . parseConstraint ( rs ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( Out , Util . UTF8 ) ) ; 
myDDS . printConstrainedXML ( pw ) ; 
} catch ( ParseException pe ) { 
parseExceptionHandler ( pe , rs . getResponse ( ) ) ; 
dap2ExceptionHandler ( de , rs . getResponse ( ) ) ; 
} catch ( IOException pe ) { 
IOExceptionHandler ( pe , rs ) ; 
anyExceptionHandler ( t , rs ) ; 
if ( ds != null ) ds . release ( ) ; 
} public void doGetBLOB ( ReqState rs ) 
rs . getResponse ( ) . setContentType ( "application/octet-stream" ) ; 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-blob" ) ; 
ServletOutputStream sOut = rs . getResponse ( ) . getOutputStream ( ) ; 
OutputStream bOut ; 
DeflaterOutputStream dOut = null ; 
if ( rs . getAcceptsCompressed ( ) && allowDeflate ) { 
rs . getResponse ( ) . setHeader ( "Content-Encoding" , "deflate" ) ; 
dOut = new DeflaterOutputStream ( sOut ) ; 
bOut = new BufferedOutputStream ( dOut ) ; 
bOut = new BufferedOutputStream ( sOut ) ; 
cacheArrayShapes ( myDDS ) ; 
CEEvaluator ce = new CEEvaluator ( myDDS , 
new ClauseFactory ( functionLibrary ) ) ; 
ce . parseConstraint ( rs . getConstraintExpression ( ) , rs . getRequestURL ( ) . toString ( ) ) ; 
DataOutputStream sink = new DataOutputStream ( bOut ) ; 
int seqLength = 5 ; 
String sls = rs . getInitParameter ( "SequenceLength" ) ; 
if ( sls != null ) { 
seqLength = ( Integer . valueOf ( sls ) ) . intValue ( ) ; 
testEngine te = new testEngine ( seqLength ) ; 
ce . send ( myDDS . getEncodedName ( ) , sink , te ) ; 
sink . flush ( ) ; 
if ( rs . getAcceptsCompressed ( ) ) { 
if ( bOut != null ) 
bOut . flush ( ) ; 
if ( dOut != null ) 
( ( DeflaterOutputStream ) dOut ) . finish ( ) ; 
IOExceptionHandler ( ioe , rs ) ; 
} public void doGetDIR ( ReqState rs ) 
rs . getResponse ( ) . setContentType ( "text/html" ) ; 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-directory" ) ; 
GetDirHandler di = new GetDirHandler ( ) ; 
di . sendDIR ( rs ) ; 
} public void badURL ( HttpServletRequest request , HttpServletResponse response ) 
response . setContentType ( "text/html" ) ; 
response . setHeader ( "XDODS-Server" , getServerVersion ( ) ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( response . getOutputStream ( ) , Util . UTF8 ) ) ; 
printBadURLPage ( pw ) ; 
printHelpPage ( pw ) ; 
response . setStatus ( HttpServletResponse . SC_OK ) ; 
} public void doGetINFO ( ReqState rs ) 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-description" ) ; 
GetInfoHandler di = new GetInfoHandler ( ) ; 
di . sendINFO ( pw , ds , rs ) ; 
} public void doGetHTML ( ReqState rs ) 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-form" ) ; 
DAS das = ds . getDAS ( ) ; 
GetHTMLInterfaceHandler di = new GetHTMLInterfaceHandler ( ) ; 
di . sendDataRequestForm ( rs , rs . getDataSet ( ) , myDDS , das ) ; 
} public void doGetCatalog ( ReqState rs ) 
rs . getResponse ( ) . setContentType ( "text/xml" ) ; 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-catalog" ) ; 
printCatalog ( rs , pw ) ; 
} protected void printCatalog ( ReqState rs , PrintWriter os ) 
} public void doGetSystemProps ( ReqState rs ) 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-status" ) ; 
Properties sysp = System . getProperties ( ) ; 
Enumeration e = sysp . propertyNames ( ) ; 
pw . println ( "<ul>" ) ; 
String value = System . getProperty ( name ) ; 
pw . println ( "</ul>" ) ; 
Runtime rt = Runtime . getRuntime ( ) ; 
pw . println ( "</body>" ) ; 
} public void doGetStatus ( ReqState rs ) 
pw . println ( "<body><ul>" ) ; 
printStatus ( pw ) ; 
pw . println ( "</ul></body>" ) ; 
} protected void printStatus ( PrintWriter os ) 
int n = prArr . size ( ) ; 
int pending = 0 ; 
StringBuilder preqs = new StringBuilder ( ) ; 
ReqState rs = ( ReqState ) prArr . get ( i ) ; 
if ( ! reqD . done ) { 
preqs . append ( "<pre>-----------------------\n" ) ; 
preqs . append ( "Request[" ) ; 
preqs . append ( reqD . reqno ) ; 
preqs . append ( "](" ) ; 
preqs . append ( reqD . threadDesc ) ; 
preqs . append ( rs . toString ( ) ) ; 
preqs . append ( "</pre>" ) ; 
pending ++ ; 
os . println ( preqs . toString ( ) ) ; 
} public void probeRequest ( PrintStream ps , ReqState rs ) 
Enumeration e ; 
HttpServletRequest request = rs . getRequest ( ) ; 
ps . println ( "" ) ; 
e = request . getHeaderNames ( ) ; 
ps . println ( "............................." ) ; 
e = request . getAttributeNames ( ) ; 
e = request . getParameterNames ( ) ; 
e = servletContext . getAttributeNames ( ) ; 
ServletConfig scnfg = getServletConfig ( ) ; 
e = scnfg . getInitParameterNames ( ) ; 
String p = ( String ) e . nextElement ( ) ; 
} public void doGet ( HttpServletRequest request , 
HttpServletResponse response ) 
long tid = Thread . currentThread ( ) . getId ( ) ; 
log . debug ( "thread=" + tid ) ; 
boolean isDebug = false ; 
ReqState rs = null ; 
RequestDebug reqD = null ; 
rs = getRequestState ( request , response ) ; 
assert ( rs != null ) ; 
if ( rs != null ) { 
String ds = rs . getDataSet ( ) ; 
String suff = rs . getRequestSuffix ( ) ; 
isDebug = ( ( ds != null ) && ds . equals ( "debug" ) && ( suff != null ) && suff . equals ( "" ) ) ; 
synchronized ( syncLock ) { 
if ( ! isDebug ) { 
long reqno = HitCounter ++ ; 
reqD = new RequestDebug ( reqno , Thread . currentThread ( ) . toString ( ) ) ; 
rs . setUserObject ( reqD ) ; 
if ( prArr == null ) prArr = new ArrayList ( 10000 ) ; 
prArr . add ( ( int ) reqno , rs ) ; 
if ( Debug . isSet ( "showRequest" ) ) { 
log . debug ( "-------------------------------------------" ) ; 
log . debug ( rs . toString ( ) ) ; 
String dataSet = rs . getDataSet ( ) ; 
String requestSuffix = rs . getRequestSuffix ( ) ; 
if ( dataSet == null || dataSet . equals ( "/" ) || dataSet . equals ( "" ) ) { 
doGetDIR ( rs ) ; 
} else if ( dataSet . equalsIgnoreCase ( "/version" ) || dataSet . equalsIgnoreCase ( "/version/" ) ) { 
doGetVER ( rs ) ; 
} else if ( dataSet . equalsIgnoreCase ( "/help" ) || dataSet . equalsIgnoreCase ( "/help/" ) ) { 
doGetHELP ( rs ) ; 
} else if ( dataSet . equalsIgnoreCase ( "/" + requestSuffix ) ) { 
} else if ( requestSuffix . equalsIgnoreCase ( "dds" ) ) { 
doGetDDS ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "das" ) ) { 
doGetDAS ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "ddx" ) ) { 
doGetDDX ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "blob" ) ) { 
doGetBLOB ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "dods" ) ) { 
doGetDAP2Data ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "asc" ) || 
requestSuffix . equalsIgnoreCase ( "ascii" ) ) { 
doGetASC ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "info" ) ) { 
doGetINFO ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "html" ) || requestSuffix . equalsIgnoreCase ( "htm" ) ) { 
doGetHTML ( rs ) ; 
} else if ( requestSuffix . equalsIgnoreCase ( "ver" ) || requestSuffix . equalsIgnoreCase ( "version" ) ) { 
} else if ( requestSuffix . equalsIgnoreCase ( "help" ) ) { 
} else if ( requestSuffix . equals ( "" ) ) { 
badURL ( request , response ) ; 
if ( reqD != null ) reqD . done = true ; 
anyExceptionHandler ( e , rs ) ; 
} void showMemUsed ( String from ) 
long totalMemory = Runtime . getRuntime ( ) . totalMemory ( ) ; 
long freeMemory = Runtime . getRuntime ( ) . freeMemory ( ) ; 
long usedMemory = ( totalMemory - freeMemory ) ; 
} private void printBadURLPage ( PrintWriter pw ) 
} public CalendarDate getReferenceDate ( ) { 
return CalendarDate . of ( null , year , month , day , hour , minute , second ) ; 
} static public void initEntity ( String entityName , String resourceName , String urlName ) { 
String entity = null ; 
try ( InputStream is = ucar . nc2 . util . IO . getFileResource ( resourceName ) ) { 
ByteArrayOutputStream sbuff = new ByteArrayOutputStream ( 3000 ) ; 
IO . copy ( is , sbuff ) ; 
entity = new String ( sbuff . toByteArray ( ) , CDM . utf8Charset ) ; 
} else if ( urlName != null ) { 
entity = IO . readURLcontentsWithException ( urlName ) ; 
entityHash . put ( entityName , entity ) ; 
entityHash . put ( urlName , entity ) ; 
} public org . xml . sax . InputSource resolveEntity ( String publicId , String systemId ) throws SAXException , IOException { 
String entity = entityHash . get ( systemId ) ; 
return new MyInputSource ( entity ) ; 
if ( systemId . contains ( "InvCatalog.0.6.dtd" ) ) { 
entity = entityHash . get ( "http://www.unidata.ucar.edu/schemas/thredds/InvCatalog.0.6.dtd" ) ; 
} private Array readVlenData ( Variable v , Section section , DataStorage dataStorage ) throws IOException , InvalidRangeException { 
raf . seek ( dataStorage . filePos ) ; 
int nelems = readVInt ( raf ) ; 
Array [ ] result = new Array [ nelems ] ; 
for ( int elem = 0 ; elem < nelems ; elem ++ ) { 
int dsize = readVInt ( raf ) ; 
byte [ ] data = new byte [ dsize ] ; 
Array dataArray = Array . factory ( v . getDataType ( ) , ( int [ ] ) null , ByteBuffer . wrap ( data ) ) ; 
result [ elem ] = dataArray ; 
return Array . makeVlenArray ( new int [ ] { nelems } , result ) ; 
} public void openDebug ( RandomAccessFile raf , NetcdfFile ncfile , List < NcsMess > ncm ) throws IOException { 
if ( ! readAndTest ( raf , NcStream . MAGIC_START ) ) { 
if ( ncm != null ) { 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , 4 , "MAGIC_START" ) ) ; 
pos = raf . getFilePointer ( ) ; 
if ( ! readAndTest ( raf , NcStream . MAGIC_HEADER ) ) { 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , 4 , "MAGIC_HEADER" ) ) ; 
int msize = readVInt ( raf ) ; 
byte [ ] m = new byte [ msize ] ; 
raf . readFully ( m ) ; 
NcStreamProto . Header proto = NcStreamProto . Header . parseFrom ( m ) ; 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , msize , proto ) ) ; 
version = proto . getVersion ( ) ; 
while ( ! raf . isAtEndOfFile ( ) ) { 
raf . readFully ( b ) ; 
if ( test ( b , NcStream . MAGIC_END ) ) { 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , 4 , "MAGIC_END" ) ) ; 
if ( test ( b , NcStream . MAGIC_ERR ) ) { 
int esize = readVInt ( raf ) ; 
byte [ ] dp = new byte [ esize ] ; 
raf . readFully ( dp ) ; 
NcStreamProto . Error error = NcStreamProto . Error . parseFrom ( dp ) ; 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , esize , error . getMessage ( ) ) ) ; 
if ( ! test ( b , NcStream . MAGIC_DATA ) ) { 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , 4 , "MAGIC_DATA" ) ) ; 
int psize = readVInt ( raf ) ; 
Variable v = ncfile . findVariable ( dproto . getVarName ( ) ) ; 
if ( ncm != null ) ncm . add ( new NcsMess ( pos , psize , dproto ) ) ; 
List < DataStorage > storage ; 
storage = ( List < DataStorage > ) v . getSPobject ( ) ; 
if ( storage == null ) { 
storage = new ArrayList < > ( ) ; 
v . setSPobject ( storage ) ; 
if ( dproto . getDataType ( ) == NcStreamProto . DataType . STRUCTURE ) { 
msize = readVInt ( raf ) ; 
m = new byte [ msize ] ; 
NcStreamProto . StructureData sdata = NcStreamProto . StructureData . parseFrom ( m ) ; 
DataStorage dataStorage = new DataStorage ( msize , pos , dproto ) ; 
dataStorage . sdata = sdata ; 
if ( ncm != null ) ncm . add ( new NcsMess ( dataStorage . filePos , msize , sdata ) ) ; 
storage . add ( dataStorage ) ; 
} else if ( dproto . getVdata ( ) ) { 
DataStorage dataStorage = new DataStorage ( 0 , raf . getFilePointer ( ) , dproto ) ; 
int totalSize = 0 ; 
totalSize += dsize ; 
raf . skipBytes ( dsize ) ; 
dataStorage . nelems = nelems ; 
dataStorage . size = totalSize ; 
if ( ncm != null ) ncm . add ( new NcsMess ( dataStorage . filePos , totalSize , dataStorage ) ) ; 
DataStorage dataStorage = new DataStorage ( dsize , raf . getFilePointer ( ) , dproto ) ; 
if ( ncm != null ) ncm . add ( new NcsMess ( dataStorage . filePos , dsize , dataStorage ) ) ; 
} static public NcmlCollectionReader readNcML ( String ncmlString , Formatter errlog ) throws IOException { 
StringReader reader = new StringReader ( ncmlString ) ; 
doc = builder . build ( new StringReader ( ncmlString ) ) ; 
return readXML ( doc , errlog , null ) ; 
} static public NcmlCollectionReader open ( String ncmlLocation , Formatter errlog ) throws IOException { 
if ( ! ncmlLocation . startsWith ( "http:" ) && ! ncmlLocation . startsWith ( "file:" ) ) 
ncmlLocation = "file:" + ncmlLocation ; 
URL url = new URL ( ncmlLocation ) ; 
doc = builder . build ( url ) ; 
return readXML ( doc , errlog , ncmlLocation ) ; 
} static public String allow ( String x , String allowChars , char replaceChar ) { 
if ( ! ( Character . isLetterOrDigit ( c ) || ( 0 <= allowChars . indexOf ( c ) ) ) ) { 
if ( ok ) 
if ( Character . isLetterOrDigit ( c ) || ( 0 <= allowChars . indexOf ( c ) ) ) { 
sb . setCharAt ( pos , replaceChar ) ; 
} public static String breakTextAtWords ( String text , String insert , int lineSize ) { 
int lineCount = 0 ; 
if ( tok . length ( ) + lineCount >= lineSize ) { 
buff . append ( insert ) ; 
lineCount = 0 ; 
buff . append ( tok ) ; 
lineCount += tok . length ( ) + 1 ; 
} public static String cleanup ( byte [ ] h ) { 
byte [ ] bb = new byte [ h . length ] ; 
for ( byte b : h ) { 
if ( b >= 32 && b < 127 ) 
bb [ count ++ ] = b ; 
return new String ( bb , 0 , count , CDM . utf8Charset ) ; 
} static public String filter ( String x , String okChars ) { 
if ( ! ( Character . isLetterOrDigit ( c ) || ( 0 <= okChars . indexOf ( c ) ) ) ) { 
if ( ok ) { 
if ( Character . isLetterOrDigit ( c ) || ( 0 <= okChars . indexOf ( c ) ) ) { 
} static public String filter7bits ( String s ) { 
char [ ] bo = new char [ s . length ( ) ] ; 
if ( ( c < 128 ) && ( c > 31 ) || ( ( c == '\n' ) || ( c == '\t' ) ) ) { 
bo [ count ++ ] = c ; 
return new String ( bo , 0 , count ) ; 
} static public String makeValidCdmObjectName ( String name ) { 
name = name . trim ( ) ; 
for ( int i = 0 ; i < name . length ( ) ; i ++ ) { 
int c = name . charAt ( i ) ; 
if ( c < 0x20 ) ok = false ; 
if ( c == '/' ) ok = false ; 
if ( ! ok ) break ; 
if ( ok ) return name ; 
StringBuilder sbuff = new StringBuilder ( name . length ( ) ) ; 
for ( int i = 0 , len = name . length ( ) ; i < len ; i ++ ) { 
sbuff . append ( '_' ) ; 
else if ( c >= 0x20 ) 
sbuff . append ( ( char ) c ) ; 
} static public int match ( String s1 , String s2 ) { 
while ( ( i < s1 . length ( ) ) && ( i < s2 . length ( ) ) ) { 
if ( s1 . charAt ( i ) != s2 . charAt ( i ) ) { 
} public static String padLeft ( String s , int desiredLength , 
String padString ) { 
while ( s . length ( ) < desiredLength ) { 
s = padString + s ; 
} public static String padRight ( String s , int desiredLength , 
StringBuilder ret = new StringBuilder ( s ) ; 
while ( ret . length ( ) < desiredLength ) { 
ret . append ( padString ) ; 
return ret . toString ( ) ; 
} static public String remove ( String s , String sub ) { 
int len = sub . length ( ) ; 
while ( 0 <= ( pos = s . indexOf ( sub ) ) ) { 
s = s . substring ( 0 , pos ) + s . substring ( pos + len ) ; 
} static public String remove ( String s , int c ) { 
if ( 0 > s . indexOf ( c ) ) { 
StringBuilder buff = new StringBuilder ( s ) ; 
while ( i < buff . length ( ) ) { 
if ( buff . charAt ( i ) == c ) { 
buff . deleteCharAt ( i ) ; 
} static public String removeFromEnd ( String s , int c ) { 
if ( 0 > s . indexOf ( c ) ) 
while ( ( s . charAt ( len - 1 ) == c ) && ( len > 0 ) ) 
if ( len == s . length ( ) ) 
return s . substring ( 0 , len ) ; 
} public static String removeWhitespace ( String inputString ) { 
char [ ] chars = inputString . toCharArray ( ) ; 
for ( char c : chars ) { 
if ( Character . isWhitespace ( c ) ) { 
} static public String collapseWhitespace ( String s ) { 
StringBuilder b = new StringBuilder ( len ) ; 
if ( ! Character . isWhitespace ( c ) ) { 
b . append ( c ) ; 
while ( ( i + 1 < len ) && Character . isWhitespace ( s . charAt ( i + 1 ) ) ) { 
} static public String replace ( String s , char out , String in ) { 
if ( s . indexOf ( out ) < 0 ) { 
StringBuilder sb = new StringBuilder ( s ) ; 
replace ( sb , out , in ) ; 
} static public String replace ( String x , char [ ] replaceChar , String [ ] replaceWith ) { 
for ( char aReplaceChar : replaceChar ) { 
int pos = x . indexOf ( aReplaceChar ) ; 
ok = ( pos < 0 ) ; 
for ( int i = 0 ; i < replaceChar . length ; i ++ ) { 
int pos = x . indexOf ( replaceChar [ i ] ) ; 
replace ( sb , replaceChar [ i ] , replaceWith [ i ] ) ; 
} public static String replace ( String string , String pattern , String value ) { 
if ( pattern . length ( ) == 0 ) 
return string ; 
if ( ! string . contains ( pattern ) ) return string ; 
StringBuilder returnValue = new StringBuilder ( ) ; 
int patternLength = pattern . length ( ) ; 
int idx = string . indexOf ( pattern ) ; 
if ( idx < 0 ) 
returnValue . append ( string . substring ( 0 , idx ) ) ; 
returnValue . append ( value ) ; 
string = string . substring ( idx + patternLength ) ; 
returnValue . append ( string ) ; 
return returnValue . toString ( ) ; 
} static public String unreplace ( String x , String [ ] orgReplace , char [ ] orgChar ) { 
for ( String anOrgReplace : orgReplace ) { 
int pos = x . indexOf ( anOrgReplace ) ; 
StringBuilder result = new StringBuilder ( x ) ; 
for ( int i = 0 ; i < orgReplace . length ; i ++ ) { 
int pos = result . indexOf ( orgReplace [ i ] ) ; 
unreplace ( result , orgReplace [ i ] , orgChar [ i ] ) ; 
} static public String substitute ( String original , String match , String subst ) { 
String s = original ; 
while ( 0 <= ( pos = s . indexOf ( match ) ) ) { 
s = sb . replace ( pos , pos + match . length ( ) , subst ) . toString ( ) ; 
} static public String escape ( String x , String okChars ) { 
StringBuilder newname = new StringBuilder ( ) ; 
for ( char c : x . toCharArray ( ) ) { 
if ( c == '%' ) { 
newname . append ( "%%" ) ; 
} else if ( ! Character . isLetterOrDigit ( c ) && okChars . indexOf ( c ) < 0 ) { 
newname . append ( '%' ) ; 
newname . append ( Integer . toHexString ( ( 0xFF & ( int ) c ) ) ) ; 
newname . append ( c ) ; 
return newname . toString ( ) ; 
} static public String unescape ( String x ) { 
if ( x . indexOf ( '%' ) < 0 ) { 
char [ ] b = new char [ 2 ] ; 
if ( c != '%' ) { 
if ( pos >= sb . length ( ) - 2 ) { 
b [ 0 ] = sb . charAt ( pos + 1 ) ; 
b [ 1 ] = sb . charAt ( pos + 2 ) ; 
int value ; 
value = Integer . parseInt ( new String ( b ) , 16 ) ; 
c = ( char ) value ; 
sb . setCharAt ( pos , c ) ; 
sb . delete ( pos + 1 , pos + 3 ) ; 
} static public String substitute ( String original , String [ ] match , String [ ] subst ) { 
for ( String aMatch : match ) { 
if ( original . contains ( aMatch ) ) { 
return original ; 
StringBuilder sb = new StringBuilder ( original ) ; 
for ( int i = 0 ; i < match . length ; i ++ ) { 
substitute ( sb , match [ i ] , subst [ i ] ) ; 
} static public void remove ( StringBuilder sb , String out ) { 
while ( i < sb . length ( ) ) { 
int c = sb . charAt ( i ) ; 
for ( int j = 0 ; j < out . length ( ) ; j ++ ) { 
if ( out . charAt ( j ) == c ) { 
sb . delete ( i , i + 1 ) ; 
if ( ok ) i ++ ; 
} static public void unreplace ( StringBuilder sb , String out , char in ) { 
while ( 0 <= ( pos = sb . indexOf ( out ) ) ) { 
sb . setCharAt ( pos , in ) ; 
sb . delete ( pos + 1 , pos + out . length ( ) ) ; 
} static public void replace ( StringBuilder sb , String out , String in ) { 
for ( int i = 0 ; i < sb . length ( ) ; i ++ ) { 
if ( out . charAt ( j ) == c ) 
sb . setCharAt ( i , in . charAt ( j ) ) ; 
} static public void substitute ( StringBuilder sbuff , String match , String subst ) { 
int pos , fromIndex = 0 ; 
int substLen = subst . length ( ) ; 
int matchLen = match . length ( ) ; 
while ( 0 <= ( pos = sbuff . indexOf ( match , fromIndex ) ) ) { 
sbuff . replace ( pos , pos + matchLen , subst ) ; 
fromIndex = pos + substLen ; 
} static public String trim ( String s , int bad ) { 
int st = 0 ; 
while ( ( st < len ) && ( s . charAt ( st ) == bad ) ) { 
st ++ ; 
while ( ( st < len ) && ( s . charAt ( len - 1 ) == bad ) ) { 
return ( ( st > 0 ) || ( len < s . length ( ) ) ) ? s . substring ( st , len ) : s ; 
} protected void makeCollection ( ) { 
datasetCollection = new MFileCollectionManager ( config , errlog , logger ) ; 
topDirectory = datasetCollection . getRoot ( ) ; 
String errs = errlog . toString ( ) ; 
} @ Subscribe 
public void processEvent ( CollectionUpdateEvent event ) { 
if ( ! config . collectionName . equals ( event . getCollectionName ( ) ) ) return ; 
update ( event . getType ( ) ) ; 
} public void showStatus ( Formatter f ) { 
checkState ( ) ; 
_showStatus ( f , false , null ) ; 
t . printStackTrace ( new PrintWriter ( sw ) ) ; 
f . format ( sw . toString ( ) ) ; 
} protected State checkState ( ) throws IOException { 
State localState ; 
firstInit ( ) ; 
updateCollection ( state , config . updateConfig . updateType ) ; 
localState = state . copy ( ) ; 
return localState ; 
state = checkState ( ) ; 
state . lastInvChange = System . currentTimeMillis ( ) ; 
updateCollection ( localState , force ) ; 
localState . lastInvChange = System . currentTimeMillis ( ) ; 
state = localState ; 
} protected String makeFullName ( DatasetNode ds ) { 
if ( ds . getParent ( ) == null ) return ds . getName ( ) ; 
String parentName = makeFullName ( ds . getParent ( ) ) ; 
if ( parentName == null || parentName . length ( ) == 0 ) return ds . getName ( ) ; 
return parentName + "/" + ds . getName ( ) ; 
} protected CatalogBuilder makeCatalogTop ( URI catURI , State localState ) throws IOException , URISyntaxException { 
Catalog parentCatalog = parent . getParentCatalog ( ) ; 
CatalogBuilder topCatalog = new CatalogBuilder ( ) ; 
topCatalog . setName ( makeFullName ( parent ) ) ; 
topCatalog . setVersion ( parentCatalog . getVersion ( ) ) ; 
topCatalog . setBaseURI ( catURI ) ; 
DatasetBuilder top = makeDatasetTop ( catURI , localState ) ; 
topCatalog . addDataset ( top ) ; 
topCatalog . addService ( virtualService ) ; 
return topCatalog ; 
} protected CatalogBuilder makeCatalogFiles ( URI catURI , State localState , List < String > filenames , boolean addLatest ) throws IOException { 
CatalogBuilder result = new CatalogBuilder ( ) ; 
result . setName ( makeFullName ( parent ) ) ; 
result . setVersion ( parentCatalog . getVersion ( ) ) ; 
result . setBaseURI ( catURI ) ; 
result . addService ( orgService ) ; 
top . setName ( FILES ) ; 
tmi . set ( Dataset . TimeCoverage , null ) ; 
if ( localState . coverage != null ) { 
tmi . set ( Dataset . GeospatialCoverage , localState . coverage ) ; 
tmi . set ( Dataset . ServiceName , orgService . getName ( ) ) ; 
result . addDataset ( top ) ; 
if ( addLatest ) { 
DatasetBuilder latest = new DatasetBuilder ( top ) ; 
latest . setName ( getLatestFileName ( ) ) ; 
latest . put ( Dataset . UrlPath , LATEST_DATASET_CATALOG ) ; 
latest . put ( Dataset . Id , LATEST_DATASET_CATALOG ) ; 
latest . put ( Dataset . ServiceName , latestService . getName ( ) ) ; 
latest . addServiceToCatalog ( latestService ) ; 
top . addDataset ( latest ) ; 
List < String > sortedFilenames = new ArrayList < > ( filenames ) ; 
Collections . sort ( sortedFilenames , String . CASE_INSENSITIVE_ORDER ) ; 
Collections . reverse ( sortedFilenames ) ; 
for ( String f : sortedFilenames ) { 
if ( ! f . startsWith ( topDirectory ) ) 
String fname = f . substring ( topDirectory . length ( ) + 1 ) ; 
ds . setName ( fname ) ; 
String lpath = this . configPath + "/" + FILES + "/" + fname ; 
ds . put ( Dataset . VariableMapLinkURI , new ThreddsMetadata . UriResolved ( makeMetadataLink ( lpath , VARIABLES ) , catURI ) ) ; 
File file = new File ( f ) ; 
ds . put ( Dataset . DataSize , file . length ( ) ) ; 
} public ucar . nc2 . dt . grid . GridDataset getGridDataset ( String matchPath ) throws IOException { 
} public NetcdfDataset getNetcdfDataset ( String matchPath ) throws IOException { 
int pos = matchPath . indexOf ( '/' ) ; 
String type = ( pos > - 1 ) ? matchPath . substring ( 0 , pos ) : matchPath ; 
String name = ( pos > - 1 ) ? matchPath . substring ( pos + 1 ) : "" ; 
if ( type . equalsIgnoreCase ( FILES ) ) { 
if ( topDirectory == null ) return null ; 
String filename = new StringBuilder ( topDirectory ) 
. append ( topDirectory . endsWith ( "/" ) ? "" : "/" ) 
. append ( name ) . toString ( ) ; 
DatasetUrl durl = new DatasetUrl ( null , filename ) ; 
return NetcdfDataset . acquireDataset ( null , durl , null , - 1 , null , null ) ; 
GridDataset gds = getGridDataset ( matchPath ) ; 
return ( gds == null ) ? null : ( NetcdfDataset ) gds . getNetcdfFile ( ) ; 
} public File getFile ( String remaining ) { 
if ( null == topDirectory ) return null ; 
int pos = remaining . indexOf ( FILES ) ; 
StringBuilder fname = new StringBuilder ( topDirectory ) ; 
if ( ! topDirectory . endsWith ( "/" ) ) 
fname . append ( "/" ) ; 
fname . append ( ( pos > - 1 ) ? remaining . substring ( pos + FILES . length ( ) + 1 ) : remaining ) ; 
return new File ( fname . toString ( ) ) ; 
} private void doCopyCompress ( Formatter f , ucar . nc2 . grib . grib2 . Grib2Record gr , RandomAccessFile raf , OutputStream out , Counters counters ) throws IOException { 
float [ ] data = gr . readData ( raf ) ; 
Grib2SectionDataRepresentation drss = gr . getDataRepresentationSection ( ) ; 
drss . getDrs ( raf ) ; 
GribData . Info info = gr . getBinaryDataInfo ( raf ) ; 
int nbits = info . numberOfBits ; 
counters . count ( "Nbits" , nbits ) ; 
int width = ( 2 << ( nbits - 1 ) ) - 1 ; 
float scale_factor = ( dataMax - dataMin ) / ( width - 2 ) ; 
float add_offset = dataMin - scale_factor ; 
doCheckTables ( mfile , f , accum ) ; 
} private void doLocalUseSection ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
doLocalUseSection ( mfile , f , useIndex ) ; 
} private void doUniqueTemplates ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
Map < Integer , FileList > gdsSet = new HashMap < > ( ) ; 
Map < Integer , FileList > pdsSet = new HashMap < > ( ) ; 
Map < Integer , FileList > drsSet = new HashMap < > ( ) ; 
doUniqueTemplates ( mfile , gdsSet , pdsSet , drsSet , f ) ; 
List < FileList > sorted = new ArrayList < > ( gdsSet . values ( ) ) ; 
for ( FileList gdsl : sorted ) { 
List < FileList > sortedPds = new ArrayList < > ( pdsSet . values ( ) ) ; 
Collections . sort ( sortedPds ) ; 
for ( FileList pdsl : sortedPds ) { 
f . format ( "%n===================================================%n" ) ; 
for ( FileCount fc : pdsl . fileList ) { 
List < FileList > sortedDrs = new ArrayList < > ( drsSet . values ( ) ) ; 
Collections . sort ( sortedDrs ) ; 
for ( FileList pdsl : sortedDrs ) { 
} private void doPdsSummary ( Formatter f , MCollection dcm , boolean eachFile ) throws IOException { 
countersAll . add ( "template" ) ; 
countersAll . add ( "timeUnit" ) ; 
countersAll . add ( "timeOffset" ) ; 
countersAll . add ( "timeIntervalSize" ) ; 
countersAll . add ( "levelType" ) ; 
countersAll . add ( "genProcessType" ) ; 
countersAll . add ( "genProcessId" ) ; 
countersAll . add ( "levelScale" ) ; 
countersAll . add ( "nExtraCoords" ) ; 
f . format ( "---%s%n" , mfile . getPath ( ) ) ; 
doPdsSummary ( f , mfile , countersAll ) ; 
countersAll . reset ( ) ; 
if ( ! eachFile ) 
} private void doIdProblems ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
countersAll . add ( "discipline" ) ; 
countersAll . add ( "masterTable" ) ; 
countersAll . add ( "localTable" ) ; 
countersAll . add ( "centerId" ) ; 
countersAll . add ( "subcenterId" ) ; 
countersAll . add ( "genProcess" ) ; 
countersAll . add ( "backProcess" ) ; 
countersAll . add ( "significanceOfReference" ) ; 
doIdProblems ( f , mfile , useIndex , countersAll ) ; 
} private void doDrsSummary ( Formatter f , MCollection dcm , boolean useIndex , boolean eachFile , boolean extra ) throws IOException { 
countersAll . add ( "DRS_template" ) ; 
countersAll . add ( "Number_of_Bits" ) ; 
doDrsSummaryIndex ( f , mfile , extra , countersAll ) ; 
doDrsSummaryScan ( f , mfile , extra , countersAll ) ; 
} private void doGdsSummary ( Formatter f , MCollection dcm , boolean extra ) throws IOException { 
counters . add ( "template" ) ; 
counters . add ( "scanMode" ) ; 
counters . add ( "scanModeDifference" ) ; 
doGdsSummary ( f , mfile , counters , extra ) ; 
} private void doTimeCoord ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
counters . add ( "timeUnit" ) ; 
counters . add ( "statType" ) ; 
counters . add ( "NumberTimeIntervals" ) ; 
counters . add ( "TimeIntervalsDiffer" ) ; 
counters . add ( "TimeIntervalsLength" ) ; 
count += doTimeCoord ( f , mfile , counters ) ; 
} private void doRename ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { 
List < VarName > varNames = new ArrayList < > ( 3000 ) ; 
Map < String , List < String > > gridsAll = new HashMap < > ( 1000 ) ; 
int countExactMatch = 0 ; 
int countExactMatchIg = 0 ; 
int countOldVars = 0 ; 
f . format ( "%n%s%n" , mfile . getPath ( ) ) ; 
Map < Integer , GridMatch > gridsNew = getGridsNew ( mfile , f ) ; 
Map < Integer , GridMatch > gridsOld = getGridsOld ( mfile , f ) ; 
Set < String > namesNew = new HashSet < > ( gridsNew . size ( ) ) ; 
for ( GridMatch gm : gridsNew . values ( ) ) 
namesNew . add ( gm . grid . getFullName ( ) ) ; 
for ( GridMatch gm : gridsOld . values ( ) ) { 
if ( namesNew . contains ( gm . grid . getFullName ( ) ) ) countExactMatch ++ ; 
countOldVars ++ ; 
for ( GridMatch gm : gridsNew . values ( ) ) { 
GridMatch match = gridsOld . get ( gm . hashCode ( ) ) ; 
gm . match = match ; 
match . match = gm ; 
if ( gm . match == null ) { 
GridMatch match = altMatch ( gm , gridsOld . values ( ) ) ; 
List < GridMatch > listNew = new ArrayList < > ( gridsNew . values ( ) ) ; 
Collections . sort ( listNew ) ; 
for ( GridMatch gm : listNew ) { 
if ( gm . match != null ) { 
boolean exact = gm . match . grid . getFullName ( ) . equals ( gm . grid . getFullName ( ) ) ; 
boolean exactIg = ! exact && gm . match . grid . getFullName ( ) . equalsIgnoreCase ( gm . grid . getFullName ( ) ) ; 
if ( exactIg ) countExactMatchIg ++ ; 
List < GridMatch > list = new ArrayList < > ( gridsNew . values ( ) ) ; 
for ( GridMatch gm : list ) { 
if ( gm . match == null ) 
List < GridMatch > listOld = new ArrayList < > ( gridsOld . values ( ) ) ; 
Collections . sort ( listOld ) ; 
for ( GridMatch gm : listOld ) { 
for ( GridMatch gmOld : listOld ) { 
String key = gmOld . grid . getShortName ( ) ; 
List < String > newGrids = gridsAll . get ( key ) ; 
if ( newGrids == null ) { 
newGrids = new ArrayList < > ( ) ; 
gridsAll . put ( key , newGrids ) ; 
if ( gmOld . match != null ) { 
String keyNew = gmOld . match . grid . getShortName ( ) ; 
if ( ! newGrids . contains ( keyNew ) ) newGrids . add ( keyNew ) ; 
if ( gmOld . match == null ) { 
Attribute att = gmOld . match . grid . findAttributeIgnoreCase ( Grib . VARIABLE_ID_ATTNAME ) ; 
String varId = att == null ? "" : att . getStringValue ( ) ; 
varNames . add ( new VarName ( mfile . getName ( ) , gmOld . grid . getShortName ( ) , gmOld . match . grid . getShortName ( ) , varId ) ) ; 
List < String > keys = new ArrayList < > ( gridsAll . keySet ( ) ) ; 
int total = keys . size ( ) ; 
Collections . sort ( newGrids ) ; 
if ( newGrids . size ( ) > 1 ) dups ++ ; 
for ( String newKey : newGrids ) 
if ( ! useIndex ) { 
Element rootElem = new Element ( "gribVarMap" ) ; 
rootElem . setAttribute ( "collection" , dcm . getCollectionName ( ) ) ; 
String currentDs = null ; 
Element dsElem = null ; 
for ( VarName vn : varNames ) { 
if ( ! vn . dataset . equals ( currentDs ) ) { 
dsElem = new Element ( "dataset" ) ; 
rootElem . addContent ( dsElem ) ; 
dsElem . setAttribute ( "name" , vn . dataset ) ; 
currentDs = vn . dataset ; 
Element param = new Element ( "param" ) ; 
dsElem . addContent ( param ) ; 
param . setAttribute ( "oldName" , vn . oldVar ) ; 
param . setAttribute ( "newName" , vn . newVar ) ; 
param . setAttribute ( "varId" , vn . varId ) ; 
FileOutputStream fout = new FileOutputStream ( "C:/tmp/grib2VarMap.xml" ) ; 
fmt . output ( doc , fout ) ; 
fout . close ( ) ; 
private GridMatch altMatch ( GridMatch want , Collection < GridMatch > test ) { 
for ( GridMatch gm : test ) { 
if ( gm . match != null ) continue ; 
if ( gm . altMatch ( want ) ) { 
return gm ; 
if ( gm . altMatchNoProb ( want ) ) { 
public java . util . List < InvDataset > getDatasets ( ) { 
read ( ) ; 
return useProxy ? proxy . getDatasets ( ) : super . getDatasets ( ) ; 
} public void release ( ) { 
datasets = new java . util . ArrayList < > ( ) ; 
proxy = null ; 
useProxy = false ; 
init = false ; 
} public synchronized void readAsynch ( InvCatalogFactory factory , CatalogSetCallback caller ) { 
if ( init ) { 
caller . setCatalog ( ( InvCatalogImpl ) getParentCatalog ( ) ) ; 
String hrefResolved ; 
java . net . URI uri = getParentCatalog ( ) . resolveUri ( href ) ; 
hrefResolved = uri . toString ( ) ; 
catch ( java . net . URISyntaxException e ) { 
datasets . add ( proxy ) ; 
factory . readXMLasynch ( hrefResolved , new Callback ( caller ) ) ; 
public thredds . catalog . InvDatasetImpl findDatasetByName ( java . lang . String p0 ) { 
return ! useProxy ? super . findDatasetByName ( p0 ) : proxy . findDatasetByName ( p0 ) ; 
public java . util . List < ThreddsMetadata . Vocab > getProjects ( ) { 
return ! useProxy ? super . getProjects ( ) : proxy . getProjects ( ) ; 
} private int calcFracDigits ( String d ) { 
int pos = d . indexOf ( "." ) ; 
if ( pos < 0 ) return 0 ; 
return d . length ( ) - pos - 1 ; 
} public void sendINFO ( PrintWriter pw , GuardedDataset gds , ReqState rs ) throws DAP2Exception , ParseException { 
String responseDoc = null ; 
ServerDDS myDDS = null ; 
DAS myDAS = null ; 
myDDS = gds . getDDS ( ) ; 
myDAS = gds . getDAS ( ) ; 
infoDir = rs . getINFOCache ( rs . getRootPath ( ) ) ; 
responseDoc = loadOverrideDoc ( infoDir , rs . getDataSet ( ) ) ; 
if ( responseDoc != null ) { 
pw . print ( responseDoc ) ; 
String user_html = get_user_supplied_docs ( rs . getServerClassName ( ) , rs . getDataSet ( ) ) ; 
String global_attrs = buildGlobalAttributes ( myDAS , myDDS ) ; 
String variable_sum = buildVariableSummaries ( myDAS , myDDS ) ; 
pw . println ( "</style>" ) ; 
pw . println ( "<body>" ) ; 
if ( global_attrs . length ( ) > 0 ) { 
pw . println ( global_attrs ) ; 
pw . println ( variable_sum ) ; 
pw . println ( user_html ) ; 
pw . println ( "</body></html>" ) ; 
} public String loadOverrideDoc ( String infoDir , String dataSet ) throws DAP2Exception { 
StringBuilder userDoc = new StringBuilder ( ) ; 
String overrideFile = dataSet + ".ovr" ; 
File fin = new File ( infoDir + overrideFile ) ; 
BufferedReader svIn = new BufferedReader ( new InputStreamReader ( new FileInputStream ( fin ) , Util . UTF8 ) ) ; 
String line = svIn . readLine ( ) ; 
userDoc . append ( line ) ; 
userDoc . append ( "\n" ) ; 
throw ( new DAP2Exception ( opendap . dap . DAP2Exception . UNKNOWN_ERROR , ioe . getMessage ( ) ) ) ; 
return ( userDoc . toString ( ) ) ; 
} private String buildGlobalAttributes ( DAS das , ServerDDS dds ) { 
StringBuilder ga = new StringBuilder ( ) ; 
Enumeration edas = das . getNames ( ) ; 
while ( edas . hasMoreElements ( ) ) { 
String name = ( String ) edas . nextElement ( ) ; 
if ( ! dasTools . nameInKillFile ( name ) && 
( dasTools . nameIsGlobal ( name ) || ! dasTools . nameInDDS ( name , dds ) ) ) { 
AttributeTable attr = das . getAttributeTable ( name ) ; 
Enumeration e = attr . getNames ( ) ; 
Attribute a = attr . getAttribute ( aName ) ; 
ga . append ( aName + "</b>:</td>\n" ) ; 
Enumeration es = a . getValues ( ) ; 
while ( es . hasMoreElements ( ) ) { 
String val = ( String ) es . nextElement ( ) ; 
ga . append ( val ) ; 
ga . append ( "<br>" ) ; 
ga . append ( "</td></tr>\n" ) ; 
ga . append ( "</table>\n<p>\n" ) ; 
ga . setLength ( 0 ) ; 
return ( ga . toString ( ) ) ; 
} private String buildVariableSummaries ( DAS das , ServerDDS dds ) { 
StringBuilder vs = new StringBuilder ( ) ; 
vs . append ( "<tr>" ) ; 
vs . append ( summarizeVariable ( bt , das ) ) ; 
vs . append ( "</tr>" ) ; 
vs . append ( "</table>\n<p>\n" ) ; 
return ( vs . toString ( ) ) ; 
} static public StructureDataDeep copy ( StructureData sdata , StructureMembers members ) { 
ArrayStructureBB abb = copyToArrayBB ( sdata , members , ByteOrder . BIG_ENDIAN ) ; 
return new StructureDataDeep ( abb ) ; 
} static public ArrayStructureBB copyToArrayBB ( ArrayStructure as , ByteOrder bo , boolean canonical ) throws IOException { 
if ( ! canonical && as . getClass ( ) . equals ( ArrayStructureBB . class ) ) { 
ArrayStructureBB abb = ( ArrayStructureBB ) as ; 
ByteBuffer bb = abb . getByteBuffer ( ) ; 
if ( bo == null || bo . equals ( bb . order ( ) ) ) 
return abb ; 
StructureMembers smo = as . getStructureMembers ( ) ; 
StructureMembers sm = new StructureMembers ( smo ) ; 
ArrayStructureBB abb = new ArrayStructureBB ( sm , as . getShape ( ) ) ; 
if ( bo != null ) { 
try ( StructureDataIterator iter = as . getStructureDataIterator ( ) ) { 
copyToArrayBB ( iter . next ( ) , abb ) ; 
} static public ArrayStructureBB copyToArrayBB ( Structure s , ArrayStructure as , ByteOrder bo ) throws IOException { 
StructureMembers sm = s . makeStructureMembers ( ) ; 
} static public ArrayStructureBB copyToArrayBB ( StructureData sdata ) { 
return copyToArrayBB ( sdata , new StructureMembers ( sdata . getStructureMembers ( ) ) , ByteOrder . BIG_ENDIAN ) ; 
} static public ArrayStructureBB copyToArrayBB ( StructureData sdata , StructureMembers sm , ByteOrder bo ) { 
int size = sm . getStructureSize ( ) ; 
ByteBuffer bb = ByteBuffer . allocate ( size ) ; 
ArrayStructureBB abb = new ArrayStructureBB ( sm , new int [ ] { 1 } , bb , 0 ) ; 
copyToArrayBB ( sdata , abb ) ; 
} static public int copyToArrayBB ( StructureData sdata , ArrayStructureBB abb ) { 
int start = bb . limit ( ) ; 
for ( StructureMembers . Member wantMember : abb . getMembers ( ) ) { 
StructureMembers . Member m = sdata . findMember ( wantMember . getName ( ) ) ; 
assert m != null ; 
assert m . getDataType ( ) == wantMember . getDataType ( ) ; 
DataType dtype = m . getDataType ( ) ; 
if ( m . isScalar ( ) ) { 
switch ( dtype ) { 
case STRING : 
bb . putInt ( abb . addObjectToHeap ( sdata . getScalarString ( m ) ) ) ; 
case FLOAT : 
bb . putFloat ( sdata . getScalarFloat ( m ) ) ; 
case DOUBLE : 
bb . putDouble ( sdata . getScalarDouble ( m ) ) ; 
bb . putInt ( sdata . getScalarInt ( m ) ) ; 
bb . putShort ( sdata . getScalarShort ( m ) ) ; 
bb . put ( sdata . getScalarByte ( m ) ) ; 
case CHAR : 
bb . put ( ( byte ) sdata . getScalarChar ( m ) ) ; 
bb . putLong ( sdata . getScalarLong ( m ) ) ; 
StructureData sd = sdata . getScalarStructure ( m ) ; 
ArrayStructureBB out_abb = new ArrayStructureBB ( sd . getStructureMembers ( ) , 
new int [ ] { 1 } , bb , 0 ) ; 
copyToArrayBB ( sd , out_abb ) ; 
String [ ] ss = sdata . getJavaArrayString ( m ) ; 
bb . putInt ( abb . addObjectToHeap ( ss ) ) ; 
float [ ] fdata = sdata . getJavaArrayFloat ( m ) ; 
bb . putFloat ( fdata [ i ] ) ; 
double [ ] ddata = sdata . getJavaArrayDouble ( m ) ; 
bb . putDouble ( ddata [ i ] ) ; 
int [ ] idata = sdata . getJavaArrayInt ( m ) ; 
bb . putInt ( idata [ i ] ) ; 
short [ ] shdata = sdata . getJavaArrayShort ( m ) ; 
bb . putShort ( shdata [ i ] ) ; 
byte [ ] bdata = sdata . getJavaArrayByte ( m ) ; 
bb . put ( bdata [ i ] ) ; 
char [ ] cdata = sdata . getJavaArrayChar ( m ) ; 
bb . put ( IospHelper . convertCharToByte ( cdata ) ) ; 
long [ ] ldata = sdata . getJavaArrayLong ( m ) ; 
bb . putLong ( ldata [ i ] ) ; 
return bb . limit ( ) - start ; 
public double getForecastTimeIntervalSizeInHours ( Grib2Pds pds ) { 
boolean needOverride = false ; 
needOverride = ( ti . timeRangeUnit == 255 ) ; 
if ( ! needOverride ) 
return super . getForecastTimeIntervalSizeInHours ( pds ) ; 
return 12.0 ; 
} public CoordinateAxis1D section ( Range r ) throws InvalidRangeException { 
Section section = new Section ( ) . appendRange ( r ) ; 
CoordinateAxis1D result = ( CoordinateAxis1D ) section ( section ) ; 
int len = r . length ( ) ; 
if ( isNumeric ( ) ) { 
double [ ] new_mids = new double [ len ] ; 
for ( int idx = 0 ; idx < len ; idx ++ ) { 
int old_idx = r . element ( idx ) ; 
new_mids [ idx ] = coords [ old_idx ] ; 
result . coords = new_mids ; 
double [ ] new_bound1 = new double [ len ] ; 
double [ ] new_bound2 = new double [ len ] ; 
double [ ] new_edge = new double [ len + 1 ] ; 
new_bound1 [ idx ] = bound1 [ old_idx ] ; 
new_bound2 [ idx ] = bound2 [ old_idx ] ; 
new_edge [ idx ] = bound1 [ old_idx ] ; 
new_edge [ idx + 1 ] = bound2 [ old_idx ] ; 
result . bound1 = new_bound1 ; 
result . bound2 = new_bound2 ; 
result . edge = new_edge ; 
new_edge [ idx ] = edge [ old_idx ] ; 
new_edge [ idx + 1 ] = edge [ old_idx + 1 ] ; 
if ( names != null ) { 
String [ ] new_names = new String [ len ] ; 
new_names [ idx ] = names [ old_idx ] ; 
result . names = new_names ; 
result . wasCalcRegular = false ; 
result . calcIsRegular ( ) ; 
} public List < NamedObject > getNames ( ) { 
int n = getDimension ( 0 ) . getLength ( ) ; 
List < NamedObject > names = new ArrayList < > ( n ) ; 
public String getCoordName ( int index ) { 
if ( ! wasRead ) doRead ( ) ; 
if ( isNumeric ( ) ) 
return Format . d ( getCoordValue ( index ) , 5 , 8 ) ; 
return names [ index ] ; 
public double getCoordValue ( int index ) { 
return coords [ index ] ; 
public double getMinValue ( ) { 
return Math . min ( coords [ 0 ] , coords [ coords . length - 1 ] ) ; 
public double getMaxValue ( ) { 
return Math . max ( coords [ 0 ] , coords [ coords . length - 1 ] ) ; 
public double getMinEdgeValue ( ) { 
if ( edge == null ) return getMinValue ( ) ; 
return Math . min ( edge [ 0 ] , edge [ edge . length - 1 ] ) ; 
public double getMaxEdgeValue ( ) { 
if ( edge == null ) return getMaxValue ( ) ; 
return Math . max ( edge [ 0 ] , edge [ edge . length - 1 ] ) ; 
public double getCoordEdge ( int index ) { 
if ( ! wasBoundsDone ) makeBounds ( ) ; 
return edge [ index ] ; 
public double [ ] getCoordValues ( ) { 
return coords . clone ( ) ; 
public double [ ] getCoordEdges ( ) { 
return edge . clone ( ) ; 
public boolean isContiguous ( ) { 
return isContiguous ; 
public boolean isInterval ( ) { 
return isInterval ; 
public double [ ] getBound1 ( ) { 
if ( bound1 == null ) makeBoundsFromEdges ( ) ; 
assert bound1 != null ; 
return bound1 . clone ( ) ; 
public double [ ] getBound2 ( ) { 
if ( bound2 == null ) makeBoundsFromEdges ( ) ; 
assert bound2 != null ; 
return bound2 . clone ( ) ; 
public double [ ] getCoordBounds ( int i ) { 
double [ ] e = new double [ 2 ] ; 
if ( isContiguous ( ) ) { 
e [ 0 ] = getCoordEdge ( i ) ; 
e [ 1 ] = getCoordEdge ( i + 1 ) ; 
e [ 0 ] = bound1 [ i ] ; 
e [ 1 ] = bound2 [ i ] ; 
public double getCoordBoundsMidpoint ( int i ) { 
double [ ] bounds = getCoordBounds ( i ) ; 
return ( bounds [ 0 ] + bounds [ 1 ] ) / 2 ; 
public int findCoordElement ( double coordVal ) { 
if ( isRegular ( ) ) 
return findCoordElementRegular ( coordVal , false ) ; 
if ( isContiguous ( ) ) 
return findCoordElementIrregular ( coordVal , false ) ; 
return findCoordElementNonContiguous ( coordVal , false ) ; 
public int findCoordElementBounded ( double coordVal ) { 
if ( this . getSize ( ) == 1 ) return 0 ; 
return findCoordElementRegular ( coordVal , true ) ; 
return findCoordElementIrregular ( coordVal , true ) ; 
return findCoordElementNonContiguous ( coordVal , true ) ; 
public int findCoordElement ( double coordVal , int lastIndex ) { 
return findCoordElement ( coordVal ) ; 
private int findCoordElementRegular ( double coordValue , boolean bounded ) { 
int n = ( int ) this . getSize ( ) ; 
if ( this . getSize ( ) == 1 ) { 
double distance = coordValue - this . start ; 
double exactNumSteps = distance / this . increment ; 
int index = ( int ) Math . round ( exactNumSteps ) ; 
else if ( index >= n ) 
return bounded ? n - 1 : - 1 ; 
private boolean betweenLon ( double lon , double lonBeg , double lonEnd ) { 
while ( lon < lonBeg ) lon += 360 ; 
private int findCoordElementIrregular ( double target , boolean bounded ) { 
int high = n ; 
if ( isAscending ) { 
if ( target < this . edge [ low ] ) 
else if ( target > this . edge [ high ] ) 
int mid = low ; 
double midVal = this . edge [ mid ] ; 
if ( midVal == target ) return mid ; 
else if ( midVal < target ) low = mid ; 
return low ; 
if ( target > this . edge [ low ] ) 
else if ( target < this . edge [ high ] ) 
else if ( midVal < target ) high = mid ; 
return high - 1 ; 
private int findCoordElementNonContiguous ( double target , boolean bounded ) { 
double [ ] bounds1 = getBound1 ( ) ; 
double [ ] bounds2 = getBound2 ( ) ; 
int n = bounds1 . length ; 
if ( target < bounds1 [ 0 ] ) 
else if ( target > bounds2 [ n - 1 ] ) 
int [ ] idx = findSingleHit ( bounds1 , bounds2 , target ) ; 
if ( idx [ 0 ] == 0 && ! bounded ) return - 1 ; 
if ( idx [ 0 ] == 1 ) return idx [ 1 ] ; 
return findClosest ( coords , target ) ; 
if ( target > bounds1 [ 0 ] ) 
else if ( target < bounds2 [ n - 1 ] ) 
int [ ] idx = findSingleHit ( bounds2 , bounds1 , target ) ; 
return findClosest ( getCoordValues ( ) , target ) ; 
private int [ ] findSingleHit ( double [ ] low , double [ ] high , double target ) { 
int n = low . length ; 
if ( ( low [ i ] <= target ) && ( target <= high [ i ] ) ) { 
return new int [ ] { hits , idxFound } ; 
private int findClosest ( double [ ] values , double target ) { 
int n = values . length ; 
double diff = Math . abs ( values [ i ] - target ) ; 
public double getStart ( ) { 
calcIsRegular ( ) ; 
return start ; 
public double getIncrement ( ) { 
public boolean isRegular ( ) { 
return isRegular ; 
private void calcIsRegular ( ) { 
if ( wasCalcRegular ) return ; 
else if ( getSize ( ) < 2 ) 
isRegular = true ; 
start = getCoordValue ( 0 ) ; 
int n = ( int ) getSize ( ) ; 
increment = ( getCoordValue ( n - 1 ) - getCoordValue ( 0 ) ) / ( n - 1 ) ; 
for ( int i = 1 ; i < getSize ( ) ; i ++ ) 
if ( ! ucar . nc2 . util . Misc . nearlyEquals ( getCoordValue ( i ) - getCoordValue ( i - 1 ) , increment , 5.0e-3 ) ) { 
wasCalcRegular = true ; 
private void doRead ( ) { 
readValues ( ) ; 
wasRead = true ; 
if ( getSize ( ) < 2 ) 
isAscending = true ; 
isAscending = getCoordValue ( 0 ) < getCoordValue ( 1 ) ; 
} else if ( getDataType ( ) == DataType . STRING ) { 
readStringValues ( ) ; 
readCharValues ( ) ; 
public void correctLongitudeWrap ( ) { 
if ( axisType != AxisType . Lon ) { 
boolean monotonic = true ; 
for ( int i = 0 ; i < coords . length - 1 ; i ++ ) 
monotonic &= isAscending ? coords [ i ] < coords [ i + 1 ] : coords [ i ] > coords [ i + 1 ] ; 
if ( ! monotonic ) { 
boolean cross = false ; 
for ( int i = 0 ; i < coords . length ; i ++ ) { 
if ( cross ) coords [ i ] += 360 ; 
if ( ! cross && ( i < coords . length - 1 ) && ( coords [ i ] > coords [ i + 1 ] ) ) 
cross = true ; 
if ( cross ) coords [ i ] -= 360 ; 
if ( ! cross && ( i < coords . length - 1 ) && ( coords [ i ] < coords [ i + 1 ] ) ) 
Array cachedData = Array . factory ( DataType . DOUBLE , getShape ( ) , coords ) ; 
if ( getDataType ( ) != DataType . DOUBLE ) 
cachedData = MAMath . convert ( cachedData , getDataType ( ) ) ; 
setCachedData ( cachedData ) ; 
if ( ! isInterval ) { 
makeEdges ( ) ; 
private void readStringValues ( ) { 
data = read ( ) ; 
throw new IllegalStateException ( ioe ) ; 
names = new String [ ( int ) data . getSize ( ) ] ; 
names [ count ++ ] = ( String ) ii . getObjectNext ( ) ; 
private void readCharValues ( ) { 
ArrayChar data ; 
data = ( ArrayChar ) read ( ) ; 
names = new String [ iter . getNumElems ( ) ] ; 
names [ count ++ ] = iter . next ( ) ; 
private void readValues ( ) { 
coords = ( double [ ] ) data . get1DJavaArray ( DataType . DOUBLE ) ; 
private void makeBounds ( ) { 
if ( ! makeBoundsFromAux ( ) ) { 
wasBoundsDone = true ; 
private boolean makeBoundsFromAux ( ) { 
if ( ( null == boundsAtt ) || ! boundsAtt . isString ( ) ) return false ; 
if ( null == boundsVar ) return false ; 
if ( 2 != boundsVar . getRank ( ) ) return false ; 
if ( getDimension ( 0 ) != boundsVar . getDimension ( 0 ) ) return false ; 
if ( 2 != boundsVar . getDimension ( 1 ) . getLength ( ) ) return false ; 
boundsVar . removeEnhancement ( NetcdfDataset . Enhance . ConvertMissing ) ; 
int n = shape [ 0 ] ; 
double [ ] value1 = new double [ n ] ; 
double [ ] value2 = new double [ n ] ; 
Index ima = data . getIndex ( ) ; 
ima . set0 ( i ) ; 
value1 [ i ] = data . getDouble ( ima . set1 ( 0 ) ) ; 
value2 [ i ] = data . getDouble ( ima . set1 ( 1 ) ) ; 
boolean contig = true ; 
for ( int i = 0 ; i < n - 1 ; i ++ ) { 
if ( ! ucar . nc2 . util . Misc . nearlyEquals ( value1 [ i + 1 ] , value2 [ i ] ) ) 
contig = false ; 
if ( contig ) { 
edge = new double [ n + 1 ] ; 
edge [ 0 ] = value1 [ 0 ] ; 
for ( int i = 1 ; i < n + 1 ; i ++ ) 
edge [ i ] = value2 [ i - 1 ] ; 
for ( int i = 1 ; i < n ; i ++ ) 
edge [ i ] = ( value1 [ i ] + value2 [ i - 1 ] ) / 2 ; 
edge [ n ] = value2 [ n - 1 ] ; 
isContiguous = false ; 
bound1 = value1 ; 
bound2 = value2 ; 
isInterval = true ; 
private void makeEdges ( ) { 
int size = ( int ) getSize ( ) ; 
edge = new double [ size + 1 ] ; 
if ( size < 1 ) return ; 
for ( int i = 1 ; i < size ; i ++ ) 
edge [ i ] = ( coords [ i - 1 ] + coords [ i ] ) / 2 ; 
edge [ 0 ] = coords [ 0 ] - ( edge [ 1 ] - coords [ 0 ] ) ; 
edge [ size ] = coords [ size - 1 ] + ( coords [ size - 1 ] - edge [ size - 1 ] ) ; 
isContiguous = true ; 
private void makeBoundsFromEdges ( ) { 
if ( size == 0 ) return ; 
bound1 = new double [ size ] ; 
bound2 = new double [ size ] ; 
bound1 [ i ] = edge [ i ] ; 
bound2 [ i ] = edge [ i + 1 ] ; 
if ( bound1 [ 0 ] > bound2 [ 0 ] ) { 
double [ ] temp = bound1 ; 
bound1 = bound2 ; 
bound2 = temp ; 
} @ Override public int showDialog ( Component parent , String approveButtonText ) throws HeadlessException { 
int returnValue = super . showDialog ( parent , approveButtonText ) ; 
this . dialog = null ; 
return returnValue ; 
} static public TableConfigurer getTableConfigurer ( FeatureType wantFeatureType , NetcdfDataset ds ) throws IOException { 
String convUsed = null ; 
Configurator anal = null ; 
anal = matchConfigurator ( convName ) ; 
if ( anal != null ) { 
convUsed = convName ; 
if ( anal == null ) { 
if ( ( convName . indexOf ( ',' ) > 0 ) || ( convName . indexOf ( ';' ) > 0 ) ) { 
StringTokenizer stoke = new StringTokenizer ( convName , ",;" ) ; 
} else if ( ( convName . indexOf ( '/' ) > 0 ) ) { 
StringTokenizer stoke = new StringTokenizer ( convName , "/" ) ; 
for ( Configurator conv : conventionList ) { 
anal = conv ; 
convUsed = name ; 
if ( anal != null ) break ; 
Class c = conv . confClass ; 
Method isMineMethod ; 
isMineMethod = c . getMethod ( "isMine" , new Class [ ] { FeatureType . class , NetcdfDataset . class } ) ; 
Boolean result = ( Boolean ) isMineMethod . invoke ( conv . confInstance , wantFeatureType , ds ) ; 
convUsed = conv . convName ; 
TableConfigurer tc = null ; 
tc = ( TableConfigurer ) anal . confClass . newInstance ( ) ; 
tc . setConvName ( convName ) ; 
tc . setConvUsed ( convUsed ) ; 
} static public TableAnalyzer factory ( TableConfigurer tc , FeatureType wantFeatureType , NetcdfDataset ds ) throws IOException { 
TableAnalyzer analyzer = new TableAnalyzer ( ds , tc ) ; 
if ( tc . getConvName ( ) == null ) 
if ( tc . getConvUsed ( ) != null ) { 
analyzer . setConventionUsed ( tc . getConvUsed ( ) ) ; 
if ( ! tc . getConvUsed ( ) . equals ( tc . getConvName ( ) ) ) 
analyzer . analyze ( wantFeatureType ) ; 
return analyzer ; 
} public FeatureType getFirstFeatureType ( ) { 
for ( NestedTable nt : leaves ) { 
if ( nt . hasCoords ( ) ) 
return nt . getFeatureType ( ) ; 
} private void analyze ( FeatureType wantFeatureType ) throws IOException { 
boolean structAdded = ( Boolean ) ds . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
makeTablesDefault ( structAdded ) ; 
makeNestedTables ( ) ; 
configResult = tc . getConfig ( wantFeatureType , ds , errlog ) ; 
if ( configResult != null ) 
addTableRecurse ( configResult ) ; 
for ( TableConfig config : tableSet ) { 
if ( config . children == null ) { 
NestedTable flatTable = new NestedTable ( ds , config , errlog ) ; 
leaves . add ( flatTable ) ; 
if ( PointDatasetStandardFactory . showTables ) 
getDetailInfo ( new Formatter ( System . out ) ) ; 
} private void makeTablesDefault ( boolean structAdded ) throws IOException { 
List < Variable > vars = new ArrayList < > ( ds . getVariables ( ) ) ; 
Iterator < Variable > iter = vars . iterator ( ) ; 
Variable v = iter . next ( ) ; 
TableConfig st = new TableConfig ( Table . Type . Structure , v . getFullName ( ) ) ; 
CoordSysEvaluator . findCoords ( st , ds , null ) ; 
st . structName = v . getFullName ( ) ; 
st . nestedTableName = v . getShortName ( ) ; 
addTable ( st ) ; 
checkIfTrajectory ( st ) ; 
findNestedStructures ( ( Structure ) v , st ) ; 
} else if ( structAdded && v . isUnlimited ( ) ) { 
if ( tableSet . size ( ) > 0 ) return ; 
Set < Dimension > dimSet = new HashSet < > ( 10 ) ; 
if ( ( axis . getAxisType ( ) == AxisType . Lat ) || ( axis . getAxisType ( ) == AxisType . Lon ) || ( axis . getAxisType ( ) == AxisType . Time ) ) 
for ( Dimension dim : axis . getDimensions ( ) ) 
dimSet . add ( dim ) ; 
if ( dimSet . size ( ) == 1 ) { 
final Dimension obsDim = ( Dimension ) dimSet . toArray ( ) [ 0 ] ; 
TableConfig st = new TableConfig ( Table . Type . Structure , obsDim . getShortName ( ) ) ; 
st . structureType = obsDim . isUnlimited ( ) ? TableConfig . StructureType . Structure : TableConfig . StructureType . PsuedoStructure ; 
st . structName = obsDim . isUnlimited ( ) ? "record" : obsDim . getShortName ( ) ; 
st . dimName = obsDim . getShortName ( ) ; 
CoordSysEvaluator . findCoords ( st , ds , new CoordSysEvaluator . Predicate ( ) { 
return obsDim . equals ( axis . getDimension ( 0 ) ) ; 
CoordinateAxis time = CoordSysEvaluator . findCoordByType ( ds , AxisType . Time ) ; 
if ( ( time != null ) && ( time . getRank ( ) == 0 ) ) { 
st . addJoin ( new JoinArray ( time , JoinArray . Type . scalar , 0 ) ) ; 
st . time = time . getShortName ( ) ; 
CoordinateAxis time = null ; 
if ( ( axis . getAxisType ( ) == AxisType . Time ) && axis . isIndependentCoordinate ( ) ) { 
time = axis ; 
if ( time != null ) { 
Dimension obsDim = time . getDimension ( 0 ) ; 
st . structureType = TableConfig . StructureType . PsuedoStructure ; 
} public void showNestedTables ( java . util . Formatter sf ) { 
nt . show ( sf ) ; 
} private Document makeDocument ( ) { 
Element rootElem = new Element ( "featureDataset" ) ; 
rootElem . addContent ( new Element ( "analyser" ) . setAttribute ( "class" , getName ( ) ) ) ; 
if ( ft != null ) 
rootElem . setAttribute ( "featureType" , ft . toString ( ) ) ; 
writeTable ( rootElem , nt . getLeaf ( ) ) ; 
} static void doit ( String filename ) throws IOException { 
System . out . println ( filename ) ; 
NetcdfDataset ncd = ucar . nc2 . dataset . NetcdfDataset . openDataset ( filename ) ; 
TableAnalyzer csa = TableAnalyzer . factory ( null , null , ncd ) ; 
csa . getDetailInfo ( new Formatter ( System . out ) ) ; 
System . out . println ( "%n-----------------" ) ; 
mcGridReader = new McIDASGridReader ( ) ; 
return mcGridReader . init ( raf , false ) ; 
if ( mcGridReader == null ) { 
mcGridReader . init ( raf ) ; 
GridIndex index = mcGridReader . getGridIndex ( ) ; 
open ( index , cancelTask ) ; 
+ ( System . currentTimeMillis ( ) - start ) ) ; 
} protected void open ( GridIndex index , CancelTask cancelTask ) 
McIDASLookup lookup = new McIDASLookup ( ( McIDASGridRecord ) index . getGridRecords ( ) . get ( 0 ) ) ; 
GridIndexToNC delegate = new GridIndexToNC ( index . filename ) ; 
delegate . open ( index , lookup , 4 , ncfile , cancelTask ) ; 
} public boolean sync ( ) { 
if ( ! mcGridReader . init ( ) ) { 
open ( index , null ) ; 
} static ArrayShort factory ( Index index , boolean isUnsigned ) { 
return ArrayShort . factory ( index , isUnsigned , null ) ; 
short [ ] ja = ( short [ ] ) javaArray ; 
for ( short aJa : ja ) iter . setShortNext ( aJa ) ; 
} protected void copyTo1DJavaArray ( IndexIterator iter , Object javaArray ) { 
for ( int i = 0 ; i < ja . length ; i ++ ) 
ja [ i ] = iter . getShortNext ( ) ; 
short val = storage [ index ] ; 
return ( double ) ( isUnsigned ( ) ? DataType . unsignedShortToInt ( val ) : val ) ; 
} public void dap2ExceptionHandler ( DAP2Exception de , HttpServletResponse response ) { 
de . print ( System . err ) ; 
de . printStackTrace ( System . err ) ; 
} public void anyExceptionHandler ( Throwable e , ReqState rs ) { 
if ( rs == null ) 
DAP2Exception de2 = new DAP2Exception ( opendap . dap . DAP2Exception . UNDEFINED_ERROR , msg ) ; 
} public void sendDODSError ( HttpServletRequest request , 
response . setContentType ( "text/plain" ) ; 
ServletOutputStream Out = response . getOutputStream ( ) ; 
} public void doGetDAS ( ReqState rs ) 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-das" ) ; 
DAS myDAS = ds . getDAS ( ) ; 
myDAS . print ( Out ) ; 
} public void badURL ( ReqState rs ) 
} public void doGetASC ( ReqState rs ) throws Exception { 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods-ascii" ) ; 
ServerDDS dds = ds . getDDS ( ) ; 
CEEvaluator ce = new CEEvaluator ( dds ) ; 
dds . printConstrained ( pw ) ; 
AsciiWriter writer = new AsciiWriter ( ) ; 
writer . toASCII ( pw , dds , ds ) ; 
} public void doDebug ( ReqState rs ) throws IOException { 
rs . getResponse ( ) . setHeader ( "Content-Description" , "dods_debug" ) ; 
pw . println ( "<title>Debugging</title>" ) ; 
pw . println ( "<body><pre>" ) ; 
StringTokenizer tz = new StringTokenizer ( rs . getConstraintExpression ( ) , "=;" ) ; 
while ( tz . hasMoreTokens ( ) ) { 
String cmd = tz . nextToken ( ) ; 
if ( cmd . equals ( "help" ) ) { 
doDebugCmd ( cmd , tz , pw ) ; 
} else if ( cmd . equals ( "on" ) ) 
Debug . set ( tz . nextToken ( ) , true ) ; 
else if ( cmd . equals ( "off" ) ) 
Debug . set ( tz . nextToken ( ) , false ) ; 
else if ( cmd . equals ( "showFlags" ) ) { 
Iterator iter = Debug . keySet ( ) . iterator ( ) ; 
String key = ( String ) iter . next ( ) ; 
} else if ( cmd . equals ( "showInitParameters" ) ) 
pw . println ( rs . toString ( ) ) ; 
else if ( cmd . equals ( "showRequest" ) ) 
probeRequest ( pw , rs ) ; 
else if ( ! doDebugCmd ( cmd , tz , pw ) ) { 
pw . println ( "--------------------------------------" ) ; 
boolean val = Debug . isSet ( key ) ; 
if ( val ) 
pw . println ( "</pre></body>" ) ; 
} public void probeRequest ( PrintWriter ps , ReqState rs ) { 
e = rs . getRequest ( ) . getHeaderNames ( ) ; 
e = rs . getRequest ( ) . getAttributeNames ( ) ; 
e = rs . getRequest ( ) . getParameterNames ( ) ; 
} private void printHelpPage ( PrintWriter pw ) { 
pw . println ( "<dl>" ) ; 
pw . println ( "</dl>" ) ; 
pw . println ( "http://opendap.gso.url.edu/cgi-bin/nph-nc/data/fnoc1.nc.das." ) ; 
super . printXML ( pw , pad , constrained ) ; 
} public static double [ ] getGaussianLatitudes ( String type , int start , 
int num ) 
double [ ] baseArray = null ; 
start -- ; 
if ( type . equalsIgnoreCase ( GAUST62 ) ) { 
baseArray = gltst62 ; 
} else if ( type . equalsIgnoreCase ( GAUSR15 ) ) { 
baseArray = glts15 ; 
} else if ( type . equalsIgnoreCase ( GAUSR20 ) ) { 
baseArray = glts20 ; 
} else if ( type . equalsIgnoreCase ( GAUSR30 ) ) { 
baseArray = glts30 ; 
} else if ( type . equalsIgnoreCase ( GAUSR40 ) ) { 
baseArray = glats ; 
if ( start + num > baseArray . length ) { 
double [ ] retVals = new double [ num ] ; 
retVals [ i ] = baseArray [ start + i ] ; 
return retVals ; 
} static public long swapLong ( byte [ ] b , int offset ) { 
} static public float swapFloat ( byte [ ] b , int offset ) { 
for ( int shiftBy = 0 , i = offset ; shiftBy < 32 ; shiftBy += 8 , i ++ ) 
return Float . intBitsToFloat ( accum ) ; 
} static public char swapChar ( byte [ ] b , int offset ) { 
return ( char ) ( high << 8 | low ) ; 
} protected void findCoordinateAxes ( NetcdfDataset ds ) { 
if ( vp . coordAxes == null ) { 
String coordsString = ds . findAttValueIgnoreCase ( vp . v , CF . COORDINATES , null ) ; 
if ( coordsString != null ) { 
vp . coordinates = coordsString ; 
} protected boolean addParameter2 ( CoordinateTransform rs , String paramName , NetcdfFile ds , AttributeContainer v , String attName , boolean readData ) { 
String varName ; 
if ( null == ( varName = v . findAttValueIgnoreCase ( attName , null ) ) ) { 
varName = varName . trim ( ) ; 
Variable dataVar ; 
if ( null == ( dataVar = ds . findVariable ( varName ) ) ) { 
if ( readData ) { 
data = dataVar . read ( ) ; 
double [ ] vals = ( double [ ] ) data . get1DJavaArray ( DataType . DOUBLE ) ; 
rs . addParameter ( new Parameter ( paramName , vals ) ) ; 
rs . addParameter ( new Parameter ( paramName , varName ) ) ; 
} public Variable findVariable ( String varShortName ) { 
if ( varShortName == null ) return null ; 
for ( Variable v : variables ) { 
if ( varShortName . equals ( v . getShortName ( ) ) ) 
} public Variable findVariableOrInParent ( String varShortName ) { 
Variable v = findVariable ( varShortName ) ; 
Group parent = getParentGroup ( ) ; 
if ( ( v == null ) && ( parent != null ) ) 
v = parent . findVariableOrInParent ( varShortName ) ; 
} public Group findGroup ( String groupShortName ) { 
if ( groupShortName == null ) return null ; 
for ( Group group : groups ) { 
if ( groupShortName . equals ( group . getShortName ( ) ) ) 
return group ; 
} public Dimension findDimension ( String name ) { 
Dimension d = findDimensionLocal ( name ) ; 
if ( d != null ) return d ; 
return parent . findDimension ( name ) ; 
} public Dimension findDimensionLocal ( String name ) { 
} public java . util . List < Attribute > getAttributes ( ) { 
return attributes . filter ( attributes , Attribute . SPECIALS ) . getAttributes ( ) ; 
} public EnumTypedef findEnumeration ( String name ) { 
for ( EnumTypedef d : enumTypedefs ) { 
return parent . findEnumeration ( name ) ; 
} public Group commonParent ( Group other ) { 
if ( isParent ( other ) ) return this ; 
if ( other . isParent ( this ) ) return other ; 
while ( ! other . isParent ( this ) ) 
other = other . getParentGroup ( ) ; 
return other ; 
} public boolean isParent ( Group other ) { 
while ( ( other != this ) && ( other . getParentGroup ( ) != null ) ) 
return ( other == this ) ; 
} public String getNameAndAttributes ( ) { 
sbuff . append ( getShortName ( ) ) ; 
for ( Attribute att : attributes . getAttributes ( ) ) { 
sbuff . append ( att . toString ( ) ) ; 
sbuff . append ( ";" ) ; 
} public void setParentGroup ( Group parent ) { 
super . setParentGroup ( parent == null ? ncfile . getRootGroup ( ) : parent ) ; 
} public void addDimension ( Dimension dim ) { 
if ( findDimensionLocal ( dim . getShortName ( ) ) != null ) 
dimensions . add ( dim ) ; 
dim . setGroup ( this ) ; 
} public boolean addDimensionIfNotExists ( Dimension dim ) { 
} public void addGroup ( Group g ) { 
if ( findGroup ( g . getShortName ( ) ) != null ) 
groups . add ( g ) ; 
g . setParentGroup ( this ) ; 
} public void addEnumeration ( EnumTypedef e ) { 
if ( e == null ) return ; 
e . setParentGroup ( this ) ; 
enumTypedefs . add ( e ) ; 
} public void addVariable ( Variable v ) { 
if ( findVariable ( v . getShortName ( ) ) != null ) { 
variables . add ( v ) ; 
v . setParentGroup ( this ) ; 
} public boolean remove ( Dimension d ) { 
return d != null && dimensions . remove ( d ) ; 
} public boolean remove ( Group g ) { 
return g != null && groups . remove ( g ) ; 
} public boolean remove ( Variable v ) { 
return v != null && variables . remove ( v ) ; 
} public boolean removeDimension ( String dimName ) { 
if ( dimName . equals ( d . getShortName ( ) ) ) { 
dimensions . remove ( d ) ; 
} public boolean removeVariable ( String shortName ) { 
for ( int i = 0 ; i < variables . size ( ) ; i ++ ) { 
Variable v = variables . get ( i ) ; 
if ( shortName . equals ( v . getShortName ( ) ) ) { 
variables . remove ( v ) ; 
} public Group setImmutable ( ) { 
super . setImmutable ( ) ; 
variables = Collections . unmodifiableList ( variables ) ; 
dimensions = Collections . unmodifiableList ( dimensions ) ; 
groups = Collections . unmodifiableList ( groups ) ; 
attributes . setImmutable ( ) ; 
} public Group makeRelativeGroup ( NetcdfFile ncf , String path , boolean ignorelast ) { 
path = path . replace ( "//" , "/" ) ; 
boolean isabsolute = ( path . charAt ( 0 ) == '/' ) ; 
if ( isabsolute ) 
path = path . substring ( 1 ) ; 
String pieces [ ] = path . split ( "/" ) ; 
if ( ignorelast ) pieces [ pieces . length - 1 ] = null ; 
Group current = ( isabsolute ? ncfile . getRootGroup ( ) : this ) ; 
for ( String name : pieces ) { 
if ( name == null ) continue ; 
String clearname = NetcdfFile . makeNameUnescaped ( name ) ; 
Group next = current . findGroup ( clearname ) ; 
next = new Group ( ncf , current , clearname ) ; 
current . addGroup ( next ) ; 
current = next ; 
return current ; 
} public DAS getDAS ( ) throws DASException 
DAS myDAS = new DAS ( ) ; 
AttributeTable looseEnds = new AttributeTable ( getLooseEndsTableName ( ) ) ; 
AttributeTable atTbl = ( AttributeTable ) getAttributeTable ( ) . clone ( ) ; 
int countLooseAttributes = 0 ; 
Enumeration e = atTbl . getNames ( ) ; 
Attribute a = atTbl . getAttribute ( aName ) ; 
String clearname = a . getClearName ( ) ; 
String attribute = ( ( Alias ) a ) . getAliasedToAttributeFieldAsClearString ( ) ; 
looseEnds . addAlias ( clearname , convertDDSAliasFieldsToDASAliasFields ( attribute ) ) ; 
countLooseAttributes ++ ; 
myDAS . addAttributeTable ( clearname , a . getContainer ( ) ) ; 
int type = a . getType ( ) ; 
Enumeration vals = a . getValues ( ) ; 
while ( vals . hasMoreElements ( ) ) { 
String value = ( String ) vals . nextElement ( ) ; 
looseEnds . appendAttribute ( clearname , type , value , true ) ; 
if ( countLooseAttributes > 0 ) { 
myDAS . addAttributeTable ( looseEnds . getEncodedName ( ) , looseEnds ) ; 
e = getVariables ( ) ; 
buildDASAttributeTable ( bt , myDAS ) ; 
myDAS . resolveAliases ( ) ; 
throw new DASException ( opendap . dap . DAP2Exception . UNKNOWN_ERROR , 
e . getMessage ( ) ) ; 
return ( myDAS ) ; 
} private String convertDDSAliasFieldsToDASAliasFields ( String attribute ) throws MalformedAliasException 
String prefix = "" ; 
Vector aNames = tokenizeAliasField ( attribute ) ; 
String topName = ( String ) aNames . get ( 1 ) ; 
boolean foundIt = false ; 
Enumeration e = getVariables ( ) ; 
String normName = normalize ( bt . getEncodedName ( ) ) ; 
if ( topName . equals ( normName ) ) 
foundIt = true ; 
if ( ! foundIt ) { 
prefix = "." + getLooseEndsTableName ( ) ; 
return ( prefix + attribute ) ; 
} private String checkLooseEndsTableNameConflict ( String clearname , int attempt ) 
String btName = bt . getEncodedName ( ) ; 
if ( btName . equals ( clearname ) ) { 
clearname = repairLooseEndsTableConflict ( clearname , attempt ++ ) ; 
clearname = checkLooseEndsTableNameConflict ( clearname , attempt ) ; 
AttributeTable at = getAttributeTable ( ) ; 
e = at . getNames ( ) ; 
if ( aName . equals ( clearname ) ) { 
return ( clearname ) ; 
} private String repairLooseEndsTableConflict ( String badName , int attempt ) 
String name = "" ; 
switch ( attempt ) { 
name = badName + "_DatasetAttributes_0" ; 
int last_ = badName . lastIndexOf ( "_" ) ; 
name = badName . substring ( 0 , last_ ) + "_" + attempt ; 
return ( name ) ; 
} private void buildDASAttributeTable ( BaseType bt , AttributeTable atbl ) 
throws DASException 
AttributeTable tBTAT = bt . getAttributeTable ( ) ; 
if ( tBTAT == null || tBTAT . size ( ) == 0 ) 
AttributeTable newAT = atbl . appendContainer ( tBTAT . getEncodedName ( ) ) ; 
Enumeration e = tBTAT . getNames ( ) ; 
String attrName = ( String ) e . nextElement ( ) ; 
Attribute attr = tBTAT . getAttribute ( attrName ) ; 
populateAttributeTable ( newAT , attr ) ; 
Enumeration v = ( ( DConstructor ) bt ) . getVariables ( ) ; 
while ( v . hasMoreElements ( ) ) { 
BaseType thisBT = ( BaseType ) v . nextElement ( ) ; 
buildDASAttributeTable ( thisBT , newAT ) ; 
} private void populateAttributeTable ( AttributeTable atTable , Attribute attr ) 
if ( attr . isAlias ( ) ) { 
String alias = attr . getEncodedName ( ) ; 
String attribute = ( ( Alias ) attr ) . getAliasedToAttributeFieldAsClearString ( ) ; 
atTable . addAlias ( alias , convertDDSAliasFieldsToDASAliasFields ( attribute ) ) ; 
} else if ( attr . isContainer ( ) ) { 
AttributeTable thisTable = attr . getContainer ( ) ; 
AttributeTable newTable = atTable . appendContainer ( thisTable . getEncodedName ( ) ) ; 
Enumeration e = thisTable . getNames ( ) ; 
Attribute thisAttr = thisTable . getAttribute ( attrName ) ; 
populateAttributeTable ( newTable , thisAttr ) ; 
int type = attr . getType ( ) ; 
String name = attr . getEncodedName ( ) ; 
Enumeration v = attr . getValues ( ) ; 
String value = ( String ) v . nextElement ( ) ; 
atTable . appendAttribute ( name , type , value ) ; 
} public void printDAS ( PrintWriter pw ) 
myDAS = this . getDAS ( ) ; 
myDAS . print ( pw ) ; 
} catch ( DASException dasE ) { 
dasE . getMessage ( ) ) ; 
} public void delVariable ( String name ) 
BaseType bt = getVariable ( name ) ; 
vars . removeElement ( bt ) ; 
} catch ( NoSuchVariableException e ) { 
} private DConstructor isVectorOfDConstructor ( BaseType var ) 
if ( ! ( var instanceof DVector ) ) 
if ( ! ( ( ( DVector ) var ) . getPrimitiveVector ( ) 
instanceof BaseTypePrimitiveVector ) ) 
BaseTypePrimitiveVector btpv = ( BaseTypePrimitiveVector ) 
( ( DVector ) var ) . getPrimitiveVector ( ) ; 
if ( btpv . getTemplate ( ) instanceof DConstructor ) 
return ( DConstructor ) btpv . getTemplate ( ) ; 
return isVectorOfDConstructor ( btpv . getTemplate ( ) ) ; 
} public BaseType getVariable ( String name ) throws NoSuchVariableException 
Stack s = new Stack ( ) ; 
s = search ( name , s ) ; 
return ( BaseType ) s . pop ( ) ; 
} public Stack search ( String name , Stack compStack ) 
DDSSearch ddsSearch = new DDSSearch ( compStack ) ; 
if ( ddsSearch . deepSearch ( name ) ) 
return ddsSearch . components ; 
} public void parseXML ( InputStream is , boolean validation ) throws DAP2Exception 
DDSXMLParser dp = new DDSXMLParser ( opendapNameSpace ) ; 
dp . parse ( is , this , factory , validation ) ; 
checkForAttributeNameConflict ( ) ; 
resolveAliases ( ) ; 
} public void parseXML ( Document ddxDoc , boolean validation ) throws DAP2Exception 
dp . parse ( ddxDoc , this , factory , validation ) ; 
throws BadSemanticsException 
if ( getEncodedName ( ) == null ) { 
Util . uniqueNames ( vars , getEncodedName ( ) , "Dataset" ) ; 
} public void print ( PrintWriter os ) 
bt . printDecl ( os ) ; 
if ( getEncodedName ( ) != null ) 
os . print ( getEncodedName ( ) ) ; 
} private void resolveAliases ( BaseType bt ) throws MalformedAliasException , UnresolvedAliasException , NoSuchAttributeException 
BaseType cacheBT = currentBT ; 
currentBT = bt ; 
currentAT = null ; 
if ( Debug . isSet ( "DDS.resolveAliases" ) ) 
resolveAliases ( bt . getAttributeTable ( ) ) ; 
Enumeration bte = ( ( DConstructor ) bt ) . getVariables ( ) ; 
while ( bte . hasMoreElements ( ) ) { 
BaseType thisBT = ( BaseType ) bte . nextElement ( ) ; 
resolveAliases ( thisBT ) ; 
currentBT = cacheBT ; 
Enumeration aNames = currentAT . getNames ( ) ; 
if ( Debug . isSet ( "DDS.resolveAliases" ) ) { 
String name = alias . getEncodedName ( ) ; 
Enumeration e = aNames . elements ( ) ; 
BaseType targetBT = null ; 
if ( ! isAbsolutePath ) { 
targetBT = getDeepestMatchingVariable ( this , aNames ) ; 
if ( targetBT == null ) { 
targetBT = this ; 
Attribute targetAT = null ; 
targetAT = targetBT . getAttribute ( ) ; 
targetAT = getAttribute ( targetBT . getAttributeTable ( ) , aNames ) ; 
alias . setMyVariable ( targetBT ) ; 
} private BaseType getDeepestMatchingVariable ( DConstructor dcBT , Vector vNames ) 
String vName = ( String ) vNames . get ( 0 ) ; 
Enumeration bte = dcBT . getVariables ( ) ; 
BaseType bt = ( BaseType ) bte . nextElement ( ) ; 
String normName = normalize ( bt . getClearName ( ) ) ; 
if ( normName . equals ( vName ) ) { 
vNames . remove ( 0 ) ; 
if ( vNames . size ( ) == 0 ) { 
BaseType nextBT = getDeepestMatchingVariable ( ( DConstructor ) bt , vNames ) ; 
if ( nextBT != null ) 
return ( nextBT ) ; 
return ( bt ) ; 
} public static String normalize ( String field ) 
boolean Debug = false ; 
StringBuffer sb = new StringBuffer ( field ) ; 
for ( int offset = 0 ; offset < sb . length ( ) ; offset ++ ) { 
char c = sb . charAt ( offset ) ; 
if ( c == slash || c == quote ) { 
sb . insert ( offset , slash ) ; 
if ( Debug ) { 
} public static Vector tokenizeAliasField ( String field ) throws MalformedAliasException 
int lastIndex = field . length ( ) - 1 ; 
Vector tokens = new Vector ( ) ; 
if ( field . charAt ( 0 ) == quote ) { 
int start = 1 ; 
int end = - 1 ; 
boolean escaped = false ; 
for ( int i = 1 ; i <= lastIndex || ! done ; i ++ ) { 
char c = field . charAt ( i ) ; 
if ( escaped ) { 
escaped = false ; 
if ( c == slash ) { 
escaped = true ; 
} else if ( c == quote ) { 
end = i ; 
if ( end < 0 ) 
if ( lastIndex > end && field . charAt ( end + 1 ) != dot ) 
if ( field . charAt ( lastIndex ) == dot ) 
String firstToken = field . substring ( start , end ) ; 
tokens . add ( firstToken ) ; 
if ( end < lastIndex ) { 
String theRest = field . substring ( end + 2 ) ; 
Enumeration tkns = tokenizeAliasField ( theRest ) . elements ( ) ; 
while ( tkns . hasMoreElements ( ) ) 
tokens . add ( tkns . nextElement ( ) ) ; 
return ( tokens ) ; 
int firstDot = field . indexOf ( dot ) ; 
if ( firstDot == 0 ) { 
String thisToken = "." ; 
tokens . add ( thisToken ) ; 
if ( lastIndex > 0 ) { 
String theRest = field . substring ( 1 ) ; 
if ( firstDot > 0 ) { 
String firstToken = field . substring ( 0 , firstDot ) ; 
if ( lastIndex == firstDot ) 
String theRest = field . substring ( firstDot + 1 ) ; 
tokens . add ( field ) ; 
} public void printXML ( PrintWriter pw , String pad , boolean constrained ) 
pw . print ( "<Dataset" ) ; 
pw . println ( "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"" ) ; 
pw . println ( "xmlns=\"" + opendapNameSpace + "\"" ) ; 
pw . print ( "xsi:schemaLocation=\"" ) ; 
pw . print ( schemaLocation ) ; 
if ( _dataBlobID != null ) { 
DDSXMLParser . normalizeToXML ( _dataBlobID ) + "\"/>" ) ; 
pw . println ( pad + "</Dataset>" ) ; 
} public void ingestDAS ( DAS das ) 
ingestAttributeTable ( das , this ) ; 
} catch ( DASException de ) { 
} private void ingestAttribute ( Attribute a , BaseType bt ) throws DASException 
String name = a . getEncodedName ( ) ; 
bt . addAttributeAlias ( name , attribute ) ; 
AttributeTable at = a . getContainer ( ) ; 
ingestAttributeTable ( at , bt ) ; 
bt . appendAttribute ( name , type , value , true ) ; 
} private void ingestAttributeTable ( AttributeTable at , DConstructor dc ) throws DASException 
Enumeration ate = at . getNames ( ) ; 
while ( ate . hasMoreElements ( ) ) { 
String aName = ( String ) ate . nextElement ( ) ; 
Attribute a = at . getAttribute ( aName ) ; 
Enumeration bte = dc . getVariables ( ) ; 
String bName = thisBT . getEncodedName ( ) ; 
if ( bName . equals ( aName ) ) { 
if ( a . isContainer ( ) && thisBT instanceof DConstructor ) { 
ingestAttributeTable ( a . getContainer ( ) , ( DConstructor ) thisBT ) ; 
ingestAttribute ( a , thisBT ) ; 
ingestAttribute ( a , dc ) ; 
} private void ingestAttributeTable ( AttributeTable at , BaseType bt ) throws DASException 
String atName = at . getEncodedName ( ) ; 
String bName = bt . getEncodedName ( ) ; 
if ( bName . equals ( atName ) ) { 
Enumeration e = at . getNames ( ) ; 
ingestAttribute ( a , bt ) ; 
bt . addAttributeContainer ( at ) ; 
} catch ( AttributeExistsException ase ) { 
} private void checkForAttributeNameConflict ( DConstructor dc ) throws BadSemanticsException 
Enumeration ate = dc . getAttributeNames ( ) ; 
if ( aName . equals ( bt . getEncodedName ( ) ) ) { 
checkForAttributeNameConflict ( ( DConstructor ) bt ) ; 
} public String getDDSText ( ) 
this . print ( new PrintWriter ( sw ) ) ; 
} public String getDDXText ( ) 
this . printXML ( new PrintWriter ( sw ) ) ; 
DDS d = ( DDS ) super . cloneDAG ( map ) ; 
d . vars = new Vector ( ) ; 
BaseType element = ( BaseType ) vars . elementAt ( i ) ; 
d . vars . addElement ( cloneDAG ( map , element ) ) ; 
d . setEncodedName ( this . getEncodedName ( ) ) ; 
d . factory = this . factory ; 
boolean ok = false ; 
Grib2IndexProto . Grib2Index . Builder rootBuilder = Grib2IndexProto . Grib2Index . newBuilder ( ) ; 
Grib2RecordScanner scan = new Grib2RecordScanner ( dataRaf ) ; 
Grib2Record r = scan . next ( ) ; 
Grib2SectionGridDefinition gdss = r . getGDSsection ( ) ; 
if ( index == null ) { 
rootBuilder . addRecords ( makeRecordProto ( r , index , r . getGDS ( ) . scanMode ) ) ; 
Grib2IndexProto . Grib2Index index = rootBuilder . build ( ) ; 
ok = true ; 
} private Grib2IndexProto . GribIdSection makeIdProto ( Grib2SectionIdentification id ) { 
Grib2IndexProto . GribIdSection . Builder b = Grib2IndexProto . GribIdSection . newBuilder ( ) ; 
b . setCenterId ( id . getCenter_id ( ) ) ; 
b . setSubcenterId ( id . getSubcenter_id ( ) ) ; 
b . setMasterTableVersion ( id . getMaster_table_version ( ) ) ; 
b . setLocalTableVersion ( id . getLocal_table_version ( ) ) ; 
b . setSignificanceOfRT ( id . getSignificanceOfRT ( ) ) ; 
b . addRefDate ( id . getYear ( ) ) ; 
b . addRefDate ( id . getMonth ( ) ) ; 
b . addRefDate ( id . getDay ( ) ) ; 
b . addRefDate ( id . getHour ( ) ) ; 
b . addRefDate ( id . getMinute ( ) ) ; 
b . addRefDate ( id . getSecond ( ) ) ; 
b . setProductionStatus ( id . getProductionStatus ( ) ) ; 
b . setProcessedDataType ( id . getTypeOfProcessedData ( ) ) ; 
} public void writeGrid ( GridDataset dataset , GridDatatype grid , Array data , boolean greyScale ) throws IOException { 
double xStart = xaxis . getCoordEdge ( 0 ) * scaler ; 
double yStart = yaxis . getCoordEdge ( 0 ) * scaler ; 
yStart = yaxis . getCoordEdge ( ( int ) yaxis . getSize ( ) ) * scaler ; 
writeGrid ( grid , data , greyScale , xStart , yStart , xInc , yInc , pageNumber ) ; 
} protected void writeGrid ( GridDatatype grid , Array data , boolean greyScale , double xStart , double yStart , double xInc , 
double yInc , int imageNumber ) throws IOException { 
int nextStart = 0 ; 
if ( ! gcs . isLatLon ( ) 
&& ! ( gcs . getProjection ( ) instanceof LambertConformal ) 
&& ! ( gcs . getProjection ( ) instanceof Stereographic ) 
&& ! ( gcs . getProjection ( ) instanceof Mercator ) 
&& ! ( gcs . getProjection ( ) instanceof AlbersEqualAreaEllipse ) 
&& ! ( gcs . getProjection ( ) instanceof AlbersEqualArea ) ) { 
MAMath . MinMax dataMinMax = grid . getMinMaxSkipMissingData ( data ) ; 
if ( greyScale ) { 
ArrayByte result = replaceMissingValuesAndScale ( grid , data , dataMinMax ) ; 
nextStart = geotiff . writeData ( ( byte [ ] ) result . getStorage ( ) , imageNumber ) ; 
ArrayFloat result = replaceMissingValues ( grid , data , dataMinMax ) ; 
nextStart = geotiff . writeData ( ( float [ ] ) result . getStorage ( ) , imageNumber ) ; 
int height = data . getShape ( ) [ 0 ] ; 
int width = data . getShape ( ) [ 1 ] ; 
writeMetadata ( greyScale , xStart , yStart , xInc , yInc , height , width , imageNumber , nextStart , dataMinMax , gcs . getProjection ( ) ) ; 
} private ArrayFloat replaceMissingValues ( IsMissingEvaluator grid , Array data , MAMath . MinMax dataMinMax ) { 
float minValue = ( float ) ( dataMinMax . min - 1.0 ) ; 
ArrayFloat floatArray = ( ArrayFloat ) Array . factory ( DataType . FLOAT , data . getShape ( ) ) ; 
IndexIterator dataIter = data . getIndexIterator ( ) ; 
IndexIterator floatIter = floatArray . getIndexIterator ( ) ; 
while ( dataIter . hasNext ( ) ) { 
float v = dataIter . getFloatNext ( ) ; 
if ( grid . isMissing ( ( double ) v ) ) { 
v = minValue ; 
floatIter . setFloatNext ( v ) ; 
return floatArray ; 
} private ArrayByte replaceMissingValuesAndScale ( IsMissingEvaluator grid , Array data , MAMath . MinMax dataMinMax ) { 
double scale = 254.0 / ( dataMinMax . max - dataMinMax . min ) ; 
ArrayByte byteArray = ( ArrayByte ) Array . factory ( DataType . BYTE , data . getShape ( ) ) ; 
IndexIterator resultIter = byteArray . getIndexIterator ( ) ; 
byte bv ; 
double v = dataIter . getDoubleNext ( ) ; 
if ( grid . isMissing ( v ) ) { 
bv = 0 ; 
int iv = ( int ) ( ( v - dataMinMax . min ) * scale + 1 ) ; 
bv = ( byte ) ( iv & 0xff ) ; 
resultIter . setByteNext ( bv ) ; 
return byteArray ; 
} private double geoShiftGetXstart ( Array lon , double inc ) { 
Index ilon = lon . getIndex ( ) ; 
int [ ] lonShape = lon . getShape ( ) ; 
double xlon = 0.0 ; 
LatLonPoint p0 = new LatLonPointImpl ( 0 , lon . getFloat ( ilon . set ( 0 ) ) ) ; 
LatLonPoint pN = new LatLonPointImpl ( 0 , lon . getFloat ( ilon . set ( lonShape [ 0 ] - 1 ) ) ) ; 
xlon = p0 . getLongitude ( ) ; 
while ( lonIter . hasNext ( ) ) { 
float l = lonIter . getFloatNext ( ) ; 
LatLonPoint pn = new LatLonPointImpl ( 0 , l ) ; 
if ( pn . getLongitude ( ) < xlon ) { 
xlon = pn . getLongitude ( ) ; 
if ( p0 . getLongitude ( ) == pN . getLongitude ( ) ) { 
xlon = xlon - inc ; 
return xlon ; 
} public void writeGrid ( GeoReferencedArray array , boolean greyScale ) throws IOException { 
CoverageCoordSys gcs = array . getCoordSysForData ( ) ; 
if ( ! gcs . isRegularSpatial ( ) ) 
Projection proj = gcs . getProjection ( ) ; 
CoverageCoordAxis1D xaxis = ( CoverageCoordAxis1D ) gcs . getXAxis ( ) ; 
CoverageCoordAxis1D yaxis = ( CoverageCoordAxis1D ) gcs . getYAxis ( ) ; 
double scaler = ( xaxis . getUnits ( ) . equalsIgnoreCase ( "km" ) ) ? 1000.0 : 1.0 ; 
double xStart = xaxis . getCoordEdge1 ( 0 ) * scaler ; 
double yStart = yaxis . getCoordEdge1 ( 0 ) * scaler ; 
double xInc = xaxis . getResolution ( ) * scaler ; 
double yInc = Math . abs ( yaxis . getResolution ( ) ) * scaler ; 
Array data = array . getData ( ) . reduce ( ) ; 
if ( yaxis . getCoordMidpoint ( 0 ) < yaxis . getCoordMidpoint ( 1 ) ) { 
yStart = yaxis . getCoordEdgeLast ( ) ; 
MAMath . MinMax dataMinMax = MAMath . getMinMaxSkipMissingData ( data , array ) ; 
ArrayByte result = replaceMissingValuesAndScale ( array , data , dataMinMax ) ; 
nextStart = geotiff . writeData ( ( byte [ ] ) result . getStorage ( ) , pageNumber ) ; 
ArrayFloat result = replaceMissingValues ( array , data , dataMinMax ) ; 
nextStart = geotiff . writeData ( ( float [ ] ) result . getStorage ( ) , pageNumber ) ; 
writeMetadata ( greyScale , xStart , yStart , xInc , yInc , height , width , pageNumber , nextStart , dataMinMax , proj ) ; 
} private List < Variable > searchAliasedDimension ( NetcdfDataset ds , Dimension dim ) { 
String alias = ds . findAttValueIgnoreCase ( null , dimName , null ) ; 
while ( parser . hasMoreTokens ( ) ) { 
String token = parser . nextToken ( ) ; 
Variable ncvar = ds . findVariable ( token ) ; 
if ( ncvar == null ) 
if ( ncvar . getRank ( ) != 1 ) 
Iterator dimIter = ncvar . getDimensions ( ) . iterator ( ) ; 
Dimension dim2 = ( Dimension ) dimIter . next ( ) ; 
if ( dimName . equals ( dim2 . getShortName ( ) ) ) { 
vars . add ( ncvar ) ; 
if ( debug ) System . out . println ( ) ; 
} public void write ( HttpServletResponse hsr ) throws IOException { 
PrintWriter xmlResponse = hsr . getWriter ( ) ; 
xmlResponse . append ( "exceptionCode=\"" + ExceptionCode + "\">" ) ; 
xmlResponse . append ( "<ows:ExceptionText>" + text + "</ows:ExceptionText>" ) ; 
xmlResponse . append ( "</ows:Exception>" ) ; 
xmlResponse . append ( "</ows:ExceptionReport>" ) ; 
} static ArrayInt factory ( Index index , boolean isUnsigned ) { 
return ArrayInt . factory ( index , isUnsigned , null ) ; 
} static ArrayInt factory ( Index index , boolean isUnsigned , int [ ] storage ) { 
return new ArrayInt . D0 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D1 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D2 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D3 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D4 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D5 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D6 ( index , isUnsigned , storage ) ; 
return new ArrayInt . D7 ( index , isUnsigned , storage ) ; 
return new ArrayInt ( index , isUnsigned , storage ) ; 
int [ ] ja = ( int [ ] ) javaArray ; 
for ( int aJa : ja ) iter . setIntNext ( aJa ) ; 
int val = storage [ index ] ; 
return ( double ) ( isUnsigned ( ) ? DataType . unsignedIntToLong ( val ) : val ) ; 
public synchronized 
String nc_inq_libvers ( ) { 
String ret ; 
try { ce ( ) ; 
ret = nc4 . nc_inq_libvers ( ) ; 
if ( TRACE ) trace ( ret , "nc_inq_libvers" , "-" ) ; 
} finally { cx ( ) ; } 
} static GribCollectionImmutable acquireGribCollection ( FileFactory factory , Object hashKey , 
String location , int buffer_size , CancelTask cancelTask , Object spiObject ) throws IOException { 
FileCacheable result ; 
DatasetUrl durl = new DatasetUrl ( null , location ) ; 
if ( gribCollectionCache != null ) { 
result = GribCdmIndex . gribCollectionCache . acquire ( factory , hashKey , durl , buffer_size , cancelTask , spiObject ) ; 
result = factory . open ( durl , buffer_size , cancelTask , spiObject ) ; 
return ( GribCollectionImmutable ) result ; 
} public static File getTopIndexFileFromConfig ( FeatureCollectionConfig config ) { 
File indexFile = makeTopIndexFileFromConfig ( config ) ; 
return GribIndexCache . getExistingFileOrCache ( indexFile . getPath ( ) ) ; 
} private static File makeTopIndexFileFromConfig ( FeatureCollectionConfig config ) { 
CollectionSpecParser specp = config . getCollectionSpecParser ( errlog ) ; 
String name = StringUtil2 . replace ( config . collectionName , '\\' , "/" ) ; 
return makeIndexFile ( name , new File ( specp . getRootDir ( ) ) ) ; 
} public static GribCollectionType getType ( RandomAccessFile raf ) throws IOException { 
String magic ; 
magic = raf . readString ( Grib2CollectionWriter . MAGIC_START . getBytes ( CDM . utf8Charset ) . length ) ; 
switch ( magic ) { 
case Grib2CollectionWriter . MAGIC_START : 
return GribCollectionType . GRIB2 ; 
case Grib1CollectionWriter . MAGIC_START : 
return GribCollectionType . GRIB1 ; 
case Grib2PartitionBuilder . MAGIC_START : 
return GribCollectionType . Partition2 ; 
case Grib1PartitionBuilder . MAGIC_START : 
return GribCollectionType . Partition1 ; 
return GribCollectionType . none ; 
public static GribCollectionImmutable openCdmIndex ( String indexFilename , FeatureCollectionConfig config , boolean useCache , Logger logger ) throws IOException { 
File indexFileInCache = useCache ? GribIndexCache . getExistingFileOrCache ( indexFilename ) : new File ( indexFilename ) ; 
if ( indexFileInCache == null ) 
String indexFilenameInCache = indexFileInCache . getPath ( ) ; 
String name = makeNameFromIndexFilename ( indexFilename ) ; 
GribCollectionImmutable result = null ; 
try ( RandomAccessFile raf = RandomAccessFile . acquire ( indexFilenameInCache ) ) { 
GribCollectionType type = getType ( raf ) ; 
case GRIB2 : 
result = Grib2CollectionBuilderFromIndex . readFromIndex ( name , raf , config , logger ) ; 
case Partition2 : 
result = Grib2PartitionBuilderFromIndex . createTimePartitionFromIndex ( name , raf , config , logger ) ; 
case GRIB1 : 
result = Grib1CollectionBuilderFromIndex . readFromIndex ( name , raf , config , logger ) ; 
case Partition1 : 
result = Grib1PartitionBuilderFromIndex . createTimePartitionFromIndex ( name , raf , config , logger ) ; 
} catch ( FileNotFoundException ioe ) { 
RandomAccessFile . eject ( indexFilenameInCache ) ; 
if ( ! indexFileInCache . delete ( ) ) 
public static GribCollectionMutable openMutableGCFromIndex ( String indexFilename , FeatureCollectionConfig config , boolean dataOnly , boolean useCache , Logger logger ) { 
if ( indexFileInCache == null ) { 
GribCollectionMutable result = null ; 
result = Grib2CollectionBuilderFromIndex . openMutableGCFromIndex ( name , raf , config , logger ) ; 
result = Grib2PartitionBuilderFromIndex . openMutablePCFromIndex ( name , raf , config , logger ) ; 
result = Grib1CollectionBuilderFromIndex . openMutableGCFromIndex ( name , raf , config , logger ) ; 
result = Grib1PartitionBuilderFromIndex . openMutablePCFromIndex ( name , raf , config , logger ) ; 
result . lastModified = raf . getLastModified ( ) ; 
result . fileSize = raf . length ( ) ; 
} public static boolean updateGribCollectionFromPCollection ( boolean isGrib1 , PartitionManager dcm , CollectionUpdateType updateType , 
Formatter errlog , org . slf4j . Logger logger ) throws IOException { 
if ( updateType == CollectionUpdateType . never || dcm instanceof CollectionSingleIndexFile ) { 
boolean changed = updatePartition ( isGrib1 , dcm , updateType , logger , errlog ) ; 
return changed ; 
} public static boolean updateGribCollection ( FeatureCollectionConfig config , CollectionUpdateType updateType , Logger logger ) throws IOException { 
if ( logger == null ) logger = classLogger ; 
Path rootPath = Paths . get ( specp . getRootDir ( ) ) ; 
boolean isGrib1 = config . type == FeatureCollectionType . GRIB1 ; 
if ( config . ptype == FeatureCollectionConfig . PartitionType . none || config . ptype == FeatureCollectionConfig . PartitionType . all ) { 
try ( CollectionAbstract dcm = new CollectionPathMatcher ( config , specp , logger ) ) { 
changed = updateGribCollection ( isGrib1 , dcm , updateType , FeatureCollectionConfig . PartitionType . none , logger , errlog ) ; 
} else if ( config . ptype == FeatureCollectionConfig . PartitionType . timePeriod ) { 
try ( TimePartition tp = new TimePartition ( config , specp , logger ) ) { 
changed = updateTimePartition ( isGrib1 , tp , updateType , logger ) ; 
if ( specp . wantSubdirs ( ) ) { 
try ( DirectoryPartition dpart = new DirectoryPartition ( config , rootPath , true , new GribCdmIndex ( logger ) , NCX_SUFFIX , logger ) ) { 
dpart . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; 
changed = updateDirectoryCollectionRecurse ( isGrib1 , dpart , config , updateType , logger ) ; 
changed = updateLeafCollection ( isGrib1 , config , updateType , true , logger , rootPath ) ; 
} public static boolean updateGribCollection ( boolean isGrib1 , MCollection dcm , 
CollectionUpdateType updateType , FeatureCollectionConfig . PartitionType ptype , 
Logger logger , Formatter errlog ) throws IOException { 
if ( ! isUpdateNeeded ( dcm . getIndexFilename ( NCX_SUFFIX ) , updateType , ( isGrib1 ? GribCollectionType . GRIB1 : GribCollectionType . GRIB2 ) , logger ) ) return false ; 
if ( isGrib1 ) { 
Grib1CollectionBuilder builder = new Grib1CollectionBuilder ( dcm . getCollectionName ( ) , dcm , logger ) ; 
changed = builder . updateNeeded ( updateType ) && builder . createIndex ( ptype , errlog ) ; 
Grib2CollectionBuilder builder = new Grib2CollectionBuilder ( dcm . getCollectionName ( ) , dcm , logger ) ; 
} private static boolean updatePartition ( boolean isGrib1 , PartitionManager dcm , CollectionUpdateType updateType , 
Grib1PartitionBuilder builder = new Grib1PartitionBuilder ( dcm . getCollectionName ( ) , new File ( dcm . getRoot ( ) ) , dcm , logger ) ; 
changed = builder . updateNeeded ( updateType ) && builder . createPartitionedIndex ( updateType , errlog ) ; 
Grib2PartitionBuilder builder = new Grib2PartitionBuilder ( dcm . getCollectionName ( ) , new File ( dcm . getRoot ( ) ) , dcm , logger ) ; 
} private static boolean updateLeafCollection ( boolean isGrib1 , FeatureCollectionConfig config , 
CollectionUpdateType updateType , boolean isTop , 
Logger logger , Path dirPath ) throws IOException { 
if ( config . ptype == FeatureCollectionConfig . PartitionType . file ) { 
return updateFilePartition ( isGrib1 , config , updateType , isTop , logger , dirPath ) ; 
try ( DirectoryCollection dcm = new DirectoryCollection ( config . collectionName , dirPath , isTop , config . olderThan , logger ) ) { 
dcm . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; 
if ( specp . getFilter ( ) != null ) 
dcm . setStreamFilter ( new StreamFilter ( specp . getFilter ( ) , specp . getFilterOnName ( ) ) ) ; 
boolean changed = updateGribCollection ( isGrib1 , dcm , updateType , FeatureCollectionConfig . PartitionType . directory , logger , errlog ) ; 
} private static boolean updateFilePartition ( final boolean isGrib1 , final FeatureCollectionConfig config , 
final CollectionUpdateType updateType , boolean isTop , 
final Logger logger , Path dirPath ) throws IOException { 
final Formatter errlog = new Formatter ( ) ; 
try ( FilePartition partition = new FilePartition ( config . collectionName , dirPath , isTop , config . olderThan , logger ) ) { 
partition . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; 
partition . setStreamFilter ( new StreamFilter ( specp . getFilter ( ) , specp . getFilterOnName ( ) ) ) ; 
if ( ! isUpdateNeeded ( partition . getIndexFilename ( NCX_SUFFIX ) , updateType , ( isGrib1 ? GribCollectionType . Partition1 : GribCollectionType . Partition2 ) , logger ) ) 
final AtomicBoolean anyChange = new AtomicBoolean ( false ) ; 
if ( updateType != CollectionUpdateType . testIndexOnly ) { 
partition . iterateOverMFileCollection ( mfile -> { 
MCollection part = new CollectionSingleFile ( mfile , logger ) ; 
part . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; 
boolean changed = updateGribCollection ( isGrib1 , part , updateType , FeatureCollectionConfig . PartitionType . file , logger , errlog ) ; 
if ( changed ) anyChange . set ( true ) ; 
} catch ( IllegalStateException t ) { 
partition . removePartition ( part ) ; 
boolean recreated = updatePartition ( isGrib1 , partition , updateType , logger , errlog ) ; 
return recreated ; 
} public static GribCollectionImmutable openGribCollection ( FeatureCollectionConfig config , CollectionUpdateType updateType , Logger logger ) throws IOException { 
boolean changed = updateGribCollection ( config , updateType , logger ) ; 
File idxFile = makeTopIndexFileFromConfig ( config ) ; 
if ( ( updateType == CollectionUpdateType . never ) || changed ) { 
gribCollectionCache . clearCache ( true ) ; 
return openCdmIndex ( idxFile . getPath ( ) , config , true , logger ) ; 
} public static GribCollectionImmutable openGribCollectionFromRaf ( RandomAccessFile raf , FeatureCollectionConfig config , 
CollectionUpdateType updateType , org . slf4j . Logger logger ) throws IOException { 
GribCollectionImmutable result ; 
boolean isGrib1 = false ; 
boolean isGrib2 = Grib2RecordScanner . isValidFile ( raf ) ; 
if ( ! isGrib2 ) isGrib1 = Grib1RecordScanner . isValidFile ( raf ) ; 
if ( isGrib1 || isGrib2 ) { 
result = openGribCollectionFromDataFile ( isGrib1 , raf , config , updateType , null , logger ) ; 
result = openGribCollectionFromIndexFile ( raf , config , logger ) ; 
} private static GribCollectionImmutable openGribCollectionFromDataFile ( boolean isGrib1 , RandomAccessFile dataRaf , FeatureCollectionConfig config , 
CollectionUpdateType updateType , Formatter errlog , org . slf4j . Logger logger ) throws IOException { 
String filename = dataRaf . getLocation ( ) ; 
File dataFile = new File ( filename ) ; 
MFile mfile = new MFileOS ( dataFile ) ; 
return openGribCollectionFromDataFile ( isGrib1 , mfile , updateType , config , errlog , logger ) ; 
public static GribCollectionImmutable openGribCollectionFromDataFile ( boolean isGrib1 , MFile mfile , CollectionUpdateType updateType , 
FeatureCollectionConfig config , Formatter errlog , org . slf4j . Logger logger ) throws IOException { 
MCollection dcm = new CollectionSingleFile ( mfile , logger ) ; 
boolean changed = ( builder . updateNeeded ( updateType ) && builder . createIndex ( FeatureCollectionConfig . PartitionType . file , errlog ) ) ; 
GribCollectionImmutable result = openCdmIndex ( dcm . getIndexFilename ( NCX_SUFFIX ) , config , true , logger ) ; 
if ( updateType == CollectionUpdateType . never ) return null ; 
if ( updateType == CollectionUpdateType . always ) return null ; 
return openGribCollectionFromDataFile ( isGrib1 , mfile , CollectionUpdateType . always , config , errlog , logger ) ; 
public static GribCollectionImmutable openGribCollectionFromIndexFile ( RandomAccessFile indexRaf , FeatureCollectionConfig config , 
org . slf4j . Logger logger ) throws IOException { 
GribCollectionType type = getType ( indexRaf ) ; 
String location = indexRaf . getLocation ( ) ; 
int pos = f . getName ( ) . lastIndexOf ( "." ) ; 
String name = ( pos > 0 ) ? f . getName ( ) . substring ( 0 , pos ) : f . getName ( ) ; 
return Grib1PartitionBuilderFromIndex . createTimePartitionFromIndex ( name , indexRaf , config , logger ) ; 
return Grib1CollectionBuilderFromIndex . readFromIndex ( name , indexRaf , config , logger ) ; 
return Grib2PartitionBuilderFromIndex . createTimePartitionFromIndex ( name , indexRaf , config , logger ) ; 
return Grib2CollectionBuilderFromIndex . readFromIndex ( name , indexRaf , config , logger ) ; 
public boolean readChildren ( Path indexFile , AddChildCallback callback ) throws IOException { 
try ( RandomAccessFile raf = RandomAccessFile . acquire ( indexFile . toString ( ) ) ) { 
if ( type == GribCollectionType . Partition1 || type == GribCollectionType . Partition2 ) { 
if ( openIndex ( raf , logger ) ) { 
String topDir = gribCollectionIndex . getTopDir ( ) ; 
int n = gribCollectionIndex . getMfilesCount ( ) ; 
GribCollectionProto . MFile mfilep = gribCollectionIndex . getMfiles ( i ) ; 
callback . addChild ( topDir , mfilep . getFilename ( ) , mfilep . getLastModified ( ) ) ; 
urlMatch ( URL pattern , URL url ) { 
int relation ; 
if ( pattern == null ) 
return ( url == null ) ; 
if ( ! ( url . getHost ( ) . endsWith ( pattern . getHost ( ) ) ) ) 
if ( ! ( url . getPath ( ) . startsWith ( pattern . getPath ( ) ) ) ) 
if ( pattern . getPort ( ) > 0 && pattern . getPort ( ) != url . getPort ( ) ) 
add ( String key , String value , String url ) { 
if ( key == null ) return ; 
if ( ! initialized ) RC . initialize ( ) ; 
Triple t = new Triple ( key , value , url ) ; 
dfaltRC . insert ( t ) ; 
setWellKnown ( ) ; 
} static synchronized public String 
find ( String key , String url ) { 
Triple t = dfaltRC . lookup ( key , url ) ; 
return ( t == null ? null : t . value ) ; 
} static void 
setWellKnown ( ) { 
if ( dfaltRC . triplestore . size ( ) == 0 ) return ; 
for ( String key : dfaltRC . keySet ( ) ) { 
Triple triple = dfaltRC . lookup ( key ) ; 
if ( triple . url == null ) { 
RC . set ( key , triple . value ) ; 
load ( String abspath ) { 
abspath = abspath . replace ( '\\' , '/' ) ; 
File rcFile = new File ( abspath ) ; 
if ( ! rcFile . exists ( ) || ! rcFile . canRead ( ) ) { 
try ( BufferedReader rdr = new BufferedReader ( new InputStreamReader ( new FileInputStream ( rcFile ) , CDM . UTF8 ) ) ) { 
for ( int lineno = 1 ; ; lineno ++ ) { 
URL url = null ; 
String line = rdr . readLine ( ) ; 
line = line . trim ( ) ; 
if ( line . length ( ) == 0 ) continue ; 
if ( line . charAt ( 0 ) == '#' ) continue ; 
if ( line . charAt ( 0 ) == LTAG ) { 
int rindex = line . indexOf ( RTAG ) ; 
if ( rindex < 0 ) return false ; 
String surl = line . substring ( 1 , rindex ) ; 
url = new URL ( surl ) ; 
} catch ( MalformedURLException mue ) { 
line = line . substring ( rindex + 1 ) ; 
String [ ] pieces = line . split ( "\\s*=\\s*" ) ; 
assert ( pieces . length == 1 || pieces . length == 2 ) ; 
String value = "1" ; 
if ( pieces . length == 2 ) value = pieces [ 1 ] . trim ( ) ; 
Triple triple = new Triple ( pieces [ 0 ] . trim ( ) , value , url ) ; 
List < Triple > list = triplestore . get ( triple . key ) ; 
if ( list == null ) list = new ArrayList < Triple > ( ) ; 
Triple prev = addtriple ( list , triple ) ; 
triplestore . put ( triple . key , list ) ; 
} catch ( FileNotFoundException fe ) { 
} public Triple 
insert ( Triple t ) { 
if ( t . key == null ) return null ; 
List < Triple > list = triplestore . get ( t . key ) ; 
Triple prev = addtriple ( list , t ) ; 
triplestore . put ( t . key , list ) ; 
lhs . printConstraint ( os ) ; 
String op = ExprParserConstants . tokenImage [ operator ] ; 
op = op . substring ( 1 , op . length ( ) - 1 ) ; 
os . print ( op ) ; 
if ( rhs . size ( ) == 1 ) { 
( ( ValueClause ) rhs . get ( 0 ) ) . printConstraint ( os ) ; 
os . print ( "{" ) ; 
Iterator it = rhs . iterator ( ) ; 
( ( ValueClause ) it . next ( ) ) . printConstraint ( os ) ; 
} public List < Dataset > getDatasetsLocal ( ) { 
List < Dataset > datasets = ( List < Dataset > ) flds . get ( Dataset . Datasets ) ; 
return datasets == null ? new ArrayList < > ( 0 ) : datasets ; 
} public Dataset findDatasetByName ( String name ) { 
if ( ds . getName ( ) . equals ( name ) ) return ds ; 
Dataset result = ds . findDatasetByName ( name ) ; 
} public void setProjection ( ProjectionImpl project ) { 
displayProject = project ; 
if ( featSetList == null ) 
Iterator iter = featSetList . iterator ( ) ; 
FeatureSet fs = ( FeatureSet ) iter . next ( ) ; 
fs . newProjection = true ; 
long startTime = System . currentTimeMillis ( ) ; 
if ( featSetList == null ) { 
initFeatSetList ( ) ; 
assert ! featSetList . isEmpty ( ) ; 
FeatureSet fs = ( FeatureSet ) featSetList . get ( 0 ) ; 
if ( featSetList . size ( ) > 1 ) { 
double scale = 1.0 ; 
AffineTransform world2device = g . getTransform ( ) ; 
AffineTransform world2normal = normal2device . createInverse ( ) ; 
world2normal . concatenate ( world2device ) ; 
scale = Math . max ( Math . abs ( world2normal . getScaleX ( ) ) , Math . abs ( world2normal . getShearX ( ) ) ) ; 
if ( Debug . isSet ( "GisFeature/showTransform" ) ) { 
if ( ! displayProject . isLatLon ( ) ) 
scale *= 111.0 ; 
double minD = Double . MAX_VALUE ; 
for ( Object aFeatSetList : featSetList ) { 
FeatureSet tryfs = ( FeatureSet ) aFeatSetList ; 
double d = Math . abs ( scale * tryfs . minDist - pixelMatch ) ; 
if ( d < minD ) { 
minD = d ; 
fs = tryfs ; 
if ( Debug . isSet ( "GisFeature/MapResolution" ) ) { 
if ( fs . featureList == null ) 
fs . createFeatures ( ) ; 
if ( ! displayProject . equals ( fs . project ) ) { 
fs . setProjection ( displayProject ) ; 
if ( fs . newProjection && displayProject . isLatLon ( ) ) { 
fs . newProjection = false ; 
if ( Debug . isSet ( "GisFeature/timing/getShapes" ) ) { 
long tookTime = System . currentTimeMillis ( ) - startTime ; 
return fs . getShapes ( ) ; 
} private ArrayList makeShapes ( Iterator featList ) { 
ArrayList shapeList = new ArrayList ( ) ; 
if ( Debug . isSet ( "GisFeature/MapDraw" ) ) { 
while ( featList . hasNext ( ) ) { 
AbstractGisFeature feature = ( AbstractGisFeature ) featList . next ( ) ; 
if ( dataProject . isLatLon ( ) ) 
else if ( dataProject == displayProject ) 
return shapeList ; 
return getID ( ) . length ( ) >= string . length ( ) 
? getID ( ) . compareToIgnoreCase ( string ) 
: getID ( ) . compareToIgnoreCase ( 
string . substring ( 0 , getID ( ) . length ( ) ) ) ; 
} public boolean startProgressMonitorTask ( ProgressMonitorTask pmt ) { 
if ( busy ) return false ; 
busy = true ; 
this . task = pmt ; 
isCancelled = false ; 
setIcon ( icon [ 0 ] ) ; 
if ( isCancelled && ! task . isCancel ( ) ) { 
setIcon ( icon [ count % 2 ] ) ; 
if ( myTimer != null ) 
myTimer . stop ( ) ; 
myTimer = null ; 
if ( task . isError ( ) ) 
busy = false ; 
myTimer = new javax . swing . Timer ( 1000 , watcher ) ; 
myTimer . start ( ) ; 
Thread taskThread = new Thread ( task ) ; 
} private Accum scanLeafDirectoryCollection ( boolean isGrib1 , FeatureCollectionConfig config , 
Counters parentCounters , 
Logger logger , Path dirPath , boolean isTop , 
Indent indent , Formatter fm ) throws IOException { 
reportOneFileHeader ( indent , fm ) ; 
Accum accum = new Accum ( ) ; 
int nfiles = 0 ; 
Counters countersThisDir = parentCounters . makeSubCounters ( ) ; 
DirectoryCollection dcm = new DirectoryCollection ( config . collectionName , dirPath , isTop , config . olderThan , logger ) ; 
try ( CloseableIterator < MFile > iter = dcm . getFileIterator ( ) ) { 
MFile mfile = iter . next ( ) ; 
Counters countersOneFile = countersThisDir . makeSubCounters ( ) ; 
Grib1Index grib1Index = readGrib1Index ( mfile , false ) ; 
if ( grib1Index == null ) { 
for ( ucar . nc2 . grib . grib1 . Grib1Record gr : grib1Index . getRecords ( ) ) { 
accumGrib1Record ( gr , countersOneFile ) ; 
Grib2Index grib2Index = readGrib2Index ( mfile , false ) ; 
if ( grib2Index == null ) { 
for ( ucar . nc2 . grib . grib2 . Grib2Record gr : grib2Index . getRecords ( ) ) { 
accumGrib2Record ( gr , countersOneFile ) ; 
accum . nrecords += nrecords ; 
countersThisDir . addTo ( countersOneFile ) ; 
if ( config . ptype == FeatureCollectionConfig . PartitionType . file ) 
reportOneFile ( mfile , nrecords , countersOneFile , indent , fm ) ; 
nfiles ++ ; 
if ( path . endsWith ( GribIndex . GBX9_IDX ) ) { 
accum . indexSize += ( ( float ) mfile . getLength ( ) / ( 1000 * 1000 ) ) ; 
accum . fileSize += ( ( float ) mfile . getLength ( ) / ( 1000 * 1000 ) ) ; 
File idxFile = GribIndexCache . getExistingFileOrCache ( path + GribIndex . GBX9_IDX ) ; 
if ( idxFile . exists ( ) ) 
accum . indexSize += ( ( float ) idxFile . length ( ) / ( 1000 * 1000 ) ) ; 
parentCounters . addTo ( countersThisDir ) ; 
accum . nfiles += nfiles ; 
accum . last = reportOneDir ( dirPath . toString ( ) , accum , countersThisDir , indent , accum . last ) ; 
} private boolean needsUpdate ( CollectionUpdateType ff , File collectionIndexFile ) throws IOException { 
long collectionLastModified = collectionIndexFile . lastModified ( ) ; 
Set < String > newFileSet = new HashSet < > ( ) ; 
for ( MCollection dcm : partitionManager . makePartitions ( CollectionUpdateType . test ) ) { 
String partitionIndexFilename = StringUtil2 . replace ( dcm . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) , '\\' , "/" ) ; 
File partitionIndexFile = GribIndexCache . getExistingFileOrCache ( partitionIndexFilename ) ; 
if ( partitionIndexFile == null ) 
if ( collectionLastModified < partitionIndexFile . lastModified ( ) ) 
newFileSet . add ( partitionIndexFilename ) ; 
if ( ff == CollectionUpdateType . testIndexOnly ) return false ; 
GribCdmIndex reader = new GribCdmIndex ( logger ) ; 
List < MFile > oldFiles = new ArrayList < > ( ) ; 
reader . readMFiles ( collectionIndexFile . toPath ( ) , oldFiles ) ; 
Set < String > oldFileSet = new HashSet < > ( ) ; 
for ( MFile oldFile : oldFiles ) { 
if ( ! newFileSet . contains ( oldFile . getPath ( ) ) ) 
oldFileSet . add ( oldFile . getPath ( ) ) ; 
for ( String newFilename : newFileSet ) { 
if ( ! oldFileSet . contains ( newFilename ) ) 
} boolean createPartitionedIndex ( CollectionUpdateType forcePartition , Formatter errlog ) throws IOException { 
if ( errlog == null ) errlog = new Formatter ( ) ; 
for ( MCollection dcmp : partitionManager . makePartitions ( forcePartition ) ) { 
dcmp . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , partitionManager . getAuxInfo ( FeatureCollectionConfig . AUX_CONFIG ) ) ; 
result . addPartition ( dcmp ) ; 
result . sortPartitions ( ) ; 
int n = result . getPartitionSize ( ) ; 
int idx = partitionManager . getProtoIndex ( n ) ; 
PartitionCollectionMutable . Partition canon = result . getPartition ( idx ) ; 
try ( GribCollectionMutable gc = canon . makeGribCollection ( ) ) { 
result . copyInfo ( gc ) ; 
result . isPartitionOfPartitions = ( gc instanceof PartitionCollectionMutable ) ; 
result . dateRange = gc . dateRange ; 
GribCollectionMutable . Dataset ds2D = makeDataset2D ( errlog ) ; 
if ( ds2D == null ) { 
if ( ds2D . gctype == GribCollectionImmutable . Type . TwoD ) 
makeDatasetBest ( ds2D , false ) ; 
return writeIndex ( result , errlog ) ; 
} private void makeDatasetBest ( GribCollectionMutable . Dataset ds2D , boolean isComplete ) { 
GribCollectionMutable . Dataset dsBest = result . makeDataset ( isComplete ? GribCollectionImmutable . Type . BestComplete : GribCollectionImmutable . Type . Best ) ; 
int npart = result . getPartitionSize ( ) ; 
for ( GribCollectionMutable . GroupGC group2D : ds2D . groups ) { 
GribCollectionMutable . GroupGC groupB = dsBest . addGroupCopy ( group2D ) ; 
groupB . isTwoD = false ; 
HashMap < Coordinate , CoordinateTimeAbstract > map2DtoBest = new HashMap < > ( ) ; 
CoordinateSharerBest sharer = new CoordinateSharerBest ( ) ; 
for ( Coordinate coord : group2D . coords ) { 
if ( coord instanceof CoordinateRuntime ) continue ; 
CoordinateTimeAbstract best = ( ( CoordinateTime2D ) coord ) . makeBestTimeCoordinate ( result . masterRuntime ) ; 
if ( ! isComplete ) best = best . makeBestFromComplete ( ) ; 
sharer . addCoordinate ( best ) ; 
map2DtoBest . put ( coord , best ) ; 
sharer . addCoordinate ( coord ) ; 
groupB . coords = sharer . finish ( ) ; 
for ( GribCollectionMutable . VariableIndex vi2d : group2D . variList ) { 
PartitionCollectionMutable . VariableIndexPartitioned vip = result . makeVariableIndexPartitioned ( groupB , vi2d , npart ) ; 
vip . finish ( ) ; 
List < Coordinate > newCoords = new ArrayList < > ( ) ; 
for ( Integer groupIndex : vi2d . coordIndex ) { 
Coordinate coord2D = group2D . coords . get ( groupIndex ) ; 
if ( coord2D instanceof CoordinateRuntime ) continue ; 
if ( coord2D instanceof CoordinateTime2D ) { 
newCoords . add ( map2DtoBest . get ( coord2D ) ) ; 
newCoords . add ( coord2D ) ; 
vip . coordIndex = sharer . reindex ( newCoords ) ; 
} protected boolean writeIndex ( PartitionCollectionMutable pc , Formatter f ) throws IOException { 
File idxFile = GribIndexCache . getFileOrCache ( partitionManager . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) ) ; 
if ( ! idxFile . delete ( ) ) 
writer = new GribCollectionWriter ( null , null ) ; 
raf . write ( getMagicStart ( ) . getBytes ( CDM . utf8Charset ) ) ; 
raf . writeInt ( getVersion ( ) ) ; 
indexBuilder . setName ( pc . getName ( ) ) ; 
Path topDir = pc . directory . toPath ( ) ; 
String pathS = StringUtil2 . replace ( topDir . toString ( ) , '\\' , "/" ) ; 
indexBuilder . setTopDir ( pathS ) ; 
for ( PartitionCollectionMutable . Partition part : pc . partitions ) { 
String pathRS = makeReletiveFilename ( pc , part ) ; 
b . setFilename ( pathRS ) ; 
b . setLastModified ( part . getLastModified ( ) ) ; 
b . setLength ( part . fileSize ) ; 
b . setIndex ( count ++ ) ; 
indexBuilder . setCenter ( pc . center ) ; 
indexBuilder . setSubcenter ( pc . subcenter ) ; 
indexBuilder . setMaster ( pc . master ) ; 
indexBuilder . setLocal ( pc . local ) ; 
indexBuilder . setGenProcessId ( pc . genProcessId ) ; 
indexBuilder . setGenProcessType ( pc . genProcessType ) ; 
indexBuilder . setBackProcessId ( pc . backProcessId ) ; 
indexBuilder . setStartTime ( pc . dateRange . getStart ( ) . getMillis ( ) ) ; 
indexBuilder . setEndTime ( pc . dateRange . getEnd ( ) . getMillis ( ) ) ; 
indexBuilder . setMasterRuntime ( writer . writeCoordProto ( pc . masterRuntime ) ) ; 
for ( GribCollectionMutable . Dataset ds : pc . datasets ) 
indexBuilder . addDataset ( writeDatasetProto ( pc , ds ) ) ; 
if ( pc . run2part != null ) { 
for ( int part : pc . run2part ) 
indexBuilder . addRun2Part ( part ) ; 
for ( PartitionCollectionMutable . Partition part : pc . partitions ) 
indexBuilder . addPartitions ( writePartitionProto ( pc , part ) ) ; 
indexBuilder . setIsPartitionOfPartitions ( pc . isPartitionOfPartitions ) ; 
} private GribCollectionProto . Dataset writeDatasetProto ( PartitionCollectionMutable pc , GribCollectionMutable . Dataset ds ) throws IOException { 
GribCollectionProto . Dataset . Builder b = GribCollectionProto . Dataset . newBuilder ( ) ; 
GribCollectionProto . Dataset . Type type = GribCollectionProto . Dataset . Type . valueOf ( ds . gctype . toString ( ) ) ; 
b . setType ( type ) ; 
for ( GribCollectionMutable . GroupGC group : ds . groups ) 
b . addGroups ( writeGroupProto ( pc , group ) ) ; 
} private GribCollectionProto . Group writeGroupProto ( PartitionCollectionMutable pc , GribCollectionMutable . GroupGC g ) throws IOException { 
GribCollectionProto . Group . Builder b = GribCollectionProto . Group . newBuilder ( ) ; 
b . setGds ( GribCollectionWriter . writeGdsProto ( g . horizCoordSys . getRawGds ( ) , g . horizCoordSys . getPredefinedGridDefinition ( ) ) ) ; 
for ( GribCollectionMutable . VariableIndex vb : g . variList ) { 
b . addVariables ( writeVariableProto ( ( PartitionCollectionMutable . VariableIndexPartitioned ) vb ) ) ; 
for ( Coordinate coord : g . coords ) { 
b . addCoords ( writer . writeCoordProto ( ( CoordinateRuntime ) coord ) ) ; 
b . addCoords ( writer . writeCoordProto ( ( CoordinateTime ) coord ) ) ; 
b . addCoords ( writer . writeCoordProto ( ( CoordinateTimeIntv ) coord ) ) ; 
b . addCoords ( writer . writeCoordProto ( ( CoordinateTime2D ) coord ) ) ; 
b . addCoords ( writer . writeCoordProto ( ( CoordinateVert ) coord ) ) ; 
b . addCoords ( writer . writeCoordProto ( ( CoordinateEns ) coord ) ) ; 
if ( g . filenose != null ) 
for ( Integer fileno : g . filenose ) 
b . addFileno ( fileno ) ; 
} private GribCollectionProto . Variable writeVariableProto ( PartitionCollectionMutable . VariableIndexPartitioned vp ) { 
GribCollectionProto . Variable . Builder b = GribCollectionProto . Variable . newBuilder ( ) ; 
b . setDiscipline ( vp . discipline ) ; 
b . setPds ( ByteString . copyFrom ( vp . rawPds ) ) ; 
b . addIds ( vp . center ) ; 
b . addIds ( vp . subcenter ) ; 
b . setRecordsPos ( vp . recordsPos ) ; 
b . setRecordsLen ( vp . recordsLen ) ; 
for ( int idx : vp . coordIndex ) 
b . addCoordIdx ( idx ) ; 
b . setNdups ( vp . ndups ) ; 
b . setNrecords ( vp . nrecords ) ; 
b . setMissing ( vp . nmissing ) ; 
if ( vp . nparts > 0 && vp . partnoSA != null ) { 
for ( int i = 0 ; i < vp . nparts ; i ++ ) 
b . addPartVariable ( writePartitionVariableProto ( vp . partnoSA . get ( i ) , vp . groupnoSA . get ( i ) , vp . varnoSA . get ( i ) , vp . nrecords , vp . ndups , vp . nmissing ) ) ; 
} private GribCollectionProto . PartitionVariable writePartitionVariableProto ( int partno , int groupno , int varno , int nrecords , int ndups , int nmissing ) { 
GribCollectionProto . PartitionVariable . Builder pb = GribCollectionProto . PartitionVariable . newBuilder ( ) ; 
pb . setPartno ( partno ) ; 
pb . setGroupno ( groupno ) ; 
pb . setVarno ( varno ) ; 
pb . setNdups ( ndups ) ; 
pb . setNrecords ( nrecords ) ; 
pb . setMissing ( nmissing ) ; 
return pb . build ( ) ; 
} private GribCollectionProto . Partition writePartitionProto ( PartitionCollectionMutable pc , PartitionCollectionMutable . Partition p ) { 
GribCollectionProto . Partition . Builder b = GribCollectionProto . Partition . newBuilder ( ) ; 
String pathRS = makeReletiveFilename ( pc , p ) ; 
b . setName ( p . name ) ; 
b . setLastModified ( p . lastModified ) ; 
b . setLength ( p . fileSize ) ; 
if ( p . partitionDate != null ) 
b . setPartitionDate ( p . partitionDate . getMillis ( ) ) ; 
} public boolean equalsData ( ucar . nc2 . ft . fmrc . EnsCoord other ) { 
if ( ensembles != other . ensembles ) 
if ( pdn != other . pdn ) 
for ( int i = 0 ; i < ensTypes . length ; i ++ ) { 
if ( ensTypes [ i ] != other . ensTypes [ i ] ) 
} static public EnsCoord findEnsCoord ( List < EnsCoord > ensCoords , EnsCoord want ) { 
if ( want == null ) return null ; 
for ( EnsCoord ec : ensCoords ) { 
if ( want . equalsData ( ec ) ) 
EnsCoord result = new EnsCoord ( want ) ; 
ensCoords . add ( result ) ; 
} static public void normalize ( EnsCoord result , List < EnsCoord > ecList ) { 
List < EnsCoord > extra = new ArrayList < > ( ) ; 
for ( EnsCoord ec : ecList ) { 
if ( ! result . equalsData ( ec ) ) { 
extra . add ( ec ) ; 
if ( extra . size ( ) == 0 ) 
for ( EnsCoord ec : extra ) { 
if ( ec . getNEnsembles ( ) < result . getNEnsembles ( ) ) 
result = ec ; 
} private GribCollectionProto . SparseArray writeSparseArray ( Grib1CollectionBuilder . VariableBag vb , 
Set < Integer > fileSet ) { 
SparseArray < Grib1Record > sa = vb . coordND . getSparseArray ( ) ; 
for ( int size : sa . getShape ( ) ) { 
for ( int track : sa . getTrack ( ) ) { 
for ( Grib1Record gr : sa . getContent ( ) ) { 
Grib1SectionIndicator is = gr . getIs ( ) ; 
br . setStartPos ( is . getStartPos ( ) ) ; 
} private GribCollectionProto . Dataset writeDatasetProto ( GribCollectionImmutable . Type type , 
List < Group > groups ) { 
GribCollectionProto . Dataset . Type ptype = GribCollectionProto . Dataset . Type 
. valueOf ( type . toString ( ) ) ; 
b . setType ( ptype ) ; 
b . addGroups ( writeGroupProto ( group ) ) ; 
} private GribCollectionProto . Group writeGroupProto ( Group g ) { 
b . setGds ( writeGdsProto ( g . gdss . getRawBytes ( ) , g . gdss . getPredefinedGridDefinition ( ) ) ) ; 
for ( Grib1CollectionBuilder . VariableBag vbag : g . gribVars ) { 
b . addVariables ( writeVariableProto ( vbag ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateRuntime ) coord ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateTime ) coord ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateTimeIntv ) coord ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateTime2D ) coord ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateVert ) coord ) ) ; 
b . addCoords ( writeCoordProto ( ( CoordinateEns ) coord ) ) ; 
for ( Integer aFileSet : g . fileSet ) { 
b . addFileno ( aFileSet ) ; 
} private GribCollectionProto . Variable writeVariableProto ( Grib1CollectionBuilder . VariableBag vb ) { 
b . setDiscipline ( 0 ) ; 
b . setPds ( ByteString . copyFrom ( vb . first . getPDSsection ( ) . getRawBytes ( ) ) ) ; 
b . setRecordsPos ( vb . pos ) ; 
b . setRecordsLen ( vb . length ) ; 
for ( int idx : vb . coordIndex ) { 
SparseArray sa = vb . coordND . getSparseArray ( ) ; 
if ( sa != null ) { 
b . setNrecords ( sa . countNotMissing ( ) ) ; 
b . setMissing ( sa . countMissing ( ) ) ; 
} public void setObject ( int index , Object value ) { 
if ( sdata == null ) 
sdata [ index ] = ( StructureData ) value ; 
} public StructureData getStructureData ( int index ) { 
if ( index >= sdata . length ) 
if ( sdata [ index ] == null ) 
sdata [ index ] = makeStructureData ( this , index ) ; 
return sdata [ index ] ; 
} public Array getArray ( int recno , StructureMembers . Member m ) { 
double [ ] da = getJavaArrayDouble ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , da ) ; 
float [ ] fa = getJavaArrayFloat ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , fa ) ; 
byte [ ] ba = getJavaArrayByte ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , ba ) ; 
short [ ] sa = getJavaArrayShort ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , sa ) ; 
int [ ] ia = getJavaArrayInt ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , ia ) ; 
long [ ] la = getJavaArrayLong ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , la ) ; 
char [ ] ca = getJavaArrayChar ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , ca ) ; 
String [ ] str = getJavaArrayString ( recno , m ) ; 
return Array . factory ( dataType , m . getShape ( ) , str ) ; 
return getArrayStructure ( recno , m ) ; 
return getArraySequence ( recno , m ) ; 
case OPAQUE : 
return getArrayObject ( recno , m ) ; 
} public void setMemberArray ( StructureMembers . Member m , Array memberArray ) { 
m . setDataArray ( memberArray ) ; 
if ( memberArray instanceof ArrayStructure ) { 
ArrayStructure as = ( ArrayStructure ) memberArray ; 
m . setStructureMembers ( as . getStructureMembers ( ) ) ; 
} public Array extractMemberArray ( StructureMembers . Member m ) throws IOException { 
if ( m . getDataArray ( ) != null ) 
return m . getDataArray ( ) ; 
int [ ] mshape = m . getShape ( ) ; 
int rrank = rank + mshape . length ; 
int [ ] rshape = new int [ rrank ] ; 
System . arraycopy ( getShape ( ) , 0 , rshape , 0 , rank ) ; 
System . arraycopy ( mshape , 0 , rshape , rank , mshape . length ) ; 
result = new ArrayStructureW ( membersw , rshape ) ; 
result = Array . factory ( DataType . OPAQUE , rshape ) ; 
result = Array . factory ( dataType , rshape ) ; 
IndexIterator resultIter = result . getIndexIterator ( ) ; 
for ( int recno = 0 ; recno < getSize ( ) ; recno ++ ) 
copyDoubles ( recno , m , resultIter ) ; 
copyFloats ( recno , m , resultIter ) ; 
copyBytes ( recno , m , resultIter ) ; 
copyShorts ( recno , m , resultIter ) ; 
copyInts ( recno , m , resultIter ) ; 
copyLongs ( recno , m , resultIter ) ; 
copyChars ( recno , m , resultIter ) ; 
} else if ( ( dataType == DataType . STRING ) || ( dataType == DataType . OPAQUE ) ) { 
copyObjects ( recno , m , resultIter ) ; 
copyStructures ( recno , m , resultIter ) ; 
copySequences ( recno , m , resultIter ) ; 
} protected void copyStructures ( int recnum , StructureMembers . Member m , IndexIterator result ) { 
Array data = getArray ( recnum , m ) ; 
while ( dataIter . hasNext ( ) ) 
result . setObjectNext ( dataIter . getObjectNext ( ) ) ; 
} public Object getScalarObject ( int recno , StructureMembers . Member m ) { 
return getScalarDouble ( recno , m ) ; 
return getScalarFloat ( recno , m ) ; 
return getScalarByte ( recno , m ) ; 
return getScalarShort ( recno , m ) ; 
return getScalarInt ( recno , m ) ; 
return getScalarLong ( recno , m ) ; 
return getScalarString ( recno , m ) ; 
return getScalarStructure ( recno , m ) ; 
ArrayObject data = ( ArrayObject ) m . getDataArray ( ) ; 
return data . getObject ( recno * m . getSize ( ) ) ; 
} public float convertScalarFloat ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) == DataType . FLOAT ) return getScalarFloat ( recnum , m ) ; 
if ( m . getDataType ( ) == DataType . DOUBLE ) return ( float ) getScalarDouble ( recnum , m ) ; 
Object o = getScalarObject ( recnum , m ) ; 
if ( o instanceof Number ) return ( ( Number ) o ) . floatValue ( ) ; 
} public double convertScalarDouble ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) == DataType . DOUBLE ) return getScalarDouble ( recnum , m ) ; 
if ( m . getDataType ( ) == DataType . FLOAT ) return ( double ) getScalarFloat ( recnum , m ) ; 
if ( o instanceof Number ) return ( ( Number ) o ) . doubleValue ( ) ; 
} public int convertScalarInt ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) == DataType . INT || m . getDataType ( ) == DataType . UINT ) return getScalarInt ( recnum , m ) ; 
if ( m . getDataType ( ) == DataType . SHORT ) return ( int ) getScalarShort ( recnum , m ) ; 
if ( m . getDataType ( ) == DataType . USHORT ) return DataType . unsignedShortToInt ( getScalarShort ( recnum , m ) ) ; 
if ( m . getDataType ( ) == DataType . BYTE ) return ( int ) getScalarByte ( recnum , m ) ; 
if ( m . getDataType ( ) == DataType . UBYTE ) return ( int ) DataType . unsignedByteToShort ( getScalarByte ( recnum , m ) ) ; 
if ( m . getDataType ( ) == DataType . LONG || m . getDataType ( ) == DataType . ULONG ) return ( int ) getScalarLong ( recnum , m ) ; 
if ( o instanceof Number ) return ( ( Number ) o ) . intValue ( ) ; 
} public float getScalarFloat ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) != DataType . FLOAT ) 
return data . getFloat ( recnum * m . getSize ( ) ) ; 
} public byte getScalarByte ( int recnum , StructureMembers . Member m ) { 
if ( ! ( m . getDataType ( ) . getPrimitiveClassType ( ) == byte . class ) ) 
return data . getByte ( recnum * m . getSize ( ) ) ; 
} public short getScalarShort ( int recnum , StructureMembers . Member m ) { 
if ( ! ( m . getDataType ( ) . getPrimitiveClassType ( ) == short . class ) ) 
return data . getShort ( recnum * m . getSize ( ) ) ; 
} public char getScalarChar ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) != DataType . CHAR ) 
return data . getChar ( recnum * m . getSize ( ) ) ; 
} public String getScalarString ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) == DataType . CHAR ) { 
ArrayChar data = ( ArrayChar ) m . getDataArray ( ) ; 
return data . getString ( recnum ) ; 
return ( String ) data . getObject ( recnum ) ; 
} public StructureData getScalarStructure ( int recnum , StructureMembers . Member m ) { 
ArrayStructure data = ( ArrayStructure ) m . getDataArray ( ) ; 
return data . getStructureData ( recnum * m . getSize ( ) ) ; 
} public ArrayStructure getArrayStructure ( int recnum , StructureMembers . Member m ) { 
if ( ( m . getDataType ( ) != DataType . STRUCTURE ) && ( m . getDataType ( ) != DataType . SEQUENCE ) ) 
if ( m . getDataType ( ) == DataType . SEQUENCE ) 
return getArraySequence ( recnum , m ) ; 
ArrayStructure array = ( ArrayStructure ) m . getDataArray ( ) ; 
int count = m . getSize ( ) ; 
StructureData [ ] this_sdata = new StructureData [ count ] ; 
this_sdata [ i ] = array . getStructureData ( recnum * count + i ) ; 
StructureMembers membersw = new StructureMembers ( array . getStructureMembers ( ) ) ; 
return new ArrayStructureW ( membersw , m . getShape ( ) , this_sdata ) ; 
} public ArraySequence getArraySequence ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) != DataType . SEQUENCE ) 
ArrayObject array = ( ArrayObject ) m . getDataArray ( ) ; 
return ( ArraySequence ) array . getObject ( recnum ) ; 
} public ArrayObject getArrayObject ( int recnum , StructureMembers . Member m ) { 
if ( m . getDataType ( ) != DataType . OPAQUE ) 
return ( ArrayObject ) array . getObject ( recnum ) ; 
} int setDirect ( int v0 , int v1 , int v2 ) { 
if ( v0 < 0 || v0 >= shape0 ) 
if ( v1 < 0 || v1 >= shape1 ) 
if ( v2 < 0 || v2 >= shape2 ) 
return offset + v0 * stride0 + v1 * stride1 + v2 * stride2 ; 
if ( ProjectionPointImpl . isInfinite ( pt1 ) || ProjectionPointImpl . isInfinite ( pt2 ) ) 
return ( pt1 . getX ( ) * pt2 . getX ( ) < 0 ) && ( Math . abs ( pt1 . getX ( ) - pt2 . getX ( ) ) > 5000.0 ) ; 
attributeConvert ( DapType type , Object value ) 
if ( value == null ) return value ; 
if ( type . isEnumType ( ) ) { 
int ival = Integer . parseInt ( value . toString ( ) ) ; 
return ival ; 
DapEnumConst dec = ( ( DapEnumeration ) type ) . lookup ( value . toString ( ) ) ; 
if ( dec == null ) 
return dec . getValue ( ) ; 
} else if ( value instanceof Long ) { 
return ( Long ) value ; 
} else if ( value instanceof Float ) { 
return ( Float ) value ; 
} else if ( value instanceof Double ) { 
} else if ( value instanceof Character ) { 
return ( ( Character ) value ) ; 
} static public int getJavaSize ( TypeSort atomtype ) 
} static public long forceRange ( TypeSort basetype , long value ) 
switch ( basetype ) { 
value = minmax ( value , 0 , 255 ) ; 
value = minmax ( value , ( long ) Byte . MIN_VALUE , ( long ) Byte . MAX_VALUE ) ; 
value = value & 0xFFL ; 
value = minmax ( value , ( long ) Short . MIN_VALUE , ( long ) Short . MAX_VALUE ) ; 
value = value & 0xFFFFL ; 
value = minmax ( value , ( long ) Integer . MIN_VALUE , ( long ) Integer . MAX_VALUE ) ; 
value = value & 0xFFFFFFFFL ; 
} static protected long 
minmax ( long value , long min , long max ) 
if ( value < min ) return min ; 
if ( value > max ) return max ; 
} public static String extractPath ( HttpServletRequest req , String removePrefix ) { 
String dataPath = req . getPathInfo ( ) ; 
if ( dataPath == null ) { 
dataPath = req . getServletPath ( ) ; 
if ( dataPath == null ) 
if ( removePrefix != null ) { 
if ( dataPath . startsWith ( removePrefix ) ) { 
dataPath = dataPath . substring ( removePrefix . length ( ) ) ; 
} else if ( dataPath . startsWith ( "/" ) ) { 
dataPath = dataPath . substring ( 1 ) ; 
if ( dataPath . startsWith ( removePrefix ) ) 
if ( dataPath . startsWith ( "/" ) ) 
if ( dataPath . contains ( ".." ) ) 
return dataPath ; 
} public static String getFileNameForResponse ( String pathInfo , NetcdfFileWriter . Version version ) { 
return getFileNameForResponse ( pathInfo , version . getSuffix ( ) ) ; 
} public static void printProjArgs ( int Projection , double [ ] projargs ) { 
double NorthBound ; 
double SouthBound ; 
double WestBound ; 
double EastBound ; 
double RowInc ; 
double ColInc ; 
double Lat1 ; 
double Lat2 ; 
double PoleRow ; 
double PoleCol ; 
double CentralLat ; 
double CentralLon ; 
double CentralRow ; 
double CentralCol ; 
double Rotation ; 
double Cone ; 
double Hemisphere ; 
double ConeFactor ; 
double CosCentralLat ; 
double SinCentralLat ; 
double StereoScale ; 
double InvScale ; 
double CylinderScale ; 
switch ( Projection ) { 
case PROJ_GENERIC : 
case PROJ_LINEAR : 
case PROJ_CYLINDRICAL : 
case PROJ_SPHERICAL : 
NorthBound = projargs [ 0 ] ; 
WestBound = projargs [ 1 ] ; 
RowInc = projargs [ 2 ] ; 
ColInc = projargs [ 3 ] ; 
+ ColInc ) ; 
case PROJ_ROTATED : 
CentralLat = projargs [ 4 ] ; 
CentralLon = projargs [ 5 ] ; 
Rotation = projargs [ 6 ] ; 
System . out . println ( "Rotated:" ) ; 
+ Rotation ) ; 
case PROJ_LAMBERT : 
Lat1 = projargs [ 0 ] ; 
Lat2 = projargs [ 1 ] ; 
PoleRow = projargs [ 2 ] ; 
PoleCol = projargs [ 3 ] ; 
CentralLon = projargs [ 4 ] ; 
ColInc = projargs [ 5 ] ; 
case PROJ_STEREO : 
CentralLat = projargs [ 0 ] ; 
CentralLon = projargs [ 1 ] ; 
CentralRow = projargs [ 2 ] ; 
CentralCol = projargs [ 3 ] ; 
ColInc = projargs [ 4 ] ; 
eval ( DapVariable var , DapSequence seq , DataCursor record , CEAST expr ) 
switch ( expr . sort ) { 
case CONSTANT : 
return expr . value ; 
return fieldValue ( var , seq , record , expr . name ) ; 
case EXPR : 
Object lhs = eval ( var , seq , record , expr . lhs ) ; 
Object rhs = ( expr . rhs == null ? null : eval ( var , seq , record , expr . rhs ) ) ; 
if ( rhs != null ) 
return compare ( lhs , rhs ) < 0 ; 
return compare ( lhs , rhs ) <= 0 ; 
return compare ( lhs , rhs ) > 0 ; 
return compare ( lhs , rhs ) >= 0 ; 
case EQ : 
return lhs . equals ( rhs ) ; 
case NEQ : 
return ! lhs . equals ( rhs ) ; 
case REQ : 
return lhs . toString ( ) . matches ( rhs . toString ( ) ) ; 
case AND : 
return ( ( Boolean ) lhs ) && ( ( Boolean ) rhs ) ; 
else switch ( expr . op ) { 
case NOT : 
return ! ( ( Boolean ) lhs ) ; 
Segment seg = segments . get ( i ) ; 
if ( ! seg . var . isTopLevel ( ) ) 
if ( ! first ) buf . append ( ";" ) ; 
dumpvar ( seg , buf , true ) ; 
dumpvar ( Segment seg , StringBuilder buf , boolean forconstraint ) 
if ( seg . var . isTopLevel ( ) ) 
buf . append ( seg . var . getFQN ( ) ) ; 
buf . append ( seg . var . getShortName ( ) ) ; 
List < DapDimension > dimset = seg . var . getDimensions ( ) ; 
List < Slice > slices = seg . slices ; 
dimset = new ArrayList < DapDimension > ( ) ; 
assert ( dimset . size ( ) == 0 && DapUtil . isScalarSlices ( slices ) ) 
|| ( dimset . size ( ) == slices . size ( ) ) ; 
buf . append ( forconstraint ? slice . toConstraintString ( ) : slice . toString ( ) ) ; 
DapType basetype = seg . var . getBaseType ( ) ; 
if ( basetype . isAtomic ( ) ) 
if ( basetype . getTypeSort ( ) . isCompound ( ) ) { 
DapStructure struct = ( DapStructure ) basetype ; 
if ( ! isWholeCompound ( struct ) ) { 
buf . append ( LBRACE ) ; 
Segment fseg = findSegment ( field ) ; 
dumpvar ( fseg , buf , forconstraint ) ; 
buf . append ( RBRACE ) ; 
if ( basetype . getTypeSort ( ) . isSeqType ( ) && seg . filter != null ) { 
buf . append ( "|" ) ; 
buf . append ( seg . filter . toString ( ) ) ; 
references ( DapNode node ) 
boolean isref = false ; 
DapDimension dim = this . redef . get ( ( DapDimension ) node ) ; 
if ( dim == null ) dim = ( DapDimension ) node ; 
isref = this . dimrefs . contains ( dim ) ; 
isref = ( this . enums . contains ( ( DapEnumeration ) node ) ) ; 
isref = ( findVariableIndex ( ( DapVariable ) node ) >= 0 ) ; 
isref = ( this . groups . contains ( ( DapGroup ) node ) ) ; 
return isref ; 
} public boolean match ( DapVariable sqvar , DapSequence seq , DataCursor rec ) 
Segment sseq = findSegment ( sqvar ) ; 
if ( sseq == null ) 
CEAST filter = sseq . filter ; 
if ( filter == null ) 
return matches ( sqvar , seq , rec , filter ) ; 
} protected boolean 
matches ( DapVariable var , DapSequence seq , DataCursor rec , CEAST filter ) 
Object value = eval ( var , seq , rec , filter ) ; 
return ( ( Boolean ) value ) ; 
} protected int findVariableIndex ( DapVariable var ) 
if ( variables . get ( i ) == var ) 
expand ( ) 
Queue < DapVariable > queue = new ArrayDeque < DapVariable > ( ) ; 
DapVariable var = variables . get ( i ) ; 
if ( ! var . isTopLevel ( ) ) 
DapType base = var . getBaseType ( ) ; 
if ( base . getTypeSort ( ) . isCompound ( ) ) { 
DapStructure struct = ( DapStructure ) base ; 
if ( expansionCount ( struct ) == 0 ) 
queue . add ( var ) ; 
while ( queue . size ( ) > 0 ) { 
DapVariable vvstruct = queue . remove ( ) ; 
DapStructure dstruct = ( DapStructure ) vvstruct . getBaseType ( ) ; 
for ( DapVariable field : dstruct . getFields ( ) ) { 
if ( findVariableIndex ( field ) < 0 ) { 
this . segments . add ( new Segment ( field ) ) ; 
this . variables . add ( field ) ; 
DapType fbase = field . getBaseType ( ) ; 
if ( fbase . getTypeSort ( ) . isCompound ( ) ) { 
if ( expansionCount ( ( DapStructure ) fbase ) == 0 ) 
queue . add ( field ) ; 
this . expansion = Expand . EXPANDED ; 
contract ( ) 
Set < DapStructure > contracted = new HashSet < > ( ) ; 
if ( var . isTopLevel ( ) ) { 
contractR ( ( DapStructure ) base , contracted ) ; 
this . expansion = Expand . CONTRACTED ; 
contractR ( DapStructure dstruct , Set < DapStructure > contracted ) 
if ( contracted . contains ( dstruct ) ) 
int processed = 0 ; 
List < DapVariable > fields = dstruct . getFields ( ) ; 
if ( findVariableIndex ( field ) < 0 ) 
DapType base = field . getBaseType ( ) ; 
if ( base . getTypeSort ( ) . isCompound ( ) 
&& ! contracted . contains ( ( field ) ) ) { 
if ( ! contractR ( ( DapStructure ) base , contracted ) ) 
processed ++ ; 
if ( processed < fields . size ( ) ) 
contracted . add ( dstruct ) ; 
expansionCount ( DapStructure struct ) 
if ( findVariableIndex ( field ) >= 0 ) count ++ ; 
isWholeCompound ( DapStructure dstruct ) 
Segment seg = findSegment ( field ) ; 
if ( seg == null ) 
if ( slices != null ) { 
for ( Slice slice : slices ) { 
if ( slice . isConstrained ( ) ) 
if ( ! isWholeCompound ( ( DapStructure ) base ) ) 
return ( processed == fields . size ( ) ) ; 
computedimensions ( ) 
for ( DapDimension key : redefslice . keySet ( ) ) { 
Slice slice = redefslice . get ( key ) ; 
DapDimension newdim = ( DapDimension ) key . clone ( ) ; 
newdim . setSize ( slice . getCount ( ) ) ; 
redef . put ( key , newdim ) ; 
if ( seg . var . getRank ( ) == 0 ) 
List < DapDimension > orig = seg . var . getDimensions ( ) ; 
List < DapDimension > newdims = new ArrayList < > ( ) ; 
slices = new ArrayList < Slice > ( ) ; 
while ( slices . size ( ) < orig . size ( ) ) 
slices . add ( new Slice ( ) . setConstrained ( false ) ) ; 
assert ( slices != null && slices . size ( ) == orig . size ( ) ) ; 
for ( int j = 0 ; j < slices . size ( ) ; j ++ ) { 
Slice slice = slices . get ( j ) ; 
DapDimension dim0 = orig . get ( j ) ; 
DapDimension newdim = redef . get ( dim0 ) ; 
if ( newdim == null ) 
newdim = dim0 ; 
slice . setMaxSize ( newdim . getSize ( ) ) ; 
Slice newslice = null ; 
if ( slice . isConstrained ( ) ) { 
newdim = new DapDimension ( slice . getCount ( ) ) ; 
newslice = new Slice ( newdim ) ; 
if ( newslice != null ) { 
if ( ! dimrefs . contains ( dim0 ) ) dimrefs . add ( dim0 ) ; 
slices . set ( j , newslice ) ; 
newdims . add ( newdim ) ; 
seg . setDimset ( newdims ) ; 
} protected void computeenums ( ) 
if ( var . getSort ( ) != DapSort . VARIABLE ) 
DapType daptype = var . getBaseType ( ) ; 
if ( ! daptype . isEnumType ( ) ) 
if ( ! this . enums . contains ( ( DapEnumeration ) daptype ) ) 
this . enums . add ( ( DapEnumeration ) daptype ) ; 
} protected void computegroups ( ) 
List < DapGroup > path = var . getGroupPath ( ) ; 
for ( DapGroup group : path ) { 
if ( ! this . groups . contains ( group ) ) 
this . groups . add ( group ) ; 
for ( DapDimension dim : this . dimrefs ) { 
if ( ! dim . isShared ( ) ) 
List < DapGroup > path = dim . getGroupPath ( ) ; 
for ( DapEnumeration en : this . enums ) { 
List < DapGroup > path = en . getGroupPath ( ) ; 
} static public CEConstraint 
compile ( String sce , DapDataset dmr ) 
if ( sce == null || sce . length ( ) == 0 ) 
return CEConstraint . getUniversal ( dmr ) ; 
CEParserImpl ceparser = new CEParserImpl ( dmr ) ; 
ceparser . setDebugLevel ( 1 ) ; 
boolean ok ; 
ok = ceparser . parse ( sce ) ; 
CEAST root = ceparser . getCEAST ( ) ; 
CECompiler compiler = new CECompiler ( ) ; 
CEConstraint ce = compiler . compile ( dmr , root ) ; 
ce . expand ( ) ; 
ce . finish ( ) ; 
} public final void printDecl ( PrintWriter os , String space , 
PrimitiveVector v = ( PrimitiveVector ) super . cloneDAG ( map ) ; 
v . var = ( BaseType ) cloneDAG ( map , var ) ; 
axiso = timeAxis2D . subset ( params ) ; 
double val = runAxisSubset . getCoord ( 0 ) ; 
Optional < TimeOffsetAxis > too = timeAxis2D . subsetFromTime ( params , runDate ) ; 
double start = timeAxis . getStartValue ( ) ; 
double end = timeAxis . getEndValue ( ) ; 
double runOffset = runAxisSubset . getCoord ( i ) ; 
runValues [ count ++ ] = runAxisSubset . getCoord ( runtimeIdx . get ( k ) ) ; 
if ( raf instanceof HTTPRandomAccessFile ) { 
if ( raf . length ( ) > raf . getBufferSize ( ) ) 
GribCdmIndex . GribCollectionType type = GribCdmIndex . getType ( raf ) ; 
if ( type == GribCdmIndex . GribCollectionType . GRIB2 ) return true ; 
if ( type == GribCdmIndex . GribCollectionType . Partition2 ) return true ; 
return Grib2RecordScanner . isValidFile ( raf ) ; 
store . putBeanObject ( VIEWER_SIZE , getSize ( ) ) ; 
store . putBeanObject ( SOURCE_WINDOW_SIZE , ( Rectangle ) sourceWindow . getBounds ( ) ) ; 
if ( fileChooser != null ) fileChooser . save ( ) ; 
if ( datasetChooser != null ) datasetChooser . save ( ) ; 
if ( sourcePane != null ) sourcePane . save ( ) ; 
} private void makeActionsSystem ( ) { 
BAMutil . setActionProperties ( printAction , "Print" , "Print..." , false , 'P' , KeyEvent . VK_P ) ; 
sysConfigAction = new AbstractAction ( ) { 
if ( sysConfigDialog == null ) 
makeSysConfigWindow ( ) ; 
sysConfigDialog . show ( ) ; 
BAMutil . setActionProperties ( sysConfigAction , "Preferences" , "Configure..." , false , 'C' , - 1 ) ; 
clearDebugFlagsAction = new AbstractAction ( ) { 
public void actionPerformed ( ActionEvent e ) { Debug . clear ( ) ; } 
clearRecentAction = new AbstractAction ( ) { 
recentDatasetList = new ArrayList ( ) ; 
* / 
AbstractAction clearDebugFlagsAction = new AbstractAction ( ) { 
public void actionPerformed ( ActionEvent e ) { } 
} boolean init ( ) { 
System . setProperty ( "tds.log.dir" , contentTdmDir . toString ( ) ) ; 
if ( ! Files . exists ( threddsConfig ) ) { 
ThreddsConfigReader reader = new ThreddsConfigReader ( threddsConfig . toString ( ) , log ) ; 
for ( String location : reader . getRootList ( "catalogRoot" ) ) { 
Resource r = new FileSystemResource ( contentThreddsDir . toString ( ) + "/" + location ) ; 
catalogRoots . add ( r ) ; 
String gribIndexDir = reader . get ( "GribIndex.dir" , new File ( contentThreddsDir . toString ( ) , "cache/grib/" ) . getPath ( ) ) ; 
Boolean gribIndexAlwaysUse = reader . getBoolean ( "GribIndex.alwaysUse" , false ) ; 
Boolean gribIndexNeverUse = reader . getBoolean ( "GribIndex.neverUse" , false ) ; 
String gribIndexPolicy = reader . get ( "GribIndex.policy" , null ) ; 
DiskCache2 gribCache = gribIndexNeverUse ? DiskCache2 . getNoop ( ) : new DiskCache2 ( gribIndexDir , false , - 1 , - 1 ) ; 
gribCache . setPolicy ( gribIndexPolicy ) ; 
gribCache . setAlwaysUseCache ( gribIndexAlwaysUse ) ; 
gribCache . setNeverUseCache ( gribIndexNeverUse ) ; 
GribIndexCache . setDiskCache2 ( gribCache ) ; 
} public static GempakFileReader getInstance ( RandomAccessFile raf , boolean fullCheck ) throws IOException { 
GempakFileReader gfr = new GempakFileReader ( ) ; 
gfr . init ( raf , fullCheck ) ; 
return gfr ; 
} public boolean init ( RandomAccessFile raf , boolean fullCheck ) throws IOException { 
setByteOrder ( ) ; 
dmLabel = new DMLabel ( ) ; 
boolean labelOk = dmLabel . init ( ) ; 
if ( ! labelOk ) { 
readKeys ( ) ; 
if ( keys == null ) { 
readHeaders ( ) ; 
if ( headers == null ) { 
readParts ( ) ; 
if ( parts == null ) { 
readFileHeaderInfo ( ) ; 
if ( fileHeaderInfo == null ) { 
} public int getByteOrder ( int kmachn ) { 
if ( ( kmachn == MTVAX ) || ( kmachn == MTULTX ) || ( kmachn == MTALPH ) 
|| ( kmachn == MTLNUX ) || ( kmachn == MTIGPH ) ) { 
return RandomAccessFile . LITTLE_ENDIAN ; 
return RandomAccessFile . BIG_ENDIAN ; 
} void setByteOrder ( ) { 
MTMACH = RandomAccessFile . LITTLE_ENDIAN ; 
MTMACH = RandomAccessFile . BIG_ENDIAN ; 
} protected void readFileHeaderInfo ( ) throws IOException { 
if ( dmLabel == null ) { 
int iread = dmLabel . kpfile ; 
int numheaders = dmLabel . kfhdrs ; 
String [ ] names = new String [ numheaders ] ; 
int [ ] lens = new int [ numheaders ] ; 
int [ ] types = new int [ numheaders ] ; 
for ( int i = 0 ; i < numheaders ; i ++ ) { 
names [ i ] = DM_RSTR ( iread ++ ) ; 
lens [ i ] = DM_RINT ( iread ++ ) ; 
types [ i ] = DM_RINT ( iread ++ ) ; 
fileHeaderInfo = new ArrayList < > ( ) ; 
DMFileHeaderInfo ghi = new DMFileHeaderInfo ( ) ; 
ghi . kfhnam = names [ i ] ; 
ghi . kfhlen = lens [ i ] ; 
ghi . kfhtyp = types [ i ] ; 
fileHeaderInfo . add ( ghi ) ; 
} protected void readKeys ( ) throws IOException { 
keys = new DMKeys ( ) ; 
int num = dmLabel . krkeys ; 
List < Key > rkeys = new ArrayList < > ( num ) ; 
String key = DM_RSTR ( dmLabel . kprkey + i ) ; 
rkeys . add ( new Key ( key , i , ROW ) ) ; 
keys . kkrow = rkeys ; 
num = dmLabel . kckeys ; 
List < Key > ckeys = new ArrayList < > ( num ) ; 
String key = DM_RSTR ( dmLabel . kpckey + i ) ; 
ckeys . add ( new Key ( key , i , COL ) ) ; 
keys . kkcol = ckeys ; 
} protected void readHeaders ( ) throws IOException { 
headers = new DMHeaders ( ) ; 
List < int [ ] > rowHeaders = new ArrayList < > ( dmLabel . krow ) ; 
int istart = dmLabel . kprowh ; 
int [ ] header ; 
for ( int i = 0 ; i < dmLabel . krow ; i ++ ) { 
header = new int [ dmLabel . krkeys + 1 ] ; 
DM_RINT ( istart , header ) ; 
headers . lstrw = i ; 
rowHeaders . add ( header ) ; 
istart += header . length ; 
headers . rowHeaders = rowHeaders ; 
List < int [ ] > colHeaders = new ArrayList < > ( dmLabel . kcol ) ; 
istart = dmLabel . kpcolh ; 
for ( int i = 0 ; i < dmLabel . kcol ; i ++ ) { 
header = new int [ dmLabel . kckeys + 1 ] ; 
headers . lstcl = i ; 
colHeaders . add ( header ) ; 
headers . colHeaders = colHeaders ; 
int [ ] keyLoc = new int [ swapKeys . length ] ; 
String [ ] keyType = new String [ swapKeys . length ] ; 
boolean haveRow = false ; 
boolean haveCol = false ; 
for ( int i = 0 ; i < swapKeys . length ; i ++ ) { 
Key key = findKey ( swapKeys [ i ] ) ; 
keyLoc [ i ] = ( key != null ) 
? key . loc + 1 
keyType [ i ] = ( key != null ) 
? key . type 
: "" ; 
if ( keyType [ i ] . equals ( ROW ) ) { 
haveRow = true ; 
if ( keyType [ i ] . equals ( COL ) ) { 
haveCol = true ; 
if ( haveRow ) { 
for ( int [ ] toCheck : headers . rowHeaders ) { 
for ( int j = 0 ; j < swapKeys . length ; j ++ ) { 
if ( keyType [ j ] . equals ( ROW ) ) { 
if ( swapKeys [ j ] . equals ( "GVCD" ) 
&& ! ( toCheck [ keyLoc [ j ] ] 
> GempakUtil . vertCoords . length ) ) { 
GempakUtil . swp4 ( toCheck , keyLoc [ j ] , swapNum [ j ] ) ; 
if ( haveCol ) { 
for ( int [ ] toCheck : headers . colHeaders ) { 
if ( keyType [ j ] . equals ( COL ) ) { 
} protected void readParts ( ) throws IOException { 
int iread = dmLabel . kppart ; 
int numParts = dmLabel . kprt ; 
DMPart [ ] partArray = new DMPart [ numParts ] ; 
for ( int i = 0 ; i < numParts ; i ++ ) { 
partArray [ i ] = new DMPart ( ) ; 
partArray [ i ] . kprtnm = DM_RSTR ( iread ++ ) ; 
partArray [ i ] . klnhdr = DM_RINT ( iread ++ ) ; 
partArray [ i ] . ktyprt = DM_RINT ( iread ++ ) ; 
partArray [ i ] . kparms = DM_RINT ( iread ++ ) ; 
int numParms = partArray [ i ] . kparms ; 
List < DMParam > parms = new ArrayList < > ( numParms ) ; 
for ( int j = 0 ; j < numParms ; j ++ ) { 
DMParam dmp = new DMParam ( ) ; 
parms . add ( dmp ) ; 
dmp . kprmnm = DM_RSTR ( iread ++ ) ; 
partArray [ i ] . params = parms ; 
List parms = partArray [ i ] . params ; 
DMParam dmp = ( DMParam ) parms . get ( j ) ; 
dmp . kscale = DM_RINT ( iread ++ ) ; 
dmp . koffst = DM_RINT ( iread ++ ) ; 
dmp . kbits = DM_RINT ( iread ++ ) ; 
parts = new ArrayList < > ( numParts ) ; 
parts . addAll ( Arrays . asList ( partArray ) . subList ( 0 , numParts ) ) ; 
for ( DMPart part : parts ) { 
if ( part . ktyprt == MDRPCK ) { 
part . packInfo = new PackingInfo ( part ) ; 
GempakFileReader gfr = getInstance ( getFile ( args [ 0 ] ) , true ) ; 
gfr . printFileLabel ( ) ; 
gfr . printKeys ( ) ; 
gfr . printHeaders ( ) ; 
gfr . printParts ( ) ; 
} public Key findKey ( String name ) { 
for ( Key key : keys . kkrow ) { 
if ( key . name . equals ( name ) ) { 
for ( Key key : keys . kkcol ) { 
} public DMFileHeaderInfo findFileHeader ( String name ) { 
if ( ( fileHeaderInfo == null ) || fileHeaderInfo . isEmpty ( ) ) { 
for ( DMFileHeaderInfo fhi : fileHeaderInfo ) { 
if ( name . equals ( fhi . kfhnam ) ) { 
return fhi ; 
} public float [ ] getFileHeader ( String name ) throws IOException { 
DMFileHeaderInfo fh = findFileHeader ( name ) ; 
if ( ( fh == null ) || ( fh . kfhtyp != MDREAL ) ) { 
int knt = fileHeaderInfo . indexOf ( fh ) ; 
int iread = dmLabel . kpfile + 3 * dmLabel . kfhdrs ; 
for ( int i = 0 ; i < knt ; i ++ ) { 
DMFileHeaderInfo fhi = fileHeaderInfo . get ( i ) ; 
iread = iread + fhi . kfhlen + 1 ; 
int nword = DM_RINT ( iread ) ; 
if ( nword <= 0 ) { 
iread ++ ; 
float [ ] rheader = new float [ nword ] ; 
if ( name . equals ( "NAVB" ) && needToSwap ) { 
DM_RFLT ( iread , 1 , rheader , 0 ) ; 
needToSwap = false ; 
DM_RFLT ( iread , 1 , rheader , 1 ) ; 
DM_RFLT ( iread , nword - 2 , rheader , 2 ) ; 
DM_RFLT ( iread , rheader ) ; 
return rheader ; 
} public void printParts ( ) { 
for ( int i = 0 ; i < parts . size ( ) ; i ++ ) { 
System . out . println ( "\nParts[" + i + "]:" ) ; 
System . out . println ( parts . get ( i ) ) ; 
} public int getPartNumber ( String name ) { 
int part = 0 ; 
if ( ( parts != null ) && ! parts . isEmpty ( ) ) { 
String partName = parts . get ( i ) . kprtnm ; 
if ( partName . equals ( name ) ) { 
part = i + 1 ; 
return part ; 
} public DMPart getPart ( String name ) { 
String partName = part . kprtnm ; 
} public int getDataPointer ( int irow , int icol , String partName ) { 
int ipoint = - 1 ; 
if ( ( irow < 1 ) || ( irow > dmLabel . krow ) || ( icol < 1 ) 
|| ( icol > dmLabel . kcol ) ) { 
+ icol ) ; 
return ipoint ; 
int iprt = getPartNumber ( partName ) ; 
if ( ( part . ktyprt != MDREAL ) && ( part . ktyprt != MDGRID ) 
&& ( part . ktyprt != MDRPCK ) ) { 
ipoint = dmLabel . kpdata + ( irow - 1 ) * dmLabel . kcol * dmLabel . kprt 
+ ( icol - 1 ) * dmLabel . kprt + ( iprt - 1 ) ; 
} public int DM_RINT ( int word ) throws IOException { 
rf . seek ( getOffset ( word ) ) ; 
if ( IMISSD != dmLabel . kmissd ) { 
if ( idata == dmLabel . kmissd ) { 
idata = IMISSD ; 
} public void DM_RINT ( int word , int num , int [ ] iarray , int start ) 
if ( start + i > iarray . length ) { 
iarray [ start + i ] = DM_RINT ( word + i ) ; 
} public float DM_RFLT ( int word ) throws IOException { 
float rdata = rf . readFloat ( ) ; 
if ( RMISSD != dmLabel . smissd ) { 
if ( Math . abs ( rdata - dmLabel . smissd ) < RDIFFD ) { 
rdata = RMISSD ; 
return rdata ; 
} public void DM_RFLT ( int word , int num , float [ ] rarray , int start ) 
if ( start + i > rarray . length ) { 
rarray [ start + i ] = DM_RFLT ( word + i ) ; 
} public String DM_RSTR ( int isword , int nchar ) throws IOException { 
rf . seek ( getOffset ( isword ) ) ; 
return rf . readString ( nchar ) ; 
} public RData DM_RDTR ( int irow , int icol , String partName ) 
return DM_RDTR ( irow , icol , partName , 1 ) ; 
} public RData DM_RDTR ( int irow , int icol , String partName , 
int decimalScale ) 
float [ ] rdata ; 
int [ ] header = null ; 
header = new int [ ilenhd ] ; 
int nword = length - ilenhd ; 
isword += header . length ; 
if ( part . ktyprt == MDREAL ) { 
rdata = new float [ nword ] ; 
DM_RFLT ( isword , rdata ) ; 
} else if ( part . ktyprt == MDGRID ) { 
rdata = DM_RPKG ( isword , nword , decimalScale ) ; 
int [ ] idata = new int [ nword ] ; 
DM_RINT ( isword , idata ) ; 
rdata = DM_UNPK ( part , idata ) ; 
} catch ( EOFException eof ) { 
rdata = null ; 
RData rd = null ; 
if ( rdata != null ) { 
rd = new RData ( header , rdata ) ; 
return rd ; 
} public float [ ] DM_UNPK ( DMPart part , int [ ] ibitst ) { 
int nparms = part . kparms ; 
int nwordp = part . kwordp ; 
int npack = ( ibitst . length - 1 ) / nwordp + 1 ; 
if ( npack * nwordp != ibitst . length ) { 
float [ ] data = new float [ nparms * npack ] ; 
PackingInfo pkinf = part . packInfo ; 
int ir = 0 ; 
for ( int pack = 0 ; pack < npack ; pack ++ ) { 
int [ ] jdata = new int [ nwordp ] ; 
System . arraycopy ( ibitst , ii , jdata , 0 , nwordp ) ; 
for ( int idata = 0 ; idata < nparms ; idata ++ ) { 
int jbit = pkinf . nbitsc [ idata ] ; 
int jsbit = pkinf . isbitc [ idata ] ; 
int jshift = 1 - jsbit ; 
int jsword = pkinf . iswrdc [ idata ] ; 
int jword = jdata [ jsword ] ; 
int mask = mskpat > > > ( 32 - jbit ) ; 
int ifield = jword > > > Math . abs ( jshift ) ; 
ifield = ifield & mask ; 
if ( ( jsbit + jbit - 1 ) > 32 ) { 
jword = jdata [ jsword + 1 ] ; 
jshift = jshift + 32 ; 
int iword = jword << jshift ; 
iword = iword & mask ; 
ifield = ifield | iword ; 
if ( ifield == pkinf . imissc [ idata ] ) { 
data [ ir + idata ] = RMISSD ; 
data [ ir + idata ] = ( ifield + pkinf . koffst [ idata ] ) 
* ( float ) pkinf . scalec [ idata ] ; 
ir += nparms ; 
ii += nwordp ; 
} protected static String getBits ( int b ) { 
Formatter s = new Formatter ( ) ; 
for ( int i = 31 ; i >= 0 ; i -- ) { 
if ( ( b & ( 1 << i ) ) != 0 ) { 
s . format ( "1" ) ; 
s . format ( "0" ) ; 
if ( i % 8 == 0 ) { 
s . format ( "|" ) ; 
return s . toString ( ) ; 
} public void writeDataAll ( WritableByteChannel channel ) throws IOException , InvalidRangeException { 
int nbytes = ( int ) v . readToByteChannel ( v . getShapeAsSection ( ) , channel ) ; 
filePos += pad ( channel , nbytes ) ; 
Section section = new Section ( ) . appendRange ( null ) ; 
long bytesDone = 0 ; 
long done = 0 ; 
long nrecs = ( int ) recordVar . getSize ( ) ; 
int structureSize = recordVar . getElementSize ( ) ; 
int readAtaTime = Math . max ( 10 , buffer_size / structureSize ) ; 
for ( int count = 0 ; count < nrecs ; count += readAtaTime ) { 
long last = Math . min ( nrecs , done + readAtaTime ) ; 
int need = ( int ) ( last - done ) ; 
section . setRange ( 0 , new Range ( count , count + need - 1 ) ) ; 
bytesDone += recordVar . readToByteChannel ( section , channel ) ; 
done += need ; 
assert done == nrecs ; 
bytesDone /= 1000 * 1000 ; 
} public static void writeFromFile ( NetcdfFile fileIn , String fileOutName ) throws IOException , InvalidRangeException { 
try ( FileOutputStream stream = new FileOutputStream ( fileOutName ) ) { 
WritableByteChannel channel = stream . getChannel ( ) ; 
DataOutputStream dout = new DataOutputStream ( Channels . newOutputStream ( channel ) ) ; 
N3channelWriter writer = new N3channelWriter ( fileIn ) ; 
int numrec = fileIn . getUnlimitedDimension ( ) == null ? 0 : fileIn . getUnlimitedDimension ( ) . getLength ( ) ; 
writer . writeHeader ( dout , numrec ) ; 
dout . flush ( ) ; 
writer . writeDataAll ( channel ) ; 
} public static void writeToChannel ( NetcdfFile ncfile , WritableByteChannel wbc ) throws IOException , InvalidRangeException { 
DataOutputStream stream = new DataOutputStream ( new BufferedOutputStream ( Channels . newOutputStream ( wbc ) , 8000 ) ) ; 
N3channelWriter writer = new N3channelWriter ( ncfile ) ; 
int numrec = ncfile . getUnlimitedDimension ( ) == null ? 0 : ncfile . getUnlimitedDimension ( ) . getLength ( ) ; 
writer . writeHeader ( stream , numrec ) ; 
writer . writeDataAll ( wbc ) ; 
} public void parse ( Document ddx , DDS targetDDS , BaseTypeFactory fac , boolean validation ) throws DAP2Exception { 
dds = targetDDS ; 
factory = fac ; 
Element root = ddx . getRootElement ( ) ; 
lastDoc = ddx ; 
parseLevel = 0 ; 
String type = root . getName ( ) ; 
if ( ! ( type . equals ( "Dataset" ) ) ) { 
String name = root . getAttribute ( "name" ) . getValue ( ) ; 
dds . setClearName ( name ) ; 
parentDC = dds ; 
currentBT = dds ; 
Iterator ci = root . getChildren ( ) . iterator ( ) ; 
while ( ci . hasNext ( ) ) { 
Element child = ( Element ) ci . next ( ) ; 
} public void parse ( InputStream is , DDS targetDDS , BaseTypeFactory fac , boolean validation ) throws DAP2Exception { 
SAXBuilder parser = new SAXBuilder ( ) ; 
parser . setFeature ( "http://apache.org/xml/features/validation/schema" , validation ) ; 
Document doc = parser . build ( is ) ; 
parse ( doc , targetDDS , fac , validation ) ; 
} catch ( JDOMException jde ) { 
throw new DAP2Exception ( jde ) ; 
throw new DAP2Exception ( ioe ) ; 
} private void parseBase ( Element e , String indent ) 
throws DASException , NoSuchTypeException , BadSemanticsException { 
parseLevel ++ ; 
String type = e . getName ( ) ; 
if ( type . equals ( "Attribute" ) ) { 
} else if ( type . equals ( "Alias" ) ) { 
} else if ( type . equals ( "dataBLOB" ) ) { 
org . jdom2 . Attribute hrefAttr = e . getAttribute ( "href" ) ; 
String contentID = hrefAttr . getValue ( ) ; 
dds . setBlobContentID ( contentID ) ; 
if ( _Debug ) showXMLElement ( e , indent ) ; 
BaseType bt = newBaseType ( e ) ; 
parentDC . addVariable ( bt ) ; 
DConstructor myParentDC = parentDC ; 
parentDC = ( DConstructor ) bt ; 
parseGrid ( e , indent ) ; 
for ( Element child : e . getChildren ( ) ) { 
parentDC = myParentDC ; 
parseArray ( e , ( DArray ) bt , indent ) ; 
parseLevel -- ; 
} private void parseArray ( Element ArrayElement , DArray da , String indent ) 
int countTemplateVars = 0 ; 
int numDims = 0 ; 
for ( Element e : ArrayElement . getChildren ( ) ) { 
if ( e . getName ( ) . equals ( "Attribute" ) ) { 
else if ( e . getName ( ) . equals ( "Alias" ) ) { 
else if ( e . getName ( ) . equals ( "dimension" ) ) { 
numDims ++ ; 
Attribute nameAttr = e . getAttribute ( "name" ) ; 
if ( nameAttr != null ) 
name = nameAttr . getValue ( ) ; 
int size = Integer . parseInt ( e . getAttribute ( "size" ) . getValue ( ) ) ; 
da . appendDim ( size , ( name ) ) ; 
countTemplateVars ++ ; 
BaseType template = buildArrayTemplate ( e , indent ) ; 
template . setClearName ( da . getClearName ( ) ) ; 
da . addVariable ( template ) ; 
da . printDecl ( System . out , indent ) ; 
if ( countTemplateVars != 1 ) { 
} private BaseType buildArrayTemplate ( Element template , String indent ) 
if ( _Debug ) showXMLElement ( template , indent + "...:" ) ; 
Iterator attrElements = template . getChildren ( "Attribute" , opendapNameSpace ) . iterator ( ) ; 
if ( attrElements . hasNext ( ) ) 
bt = newBaseType ( template ) ; 
parseGrid ( template , indent ) ; 
for ( Element child : template . getChildren ( ) ) { 
} private void parseGrid ( Element gridElement , String indent ) 
DGrid myGrid = ( DGrid ) parentDC ; 
for ( Element element : gridElement . getChildren ( ) ) System . out . println ( element ) ; 
String eName = "Array" ; 
Element arrayElement = gridElement . getChild ( eName , opendapNameSpace ) ; 
DArray gridArray = ( DArray ) newBaseType ( arrayElement ) ; 
myGrid . addVariable ( gridArray , DGrid . ARRAY ) ; 
eName = "Map" ; 
List < Element > mapElements = gridElement . getChildren ( "Map" , opendapNameSpace ) ; 
if ( mapElements . size ( ) != gridArray . numDimensions ( ) ) 
for ( Element mapElement : mapElements ) { 
DArray thisMap = ( DArray ) newBaseType ( mapElement ) ; 
if ( thisMap . numDimensions ( ) != 1 ) 
myGrid . addVariable ( thisMap , DGrid . MAPS ) ; 
} private void showXMLElement ( Element e , String indent ) { 
String text = e . getTextNormalize ( ) ; 
if ( ! text . equals ( "" ) ) 
for ( Attribute att : e . getAttributes ( ) ) { 
for ( Element kid : e . getChildren ( ) ) { 
} private BaseType newBaseType ( Element e ) throws DASException , NoSuchTypeException { 
org . jdom2 . Attribute nameAttr = e . getAttribute ( "name" ) ; 
currentBT = newBaseTypeFactory ( type , name ) ; 
return ( currentBT ) ; 
} private BaseType newBaseTypeFactory ( String typeString , String name ) throws NoSuchTypeException { 
if ( typeString . equals ( "Array" ) || typeString . equals ( "Map" ) ) { 
bt = factory . newDArray ( ) ; 
bt . setClearName ( name ) ; 
} else if ( typeString . equals ( "Grid" ) ) { 
bt = factory . newDGrid ( ) ; 
} else if ( typeString . equals ( "Structure" ) ) { 
bt = factory . newDStructure ( ) ; 
} else if ( typeString . equals ( "Sequence" ) ) { 
bt = factory . newDSequence ( ) ; 
} else if ( typeString . equals ( "Int16" ) ) { 
bt = factory . newDInt16 ( ) ; 
} else if ( typeString . equals ( "UInt16" ) ) { 
bt = factory . newDUInt16 ( ) ; 
} else if ( typeString . equals ( "Int32" ) ) { 
bt = factory . newDInt32 ( ) ; 
} else if ( typeString . equals ( "UInt32" ) ) { 
bt = factory . newDUInt32 ( ) ; 
} else if ( typeString . equals ( "Float32" ) ) { 
bt = factory . newDFloat32 ( ) ; 
} else if ( typeString . equals ( "Float64" ) ) { 
bt = factory . newDFloat64 ( ) ; 
} else if ( typeString . equals ( "Byte" ) ) { 
bt = factory . newDByte ( ) ; 
} else if ( typeString . equals ( "String" ) ) { 
bt = factory . newDString ( ) ; 
} else if ( typeString . equals ( "Url" ) ) { 
bt = factory . newDURL ( ) ; 
} private void parseAttributes ( Element e , String indent ) 
throws DASException , NoSuchTypeException { 
for ( Element attrElement : e . getChildren ( "Attribute" , opendapNameSpace ) ) { 
Attribute nameAttr = attrElement . getAttribute ( "name" ) ; 
String typeName = null ; 
Attribute typeAttr = attrElement . getAttribute ( "type" ) ; 
typeName = typeAttr . getValue ( ) ; 
if ( typeName . equals ( "Container" ) ) { 
Iterator valueChildren = attrElement . getChildren ( "value" , opendapNameSpace ) . iterator ( ) ; 
if ( valueChildren . hasNext ( ) ) 
throw new AttributeBadValueException ( 
AttributeTable cacheAttributeTable = currentAT ; 
if ( currentAT == null ) 
currentAT = currentBT . appendAttributeContainer ( name ) ; 
currentAT = currentAT . appendContainer ( name ) ; 
currentAT = cacheAttributeTable ; 
Iterator attrChildren = attrElement . getChildren ( "Attribute" , opendapNameSpace ) . iterator ( ) ; 
if ( attrChildren . hasNext ( ) ) 
for ( Element valueChild : attrElement . getChildren ( "value" , opendapNameSpace ) ) { 
String value = valueChild . getText ( ) ; 
int typeVal = opendap . dap . Attribute . getTypeVal ( typeName ) ; 
currentBT . appendAttribute ( name , typeVal , value , true ) ; 
currentAT . appendAttribute ( name , typeVal , value , true ) ; 
} private void parseAliases ( Element e , String indent ) throws DASException { 
for ( Element aliasElement : e . getChildren ( "Alias" , opendapNameSpace ) ) { 
Attribute nameAttr = aliasElement . getAttribute ( "name" ) ; 
String attributeName = null ; 
Attribute attributeAttr = aliasElement . getAttribute ( "Attribute" ) ; 
attributeName = attributeAttr . getValue ( ) ; 
currentBT . addAttributeAlias ( name , attributeName ) ; 
currentAT . addAlias ( name , attributeName ) ; 
} public static String normalizeToXML ( String s ) { 
String xmlGT = "&gt;" ; 
String xmlLT = "&lt;" ; 
String xmlAmp = "&amp;" ; 
String xmlApos = "&apos;" ; 
String xmlQuote = "&quot;" ; 
sb . replace ( offset , offset + 1 , xmlGT ) ; 
sb . replace ( offset , offset + 1 , xmlLT ) ; 
sb . replace ( offset , offset + 1 , xmlAmp ) ; 
sb . replace ( offset , offset + 1 , xmlApos ) ; 
case '\"' : 
sb . replace ( offset , offset + 1 , xmlQuote ) ; 
} public static FeaturePropertyType initFeatureOfInterest ( 
FeaturePropertyType featureOfInterest , StationTimeSeriesFeature stationFeat ) { 
MonitoringPointDocument monitoringPointDoc = MonitoringPointDocument . Factory . newInstance ( ) ; 
NcMonitoringPointType . initMonitoringPointType ( monitoringPointDoc . addNewMonitoringPoint ( ) , stationFeat ) ; 
featureOfInterest . set ( monitoringPointDoc ) ; 
return featureOfInterest ; 
} private List < DataDescriptor > decode ( List < Short > keyDesc , BufrTableLookup lookup ) { 
if ( keyDesc == null ) return null ; 
List < DataDescriptor > keys = new ArrayList < DataDescriptor > ( ) ; 
for ( short id : keyDesc ) { 
DataDescriptor dd = new DataDescriptor ( id , lookup ) ; 
keys . add ( dd ) ; 
if ( dd . f == 3 ) { 
TableD . Descriptor tdd = lookup . getDescriptorTableD ( dd . fxy ) ; 
if ( tdd == null || tdd . getSequence ( ) == null ) { 
dd . bad = true ; 
dd . name = tdd . getName ( ) ; 
dd . subKeys = decode ( tdd . getSequence ( ) , lookup ) ; 
} private List < DataDescriptor > replicate ( List < DataDescriptor > keys ) { 
List < DataDescriptor > tree = new ArrayList < DataDescriptor > ( ) ; 
Iterator < DataDescriptor > dkIter = keys . iterator ( ) ; 
while ( dkIter . hasNext ( ) ) { 
DataDescriptor dk = dkIter . next ( ) ; 
if ( dk . f == 1 ) { 
dk . subKeys = new ArrayList < DataDescriptor > ( ) ; 
dk . replication = dk . y ; 
if ( dk . replication == 0 ) { 
root . isVarLength = true ; 
DataDescriptor replication = dkIter . next ( ) ; 
if ( replication . y == 0 ) 
dk . replicationCountSize = 1 ; 
else if ( replication . y == 1 ) 
dk . replicationCountSize = 8 ; 
else if ( replication . y == 2 ) 
dk . replicationCountSize = 16 ; 
else if ( replication . y == 11 ) 
dk . repetitionCountSize = 8 ; 
else if ( replication . y == 12 ) 
dk . repetitionCountSize = 16 ; 
for ( int j = 0 ; j < dk . x && dkIter . hasNext ( ) ; j ++ ) { 
dk . subKeys . add ( dkIter . next ( ) ) ; 
dk . subKeys = replicate ( dk . subKeys ) ; 
} else if ( ( dk . f == 3 ) && ( dk . subKeys != null ) ) { 
tree . add ( dk ) ; 
return tree ; 
} private void grabCompoundNames ( List < DataDescriptor > tree ) { 
for ( int i = 0 ; i < tree . size ( ) ; i ++ ) { 
DataDescriptor key = tree . get ( i ) ; 
if ( key . bad ) continue ; 
if ( ( key . f == 3 ) && ( key . subKeys != null ) ) { 
grabCompoundNames ( key . subKeys ) ; 
} else if ( key . f == 1 && key . x == 1 && i < tree . size ( ) - 1 ) { 
DataDescriptor nextKey = tree . get ( i + 1 ) ; 
if ( nextKey . f == 3 ) { 
if ( nextKey . name != null && ! nextKey . name . isEmpty ( ) ) 
key . name = nextKey . name ; 
} else if ( key . y == 0 && i < tree . size ( ) - 2 ) { 
DataDescriptor nnKey = tree . get ( i + 2 ) ; 
if ( nnKey . f == 3 ) 
if ( nnKey . name != null && ! nnKey . name . isEmpty ( ) ) 
key . name = nnKey . name ; 
} private void flatten ( List < DataDescriptor > result , List < DataDescriptor > tree ) { 
for ( DataDescriptor key : tree ) { 
if ( key . bad ) { 
root . isBad = true ; 
result . add ( key ) ; 
flatten ( result , key . subKeys ) ; 
} else if ( key . f == 1 ) { 
List < DataDescriptor > subTree = new ArrayList < DataDescriptor > ( ) ; 
flatten ( subTree , key . subKeys ) ; 
key . subKeys = subTree ; 
} private void operate ( List < DataDescriptor > tree ) { 
if ( tree == null ) return ; 
boolean hasAssFields = false ; 
DataDescriptor . AssociatedField assField = null ; 
Iterator < DataDescriptor > iter = tree . iterator ( ) ; 
DataDescriptor dd = iter . next ( ) ; 
if ( dd . f == 2 ) { 
if ( dd . x == 1 ) { 
changeWidth = ( dd . y == 0 ) ? null : dd ; 
} else if ( dd . x == 2 ) { 
changeScale = ( dd . y == 0 ) ? null : dd ; 
} else if ( dd . x == 3 ) { 
changeRefval = ( dd . y == 255 ) ? null : dd ; 
} else if ( dd . x == 4 ) { 
assField = ( dd . y == 0 ) ? null : new DataDescriptor . AssociatedField ( dd . y ) ; 
hasAssFields = true ; 
} else if ( dd . x == 5 ) { 
dd . type = 1 ; 
dd . bitWidth = dd . y * 8 ; 
dd . name = "Note" ; 
} else if ( dd . x == 6 ) { 
if ( ( dd . y != 0 ) && iter . hasNext ( ) ) { 
DataDescriptor next = iter . next ( ) ; 
next . bitWidth = dd . y ; 
} else if ( dd . x == 7 ) { 
changeWtf = ( dd . y == 0 ) ? null : dd ; 
} else if ( dd . x == 36 ) { 
if ( iter . hasNext ( ) ) { 
DataDescriptor dpi_dd = iter . next ( ) ; 
dpi = new DataPresentIndicator ( tree , dpi_dd ) ; 
dd . dpi = dpi ; 
dpi_dd . dpi = dpi ; 
} else if ( ( dd . x == 37 ) && ( dd . y == 255 ) ) { 
dpi = null ; 
} else if ( ( dd . x == 24 ) && ( dd . y == 255 ) ) { 
} else if ( dd . subKeys != null ) { 
operate ( dd . subKeys ) ; 
if ( dd . type != 3 ) { 
if ( changeWidth != null ) 
dd . bitWidth += changeWidth . y - 128 ; 
if ( changeScale != null ) 
dd . scale += changeScale . y - 128 ; 
if ( changeRefval != null ) 
dd . refVal += changeRefval . y - 128 ; 
if ( changeWtf != null && dd . type == 0 ) { 
int y = changeWtf . y ; 
dd . scale += y ; 
dd . refVal *= Math . pow ( 10 , y ) ; 
int wtf = ( ( 10 * y ) + 2 ) / 3 ; 
dd . bitWidth += wtf ; 
if ( ( dd . f == 0 ) && ( assField != null ) ) { 
assField . nfields ++ ; 
dd . assField = assField ; 
assField . dataFldName = dd . name ; 
if ( hasAssFields ) addAssFields ( tree ) ; 
public Grib1ParamTime getParamTime ( Grib1SectionProductDefinition pds ) { 
int p1 = pds . getTimeValue1 ( ) ; 
int p2 = pds . getTimeValue2 ( ) ; 
int timeRangeIndicator = pds . getTimeRangeIndicator ( ) ; 
int n = pds . getNincluded ( ) ; 
int start ; 
int end ; 
int forecastTime = 0 ; 
boolean isInterval ; 
end = ( n > 0 ) ? p1 + n * ( p2 - p1 ) : p2 ; 
forecastTime = p1 ; 
end = ( n > 0 ) ? p1 + ( n - 1 ) * p2 : p1 ; 
isInterval = ( n > 0 ) ; 
return super . getParamTime ( pds ) ; 
return new Grib1ParamTime ( this , timeRangeIndicator , isInterval , start , end , forecastTime ) ; 
} public String getDatasetFilename ( ) { 
String s = getEncodedName ( ) ; 
System . out . println ( s ) ; 
return ( s ) ; 
} public void printConstrained ( PrintWriter os ) { 
ServerMethods sm = ( ServerMethods ) bt ; 
return gemreader . getFileSubType ( ) 
. equals ( GempakSurfaceFileReader . STANDARD ) || gemreader 
. getFileSubType ( ) . equals ( GempakSurfaceFileReader . SHIP ) ; 
} public String getCFFeatureType ( ) { 
if ( gemreader . getFileSubType ( ) . equals ( GempakSurfaceFileReader . SHIP ) ) { 
return CF . FeatureType . point . toString ( ) ; 
return CF . FeatureType . timeSeries . toString ( ) ; 
array = readShipData ( v2 , section ) ; 
} else if ( gemreader . getFileSubType ( ) . equals ( 
GempakSurfaceFileReader . STANDARD ) ) { 
array = readStandardData ( v2 , section ) ; 
} private Array readStandardData ( Variable v2 , Section section ) 
List < GempakParameter > params = 
gemreader . getParameters ( GempakSurfaceFileReader . SFDT ) ; 
List < StructureMembers . Member > mbers = 
members . getMembers ( ) ; 
int numBytes = 0 ; 
int totalNumBytes = 0 ; 
for ( StructureMembers . Member member : mbers ) { 
member . setDataParam ( 4 * i ++ ) ; 
numBytes = member . getDataType ( ) . getSize ( ) ; 
totalNumBytes += numBytes ; 
members . setStructureSize ( totalNumBytes ) ; 
float [ ] missing = new float [ mbers . size ( ) ] ; 
int missnum = 0 ; 
for ( Variable v : pdata . getVariables ( ) ) { 
Attribute att = v . findAttribute ( "missing_value" ) ; 
missing [ missnum ++ ] = ( att == null ) 
? GempakConstants . RMISSD 
: att . getNumericValue ( ) . floatValue ( ) ; 
byte [ ] bytes = new byte [ totalNumBytes * size ] ; 
array = new ArrayStructureBB ( members , new int [ ] { size } , buf , 0 ) ; 
GempakFileReader . RData vals = gemreader . DM_RDTR ( timeIdx + 1 , stnIdx + 1 , GempakSurfaceFileReader . SFDT ) ; 
if ( member . getDataType ( ) . equals ( DataType . FLOAT ) ) { 
buf . putFloat ( missing [ k ] ) ; 
buf . put ( ( byte ) 1 ) ; 
float [ ] reals = vals . data ; 
buf . putFloat ( reals [ var ] ) ; 
buf . put ( ( byte ) 0 ) ; 
} private Array readShipData ( Variable v2 , Section section ) 
List < StructureMembers . Member > mbers = members . getMembers ( ) ; 
int ssize = 0 ; 
if ( stnKeyNames . contains ( member . getName ( ) ) ) { 
int varSize = getStnVarSize ( member . getName ( ) ) ; 
member . setDataParam ( ssize ) ; 
ssize += varSize ; 
} else if ( member . getName ( ) . equals ( TIME_VAR ) ) { 
ssize += 8 ; 
} else if ( member . getName ( ) . equals ( MISSING_VAR ) ) { 
ssize += 1 ; 
ssize += 4 ; 
members . setStructureSize ( ssize ) ; 
int size = recordRange . length ( ) ; 
byte [ ] bytes = new byte [ ssize * size ] ; 
List < GempakStation > stationList = gemreader . getStations ( ) ; 
List < Date > dateList = gemreader . getDates ( ) ; 
boolean needToReadData = ! pdata . isSubset ( ) ; 
if ( ! needToReadData ) { 
needToReadData = true ; 
for ( int recIdx : recordRange ) { 
GempakStation stn = stationList . get ( recIdx ) ; 
for ( String varname : stnKeyNames ) { 
if ( members . findMember ( varname ) == null ) { 
String temp = null ; 
temp = StringUtil2 . padRight ( stn . getName ( ) , 8 ) ; 
buf . putInt ( stn . getSTNM ( ) ) ; 
buf . putFloat ( ( float ) stn . getLatitude ( ) ) ; 
buf . putFloat ( ( float ) stn . getLongitude ( ) ) ; 
buf . putFloat ( ( float ) stn . getAltitude ( ) ) ; 
temp = StringUtil2 . padRight ( stn . getSTAT ( ) , 2 ) ; 
temp = StringUtil2 . padRight ( stn . getCOUN ( ) , 2 ) ; 
temp = StringUtil2 . padRight ( stn . getSTD2 ( ) , 4 ) ; 
buf . putInt ( stn . getSPRI ( ) ) ; 
temp = StringUtil2 . padRight ( stn . getSWFO ( ) , 4 ) ; 
temp = StringUtil2 . padRight ( stn . getWFO2 ( ) , 4 ) ; 
if ( temp != null ) { 
buf . put ( temp . getBytes ( CDM . utf8Charset ) ) ; 
if ( members . findMember ( TIME_VAR ) != null ) { 
Date time = dateList . get ( recIdx ) ; 
buf . putDouble ( time . getTime ( ) / 1000.d ) ; 
if ( needToReadData ) { 
int column = stn . getIndex ( ) ; 
GempakFileReader . RData vals = 
gemreader . DM_RDTR ( 1 , column , 
GempakSurfaceFileReader . SFDT ) ; 
buf . putFloat ( GempakConstants . RMISSD ) ; 
switch ( fileType ) { 
case GempakSurfaceFileReader . STANDARD : 
buildStandardFile ( ) ; 
case GempakSurfaceFileReader . SHIP : 
buildShipFile ( ) ; 
buildClimateFile ( ) ; 
} private void buildStandardFile ( ) { 
Structure sfData = makeStructure ( GempakSurfaceFileReader . SFDT , 
stationTime , true ) ; 
if ( sfData == null ) { 
ncfile . addVariable ( null , sfData ) ; 
ncfile . addAttribute ( 
"CF:featureType" , 
CF . FeatureType . timeSeries . toString ( ) ) ) ; 
} private void buildShipFile ( ) { 
int numObs = stations . size ( ) ; 
Dimension record = new Dimension ( "record" , numObs , true , 
( numObs == 0 ) , false ) ; 
ncfile . addDimension ( null , record ) ; 
List < Dimension > records = new ArrayList < > ( 1 ) ; 
Variable timeVar = new Variable ( ncfile , null , null , TIME_VAR , 
DataType . DOUBLE , ( String ) null ) ; 
List < Variable > stationVars = makeStationVars ( stations , null ) ; 
Structure sVar = new Structure ( ncfile , null , null , "Obs" ) ; 
sVar . setDimensions ( records ) ; 
boolean hasElevation = false ; 
if ( stnVar . getShortName ( ) . equals ( "SELV" ) ) { 
hasElevation = true ; 
sVar . addMemberVariable ( stnVar ) ; 
sVar . addMemberVariable ( timeVar ) ; 
Variable var = makeParamVariable ( param , null ) ; 
sVar . addMemberVariable ( var ) ; 
if ( hasElevation ) { 
sVar . addAttribute ( new Attribute ( CF . COORDINATES , coords ) ) ; 
new Attribute ( "CF:featureType" , 
CF . FeatureType . point . toString ( ) ) ) ; 
} public static float absoluteDifference ( float a , float b ) { 
if ( Float . compare ( a , b ) == 0 ) { 
return Math . abs ( a - b ) ; 
} public static double absoluteDifference ( double a , double b ) { 
if ( Double . compare ( a , b ) == 0 ) { 
} public static float relativeDifference ( float a , float b ) { 
float absDiff = absoluteDifference ( a , b ) ; 
} else if ( a == 0 || b == 0 || absDiff < Float . MIN_NORMAL ) { 
return absDiff / Float . MIN_NORMAL ; 
float maxAbsValue = Math . max ( Math . abs ( a ) , Math . abs ( b ) ) ; 
return absDiff / maxAbsValue ; 
} public static boolean nearlyEqualsAbs ( float a , float b , float maxAbsDiff ) { 
return absoluteDifference ( a , b ) <= Math . abs ( maxAbsDiff ) ; 
} static public boolean compare ( byte [ ] raw1 , byte [ ] raw2 , Formatter f ) { 
if ( raw1 == null || raw2 == null ) return false ; 
if ( raw1 . length != raw2 . length ) { 
int len = Math . min ( raw1 . length , raw2 . length ) ; 
int ndiff = 0 ; 
if ( raw1 [ i ] != raw2 [ i ] ) { 
ndiff ++ ; 
return ndiff == 0 && ( raw1 . length == raw2 . length ) ; 
} public static InvDataset copyDataset ( InvDataset dataset , List < InvService > availableServices , 
boolean copyInheritedMetadataFromParents ) 
InvDatasetImpl resultDs ; 
if ( dataset instanceof InvCatalogRef ) 
InvCatalogRef catRef = ( InvCatalogRef ) dataset ; 
resultDs = new InvCatalogRef ( null , catRef . getName ( ) , catRef . getXlinkHref ( ) ) ; 
resultDs = new InvDatasetImpl ( null , dataset . getName ( ) ) ; 
resultDs . setID ( dataset . getID ( ) ) ; 
resultDs . transferMetadata ( ( InvDatasetImpl ) dataset , copyInheritedMetadataFromParents ) ; 
if ( ! ( dataset instanceof InvCatalogRef ) ) { 
String urlPath = ( ( InvDatasetImpl ) dataset ) . getUrlPath ( ) ; 
if ( urlPath != null ) 
resultDs . setUrlPath ( urlPath ) ; 
for ( InvAccess curAccess : dataset . getAccess ( ) ) { 
InvAccess access = copyAccess ( curAccess , resultDs , availableServices ) ; 
if ( access != null ) resultDs . addAccess ( access ) ; 
for ( InvDataset curDs : dataset . getDatasets ( ) ) 
InvDatasetImpl curDsCopy = ( InvDatasetImpl ) copyDataset ( curDs , availableServices , false ) ; 
curDsCopy . setParent ( resultDs ) ; 
resultDs . addDataset ( curDsCopy ) ; 
return resultDs ; 
} static void readWmoXmlTableB ( InputStream ios , TableB b ) throws IOException { 
String [ ] elems = null ; 
for ( Version v : Version . values ( ) ) { 
elems = v . getElemNamesB ( ) ; 
if ( featList != null && featList . size ( ) > 0 ) { 
if ( elems == null ) { 
elems = Version . BUFR_WMO . getElemNamesB ( ) ; 
List < Element > featList = root . getChildren ( ) ; 
Element ce = elem . getChild ( elems [ 1 ] ) ; 
if ( ce == null ) continue ; 
String name = Util . cleanName ( elem . getChildTextNormalize ( elems [ 1 ] ) ) ; 
String units = cleanUnit ( elem . getChildTextNormalize ( "BUFR_Unit" ) ) ; 
int x = 0 , y = 0 , scale = 0 , reference = 0 , width = 0 ; 
String fxy = null ; 
String s = null ; 
fxy = elem . getChildTextNormalize ( "FXY" ) ; 
int xy = Integer . parseInt ( cleanNumber ( fxy ) ) ; 
x = xy / 1000 ; 
y = xy % 1000 ; 
s = elem . getChildTextNormalize ( "BUFR_Scale" ) ; 
scale = Integer . parseInt ( cleanNumber ( s ) ) ; 
s = elem . getChildTextNormalize ( "BUFR_ReferenceValue" ) ; 
reference = Integer . parseInt ( cleanNumber ( s ) ) ; 
s = elem . getChildTextNormalize ( "BUFR_DataWidth_Bits" ) ; 
width = Integer . parseInt ( cleanNumber ( s ) ) ; 
b . addDescriptor ( ( short ) x , ( short ) y , scale , reference , width , name , units , null ) ; 
} static void readWmoXmlTableD ( InputStream ios , TableD tableD ) throws IOException { 
int currSeqno = - 1 ; 
TableD . Descriptor currDesc = null ; 
elems = v . getElemNamesD ( ) ; 
elems = Version . BUFR_WMO . getElemNamesD ( ) ; 
String seqs = elem . getChildTextNormalize ( "FXY1" ) ; 
int seq = Integer . parseInt ( seqs ) ; 
if ( currSeqno != seq ) { 
int y = seq % 1000 ; 
int w = seq / 1000 ; 
int x = w % 100 ; 
String seqName = Util . cleanName ( elem . getChildTextNormalize ( elems [ 1 ] ) ) ; 
currDesc = tableD . addDescriptor ( ( short ) x , ( short ) y , seqName , new ArrayList < Short > ( ) ) ; 
currSeqno = seq ; 
String fnos = elem . getChildTextNormalize ( "FXY2" ) ; 
int fno = Integer . parseInt ( fnos ) ; 
int y = fno % 1000 ; 
int w = fno / 1000 ; 
int f = w / 100 ; 
int fxy = ( f << 14 ) + ( x << 8 ) + y ; 
currDesc . addFeature ( ( short ) fxy ) ; 
} static GribCollectionProto . Gds writeGdsProto ( byte [ ] rawGds , int predefinedGridDefinition ) { 
GribCollectionProto . Gds . Builder b = GribCollectionProto . Gds . newBuilder ( ) ; 
if ( predefinedGridDefinition >= 0 ) 
b . setPredefinedGridDefinition ( predefinedGridDefinition ) ; 
b . setGds ( ByteString . copyFrom ( rawGds ) ) ; 
} GribCollectionProto . Coord writeCoordProto ( CoordinateRuntime coord ) { 
GribCollectionProto . Coord . Builder b = GribCollectionProto . Coord . newBuilder ( ) ; 
b . setAxisType ( convertAxisType ( coord . getType ( ) ) ) ; 
b . setCode ( coord . getCode ( ) ) ; 
if ( coord . getUnit ( ) != null ) 
b . setUnit ( coord . getUnit ( ) ) ; 
for ( int idx = 0 ; idx < coord . getSize ( ) ; idx ++ ) { 
long runtime = coord . getRuntime ( idx ) ; 
b . addMsecs ( runtime ) ; 
} public static GribCollectionProto . GribAxisType convertAxisType ( Coordinate . Type type ) { 
return GribCollectionProto . GribAxisType . runtime ; 
return GribCollectionProto . GribAxisType . time ; 
return GribCollectionProto . GribAxisType . time2D ; 
return GribCollectionProto . GribAxisType . timeIntv ; 
return GribCollectionProto . GribAxisType . ens ; 
return GribCollectionProto . GribAxisType . vert ; 
public boolean references ( DapNode node ) 
} public final Unit parse ( final String spec ) throws NoSuchUnitException , 
PrefixDBException , UnitSystemException { 
synchronized ( MUTEX ) { 
return parse ( spec , UnitDBManager . instance ( ) ) ; 
} void checkSort ( Ray [ ] r ) { 
int j = 0 , n = 0 , n1 = 0 , n2 = 0 ; 
short time1 = 0 , time2 = 0 ; 
int [ ] k1 = new int [ 300 ] ; 
int [ ] k2 = new int [ 300 ] ; 
for ( int i = 0 ; i < r . length - 1 ; i ++ ) { 
time1 = r [ i ] . getTime ( ) ; 
time2 = r [ i + 1 ] . getTime ( ) ; 
if ( time1 != time2 ) { 
k2 [ j ] = i ; 
j = j + 1 ; 
k1 [ j ] = i + 1 ; 
if ( k2 [ j ] < r . length - 1 ) { 
k1 [ j ] = k2 [ j - 1 ] + 1 ; 
k2 [ j ] = r . length - 1 ; 
n = j + 1 ; 
int it1 = 0 , it2 = 0 ; 
for ( int ii = 0 ; ii < j + 1 ; ii ++ ) { 
n1 = k1 [ ii ] ; 
for ( int i = 0 ; i < j + 1 ; i ++ ) { 
if ( i != ii ) { 
n2 = k1 [ i ] ; 
if ( r [ n1 ] . getTime ( ) == r [ n2 ] . getTime ( ) ) { 
it1 = ii ; 
it2 = i ; 
n1 = k1 [ it1 ] ; 
n2 = k1 [ it2 ] ; 
int s1 = k2 [ it1 ] - k1 [ it1 ] + 1 ; 
int s2 = k2 [ it2 ] - k1 [ it2 ] + 1 ; 
float [ ] t0 = new float [ s1 ] ; 
float [ ] t00 = new float [ s2 ] ; 
for ( int i = 0 ; i < s1 ; i ++ ) { 
t0 [ i ] = r [ n1 + i ] . getAz ( ) ; 
for ( int i = 0 ; i < s2 ; i ++ ) { 
t00 [ i ] = r [ n2 + i ] . getAz ( ) ; 
float mx0 = t0 [ 0 ] ; 
if ( mx0 < t0 [ i ] ) mx0 = t0 [ i ] ; 
float mx00 = t00 [ 0 ] ; 
if ( mx00 < t00 [ i ] ) mx00 = t00 [ i ] ; 
if ( ( mx0 > 330.0f & mx00 < 50.0f ) ) { 
float q = r [ n1 + i ] . getAz ( ) ; 
r [ n1 + i ] . setAz ( q - 360.0f ) ; 
Arrays . sort ( r , new RayComparator ( ) ) ; 
for ( int i = 0 ; i < r . length ; i ++ ) { 
float a = r [ i ] . getAz ( ) ; 
if ( a < 0 & a > - 361.0f ) { 
float qa = r [ i ] . getAz ( ) ; 
r [ i ] . setAz ( qa + 360.0f ) ; 
} public static void probeObject ( Object o ) { 
Class c = o . getClass ( ) ; 
Class interfaces [ ] = c . getInterfaces ( ) ; 
Class parent = c . getSuperclass ( ) ; 
Method m [ ] = c . getMethods ( ) ; 
for ( int i = 0 ; i < interfaces . length ; i ++ ) { 
System . out . println ( "Methods:" ) ; 
Class params [ ] = m [ i ] . getParameterTypes ( ) ; 
Class excepts [ ] = m [ i ] . getExceptionTypes ( ) ; 
Class ret = m [ i ] . getReturnType ( ) ; 
for ( int j = 0 ; j < params . length ; j ++ ) { 
if ( j > 0 ) 
System . out . print ( params [ j ] . getName ( ) ) ; 
for ( int j = 0 ; j < excepts . length ; j ++ ) { 
System . out . print ( excepts [ j ] . getName ( ) ) ; 
System . out . println ( "******************" ) ; 
sink . writeInt ( ( int ) vals [ i ] ) ; 
public Object getInternalStorage ( ) { 
return ( vals ) ; 
public void setInternalStorage ( Object o ) { 
vals = ( short [ ] ) o ; 
public PrimitiveVector subset ( int start , int stop , int stride ) { 
Int16PrimitiveVector n = new Int16PrimitiveVector ( getTemplate ( ) ) ; 
public void printVal ( PrintWriter os , String space , 
boolean print_decl_p ) { } 
public DAPNode cloneDAG ( CloneMap map ) 
Int16PrimitiveVector v = ( Int16PrimitiveVector ) super . cloneDAG ( map ) ; 
v . vals = new short [ vals . length ] ; 
} private boolean isTiled ( Variable v ) { 
for ( Dimension d : v . getDimensions ( ) ) { 
for ( Range r : section . getRanges ( ) ) { 
if ( d . getShortName ( ) . equals ( r . getName ( ) ) ) 
} public CoordinateTimeAbstract makeBestFromComplete ( ) { 
int [ ] best = new int [ time2runtime . length ] ; 
int last = - 1 ; 
for ( int i = 0 ; i < time2runtime . length ; i ++ ) { 
int time = time2runtime [ i ] ; 
if ( time >= last ) { 
last = time ; 
best [ i ] = time ; 
best [ i ] = - 1 ; 
return makeBestFromComplete ( best , count ) ; 
} public ProjectionPoint latLonToProj ( LatLonPoint latlon , ProjectionPointImpl result ) { 
result . setLocation ( LatLonPointImpl . lonNormal ( latlon . getLongitude ( ) , 
centerLon ) , latlon . getLatitude ( ) ) ; 
result . setLongitude ( world . getX ( ) ) ; 
result . setLatitude ( world . getY ( ) ) ; 
float [ ] fromX = from [ INDEX_X ] ; 
float [ ] fromY = from [ INDEX_Y ] ; 
to [ INDEX_LAT ] = fromY ; 
to [ INDEX_LON ] = fromX ; 
double [ ] toX = to [ INDEX_X ] ; 
double [ ] toY = to [ INDEX_Y ] ; 
double [ ] fromLat = from [ latIndex ] ; 
double [ ] fromLon = from [ lonIndex ] ; 
double lat , lon ; 
lat = fromLat [ i ] ; 
lon = centerLon + Math . IEEEremainder ( fromLon [ i ] - centerLon , 360.0 ) ; 
toX [ i ] = lon ; 
toY [ i ] = lat ; 
return Math . abs ( pt1 . getX ( ) - pt2 . getX ( ) ) > 270.0 ; 
} public ProjectionRect [ ] latLonToProjRect ( LatLonRect latlonR ) { 
double lat0 = latlonR . getLowerLeftPoint ( ) . getLatitude ( ) ; 
double height = Math . abs ( latlonR . getUpperRightPoint ( ) . getLatitude ( ) - lat0 ) ; 
double width = latlonR . getWidth ( ) ; 
double lon0 = LatLonPointImpl . lonNormal ( 
latlonR . getLowerLeftPoint ( ) . getLongitude ( ) , 
centerLon ) ; 
double lon1 = LatLonPointImpl . lonNormal ( 
latlonR . getUpperRightPoint ( ) . getLongitude ( ) , 
ProjectionRect [ ] rects = new ProjectionRect [ ] { new ProjectionRect ( ) , new ProjectionRect ( ) } ; 
if ( lon0 < lon1 ) { 
rects [ 0 ] . setRect ( lon0 , lat0 , width , height ) ; 
rects [ 1 ] = null ; 
double y = centerLon + 180 - lon0 ; 
rects [ 0 ] . setRect ( lon0 , lat0 , y , height ) ; 
rects [ 1 ] . setRect ( lon1 - width + y , lat0 , width - y , height ) ; 
return rects ; 
} public ProjectionRect [ ] latLonToProjRect ( double lat0 , double lon0 , double lat1 , double lon1 ) { 
double height = Math . abs ( lat1 - lat0 ) ; 
lat0 = Math . min ( lat1 , lat0 ) ; 
double width = lon1 - lon0 ; 
if ( width < 1.0e-8 ) { 
lon0 = LatLonPointImpl . lonNormal ( lon0 , centerLon ) ; 
lon1 = LatLonPointImpl . lonNormal ( lon1 , centerLon ) ; 
if ( width >= 360.0 ) { 
rects [ 0 ] . setRect ( centerLon - 180.0 , lat0 , 360.0 , height ) ; 
} else if ( lon0 < lon1 ) { 
} @ RequestMapping ( method = RequestMethod . GET ) 
protected void showDebugPage ( HttpServletRequest request , HttpServletResponse response ) throws IOException { 
response . setContentType ( ContentType . html . getContentHeader ( ) ) ; 
response . setHeader ( "Content-Description" , "thredds_debug" ) ; 
ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; 
PrintStream pw = new PrintStream ( bos , false , CDM . UTF8 ) ; 
pw . println ( htmlu . getHtmlDoctypeAndOpenTag ( ) ) ; 
pw . println ( htmlu . getTdsPageCssLink ( ) ) ; 
pw . println ( htmlu . getGoogleTrackingContent ( ) ) ; 
pw . println ( htmlu . getOldStyleHeader ( ) ) ; 
String cmds = request . getQueryString ( ) ; 
if ( ( cmds == null ) || ( cmds . length ( ) == 0 ) ) { 
showDebugActions ( request , pw ) ; 
StringTokenizer tz = new StringTokenizer ( cmds , ";" ) ; 
String target = null ; 
int pos = cmd . indexOf ( '/' ) ; 
String dhName = "General" ; 
dhName = cmd . substring ( 0 , pos ) ; 
cmd = cmd . substring ( pos + 1 ) ; 
pos = cmd . indexOf ( '=' ) ; 
target = cmd . substring ( pos + 1 ) ; 
cmd = cmd . substring ( 0 , pos ) ; 
DebugCommands . Category dh = debugCommands . findCategory ( dhName ) ; 
if ( dh == null ) { 
DebugCommands . Action action = dh . actions . get ( cmd ) ; 
if ( action == null ) 
action . doAction ( new DebugCommands . Event ( request , response , pw , bos , target ) ) ; 
pw . println ( "</pre></body></html>" ) ; 
PrintWriter responsePS = response . getWriter ( ) ; 
responsePS . write ( bos . toString ( CDM . UTF8 ) ) ; 
responsePS . flush ( ) ; 
} @ RequestMapping ( value = "/**" , method = RequestMethod . GET ) 
public ResponseEntity < String > handleCapabilitiesRequest ( HttpServletRequest request , HttpServletResponse response , @ RequestParam String req ) throws IOException { 
if ( ! allowedServices . isAllowed ( StandardService . cdmRemote ) ) 
throw new ServiceNotAllowed ( StandardService . cdmRemote . toString ( ) ) ; 
String datasetPath = TdsPathUtils . extractPath ( request , "/cdmremote" ) ; 
String absPath = getAbsolutePath ( request ) ; 
HttpHeaders responseHeaders ; 
if ( showReq ) 
try ( NetcdfFile ncfile = TdsRequestedDataset . getNetcdfFile ( request , response , datasetPath ) ) { 
responseHeaders = new HttpHeaders ( ) ; 
responseHeaders . setDate ( "Last-Modified" , TdsRequestedDataset . getLastModified ( datasetPath ) ) ; 
if ( req == null ) { 
response . setContentType ( ContentType . binary . getContentHeader ( ) ) ; 
response . setHeader ( "Content-Description" , "ncstream" ) ; 
return new ResponseEntity < > ( null , responseHeaders , HttpStatus . OK ) ; 
switch ( req . toLowerCase ( ) ) { 
case "form" : 
case "cdl" : 
ncfile . setLocation ( datasetPath ) ; 
String cdl = ncfile . toString ( ) ; 
return new ResponseEntity < > ( cdl , responseHeaders , HttpStatus . OK ) ; 
case "ncml" : 
String ncml = ncfile . toNcML ( absPath ) ; 
responseHeaders . set ( ContentType . HEADER , ContentType . xml . getContentHeader ( ) ) ; 
return new ResponseEntity < > ( ncml , responseHeaders , HttpStatus . OK ) ; 
} int setDirect ( int v0 , int v1 , int v2 , int v3 , int v4 ) { 
return offset + v0 * stride0 + v1 * stride1 + v2 * stride2 + v3 * stride3 + 
v4 * stride4 ; 
} private void showTimeSeriesAll ( java . util . List < LogReader . Log > logs ) { 
long period = 1000 * 60 * 5 ; 
TimeDuration tu = new TimeDuration ( intervalS ) ; 
period = ( long ) ( 1000 * tu . getValueInSeconds ( ) ) ; 
long current = 0 ; 
long bytes = 0 ; 
long timeTook = 0 ; 
long total_count = 0 ; 
for ( LogReader . Log log : logs ) { 
long msecs = log . date ; 
if ( msecs - current > period ) { 
if ( current > 0 ) { 
total_count += count ; 
addPoint ( bytesSentData , timeTookData , nreqData , new Date ( current ) , bytes , count , timeTook ) ; 
bytes = 0 ; 
timeTook = 0 ; 
current = msecs ; 
bytes += log . getBytes ( ) ; 
timeTook += log . getMsecs ( ) ; 
mc . finish ( new java . awt . Dimension ( 1000 , 1000 ) ) ; 
timeSeriesPanel . removeAll ( ) ; 
timeSeriesPanel . add ( mc ) ; 
} static public Map < String , Attribute > makeMap ( List < Attribute > atts ) 
int size = ( atts == null ) ? 1 : atts . size ( ) ; 
Map < String , Attribute > result = new HashMap < > ( size ) ; 
if ( atts == null ) return result ; 
for ( Attribute att : atts ) result . put ( att . getShortName ( ) , att ) ; 
} public Array getValues ( ) { 
if ( values == null && svalue != null ) { 
values = Array . factory ( DataType . STRING , new int [ ] { 1 } ) ; 
values . setObject ( values . getIndex ( ) , svalue ) ; 
if ( dataType != DataType . STRING ) return null ; 
return ( svalue != null ) ? svalue : _getStringValue ( 0 ) ; 
} public Number getNumericValue ( int index ) { 
if ( ( index < 0 ) || ( index >= nelems ) ) 
return new Double ( getStringValue ( index ) ) ; 
return values . getByte ( index ) ; 
return values . getShort ( index ) ; 
return values . getInt ( index ) ; 
return values . getFloat ( index ) ; 
return values . getDouble ( index ) ; 
return values . getLong ( index ) ; 
} protected void writeCDL ( Formatter f , boolean strict , String parentname ) { 
if ( strict && ( isString ( ) || this . getEnumType ( ) != null ) ) 
if ( strict && parentname != null ) f . format ( NetcdfFile . makeValidCDLName ( parentname ) ) ; 
f . format ( ":" ) ; 
f . format ( "%s" , strict ? NetcdfFile . makeValidCDLName ( getShortName ( ) ) : getShortName ( ) ) ; 
if ( isString ( ) ) { 
for ( int i = 0 ; i < getLength ( ) ; i ++ ) { 
String val = getStringValue ( i ) ; 
if ( val != null ) 
f . format ( "\"%s\"" , encodeString ( val ) ) ; 
} else if ( getEnumType ( ) != null ) { 
EnumTypedef en = getEnumType ( ) ; 
String econst = getStringValue ( i ) ; 
Integer ecint = en . lookupEnumInt ( econst ) ; 
if ( ecint == null ) 
f . format ( "\"%s\"" , encodeString ( econst ) ) ; 
Number number = getNumericValue ( i ) ; 
if ( dataType . isUnsigned ( ) ) { 
number = DataType . widenNumber ( number ) ; 
f . format ( "%s" , number ) ; 
f . format ( "U" ) ; 
f . format ( "f" ) ; 
else if ( dataType == DataType . SHORT || dataType == DataType . USHORT ) { 
f . format ( "S" ) ; 
} else if ( dataType == DataType . BYTE || dataType == DataType . UBYTE ) { 
f . format ( "B" ) ; 
} else if ( dataType == DataType . LONG || dataType == DataType . ULONG ) { 
f . format ( "L" ) ; 
} private void setStringValue ( String val ) { 
if ( val == null ) 
int len = val . length ( ) ; 
while ( ( len > 0 ) && ( val . charAt ( len - 1 ) == 0 ) ) 
if ( len != val . length ( ) ) 
val = val . substring ( 0 , len ) ; 
this . svalue = val ; 
this . nelems = 1 ; 
this . dataType = DataType . STRING ; 
} public void setValues ( List values ) 
if ( values == null || values . size ( ) == 0 ) 
int n = values . size ( ) ; 
Class c = values . get ( 0 ) . getClass ( ) ; 
Object pa ; 
if ( c == String . class ) { 
String [ ] va = new String [ n ] ; 
pa = va ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( String ) values . get ( i ) ; 
} else if ( c == Integer . class ) { 
int [ ] va = new int [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Integer ) values . get ( i ) ; 
} else if ( c == Double . class ) { 
double [ ] va = new double [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Double ) values . get ( i ) ; 
} else if ( c == Float . class ) { 
float [ ] va = new float [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Float ) values . get ( i ) ; 
} else if ( c == Short . class ) { 
short [ ] va = new short [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Short ) values . get ( i ) ; 
} else if ( c == Byte . class ) { 
byte [ ] va = new byte [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Byte ) values . get ( i ) ; 
} else if ( c == Long . class ) { 
long [ ] va = new long [ n ] ; 
for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Long ) values . get ( i ) ; 
setValues ( Array . factory ( this . dataType , new int [ ] { n } , pa ) ) ; 
} public void setValues ( Array arr ) { 
if ( arr == null ) { 
dataType = DataType . STRING ; 
if ( arr . getElementType ( ) == char . class ) { 
ArrayChar carr = ( ArrayChar ) arr ; 
if ( carr . getRank ( ) == 1 ) { 
svalue = carr . getString ( ) ; 
arr = carr . make1DStringArray ( ) ; 
if ( arr . getElementType ( ) == ByteBuffer . class ) { 
int totalLen = 0 ; 
arr . resetLocalIterator ( ) ; 
while ( arr . hasNext ( ) ) { 
ByteBuffer bb = ( ByteBuffer ) arr . next ( ) ; 
totalLen += bb . limit ( ) ; 
byte [ ] ba = new byte [ totalLen ] ; 
System . arraycopy ( bb . array ( ) , 0 , ba , pos , bb . limit ( ) ) ; 
pos += bb . limit ( ) ; 
arr = Array . factory ( DataType . BYTE , new int [ ] { totalLen } , ba ) ; 
if ( DataType . getType ( arr ) == DataType . OBJECT ) 
if ( arr . getRank ( ) > 1 ) 
arr = arr . reshape ( new int [ ] { ( int ) arr . getSize ( ) } ) ; 
this . values = arr ; 
this . nelems = ( int ) arr . getSize ( ) ; 
this . dataType = DataType . getType ( arr ) ; 
} public void scan ( ) throws IOException 
state = 1 ; 
if ( proxyDsHandlers == null ) proxyDsHandlers = Collections . EMPTY_MAP ; 
genCatalog = createSkeletonCatalog ( currentLevel ) ; 
InvDatasetImpl topInvDs = ( InvDatasetImpl ) genCatalog . getDatasets ( ) . get ( 0 ) ; 
List crDsList = currentLevel . listDatasets ( this . filter ) ; 
if ( sorter != null ) sorter . sort ( crDsList ) ; 
for ( int i = 0 ; i < crDsList . size ( ) ; i ++ ) 
CrawlableDataset curCrDs = ( CrawlableDataset ) crDsList . get ( i ) ; 
InvDatasetImpl curInvDs = ( InvDatasetImpl ) createInvDatasetFromCrawlableDataset ( curCrDs , topInvDs , null ) ; 
InvCrawlablePair dsInfo = new InvCrawlablePair ( curCrDs , curInvDs ) ; 
if ( curCrDs . isCollection ( ) ) 
catRefInfo . add ( dsInfo ) ; 
atomicDsInfo . add ( dsInfo ) ; 
topInvDs . addDataset ( curInvDs ) ; 
( ( InvCatalogImpl ) genCatalog ) . finish ( ) ; 
if ( atomicDsInfo . size ( ) > 0 ) 
boolean anyProxiesAdded = false ; 
for ( Iterator it = proxyDsHandlers . values ( ) . iterator ( ) ; it . hasNext ( ) ; ) 
ProxyDatasetHandler curProxy = ( ProxyDatasetHandler ) it . next ( ) ; 
InvService proxyService = curProxy . getProxyDatasetService ( currentLevel ) ; 
if ( proxyService != null ) 
CrawlableDataset crDsToAdd = curProxy . createProxyDataset ( currentLevel ) ; 
InvDatasetImpl invDsToAdd = createInvDatasetFromCrawlableDataset ( crDsToAdd , topInvDs , proxyService ) ; 
InvCrawlablePair dsInfo = new InvCrawlablePair ( crDsToAdd , invDsToAdd ) ; 
proxyDsInfo . add ( dsInfo ) ; 
int index = curProxy . getProxyDatasetLocation ( currentLevel , topInvDs . getDatasets ( ) . size ( ) ) ; 
topInvDs . addDataset ( index , ( InvDatasetImpl ) invDsToAdd ) ; 
genCatalog . addService ( proxyService ) ; 
anyProxiesAdded = true ; 
if ( anyProxiesAdded ) ( ( InvCatalogImpl ) genCatalog ) . finish ( ) ; 
this . addTopLevelMetadata ( genCatalog , true ) ; 
state = 2 ; 
} public InvCatalogImpl generateProxyDsResolverCatalog ( ProxyDatasetHandler pdh ) 
InvCatalogImpl catalog = createSkeletonCatalog ( currentLevel ) ; 
InvDatasetImpl topDs = ( InvDatasetImpl ) catalog . getDatasets ( ) . get ( 0 ) ; 
InvCrawlablePair actualDsInfo = pdh . getActualDataset ( atomicDsInfo ) ; 
if ( actualDsInfo == null ) 
return catalog ; 
InvDatasetImpl actualInvDs = ( InvDatasetImpl ) actualDsInfo . getInvDataset ( ) ; 
actualInvDs . setName ( pdh . getActualDatasetName ( actualDsInfo , topDs . getName ( ) ) ) ; 
catalog . removeDataset ( topDs ) ; 
catalog . addDataset ( actualInvDs ) ; 
catalog . finish ( ) ; 
this . addTopLevelMetadata ( catalog , false ) ; 
} private String getID ( CrawlableDataset dataset ) 
if ( dataset == null ) 
if ( collectionId == null ) 
int i = collectionLevel . getPath ( ) . length ( ) ; 
String id = dataset . getPath ( ) . substring ( i ) ; 
if ( id . startsWith ( "/" ) ) 
id = id . substring ( 1 ) ; 
if ( collectionId . equals ( "" ) ) 
if ( id . equals ( "" ) ) 
return collectionId ; 
return ( collectionId + "/" + id ) ; 
} private String getUrlPath ( CrawlableDataset dataset , InvService service ) 
InvService serviceForThisDs = service != null ? service : this . service ; 
if ( serviceForThisDs . getBase ( ) . equals ( "" ) 
&& ! serviceForThisDs . getServiceType ( ) . equals ( ServiceType . COMPOUND ) ) 
String urlPath = dataset . getPath ( ) . substring ( catalogLevel . getPath ( ) . length ( ) ) ; 
if ( urlPath . startsWith ( "/" ) ) 
urlPath = urlPath . substring ( 1 ) ; 
return urlPath ; 
if ( serviceForThisDs . isRelativeBase ( ) ) 
String relPath = dataset . getPath ( ) . substring ( collectionLevel . getPath ( ) . length ( ) ) ; 
if ( relPath . startsWith ( "/" ) ) 
relPath = relPath . substring ( 1 ) ; 
return ( ( collectionPath . equals ( "" ) ? "" : collectionPath + "/" ) + relPath ) ; 
return relPath ; 
} private String getXlinkHref ( CrawlableDataset dataset ) 
String path = dataset . getPath ( ) . substring ( catalogLevel . getPath ( ) . length ( ) ) ; 
if ( path . startsWith ( "/" ) ) 
path += "catalog.xml" ; 
path += "/catalog.xml" ; 
return CatalogUtils . escapePathForURL ( path ) ; 
} public static int write ( OutputStream out , PointFeatureIterator pointFeatIter , String name , String timeUnitString , 
String altUnits ) throws IOException { 
int numWritten = 0 ; 
PointFeature pointFeat = pointFeatIter . next ( ) ; 
if ( numWritten == 0 ) { 
PointStreamProto . PointFeatureCollection protoPfc = 
PointStream . encodePointFeatureCollection ( name , timeUnitString , altUnits , pointFeat ) ; 
byte [ ] data = protoPfc . toByteArray ( ) ; 
PointStream . writeMagic ( out , MessageType . PointFeatureCollection ) ; 
NcStream . writeVInt ( out , data . length ) ; 
out . write ( data ) ; 
PointStreamProto . PointFeature protoPointFeat = PointStream . encodePointFeature ( pointFeat ) ; 
byte [ ] data = protoPointFeat . toByteArray ( ) ; 
PointStream . writeMagic ( out , MessageType . PointFeature ) ; 
++ numWritten ; 
NcStreamProto . Error protoError = 
NcStream . encodeErrorMessage ( t . getMessage ( ) != null ? t . getMessage ( ) : t . getClass ( ) . getName ( ) ) ; 
byte [ ] data = protoError . toByteArray ( ) ; 
PointStream . writeMagic ( out , PointStream . MessageType . Error ) ; 
throw new IOException ( t ) ; 
PointStream . writeMagic ( out , PointStream . MessageType . End ) ; 
return numWritten ; 
} void scheduleWrite ( Message m ) { 
q . add ( m ) ; 
if ( ! isScheduled . getAndSet ( true ) ) { 
executor . submit ( this ) ; 
if ( rootName != null ) 
rootName += "." + getEncodedName ( ) ; 
rootName = getEncodedName ( ) ; 
toASCII ta = ( toASCII ) e . nextElement ( ) ; 
if ( ! newLine && ! firstPass ) 
ta . toASCII ( pw , addName , rootName , newLine ) ; 
} public void makeComponent ( JTabbedPane parent , final String title ) { 
parent = tabbedPane ; 
int n = parent . getTabCount ( ) ; 
int idx ; 
for ( idx = 0 ; idx < n ; idx ++ ) { 
String cTitle = parent . getTitleAt ( idx ) ; 
if ( cTitle . equals ( title ) ) break ; 
if ( idx >= n ) { 
Component c ; 
switch ( title ) { 
case "Aggregation" : 
aggPanel = new AggPanel ( ( PreferencesExt ) mainPrefs . node ( "NcMLAggregation" ) ) ; 
c = aggPanel ; 
case "BUFR" : 
bufrPanel = new BufrPanel ( ( PreferencesExt ) mainPrefs . node ( "bufr" ) ) ; 
c = bufrPanel ; 
case "BUFRTableB" : 
bufrTableBPanel = new BufrTableBPanel ( ( PreferencesExt ) mainPrefs . node ( "bufr2" ) ) ; 
c = bufrTableBPanel ; 
case "BUFRTableD" : 
bufrTableDPanel = new BufrTableDPanel ( ( PreferencesExt ) mainPrefs . node ( "bufrD" ) ) ; 
c = bufrTableDPanel ; 
case "BufrReports" : { 
PreferencesExt prefs = ( PreferencesExt ) mainPrefs . node ( "bufrReports" ) ; 
ReportPanel rp = new BufrReportPanel ( prefs ) ; 
bufrReportPanel = new ReportOpPanel ( prefs , rp ) ; 
c = bufrReportPanel ; 
case "BUFR-CODES" : 
bufrCodePanel = new BufrCodePanel ( ( PreferencesExt ) mainPrefs . node ( "bufr-codes" ) ) ; 
c = bufrCodePanel ; 
case "CdmrFeature" : 
cdmremotePanel = new CdmrFeatureOpPanel ( ( PreferencesExt ) mainPrefs . node ( "CdmrFeature" ) ) ; 
c = cdmremotePanel ; 
case "CollectionSpec" : 
fcPanel = new CollectionSpecPanel ( ( PreferencesExt ) mainPrefs . node ( "collSpec" ) ) ; 
c = fcPanel ; 
case "DirectoryPartition" : 
dirPartPanel = new DirectoryPartitionPanel ( ( PreferencesExt ) mainPrefs . node ( "dirPartition" ) ) ; 
c = dirPartPanel ; 
case "NcStream" : 
ncStreamPanel = new NcStreamOpPanel ( ( PreferencesExt ) mainPrefs . node ( "NcStream" ) ) ; 
c = ncStreamPanel ; 
case "GRIB1collection" : 
grib1CollectionPanel = new Grib1CollectionOpPanel ( ( PreferencesExt ) mainPrefs . node ( "grib1raw" ) ) ; 
c = grib1CollectionPanel ; 
case "GRIB1data" : 
grib1DataPanel = new Grib1DataOpPanel ( ( PreferencesExt ) mainPrefs . node ( "grib1Data" ) ) ; 
c = grib1DataPanel ; 
case "GRIB-FILES" : 
gribFilesPanel = new GribFilesOpPanel ( ( PreferencesExt ) mainPrefs . node ( "gribFiles" ) ) ; 
c = gribFilesPanel ; 
case "GRIB2collection" : 
grib2CollectionPanel = new Grib2CollectionOpPanel ( ( PreferencesExt ) mainPrefs . node ( "gribNew" ) ) ; 
c = grib2CollectionPanel ; 
case "GRIB2data" : 
grib2DataPanel = new Grib2DataOpPanel ( ( PreferencesExt ) mainPrefs . node ( "grib2Data" ) ) ; 
c = grib2DataPanel ; 
case "BufrCdmIndex" : 
bufrCdmIndexPanel = new BufrCdmIndexOpPanel ( ( PreferencesExt ) mainPrefs . node ( "bufrCdmIdx" ) ) ; 
c = bufrCdmIndexPanel ; 
case "CdmIndex4" : 
cdmIndexPanel = new CdmIndexOpPanel ( ( PreferencesExt ) mainPrefs . node ( "cdmIdx3" ) ) ; 
c = cdmIndexPanel ; 
case "CdmIndexReport" : { 
PreferencesExt prefs = ( PreferencesExt ) mainPrefs . node ( "CdmIndexReport" ) ; 
ReportPanel rp = new CdmIndexReportPanel ( prefs ) ; 
cdmIndexReportPanel = new ReportOpPanel ( prefs , rp ) ; 
c = cdmIndexReportPanel ; 
case "GribIndex" : 
gribIdxPanel = new GribIndexOpPanel ( ( PreferencesExt ) mainPrefs . node ( "gribIdx" ) ) ; 
c = gribIdxPanel ; 
case "GRIB1-REPORT" : { 
PreferencesExt prefs = ( PreferencesExt ) mainPrefs . node ( "grib1Report" ) ; 
ReportPanel rp = new Grib1ReportPanel ( prefs ) ; 
grib1ReportPanel = new ReportOpPanel ( prefs , rp ) ; 
c = grib1ReportPanel ; 
case "GRIB2-REPORT" : { 
PreferencesExt prefs = ( PreferencesExt ) mainPrefs . node ( "gribReport" ) ; 
ReportPanel rp = new Grib2ReportPanel ( prefs ) ; 
grib2ReportPanel = new ReportOpPanel ( prefs , rp ) ; 
c = grib2ReportPanel ; 
case "WMO-COMMON" : 
wmoCommonCodePanel = new WmoCCPanel ( ( PreferencesExt ) mainPrefs . node ( "wmo-common" ) ) ; 
c = wmoCommonCodePanel ; 
case "WMO-CODES" : 
gribCodePanel = new GribCodePanel ( ( PreferencesExt ) mainPrefs . node ( "wmo-codes" ) ) ; 
c = gribCodePanel ; 
case "WMO-TEMPLATES" : 
gribTemplatePanel = new GribTemplatePanel ( ( PreferencesExt ) mainPrefs . node ( "wmo-templates" ) ) ; 
c = gribTemplatePanel ; 
case "GRIB1-TABLES" : 
grib1TablePanel = new Grib1TablePanel ( ( PreferencesExt ) mainPrefs . node ( "grib1-tables" ) ) ; 
c = grib1TablePanel ; 
case "GRIB2-TABLES" : 
grib2TablePanel = new Grib2TablePanel ( ( PreferencesExt ) mainPrefs . node ( "grib2-tables" ) ) ; 
c = grib2TablePanel ; 
case "GRIB-Rewrite" : 
gribRewritePanel = new GribRewriteOpPanel ( ( PreferencesExt ) mainPrefs . node ( "grib-rewrite" ) ) ; 
c = gribRewritePanel ; 
case "CoordSys" : 
coordSysPanel = new CoordSysPanel ( ( PreferencesExt ) mainPrefs . node ( "CoordSys" ) ) ; 
c = coordSysPanel ; 
case "FeatureScan" : 
ftPanel = new FeatureScanPanel ( ( PreferencesExt ) mainPrefs . node ( "ftPanel" ) ) ; 
c = ftPanel ; 
case "GeoTiff" : 
geotiffPanel = new GeotiffPanel ( ( PreferencesExt ) mainPrefs . node ( "WCS" ) ) ; 
c = geotiffPanel ; 
case "Grids" : 
gridPanel = new GeoGridPanel ( ( PreferencesExt ) mainPrefs . node ( "grid" ) ) ; 
c = gridPanel ; 
case "SimpleGeometry" : 
simpleGeomPanel = new SimpleGeomPanel ( ( PreferencesExt ) mainPrefs . node ( "simpleGeom" ) ) ; 
c = simpleGeomPanel ; 
case "Coverages" : 
coveragePanel = new CoveragePanel ( ( PreferencesExt ) mainPrefs . node ( "coverage2" ) ) ; 
c = coveragePanel ; 
case "HDF5-Objects" : 
hdf5ObjectPanel = new Hdf5ObjectPanel ( ( PreferencesExt ) mainPrefs . node ( "hdf5" ) ) ; 
c = hdf5ObjectPanel ; 
case "HDF5-Data" : 
hdf5DataPanel = new Hdf5DataPanel ( ( PreferencesExt ) mainPrefs . node ( "hdf5data" ) ) ; 
c = hdf5DataPanel ; 
case "Netcdf4-JNI" : 
nc4viewer = new DatasetViewerPanel ( ( PreferencesExt ) mainPrefs . node ( "nc4viewer" ) , true ) ; 
c = nc4viewer ; 
case "HDF4" : 
hdf4Panel = new Hdf4Panel ( ( PreferencesExt ) mainPrefs . node ( "hdf4" ) ) ; 
c = hdf4Panel ; 
case "Images" : 
imagePanel = new ImagePanel ( ( PreferencesExt ) mainPrefs . node ( "images" ) ) ; 
c = imagePanel ; 
case "Fmrc" : 
fmrcPanel = new FmrcPanel ( ( PreferencesExt ) mainPrefs . node ( "fmrc2" ) ) ; 
c = fmrcPanel ; 
case "Collections" : 
fmrcCollectionPanel = new FmrcCollectionPanel ( ( PreferencesExt ) mainPrefs . node ( "collections" ) ) ; 
c = fmrcCollectionPanel ; 
case "NCDump" : 
ncdumpPanel = new NCdumpPanel ( ( PreferencesExt ) mainPrefs . node ( "NCDump" ) ) ; 
c = ncdumpPanel ; 
case "NcmlEditor" : 
ncmlEditorPanel = new NcmlEditorPanel ( ( PreferencesExt ) mainPrefs . node ( "NcmlEditor" ) ) ; 
c = ncmlEditorPanel ; 
case "PointFeature" : 
pointFeaturePanel = new PointFeaturePanel ( ( PreferencesExt ) mainPrefs . node ( "pointFeature" ) ) ; 
c = pointFeaturePanel ; 
case "Radial" : 
radialPanel = new RadialPanel ( ( PreferencesExt ) mainPrefs . node ( "radial" ) ) ; 
c = radialPanel ; 
case "StationRadial" : 
stationRadialPanel = new StationRadialPanel ( ( PreferencesExt ) mainPrefs . node ( "stationRadar" ) ) ; 
c = stationRadialPanel ; 
case "THREDDS" : 
threddsUI = new ThreddsUI ( parentFrame , ( PreferencesExt ) mainPrefs . node ( "thredds" ) ) ; 
threddsUI . addPropertyChangeListener ( new PropertyChangeListener ( ) { 
public void propertyChange ( PropertyChangeEvent e ) { 
if ( e . getPropertyName ( ) . equals ( "InvAccess" ) ) { 
thredds . client . catalog . Access access = ( thredds . client . catalog . Access ) e . getNewValue ( ) ; 
jumptoThreddsDatatype ( access ) ; 
if ( e . getPropertyName ( ) . equals ( "Dataset" ) || e . getPropertyName ( ) . equals ( "CoordSys" ) || e . getPropertyName ( ) . equals ( "File" ) ) { 
thredds . client . catalog . Dataset ds = ( thredds . client . catalog . Dataset ) e . getNewValue ( ) ; 
setThreddsDatatype ( ds , e . getPropertyName ( ) ) ; 
c = threddsUI ; 
case "Units" : 
unitsPanel = new UnitsPanel ( ( PreferencesExt ) mainPrefs . node ( "units" ) ) ; 
c = unitsPanel ; 
case "URLdump" : 
urlPanel = new URLDumpPane ( ( PreferencesExt ) mainPrefs . node ( "urlDump" ) ) ; 
c = urlPanel ; 
case "Viewer" : 
c = viewerPanel ; 
case "Writer" : 
writerPanel = new DatasetWriterPanel ( ( PreferencesExt ) mainPrefs . node ( "writer" ) ) ; 
c = writerPanel ; 
case "WMS" : 
wmsPanel = new WmsPanel ( ( PreferencesExt ) mainPrefs . node ( "wms" ) ) ; 
c = wmsPanel ; 
parent . setComponentAt ( idx , c ) ; 
} private void setThreddsDatatype ( thredds . client . catalog . Dataset invDataset , String wants ) { 
if ( invDataset == null ) return ; 
boolean wantsViewer = wants . equals ( "File" ) ; 
boolean wantsCoordSys = wants . equals ( "CoordSys" ) ; 
if ( wantsViewer ) { 
openNetcdfFile ( threddsDataFactory . openDataset ( invDataset , true , null , null ) ) ; 
if ( wantsCoordSys ) { 
NetcdfDataset ncd = threddsDataFactory . openDataset ( invDataset , true , null , null ) ; 
openCoordSystems ( ncd ) ; 
DataFactory . Result threddsData = threddsDataFactory . openFeatureDataset ( invDataset , null ) ; 
if ( threddsData . fatalError ) { 
jumptoThreddsDatatype ( threddsData ) ; 
} private void jumptoThreddsDatatype ( thredds . client . catalog . Access invAccess ) { 
if ( invAccess == null ) { 
thredds . client . catalog . Service s = invAccess . getService ( ) ; 
if ( s . getType ( ) == ServiceType . HTTPServer ) { 
downloadFile ( invAccess . getStandardUrlName ( ) ) ; 
if ( s . getType ( ) == ServiceType . WMS ) { 
openWMSDataset ( invAccess . getStandardUrlName ( ) ) ; 
if ( s . getType ( ) == ServiceType . CdmrFeature ) { 
openCoverageDataset ( invAccess . getWrappedUrlName ( ) ) ; 
thredds . client . catalog . Dataset ds = invAccess . getDataset ( ) ; 
openNetcdfFile ( threddsDataFactory . openDataset ( invAccess , true , null , null ) ) ; 
DataFactory . Result threddsData = null ; 
threddsData = threddsDataFactory . openFeatureDataset ( invAccess , null ) ; 
if ( threddsData != null ) { 
threddsData . close ( ) ; 
catch ( IOException ioe2 ) { 
} private void jumptoThreddsDatatype ( DataFactory . Result threddsData ) { 
if ( threddsData . featureType . isCoverageFeatureType ( ) ) { 
if ( threddsData . featureDataset instanceof FeatureDatasetCoverage ) { 
makeComponent ( ftTabPane , "Coverages" ) ; 
coveragePanel . setDataset ( threddsData . featureDataset ) ; 
tabbedPane . setSelectedComponent ( ftTabPane ) ; 
ftTabPane . setSelectedComponent ( coveragePanel ) ; 
else if ( threddsData . featureDataset instanceof GridDataset ) { 
makeComponent ( ftTabPane , "Grids" ) ; 
gridPanel . setDataset ( ( GridDataset ) threddsData . featureDataset ) ; 
ftTabPane . setSelectedComponent ( gridPanel ) ; 
else if ( threddsData . featureType == FeatureType . IMAGE ) { 
makeComponent ( ftTabPane , "Images" ) ; 
imagePanel . setImageLocation ( threddsData . imageURL ) ; 
ftTabPane . setSelectedComponent ( imagePanel ) ; 
else if ( threddsData . featureType == FeatureType . RADIAL ) { 
makeComponent ( ftTabPane , "Radial" ) ; 
radialPanel . setDataset ( ( RadialDatasetSweep ) threddsData . featureDataset ) ; 
ftTabPane . setSelectedComponent ( radialPanel ) ; 
else if ( threddsData . featureType . isPointFeatureType ( ) ) { 
makeComponent ( ftTabPane , "PointFeature" ) ; 
pointFeaturePanel . setPointFeatureDataset ( ( PointDatasetImpl ) threddsData . featureDataset ) ; 
ftTabPane . setSelectedComponent ( pointFeaturePanel ) ; 
else if ( threddsData . featureType == FeatureType . STATION_RADIAL ) { 
makeComponent ( ftTabPane , "StationRadial" ) ; 
stationRadialPanel . setStationRadialDataset ( threddsData . featureDataset ) ; 
ftTabPane . setSelectedComponent ( stationRadialPanel ) ; 
} private static void setDataset ( ) { 
SwingUtilities . invokeLater ( ( ) -> { 
int pos = wantDataset . indexOf ( '#' ) ; 
final String catName = wantDataset . substring ( 0 , pos ) ; 
if ( catName . endsWith ( ".xml" ) ) { 
ui . makeComponent ( null , "THREDDS" ) ; 
ui . threddsUI . setDataset ( wantDataset ) ; 
ui . tabbedPane . setSelectedComponent ( ui . threddsUI ) ; 
ui . openNetcdfFile ( wantDataset ) ; 
} private static void prepareGui ( ) { 
final String osName = System . getProperty ( "os.name" ) . toLowerCase ( ) ; 
if ( isMacOs ) { 
System . setProperty ( "apple.laf.useScreenMenuBar" , "true" ) ; 
doSavePrefsAndUI ( ) ; 
for ( UIManager . LookAndFeelInfo info : UIManager . getInstalledLookAndFeels ( ) ) { 
if ( "Nimbus" . equals ( info . getName ( ) ) ) { 
UIManager . setLookAndFeel ( info . getClassName ( ) ) ; 
catch ( Exception exc ) { 
if ( log . isTraceEnabled ( ) ) { 
exc . printStackTrace ( ) ; 
final Toolkit tk = Toolkit . getDefaultToolkit ( ) ; 
final Font f = new Font ( "SansSerif" , Font . PLAIN , 12 ) ; 
@ SuppressWarnings ( "deprecation" ) 
final FontMetrics fm = tk . getFontMetrics ( f ) ; 
} private static void createToolsFrame ( ) { 
ui = new ToolsUI ( prefs , frame ) ; 
public void windowActivated ( final WindowEvent e ) { 
ToolsSplashScreen . getSharedInstance ( ) . setVisible ( false ) ; 
public void windowClosing ( final WindowEvent e ) { 
if ( ! done ) { 
exit ( ) ; 
final Rectangle have = frame . getGraphicsConfiguration ( ) . getBounds ( ) ; 
final Rectangle def = new Rectangle ( 50 , 50 , 800 , 800 ) ; 
Rectangle want = ( Rectangle ) prefs . getBean ( FRAME_SIZE , def ) ; 
if ( want . getX ( ) > have . getWidth ( ) - 25 ) { 
want = def ; 
frame . setBounds ( want ) ; 
if ( wantDataset != null ) { 
setDataset ( ) ; 
String aphString = this . getResultService ( ) . getAccessPointHeader ( ) ; 
String apString = this . getAccessPoint ( ) ; 
if ( ! apString . startsWith ( aphString ) ) 
String apVersionString = apString + "version" ; 
String apVersionResultContent = null ; 
apVersionResultContent = urlExtractor . getTextContent ( apVersionString ) ; 
catch ( java . io . IOException e ) 
IOException myE = new IOException ( tmpMsg + e . getMessage ( ) ) ; 
myE . initCause ( e ) ; 
throw ( myE ) ; 
if ( apVersionResultContent . indexOf ( "DODS" ) == - 1 && 
apVersionResultContent . indexOf ( "OPeNDAP" ) == - 1 && 
apVersionResultContent . indexOf ( "DAP" ) == - 1 ) 
throw new IOException ( tmpMsg ) ; 
accessPointHeaderUri = new URI ( aphString ) ; 
DodsDirInvDataset topDs = null ; 
topDs = new DodsDirInvDataset ( null , new URI ( apString ) ) ; 
List dsList = new ArrayList ( ) ; 
List possibleDsList = null ; 
possibleDsList = urlExtractor . extract ( dataset . getName ( ) ) ; 
return ( dsList ) ; 
String curDsUrlString = null ; 
URI curDsUri = null ; 
for ( Iterator it = possibleDsList . iterator ( ) ; it . hasNext ( ) ; ) 
curDsUrlString = ( String ) it . next ( ) ; 
if ( ( ! curDsUrlString . endsWith ( ".html" ) ) && ( ! curDsUrlString . endsWith ( "/" ) ) ) 
if ( curDsUrlString . endsWith ( ".html" ) ) 
curDsUrlString = curDsUrlString . substring ( 0 , curDsUrlString . length ( ) - 5 ) ; 
if ( ! curDsUrlString . startsWith ( this . accessPointHeaderUri . toString ( ) ) ) 
curDsUri = new URI ( curDsUrlString ) ; 
curDs = new DodsDirInvDataset ( null , curDsUri ) ; 
dsList . add ( curDs ) ; 
} static public String makeName ( List < CoordinateAxis > axes ) { 
List < CoordinateAxis > axesSorted = new ArrayList < > ( axes ) ; 
Collections . sort ( axesSorted , new CoordinateAxis . AxisComparator ( ) ) ; 
for ( int i = 0 ; i < axesSorted . size ( ) ; i ++ ) { 
CoordinateAxis axis = axesSorted . get ( i ) ; 
buff . append ( axis . getFullNameEscaped ( ) ) ; 
} private CoordinateAxis lesserRank ( CoordinateAxis a1 , CoordinateAxis a2 ) { 
if ( a1 == null ) return a2 ; 
return ( a1 . getRank ( ) <= a2 . getRank ( ) ) ? a1 : a2 ; 
} public CoordinateAxis findAxis ( AxisType type ) { 
CoordinateAxis result = null ; 
for ( CoordinateAxis axis : coordAxes ) { 
if ( ( axisType != null ) && ( axisType == type ) ) 
result = lesserRank ( result , axis ) ; 
} public ProjectionCT getProjectionCT ( ) { 
for ( CoordinateTransform ct : coordTrans ) { 
if ( ct instanceof ProjectionCT ) 
return ( ProjectionCT ) ct ; 
} public ProjectionImpl getProjection ( ) { 
if ( projection == null ) { 
if ( isLatLon ( ) ) projection = new LatLonProjection ( ) ; 
ProjectionCT projCT = getProjectionCT ( ) ; 
if ( null != projCT ) projection = projCT . getProjection ( ) ; 
} public boolean isGeoXY ( ) { 
if ( ( xAxis == null ) || ( yAxis == null ) ) return false ; 
return null != getProjection ( ) && ! ( projection instanceof LatLonProjection ) ; 
} public boolean isRegular ( ) { 
if ( ! ( axis instanceof CoordinateAxis1D ) ) return false ; 
if ( ! ( ( CoordinateAxis1D ) axis ) . isRegular ( ) ) return false ; 
} public static boolean isSubset ( Collection < Dimension > subset , Collection < Dimension > set ) { 
for ( Dimension d : subset ) { 
if ( ! ( set . contains ( d ) ) ) 
} public boolean containsAxes ( List < CoordinateAxis > wantAxes ) { 
for ( CoordinateAxis ca : wantAxes ) { 
if ( ! containsAxis ( ca . getFullName ( ) ) ) 
} public boolean containsAxis ( String axisName ) { 
for ( CoordinateAxis ca : coordAxes ) { 
if ( ca . getFullName ( ) . equals ( axisName ) ) 
} public boolean containsDomain ( List < Dimension > wantDimensions ) { 
for ( Dimension d : wantDimensions ) { 
if ( ! domain . contains ( d ) ) 
} public boolean containsAxisTypes ( List < AxisType > wantAxes ) { 
for ( AxisType wantAxisType : wantAxes ) { 
if ( ! containsAxisType ( wantAxisType ) ) return false ; 
} public boolean containsAxisType ( AxisType wantAxisType ) { 
if ( ca . getAxisType ( ) == wantAxisType ) return true ; 
} static public DAPNode cloneDAG ( CloneMap map , DAPNode src ) 
DAPNode bt = map . nodes . get ( src ) ; 
if ( bt == null ) 
bt = src . cloneDAG ( map ) ; 
DAPNode node = ( DAPNode ) super . clone ( ) ; 
map . nodes . put ( this , node ) ; 
DAPNode tmp = map . nodes . get ( _myParent ) ; 
if ( tmp != node ) 
_myParent = tmp ; 
} public void sendDataRequestForm ( ReqState rs , 
int suffixIndex = rs . getRequest ( ) . getRequestURL ( ) . toString ( ) . lastIndexOf ( "." ) ; 
requestURL = rs . getRequest ( ) . getRequestURL ( ) . substring ( 0 , suffixIndex ) ; 
pw = new PrintWriter ( new OutputStreamWriter ( rs . getResponse ( ) . getOutputStream ( ) , Util . UTF8 ) ) ; 
+ "support@unidata.ucar.edu" 
+ "</a></address>" 
+ "</body></html>\n" 
} private static TypeAndOrder findTao ( int center , String key ) { 
Map < String , BufrCdmIndexProto . FldType > local = locals . get ( center ) ; 
BufrCdmIndexProto . FldType result = local . get ( key ) ; 
if ( result != null ) return new TypeAndOrder ( result , - 1 ) ; 
return fld2type . get ( key ) ; 
} public static StandardFieldsFromMessage extract ( Message m ) throws IOException { 
StandardFieldsFromMessage result = new StandardFieldsFromMessage ( ) ; 
extract ( m . ids . getCenterId ( ) , m . getRootDataDescriptor ( ) , result ) ; 
} public String getToolTipText ( MouseEvent event ) { 
String text = super . getToolTipText ( event ) ; 
listenerList . add ( javax . swing . event . ListSelectionListener . class , l ) ; 
listenerList . remove ( javax . swing . event . ListSelectionListener . class , l ) ; 
} public Object getSelectedBean ( ) { 
int viewRowIndex = jtable . getSelectedRow ( ) ; 
if ( viewRowIndex < 0 ) 
int modelRowIndex = jtable . convertRowIndexToModel ( viewRowIndex ) ; 
return ( modelRowIndex < 0 ) || ( modelRowIndex >= beans . size ( ) ) ? null : beans . get ( modelRowIndex ) ; 
} public List getSelectedBeans ( ) { 
ArrayList < Object > list = new ArrayList < > ( ) ; 
int [ ] viewRowIndices = jtable . getSelectedRows ( ) ; 
for ( int viewRowIndex : viewRowIndices ) { 
list . add ( beans . get ( modelRowIndex ) ) ; 
} public ArrayList < Object > getSelectedCells ( ) { 
int [ ] viewColumnIndices = jtable . getSelectedColumns ( ) ; 
for ( int i = 0 ; i < viewRowIndices . length ; i ++ ) 
for ( int j = 0 ; i < viewColumnIndices . length ; j ++ ) { 
int modelRowIndex = jtable . convertRowIndexToModel ( viewRowIndices [ i ] ) ; 
int modelColumnIndex = jtable . convertColumnIndexToModel ( viewColumnIndices [ j ] ) ; 
list . add ( model . getValueAt ( modelRowIndex , modelColumnIndex ) ) ; 
} public void clearSelectedCells ( ) { 
TableColumnModel tcm = jtable . getColumnModel ( ) ; 
for ( int viewColumnIndex : viewColumnIndices ) { 
TableColumn tc = tcm . getColumn ( viewColumnIndex ) ; 
int modelColumnIndex = tc . getModelIndex ( ) ; 
Class colClass = jtable . getColumnClass ( viewColumnIndex ) ; 
Object zeroValue = model . zeroValue ( colClass ) ; 
model . setValueAt ( zeroValue , modelRowIndex , modelColumnIndex ) ; 
} public void setSelectedBean ( Object bean ) { 
if ( bean == null ) return ; 
int modelRowIndex = beans . indexOf ( bean ) ; 
int viewRowIndex = jtable . convertRowIndexToView ( modelRowIndex ) ; 
if ( viewRowIndex >= 0 ) 
jtable . getSelectionModel ( ) . setSelectionInterval ( viewRowIndex , viewRowIndex ) ; 
makeRowVisible ( viewRowIndex ) ; 
} public void setSelectedBeans ( List want ) { 
jtable . getSelectionModel ( ) . clearSelection ( ) ; 
for ( Object bean : want ) { 
if ( viewRowIndex >= 0 ) { 
jtable . getSelectionModel ( ) . addSelectionInterval ( viewRowIndex , viewRowIndex ) ; 
} public void saveState ( boolean saveData ) { 
if ( saveData ) { 
store . putBeanCollection ( "beanList" , beans ) ; 
List < PropertyCol > propCols = new ArrayList < > ( ) ; 
HidableTableColumnModel tableColumnModel = ( HidableTableColumnModel ) jtable . getColumnModel ( ) ; 
Enumeration < TableColumn > columns = tableColumnModel . getColumns ( false ) ; 
while ( columns . hasMoreElements ( ) ) { 
PropertyCol propCol = new PropertyCol ( ) ; 
TableColumn column = columns . nextElement ( ) ; 
propCol . setName ( column . getIdentifier ( ) . toString ( ) ) ; 
propCol . setWidth ( column . getWidth ( ) ) ; 
propCol . setVisible ( tableColumnModel . isColumnVisible ( column ) ) ; 
propCols . add ( propCol ) ; 
store . putBeanCollection ( "propertyCol" , propCols ) ; 
} public void fireBeanDataChanged ( Object bean ) { 
int row = beans . indexOf ( bean ) ; 
if ( row >= 0 ) { 
model . fireTableRowsUpdated ( row , row ) ; 
} protected void restoreState ( ) { 
if ( store == null ) { 
ArrayList propColObjs = ( ArrayList ) store . getBean ( "propertyCol" , new ArrayList ( ) ) ; 
int newViewIndex = 0 ; 
for ( Object propColObj : propColObjs ) { 
PropertyCol propCol = ( PropertyCol ) propColObj ; 
int currentViewIndex = tableColumnModel . getColumnIndex ( propCol . getName ( ) ) ; 
TableColumn column = tableColumnModel . getColumn ( currentViewIndex ) ; 
column . setPreferredWidth ( propCol . getWidth ( ) ) ; 
tableColumnModel . moveColumn ( currentViewIndex , newViewIndex ) ; 
tableColumnModel . setColumnVisible ( column , propCol . isVisible ( ) ) ; 
if ( propCol . isVisible ( ) ) { 
++ newViewIndex ; 
logger . debug ( String . format ( 
} static public Class 
cdmElementClass ( DataType dt ) 
switch ( dt ) { 
case BOOLEAN : 
return boolean . class ; 
return byte . class ; 
return char . class ; 
return short . class ; 
return int . class ; 
return long . class ; 
return float . class ; 
return double . class ; 
return String . class ; 
return ByteBuffer . class ; 
attributeParse ( DataType cdmtype , EnumTypedef en , Object o ) 
String so = o . toString ( ) ; 
if ( en != null ) { 
switch ( cdmtype ) { 
if ( ! ( o instanceof Integer ) ) 
throw new ConversionException ( o . toString ( ) ) ; 
int eval = ( Integer ) o ; 
String econst = en . lookupEnumString ( eval ) ; 
if ( econst == null ) 
return econst ; 
long lval = 0 ; 
double dval = 0.0 ; 
boolean islong = true ; 
boolean isdouble = true ; 
lval = Long . parseLong ( so ) ; 
islong = false ; 
dval = Double . parseDouble ( so ) ; 
isdouble = false ; 
o = null ; 
if ( so . equalsIgnoreCase ( "false" ) 
|| ( islong && lval == 0 ) ) 
o = Boolean . FALSE ; 
o = Boolean . TRUE ; 
if ( islong ) o = Byte . valueOf ( ( byte ) lval ) ; 
if ( islong ) o = Short . valueOf ( ( short ) lval ) ; 
if ( islong ) o = Integer . valueOf ( ( int ) lval ) ; 
if ( islong ) o = Long . valueOf ( lval ) ; 
if ( islong ) o = Byte . valueOf ( ( byte ) ( lval & 0xFFL ) ) ; 
if ( islong ) o = Short . valueOf ( ( short ) ( lval & 0xFFFFL ) ) ; 
if ( islong ) o = Integer . valueOf ( ( int ) ( lval & 0xFFFFFFFFL ) ) ; 
BigInteger bi = new BigInteger ( so ) ; 
bi = bi . and ( LONGMASK ) ; 
o = ( Long ) bi . longValue ( ) ; 
if ( islong && ! isdouble ) { 
dval = ( double ) lval ; 
isdouble = true ; 
if ( isdouble ) o = ( Float ) ( ( float ) dval ) ; 
if ( isdouble ) o = ( Double ) ( dval ) ; 
return so ; 
if ( so . startsWith ( "0x" ) || so . startsWith ( "0X" ) ) 
so = so . substring ( 2 ) ; 
bi = new BigInteger ( so , 16 ) ; 
byte [ ] bb = bi . toByteArray ( ) ; 
o = ByteBuffer . wrap ( bb ) ; 
} public static UnknownUnit create ( String name ) throws NameException { 
UnknownUnit unit ; 
name = name . toLowerCase ( ) ; 
unit = map . get ( name ) ; 
unit = new UnknownUnit ( name ) ; 
map . put ( unit . getName ( ) , unit ) ; 
map . put ( unit . getPlural ( ) , unit ) ; 
public void close ( ) throws IOException 
consume ( ) ; 
if ( method != null ) method . close ( ) ; 
} private boolean isExtra ( Variable v ) { 
return v != null && extras != null && extras . contains ( v ) ; 
} private boolean isCoordinate ( Variable v ) { 
if ( v == null ) return false ; 
return ( latVE != null && latVE . axisName . equals ( name ) ) || 
( lonVE != null && lonVE . axisName . equals ( name ) ) || 
( altVE != null && altVE . axisName . equals ( name ) ) || 
( stnAltVE != null && stnAltVE . axisName . equals ( name ) ) || 
( timeVE != null && timeVE . axisName . equals ( name ) ) || 
( nomTimeVE != null && nomTimeVE . axisName . equals ( name ) ) ; 
} private CoordVarExtractor findCoordinateAxis ( Table . CoordName coordName , Table t , int nestingLevel ) { 
if ( t == null ) return null ; 
String axisName = t . findCoordinateVariableName ( coordName ) ; 
if ( axisName != null ) { 
VariableDS v = t . findVariable ( axisName ) ; 
return new CoordVarExtractorVariable ( v , axisName , nestingLevel ) ; 
if ( t . extraJoins != null ) { 
for ( Join j : t . extraJoins ) { 
v = j . findVariable ( axisName ) ; 
if ( t instanceof Table . TableSingleton ) { 
Table . TableSingleton ts = ( Table . TableSingleton ) t ; 
return new CoordVarStructureData ( axisName , ts . sdata ) ; 
if ( t instanceof Table . TableTop ) { 
v = ( VariableDS ) ds . findVariable ( axisName ) ; 
return new CoordVarTop ( v ) ; 
return new CoordVarConstant ( coordName . toString ( ) , "" , axisName ) ; 
return findCoordinateAxis ( coordName , t . parent , nestingLevel + 1 ) ; 
} private void addDataVariables ( List < VariableSimpleIF > list , Table t ) { 
if ( t . parent != null ) addDataVariables ( list , t . parent ) ; 
for ( VariableSimpleIF col : t . cols . values ( ) ) { 
if ( t . nondataVars . contains ( col . getFullName ( ) ) ) continue ; 
if ( t . nondataVars . contains ( col . getShortName ( ) ) ) continue ; 
list . add ( col ) ; 
} void addParentJoin ( Cursor cursor ) throws IOException { 
int level = cursor . currentIndex ; 
Table t = getTable ( level ) ; 
List < StructureData > sdata = new ArrayList < > ( 3 ) ; 
sdata . add ( cursor . tableData [ level ] ) ; 
sdata . add ( j . getJoinData ( cursor ) ) ; 
cursor . tableData [ level ] = StructureDataFactory . make ( sdata . toArray ( new StructureData [ sdata . size ( ) ] ) ) ; 
} public StructureDataIterator getStationDataIterator ( ) throws IOException { 
Table stationTable = root ; 
StructureDataIterator siter = stationTable . getStructureDataIterator ( null ) ; 
if ( stationTable . limit != null ) { 
Variable limitV = ds . findVariable ( stationTable . limit ) ; 
int limit = limitV . readScalarInt ( ) ; 
return new StructureDataIteratorLimited ( siter , limit ) ; 
return siter ; 
} StationFeature makeStation ( StructureData stationData ) { 
if ( stnVE . isMissing ( stationData ) ) return null ; 
String stationName = stnVE . getCoordValueAsString ( stationData ) ; 
String stationDesc = ( stnDescVE == null ) ? "" : stnDescVE . getCoordValueAsString ( stationData ) ; 
String stnWmoId = ( wmoVE == null ) ? "" : wmoVE . getCoordValueAsString ( stationData ) ; 
double lat = latVE . getCoordValue ( stationData ) ; 
double lon = lonVE . getCoordValue ( stationData ) ; 
double elev = ( stnAltVE == null ) ? Double . NaN : stnAltVE . getCoordValue ( stationData ) ; 
if ( Double . isNaN ( lat ) || Double . isNaN ( lon ) ) return null ; 
return new StationFeatureImpl ( stationName , stationDesc , stnWmoId , lat , lon , elev , - 1 , stationData ) ; 
} public NodeMap < CDMNode , DapNode > 
Group cdmroot = ncfile . getRootGroup ( ) ; 
this . nodemap . put ( cdmroot , this . dmr ) ; 
fillGroup ( cdmroot , this . dmr , ncfile ) ; 
return this . nodemap ; 
createVar ( DapVariable dapvar , NetcdfFile ncfile , 
Group cdmgroup , Structure cdmparentstruct ) 
Variable cdmvar = null ; 
DapType basetype = dapvar . getBaseType ( ) ; 
if ( basetype . isAtomic ( ) ) { 
DapVariable atomvar = ( DapVariable ) dapvar ; 
cdmvar = new Variable ( ncfile , 
cdmgroup , 
cdmparentstruct , 
atomvar . getShortName ( ) ) ; 
DataType cdmbasetype ; 
if ( basetype . isEnumType ( ) ) 
cdmbasetype = CDMTypeFcns . enumTypeFor ( basetype ) ; 
cdmbasetype = CDMTypeFcns . daptype2cdmtype ( basetype ) ; 
if ( cdmbasetype == null ) 
cdmvar . setDataType ( cdmbasetype ) ; 
EnumTypedef cdmenum = ( EnumTypedef ) this . nodemap . get ( basetype ) ; 
if ( cdmenum == null ) 
cdmvar . setEnumTypedef ( cdmenum ) ; 
this . nodemap . put ( cdmvar , dapvar ) ; 
} else if ( basetype . isStructType ( ) ) { 
DapStructure dapstruct = ( DapStructure ) basetype ; 
Structure cdmstruct = new Structure ( ncfile , 
dapstruct . getShortName ( ) ) ; 
cdmvar = cdmstruct ; 
for ( DapVariable field : dapstruct . getFields ( ) ) { 
createVar ( field , ncfile , cdmgroup , cdmstruct ) ; 
} else if ( basetype . isSeqType ( ) ) { 
DapSequence dapseq = ( DapSequence ) basetype ; 
Sequence cdmseq = new Sequence ( ncfile , 
dapseq . getShortName ( ) ) ; 
cdmvar = cdmseq ; 
for ( DapVariable field : dapseq . getFields ( ) ) { 
createVar ( field , ncfile , cdmgroup , cdmseq ) ; 
if ( dapvar . getRank ( ) > 0 ) { 
List value = new ArrayList ( ) ; 
Attribute warning = new Attribute ( "_WARNING:" , value ) ; 
cdmvar . addAttribute ( warning ) ; 
int rank = dapvar . getRank ( ) ; 
List < Dimension > cdmdims = new ArrayList < Dimension > ( rank + 1 ) ; 
for ( int i = 0 ; i < rank ; i ++ ) { 
DapDimension dim = dapvar . getDimension ( i ) ; 
Dimension cdmdim = createDimensionRef ( dim , cdmgroup ) ; 
cdmdims . add ( cdmdim ) ; 
if ( basetype . isSeqType ( ) ) { 
cdmdims . add ( Dimension . VLEN ) ; 
cdmvar . setDimensions ( cdmdims ) ; 
for ( String key : dapvar . getAttributes ( ) . keySet ( ) ) { 
DapAttribute attr = dapvar . getAttributes ( ) . get ( key ) ; 
Attribute cdmattr = createAttribute ( attr ) ; 
cdmvar . addAttribute ( cdmattr ) ; 
if ( cdmparentstruct != null ) 
cdmparentstruct . addMemberVariable ( cdmvar ) ; 
else if ( cdmgroup != null ) 
cdmgroup . addVariable ( cdmvar ) ; 
note ( Notes note ) 
assert ( this . allnotes != null ) ; 
int gid = note . gid ; 
int id = note . id ; 
NoteSort sort = note . getSort ( ) ; 
Map < Long , Notes > sortnotes = this . allnotes . get ( sort ) ; 
assert sortnotes != null ; 
assert sortnotes . get ( id ) == null ; 
sortnotes . put ( ( long ) id , note ) ; 
long gv = Nc4Notes . getVarId ( ( VarNotes ) note ) ; 
assert sortnotes . get ( gv ) == null ; 
sortnotes . put ( gv , note ) ; 
} VarNotes 
findVar ( int gid , int varid ) 
long gv = Nc4Notes . getVarId ( gid , varid , - 1 ) ; 
return ( VarNotes ) find ( gv , NoteSort . VAR ) ; 
findField ( int gid , int varid , int fid ) 
long gv = Nc4Notes . getVarId ( gid , varid , fid ) ; 
} Notes 
find ( DapNode node ) 
NoteSort sort = noteSortFor ( node ) ; 
for ( Map . Entry < Long , Notes > entries : sortnotes . entrySet ( ) ) { 
Notes note = entries . getValue ( ) ; 
if ( note . get ( ) == node ) 
public Nc4DSP 
open ( String filepath ) 
if ( filepath . startsWith ( "file:" ) ) try { 
XURI xuri = new XURI ( filepath ) ; 
filepath = xuri . getPath ( ) ; 
int ret , mode ; 
IntByReference ncidp = new IntByReference ( ) ; 
this . filepath = filepath ; 
mode = NC_NOWRITE ; 
Nc4Cursor . errcheck ( nc4 , ret = nc4 . nc_open ( this . filepath , mode , ncidp ) ) ; 
this . ncid = ncidp . getValue ( ) ; 
IntByReference formatp = new IntByReference ( ) ; 
Nc4Cursor . errcheck ( nc4 , ret = nc4 . nc_inq_format ( ncid , formatp ) ) ; 
this . format = formatp . getValue ( ) ; 
this . filepath , ncid , this . format ) ; 
Nc4DMRCompiler dmrcompiler = new Nc4DMRCompiler ( this , ncid , dmrfactory ) ; 
setDMR ( dmrcompiler . compile ( ) ) ; 
System . err . println ( printDMR ( getDMR ( ) ) ) ; 
} static public String makeString ( byte [ ] b ) 
for ( count = 0 ; ( count < b . length && b [ count ] != 0 ) ; count ++ ) { 
return new String ( b , 0 , count , DapUtil . UTF8 ) ; 
} static public SimpleUnit factory ( String name ) { 
return factoryWithExceptions ( name ) ; 
} static public SimpleUnit factoryWithExceptions ( String name ) throws UnitException { 
UnitFormat format = UnitFormatManager . instance ( ) ; 
Unit uu = format . parse ( name ) ; 
if ( isTimeUnit ( uu ) ) return new TimeUnit ( name ) ; 
return new SimpleUnit ( uu ) ; 
} static protected Unit makeUnit ( String name ) throws UnitException { 
return format . parse ( name ) ; 
} static public boolean isCompatible ( String unitString1 , String unitString2 ) { 
Unit uu1 , uu2 ; 
uu1 = format . parse ( unitString1 ) ; 
uu2 = format . parse ( unitString2 ) ; 
return uu1 . isCompatible ( uu2 ) ; 
} static public boolean isCompatibleWithExceptions ( String unitString1 , String unitString2 ) throws UnitException { 
Unit uu1 = format . parse ( unitString1 ) ; 
Unit uu2 = format . parse ( unitString2 ) ; 
} static public boolean isDateUnit ( ucar . units . Unit uu ) { 
boolean ok = uu . isCompatible ( dateReferenceUnit ) ; 
uu . getConverterTo ( dateReferenceUnit ) ; 
} catch ( ConversionException e ) { 
} static public boolean isDateUnit ( String unitString ) { 
SimpleUnit su = factory ( unitString ) ; 
return su != null && isDateUnit ( su . getUnit ( ) ) ; 
} static public boolean isTimeUnit ( String unitString ) { 
return su != null && isTimeUnit ( su . getUnit ( ) ) ; 
} static public double getConversionFactor ( String inputUnitString , String outputUnitString ) throws IllegalArgumentException { 
SimpleUnit inputUnit = SimpleUnit . factory ( inputUnitString ) ; 
SimpleUnit outputUnit = SimpleUnit . factory ( outputUnitString ) ; 
return inputUnit . convertTo ( 1.0 , outputUnit ) ; 
} public double convertTo ( double value , SimpleUnit outputUnit ) throws IllegalArgumentException { 
return uu . convertTo ( value , outputUnit . getUnit ( ) ) ; 
} public boolean isCompatible ( String unitString ) { 
Unit uuWant ; 
uuWant = format . parse ( unitString ) ; 
return uu . isCompatible ( uuWant ) ; 
} public boolean isUnknownUnit ( ) { 
ucar . units . Unit uu = getUnit ( ) ; 
if ( uu instanceof ucar . units . UnknownUnit ) 
if ( uu instanceof ucar . units . DerivedUnit ) 
return isUnknownUnit ( ( ucar . units . DerivedUnit ) uu ) ; 
if ( uu instanceof ucar . units . ScaledUnit ) { 
ucar . units . ScaledUnit scu = ( ucar . units . ScaledUnit ) uu ; 
Unit u = scu . getUnit ( ) ; 
if ( u instanceof ucar . units . UnknownUnit ) 
if ( u instanceof ucar . units . DerivedUnit ) 
return isUnknownUnit ( ( ucar . units . DerivedUnit ) u ) ; 
} public double getValue ( ) { 
if ( ! ( uu instanceof ScaledUnit ) ) return Double . NaN ; 
ScaledUnit offset = ( ScaledUnit ) uu ; 
return offset . getScale ( ) ; 
} public TopLevelClause newRelOpClause ( int operator , 
SubClause lhs , 
List rhs ) 
throws DAP2ServerSideException { 
return new RelOpClause ( operator , 
lhs , 
rhs ) ; 
} public TopLevelClause newBoolFunctionClause ( String functionName , 
List children ) 
throws DAP2ServerSideException , 
NoSuchFunctionException { 
BoolFunction function = 
functionLibrary . getBoolFunction ( functionName ) ; 
if ( functionLibrary . getBTFunction ( functionName ) != null ) { 
throw new NoSuchFunctionException 
return new BoolFunctionClause ( function , 
children ) ; 
} public SubClause newBTFunctionClause ( String functionName , 
BTFunction function = 
functionLibrary . getBTFunction ( functionName ) ; 
if ( functionLibrary . getBoolFunction ( functionName ) != null ) { 
return new BTFunctionClause ( function , 
} public void writeRecord ( StationObsDatatype sobs , StructureData sdata ) throws IOException { 
for ( Variable v : recordVars ) { 
if ( timeName . equals ( v . getShortName ( ) ) ) { 
Date d = sobs . getObservationTimeAsDate ( ) ; 
int secs = ( int ) ( d . getTime ( ) / 1000 ) ; 
timeArray . set ( 0 , secs ) ; 
} else if ( parentName . equals ( v . getShortName ( ) ) ) { 
int stationIndex = stnList . indexOf ( sobs . getStation ( ) ) ; 
parentArray . set ( 0 , stationIndex ) ; 
v . setCachedData ( sdata . getArray ( v . getShortName ( ) ) , false ) ; 
ncfile . writeRecordData ( recordVars ) ; 
} public static void rewrite ( String fileIn , String fileOut , boolean inMemory , boolean sort ) throws IOException { 
StationObsDataset sobs = ( StationObsDataset ) TypedDatasetFactory . open ( FeatureType . STATION , ncd , null , errlog ) ; 
List < ucar . unidata . geoloc . Station > stns = sobs . getStations ( ) ; 
List < VariableSimpleIF > vars = sobs . getDataVariables ( ) ; 
writer . writeHeader ( stns , vars , - 1 ) ; 
if ( sort ) { 
for ( ucar . unidata . geoloc . Station s : stns ) { 
DataIterator iter = sobs . getDataIterator ( s ) ; 
StationObsDatatype sobsData = ( StationObsDatatype ) iter . nextData ( ) ; 
StructureData data = sobsData . getData ( ) ; 
writer . writeRecord ( sobsData , data ) ; 
DataIterator iter = sobs . getDataIterator ( 1000 * 1000 ) ; 
} public static java . awt . image . BufferedImage makeGrayscaleImage ( Array ma , IsMissingEvaluator missEval ) { 
if ( ma . getRank ( ) < 2 ) return null ; 
if ( ma . getRank ( ) == 3 ) 
ma = ma . reduce ( ) ; 
ma = ma . slice ( 0 , 0 ) ; 
int h = ma . getShape ( ) [ 0 ] ; 
int w = ma . getShape ( ) [ 1 ] ; 
DataBuffer dataBuffer = makeDataBuffer ( ma , missEval ) ; 
WritableRaster raster = WritableRaster . createInterleavedRaster ( dataBuffer , 
w , h , 
w , 
1 , 
new int [ ] { 0 } , 
ColorSpace cs = ColorSpace . getInstance ( ColorSpace . CS_GRAY ) ; 
ComponentColorModel colorModel = new ComponentColorModel ( cs , new int [ ] { 8 } , 
false , false , Transparency . OPAQUE , DataBuffer . TYPE_BYTE ) ; 
return new BufferedImage ( colorModel , raster , false , null ) ; 
} protected String translatePathToReletiveLocation ( String dsPath , String configPath ) { 
if ( dsPath == null ) return null ; 
if ( dsPath . length ( ) == 0 ) return null ; 
if ( dsPath . startsWith ( "/" ) ) 
dsPath = dsPath . substring ( 1 ) ; 
if ( ! dsPath . startsWith ( configPath ) ) 
String dataDir = dsPath . substring ( configPath . length ( ) ) ; 
if ( dataDir . startsWith ( "/" ) ) 
dataDir = dataDir . substring ( 1 ) ; 
return dataDir ; 
} public int crawl ( String catUrl , CancelTask task , PrintWriter out , Object context ) { 
InvCatalogImpl cat = catFactory . readXML ( catUrl ) ; 
if ( out != null ) { 
if ( isValid ) 
return crawl ( cat , task , out , context ) ; 
} public int crawl ( InvCatalogImpl cat , CancelTask task , PrintWriter out , Object context ) { 
countCatrefs = 0 ; 
for ( InvDataset ds : cat . getDatasets ( ) ) { 
if ( type == Type . all ) 
crawlDataset ( ds , task , out , context , true ) ; 
crawlDirectDatasets ( ds , task , out , context , true ) ; 
if ( ( task != null ) && task . isCancel ( ) ) break ; 
return 1 + countCatrefs ; 
} public void crawlDataset ( InvDataset ds , CancelTask task , PrintWriter out , Object context , boolean release ) { 
boolean isCatRef = ( ds instanceof InvCatalogRef ) ; 
if ( filter != null && filter . skipAll ( ds ) ) { 
if ( isCatRef && release ) ( ( InvCatalogRef ) ds ) . release ( ) ; 
boolean isDataScan = ds . findProperty ( "DatasetScan" ) != null ; 
if ( isCatRef ) { 
countCatrefs ++ ; 
if ( ! listen . getCatalogRef ( catref , context ) ) { 
if ( release ) catref . release ( ) ; 
if ( ! isCatRef || isDataScan ) 
listen . getDataset ( ds , context ) ; 
List < InvDataset > dlist = ds . getDatasets ( ) ; 
if ( ! isDataScan ) { 
listen . getDataset ( catref . getProxyDataset ( ) , context ) ; 
for ( InvDataset dds : dlist ) { 
crawlDataset ( dds , task , out , context , release ) ; 
if ( ( task != null ) && task . isCancel ( ) ) 
if ( isCatRef && release ) { 
catref . release ( ) ; 
} public void crawlDirectDatasets ( InvDataset ds , CancelTask task , PrintWriter out , Object context , boolean release ) { 
List < InvDataset > leaves = new ArrayList < InvDataset > ( ) ; 
if ( dds . hasAccess ( ) ) 
leaves . add ( dds ) ; 
if ( leaves . size ( ) > 0 ) { 
if ( type == Type . first_direct ) { 
InvDataset dds = leaves . get ( 0 ) ; 
listen . getDataset ( dds , context ) ; 
} else if ( type == Type . random_direct ) { 
listen . getDataset ( chooseRandom ( leaves ) , context ) ; 
} else if ( type == Type . random_direct_middle ) { 
listen . getDataset ( chooseRandomNotFirstOrLast ( leaves ) , context ) ; 
for ( InvDataset dds : leaves ) { 
if ( dds . hasNestedDatasets ( ) ) 
crawlDirectDatasets ( dds , task , out , context , release ) ; 
if ( ds instanceof InvCatalogRef && release ) { 
} public static File getFileOrCache ( String fileLocation ) { 
File result = getExistingFileOrCache ( fileLocation ) ; 
return getDiskCache2 ( ) . getFile ( fileLocation ) ; 
} public static File getExistingFileOrCache ( String fileLocation ) { 
File result = getDiskCache2 ( ) . getExistingFileOrCache ( fileLocation ) ; 
if ( result == null && Grib . debugGbxIndexOnly && fileLocation . endsWith ( ".gbx9.ncx4" ) ) { 
int length = fileLocation . length ( ) ; 
String maybeIndexAlreadyExists = fileLocation . substring ( 0 , length - 10 ) + ".ncx4" ; 
result = getDiskCache2 ( ) . getExistingFileOrCache ( maybeIndexAlreadyExists ) ; 
} public static DirectPositionType initPos ( DirectPositionType pos , StationTimeSeriesFeature stationFeat ) { 
pos . setListValue ( Arrays . asList ( 
stationFeat . getLatitude ( ) , stationFeat . getLongitude ( ) , stationFeat . getAltitude ( ) ) ) ; 
return pos ; 
} protected PasswordAuthentication getPasswordAuthentication ( ) 
if ( pwa == null ) throw new IllegalStateException ( ) ; 
serverF . setText ( getRequestingHost ( ) + ":" + getRequestingPort ( ) ) ; 
realmF . setText ( getRequestingPrompt ( ) ) ; 
dialog . setVisible ( true ) ; 
return new PasswordAuthentication ( pwa . getUserName ( ) , pwa . getPassword ( ) . toCharArray ( ) ) ; 
} public Credentials getCredentials ( AuthScope scope ) 
serverF . setText ( scope . getHost ( ) + ":" + scope . getPort ( ) ) ; 
String realmName = scope . getRealm ( ) ; 
if ( realmName == null ) { 
realmF . setText ( realmName ) ; 
UsernamePasswordCredentials upc = new UsernamePasswordCredentials ( pwa . getUserName ( ) , new String ( pwa . getPassword ( ) ) ) ; 
return upc ; 
} static public void setDebugLeaks ( boolean b ) { 
if ( b ) { 
count_openFiles . set ( 0 ) ; 
maxOpenFiles . set ( 0 ) ; 
allFiles = new HashSet < > ( 1000 ) ; 
debugLeaks = b ; 
} static public List < String > getAllFiles ( ) { 
if ( null == allFiles ) return null ; 
result . addAll ( allFiles ) ; 
} public synchronized void close ( ) throws IOException { 
if ( cacheState > 0 ) { 
if ( cacheState == 1 ) { 
cacheState = 2 ; 
if ( cache . release ( this ) ) 
cacheState = 0 ; 
if ( debugLeaks ) { 
openFiles . remove ( location ) ; 
if ( file == null ) 
if ( ! readonly && ( minLength != 0 ) && ( minLength != fileSize ) ) { 
file . setLength ( minLength ) ; 
file . close ( ) ; 
file = null ; 
} public void seek ( long pos ) throws IOException { 
if ( ( pos >= bufferStart ) && ( pos < dataEnd ) ) { 
filePosition = pos ; 
readBuffer ( pos ) ; 
} public long length ( ) throws IOException { 
long fileLength = ( file == null ) ? - 1L : file . length ( ) ; 
if ( fileLength < dataEnd ) { 
return dataEnd ; 
return fileLength ; 
} public void flush ( ) throws IOException { 
if ( bufferModified ) { 
file . seek ( bufferStart ) ; 
file . write ( buffer , 0 , dataSize ) ; 
bufferModified = false ; 
} public int read ( ) throws IOException { 
if ( filePosition < dataEnd ) { 
int pos = ( int ) ( filePosition - bufferStart ) ; 
filePosition ++ ; 
return ( buffer [ pos ] & 0xff ) ; 
} else if ( endOfFile ) { 
seek ( filePosition ) ; 
} public int readBytes ( byte b [ ] , int off , int len ) throws IOException { 
if ( endOfFile ) { 
int bytesAvailable = ( int ) ( dataEnd - filePosition ) ; 
if ( bytesAvailable < 1 ) { 
return readBytes ( b , off , len ) ; 
int copyLength = ( bytesAvailable >= len ) 
? len 
: bytesAvailable ; 
System . arraycopy ( buffer , ( int ) ( filePosition - bufferStart ) , b , off , copyLength ) ; 
filePosition += copyLength ; 
if ( copyLength < len ) { 
int extraCopy = len - copyLength ; 
if ( extraCopy > buffer . length ) { 
extraCopy = read_ ( filePosition , b , off + copyLength , len - copyLength ) ; 
if ( ! endOfFile ) { 
extraCopy = ( extraCopy > dataSize ) 
? dataSize 
: extraCopy ; 
System . arraycopy ( buffer , 0 , b , off + copyLength , extraCopy ) ; 
extraCopy = - 1 ; 
if ( extraCopy > 0 ) { 
filePosition += extraCopy ; 
return copyLength + extraCopy ; 
return copyLength ; 
} public long readToByteChannel ( WritableByteChannel dest , long offset , long nbytes ) throws IOException { 
if ( fileChannel == null ) 
fileChannel = file . getChannel ( ) ; 
long need = nbytes ; 
while ( need > 0 ) { 
long count = fileChannel . transferTo ( offset , need , dest ) ; 
need -= count ; 
offset += count ; 
return nbytes - need ; 
} protected int read_ ( long pos , byte [ ] b , int offset , int len ) throws IOException { 
file . seek ( pos ) ; 
int n = file . read ( b , offset , len ) ; 
if ( debugAccess ) { 
if ( showRead ) 
debug_nseeks . incrementAndGet ( ) ; 
debug_nbytes . addAndGet ( len ) ; 
if ( extendMode && ( n < len ) ) { 
n = len ; 
} public final void readFully ( byte b [ ] , int off , int len ) throws IOException { 
while ( n < len ) { 
int count = this . read ( b , off + n , len - n ) ; 
n += count ; 
} public void write ( int b ) throws IOException { 
buffer [ pos ] = ( byte ) b ; 
bufferModified = true ; 
if ( dataSize != buffer . length ) { 
dataSize ++ ; 
dataEnd ++ ; 
write ( b ) ; 
} public void writeBytes ( byte b [ ] , int off , int len ) throws IOException { 
if ( len < buffer . length ) { 
int spaceInBuffer = 0 ; 
int copyLength = 0 ; 
if ( filePosition >= bufferStart ) { 
spaceInBuffer = ( int ) ( ( bufferStart + buffer . length ) - filePosition ) ; 
if ( spaceInBuffer > 0 ) { 
copyLength = ( spaceInBuffer > len ) ? len : spaceInBuffer ; 
System . arraycopy ( b , off , buffer , ( int ) ( filePosition - bufferStart ) , copyLength ) ; 
long myDataEnd = filePosition + copyLength ; 
dataEnd = ( myDataEnd > dataEnd ) ? myDataEnd : dataEnd ; 
dataSize = ( int ) ( dataEnd - bufferStart ) ; 
System . arraycopy ( b , off + copyLength , buffer , ( int ) ( filePosition - bufferStart ) , len - copyLength ) ; 
long myDataEnd = filePosition + ( len - copyLength ) ; 
filePosition += ( len - copyLength ) ; 
file . seek ( filePosition ) ; 
file . write ( b , off , len ) ; 
filePosition += len ; 
bufferStart = filePosition ; 
dataSize = 0 ; 
dataEnd = bufferStart + dataSize ; 
} public final void readShort ( short [ ] pa , int start , int n ) throws IOException { 
pa [ start + i ] = readShort ( ) ; 
} public final int readIntUnbuffered ( long pos ) throws IOException { 
byte [ ] bb = new byte [ 4 ] ; 
read_ ( pos , bb , 0 , 4 ) ; 
int ch1 = bb [ 0 ] & 0xff ; 
int ch2 = bb [ 1 ] & 0xff ; 
int ch3 = bb [ 2 ] & 0xff ; 
int ch4 = bb [ 3 ] & 0xff ; 
if ( ( ch1 | ch2 | ch3 | ch4 ) < 0 ) { 
throw new EOFException ( ) ; 
if ( bigEndian ) { 
return ( ( ch1 << 24 ) + ( ch2 << 16 ) + ( ch3 << 8 ) + ( ch4 ) ) ; 
return ( ( ch4 << 24 ) + ( ch3 << 16 ) + ( ch2 << 8 ) + ( ch1 ) ) ; 
} public final void readInt ( int [ ] pa , int start , int n ) throws IOException { 
pa [ start + i ] = readInt ( ) ; 
} public final void readLong ( long [ ] pa , int start , int n ) throws IOException { 
pa [ start + i ] = readLong ( ) ; 
} public final void readFloat ( float [ ] pa , int start , int n ) throws IOException { 
pa [ start + i ] = Float . intBitsToFloat ( readInt ( ) ) ; 
} public final void readDouble ( double [ ] pa , int start , int n ) throws IOException { 
pa [ start + i ] = Double . longBitsToDouble ( readLong ( ) ) ; 
} public String readString ( int nbytes ) throws IOException { 
byte [ ] data = new byte [ nbytes ] ; 
readFully ( data ) ; 
return new String ( data , CDM . utf8Charset ) ; 
} public String readStringMax ( int nbytes ) throws IOException { 
byte [ ] b = new byte [ nbytes ] ; 
readFully ( b ) ; 
for ( count = 0 ; count < nbytes ; count ++ ) 
if ( b [ count ] == 0 ) break ; 
return new String ( b , 0 , count , CDM . utf8Charset ) ; 
} public final void writeBoolean ( boolean [ ] pa , int start , int n ) throws IOException { 
writeBoolean ( pa [ start + i ] ) ; 
} public final void writeShort ( short [ ] pa , int start , int n ) throws IOException { 
writeShort ( pa [ start + i ] ) ; 
} public final void writeChar ( char [ ] pa , int start , int n ) throws IOException { 
writeChar ( pa [ start + i ] ) ; 
} public final void writeInt ( int [ ] pa , int start , int n ) throws IOException { 
writeInt ( pa [ start + i ] ) ; 
} public final void writeLong ( long [ ] pa , int start , int n ) throws IOException { 
writeLong ( pa [ start + i ] ) ; 
} public final void writeFloat ( float [ ] pa , int start , int n ) throws IOException { 
writeFloat ( pa [ start + i ] ) ; 
} public final void writeDouble ( double [ ] pa , int start , int n ) throws IOException { 
writeDouble ( pa [ start + i ] ) ; 
} public final void writeBytes ( String s ) throws IOException { 
write ( ( byte ) s . charAt ( i ) ) ; 
} public final void writeBytes ( char b [ ] , int off , int len ) throws IOException { 
for ( int i = off ; i < len ; i ++ ) { 
write ( ( byte ) b [ i ] ) ; 
} public final void writeChars ( String s ) throws IOException { 
int v = s . charAt ( i ) ; 
write ( ( v > > > 8 ) & 0xFF ) ; 
write ( ( v ) & 0xFF ) ; 
} public final void writeUTF ( String str ) throws IOException { 
int strlen = str . length ( ) ; 
int utflen = 0 ; 
for ( int i = 0 ; i < strlen ; i ++ ) { 
int c = str . charAt ( i ) ; 
if ( ( c >= 0x0001 ) && ( c <= 0x007F ) ) { 
utflen ++ ; 
} else if ( c > 0x07FF ) { 
utflen += 3 ; 
utflen += 2 ; 
if ( utflen > 65535 ) { 
throw new UTFDataFormatException ( ) ; 
write ( ( utflen > > > 8 ) & 0xFF ) ; 
write ( ( utflen ) & 0xFF ) ; 
write ( c ) ; 
write ( 0xE0 | ( ( c > > 12 ) & 0x0F ) ) ; 
write ( 0x80 | ( ( c > > 6 ) & 0x3F ) ) ; 
write ( 0x80 | ( ( c ) & 0x3F ) ) ; 
write ( 0xC0 | ( ( c > > 6 ) & 0x1F ) ) ; 
} public boolean searchForward ( KMPMatch match , int maxBytes ) throws IOException { 
long start = getFilePointer ( ) ; 
long last = ( maxBytes < 0 ) ? length ( ) : Math . min ( length ( ) , start + maxBytes ) ; 
long needToScan = last - start ; 
bytesAvailable = ( int ) ( dataEnd - filePosition ) ; 
int bufStart = ( int ) ( filePosition - bufferStart ) ; 
int scanBytes = ( int ) Math . min ( bytesAvailable , needToScan ) ; 
int pos = match . indexOf ( buffer , bufStart , scanBytes ) ; 
seek ( bufferStart + pos ) ; 
int matchLen = match . getMatchLength ( ) ; 
needToScan -= scanBytes - matchLen ; 
while ( needToScan > matchLen ) { 
readBuffer ( dataEnd - matchLen ) ; 
scanBytes = ( int ) Math . min ( buffer . length , needToScan ) ; 
pos = match . indexOf ( buffer , 0 , scanBytes ) ; 
seek ( last ) ; 
} public void appendQuery ( StringBuffer sbuff , ArrayList values ) { 
if ( template != null ) 
appendQueryFromTemplate ( sbuff , values ) ; 
appendQueryFromParamValue ( sbuff , values ) ; 
public boolean isValid ( NcssGridParamsBean params , ConstraintValidatorContext constraintValidatorContext ) { 
if ( params . getLatitude ( ) != null || params . getLongitude ( ) != null ) { 
if ( ! params . hasLatLonPoint ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.lat_or_lon_missing}" ) . addConstraintViolation ( ) ; 
if ( params . getNorth ( ) != null || params . getSouth ( ) != null || params . getEast ( ) != null || params . getWest ( ) != null ) { 
if ( ! params . hasLatLonBB ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.wrong_bbox}" ) . addConstraintViolation ( ) ; 
if ( params . getNorth ( ) < params . getSouth ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.north_south}" ) . addConstraintViolation ( ) ; 
if ( params . getEast ( ) < params . getWest ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.east_west}" ) . addConstraintViolation ( ) ; 
if ( params . getMaxx ( ) != null || params . getMinx ( ) != null || params . getMaxy ( ) != null || params . getMiny ( ) != null ) { 
if ( ! params . hasProjectionBB ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.wrong_pbox}" ) . addConstraintViolation ( ) ; 
if ( params . getMaxx ( ) < params . getMinx ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.rangex}" ) . addConstraintViolation ( ) ; 
if ( params . getMaxy ( ) < params . getMiny ( ) ) { 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.rangey}" ) . addConstraintViolation ( ) ; 
if ( params . getRuntime ( ) != null ) { 
if ( "latest" . equalsIgnoreCase ( params . getRuntime ( ) ) ) { 
params . setLatestRuntime ( true ) ; 
} else if ( "all" . equalsIgnoreCase ( params . getRuntime ( ) ) ) { 
params . setAllRuntime ( true ) ; 
CalendarDate cd = TimeParamsValidator . validateISOString ( params . getRuntime ( ) , "{thredds.server.ncSubset.validation.param.runtime}" , constraintValidatorContext ) ; 
if ( cd != null ) 
params . setRuntimeDate ( cd ) ; 
if ( params . getTimeOffset ( ) != null ) { 
if ( "first" . equalsIgnoreCase ( params . getTimeOffset ( ) ) ) { 
params . setFirstTimeOffset ( true ) ; 
double val = Double . parseDouble ( params . getTimeOffset ( ) ) ; 
params . setTimeOffsetVal ( val ) ; 
constraintValidatorContext . buildConstraintViolationWithTemplate ( "{thredds.server.ncSubset.validation.param.time_offset}" ) . addConstraintViolation ( ) ; 
} static public MCollection factory ( FeatureCollectionConfig config , Path topDir , boolean isTop , IndexReader indexReader , String suffix , org . slf4j . Logger logger ) throws IOException { 
DirectoryBuilder builder = new DirectoryBuilder ( config . collectionName , topDir . toString ( ) , suffix ) ; 
DirectoryPartition dpart = new DirectoryPartition ( config , topDir , isTop , indexReader , suffix , logger ) ; 
if ( ! builder . isLeaf ( indexReader ) ) { 
return dpart ; 
boolean hasIndex = builder . findIndex ( ) ; 
if ( hasIndex ) { 
return dpart . makeChildCollection ( builder ) ; 
DirectoryCollection result = new DirectoryCollection ( config . collectionName , topDir , isTop , config . olderThan , logger ) ; 
} public boolean findIndex ( ) throws IOException { 
Path indexPath = Paths . get ( dir . toString ( ) , partitionName + suffix ) ; 
if ( Files . exists ( indexPath ) ) { 
this . index = indexPath ; 
BasicFileAttributes attr = Files . readAttributes ( indexPath , BasicFileAttributes . class ) ; 
this . indexLastModified = attr . lastModifiedTime ( ) ; 
this . indexSize = attr . size ( ) ; 
} private boolean isLeaf ( IndexReader indexReader ) throws IOException { 
if ( partitionStatus == PartitionStatus . unknown ) { 
int countDir = 0 , countFile = 0 , count = 0 ; 
try ( DirectoryStream < Path > dirStream = Files . newDirectoryStream ( dir ) ) { 
Iterator < Path > iterator = dirStream . iterator ( ) ; 
while ( iterator . hasNext ( ) && count ++ < 100 ) { 
Path p = iterator . next ( ) ; 
BasicFileAttributes attr = Files . readAttributes ( p , BasicFileAttributes . class ) ; 
if ( attr . isDirectory ( ) ) countDir ++ ; 
else countFile ++ ; 
partitionStatus = ( countFile > countDir ) ? PartitionStatus . isLeaf : PartitionStatus . isDirectoryPartition ; 
return partitionStatus == PartitionStatus . isLeaf ; 
} public List < DirectoryBuilder > constructChildren ( IndexReader indexReader , CollectionUpdateType forceCollection ) throws IOException { 
if ( childrenConstructed ) return children ; 
if ( index != null && forceCollection == CollectionUpdateType . nocheck ) { 
constructChildrenFromIndex ( indexReader , false ) ; 
scanForChildren ( ) ; 
partitionStatus = ( children . size ( ) > 0 ) ? PartitionStatus . isDirectoryPartition : PartitionStatus . isLeaf ; 
childrenConstructed = true ; 
return children ; 
} private void scanForChildren ( ) { 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( dir ) ) { 
if ( attr . isDirectory ( ) ) { 
children . add ( new DirectoryBuilder ( topCollectionName , p , attr , suffix ) ) ; 
if ( debug ) System . out . printf ( "done=%d%n" , count ) ; 
} public List < MFile > readFilesFromIndex ( IndexReader indexReader ) throws IOException { 
List < MFile > result = new ArrayList < > ( 100 ) ; 
if ( index == null ) return result ; 
indexReader . readMFiles ( index , result ) ; 
} static public GridDataset open ( String location ) throws java . io . IOException { 
return open ( location , NetcdfDataset . getDefaultEnhanceMode ( ) ) ; 
} static public GridDataset open ( String location , Set < NetcdfDataset . Enhance > enhanceMode ) throws java . io . IOException { 
NetcdfDataset ds = ucar . nc2 . dataset . NetcdfDataset . acquireDataset ( null , DatasetUrl . findDatasetUrl ( location ) , enhanceMode , - 1 , null , null ) ; 
return new GridDataset ( ds , null ) ; 
} public List < ucar . nc2 . dt . GridDataset . Gridset > getGridsets ( ) { 
return new ArrayList < ucar . nc2 . dt . GridDataset . Gridset > ( gridsetHash . values ( ) ) ; 
} private void getInfo ( Formatter buf ) { 
int countGridset = 0 ; 
for ( Gridset gs : gridsetHash . values ( ) ) { 
GridCoordSystem gcs = gs . getGeoCoordSystem ( ) ; 
if ( ( gcs . getProjection ( ) != null ) && ! gcs . getProjection ( ) . isLatLon ( ) ) 
buf . format ( "%n" ) ; 
buf . format ( "Name__________________________Unit__________________________hasMissing_Description%n" ) ; 
for ( GridDatatype grid : gs . getGrids ( ) ) { 
buf . format ( "%s%n" , grid . getInfo ( ) ) ; 
countGridset ++ ; 
buf . format ( "Name__________________________Units_______________Type______Description%n" ) ; 
if ( axis . getAxisType ( ) == null ) continue ; 
axis . getInfo ( buf ) ; 
if ( fileCache != null ) { 
if ( fileCache . release ( this ) ) return ; 
if ( ncd != null ) ncd . close ( ) ; 
ncd = null ; 
} public static synchronized void shutdown ( ) { 
} public FileCacheable acquire ( FileFactory factory , DatasetUrl durl , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { 
return acquire ( factory , durl . trueurl , durl , - 1 , cancelTask , null ) ; 
public FileCacheable acquire ( FileFactory factory , Object hashKey , DatasetUrl location , 
int buffer_size , CancelTask cancelTask , Object spiObject ) throws IOException { 
if ( null == hashKey ) hashKey = location . trueurl ; 
if ( null == hashKey ) throw new IllegalArgumentException ( ) ; 
Tracker t = null ; 
if ( trackAll ) { 
t = new Tracker ( hashKey ) ; 
Tracker prev = track . putIfAbsent ( hashKey , t ) ; 
if ( prev != null ) t = prev ; 
FileCacheable ncfile = acquireCacheOnly ( hashKey ) ; 
hits . incrementAndGet ( ) ; 
if ( t != null ) t . hit ++ ; 
miss . incrementAndGet ( ) ; 
if ( t != null ) t . miss ++ ; 
ncfile = factory . open ( location , buffer_size , cancelTask , spiObject ) ; 
if ( cacheLog . isDebugEnabled ( ) ) 
if ( ( cancelTask != null ) && ( cancelTask . isCancel ( ) ) ) { 
if ( ncfile != null ) ncfile . close ( ) ; 
if ( disabled . get ( ) ) return ncfile ; 
CacheElement elem ; 
synchronized ( cache ) { 
elem = cache . get ( hashKey ) ; 
if ( elem == null ) cache . put ( hashKey , new CacheElement ( ncfile , hashKey ) ) ; 
if ( elem != null ) { 
synchronized ( elem ) { 
elem . addFile ( ncfile ) ; 
boolean needHard = false ; 
boolean needSoft = false ; 
synchronized ( hasScheduled ) { 
if ( ! hasScheduled . get ( ) ) { 
int count = files . size ( ) ; 
if ( ( count > hardLimit ) && ( hardLimit > 0 ) ) { 
needHard = true ; 
hasScheduled . getAndSet ( true ) ; 
} else if ( ( count > softLimit ) && ( softLimit > 0 ) ) { 
needSoft = true ; 
if ( needHard ) { 
if ( debugCleanup ) 
cleanup ( hardLimit ) ; 
} else if ( needSoft ) { 
schedule ( new CleanupTask ( ) , 100 ) ; 
} private FileCacheable acquireCacheOnly ( Object hashKey ) { 
if ( disabled . get ( ) ) return null ; 
CacheElement wantCacheElem = cache . get ( hashKey ) ; 
if ( wantCacheElem == null ) return null ; 
CacheElement . CacheFile want = null ; 
synchronized ( wantCacheElem ) { 
for ( CacheElement . CacheFile file : wantCacheElem . list ) { 
if ( file . isLocked . compareAndSet ( false , true ) ) { 
want = file ; 
if ( want . ncfile != null ) { 
long lastModified = want . ncfile . getLastModified ( ) ; 
boolean changed = lastModified != want . lastModified ; 
if ( cacheLog . isDebugEnabled ( ) && changed ) 
if ( changed ) { 
remove ( want ) ; 
want . ncfile . reacquire ( ) ; 
if ( debugPrint && want . ncfile != null ) { 
return want . ncfile ; 
} private void remove ( CacheElement . CacheFile want ) { 
want . remove ( ) ; 
files . remove ( want . ncfile ) ; 
want . ncfile . setFileCache ( null ) ; 
want . ncfile . close ( ) ; 
want . ncfile = null ; 
public void eject ( Object hashKey ) { 
if ( disabled . get ( ) ) return ; 
if ( wantCacheElem == null ) return ; 
for ( CacheElement . CacheFile want : wantCacheElem . list ) { 
wantCacheElem . list . clear ( ) ; 
cache . remove ( hashKey ) ; 
public boolean release ( FileCacheable ncfile ) throws IOException { 
if ( ncfile == null ) return false ; 
if ( disabled . get ( ) ) { 
ncfile . setFileCache ( null ) ; 
CacheElement . CacheFile file = files . get ( ncfile ) ; 
if ( ! file . isLocked . get ( ) ) { 
file . lastAccessed = System . currentTimeMillis ( ) ; 
file . countAccessed ++ ; 
file . isLocked . set ( false ) ; 
file . ncfile . release ( ) ; 
} public String getInfo ( FileCacheable ncfile ) throws IOException { 
if ( ncfile == null ) return "" ; 
public void showCache ( Formatter format ) { 
ArrayList < CacheElement . CacheFile > allFiles = new ArrayList < > ( files . size ( ) ) ; 
for ( CacheElement elem : cache . values ( ) ) { 
allFiles . addAll ( elem . list ) ; 
Collections . sort ( allFiles ) ; 
for ( CacheElement . CacheFile file : allFiles ) { 
String loc = file . ncfile != null ? file . ncfile . getLocation ( ) : "null" ; 
showStats ( format ) ; 
} public void showStats ( Formatter format ) { 
} synchronized void cleanup ( int maxElements ) { 
int size = files . size ( ) ; 
if ( size <= minElements ) return ; 
cleanups . incrementAndGet ( ) ; 
List < CacheElement . CacheFile > allFiles = new ArrayList < > ( size + 10 ) ; 
for ( CacheElement . CacheFile file : files . values ( ) ) { 
if ( ! file . isLocked . get ( ) ) allFiles . add ( file ) ; 
int need2delete = size - minElements ; 
int minDelete = size - maxElements ; 
List < CacheElement . CacheFile > deleteList = new ArrayList < > ( need2delete ) ; 
Iterator < CacheElement . CacheFile > iter = allFiles . iterator ( ) ; 
while ( iter . hasNext ( ) && ( count < need2delete ) ) { 
CacheElement . CacheFile file = iter . next ( ) ; 
file . remove ( ) ; 
deleteList . add ( file ) ; 
if ( count < minDelete ) { 
if ( elem . list . size ( ) == 0 ) 
cache . remove ( elem . hashKey ) ; 
for ( CacheElement . CacheFile file : deleteList ) { 
if ( null == files . remove ( file . ncfile ) ) { 
file . ncfile . setFileCache ( null ) ; 
file . ncfile . close ( ) ; 
file . ncfile = null ; 
hasScheduled . set ( false ) ; 
} private static int int4 ( int a , int b , int c , int d ) { 
if ( a == 0xff && b == 0xff && c == 0xff && d == 0xff ) 
return UNDEFINED ; 
return ( 1 - ( ( a & 128 ) > > 6 ) ) * ( ( a & 127 ) << 24 | b << 16 | c << 8 | d ) ; 
public FileCacheable acquire ( FileFactory factory , DatasetUrl location ) throws IOException { 
return acquire ( factory , location . trueurl , location , - 1 , null , null ) ; 
addToCache ( hashKey , ncfile ) ; 
boolean changed = lastModified != wantCacheElem . lastModified . get ( ) ; 
expireFromCache ( wantCacheElem ) ; 
updateInCache ( wantCacheElem ) ; 
} private CacheElement updateInCache ( CacheElement elem ) { 
if ( shadowCache . firstKey ( ) == elem ) return elem ; 
elem . updateAccessed ( ) ; 
CacheElement prev = shadowCache . put ( elem , elem ) ; 
if ( prev != null && ( elem != prev ) ) { 
CacheElementComparator cc = new CacheElementComparator ( ) ; 
} private void addToCache ( Object hashKey , FileCacheable ncfile ) { 
CacheElement newCacheElem = new CacheElement ( hashKey ) ; 
CacheElement previous = cache . putIfAbsent ( hashKey , newCacheElem ) ; 
CacheElement elem = ( previous != null ) ? previous : newCacheElem ; 
shadowCache . put ( newCacheElem , newCacheElem ) ; 
int size = cacheSize . getAndIncrement ( ) ; 
if ( size > softLimit ) { 
removeFromCache ( size - softLimit ) ; 
int hashcode = System . identityHashCode ( ncfile ) ; 
CacheElement . CacheFile file = files . get ( hashcode ) ; 
} public synchronized void clearCache ( boolean force ) { 
List < CacheElement . CacheFile > deleteList = new ArrayList < > ( 2 * cache . size ( ) ) ; 
if ( force ) { 
cache . clear ( ) ; 
deleteList . addAll ( files . values ( ) ) ; 
files . clear ( ) ; 
Iterator < CacheElement . CacheFile > iter = files . values ( ) . iterator ( ) ; 
if ( force && file . isLocked . get ( ) ) 
if ( file . ncfile == null ) continue ; 
CalendarDate cd = CalendarDate . of ( file . getLastAccessed ( ) ) ; 
} public void showTracking ( Formatter format ) { 
if ( track == null ) return ; 
List < Tracker > all = new ArrayList < > ( track . size ( ) ) ; 
for ( Tracker val : track . values ( ) ) all . add ( val ) ; 
Collections . sort ( all ) ; 
int countAll = 0 ; 
for ( Tracker t : all ) { 
countAll += t . hit + t . miss ; 
format . format ( "%n" ) ; 
} public boolean parse ( String input ) throws ParseException 
( ( Dap2Lex ) yylexer ) . reset ( parsestate ) ; 
( ( Dap2Lex ) yylexer ) . setText ( input ) ; 
} public static boolean isGridCoordSys ( Formatter sbuff , CoordinateSystem cs , VariableEnhanced v ) { 
if ( cs . getRankDomain ( ) < 2 ) { 
if ( sbuff != null ) { 
if ( ! cs . isLatLon ( ) ) { 
if ( ( cs . getXaxis ( ) == null ) || ( cs . getYaxis ( ) == null ) ) { 
if ( null == cs . getProjection ( ) ) { 
CoordinateAxis xaxis , yaxis ; 
if ( cs . isGeoXY ( ) ) { 
xaxis = cs . getXaxis ( ) ; 
yaxis = cs . getYaxis ( ) ; 
ProjectionImpl p = cs . getProjection ( ) ; 
if ( ! ( p instanceof RotatedPole ) ) { 
if ( ! SimpleUnit . kmUnit . isCompatible ( xaxis . getUnitsString ( ) ) ) { 
if ( ! SimpleUnit . kmUnit . isCompatible ( yaxis . getUnitsString ( ) ) ) { 
xaxis = cs . getLonAxis ( ) ; 
yaxis = cs . getLatAxis ( ) ; 
if ( ( xaxis . getRank ( ) > 2 ) || ( yaxis . getRank ( ) > 2 ) ) { 
int xyDomainSize = CoordinateSystem . countDomain ( new CoordinateAxis [ ] { xaxis , yaxis } ) ; 
if ( xyDomainSize < 2 ) { 
List < CoordinateAxis > testAxis = new ArrayList < > ( ) ; 
testAxis . add ( xaxis ) ; 
testAxis . add ( yaxis ) ; 
CoordinateAxis z = cs . getHeightAxis ( ) ; 
if ( ( z == null ) || ! ( z instanceof CoordinateAxis1D ) ) z = cs . getPressureAxis ( ) ; 
if ( ( z == null ) || ! ( z instanceof CoordinateAxis1D ) ) z = cs . getZaxis ( ) ; 
if ( ( z != null ) && ! ( z instanceof CoordinateAxis1D ) ) { 
if ( z != null ) 
testAxis . add ( z ) ; 
CoordinateAxis t = cs . getTaxis ( ) ; 
CoordinateAxis rt = cs . findAxis ( AxisType . RunTime ) ; 
if ( rt != null ) { 
if ( ! rt . isScalar ( ) && ! ( rt instanceof CoordinateAxis1D ) ) { 
if ( ( t != null ) && ! ( t instanceof CoordinateAxis1D ) && ( t . getRank ( ) != 0 ) ) { 
if ( rt . getRank ( ) != 1 ) { 
if ( ! rt . getDimension ( 0 ) . equals ( t . getDimension ( 0 ) ) ) { 
testAxis . add ( t ) ; 
if ( rt != null ) 
testAxis . add ( rt ) ; 
CoordinateAxis ens = cs . getEnsembleAxis ( ) ; 
if ( ens != null ) 
testAxis . add ( ens ) ; 
List < Dimension > testDomain = new ArrayList < > ( ) ; 
for ( CoordinateAxis axis : testAxis ) { 
for ( Dimension dim : axis . getDimensions ( ) ) { 
if ( ! testDomain . contains ( dim ) ) 
testDomain . add ( dim ) ; 
if ( ! CoordinateSystem . isSubset ( v . getDimensionsAll ( ) , testDomain ) ) { 
} public static GridCoordSys makeGridCoordSys ( Formatter sbuff , CoordinateSystem cs , VariableEnhanced v ) { 
v . getNameAndDimensions ( sbuff , false , true ) ; 
if ( isGridCoordSys ( sbuff , cs , v ) ) { 
GridCoordSys gcs = new GridCoordSys ( cs , sbuff ) ; 
return gcs ; 
} void makeVerticalTransform ( GridDataset gds , Formatter parseInfo ) { 
if ( vt != null ) return ; 
if ( vCT == null ) return ; 
vt = vCT . makeVerticalTransform ( gds . getNetcdfDataset ( ) , timeDim ) ; 
if ( vt == null ) { 
if ( parseInfo != null ) 
public boolean isGlobalLon ( ) { 
if ( ! isLatLon ) return false ; 
if ( ! ( horizXaxis instanceof CoordinateAxis1D ) ) return false ; 
CoordinateAxis1D lon = ( CoordinateAxis1D ) horizXaxis ; 
double first = lon . getCoordEdge ( 0 ) ; 
double last = lon . getCoordEdge ( ( int ) lon . getSize ( ) ) ; 
double min = Math . min ( first , last ) ; 
double max = Math . max ( first , last ) ; 
return ( max - min ) >= 360 ; 
public boolean isZPositive ( ) { 
if ( vertZaxis == null ) return false ; 
if ( vertZaxis . getPositive ( ) != null ) { 
return vertZaxis . getPositive ( ) . equalsIgnoreCase ( ucar . nc2 . constants . CF . POSITIVE_UP ) ; 
if ( vertZaxis . getAxisType ( ) == AxisType . Height ) return true ; 
return vertZaxis . getAxisType ( ) != AxisType . Pressure ; 
public int [ ] findXYindexFromCoord ( double x_coord , double y_coord , int [ ] result ) { 
result = new int [ 2 ] ; 
if ( ( horizXaxis instanceof CoordinateAxis1D ) && ( horizYaxis instanceof CoordinateAxis1D ) ) { 
result [ 0 ] = ( ( CoordinateAxis1D ) horizXaxis ) . findCoordElement ( x_coord ) ; 
result [ 1 ] = ( ( CoordinateAxis1D ) horizYaxis ) . findCoordElement ( y_coord ) ; 
} else if ( ( horizXaxis instanceof CoordinateAxis2D ) && ( horizYaxis instanceof CoordinateAxis2D ) ) { 
if ( g2d == null ) 
g2d = new GridCoordinate2D ( ( CoordinateAxis2D ) horizYaxis , ( CoordinateAxis2D ) horizXaxis ) ; 
int [ ] result2 = new int [ 2 ] ; 
boolean found = g2d . findCoordElement ( y_coord , x_coord , result2 ) ; 
result [ 0 ] = result2 [ 1 ] ; 
result [ 1 ] = result2 [ 0 ] ; 
result [ 0 ] = - 1 ; 
result [ 1 ] = - 1 ; 
throw new IllegalStateException ( "GridCoordSystem.findXYindexFromCoord" ) ; 
public int [ ] findXYindexFromCoordBounded ( double x_coord , double y_coord , int [ ] result ) { 
result [ 0 ] = ( ( CoordinateAxis1D ) horizXaxis ) . findCoordElementBounded ( x_coord ) ; 
result [ 1 ] = ( ( CoordinateAxis1D ) horizYaxis ) . findCoordElementBounded ( y_coord ) ; 
g2d . findCoordElement ( y_coord , x_coord , result2 ) ; 
public int [ ] findXYindexFromLatLon ( double lat , double lon , int [ ] result ) { 
Projection dataProjection = getProjection ( ) ; 
ProjectionPoint pp = dataProjection . latLonToProj ( new LatLonPointImpl ( lat , lon ) , new ProjectionPointImpl ( ) ) ; 
return findXYindexFromCoord ( pp . getX ( ) , pp . getY ( ) , result ) ; 
public int [ ] findXYindexFromLatLonBounded ( double lat , double lon , int [ ] result ) { 
return findXYindexFromCoordBounded ( pp . getX ( ) , pp . getY ( ) , result ) ; 
public ProjectionRect getBoundingBox ( ) { 
if ( ! ( horizXaxis instanceof CoordinateAxis1D ) || ! ( horizYaxis instanceof CoordinateAxis1D ) ) { 
mapArea = new ProjectionRect ( horizXaxis . getMinValue ( ) , horizYaxis . getMinValue ( ) , 
horizXaxis . getMaxValue ( ) , horizYaxis . getMaxValue ( ) ) ; 
public LatLonPoint getLatLon ( int xindex , int yindex ) { 
public List < Range > getRangesFromLatLonRect ( LatLonRect rect ) throws InvalidRangeException { 
double minx , maxx , miny , maxy ; 
ProjectionImpl proj = getProjection ( ) ; 
if ( proj != null && ! ( proj instanceof VerticalPerspectiveView ) && ! ( proj instanceof MSGnavigation ) 
&& ! ( proj instanceof Geostationary ) ) { 
LatLonRect bb = getLatLonBoundingBox ( ) ; 
LatLonRect rect2 = bb . intersect ( rect ) ; 
if ( null == rect2 ) 
rect = rect2 ; 
CoordinateAxis xaxis = getXHorizAxis ( ) ; 
CoordinateAxis yaxis = getYHorizAxis ( ) ; 
LatLonPointImpl llpt = rect . getLowerLeftPoint ( ) ; 
LatLonPointImpl urpt = rect . getUpperRightPoint ( ) ; 
LatLonPointImpl lrpt = rect . getLowerRightPoint ( ) ; 
LatLonPointImpl ulpt = rect . getUpperLeftPoint ( ) ; 
minx = getMinOrMaxLon ( llpt . getLongitude ( ) , ulpt . getLongitude ( ) , true ) ; 
miny = Math . min ( llpt . getLatitude ( ) , lrpt . getLatitude ( ) ) ; 
maxx = getMinOrMaxLon ( urpt . getLongitude ( ) , lrpt . getLongitude ( ) , false ) ; 
maxy = Math . min ( ulpt . getLatitude ( ) , urpt . getLatitude ( ) ) ; 
double minLon = xaxis . getMinValue ( ) ; 
minx = LatLonPointImpl . lonNormalFrom ( minx , minLon ) ; 
maxx = LatLonPointImpl . lonNormalFrom ( maxx , minLon ) ; 
ProjectionRect prect = getProjection ( ) . latLonToProjBB ( rect ) ; 
minx = prect . getMinPoint ( ) . getX ( ) ; 
miny = prect . getMinPoint ( ) . getY ( ) ; 
maxx = prect . getMaxPoint ( ) . getX ( ) ; 
maxy = prect . getMaxPoint ( ) . getY ( ) ; 
if ( ( xaxis instanceof CoordinateAxis1D ) && ( yaxis instanceof CoordinateAxis1D ) ) { 
CoordinateAxis1D xaxis1 = ( CoordinateAxis1D ) xaxis ; 
CoordinateAxis1D yaxis1 = ( CoordinateAxis1D ) yaxis ; 
int minxIndex = xaxis1 . findCoordElementBounded ( minx ) ; 
int minyIndex = yaxis1 . findCoordElementBounded ( miny ) ; 
int maxxIndex = xaxis1 . findCoordElementBounded ( maxx ) ; 
int maxyIndex = yaxis1 . findCoordElementBounded ( maxy ) ; 
list . add ( new Range ( Math . min ( minyIndex , maxyIndex ) , Math . max ( minyIndex , maxyIndex ) ) ) ; 
list . add ( new Range ( Math . min ( minxIndex , maxxIndex ) , Math . max ( minxIndex , maxxIndex ) ) ) ; 
} else if ( ( xaxis instanceof CoordinateAxis2D ) && ( yaxis instanceof CoordinateAxis2D ) && isLatLon ( ) ) { 
CoordinateAxis2D lon_axis = ( CoordinateAxis2D ) xaxis ; 
CoordinateAxis2D lat_axis = ( CoordinateAxis2D ) yaxis ; 
int shape [ ] = lon_axis . getShape ( ) ; 
int nj = shape [ 0 ] ; 
int ni = shape [ 1 ] ; 
int mini = Integer . MAX_VALUE , minj = Integer . MAX_VALUE ; 
int maxi = - 1 , maxj = - 1 ; 
double lat = lat_axis . getCoordValue ( j , i ) ; 
double lon = lon_axis . getCoordValue ( j , i ) ; 
if ( ( lat >= miny ) && ( lat <= maxy ) && ( lon >= minx ) && ( lon <= maxx ) ) { 
if ( i > maxi ) maxi = i ; 
if ( i < mini ) mini = i ; 
if ( j > maxj ) maxj = j ; 
if ( j < minj ) minj = j ; 
if ( ( mini > maxi ) || ( minj > maxj ) ) { 
mini = 0 ; 
minj = 0 ; 
maxi = - 1 ; 
maxj = - 1 ; 
ArrayList < Range > list = new ArrayList < > ( ) ; 
list . add ( new Range ( minj , maxj ) ) ; 
list . add ( new Range ( mini , maxi ) ) ; 
public List < CalendarDate > getCalendarDates ( ) { 
if ( timeTaxis != null ) 
return timeTaxis . getCalendarDates ( ) ; 
return makeCalendarDates2D ( ) ; 
} public List < NamedObject > getLevels ( ) { 
if ( vertZaxis == null ) 
return new ArrayList < > ( 0 ) ; 
int n = ( int ) vertZaxis . getSize ( ) ; 
List < NamedObject > levels = new ArrayList < > ( n ) ; 
levels . add ( new ucar . nc2 . util . NamedAnything ( vertZaxis . getCoordName ( i ) , vertZaxis . getUnitsString ( ) ) ) ; 
public String getLevelName ( int index ) { 
if ( ( vertZaxis == null ) || ( index < 0 ) || ( index >= vertZaxis . getSize ( ) ) ) 
return vertZaxis . getCoordName ( index ) . trim ( ) ; 
public int getLevelIndex ( String name ) { 
if ( ( vertZaxis == null ) || ( name == null ) ) return - 1 ; 
for ( int i = 0 ; i < vertZaxis . getSize ( ) ; i ++ ) { 
if ( vertZaxis . getCoordName ( i ) . trim ( ) . equals ( name ) ) 
public List < NamedObject > getTimes ( ) { 
List < CalendarDate > cdates = getCalendarDates ( ) ; 
List < NamedObject > times = new ArrayList < > ( cdates . size ( ) ) ; 
for ( CalendarDate cd : cdates ) { 
return times ; 
public int [ ] findXYCoordElement ( double x_coord , double y_coord , int [ ] result ) { 
return findXYindexFromCoord ( x_coord , y_coord , result ) ; 
public DateRange getDateRange ( ) { 
Date [ ] dates = getTimeDates ( ) ; 
if ( dates . length > 0 ) 
return new DateRange ( dates [ 0 ] , dates [ dates . length - 1 ] ) ; 
public java . util . Date [ ] getTimeDates ( ) { 
if ( ( timeTaxis != null ) && ( timeTaxis . getSize ( ) > 0 ) ) { 
return timeTaxis . getTimeDates ( ) ; 
} else if ( ( tAxis != null ) && ( tAxis . getSize ( ) > 0 ) ) { 
return makeTimes2D ( ) ; 
return new Date [ 0 ] ; 
private Date [ ] makeTimes2D ( ) { 
Set < Date > dates = new HashSet < > ( ) ; 
String units = tAxis . getUnitsString ( ) ; 
if ( units != null && SimpleUnit . isDateUnit ( units ) && tAxis . getDataType ( ) . isNumeric ( ) ) { 
DateUnit du = new DateUnit ( units ) ; 
Array data = tAxis . read ( ) ; 
while ( data . hasNext ( ) ) { 
Date d = du . makeDate ( data . nextDouble ( ) ) ; 
} else if ( tAxis . getDataType ( ) == DataType . STRING ) { 
Date d = formatter . getISODate ( ( String ) data . next ( ) ) ; 
} else if ( tAxis . getDataType ( ) == DataType . CHAR ) { 
ArrayChar data = ( ArrayChar ) tAxis . read ( ) ; 
Date d = formatter . getISODate ( iter . next ( ) ) ; 
int n = dates . size ( ) ; 
Date [ ] dd = dates . toArray ( new Date [ n ] ) ; 
List < Date > dateList = Arrays . asList ( dd ) ; 
Collections . sort ( dateList ) ; 
Date [ ] timeDates = new Date [ n ] ; 
for ( Date d : dateList ) 
timeDates [ count ++ ] = d ; 
return timeDates ; 
public String getTimeName ( int index ) { 
if ( ( index < 0 ) || ( index >= cdates . size ( ) ) ) 
return cdates . get ( index ) . toString ( ) ; 
public int getTimeIndex ( String name ) { 
for ( int i = 0 ; i < cdates . size ( ) ; i ++ ) { 
if ( cdates . get ( i ) . toString ( ) . equals ( name ) ) return i ; 
public int findTimeIndexFromDate ( java . util . Date d ) { 
if ( timeTaxis == null ) return - 1 ; 
return timeTaxis . findTimeIndexFromDate ( d ) ; 
static private double getMinOrMaxLon ( double lon1 , double lon2 , boolean wantMin ) { 
double midpoint = ( lon1 + lon2 ) / 2 ; 
lon1 = LatLonPointImpl . lonNormal ( lon1 , midpoint ) ; 
lon2 = LatLonPointImpl . lonNormal ( lon2 , midpoint ) ; 
return wantMin ? Math . min ( lon1 , lon2 ) : Math . max ( lon1 , lon2 ) ; 
static public LatLonRect getLatLonBoundingBox ( Projection proj , double startx , double starty , double endx , double endy ) { 
if ( proj instanceof LatLonProjection ) { 
double deltaLat = endy - starty ; 
double deltaLon = endx - startx ; 
LatLonPoint llpt = new LatLonPointImpl ( starty , startx ) ; 
return new LatLonRect ( llpt , deltaLat , deltaLon ) ; 
ProjectionRect bb = new ProjectionRect ( startx , starty , endx , endy ) ; 
LatLonPointImpl llpt = ( LatLonPointImpl ) proj . projToLatLon ( bb . getLowerLeftPoint ( ) , new LatLonPointImpl ( ) ) ; 
LatLonPointImpl lrpt = ( LatLonPointImpl ) proj . projToLatLon ( bb . getLowerRightPoint ( ) , new LatLonPointImpl ( ) ) ; 
LatLonPointImpl urpt = ( LatLonPointImpl ) proj . projToLatLon ( bb . getUpperRightPoint ( ) , new LatLonPointImpl ( ) ) ; 
LatLonPointImpl ulpt = ( LatLonPointImpl ) proj . projToLatLon ( bb . getUpperLeftPoint ( ) , new LatLonPointImpl ( ) ) ; 
boolean includesNorthPole = false ; 
boolean includesSouthPole = false ; 
LatLonRect llbb ; 
if ( includesNorthPole && ! includesSouthPole ) { 
llbb = new LatLonRect ( llpt , new LatLonPointImpl ( 90.0 , 0.0 ) ) ; 
llbb . extend ( lrpt ) ; 
llbb . extend ( urpt ) ; 
llbb . extend ( ulpt ) ; 
} else if ( includesSouthPole && ! includesNorthPole ) { 
llbb = new LatLonRect ( llpt , new LatLonPointImpl ( - 90.0 , - 180.0 ) ) ; 
double latMin = Math . min ( llpt . getLatitude ( ) , lrpt . getLatitude ( ) ) ; 
double latMax = Math . max ( ulpt . getLatitude ( ) , urpt . getLatitude ( ) ) ; 
double lonMin = getMinOrMaxLon ( llpt . getLongitude ( ) , ulpt . getLongitude ( ) , true ) ; 
double lonMax = getMinOrMaxLon ( lrpt . getLongitude ( ) , urpt . getLongitude ( ) , false ) ; 
llpt . set ( latMin , lonMin ) ; 
urpt . set ( latMax , lonMax ) ; 
llbb = new LatLonRect ( llpt , urpt ) ; 
} protected int getItemPos ( ) { 
if ( nitems < 1 ) 
return - arrow_size ; 
else if ( nitems == 1 ) 
return b . width / 2 ; 
int item = table . getSelectedRowIndex ( ) ; 
int eff_width = b . width - 2 * arrow_size ; 
int pixel = ( item * eff_width ) / ( nitems - 1 ) ; 
return pixel + arrow_size ; 
} protected int getItem ( int pixel ) { 
if ( nitems < 2 ) 
double fitem = ( ( double ) ( pixel - arrow_size ) * ( nitems - 1 ) ) / eff_width ; 
int item = ( int ) ( fitem + .5 ) ; 
item = Math . max ( Math . min ( item , nitems - 1 ) , 0 ) ; 
return item ; 
} public static String makeCollectionName ( String topCollectionName , Path dir ) { 
int last = dir . getNameCount ( ) - 1 ; 
Path lastDir = dir . getName ( last ) ; 
String lastDirName = lastDir . toString ( ) ; 
return topCollectionName + "-" + lastDirName ; 
} public static Path makeCollectionIndexPath ( String topCollectionName , Path dir , String suffix ) { 
String collectionName = makeCollectionName ( topCollectionName , dir ) ; 
return Paths . get ( dir . toString ( ) , collectionName + suffix ) ; 
} public void iterateOverMFileCollection ( Visitor visit ) throws IOException { 
try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( collectionDir , new MyStreamFilter ( ) ) ) { 
if ( ! attr . isDirectory ( ) ) 
visit . consume ( new MFileOS7 ( p ) ) ; 
if ( debug ) System . out . printf ( "%d%n" , count ) ; 
} public void getRemoteFiles ( final CancelTask _cancel ) { 
this . cancel = _cancel ; 
String urls = config . getServerPrefix ( ) + "/thredds/admin/log/" + type + "/" ; 
try ( HTTPMethod method = HTTPFactory . Get ( session , urls ) ) { 
if ( statusCode == 200 ) 
contents = method . getResponseAsString ( ) ; 
if ( ( contents == null ) || ( contents . length ( ) == 0 ) ) { 
final String list = contents ; 
SwingWorker worker = new SwingWorker < String , Void > ( ) { 
protected String doInBackground ( ) throws Exception { 
String [ ] lines = list . split ( "\n" ) ; 
new RemoteLog ( line . trim ( ) ) ; 
if ( cancel . isCancel ( ) ) { 
public void done ( ) { 
if ( cancel . isCancel ( ) ) 
worker . execute ( ) ; 
if ( pointFeature != null ) { 
pointFeature = nextFilteredDataPoint ( ) ; 
if ( pointFeature == null ) { 
assert pointFeature != null ; 
PointFeature ret = pointFeature ; 
calcBounds ( ret ) ; 
pointFeature = null ; 
} private PointFeature nextFilteredDataPoint ( ) { 
while ( origIter . hasNext ( ) ) { 
PointFeature pointFeat = origIter . next ( ) ; 
if ( filter . filter ( pointFeat ) ) { 
public String getSubCenterName ( int center , int subcenter ) { 
switch ( subcenter ) { 
return super . getSubCenterName ( center , subcenter ) ; 
} public static CalendarPeriod . Field fromUnitString ( String udunit ) { 
udunit = udunit . trim ( ) ; 
udunit = udunit . toLowerCase ( ) ; 
if ( udunit . equals ( "s" ) ) return Field . Second ; 
if ( udunit . equals ( "ms" ) ) return Field . Millisec ; 
if ( udunit . endsWith ( "s" ) ) udunit = udunit . substring ( 0 , udunit . length ( ) - 1 ) ; 
switch ( udunit ) { 
case "second" : 
case "sec" : 
return Field . Second ; 
case "millisecond" : 
case "millisec" : 
case "msec" : 
return Field . Millisec ; 
case "minute" : 
case "min" : 
return Field . Minute ; 
case "hour" : 
case "hr" : 
case "h" : 
return Field . Hour ; 
case "day" : 
case "d" : 
return Field . Day ; 
case "month" : 
case "mon" : 
return Field . Month ; 
case "year" : 
case "yr" : 
return Field . Year ; 
} public static CalendarPeriod of ( int value , Field field ) { 
CalendarPeriod want = new CalendarPeriod ( value , field ) ; 
if ( cache == null ) return want ; 
CalendarPeriod got = cache . getIfPresent ( want ) ; 
if ( got != null ) return got ; 
cache . put ( want , want ) ; 
} public static CalendarPeriod of ( String udunit ) { 
String units ; 
String [ ] split = StringUtil2 . splitString ( udunit ) ; 
if ( split . length == 1 ) { 
value = 1 ; 
units = split [ 0 ] ; 
} else if ( split . length == 2 ) { 
value = Integer . parseInt ( split [ 0 ] ) ; 
units = split [ 1 ] ; 
CalendarPeriod . Field unit = CalendarPeriod . fromUnitString ( units ) ; 
return CalendarPeriod . of ( value , unit ) ; 
} public int subtract ( CalendarDate start , CalendarDate end ) { 
long diff = end . getDifferenceInMsecs ( start ) ; 
int thislen = millisecs ( ) ; 
if ( ( diff % thislen != 0 ) ) 
return ( int ) ( diff / thislen ) ; 
} public double getConvertFactor ( CalendarPeriod from ) { 
if ( field == CalendarPeriod . Field . Month || field == CalendarPeriod . Field . Year ) { 
return ( double ) from . millisecs ( ) / millisecs ( ) ; 
} public double getValueInMillisecs ( ) { 
if ( field == CalendarPeriod . Field . Month ) 
return 30.0 * 24.0 * 60.0 * 60.0 * 1000.0 * value ; 
else if ( field == CalendarPeriod . Field . Year ) 
return 365.0 * 24.0 * 60.0 * 60.0 * 1000.0 * value ; 
else return millisecs ( ) ; 
} public int getOffset ( CalendarDate start , CalendarDate end ) { 
if ( start . equals ( end ) ) return 0 ; 
long start_millis = start . getDateTime ( ) . getMillis ( ) ; 
long end_millis = end . getDateTime ( ) . getMillis ( ) ; 
Period p ; 
if ( start_millis < end_millis ) 
p = new Period ( start_millis , end_millis + 5000 , getPeriodType ( ) ) ; 
p = new Period ( start_millis + 5000 , end_millis , getPeriodType ( ) ) ; 
return p . get ( getDurationFieldType ( ) ) ; 
gemreader = new GempakGridReader ( raf . getLocation ( ) ) ; 
GridIndex index = gemreader . getGridIndex ( ) ; 
} protected void open ( GridIndex index , CancelTask cancelTask ) throws IOException { 
GempakLookup lookup = new GempakLookup ( ( GempakGridRecord ) index . getGridRecords ( ) . get ( 0 ) ) ; 
} public boolean sync ( ) throws IOException { 
if ( ( gemreader . getInitFileSize ( ) < raf . length ( ) ) && extendIndex ) { 
gemreader . init ( true ) ; 
} private void initTables ( ) { 
GempakGridParameterTable . addParameters ( 
"resources/nj22/tables/gempak/wmogrib3.tbl" ) ; 
"resources/nj22/tables/gempak/ncepgrib2.tbl" ) ; 
} private boolean put ( DataRootExt dateRootExt ) { 
map . put ( dateRootExt . getPath ( ) , dateRootExt ) ; 
return treeSet . add ( dateRootExt . getPath ( ) ) ; 
} public String findLongestPathMatch ( String reqPath ) { 
SortedSet < String > tail = treeSet . tailSet ( reqPath ) ; 
String after = tail . first ( ) ; 
if ( reqPath . startsWith ( after ) ) 
return tail . first ( ) ; 
for ( String key : tail ) { 
if ( reqPath . startsWith ( key ) ) 
if ( StringUtil2 . match ( reqPath , key ) == 0 ) 
} public DataRoot findDataRoot ( String reqPath ) { 
String path = findLongestPathMatch ( reqPath ) ; 
DataRootExt dataRootExt = map . get ( path ) ; 
if ( dataRootExt == null ) { 
return convert2DataRoot ( dataRootExt ) ; 
} public @ Nonnull DataRoot convert2DataRoot ( DataRootExt dataRootExt ) { 
DataRoot dataRoot = dataRootExt . getDataRoot ( ) ; 
if ( dataRoot != null ) return dataRoot ; 
dataRoot = readDataRootFromCatalog ( dataRootExt ) ; 
dataRootExt . setDataRoot ( dataRoot ) ; 
return dataRoot ; 
} public void extractDataRoots ( String catalogRelPath , List < Dataset > dsList , boolean checkDups , Map < String , String > idMap ) { 
for ( Dataset dataset : dsList ) { 
if ( dataset instanceof DatasetScan ) { 
DatasetScan ds = ( DatasetScan ) dataset ; 
addRoot ( ds , catalogRelPath , checkDups ) ; 
} else if ( dataset instanceof FeatureCollectionRef ) { 
FeatureCollectionRef fc = ( FeatureCollectionRef ) dataset ; 
addRoot ( fc , catalogRelPath , checkDups ) ; 
if ( idMap != null ) { 
String catWithSameFc = idMap . get ( fc . getCollectionName ( ) ) ; 
if ( catWithSameFc != null ) 
idMap . put ( fc . getCollectionName ( ) , catalogRelPath ) ; 
} else if ( dataset instanceof CatalogScan ) { 
CatalogScan catScan = ( CatalogScan ) dataset ; 
addRoot ( catScan , catalogRelPath , checkDups ) ; 
if ( ! ( dataset instanceof CatalogRef ) ) { 
extractDataRoots ( catalogRelPath , dataset . getDatasetsLocal ( ) , checkDups , idMap ) ; 
} public CalendarDateRange getCalendarDateRange ( Calendar cal ) { 
if ( dateRange == null ) return null ; 
if ( cal . equals ( Calendar . getDefault ( ) ) ) return dateRange ; 
return makeCalendarDateRange ( cal ) ; 
} public List < Integer > reindex ( List < Coordinate > coords ) { 
List < Integer > result = new ArrayList < > ( ) ; 
Coordinate sub = swap . get ( coord ) ; 
Coordinate use = ( sub == null ) ? coord : sub ; 
Integer idx = indexMap . get ( use ) ; 
result . add ( idx ) ; 
} static public NetcdfFileWriter openExisting ( String location ) throws IOException { 
return new NetcdfFileWriter ( null , location , true , null ) ; 
} static public NetcdfFileWriter createNew ( Version version , String location , Nc4Chunking chunker ) throws IOException { 
return new NetcdfFileWriter ( version , location , false , chunker ) ; 
return addDimension ( null , dimName , length , false , false ) ; 
} public Dimension addDimension ( Group g , String dimName , int length ) { 
return addDimension ( g , dimName , length , false , false ) ; 
} public Dimension addDimension ( Group g , String dimName , int length , boolean isUnlimited , boolean isVariableLength ) { 
if ( ! isValidObjectName ( dimName ) ) 
Dimension dim = new Dimension ( dimName , length , true , isUnlimited , isVariableLength ) ; 
ncfile . addDimension ( g , dim ) ; 
} public Dimension renameDimension ( Group g , String oldName , String newName ) { 
if ( g == null ) g = ncfile . getRootGroup ( ) ; 
Dimension dim = g . findDimension ( oldName ) ; 
} public Group addGroup ( Group parent , String name ) { 
if ( parent == null ) return ncfile . getRootGroup ( ) ; 
Group result = new Group ( ncfile , parent , name ) ; 
parent . addGroup ( result ) ; 
} public Attribute addGroupAttribute ( Group g , Attribute att ) { 
if ( ! isValidObjectName ( att . getShortName ( ) ) ) { 
String attName = createValidObjectName ( att . getShortName ( ) ) ; 
return ncfile . addAttribute ( g , att ) ; 
} public EnumTypedef addTypedef ( Group g , EnumTypedef td ) { 
if ( ! version . isExtendedModel ( ) ) 
g . addEnumeration ( td ) ; 
return td ; 
} public Attribute deleteGroupAttribute ( Group g , String attName ) { 
Attribute att = g . findAttribute ( attName ) ; 
g . remove ( att ) ; 
} public Attribute renameGroupAttribute ( Group g , String oldName , String newName ) { 
if ( ! isValidObjectName ( newName ) ) { 
String newnewName = createValidObjectName ( newName ) ; 
newName = newnewName ; 
Attribute att = g . findAttribute ( oldName ) ; 
g . addAttribute ( att ) ; 
} public Variable addVariable ( Group g , String shortName , DataType dataType , String dimString ) { 
Group parent = ( g == null ) ? ncfile . getRootGroup ( ) : g ; 
return addVariable ( g , null , shortName , dataType , Dimension . makeDimensionsList ( parent , dimString ) ) ; 
} public Variable addVariable ( Group g , String shortName , DataType dataType , List < Dimension > dims ) { 
Variable oldVar = g . findVariable ( shortName ) ; 
if ( oldVar != null ) return null ; 
return addVariable ( g , null , shortName , dataType , dims ) ; 
} public Variable addVariable ( Group g , Structure parent , String shortName , DataType dataType , List < Dimension > dims ) { 
DataType writeType = version . isExtendedModel ( ) ? 
dataType : dataType . withSignedness ( DataType . Signedness . SIGNED ) ; 
boolean usingSignForUnsign = writeType != dataType ; 
if ( ! isValidDataType ( writeType ) ) 
if ( ! version . isExtendedModel ( ) ) { 
Dimension d = dims . get ( i ) ; 
if ( d . isUnlimited ( ) && ( i != 0 ) ) 
shortName = makeValidObjectName ( shortName ) ; 
v = new Structure ( ncfile , g , parent , shortName ) ; 
v = new Variable ( ncfile , g , parent , shortName ) ; 
v . setDataType ( writeType ) ; 
if ( usingSignForUnsign ) 
v . addAttribute ( new Attribute ( CDM . UNSIGNED , "true" ) ) ; 
if ( version == Version . netcdf3 && size > N3iosp . MAX_VARSIZE ) 
} public Structure addCopyOfStructure ( Group g , @ Nonnull Structure original , String shortName , List < Dimension > dims ) { 
if ( original == null ) 
Structure s = new Structure ( ncfile , g , null , shortName ) ; 
s . setDimensions ( dims ) ; 
for ( Variable m : original . getVariables ( ) ) { 
Variable nest = new Variable ( ncfile , g , s , m . getShortName ( ) ) ; 
nest . setDataType ( m . getDataType ( ) ) ; 
nest . setDimensions ( m . getDimensions ( ) ) ; 
nest . addAll ( m . getAttributes ( ) ) ; 
s . addMemberVariable ( nest ) ; 
ncfile . addVariable ( g , s ) ; 
} public Variable addStringVariable ( Group g , Variable stringVar , List < Dimension > dims ) { 
if ( ! N3iosp . isValidNetcdfObjectName ( stringVar . getShortName ( ) ) ) 
int max_strlen = 0 ; 
data = stringVar . read ( ) ; 
String s = ( String ) ii . getObjectNext ( ) ; 
max_strlen = Math . max ( max_strlen , s . length ( ) ) ; 
log . error ( err ) ; 
System . out . println ( err ) ; 
return addStringVariable ( g , stringVar . getShortName ( ) , dims , max_strlen ) ; 
} public Variable addStringVariable ( Group g , String shortName , List < Dimension > dims , int max_strlen ) { 
Variable v = new Variable ( ncfile , g , null , shortName ) ; 
Dimension d = addDimension ( g , shortName + "_strlen" , max_strlen ) ; 
List < Dimension > sdims = new ArrayList < > ( dims ) ; 
Variable v = ncfile . findVariable ( oldName ) ; 
if ( null != v ) { 
String fullOldNameEscaped = v . getFullNameEscaped ( ) ; 
v . setName ( newName ) ; 
varRenameMap . put ( v . getFullNameEscaped ( ) , fullOldNameEscaped ) ; 
} public boolean addVariableAttribute ( Variable v , Attribute att ) { 
if ( ! isNewFile ) 
spiw . create ( location , ncfile , extraHeader , preallocateSize , isLargeFile ) ; 
} public boolean setRedefineMode ( boolean redefineMode ) throws IOException { 
if ( redefineMode && ! defineMode ) { 
defineMode = true ; 
} else if ( ! redefineMode && defineMode ) { 
boolean ok = spiw . rewriteHeader ( isLargeFile ) ; 
rewrite ( ) ; 
return ! ok ; 
if ( ! prevFile . exists ( ) ) { 
if ( tmpFile . exists ( ) ) { 
boolean ok = tmpFile . delete ( ) ; 
FileWriter2 fileWriter2 = new FileWriter2 ( this ) ; 
String oldVarName = v . getFullName ( ) ; 
Variable oldVar = oldFile . findVariable ( oldVarName ) ; 
if ( oldVar != null ) { 
fileWriter2 . copyAll ( oldVar , v ) ; 
} else if ( varRenameMap . containsKey ( oldVarName ) ) { 
String realOldVarName = varRenameMap . get ( oldVarName ) ; 
oldVar = oldFile . findVariable ( realOldVarName ) ; 
log . warn ( message ) ; 
} public Structure addRecordStructure ( ) { 
if ( version != Version . netcdf3 ) return null ; 
boolean ok = ( Boolean ) ncfile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; 
return ( Structure ) ncfile . findVariable ( "record" ) ; 
} public void write ( String varname , Array values ) throws java . io . IOException , InvalidRangeException { 
write ( findVariable ( varname ) , values ) ; 
} public void write ( Variable v , Array values ) throws java . io . IOException , InvalidRangeException { 
if ( ncfile != v . getNetcdfFile ( ) ) 
write ( v , new int [ values . getRank ( ) ] , values ) ; 
} public void write ( Variable v , int [ ] origin , Array values ) throws java . io . IOException , InvalidRangeException { 
spiw . writeData ( v , new Section ( origin , values . getShape ( ) ) , values ) ; 
v . invalidateCache ( ) ; 
} public void writeStringData ( Variable v , Array values ) throws java . io . IOException , InvalidRangeException { 
writeStringData ( v , new int [ values . getRank ( ) ] , values ) ; 
} public void writeStringData ( Variable v , int [ ] origin , Array values ) throws java . io . IOException , InvalidRangeException { 
if ( v . getDataType ( ) != DataType . CHAR ) 
int rank = v . getRank ( ) ; 
int strlen = v . getShape ( rank - 1 ) ; 
write ( v , corigin , cvalues ) ; 
} public synchronized void close ( ) throws java . io . IOException { 
setRedefineMode ( false ) ; 
} public void abort ( ) throws java . io . IOException { 
} public void writeProperties ( PrintWriter out ) throws IOException { 
if ( p == null ) p = BeanParser . getParser ( o . getClass ( ) ) ; 
p . writeProperties ( o , out ) ; 
} public ThreddsMetadata extract ( Dataset threddsDataset ) throws IOException { 
ThreddsMetadata metadata = new ThreddsMetadata ( ) ; 
Map < String , Object > flds = metadata . getFlds ( ) ; 
try ( DataFactory . Result result = new DataFactory ( ) . openFeatureDataset ( threddsDataset , null ) ) { 
if ( result . featureType . isCoverageFeatureType ( ) ) { 
flds . put ( Dataset . GeospatialCoverage , extractGeospatial ( gridDataset ) ) ; 
CalendarDateRange tc = extractCalendarDateRange ( gridDataset ) ; 
if ( tc != null ) 
flds . put ( Dataset . TimeCoverage , tc ) ; 
ThreddsMetadata . VariableGroup vars = extractVariables ( threddsDataset . getDataFormatName ( ) , gridDataset ) ; 
flds . put ( Dataset . VariableGroups , vars ) ; 
} else if ( result . featureType . isPointFeatureType ( ) ) { 
PointDatasetImpl pobsDataset = ( PointDatasetImpl ) result . featureDataset ; 
if ( null != llbb ) 
flds . put ( Dataset . GeospatialCoverage , new ThreddsMetadata . GeospatialCoverage ( llbb , null , 0.0 , 0.0 ) ) ; 
CalendarDateRange tc = extractCalendarDateRange ( pobsDataset ) ; 
ThreddsMetadata . VariableGroup vars = extractVariables ( pobsDataset ) ; 
return metadata ; 
} public ThreddsMetadata . GeospatialCoverage extractGeospatial ( FeatureDatasetPoint fd ) { 
LatLonRect llbb = fd . getBoundingBox ( ) ; 
if ( llbb != null ) { 
return new ThreddsMetadata . GeospatialCoverage ( llbb , null , 0.0 , 0.0 ) ; 
} public CalendarDateRange extractCalendarDateRange ( GridDataset gridDataset ) { 
CalendarDateRange maxDateRange = null ; 
for ( GridDataset . Gridset gridset : gridDataset . getGridsets ( ) ) { 
GridCoordSystem gsys = gridset . getGeoCoordSystem ( ) ; 
CalendarDateRange dateRange ; 
CoordinateAxis1DTime time1D = gsys . getTimeAxis1D ( ) ; 
if ( time1D != null ) { 
dateRange = time1D . getCalendarDateRange ( ) ; 
CoordinateAxis time = gsys . getTimeAxis ( ) ; 
if ( time == null ) 
CalendarDateUnit du = CalendarDateUnit . of ( null , time . getUnitsString ( ) ) ; 
CalendarDate minDate = du . makeCalendarDate ( time . getMinValue ( ) ) ; 
CalendarDate maxDate = du . makeCalendarDate ( time . getMaxValue ( ) ) ; 
dateRange = CalendarDateRange . of ( minDate , maxDate ) ; 
if ( maxDateRange == null ) 
maxDateRange = dateRange ; 
maxDateRange = maxDateRange . extend ( dateRange ) ; 
return maxDateRange ; 
} List < String > matchNcepNames ( GridDataset gds , String oldName ) { 
if ( contains ( gds , oldName ) ) { 
result . add ( oldName ) ; 
Attribute att = gds . findGlobalAttributeIgnoreCase ( CDM . FILE_FORMAT ) ; 
boolean isGrib1 = ( att != null ) && att . getStringValue ( ) . startsWith ( "GRIB-1" ) ; 
boolean isGrib2 = ( att != null ) && att . getStringValue ( ) . startsWith ( "GRIB-2" ) ; 
HashMap < String , Renamer > map ; 
if ( map1 == null ) initMap1 ( ) ; 
map = map1 ; 
} else if ( isGrib2 ) { 
if ( map2 == null ) initMap2 ( ) ; 
map = map2 ; 
Renamer mbean = map . get ( oldName ) ; 
if ( mbean != null && mbean . newName != null && contains ( gds , mbean . newName ) ) { 
result . add ( mbean . newName ) ; 
if ( mbean != null ) { 
String dataset = extractDatasetFromLocation ( gds . getLocation ( ) ) ; 
for ( VariableRenamerBean r : mbean . newVars ) { 
if ( r . getDatasetType ( ) . equals ( dataset ) && contains ( gds , r . newName ) ) result . add ( r . newName ) ; 
if ( result . size ( ) == 1 ) return result ; 
result . clear ( ) ; 
for ( VariableRenamerBean r : mbean . newVarsMap . values ( ) ) { 
if ( contains ( gds , r . newName ) ) result . add ( r . newName ) ; 
if ( result . size ( ) > 0 ) return result ; 
String oldMunged = munge ( oldName ) ; 
for ( GridDatatype grid : gds . getGrids ( ) ) { 
String newMunged = munge ( grid . getShortName ( ) ) ; 
if ( newMunged . startsWith ( oldMunged ) ) 
result . add ( grid . getShortName ( ) ) ; 
} private HashMap < String , Renamer > makeMapBeans ( List < VariableRenamerBean > vbeans ) { 
HashMap < String , Renamer > map = new HashMap < > ( 3000 ) ; 
for ( VariableRenamerBean vbean : vbeans ) { 
Renamer mbean = map . get ( vbean . getOldName ( ) ) ; 
if ( mbean == null ) { 
mbean = new Renamer ( vbean . getOldName ( ) ) ; 
map . put ( vbean . getOldName ( ) , mbean ) ; 
mbean . add ( vbean ) ; 
for ( Renamer rmap : map . values ( ) ) { 
rmap . finish ( ) ; 
} public static MeasurementTimeseriesType initMeasurementTimeseries ( MeasurementTimeseriesType measurementTimeseries , 
String id = MarshallingUtil . createIdForType ( MeasurementTimeseriesType . class ) ; 
measurementTimeseries . setId ( id ) ; 
NcTVPDefaultMetadataPropertyType . initDefaultPointMetadata ( 
measurementTimeseries . addNewDefaultPointMetadata ( ) , dataVar ) ; 
for ( PointFeature pf : stationFeat ) { 
Point . initPoint ( measurementTimeseries . addNewPoint ( ) , pf , dataVar ) ; 
return measurementTimeseries ; 
return that instanceof OffsetUnit 
? getUnit ( ) . multiplyBy ( ( ( OffsetUnit ) that ) . getUnit ( ) ) 
: getUnit ( ) . multiplyBy ( that ) ; 
? getUnit ( ) . divideBy ( ( ( OffsetUnit ) that ) . getUnit ( ) ) 
: getUnit ( ) . divideBy ( that ) ; 
? getUnit ( ) . divideInto ( ( ( OffsetUnit ) that ) . getUnit ( ) ) 
: getUnit ( ) . divideInto ( that ) ; 
return ( ( DerivableUnit ) getUnit ( ) ) . toDerivedUnit ( amount + getOffset ( ) ) ; 
return ( ( DerivableUnit ) getUnit ( ) ) . fromDerivedUnit ( amount ) 
- getOffset ( ) ; 
} public double [ ] fromDerivedUnit ( final double [ ] input , final double [ ] output ) 
( ( DerivableUnit ) getUnit ( ) ) . fromDerivedUnit ( input , output ) ; 
final double origin = getOffset ( ) ; 
output [ i ] -= origin ; 
} public Array convertNestedVariable ( ucar . nc2 . Variable v , List < Range > section , DodsV dataV , boolean flatten ) throws IOException , DAP2Exception { 
Array data = convertTopVariable ( v , section , dataV ) ; 
if ( flatten ) { 
ArrayStructure as = ( ArrayStructure ) data ; 
Variable nested = v ; 
while ( nested . isMemberOfStructure ( ) ) { 
names . add ( 0 , nested . getShortName ( ) ) ; 
nested = nested . getParentStructure ( ) ; 
StructureMembers . Member m = findNested ( as , names , v . getShortName ( ) ) ; 
Array mdata = m . getDataArray ( ) ; 
if ( mdata instanceof ArraySequenceNested ) { 
ArraySequenceNested arraySeq = ( ArraySequenceNested ) mdata ; 
return arraySeq . flatten ( ) ; 
return mdata ; 
} public Array convertTopVariable ( ucar . nc2 . Variable v , List < Range > section , DodsV dataV ) throws IOException , DAP2Exception { 
Array data = convert ( dataV ) ; 
if ( ( dataV . darray != null ) && ( dataV . bt instanceof DString ) ) { 
if ( v . getDataType ( ) == DataType . STRING ) 
return convertStringArray ( data , v ) ; 
else if ( v . getDataType ( ) == DataType . CHAR ) 
return convertStringArrayToChar ( dataV . darray , v , section ) ; 
logger . error ( mess ) ; 
throw new IllegalArgumentException ( mess ) ; 
if ( ( dataV . bt instanceof DString ) && ( v . getDataType ( ) == DataType . CHAR ) ) { 
return convertStringToChar ( data , v ) ; 
} public Array convert ( DodsV dataV ) throws IOException , DAP2Exception { 
if ( dataV . darray == null ) { 
if ( dataV . bt instanceof DStructure ) { 
ArrayStructure structArray = makeArrayStructure ( dataV ) ; 
iconvertDataStructure ( ( DStructure ) dataV . bt , structArray . getStructureMembers ( ) ) ; 
return structArray ; 
} else if ( dataV . bt instanceof DGrid ) { 
} else if ( dataV . bt instanceof DSequence ) { 
iconvertDataSequenceArray ( ( DSequence ) dataV . bt , structArray . getStructureMembers ( ) ) ; 
DataType dtype = dataV . getDataType ( ) ; 
Array scalarData = Array . factory ( dtype , new int [ 0 ] ) ; 
IndexIterator scalarIndex = scalarData . getIndexIterator ( ) ; 
iconvertDataPrimitiveScalar ( dataV . bt , scalarIndex ) ; 
return scalarData ; 
if ( dataV . darray != null ) { 
iconvertDataStructureArray ( dataV . darray , structArray . getStructureMembers ( ) ) ; 
} else if ( dataV . bt instanceof DString ) { 
return convertStringArray ( dataV . darray ) ; 
opendap . dap . PrimitiveVector pv = dataV . darray . getPrimitiveVector ( ) ; 
Object storage = pv . getInternalStorage ( ) ; 
return Array . factory ( dtype , makeShape ( dataV . darray ) , storage ) ; 
throw new IllegalStateException ( mess ) ; 
} private void iconvertDataStructureArray ( DVector darray , StructureMembers members ) throws DAP2Exception { 
List < StructureMembers . Member > mlist = members . getMembers ( ) ; 
for ( StructureMembers . Member member : mlist ) { 
String name = member . getName ( ) ; 
IndexIterator ii = ( IndexIterator ) member . getDataObject ( ) ; 
BaseTypePrimitiveVector pv = ( BaseTypePrimitiveVector ) darray . getPrimitiveVector ( ) ; 
for ( int row = 0 ; row < pv . getLength ( ) ; row ++ ) { 
DStructure ds_data = ( DStructure ) pv . getValue ( row ) ; 
BaseType member_data = ds_data . getVariable ( name ) ; 
iconvertData ( member_data , ii ) ; 
} private void iconvertDataPrimitiveScalar ( BaseType dodsScalar , IndexIterator ii ) { 
if ( dodsScalar instanceof DString ) { 
String sval = ( ( DString ) dodsScalar ) . getValue ( ) ; 
ii . setObjectNext ( sval ) ; 
} else if ( dodsScalar instanceof DUInt32 ) { 
int ival = ( ( DUInt32 ) dodsScalar ) . getValue ( ) ; 
long lval = DataType . unsignedIntToLong ( ival ) ; 
ii . setLongNext ( lval ) ; 
} else if ( dodsScalar instanceof DUInt16 ) { 
short sval = ( ( DUInt16 ) dodsScalar ) . getValue ( ) ; 
int ival = DataType . unsignedShortToInt ( sval ) ; 
ii . setIntNext ( ival ) ; 
} else if ( dodsScalar instanceof DFloat32 ) 
ii . setFloatNext ( ( ( DFloat32 ) dodsScalar ) . getValue ( ) ) ; 
else if ( dodsScalar instanceof DFloat64 ) 
ii . setDoubleNext ( ( ( DFloat64 ) dodsScalar ) . getValue ( ) ) ; 
else if ( dodsScalar instanceof DInt32 ) 
ii . setIntNext ( ( ( DInt32 ) dodsScalar ) . getValue ( ) ) ; 
else if ( dodsScalar instanceof DInt16 ) 
ii . setShortNext ( ( ( DInt16 ) dodsScalar ) . getValue ( ) ) ; 
else if ( dodsScalar instanceof DByte ) 
ii . setByteNext ( ( ( DByte ) dodsScalar ) . getValue ( ) ) ; 
} private void iconvertDataPrimitiveArray ( PrimitiveVector pv , IndexIterator ii ) { 
BaseType bt = pv . getTemplate ( ) ; 
if ( bt instanceof DString ) { 
BaseTypePrimitiveVector bpv = ( BaseTypePrimitiveVector ) pv ; 
for ( int row = 0 ; row < bpv . getLength ( ) ; row ++ ) { 
DString ds = ( DString ) bpv . getValue ( row ) ; 
ii . setObjectNext ( ds . getValue ( ) ) ; 
} else if ( bt instanceof DUInt32 ) { 
UInt32PrimitiveVector bpv = ( UInt32PrimitiveVector ) pv ; 
int ival = bpv . getValue ( row ) ; 
} else if ( bt instanceof DUInt16 ) { 
UInt16PrimitiveVector bpv = ( UInt16PrimitiveVector ) pv ; 
short sval = bpv . getValue ( row ) ; 
} else if ( bt instanceof DFloat32 ) { 
Float32PrimitiveVector bpv = ( Float32PrimitiveVector ) pv ; 
for ( int row = 0 ; row < bpv . getLength ( ) ; row ++ ) 
ii . setFloatNext ( bpv . getValue ( row ) ) ; 
} else if ( bt instanceof DFloat64 ) { 
Float64PrimitiveVector bpv = ( Float64PrimitiveVector ) pv ; 
ii . setDoubleNext ( bpv . getValue ( row ) ) ; 
} else if ( bt instanceof DInt32 ) { 
Int32PrimitiveVector bpv = ( Int32PrimitiveVector ) pv ; 
ii . setIntNext ( bpv . getValue ( row ) ) ; 
} else if ( bt instanceof DInt16 ) { 
Int16PrimitiveVector bpv = ( Int16PrimitiveVector ) pv ; 
ii . setShortNext ( bpv . getValue ( row ) ) ; 
} else if ( bt instanceof DByte ) { 
BytePrimitiveVector bpv = ( BytePrimitiveVector ) pv ; 
ii . setByteNext ( bpv . getValue ( row ) ) ; 
} private Array convertStringArray ( Array data , Variable ncVar ) { 
String [ ] storage = ( String [ ] ) data . getStorage ( ) ; 
int max_len = 0 ; 
for ( String s : storage ) { 
max_len = Math . max ( max_len , s . length ( ) ) ; 
if ( max_len > 1 ) return data ; 
int n = ( int ) data . getSize ( ) ; 
char [ ] charStorage = new char [ n ] ; 
if ( s . length ( ) > 0 ) 
charStorage [ count ++ ] = s . charAt ( 0 ) ; 
ncVar . setDataType ( DataType . CHAR ) ; 
return Array . factory ( DataType . CHAR , data . getShape ( ) , charStorage ) ; 
} static synchronized public void closeAll ( ) { 
List < MetadataManager > closeDatabases = new ArrayList < > ( openDatabases ) ; 
for ( MetadataManager mm : closeDatabases ) { 
mm . close ( ) ; 
openDatabases = new ArrayList < > ( ) ; 
if ( myEnv != null ) { 
myEnv . close ( ) ; 
myEnv = null ; 
} catch ( DatabaseException dbe ) { 
} private synchronized void openDatabase ( ) { 
if ( database != null ) return ; 
DatabaseConfig dbConfig = new DatabaseConfig ( ) ; 
dbConfig . setReadOnly ( readOnly ) ; 
dbConfig . setAllowCreate ( ! readOnly ) ; 
if ( ! readOnly ) 
dbConfig . setDeferredWrite ( true ) ; 
database = myEnv . openDatabase ( null , collectionName , dbConfig ) ; 
openDatabases . add ( this ) ; 
protected boolean _validate ( StringBuffer buff ) { 
new DateType ( tf . getText ( ) , null , null ) ; 
protected Object getEditValue ( ) { 
return new DateType ( tf . getText ( ) , null , null ) ; 
} static org . joda . time . Period convertToPeriod ( int value , String udunit ) { 
return Period . millis ( value ) ; 
return Period . seconds ( value ) ; 
return Period . minutes ( value ) ; 
return Period . hours ( value ) ; 
return Period . days ( value ) ; 
case "week" : 
return Period . weeks ( value ) ; 
return Period . months ( value ) ; 
return Period . years ( value ) ; 
} private ImmutableMap < Integer , Entry > readTable ( String path ) throws IOException { 
ImmutableMap . Builder < Integer , Entry > builder = ImmutableMap . builder ( ) ; 
int code = Integer . parseInt ( num1 ) ; 
EcmwfEntry entry = new EcmwfEntry ( code , desc ) ; 
builder . put ( entry . getCode ( ) , entry ) ; 
} public boolean findCoordElementForce ( double wantLat , double wantLon , int [ ] rectIndex ) { 
findBounds ( ) ; 
if ( wantLat < latMinMax . min ) return false ; 
if ( wantLat > latMinMax . max ) return false ; 
if ( wantLon < lonMinMax . min ) return false ; 
if ( wantLon > lonMinMax . max ) return false ; 
boolean saveDebug = debug ; 
debug = false ; 
for ( int row = 0 ; row < nrows ; row ++ ) { 
for ( int col = 0 ; col < ncols ; col ++ ) { 
rectIndex [ 0 ] = row ; 
rectIndex [ 1 ] = col ; 
if ( contains ( wantLat , wantLon , rectIndex ) ) { 
debug = saveDebug ; 
} public boolean findCoordElementNoForce ( double wantLat , double wantLon , int [ ] rectIndex ) { 
double gradientLat = ( latMinMax . max - latMinMax . min ) / nrows ; 
double gradientLon = ( lonMinMax . max - lonMinMax . min ) / ncols ; 
double diffLat = wantLat - latMinMax . min ; 
double diffLon = wantLon - lonMinMax . min ; 
rectIndex [ 0 ] = ( int ) Math . round ( diffLat / gradientLat ) ; 
rectIndex [ 1 ] = ( int ) Math . round ( diffLon / gradientLon ) ; 
if ( contains ( wantLat , wantLon , rectIndex ) ) 
if ( ! jump2 ( wantLat , wantLon , rectIndex ) ) return false ; 
if ( count > 10 ) { 
} public static ErddapStringArray fromInputStream ( InputStream inputStream , String charset ) throws IOException { 
if ( charset == null || charset . isEmpty ( ) ) { 
charset = CDM . UTF8 ; 
InputStreamReader isr = new InputStreamReader ( inputStream , charset ) ; 
BufferedReader bufferedReader = new BufferedReader ( isr ) ; 
ErddapStringArray sa = new ErddapStringArray ( ) ; 
for ( String s ; ( s = bufferedReader . readLine ( ) ) != null ; ) { 
sa . add ( s ) ; 
} public void add ( String value ) { 
if ( size == array . length ) 
ensureCapacity ( size + 1L ) ; 
array [ size ++ ] = value ; 
} public void ensureCapacity ( long minCapacity ) { 
if ( array . length < minCapacity ) { 
ErddapMath2 . ensureArraySizeOkay ( minCapacity , "StringArray" ) ; 
int newCapacity = ( int ) Math . min ( Integer . MAX_VALUE - 1 , array . length + ( long ) array . length ) ; 
if ( newCapacity < minCapacity ) 
newCapacity = ( int ) minCapacity ; 
String [ ] newArray = new String [ newCapacity ] ; 
System . arraycopy ( array , 0 , newArray , 0 , size ) ; 
array = newArray ; 
} public String get ( int index ) { 
if ( index >= size ) 
return array [ index ] ; 
final Attribute levelAtt = ds . findAttribute ( "/HDFEOS/ADDITIONAL/FILE_ATTRIBUTES/@ProcessLevel" ) ; 
if ( levelAtt == null ) { return ; } 
final int level = levelAtt . getStringValue ( ) . startsWith ( "2" ) ? 2 : 3 ; 
if ( level == 3 ) { augmentDataset3 ( ds ) ; } 
} public ProjectionPoint latLonToProj ( LatLonPoint latlon , ProjectionPointImpl destPoint ) { 
double lat = latlon . getLatitude ( ) ; 
double lon = latlon . getLongitude ( ) ; 
double [ ] p0 = new double [ ] 
{ Math . cos ( lat * RAD_PER_DEG ) * Math . cos ( lon * RAD_PER_DEG ) , 
Math . cos ( lat * RAD_PER_DEG ) * Math . sin ( lon * RAD_PER_DEG ) , 
Math . sin ( lat * RAD_PER_DEG ) } ; 
double [ ] p1 = new double [ ] 
{ rotZ [ 0 ] [ 0 ] * p0 [ 0 ] + rotZ [ 0 ] [ 1 ] * p0 [ 1 ] + rotZ [ 0 ] [ 2 ] * p0 [ 2 ] , 
rotZ [ 1 ] [ 0 ] * p0 [ 0 ] + rotZ [ 1 ] [ 1 ] * p0 [ 1 ] + rotZ [ 1 ] [ 2 ] * p0 [ 2 ] , 
rotZ [ 2 ] [ 0 ] * p0 [ 0 ] + rotZ [ 2 ] [ 1 ] * p0 [ 1 ] + rotZ [ 2 ] [ 2 ] * p0 [ 2 ] } ; 
double [ ] p2 = new double [ ] 
{ rotY [ 0 ] [ 0 ] * p1 [ 0 ] + rotY [ 0 ] [ 1 ] * p1 [ 1 ] + rotY [ 0 ] [ 2 ] * p1 [ 2 ] , 
rotY [ 1 ] [ 0 ] * p1 [ 0 ] + rotY [ 1 ] [ 1 ] * p1 [ 1 ] + rotY [ 1 ] [ 2 ] * p1 [ 2 ] , 
rotY [ 2 ] [ 0 ] * p1 [ 0 ] + rotY [ 2 ] [ 1 ] * p1 [ 1 ] + rotY [ 2 ] [ 2 ] * p1 [ 2 ] } ; 
final double lonR = LatLonPointImpl . range180 ( Math . atan2 ( p2 [ 1 ] , p2 [ 0 ] ) * DEG_PER_RAD ) ; 
final double latR = Math . asin ( p2 [ 2 ] ) * DEG_PER_RAD ; 
if ( destPoint == null ) 
destPoint = new ProjectionPointImpl ( lonR , latR ) ; 
destPoint . setLocation ( lonR , latR ) ; 
if ( show ) 
return destPoint ; 
} public LatLonPoint projToLatLon ( ProjectionPoint ppt , LatLonPointImpl destPoint ) { 
final double lonR = LatLonPointImpl . range180 ( ppt . getX ( ) ) ; 
final double latR = ppt . getY ( ) ; 
{ Math . cos ( latR * RAD_PER_DEG ) * Math . cos ( lonR * RAD_PER_DEG ) , 
Math . cos ( latR * RAD_PER_DEG ) * Math . sin ( lonR * RAD_PER_DEG ) , 
Math . sin ( latR * RAD_PER_DEG ) } ; 
{ rotY [ 0 ] [ 0 ] * p0 [ 0 ] + rotY [ 1 ] [ 0 ] * p0 [ 1 ] + rotY [ 2 ] [ 0 ] * p0 [ 2 ] , 
rotY [ 0 ] [ 1 ] * p0 [ 0 ] + rotY [ 1 ] [ 1 ] * p0 [ 1 ] + rotY [ 2 ] [ 1 ] * p0 [ 2 ] , 
rotY [ 0 ] [ 2 ] * p0 [ 0 ] + rotY [ 1 ] [ 2 ] * p0 [ 1 ] + rotY [ 2 ] [ 2 ] * p0 [ 2 ] } ; 
{ rotZ [ 0 ] [ 0 ] * p1 [ 0 ] + rotZ [ 1 ] [ 0 ] * p1 [ 1 ] + rotZ [ 2 ] [ 0 ] * p1 [ 2 ] , 
rotZ [ 0 ] [ 1 ] * p1 [ 0 ] + rotZ [ 1 ] [ 1 ] * p1 [ 1 ] + rotZ [ 2 ] [ 1 ] * p1 [ 2 ] , 
rotZ [ 0 ] [ 2 ] * p1 [ 0 ] + rotZ [ 1 ] [ 2 ] * p1 [ 1 ] + rotZ [ 2 ] [ 2 ] * p1 [ 2 ] } ; 
final double lon = Math . atan2 ( p2 [ 1 ] , p2 [ 0 ] ) * DEG_PER_RAD ; 
final double lat = Math . asin ( p2 [ 2 ] ) * DEG_PER_RAD ; 
destPoint = new LatLonPointImpl ( lat , lon ) ; 
destPoint . set ( lat , lon ) ; 
} public void setScanLocation ( String scanLocation ) 
if ( ! scanLocation . equals ( this . scanLocation ) ) 
this . scanLocation = scanLocation ; 
this . scanLocationCrDs = createScanLocationCrDs ( ) ; 
if ( this . scanLocationCrDs == null ) 
else if ( ! this . scanLocationCrDs . exists ( ) ) 
else if ( ! this . scanLocationCrDs . isCollection ( ) ) 
} public String translatePathToLocation ( String dsPath ) 
if ( dsPath . length ( ) > 0 ) 
if ( ! dsPath . startsWith ( this . getPath ( ) ) ) 
String dataDir = dsPath . substring ( this . getPath ( ) . length ( ) ) ; 
CrawlableDataset curCrDs = scanLocationCrDs . getDescendant ( dataDir ) ; 
return curCrDs . getPath ( ) ; 
} public CrawlableDataset requestCrawlableDataset ( String path ) 
String crDsPath = translatePathToLocation ( path ) ; 
if ( crDsPath == null ) 
CatalogBuilder catBuilder = buildCatalogBuilder ( ) ; 
if ( catBuilder == null ) return null ; 
return catBuilder . requestCrawlableDataset ( crDsPath ) ; 
} public InvCatalogImpl makeCatalogForDirectory ( String orgPath , URI catURI ) { 
log . debug ( "baseURI=" + catURI ) ; 
log . debug ( "orgPath=" + orgPath ) ; 
log . debug ( "rootPath=" + rootPath ) ; 
log . debug ( "scanLocation=" + scanLocation ) ; 
String dsDirPath = translatePathToLocation ( orgPath ) ; 
if ( dsDirPath == null ) 
log . error ( tmpMsg ) ; 
if ( catBuilder == null ) 
String dsPath = dsDirPath . substring ( scanLocationCrDs . getPath ( ) . length ( ) ) ; 
CrawlableDataset reqCrDs = scanLocationCrDs . getDescendant ( dsPath ) ; 
CrawlableDataset parent = reqCrDs . getParentDataset ( ) ; 
dsDirPath = parent . getPath ( ) ; 
CrawlableDataset catalogCrDs ; 
catalogCrDs = catBuilder . requestCrawlableDataset ( dsDirPath ) ; 
if ( catalogCrDs == null ) 
if ( ! catalogCrDs . isCollection ( ) ) 
InvCatalogImpl catalog ; 
catalog = catBuilder . generateCatalog ( catalogCrDs ) ; 
if ( catalog != null ) 
catalog . setBaseURI ( catURI ) ; 
} public InvCatalogImpl makeProxyDsResolverCatalog ( String path , URI baseURI ) 
if ( path . endsWith ( "/" ) ) return null ; 
String dsDirPath = translatePathToLocation ( path ) ; 
int pos = dsDirPath . lastIndexOf ( '/' ) ; 
String dsName = dsDirPath . substring ( pos + 1 ) ; 
dsDirPath = dsDirPath . substring ( 0 , pos ) ; 
ProxyDatasetHandler pdh = this . getProxyDatasetHandlers ( ) . get ( dsName ) ; 
if ( pdh == null ) 
catalog = ( InvCatalogImpl ) catBuilder . generateProxyDsResolverCatalog ( catalogCrDs , pdh ) ; 
catalog . setBaseURI ( baseURI ) ; 
} private DataType getCoordinateType ( ) { 
DatasetOuterDimension first = ( DatasetOuterDimension ) nestedDatasets . get ( 0 ) ; 
return first . isStringValued ? DataType . STRING : DataType . DOUBLE ; 
public static Grib2Pds factory ( int template , byte [ ] input ) { 
return new Grib2Pds0 ( input ) ; 
return new Grib2Pds1 ( input ) ; 
return new Grib2Pds2 ( input ) ; 
return new Grib2Pds5 ( input ) ; 
return new Grib2Pds6 ( input ) ; 
return new Grib2Pds8 ( input ) ; 
return new Grib2Pds9 ( input ) ; 
return new Grib2Pds10 ( input ) ; 
return new Grib2Pds11 ( input ) ; 
return new Grib2Pds12 ( input ) ; 
return new Grib2Pds15 ( input ) ; 
return new Grib2Pds30 ( input ) ; 
return new Grib2Pds31 ( input ) ; 
return new Grib2Pds48 ( input ) ; 
return new Grib2Pds61 ( input ) ; 
} public void show ( Formatter f ) { 
template , getForecastTime ( ) , getTimeUnit ( ) , getLevelValue1 ( ) ) ; 
} protected CalendarDate calcTime ( int startIndex ) { 
int year = GribNumbers . int2 ( getOctet ( startIndex ++ ) , getOctet ( startIndex ++ ) ) ; 
int month = getOctet ( startIndex ++ ) ; 
int day = getOctet ( startIndex ++ ) ; 
int hour = getOctet ( startIndex ++ ) ; 
int minute = getOctet ( startIndex ++ ) ; 
int second = getOctet ( startIndex ++ ) ; 
if ( ( year == 0 ) && ( month == 0 ) && ( day == 0 ) && ( hour == 0 ) && ( minute == 0 ) && ( second == 0 ) ) 
return CalendarDate . UNKNOWN ; 
if ( hour > 23 ) { 
day += ( hour / 24 ) ; 
hour = hour % 24 ; 
} double applyScaleFactor ( int scale , int value ) { 
return ( ( scale == 0 ) || ( scale == 255 ) || ( value == 0 ) ) ? value : value * Math . pow ( 10 , - scale ) ; 
} public void writeHtmlDescription ( Formatter out , Dataset ds , 
out . format ( "<html>%n" ) ; 
out . format ( "<head>%n" ) ; 
out . format ( "</head>%n" ) ; 
out . format ( "<body>%n" ) ; 
if ( ds . getDataFormatName ( ) != null ) 
if ( ( ds . getDataSize ( ) > 0 ) ) 
if ( ds . getFeatureTypeName ( ) != null ) 
if ( ds . getCollectionType ( ) != null ) 
if ( ds . getId ( ) != null ) 
String href = resolveRelativeUrls | catrefEvents ? resolve ( ds , catref . getXlinkHref ( ) ) : catref . getXlinkHref ( ) ; 
out . format ( "</ul>%n" ) ; 
java . util . List < Documentation > docs = ds . getDocumentation ( ) ; 
out . format ( "<h3>Documentation:</h3>%n<ul>%n" ) ; 
for ( Documentation doc : docs ) { 
java . util . List < Access > access = ds . getAccess ( ) ; 
out . format ( "<h3>Access:</h3>%n<ol>%n" ) ; 
for ( Access a : access ) { 
Service s = a . getService ( ) ; 
String urlString = resolveRelativeUrls || datasetEvents ? a . getStandardUrlName ( ) : a . getUnresolvedUrlName ( ) ; 
String queryString = null ; 
if ( datasetEvents ) urlString = "dataset:" + urlString ; 
ServiceType stype = s . getType ( ) ; 
if ( isServer && stype != null ) 
switch ( stype ) { 
case DODS : 
urlString = urlString + ".html" ; 
urlString = urlString + ".dmr.xml" ; 
case WCS : 
queryString = "service=WCS&version=1.0.0&request=GetCapabilities" ; 
case WMS : 
queryString = "service=WMS&version=1.3.0&request=GetCapabilities" ; 
case UDDC : 
case ISO : 
String datasetId = ds . getId ( ) ; 
if ( catalogUrl != null && datasetId != null ) { 
queryString = "catalog=" + urlParamEscaper . escape ( catalogUrl ) + "&dataset=" + urlParamEscaper . escape ( datasetId ) ; 
case NetcdfSubset : 
urlString = urlString + "/dataset.html" ; 
queryString = "req=cdl" ; 
case CdmrFeature : 
queryString = "req=form" ; 
out . format ( "</ol>%n" ) ; 
out . format ( "<h3>Contributors:</h3>%n<ul>%n" ) ; 
out . format ( "<h3>Keywords:</h3>%n<ul>%n" ) ; 
out . format ( "<h3>Dates:</h3>%n<ul>%n" ) ; 
out . format ( "<h3>Projects:</h3>%n<ul>%n" ) ; 
out . format ( "<h3>Creators:</h3>%n<ul>%n" ) ; 
String newUrl = resolveRelativeUrls ? makeHrefResolve ( ds , t . getUrl ( ) , null ) : makeHref ( t . getUrl ( ) , null , null ) ; 
out . format ( "<h3>Publishers:</h3>%n<ul>%n" ) ; 
String urlLink = resolveRelativeUrls ? makeHrefResolve ( ds , t . getUrl ( ) , null ) : makeHref ( t . getUrl ( ) , null , null ) ; 
java . util . List < ThreddsMetadata . VariableGroup > vars = ds . getVariables ( ) ; 
out . format ( "<h3>Variables:</h3>%n<ul>%n" ) ; 
for ( ThreddsMetadata . VariableGroup t : vars ) { 
ThreddsMetadata . UriResolved uri = t . getVocabUri ( ) ; 
String vocabLink = resolveRelativeUrls ? makeHref ( uri . resolved . toString ( ) , null , t . getVocabulary ( ) ) : makeHref ( uri . href , null , t . getVocabulary ( ) ) ; 
out . format ( vocabLink ) ; 
out . format ( htmlEscaper . escape ( t . getVocabulary ( ) ) ) ; 
out . format ( "]:%n<ul>%n" ) ; 
if ( v . getDescription ( ) != null ) 
out . format ( "%s" , htmlEscaper . escape ( v . getVocabularyName ( ) ) ) ; 
out . format ( "%n" ) ; 
out . format ( "<h3>Variables:</h3>%n" ) ; 
ThreddsMetadata . UriResolved uri = ds . getVariableMapLink ( ) ; 
out . format ( "<ul><li>%s</li></ul>%n" , makeHref ( uri . resolved . toASCIIString ( ) , null , "VariableMap" ) ) ; 
if ( gc != null ) { 
out . format ( "<h3>GeospatialCoverage:</h3>%n<ul>%n" ) ; 
DateRange tc = ds . getTimeCoverage ( ) ; 
out . format ( "<h3>TimeCoverage:</h3>%n<ul>%n" ) ; 
DateType start = tc . getStart ( ) ; 
DateType end = tc . getEnd ( ) ; 
TimeDuration duration = tc . getDuration ( ) ; 
TimeDuration resolution = tc . getResolution ( ) ; 
java . util . List < ThreddsMetadata . MetadataOther > metadata = ds . getMetadataOther ( ) ; 
for ( ThreddsMetadata . MetadataOther m : metadata ) { 
if ( m . getXlinkHref ( ) != null ) gotSomeMetadata = true ; 
out . format ( "<h3>Metadata:</h3>%n<ul>%n" ) ; 
String type = ( m . getType ( ) == null ) ? "" : m . getType ( ) ; 
if ( m . getXlinkHref ( ) != null ) { 
String mdLink = resolveRelativeUrls ? makeHrefResolve ( ds , m . getXlinkHref ( ) , title ) : makeHref ( m . getXlinkHref ( ) , null , title ) ; 
java . util . List < Property > propsOrg = ds . getProperties ( ) ; 
java . util . List < Property > props = new ArrayList < > ( ds . getProperties ( ) . size ( ) ) ; 
for ( Property p : propsOrg ) { 
out . format ( "<h3>Properties:</h3>%n<ul>%n" ) ; 
for ( Property p : props ) { 
if ( p . getName ( ) . equals ( "attachments" ) ) { 
String attachLink = resolveRelativeUrls ? makeHrefResolve ( ds , p . getValue ( ) , p . getName ( ) ) : makeHref ( p . getValue ( ) , null , p . getName ( ) ) ; 
if ( complete ) out . format ( "</body></html>" ) ; 
} public String resolve ( Dataset ds , String href ) { 
Catalog cat = ds . getParentCatalog ( ) ; 
} private void parseLocalConcept ( String filename , String conceptName ) throws IOException { 
try ( InputStream is = new FileInputStream ( filename ) ) { 
addLocalConcept ( is , conceptName ) ; 
} private void addLocalConcept ( InputStream is , String conceptName ) throws IOException { 
try ( BufferedReader br = new BufferedReader ( new InputStreamReader ( is , ENCODING ) ) ) { 
while ( ! line . startsWith ( "#" ) ) 
line = br . readLine ( ) ; 
HashMap < String , String > items = new HashMap < > ( ) ; 
if ( ( line . length ( ) == 0 ) || line . startsWith ( "#" ) ) continue ; 
line = cleanLine ( line ) ; 
if ( line . contains ( "{" ) ) { 
String paramName = line . split ( "=" ) [ 0 ] . trim ( ) ; 
while ( line . contains ( "=" ) ) { 
String [ ] kvp = line . split ( "=" ) ; 
items . put ( kvp [ 0 ] . trim ( ) , kvp [ 1 ] . trim ( ) ) ; 
line = cleanLine ( line ) ; } 
String tableVersion = items . get ( TABLE_VERSION_ID ) ; 
String parameterNumber = items . get ( PARAM_NUM_ID ) ; 
storeConcept ( tableVersion , parameterNumber , conceptName , paramName ) ; 
} private String cleanLine ( String lineIn ) { 
String lineOut ; 
lineOut = lineIn . replaceAll ( "'" , "" ) ; 
lineOut = lineOut . replaceAll ( "\t" , "" ) ; 
lineOut = lineOut . replaceAll ( ";" , "" ) ; 
return lineOut . trim ( ) ; 
} private void storeConcept ( String tableVersion , String parameterNumber , String key , String value ) { 
HashMap < String , HashMap < String , String > > tmpTable ; 
if ( localConcepts . containsKey ( tableVersion ) ) { 
tmpTable = localConcepts . get ( tableVersion ) ; 
if ( tmpTable . containsKey ( parameterNumber ) ) { 
HashMap < String , String > tmpParam = tmpTable . get ( parameterNumber ) ; 
if ( ! tmpParam . containsKey ( key ) ) { 
tmpParam . put ( key , value ) ; 
HashMap < String , String > tmpParam = new HashMap < > ( 4 ) ; 
tmpTable . put ( parameterNumber , tmpParam ) ; 
tmpTable = new HashMap < > ( ) ; 
localConcepts . put ( tableVersion , tmpTable ) ; 
} private void writeGrib1Tables ( ) throws IOException { 
SimpleDateFormat dateFormat = 
new SimpleDateFormat ( "yyyy-MM-dd'T'HH:mm:ssz" ) ; 
String writeDate = dateFormat . format ( cal . getTime ( ) ) ; 
String grib1Info ; 
List < String > tableNums = new ArrayList < > ( ) ; 
HashMap < String , String > paramInfo ; 
Path dir = Paths . get ( ecmwfLocalConceptsLoc . replace ( "sources/" , "resources/resources/grib1/" ) ) ; 
for ( String tableNum : localConcepts . keySet ( ) ) { 
tableNums . add ( tableNum ) ; 
String fileName = "2.98." + tableNum + ".table" ; 
Path newFile = dir . resolve ( fileName ) ; 
Files . deleteIfExists ( newFile ) ; 
Files . createFile ( newFile ) ; 
try ( BufferedWriter writer = Files . newBufferedWriter ( newFile , ENCODING ) ) { 
writer . newLine ( ) ; 
for ( String paramNum : localConcepts . get ( tableNum ) . keySet ( ) ) { 
paramInfo = localConcepts . get ( tableNum ) . get ( paramNum ) ; 
String shortName = paramInfo . get ( SHORTNAME_ID ) ; 
String description = paramInfo . get ( DESCRIPTION_ID ) ; 
String units = paramInfo . get ( UNIT_ID ) ; 
writer . write ( grib1Info ) ; 
writeLookupTableFile ( tableNums , dir , writeDate ) ; 
} private void writeLookupTableFile ( List < String > tableNums , Path dir , String writeDate ) throws IOException { 
Collections . sort ( tableNums ) ; 
Path lookupTableReg = dir . resolve ( "lookupTables.txt" ) ; 
Files . deleteIfExists ( lookupTableReg ) ; 
Files . createFile ( lookupTableReg ) ; 
try ( BufferedWriter writer = Files . newBufferedWriter ( lookupTableReg , ENCODING ) ) { 
for ( String tn : tableNums ) { 
String tableName = "2.98." + tn + ".table" ; 
String reg = "98:\t-1:\t" + tn + ":\t" + tableName ; 
writer . write ( reg ) ; 
} private void showLocalConcepts ( ) { 
for ( String key : localConcepts . get ( tableNum ) . get ( paramNum ) . keySet ( ) ) { 
System . out . println ( key + ":" + localConcepts . get ( tableNum ) . get ( paramNum ) . get ( key ) ) ; 
EcmwfLocalConcepts ec = new EcmwfLocalConcepts ( ) ; 
ec . writeGrib1Tables ( ) ; 
System . out . println ( "Finished!" ) ; 
} public void respond ( HttpServletResponse res , FeatureDataset ft , String requestPathInfo , SubsetParams queryParams , 
SupportedFormat format ) throws Exception { 
write ( ) ; 
} public static List < VariableSimpleIF > getWantedVariables ( FeatureDatasetPoint fdPoint , SubsetParams ncssParams ) 
List < String > vars = ncssParams . getVariables ( ) ; 
if ( vars . size ( ) == 1 && vars . get ( 0 ) . equals ( "all" ) ) { 
return fdPoint . getDataVariables ( ) ; 
Map < String , VariableSimpleIF > dataVarsMap = new HashMap < > ( ) ; 
for ( VariableSimpleIF dataVar : fdPoint . getDataVariables ( ) ) { 
dataVarsMap . put ( dataVar . getShortName ( ) , dataVar ) ; 
List < String > allVarNames = new ArrayList < > ( dataVarsMap . keySet ( ) ) ; 
List < VariableSimpleIF > wantedVars = new ArrayList < > ( ) ; 
for ( String varName : vars ) { 
if ( allVarNames . contains ( varName ) ) { 
VariableSimpleIF var = dataVarsMap . get ( varName ) ; 
wantedVars . add ( var ) ; 
return wantedVars ; 
} public static CalendarDateRange getWantedDateRange ( SubsetParams ncssParams ) throws NcssException { 
if ( ncssParams . isTrue ( SubsetParams . timePresent ) ) { 
CalendarDate time = CalendarDate . present ( ) ; 
CalendarPeriod timeWindow = ncssParams . getTimeWindow ( ) ; 
if ( timeWindow == null ) timeWindow = CalendarPeriod . Hour ; 
return CalendarDateRange . of ( time . subtract ( timeWindow ) , time . add ( timeWindow ) ) ; 
} else if ( ncssParams . getTime ( ) != null ) { 
CalendarDate time = ncssParams . getTime ( ) ; 
} else if ( ncssParams . getTimeRange ( ) != null ) { 
return ncssParams . getTimeRange ( ) ; 
} else if ( ncssParams . isTrue ( SubsetParams . timeAll ) ) { 
return new ArraySequence ( vinfo . sm , new SeqIter ( vinfo ) , vinfo . nelems ) ; 
} private void readIndex ( String indexFilename ) throws IOException { 
try ( FileInputStream fin = new FileInputStream ( indexFilename ) ) { 
if ( ! NcStream . readAndTest ( fin , MAGIC_START_IDX . getBytes ( CDM . utf8Charset ) ) ) 
int version = fin . read ( ) ; 
if ( version != 1 ) 
int count = NcStream . readVInt ( fin ) ; 
int size = NcStream . readVInt ( fin ) ; 
byte [ ] pb = new byte [ size ] ; 
NcStream . readFully ( fin , pb ) ; 
StationIndex si = decodeStationIndex ( pb ) ; 
map . put ( si . stnId , si ) ; 
} public final boolean parse ( InputStream stream ) 
Dap2Parser parser = new Dap2Parser ( new DefaultFactory ( ) ) ; 
String text ; 
text = DConnect2 . captureStream ( stream ) ; 
if ( parser . errparse ( text , this ) != Dap2Parser . DapERR ) return false ; 
this . initCause ( pe ) ; 
} private void showFile ( TableBean bean ) { 
infoTA . setText ( "Table:" + bean . getPath ( ) + "\n" ) ; 
try ( InputStream is = GribResourceReader . getInputStream ( bean . getPath ( ) ) ) { 
infoTA . appendLine ( IO . readContents ( is ) ) ; 
infoWindow . setVisible ( true ) ; 
} public static DatasetSourceType getType ( String name ) 
return ( ( DatasetSourceType ) hash . get ( name ) ) ; 
} public static CodeWithAuthorityType initIdentifier ( 
CodeWithAuthorityType identifier , StationTimeSeriesFeature stationFeat ) { 
identifier . setCodeSpace ( "http://unidata.ucar.edu/" ) ; 
identifier . setStringValue ( stationFeat . getName ( ) ) ; 
return identifier ; 
} public static final DatasetSource newDatasetSource ( String name , DatasetSourceType type , 
DatasetSourceStructure structure , 
String accessPoint , 
ResultService resultService ) 
DatasetSource tmpDsSource = null ; 
if ( type == DatasetSourceType . getType ( "Local" ) ) 
tmpDsSource = new LocalDatasetSource ( ) ; 
else if ( type == DatasetSourceType . getType ( "DodsDir" ) ) 
tmpDsSource = new DodsDirDatasetSource ( ) ; 
else if ( type == DatasetSourceType . getType ( "DodsFileServer" ) ) 
tmpDsSource = new DodsFileServerDatasetSource ( ) ; 
else if ( type == DatasetSourceType . getType ( "GrADSDataServer" ) ) 
tmpDsSource = new GrADSDataServerDatasetSource ( ) ; 
tmpDsSource . setName ( name ) ; 
tmpDsSource . setStructure ( structure ) ; 
tmpDsSource . setAccessPoint ( accessPoint ) ; 
tmpDsSource . setResultService ( resultService ) ; 
StringBuilder log = new StringBuilder ( ) ; 
if ( tmpDsSource . validate ( log ) ) 
return ( tmpDsSource ) ; 
} public InvDataset expand ( ) throws IOException 
this . resultingCatalog = this . createSkeletonCatalog ( prefixUrlPath ) ; 
this . accessPointDataset = ( InvDataset ) this . resultingCatalog . getDatasets ( ) . get ( 0 ) ; 
if ( ! this . isCollection ( this . accessPointDataset ) ) 
expandRecursive ( this . accessPointDataset ) ; 
( ( InvCatalogImpl ) this . resultingCatalog ) . finish ( ) ; 
this . recursivelyRemoveEmptyCollectionDatasets ( this . accessPointDataset ) ; 
return ( this . accessPointDataset ) ; 
} public InvCatalog fullExpand ( ) throws IOException 
InvDataset topDs = this . expand ( ) ; 
InvCatalog generatedCat = topDs . getParentCatalog ( ) ; 
for ( Iterator it = this . getDatasetEnhancerList ( ) . iterator ( ) ; it . hasNext ( ) ; ) 
DatasetEnhancer1 dsE = ( DatasetEnhancer1 ) it . next ( ) ; 
dsE . addMetadata ( topDs ) ; 
this . nameDatasets ( ( InvDatasetImpl ) topDs ) ; 
this . sortDatasets ( topDs ) ; 
( ( InvCatalogImpl ) generatedCat ) . finish ( ) ; 
return ( generatedCat ) ; 
} private void nameDatasets ( InvDatasetImpl datasetContainer ) 
if ( this . getDatasetNamerList ( ) . isEmpty ( ) ) return ; 
if ( this . isFlatten ( ) ) 
this . nameDatasetList ( datasetContainer ) ; 
InvDatasetImpl curDs = null ; 
for ( int j = 0 ; j < datasetContainer . getDatasets ( ) . size ( ) ; j ++ ) 
curDs = ( InvDatasetImpl ) datasetContainer . getDatasets ( ) . get ( j ) ; 
this . nameDatasetTree ( curDs ) ; 
} private void nameDatasetList ( InvDatasetImpl dataset ) 
InvDatasetImpl namedDs = new InvDatasetImpl ( dataset , 
dataset . addDataset ( namedDs ) ; 
DatasetNamer curNamer = null ; 
for ( int i = 0 ; i < this . datasetNamerList . size ( ) ; i ++ ) 
curNamer = ( DatasetNamer ) this . datasetNamerList . get ( i ) ; 
InvDatasetImpl addLevelDs = null ; 
if ( curNamer . getAddLevel ( ) ) 
addLevelDs = new InvDatasetImpl ( null , curNamer . getName ( ) , 
null , null , null ) ; 
java . util . Iterator dsIter = dataset . getDatasets ( ) . iterator ( ) ; 
while ( dsIter . hasNext ( ) ) 
curDs = ( InvDatasetImpl ) dsIter . next ( ) ; 
if ( curNamer . nameDataset ( curDs ) ) 
addLevelDs . addDataset ( curDs ) ; 
namedDs . addDataset ( curDs ) ; 
dsIter . remove ( ) ; 
if ( addLevelDs . hasNestedDatasets ( ) ) 
namedDs . addDataset ( addLevelDs ) ; 
namedDs . finish ( ) ; 
for ( int i = 0 ; i < namedDs . getDatasets ( ) . size ( ) ; i ++ ) 
dataset . addDataset ( ( InvDatasetImpl ) namedDs . getDatasets ( ) . get ( i ) ) ; 
dataset . removeDataset ( namedDs ) ; 
} private void nameDatasetTree ( InvDatasetImpl dataset ) 
if ( dataset . getName ( ) . equals ( "" ) || ! dataset . hasAccess ( ) ) 
DatasetNamer dsN = null ; 
dsN = ( DatasetNamer ) this . datasetNamerList . get ( i ) ; 
if ( dsN . nameDataset ( dataset ) ) 
for ( int j = 0 ; j < dataset . getDatasets ( ) . size ( ) ; j ++ ) 
curDs = ( InvDatasetImpl ) dataset . getDatasets ( ) . get ( j ) ; 
} public void loadAndScalePictureInThread ( URL imageUrl , int priority , double rotation ) { 
boolean alreadyLoading = false ; 
if ( ( sourcePicture != null ) && ( sourcePicture . getUrl ( ) . toString ( ) . equals ( imageUrl . toString ( ) ) ) ) { 
alreadyLoading = true ; 
} else if ( PictureCache . isInCache ( imageUrl ) ) { 
if ( sourcePicture != null ) sourcePicture . removeListener ( this ) ; 
sourcePicture = PictureCache . getSourcePicture ( imageUrl ) ; 
String status = sourcePicture . getStatusMessage ( ) ; 
if ( status == null ) status = "" ; 
if ( sourcePicture . getRotation ( ) == rotation ) { 
alreadyLoading = false ; 
if ( alreadyLoading ) { 
switch ( sourcePicture . getStatusCode ( ) ) { 
case SourcePicture . UNINITIALISED : 
case SourcePicture . ERROR : 
case SourcePicture . LOADING : 
sourcePicture . addListener ( this ) ; 
sourceLoadProgressNotification ( SourcePicture . LOADING_PROGRESS , sourcePicture . getPercentLoaded ( ) ) ; 
scaleAfterLoad = true ; 
case SourcePicture . ROTATING : 
case SourcePicture . READY : 
createScaledPictureInThread ( priority ) ; 
if ( ! alreadyLoading ) { 
sourcePicture = new SourcePicture ( ) ; 
sourcePicture . loadPictureInThread ( imageUrl , priority , rotation ) ; 
} public void loadPictureImd ( URL imageUrl , double rotation ) { 
sourcePicture . loadPicture ( imageUrl , rotation ) ; 
} public void stopLoadingExcept ( URL url ) { 
if ( sourcePicture != null ) { 
boolean isCurrentlyLoading = sourcePicture . stopLoadingExcept ( url ) ; 
if ( ! isCurrentlyLoading ) { 
PictureCache . stopBackgroundLoadingExcept ( url ) ; 
} public void sourceStatusChange ( int statusCode , String statusMessage , SourcePicture sp ) { 
switch ( statusCode ) { 
setStatus ( UNINITIALISED , statusMessage ) ; 
setStatus ( ERROR , statusMessage ) ; 
sourcePicture . removeListener ( this ) ; 
setStatus ( LOADING , statusMessage ) ; 
setStatus ( LOADED , statusMessage ) ; 
if ( scaleAfterLoad ) { 
createScaledPictureInThread ( Thread . MAX_PRIORITY ) ; 
scaleAfterLoad = false ; 
} public void sourceLoadProgressNotification ( int statusCode , int percentage ) { 
Enumeration e = scalablePictureStatusListeners . elements ( ) ; 
. sourceLoadProgressNotification ( statusCode , percentage ) ; 
} public void createScaledPictureInThread ( int priority ) { 
ScaleThread t = new ScaleThread ( this ) ; 
} public Dimension getScaledSize ( ) { 
if ( scaledPicture != null ) 
return new Dimension ( scaledPicture . getWidth ( ) , scaledPicture . getHeight ( ) ) ; 
} public String getScaledSizeString ( ) { 
return Integer . toString ( scaledPicture . getWidth ( ) ) 
+ Integer . toString ( scaledPicture . getHeight ( ) ) ; 
} public static void writeJpg ( File writeFile , RenderedImage renderedImage , float jpgQuality ) { 
Iterator writers = ImageIO . getImageWritersByFormatName ( "jpg" ) ; 
ImageWriter writer = ( ImageWriter ) writers . next ( ) ; 
JPEGImageWriteParam params = new JPEGImageWriteParam ( null ) ; 
params . setCompressionMode ( ImageWriteParam . MODE_EXPLICIT ) ; 
params . setCompressionQuality ( jpgQuality ) ; 
params . setProgressiveMode ( ImageWriteParam . MODE_DISABLED ) ; 
params . setDestinationType ( new ImageTypeSpecifier ( java . awt . image . IndexColorModel . getRGBdefault ( ) , 
IndexColorModel . getRGBdefault ( ) . createCompatibleSampleModel ( 16 , 16 ) ) ) ; 
try ( ImageOutputStream ios = ImageIO . createImageOutputStream ( new FileOutputStream ( writeFile ) ) ) { 
writer . setOutput ( ios ) ; 
writer . write ( null , new IIOImage ( renderedImage , null , null ) , params ) ; 
writer . dispose ( ) ; 
String filename = ( imageUrl == null ) ? "" : imageUrl . toString ( ) ; 
} public static GempakSoundingFileReader getInstance ( RandomAccessFile raf , boolean fullCheck ) throws IOException { 
GempakSoundingFileReader gsfr = new GempakSoundingFileReader ( ) ; 
if ( dmLabel . kftype != MFSN ) { 
DMPart part = getPart ( SNDT ) ; 
if ( part != null ) { 
subType = MERGED ; 
String vertName = part . params . get ( 0 ) . kprmnm ; 
switch ( vertName ) { 
case "PRES" : 
ivert = PRES_COORD ; 
case "THTA" : 
ivert = THTA_COORD ; 
case "HGHT" : 
case "MHGT" : 
case "DHGT" : 
ivert = HGHT_COORD ; 
unmergedParts = SN_CKUA ( ) ; 
boolean haveUnMerged = ! unmergedParts . isEmpty ( ) ; 
if ( ! haveUnMerged ) { 
subType = UNMERGED ; 
} public List < String > getMergedParts ( ) { 
List < String > list = new ArrayList < > ( 1 ) ; 
list . add ( SNDT ) ; 
GempakStation station = getStations ( ) . get ( col - 1 ) ; 
String time = getDateString ( row - 1 ) ; 
StringBuilder builder = new StringBuilder ( "\n" ) ; 
builder . append ( makeHeader ( station , time ) ) ; 
boolean merge = getFileSubType ( ) . equals ( MERGED ) ; 
List < String > parts ; 
if ( merge ) { 
parts = new ArrayList < > ( ) ; 
parts . add ( SNDT ) ; 
parts = unmergedParts ; 
rd = DM_RDTR ( row , col , part ) ; 
if ( ! merge ) { 
builder . append ( part ) ; 
builder . append ( time . substring ( time . indexOf ( "/" ) + 1 ) ) ; 
List < GempakParameter > params = getParameters ( part ) ; 
int numParams = params . size ( ) ; 
int numLevels = data . length / numParams ; 
for ( int j = 0 ; j < numLevels ; j ++ ) { 
for ( int i = 0 ; i < numParams ; i ++ ) { 
builder . append ( 
StringUtil2 . padLeft ( 
Format . formatDouble ( 
data [ j * numParams + i ] , 7 , 1 ) , 7 ) ) ; 
} private String makeHeader ( GempakStation stn , String date ) { 
builder . append ( StringUtil2 . padRight ( ( stn . getSTID ( ) . trim ( ) 
+ stn . getSTD2 ( ) . trim ( ) ) , 8 ) ) ; 
builder . append ( Format . i ( stn . getSTNM ( ) , 6 ) ) ; 
builder . append ( Format . d ( stn . getLatitude ( ) , 5 ) ) ; 
builder . append ( Format . d ( stn . getLongitude ( ) , 5 ) ) ; 
builder . append ( Format . d ( stn . getAltitude ( ) , 5 ) ) ; 
} private List < String > SN_CKUA ( ) { 
List < String > types = new ArrayList < > ( ) ; 
boolean above = false ; 
String partToCheck ; 
for ( int group = 0 ; group < belowGroups . length ; group ++ ) { 
if ( above ) { 
partToCheck = aboveGroups [ group ] ; 
partToCheck = belowGroups [ group ] ; 
if ( checkForValidGroup ( partToCheck , parmLists [ group ] ) ) { 
types . add ( partToCheck ) ; 
if ( ! above ) { 
above = true ; 
} private boolean checkForValidGroup ( String partToCheck , String [ ] params ) { 
DMPart part = getPart ( partToCheck ) ; 
for ( DMParam parm : part . params ) { 
if ( ! ( parm . kprmnm . equals ( params [ i ++ ] ) ) ) { 
GempakSoundingFileReader gsfr = getInstance ( getFile ( args [ 0 ] ) , true ) ; 
gsfr . printDates ( ) ; 
gsfr . printStations ( false ) ; 
} catch ( Exception npe ) { 
col = gsfr . findStationIndex ( args [ 2 ] ) ; 
if ( col == - 1 ) { 
} static public void setRootDirectory ( String cacheDir ) { 
makeRootDirectory ( ) ; 
} static public void makeRootDirectory ( ) { 
if ( ! dir . exists ( ) ) 
checkExist = true ; 
} static public File getFile ( String fileLocation , boolean alwaysInCache ) { 
if ( alwaysInCache ) { 
return getCacheFile ( fileLocation ) ; 
if ( ! simulateUnwritableDir && f . createNewFile ( ) ) { 
boolean ret = f . delete ( ) ; 
} static public File getCacheFile ( String fileLocation ) { 
if ( ! f . setLastModified ( System . currentTimeMillis ( ) ) ) 
if ( ! checkExist ) { 
} static private String makeCachePath ( String fileLocation ) { 
Escaper urlPathEscaper = UrlEscapers . urlPathSegmentEscaper ( ) ; 
fileLocation = fileLocation . replace ( '\\' , '/' ) ; 
String cachePath = urlPathEscaper . escape ( fileLocation ) ; 
} static public void cleanCache ( Date cutoff , StringBuilder sbuff ) { 
File [ ] children = dir . listFiles ( ) ; 
if ( children == null ) return ; 
for ( File file : children ) { 
Date lastMod = new Date ( file . lastModified ( ) ) ; 
if ( lastMod . before ( cutoff ) ) { 
boolean ret = file . delete ( ) ; 
} static public void cleanCache ( long maxBytes , Comparator < File > fileComparator , StringBuilder sbuff ) { 
long total = 0 , total_delete = 0 ; 
List < File > fileList = Arrays . asList ( files ) ; 
Collections . sort ( fileList , fileComparator ) ; 
for ( File file : fileList ) { 
if ( file . length ( ) + total > maxBytes ) { 
total_delete += file . length ( ) ; 
. append ( file . length ( ) ) . append ( ")\n" ) ; 
if ( ! file . delete ( ) && sbuff != null ) 
total += file . length ( ) ; 
} static void make ( String filename ) throws IOException { 
File want = DiskCache . getCacheFile ( filename ) ; 
if ( ! want . exists ( ) ) { 
boolean ret = want . createNewFile ( ) ; 
} public static ImageIcon getIcon ( String name , boolean errMsg ) { 
ImageIcon ii = Resource . getIcon ( defaultResourcePath + name + ".gif" , errMsg ) ; 
if ( ii == null ) Resource . getIcon ( defaultResourcePath + name + ".png" , errMsg ) ; 
return ii ; 
} public static Image getImage ( String name ) { 
Image ii ; 
if ( name . endsWith ( ".png" ) || name . endsWith ( ".jpg" ) || name . endsWith ( ".gif" ) ) 
ii = Resource . getImage ( defaultResourcePath + name ) ; 
ii = Resource . getImage ( defaultResourcePath + name + ".gif" ) ; 
} public static AbstractButton makeButtcon ( Icon icon , Icon selected , String tooltip , boolean is_toggle ) { 
AbstractButton butt ; 
if ( is_toggle ) 
butt = new JToggleButton ( ) ; 
butt = new JButton ( ) ; 
if ( icon != null ) 
butt . setIcon ( icon ) ; 
if ( selected != null ) { 
if ( is_toggle ) { 
butt . setSelectedIcon ( selected ) ; 
butt . setRolloverIcon ( selected ) ; 
butt . setRolloverSelectedIcon ( selected ) ; 
butt . setPressedIcon ( selected ) ; 
butt . setRolloverEnabled ( true ) ; 
butt . setMaximumSize ( new Dimension ( 28 , 28 ) ) ; 
butt . setPreferredSize ( new Dimension ( 28 , 28 ) ) ; 
butt . setToolTipText ( tooltip ) ; 
butt . setFocusPainted ( false ) ; 
return butt ; 
} public static AbstractButton makeButtcon ( String iconName , String tooltip , boolean is_toggle ) { 
Icon icon = getIcon ( iconName , false ) ; 
Icon iconSel = getIcon ( iconName + "Sel" , false ) ; 
return makeButtcon ( icon , iconSel , tooltip , is_toggle ) ; 
} private static JMenuItem makeMenuItemFromAction ( Action act ) { 
Boolean tog = ( Boolean ) act . getValue ( BAMutil . TOGGLE ) ; 
boolean is_toggle = ( tog == null ) ? false : tog . booleanValue ( ) ; 
Integer mnu = ( Integer ) act . getValue ( BAMutil . MNEMONIC ) ; 
int mnemonic = ( tog == null ) ? - 1 : mnu . intValue ( ) ; 
Integer acc = ( Integer ) act . getValue ( BAMutil . ACCEL ) ; 
int accel = ( acc == null ) ? 0 : acc . intValue ( ) ; 
return makeMenuItem ( 
( Icon ) act . getValue ( Action . SMALL_ICON ) , 
( Icon ) act . getValue ( BAMutil . SELECTED_ICON ) , 
( String ) act . getValue ( Action . SHORT_DESCRIPTION ) , 
is_toggle , mnemonic , accel < 0 ? 0 : accel ) ; 
} public static JMenuItem addActionToMenu ( JMenu menu , Action act , int menuPos ) { 
JMenuItem mi = makeMenuItemFromAction ( act ) ; 
if ( menuPos >= 0 ) 
menu . add ( mi , menuPos ) ; 
menu . add ( mi ) ; 
if ( debugToggle ) 
Boolean state = ( Boolean ) act . getValue ( BAMutil . STATE ) ; 
if ( state == null ) state = Boolean . FALSE ; 
act . putValue ( BAMutil . STATE , state ) ; 
mi . setSelected ( state . booleanValue ( ) ) ; 
Action myAct = is_toggle ? new ToggleAction ( act ) : act ; 
mi . addActionListener ( myAct ) ; 
act . addPropertyChangeListener ( new myActionChangedListener ( mi ) ) ; 
return mi ; 
} private static AbstractButton _makeButtconFromAction ( Action act ) { 
return makeButtcon ( 
is_toggle ) ; 
} public static AbstractButton addActionToContainerPos ( Container c , Action act , int pos ) { 
AbstractButton butt = _makeButtconFromAction ( act ) ; 
c . add ( butt ) ; 
c . add ( butt , pos ) ; 
butt . setSelected ( state . booleanValue ( ) ) ; 
butt . addActionListener ( myAct ) ; 
act . addPropertyChangeListener ( new myActionChangedListener ( butt ) ) ; 
} public static void setActionProperties ( AbstractAction act , String icon_name , String action_name , 
boolean is_toggle , int mnemonic , int accel ) { 
if ( icon_name != null ) { 
act . putValue ( Action . SMALL_ICON , getIcon ( icon_name , true ) ) ; 
act . putValue ( BAMutil . SELECTED_ICON , getIcon ( icon_name + "Sel" , false ) ) ; 
act . putValue ( Action . SHORT_DESCRIPTION , action_name ) ; 
act . putValue ( Action . LONG_DESCRIPTION , action_name ) ; 
act . putValue ( BAMutil . TOGGLE , new Boolean ( is_toggle ) ) ; 
act . putValue ( BAMutil . MNEMONIC , new Integer ( mnemonic ) ) ; 
act . putValue ( BAMutil . ACCEL , new Integer ( accel ) ) ; 
} public static void setActionPropertiesToggle ( AbstractAction act , String icon_name , String action_name , 
boolean toggleValue , int mnemonic , int accel ) { 
setActionProperties ( act , icon_name , action_name , true , mnemonic , accel ) ; 
act . putValue ( BAMutil . STATE , new Boolean ( toggleValue ) ) ; 
} public static List < StationFeature > getStationsInSubset ( 
StationTimeSeriesFeatureCollection stationFeatCol , SubsetParams ncssParams ) throws IOException { 
List < StationFeature > wantedStations ; 
if ( ncssParams . getStations ( ) != null ) { 
List < String > stnNames = ncssParams . getStations ( ) ; 
if ( stnNames . get ( 0 ) . equals ( "all" ) ) { 
wantedStations = stationFeatCol . getStationFeatures ( ) ; 
wantedStations = stationFeatCol . getStationFeatures ( stnNames ) ; 
} else if ( ncssParams . getLatLonBoundingBox ( ) != null ) { 
LatLonRect llrect = ncssParams . getLatLonBoundingBox ( ) ; 
wantedStations = stationFeatCol . getStationFeatures ( llrect ) ; 
} else if ( ncssParams . getLatLonPoint ( ) != null ) { 
Station closestStation = findClosestStation ( stationFeatCol , ncssParams . getLatLonPoint ( ) ) ; 
List < String > stnList = new ArrayList < > ( ) ; 
stnList . add ( closestStation . getName ( ) ) ; 
wantedStations = stationFeatCol . getStationFeatures ( stnList ) ; 
return wantedStations ; 
} public static Station findClosestStation ( StationTimeSeriesFeatureCollection stationFeatCol , LatLonPoint pt ) 
double lat = pt . getLatitude ( ) ; 
double lon = pt . getLongitude ( ) ; 
double cos = Math . cos ( Math . toRadians ( lat ) ) ; 
List < StationFeature > stations = stationFeatCol . getStationFeatures ( ) ; 
Station min_station = stations . get ( 0 ) ; 
double min_dist = Double . MAX_VALUE ; 
double lat1 = s . getLatitude ( ) ; 
double lon1 = LatLonPointImpl . lonNormal ( s . getLongitude ( ) , lon ) ; 
double dy = Math . toRadians ( lat - lat1 ) ; 
double dx = cos * Math . toRadians ( lon - lon1 ) ; 
double dist = dy * dy + dx * dx ; 
if ( dist < min_dist ) { 
min_dist = dist ; 
min_station = s ; 
return min_station ; 
} static public boolean isBufrTable ( short fxy ) { 
int f = ( fxy & 0xC000 ) > > 14 ; 
int y = ( fxy & 0xFF ) ; 
return ( f == 0 ) && ( x == 0 ) && ( y < 13 ) ; 
} static public CoordinateAxis factory ( NetcdfDataset ncd , VariableDS vds ) { 
if ( ( vds . getRank ( ) == 0 ) || ( vds . getRank ( ) == 1 ) || ( vds . getRank ( ) == 2 && vds . getDataType ( ) == DataType . CHAR ) ) { 
return new CoordinateAxis1D ( ncd , vds ) ; 
} else if ( vds . getRank ( ) == 2 ) 
return new CoordinateAxis2D ( ncd , vds ) ; 
return new CoordinateAxis ( ncd , vds ) ; 
} public CoordinateAxis copyNoCache ( ) { 
CoordinateAxis axis = new CoordinateAxis ( ncd , getParentGroup ( ) , getShortName ( ) , getDataType ( ) , getDimensionsString ( ) , 
getUnitsString ( ) , getDescription ( ) ) ; 
axis . axisType = this . axisType ; 
axis . boundaryRef = this . boundaryRef ; 
axis . isContiguous = this . isContiguous ; 
axis . positive = this . positive ; 
axis . cache = new Variable . Cache ( ) ; 
return axis ; 
} public boolean isNumeric ( ) { 
return ( getDataType ( ) != DataType . CHAR ) && 
( getDataType ( ) != DataType . STRING ) && 
( getDataType ( ) != DataType . STRUCTURE ) ; 
} public void getInfo ( Formatter buf ) { 
buf . format ( "%-30s" , getNameAndDimensions ( ) ) ; 
buf . format ( "%-20s" , getUnitsString ( ) ) ; 
buf . format ( "%-10s" , axisType . toString ( ) ) ; 
buf . format ( "%s" , getDescription ( ) ) ; 
} public ucar . nc2 . time . Calendar getCalendarFromAttribute ( ) { 
Attribute cal = findAttribute ( CF . CALENDAR ) ; 
String s = ( cal == null ) ? null : cal . getStringValue ( ) ; 
Attribute convention = ( ncd == null ) ? null : ncd . getRootGroup ( ) . findAttribute ( CDM . CONVENTIONS ) ; 
if ( convention != null ) { 
String hasName = convention . getStringValue ( ) ; 
int version = CF1Convention . getVersion ( hasName ) ; 
if ( version >= 0 ) { 
return Calendar . gregorian ; 
if ( COARDSConvention . isMine ( hasName ) ) return Calendar . gregorian ; 
return ucar . nc2 . time . Calendar . get ( s ) ; 
} public void sort ( int colNo , boolean reverse ) { 
model . sort ( colNo , reverse ) ; 
jtable . setRowSelectionInterval ( 0 , 0 ) ; 
ensureRowIsVisible ( 0 ) ; 
} public void setList ( ArrayList rowList ) { 
this . list = rowList ; 
jtable . clearSelection ( ) ; 
jtable . revalidate ( ) ; 
} public void removeRow ( Object elem ) { 
Iterator iter = list . iterator ( ) ; 
Object row = iter . next ( ) ; 
if ( row == elem ) { 
} public TableRow getSelected ( ) { 
if ( list . size ( ) == 0 ) 
int sel = jtable . getSelectedRow ( ) ; 
if ( sel >= 0 ) 
return ( TableRow ) list . get ( sel ) ; 
} public void setSelected ( int row ) { 
if ( ( row < 0 ) || ( row >= list . size ( ) ) ) 
jtable . setRowSelectionInterval ( row , row ) ; 
ensureRowIsVisible ( row ) ; 
} public void incrSelected ( boolean increment ) { 
int curr = jtable . getSelectedRow ( ) ; 
if ( increment && ( curr < list . size ( ) - 1 ) ) 
setSelected ( curr + 1 ) ; 
else if ( ! increment && ( curr > 0 ) ) 
setSelected ( curr - 1 ) ; 
int [ ] modelIndex = new int [ colName . length ] ; 
for ( int i = 0 ; i < colName . length ; i ++ ) { 
Rectangle visibleRect = jtable . getCellRect ( nRow , 0 , true ) ; 
jtable . scrollRectToVisible ( visibleRect ) ; 
jtable . repaint ( ) ; 
} private CalendarPeriod findRangeAdjustment ( String fmtString ) { 
if ( fmtString . contains ( "H" ) || fmtString . contains ( "k" ) ) 
else if ( fmtString . contains ( "d" ) ) 
else if ( fmtString . contains ( "M" ) ) 
return CalendarPeriod . of ( 31 , CalendarPeriod . Field . Day ) ; 
return CalendarPeriod . of ( 366 , CalendarPeriod . Field . Day ) ; 
public Object isMine ( FeatureType wantFeatureType , NetcdfDataset ncd , Formatter errlog ) throws IOException { 
IOServiceProvider iosp = ncd . getIosp ( ) ; 
return ( iosp != null && iosp instanceof BufrIosp2 ) ? true : null ; 
} private void setSelectedIndex ( int idx ) { 
if ( zAxis == null ) 
currentIdx = idx ; 
slider . setValue ( world2slider ( zAxis . getCoordValue ( currentIdx ) ) ) ; 
} public int push_parse ( int yylextoken , Object yylexval ) 
throws DapException , DapException 
if ( ! this . push_parse_initialized ) 
push_parse_initialize ( ) ; 
label = YYGETTOKEN ; 
boolean push_token_consumed = true ; 
{ label = YYACCEPT ; break ; } 
case YYGETTOKEN : 
if ( ! push_token_consumed ) 
return YYPUSH_MORE ; 
yychar = yylextoken ; 
yylval = yylexval ; 
push_token_consumed = false ; 
{ label = YYABORT ; break ; } 
this . push_parse_initialized = false ; return YYACCEPT ; 
this . push_parse_initialized = false ; return YYABORT ; 
} public void push_parse_initialize ( ) 
this . yychar = yyempty_ ; 
this . yytoken = 0 ; 
this . yyn = 0 ; 
this . yylen = 0 ; 
this . yystate = 0 ; 
this . yystack = new YYStack ( ) ; 
this . label = YYNEWSTATE ; 
this . yynerrs_ = 0 ; 
this . yylval = null ; 
yystack . push ( this . yystate , this . yylval ) ; 
this . push_parse_initialized = true ; 
} static void uniqueNames ( Vector v , String varName , 
String typeName ) throws BadSemanticsException { 
String [ ] names = sortedNames ( v ) ; 
for ( int i = 1 ; i < names . length ; i ++ ) { 
if ( names [ i - 1 ] . equals ( names [ i ] ) ) { 
varName + "'" ) ; 
} static String [ ] sortedNames ( Vector v ) throws BadSemanticsException { 
String [ ] names = new String [ v . size ( ) ] ; 
for ( Enumeration e = v . elements ( ) ; e . hasMoreElements ( ) ; ) { 
String tempName = bt . getEncodedName ( ) ; 
if ( tempName == null ) 
names [ count ++ ] = tempName ; 
if ( count != names . length ) 
quickSort ( names , 0 , names . length - 1 ) ; 
} static private void quickSort ( String a [ ] , int lo0 , int hi0 ) { 
int lo = lo0 ; 
int hi = hi0 ; 
String mid ; 
if ( hi0 > lo0 ) { 
mid = a [ ( lo0 + hi0 ) / 2 ] ; 
while ( lo <= hi ) { 
while ( ( lo < hi0 ) && ( a [ lo ] . compareTo ( mid ) < 0 ) ) 
++ lo ; 
while ( ( hi > lo0 ) && ( a [ hi ] . compareTo ( mid ) > 0 ) ) 
-- hi ; 
if ( lo <= hi ) { 
swap ( a , lo , hi ) ; 
if ( lo0 < hi ) 
quickSort ( a , lo0 , hi ) ; 
if ( lo < hi0 ) 
quickSort ( a , lo , hi0 ) ; 
} static private void swap ( String a [ ] , int i , int j ) { 
String T ; 
T = a [ i ] ; 
a [ i ] = a [ j ] ; 
a [ j ] = T ; 
} static String escattr ( String s ) { 
StringBuffer buf = new StringBuffer ( s . length ( ) ) ; 
String numVal = Integer . toString ( ( int ) c & 0xFF , 8 ) ; 
for ( int pad = 0 ; pad < ( 3 - numVal . length ( ) ) ; pad ++ ) 
buf . append ( '0' ) ; 
buf . append ( numVal ) ; 
} static public MFileOS getExistingFile ( String filename ) { 
File file = new File ( filename ) ; 
if ( file . exists ( ) ) return new MFileOS ( file ) ; 
double [ ] lonlat = new double [ 2 ] ; 
lonlat [ 0 ] = latlon . getLongitude ( ) ; 
lonlat [ 1 ] = latlon . getLatitude ( ) ; 
double [ ] rlonlat = rotate ( lonlat , lonpole , polerotate , sinDlat ) ; 
destPoint = new ProjectionPointImpl ( rlonlat [ 0 ] , rlonlat [ 1 ] ) ; 
destPoint . setLocation ( rlonlat [ 0 ] , rlonlat [ 1 ] ) ; 
lonlat [ 0 ] = ppt . getX ( ) ; 
lonlat [ 1 ] = ppt . getY ( ) ; 
double [ ] rlonlat = rotate ( lonlat , - polerotate , - lonpole , - sinDlat ) ; 
destPoint = new LatLonPointImpl ( rlonlat [ 1 ] , rlonlat [ 0 ] ) ; 
destPoint . set ( rlonlat [ 1 ] , rlonlat [ 0 ] ) ; 
} private double [ ] rotate ( double [ ] lonlat , double rot1 , double rot2 , double s ) { 
double e = Math . toRadians ( lonlat [ 0 ] - rot1 ) ; 
double n = Math . toRadians ( lonlat [ 1 ] ) ; 
double cn = Math . cos ( n ) ; 
double x = cn * Math . cos ( e ) ; 
double y = cn * Math . sin ( e ) ; 
double z = Math . sin ( n ) ; 
double x2 = cosDlat * x + s * z ; 
double z2 = - s * x + cosDlat * z ; 
double R = Math . sqrt ( x2 * x2 + y * y ) ; 
double e2 = Math . atan2 ( y , x2 ) ; 
double n2 = Math . atan2 ( z2 , R ) ; 
double rlon = Math . toDegrees ( e2 ) - rot2 ; 
double rlat = Math . toDegrees ( n2 ) ; 
return new double [ ] { rlon , rlat } ; 
} static public XMLStore createFromFile ( String fileName , XMLStore storedDefaults ) throws java . io . IOException { 
File prefsFile = new File ( fileName ) ; 
InputStream primIS = null , objIS = null ; 
if ( prefsFile . exists ( ) && prefsFile . length ( ) > 0 ) { 
primIS = new BufferedInputStream ( new FileInputStream ( prefsFile ) ) ; 
objIS = new BufferedInputStream ( new FileInputStream ( prefsFile ) ) ; 
XMLStore store = new XMLStore ( primIS , objIS , storedDefaults ) ; 
store . prefsFile = prefsFile ; 
return store ; 
} static public XMLStore createFromInputStream ( InputStream is1 , InputStream is2 , XMLStore storedDefaults ) throws java . io . IOException { 
return new XMLStore ( is1 , is2 , storedDefaults ) ; 
} static public XMLStore createFromResource ( String resourceName , XMLStore storedDefaults ) 
throws java . io . IOException { 
Class c = XMLStore . class ; 
InputStream primIS = c . getResourceAsStream ( resourceName ) ; 
InputStream objIS = c . getResourceAsStream ( resourceName ) ; 
if ( primIS == null ) { 
return new XMLStore ( primIS , objIS , storedDefaults ) ; 
} static public String makeStandardFilename ( String appName , String storeName ) { 
String userHome = null ; 
userHome = System . getProperty ( "user.home" ) ; 
if ( null == userHome ) userHome = "." ; 
String dirFilename = userHome + "/" + appName ; 
File f = new File ( dirFilename ) ; 
boolean ok = f . mkdirs ( ) ; 
return dirFilename + "/" + storeName ; 
} public void save ( ) throws java . io . IOException { 
if ( prefsFile == null ) 
File prefTemp ; 
String parentFilename = prefsFile . getParent ( ) ; 
if ( parentFilename == null ) { 
prefTemp = File . createTempFile ( "pref" , ".xml" ) ; 
File parentFile = new File ( parentFilename ) ; 
prefTemp = File . createTempFile ( "pref" , ".xml" , parentFile ) ; 
prefTemp . deleteOnExit ( ) ; 
FileOutputStream fos = new FileOutputStream ( prefTemp , false ) ; 
save ( fos ) ; 
fos . close ( ) ; 
Path xmlBackup = Paths . get ( prefsFile . getAbsolutePath ( ) + ".bak" ) ; 
Path prefsPath = prefsFile . toPath ( ) ; 
if ( Files . exists ( prefsPath ) ) 
Files . move ( prefsPath , xmlBackup , StandardCopyOption . REPLACE_EXISTING ) ; 
Files . move ( prefTemp . toPath ( ) , prefsFile . toPath ( ) , 
StandardCopyOption . REPLACE_EXISTING ) ; 
} public void save ( OutputStream out ) throws java . io . IOException { 
outputExceptionMessage = null ; 
OutputMunger bos = new OutputMunger ( out ) ; 
PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( bos , 
XMLEncoder beanEncoder = new XMLEncoder ( bos ) ; 
beanEncoder . setExceptionListener ( new ExceptionListener ( ) { 
public void exceptionThrown ( Exception exception ) { 
exception . printStackTrace ( ) ; 
outputExceptionMessage = exception . getMessage ( ) ; 
if ( ! rootPrefs . isUserNode ( ) ) 
writeXmlNode ( bos , pw , rootPrefs , beanEncoder , indent ) ; 
if ( outputExceptionMessage != null ) 
throw new IOException ( outputExceptionMessage ) ; 
pw . printf ( "</preferences>%n" ) ; 
writeAtomicVariable ( DataCursor data , SerialWriter dst ) 
DapVariable template = ( DapVariable ) data . getTemplate ( ) ; 
assert ( this . ce . references ( template ) ) ; 
DapType basetype = template . getBaseType ( ) ; 
List < Slice > slices = ce . getConstrainedSlices ( template ) ; 
Object values = data . read ( slices ) ; 
dst . writeAtomicArray ( basetype , values ) ; 
writeStructure ( DataCursor data , SerialWriter dst ) 
DapStructure ds = ( DapStructure ) template . getBaseType ( ) ; 
DataCursor [ ] instance = ( DataCursor [ ] ) data . read ( index ) ; 
writeStructure1 ( instance [ 0 ] , dst ) ; 
writeStructure1 ( DataCursor instance , SerialWriter dst ) 
assert instance . getScheme ( ) == DataCursor . Scheme . STRUCTURE ; 
DapVariable template = ( DapVariable ) instance . getTemplate ( ) ; 
DataCursor df = ( DataCursor ) instance . readField ( i ) ; 
writeVariable ( df , dst ) ; 
writeSequence ( DataCursor data , SerialWriter dst ) 
DapSequence ds = ( DapSequence ) template . getBaseType ( ) ; 
if ( false ) while ( odom . hasNext ( ) ) { 
writeSequence1 ( instance [ 0 ] , dst ) ; 
DataCursor [ ] instances = ( DataCursor [ ] ) data . read ( slices ) ; 
for ( int i = 0 ; i < instances . length ; i ++ ) { 
writeSequence1 ( instances [ i ] , dst ) ; 
writeSequence1 ( DataCursor instance , SerialWriter dst ) 
DapSequence seq = ( DapSequence ) template . getBaseType ( ) ; 
long nrecs = instance . getRecordCount ( ) ; 
dst . writeCount ( nrecs ) ; 
for ( long i = 0 ; i < nrecs ; i ++ ) { 
DataCursor record = instance . readRecord ( i ) ; 
writeRecord ( record , dst ) ; 
writeRecord ( DataCursor record , SerialWriter dst ) 
DapVariable template = ( DapVariable ) record . getTemplate ( ) ; 
List < DapVariable > fields = seq . getFields ( ) ; 
DataCursor df = ( DataCursor ) record . readField ( i ) ; 
pw . print ( toASCIIFlatName ( rootName ) ) ; 
toASCII ta = ( toASCII ) e2 . nextElement ( ) ; 
ta . toASCII ( pw , false , rootName , false ) ; 
} CoverageCoordAxisBuilder subset ( String dependsOn , CoverageCoordAxis . Spacing spacing , int ncoords , double [ ] values ) { 
assert values != null ; 
if ( dependsOn != null ) { 
this . dependenceType = CoverageCoordAxis . DependenceType . dependent ; 
setDependsOn ( dependsOn ) ; 
this . spacing = spacing ; 
this . ncoords = ncoords ; 
this . reader = null ; 
this . values = values ; 
this . isSubset = true ; 
} static public boolean isValidFile ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { 
if ( ! raf . searchForward ( matcher , 40 * 1000 ) ) return false ; 
BufrIndicatorSection is = new BufrIndicatorSection ( raf ) ; 
if ( is . getBufrEdition ( ) > 4 ) return false ; 
return ! ( is . getBufrLength ( ) > raf . length ( ) ) ; 
} public String getWmoId ( ) { 
String wmoID = "" ; 
if ( ! ( stnm == GempakConstants . IMISSD ) ) { 
wmoID = String . valueOf ( ( int ) ( stnm / 10 ) ) ; 
return wmoID ; 
} public void printDecl ( PrintWriter os , String space , boolean print_semi , 
boolean constrained ) { 
getPrimitiveVector ( ) . printDecl ( os , space , false , constrained ) ; 
for ( Enumeration e = dimVector . elements ( ) ; e . hasMoreElements ( ) ; ) { 
os . print ( "[" ) ; 
String name = d . getEncodedName ( ) ; 
if ( name != null && name . length ( ) > 0 ) 
os . print ( d . getSize ( ) + "]" ) ; 
} public void printVal ( PrintWriter pw , String space , boolean print_decl_p ) { 
printDecl ( pw , space , false ) ; 
printArray ( pw , 0 , dims , shape , 0 ) ; 
pw . println ( ";" ) ; 
} private int printArray ( PrintWriter os , int index , int dims , int shape [ ] , 
for ( int i = 0 ; i < shape [ offset ] - 1 ; i ++ ) { 
getPrimitiveVector ( ) . printSingleVal ( os , index ++ ) ; 
index = printArray ( os , index , dims - 1 , shape , offset + 1 ) ; 
os . print ( "," ) ; 
} public void appendDim ( int size , String name ) { 
DArrayDimension newDim = new DArrayDimension ( size , name ) ; 
dimVector . addElement ( newDim ) ; 
newDim . setContainer ( this ) ; 
} public void squeeze ( ) { 
if ( dimVector . size ( ) == 1 ) 
Vector < DArrayDimension > squeezeCandidates = new Vector < DArrayDimension > ( ) ; 
for ( DArrayDimension dim : dimVector ) { 
if ( dim . getSize ( ) == 1 ) 
squeezeCandidates . add ( dim ) ; 
if ( squeezeCandidates . size ( ) == dimVector . size ( ) ) 
squeezeCandidates . remove ( squeezeCandidates . size ( ) - 1 ) ; 
dimVector . removeAll ( squeezeCandidates ) ; 
} public DArrayDimension getDimension ( int dimension ) throws InvalidDimensionException { 
if ( dimension < dimVector . size ( ) ) 
return dimVector . get ( dimension ) ; 
DArray a = ( DArray ) super . cloneDAG ( map ) ; 
a . dimVector = new Vector < DArrayDimension > ( ) ; 
for ( int i = 0 ; i < dimVector . size ( ) ; i ++ ) { 
DArrayDimension d = dimVector . elementAt ( i ) ; 
DArrayDimension dclone = ( DArrayDimension ) cloneDAG ( map , d ) ; 
dclone . setContainer ( a ) ; 
a . dimVector . addElement ( dclone ) ; 
} public static void compareTables ( Grib2CodeTableInterface t1 , Grib2CodeTableInterface t2 , Formatter f ) { 
for ( Grib2CodeTableInterface . Entry p1 : t1 . getEntries ( ) ) { 
if ( t1 . getEntry ( p1 . getCode ( ) ) == null ) { 
Grib2CodeTableInterface . Entry p2 = t2 . getEntry ( p1 . getCode ( ) ) ; 
for ( Grib2CodeTableInterface . Entry p2 : t2 . getEntries ( ) ) { 
if ( t2 . getEntry ( p2 . getCode ( ) ) == null ) { 
Grib2CodeTableInterface . Entry p1 = t1 . getEntry ( p2 . getCode ( ) ) ; 
t1 . getEntry ( p2 . getCode ( ) ) ; 
if ( conflict > 0 || missing > 0 ) { 
} public void setProject ( boolean state , boolean all ) { 
PrimitiveVector vals = getPrimitiveVector ( ) ; 
( ( ServerMethods ) ( vals . getTemplate ( ) ) ) . setProject ( state , all ) ; 
if ( vals . getTemplate ( ) instanceof DSequence || ce . evalClauses ( specialO ) ) { 
if ( vals instanceof BaseTypePrimitiveVector ) { 
ServerMethods sm = ( ServerMethods ) 
( ( BaseTypePrimitiveVector ) vals ) . getValue ( i ) ; 
throws InvalidDimensionException { 
DArrayDimension d = getDimension ( dimension ) ; 
} int readRowN ( DataInputStream ds , int n ) { 
if ( n > nrec ) return - 1 ; 
ds . readFully ( field , 0 , desc . FieldLength ) ; 
switch ( desc . Type ) { 
case 'C' : 
case 'D' : 
character [ n ] = new String ( field , CDM . utf8Charset ) ; 
case 'N' : 
numeric [ n ] = Double . valueOf ( new String ( field , CDM . utf8Charset ) ) ; 
case 'F' : 
if ( desc . FieldLength == 4 ) { 
numeric [ n ] = ( double ) Swap . swapFloat ( field , 0 ) ; 
numeric [ n ] = Swap . swapDouble ( field , 0 ) ; 
case 'L' : 
switch ( field [ 0 ] ) { 
case 'T' : 
case 'Y' : 
case 'y' : 
logical [ n ] = true ; 
logical [ n ] = false ; 
} public Object getData ( int i ) { 
case TYPE_CHAR : 
return character [ i ] ; 
case TYPE_NUMERIC : 
return numeric [ i ] ; 
case TYPE_BOOLEAN : 
return logical [ i ] ; 
} private void readGribCodes ( Version version ) throws IOException { 
try ( InputStream ios = WmoCodeFlagTables . class . getResourceAsStream ( version . getResourceName ( ) ) ) { 
Map < String , WmoTable > map = new HashMap < > ( ) ; 
String line = elem . getChildTextNormalize ( "No" ) ; 
String tableName = elem . getChildTextNormalize ( elems [ 1 ] ) ; 
Element subtableElem = elem . getChild ( elems [ 2 ] ) ; 
TableType type ; 
type = TableType . cat ; 
type = TableType . param ; 
} else if ( tableName . startsWith ( "Flag" ) ) { 
type = TableType . flag ; 
} else if ( tableName . startsWith ( "Code" ) ) { 
type = TableType . code ; 
if ( subtableElem != null ) { 
tableName = subtableElem . getTextNormalize ( ) ; 
TableType finalType = type ; 
WmoTable wmoTable = map . computeIfAbsent ( tableName , name -> new WmoTable ( name , finalType ) ) ; 
String code = elem . getChildTextNormalize ( "CodeFlag" ) ; 
String value = elem . getChildTextNormalize ( "Value" ) ; 
String meaning = elem . getChildTextNormalize ( elems [ 3 ] ) ; 
Element unitElem = elem . getChild ( elems [ 4 ] ) ; 
String unit = ( unitElem == null ) ? null : unitElem . getTextNormalize ( ) ; 
Element statusElem = elem . getChild ( "Status" ) ; 
String status = ( statusElem == null ) ? null : statusElem . getTextNormalize ( ) ; 
wmoTable . addEntry ( line , code , value , meaning , unit , status ) ; 
this . wmoTables = map . values ( ) . stream ( ) . sorted ( ) . collect ( ImmutableList . toImmutableList ( ) ) ; 
ImmutableMap . Builder < String , WmoTable > builder = ImmutableMap . builder ( ) ; 
this . wmoTableMap = builder . build ( ) ; 
} private Variable readVariable ( NetcdfFile ncfile , Group g , Structure parentS , Element varElem ) { 
String name = varElem . getAttributeValue ( "name" ) ; 
String type = varElem . getAttributeValue ( "type" ) ; 
if ( type == null ) { 
DataType dtype = DataType . getType ( type ) ; 
String shape = varElem . getAttributeValue ( "shape" ) ; 
shape = "" ; 
if ( dtype == DataType . STRUCTURE ) { 
Structure s = new Structure ( ncfile , g , parentS , name ) ; 
s . setDimensions ( shape ) ; 
v = s ; 
java . util . List < Element > varList = varElem . getChildren ( "variable" , Catalog . ncmlNS ) ; 
readVariable ( ncfile , g , s , vElem ) ; 
} else if ( dtype == DataType . SEQUENCE ) { 
Sequence s = new Sequence ( ncfile , g , parentS , name ) ; 
v = new Variable ( ncfile , g , parentS , name , dtype , shape ) ; 
Element valueElem = varElem . getChild ( "values" , Catalog . ncmlNS ) ; 
if ( valueElem != null ) 
readValues ( v , varElem , valueElem ) ; 
java . util . List < Element > attList = varElem . getChildren ( "attribute" , Catalog . ncmlNS ) ; 
for ( Element attElem : attList ) 
readAtt ( v , attElem ) ; 
if ( parentS != null ) 
parentS . addMemberVariable ( v ) ; 
g . addVariable ( v ) ; 
private void readValues ( Variable v , Element varElem , Element valuesElem ) { 
String startS = valuesElem . getAttributeValue ( "start" ) ; 
String incrS = valuesElem . getAttributeValue ( "increment" ) ; 
String nptsS = valuesElem . getAttributeValue ( "npts" ) ; 
int npts = ( nptsS == null ) ? ( int ) v . getSize ( ) : Integer . parseInt ( nptsS ) ; 
if ( ( startS != null ) && ( incrS != null ) ) { 
double start = Double . parseDouble ( startS ) ; 
double incr = Double . parseDouble ( incrS ) ; 
v . setValues ( npts , start , incr ) ; 
String values = varElem . getChildText ( "values" , Catalog . ncmlNS ) ; 
String sep = valuesElem . getAttributeValue ( "separator" ) ; 
if ( v . getDataType ( ) == DataType . CHAR ) { 
int nhave = values . length ( ) ; 
int nwant = ( int ) v . getSize ( ) ; 
char [ ] data = new char [ nwant ] ; 
int min = Math . min ( nhave , nwant ) ; 
for ( int i = 0 ; i < min ; i ++ ) { 
data [ i ] = values . charAt ( i ) ; 
Array dataArray = Array . factory ( DataType . CHAR , v . getShape ( ) , data ) ; 
List < String > valList = new ArrayList < > ( ) ; 
StringTokenizer tokn = new StringTokenizer ( values , sep ) ; 
while ( tokn . hasMoreTokens ( ) ) 
valList . add ( tokn . nextToken ( ) ) ; 
v . setValues ( valList ) ; 
private void readAtt ( Object parent , Element attElem ) { 
String name = attElem . getAttributeValue ( "name" ) ; 
ucar . ma2 . Array values = NcMLReader . readAttributeValues ( attElem ) ; 
Attribute att = new ucar . nc2 . Attribute ( name , values ) ; 
if ( parent instanceof Group ) 
( ( Group ) parent ) . addAttribute ( att ) ; 
else if ( parent instanceof Variable ) 
( ( Variable ) parent ) . addAttribute ( att ) ; 
private void readDim ( Group g , Element dimElem ) { 
String name = dimElem . getAttributeValue ( "name" ) ; 
String lengthS = dimElem . getAttributeValue ( "length" ) ; 
String isUnlimitedS = dimElem . getAttributeValue ( "isUnlimited" ) ; 
String isSharedS = dimElem . getAttributeValue ( "isShared" ) ; 
String isUnknownS = dimElem . getAttributeValue ( "isVariableLength" ) ; 
boolean isUnlimited = ( isUnlimitedS != null ) && isUnlimitedS . equalsIgnoreCase ( "true" ) ; 
boolean isUnknown = ( isUnknownS != null ) && isUnknownS . equalsIgnoreCase ( "true" ) ; 
boolean isShared = true ; 
if ( ( isSharedS != null ) && isSharedS . equalsIgnoreCase ( "false" ) ) 
isShared = false ; 
int len = Integer . parseInt ( lengthS ) ; 
if ( ( isUnknownS != null ) && isUnknownS . equalsIgnoreCase ( "false" ) ) 
len = Dimension . VLEN . getLength ( ) ; 
Dimension dim = new Dimension ( name , len , isShared , isUnlimited , isUnknown ) ; 
g . addDimension ( dim ) ; 
} public float [ ] getData ( RandomAccessFile raf , Grib2SectionBitMap bitmapSection , Grib2Drs gdrs ) 
this . bitmap = bitmapSection . getBitmap ( raf ) ; 
this . bitmapIndicator = bitmapSection . getBitMapIndicator ( ) ; 
if ( bitmap != null ) { 
if ( bitmap . length * 8 < totalNPoints ) { 
totalNPoints , nx , totalNPoints / nx ) ; 
raf . seek ( startPos + 5 ) ; 
switch ( dataTemplate ) { 
data = getData0 ( raf , ( Grib2Drs . Type0 ) gdrs ) ; 
data = getData2 ( raf , ( Grib2Drs . Type2 ) gdrs ) ; 
data = getData3 ( raf , ( Grib2Drs . Type3 ) gdrs ) ; 
data = getData40 ( raf , ( Grib2Drs . Type40 ) gdrs ) ; 
data = getData41 ( raf , ( Grib2Drs . Type0 ) gdrs ) ; 
case 50002 : 
data = getData50002 ( raf , ( Grib2Drs . Type50002 ) gdrs ) ; 
scanningModeCheck ( data , scanMode , nx ) ; 
} private float [ ] getData0 ( RandomAccessFile raf , Grib2Drs . Type0 gdrs ) throws IOException { 
int nb = gdrs . numberOfBits ; 
int D = gdrs . decimalScaleFactor ; 
float DD = ( float ) java . lang . Math . pow ( ( double ) 10 , ( double ) D ) ; 
float R = gdrs . referenceValue ; 
int E = gdrs . binaryScaleFactor ; 
float EE = ( float ) java . lang . Math . pow ( 2.0 , ( double ) E ) ; 
float [ ] data = new float [ totalNPoints ] ; 
BitReader reader = new BitReader ( raf , startPos + 5 ) ; 
for ( int i = 0 ; i < totalNPoints ; i ++ ) { 
data [ i ] = ( R + reader . bits2UInt ( nb ) * EE ) / DD ; 
if ( GribNumbers . testBitIsSet ( bitmap [ i / 8 ] , i % 8 ) ) { 
data [ i ] = staticMissingValue ; 
} private float [ ] getData2 ( RandomAccessFile raf , Grib2Drs . Type2 gdrs ) throws IOException { 
int mvm = gdrs . missingValueManagement ; 
float mv = getMissingValue ( gdrs ) ; 
float DD = ( float ) java . lang . Math . pow ( ( double ) 10 , ( double ) gdrs . decimalScaleFactor ) ; 
float EE = ( float ) java . lang . Math . pow ( 2.0 , ( double ) gdrs . binaryScaleFactor ) ; 
float ref_val = R / DD ; 
int NG = gdrs . numberOfGroups ; 
if ( NG == 0 ) { 
return nGroups0 ( bitmapIndicator , ref_val , mv ) ; 
int [ ] X1 = new int [ NG ] ; 
if ( nb != 0 ) { 
for ( int i = 0 ; i < NG ; i ++ ) { 
X1 [ i ] = ( int ) reader . bits2UInt ( nb ) ; 
int [ ] NB = new int [ NG ] ; 
nb = gdrs . bitsGroupWidths ; 
reader . incrByte ( ) ; 
NB [ i ] = ( int ) reader . bits2UInt ( nb ) ; 
int [ ] L = new int [ NG ] ; 
int ref = gdrs . referenceGroupLength ; 
int len_inc = gdrs . lengthIncrement ; 
nb = gdrs . bitsScaledGroupLength ; 
L [ i ] = ref + ( int ) reader . bits2UInt ( nb ) * len_inc ; 
L [ NG - 1 ] = gdrs . lengthLastGroup ; 
for ( int j = 0 ; j < L [ i ] ; j ++ ) { 
if ( NB [ i ] == 0 ) { 
if ( mvm == 0 ) { 
data [ count ++ ] = ( R + X1 [ i ] * EE ) / DD ; 
data [ count ++ ] = mv ; 
int X2 = ( int ) reader . bits2UInt ( NB [ i ] ) ; 
data [ count ++ ] = ( R + ( X1 [ i ] + X2 ) * EE ) / DD ; 
if ( X2 == bitsmv1 [ NB [ i ] ] ) { 
float [ ] tmp = new float [ totalNPoints ] ; 
tmp [ i ] = data [ idx ++ ] ; 
tmp [ i ] = mv ; 
data = tmp ; 
} private float [ ] nGroups0 ( int bitmap_flag , float ref , float mv1 ) { 
if ( bitmap_flag == 255 ) { 
data [ i ] = ref ; 
} else if ( bitmap_flag == 0 || bitmap_flag == 254 ) { 
int mask = 0 ; 
int mask_pointer = 0 ; 
if ( ( i & 7 ) == 0 ) { 
mask = bitmap [ mask_pointer ] ; 
mask_pointer ++ ; 
data [ i ] = ( ( mask & 128 ) == 0 ) ? ref : mv1 ; 
mask <<= 1 ; 
} private float [ ] getData3 ( RandomAccessFile raf , Grib2Drs . Type3 gdrs ) throws IOException { 
int ival1 ; 
int ival2 = 0 ; 
int minsd ; 
int os = gdrs . orderSpatial ; 
int nbitsd = gdrs . descriptorSpatial ; 
int sign ; 
nbitsd = nbitsd * 8 ; 
if ( nbitsd > 0 ) { 
sign = ( int ) reader . bits2UInt ( 1 ) ; 
ival1 = ( int ) reader . bits2UInt ( nbitsd - 1 ) ; 
if ( sign == 1 ) { 
ival1 = - ival1 ; 
if ( os == 2 ) { 
ival2 = ( int ) reader . bits2UInt ( nbitsd - 1 ) ; 
ival2 = - ival2 ; 
minsd = ( int ) reader . bits2UInt ( nbitsd - 1 ) ; 
minsd = - minsd ; 
data [ i ] = mv ; 
int referenceGroupWidths = gdrs . referenceGroupWidths ; 
NB [ i ] += referenceGroupWidths ; 
int referenceGroupLength = gdrs . referenceGroupLength ; 
L [ i ] = ( int ) reader . bits2UInt ( nb ) ; 
int totalL = 0 ; 
L [ i ] = L [ i ] * len_inc + referenceGroupLength ; 
totalL += L [ i ] ; 
totalL -= L [ NG - 1 ] ; 
totalL += gdrs . lengthLastGroup ; 
if ( mvm != 0 ) { 
if ( totalL != totalNPoints ) { 
if ( totalL != dataNPoints ) { 
int dataSize = 0 ; 
boolean [ ] dataBitMap = null ; 
if ( NB [ i ] != 0 ) { 
data [ count ++ ] = ( int ) reader . bits2UInt ( NB [ i ] ) + X1 [ i ] ; 
data [ count ++ ] = X1 [ i ] ; 
} else if ( mvm == 1 || mvm == 2 ) { 
dataBitMap = new boolean [ totalNPoints ] ; 
int msng1 = bitsmv1 [ NB [ i ] ] ; 
int msng2 = msng1 - 1 ; 
data [ count ] = ( int ) reader . bits2UInt ( NB [ i ] ) ; 
if ( data [ count ] == msng1 || mvm == 2 && data [ count ] == msng2 ) { 
dataBitMap [ count ] = false ; 
dataBitMap [ count ] = true ; 
data [ dataSize ++ ] = data [ count ] + X1 [ i ] ; 
int msng1 = bitsmv1 [ gdrs . numberOfBits ] ; 
if ( X1 [ i ] == msng1 ) { 
dataBitMap [ count ++ ] = false ; 
} else if ( mvm == 2 && X1 [ i ] == msng2 ) { 
data [ dataSize ++ ] = X1 [ i ] ; 
if ( os == 1 ) { 
data [ 0 ] = ival1 ; 
int itemp ; 
itemp = totalNPoints ; 
itemp = dataSize ; 
for ( int i = 1 ; i < itemp ; i ++ ) { 
data [ i ] += minsd ; 
data [ i ] = data [ i ] + data [ i - 1 ] ; 
} else if ( os == 2 ) { 
data [ 1 ] = ival2 ; 
for ( int i = 2 ; i < itemp ; i ++ ) { 
data [ i ] = data [ i ] + ( 2 * data [ i - 1 ] ) - data [ i - 2 ] ; 
data [ i ] = ( R + ( data [ i ] * EE ) ) / DD ; 
if ( dataBitMap [ i ] ) { 
tmp [ i ] = ( R + ( data [ count2 ++ ] * EE ) ) / DD ; 
} private float [ ] getData40 ( RandomAccessFile raf , Grib2Drs . Type40 gdrs ) throws IOException { 
Grib2JpegDecoder g2j = null ; 
g2j = new Grib2JpegDecoder ( nb , false ) ; 
byte [ ] buf = new byte [ dataLength - 5 ] ; 
g2j . decode ( buf ) ; 
gdrs . hasSignedProblem = g2j . hasSignedProblem ( ) ; 
float [ ] result = new float [ totalNPoints ] ; 
if ( nb == 0 ) { 
for ( int i = 0 ; i < dataNPoints ; i ++ ) { 
result [ i ] = ref_val ; 
int [ ] idata = g2j . getGdata ( ) ; 
if ( idata . length != dataNPoints ) { 
dataNPoints ) ; 
result [ i ] = ( R + idata [ i ] * EE ) / DD ; 
for ( int i = 0 , j = 0 ; i < totalNPoints ; i ++ ) { 
if ( j >= idata . length ) { 
idata . length , j , i , totalNPoints ) ; 
int indata = idata [ j ] ; 
result [ i ] = ( R + indata * EE ) / DD ; 
result [ i ] = staticMissingValue ; 
private int [ ] getData40raw ( RandomAccessFile raf , Grib2Drs . Type40 gdrs ) throws IOException { 
int missing_value = ( 2 << nb - 1 ) - 1 ; 
Grib2JpegDecoder g2j ; 
if ( idata . length != totalNPoints ) { 
totalNPoints ) ; 
int [ ] result = new int [ totalNPoints ] ; 
result [ i ] = idata [ j ] ; 
result [ i ] = missing_value ; 
} private float [ ] getData41 ( RandomAccessFile raf , Grib2Drs . Type0 gdrs ) throws IOException { 
Arrays . fill ( data , R ) ; 
InputStream in = new ByteArrayInputStream ( buf ) ; 
BufferedImage image = ImageIO . read ( in ) ; 
if ( nb != image . getColorModel ( ) . getPixelSize ( ) ) { 
image . getColorModel ( ) . getPixelSize ( ) , nb ) ; 
DataBuffer db = image . getRaster ( ) . getDataBuffer ( ) ; 
data [ i ] = ( R + db . getElem ( i ) * EE ) / DD ; 
for ( int bitPt = 0 , dataPt = 0 ; bitPt < totalNPoints ; bitPt ++ ) { 
if ( GribNumbers . testBitIsSet ( bitmap [ bitPt / 8 ] , bitPt % 8 ) ) { 
data [ bitPt ] = ( R + db . getElem ( dataPt ++ ) * EE ) / DD ; 
data [ bitPt ] = staticMissingValue ; 
} private float [ ] getData50002 ( RandomAccessFile raf , Grib2Drs . Type50002 gdrs ) throws IOException { 
BitReader reader ; 
reader = new BitReader ( raf , startPos + 5 ) ; 
int [ ] groupWidth = new int [ gdrs . p1 ] ; 
for ( int i = 0 ; i < gdrs . p1 ; i ++ ) { 
groupWidth [ i ] = ( int ) reader . bits2UInt ( gdrs . widthOfWidth ) ; 
reader = new BitReader ( raf , raf . getFilePointer ( ) ) ; 
int [ ] groupLength = new int [ gdrs . p1 ] ; 
groupLength [ i ] = ( int ) reader . bits2UInt ( gdrs . widthOfLength ) ; 
int [ ] firstOrderValues = new int [ gdrs . p1 ] ; 
firstOrderValues [ i ] = ( int ) reader . bits2UInt ( gdrs . widthOfFirstOrderValues ) ; 
int bias = 0 ; 
if ( gdrs . orderOfSPD > 0 ) { 
bias = gdrs . spd [ gdrs . orderOfSPD ] ; 
int cnt = gdrs . orderOfSPD ; 
int [ ] data = new int [ totalNPoints ] ; 
if ( groupWidth [ i ] > 0 ) { 
for ( int j = 0 ; j < groupLength [ i ] ; j ++ ) { 
data [ cnt ] = ( int ) reader . bits2UInt ( groupWidth [ i ] ) ; 
data [ cnt ] += firstOrderValues [ i ] ; 
data [ cnt ] = firstOrderValues [ i ] ; 
if ( gdrs . orderOfSPD >= 0 ) { 
System . arraycopy ( gdrs . spd , 0 , data , 0 , gdrs . orderOfSPD ) ; 
int y , z , w ; 
switch ( gdrs . orderOfSPD ) { 
y = data [ 0 ] ; 
for ( int i = 1 ; i < totalNPoints ; i ++ ) { 
y += data [ i ] + bias ; 
data [ i ] = y ; 
y = data [ 1 ] - data [ 0 ] ; 
z = data [ 1 ] ; 
for ( int i = 2 ; i < totalNPoints ; i ++ ) { 
z += y ; 
data [ i ] = z ; 
y = data [ 2 ] - data [ 1 ] ; 
z = y - ( data [ 1 ] - data [ 0 ] ) ; 
w = data [ 2 ] ; 
for ( int i = 3 ; i < totalNPoints ; i ++ ) { 
z += data [ i ] + bias ; 
y += z ; 
w += y ; 
data [ i ] = w ; 
float [ ] ret = new float [ totalNPoints ] ; 
ret [ i ] = ( ( ( data [ i ] * EE ) + R ) * DD ) ; 
} private void scanningModeCheck ( float [ ] data , int scanMode , int Xlength ) { 
if ( ( scanMode == 0 ) || ( scanMode == 64 ) ) 
if ( ! GribUtils . scanModeXisPositive ( scanMode ) ) { 
float tmp ; 
int mid = Xlength / 2 ; 
for ( int index = 0 ; index < data . length ; index += Xlength ) { 
for ( int idx = 0 ; idx < mid ; idx ++ ) { 
tmp = data [ index + idx ] ; 
data [ index + idx ] = data [ index + Xlength - idx - 1 ] ; 
data [ index + Xlength - idx - 1 ] = tmp ; 
if ( ! GribUtils . scanModeSameDirection ( scanMode ) ) { 
int row = index / Xlength ; 
if ( row % 2 != 0 ) { 
read ( List < Slice > slices ) 
switch ( this . scheme ) { 
case ATOMIC : 
return readAtomic ( slices ) ; 
if ( ( ( DapVariable ) this . getTemplate ( ) ) . getRank ( ) > 0 
|| DapUtil . isScalarSlices ( slices ) ) 
CDMCursor [ ] instances = new CDMCursor [ 1 ] ; 
instances [ 0 ] = this ; 
return instances ; 
instances = new CDMCursor [ 1 ] ; 
case STRUCTARRAY : 
instances = new CDMCursor [ ( int ) odom . totalSize ( ) ] ; 
for ( int i = 0 ; odom . hasNext ( ) ; i ++ ) { 
instances [ i ] = readStructure ( odom . next ( ) ) ; 
case SEQARRAY : 
instances = readSequence ( slices ) ; 
assert slices != null && ( ( atomvar . getRank ( ) == 0 && slices . size ( ) == 1 ) || ( slices . size ( ) == atomvar . getRank ( ) ) ) ; 
return sliceAtomic ( slices , this . array , atomvar ) ; 
} static public void makeFile ( String location , ucar . nc2 . dt . GridDataset gds , List < String > gridList , LatLonRect llbb , CalendarDateRange range ) 
CFGridWriter writer = new CFGridWriter ( ) ; 
writer . makeFile ( location , gds , gridList , llbb , range , false , 1 , 1 , 1 ) ; 
} public long makeGridFileSizeEstimate ( ucar . nc2 . dt . GridDataset gds , List < String > gridList , 
LatLonRect llbb , int horizStride , 
Range zRange , 
CalendarDateRange dateRange , int stride_time , 
boolean addLatLon ) throws IOException , InvalidRangeException { 
return makeOrTestSize ( null , gds , gridList , llbb , horizStride , zRange , dateRange , stride_time , addLatLon , true , NetcdfFileWriter . Version . netcdf3 ) ; 
} public void makeFile ( String location , ucar . nc2 . dt . GridDataset gds , List < String > gridList , 
LatLonRect llbb , CalendarDateRange range , 
boolean addLatLon , 
int horizStride , int stride_z , int stride_time ) 
makeFile ( location , gds , gridList , llbb , horizStride , null , range , stride_time , addLatLon , NetcdfFileWriter . Version . netcdf3 ) ; 
} private long processTransformationVars ( ArrayList < Variable > varList , ArrayList < String > varNameList , NetcdfDataset ncd , ucar . nc2 . dt . GridDataset gds , 
GridDatatype grid , Range timeRange , Range zRangeUse , LatLonRect llbb , int z_stride , int y_stride , int x_stride , 
List < CoordinateAxis > axisList ) throws InvalidRangeException { 
List < Range > yxRanges = new ArrayList < Range > ( 2 ) ; 
yxRanges . add ( null ) ; 
yxRanges = grid . getCoordinateSystem ( ) . getRangesFromLatLonRect ( llbb ) ; 
return processTransformationVars ( varList , varNameList , ncd , gds , grid , timeRange , zRangeUse , yxRanges . get ( 0 ) , yxRanges . get ( 1 ) , z_stride , y_stride , x_stride ) ; 
} public void setStations ( java . util . List < ucar . unidata . geoloc . Station > stns ) { 
stations = new ArrayList < StationUI > ( stns . size ( ) ) ; 
stationHash . clear ( ) ; 
StationUI sui = new StationUI ( s ) ; 
stations . add ( sui ) ; 
stationHash . put ( s . getName ( ) , sui ) ; 
posWasCalc = false ; 
calcWorldPos ( ) ; 
} public void setSelectedStation ( String name ) { 
StationUI sui = ( StationUI ) stationHash . get ( name ) ; 
if ( sui != null ) { 
setSelectedStation ( sui ) ; 
} public ucar . unidata . geoloc . Station pick ( Point2D pickPt ) { 
if ( world2Normal == null || pickPt == null || stations . isEmpty ( ) ) return null ; 
world2Normal . transform ( pickPt , ptN ) ; 
StationUI closest = ( StationUI ) stationGrid . findIntersection ( ptN ) ; 
setSelectedStation ( closest ) ; 
return getSelectedStation ( ) ; 
} public ucar . unidata . geoloc . Station pickClosest ( Point2D pickPt ) { 
StationUI closest = ( StationUI ) stationGrid . findClosest ( ptN ) ; 
} public ucar . unidata . geoloc . Station getSelectedStation ( ) { 
return ( selected != null ) ? selected . ddStation : null ; 
} private void merge ( Element iospParam ) { 
assert iospParam . getName ( ) . equals ( "iospParam" ) ; 
Element bufr2nc = iospParam . getChild ( "bufr2nc" , Catalog . ncmlNS ) ; 
if ( bufr2nc == null ) return ; 
for ( Element child : bufr2nc . getChildren ( "fld" , Catalog . ncmlNS ) ) 
merge ( child , rootConverter ) ; 
private void merge ( Element jdom , FieldConverter parent ) { 
if ( jdom == null || parent == null ) return ; 
FieldConverter fld = null ; 
String idxName = jdom . getAttributeValue ( "idx" ) ; 
if ( idxName != null ) { 
int idx = Integer . parseInt ( idxName ) ; 
fld = parent . getChild ( idx ) ; 
if ( fld == null ) { 
String fxyName = jdom . getAttributeValue ( "fxy" ) ; 
if ( fxyName != null ) { 
fld = parent . findChildByFxyName ( fxyName ) ; 
String name = jdom . getAttributeValue ( "name" ) ; 
fld = parent . findChild ( name ) ; 
String action = jdom . getAttributeValue ( "action" ) ; 
if ( action != null && ! action . isEmpty ( ) ) 
fld . setAction ( action ) ; 
if ( jdom . getChildren ( "fld" ) != null ) { 
for ( Element child : jdom . getChildren ( "fld" , Catalog . ncmlNS ) ) { 
merge ( child , fld ) ; 
private StandardFields . StandardFieldsFromStructure extract ; 
private boolean hasStations = false ; 
private boolean hasDate = false ; 
private int countObs = 0 ; 
private void scanBufrFile ( RandomAccessFile raf ) throws Exception { 
NetcdfFile ncd = null ; 
countObs = 0 ; 
MessageScanner scanner = new MessageScanner ( raf ) ; 
Message protoMessage = scanner . getFirstDataMessage ( ) ; 
messHash = protoMessage . hashCode ( ) ; 
standardFields = StandardFields . extract ( protoMessage ) ; 
rootConverter = new FieldConverter ( protoMessage . ids . getCenterId ( ) , protoMessage . getRootDataDescriptor ( ) ) ; 
if ( standardFields . hasStation ( ) ) { 
hasStations = true ; 
map = new HashMap < > ( 1000 ) ; 
featureType = guessFeatureType ( standardFields ) ; 
hasDate = standardFields . hasTime ( ) ; 
ncd = NetcdfFile . open ( raf . getLocation ( ) ) ; 
Attribute centerAtt = ncd . findGlobalAttribute ( BufrIosp2 . centerId ) ; 
int center = ( centerAtt == null ) ? 0 : centerAtt . getNumericValue ( ) . intValue ( ) ; 
Sequence seq = ( Sequence ) ncd . findVariable ( null , BufrIosp2 . obsRecord ) ; 
extract = new StandardFields . StandardFieldsFromStructure ( center , seq ) ; 
StructureDataIterator iter = seq . getStructureIterator ( ) ; 
processSeq ( iter , rootConverter , true ) ; 
setStandardActions ( rootConverter ) ; 
private FeatureType guessFeatureType ( StandardFields . StandardFieldsFromMessage standardFields ) { 
if ( standardFields . hasStation ( ) ) return FeatureType . STATION ; 
if ( standardFields . hasTime ( ) ) return FeatureType . POINT ; 
return FeatureType . ANY ; 
private void setStandardActions ( FieldConverter fld ) { 
fld . setAction ( fld . makeAction ( ) ) ; 
if ( fld . flds == null ) return ; 
for ( FieldConverter child : fld . flds ) 
setStandardActions ( child ) ; 
private CalendarDate today = CalendarDate . present ( ) ; 
private void processSeq ( StructureDataIterator sdataIter , FieldConverter parent , boolean isTop ) throws IOException { 
if ( isTop ) { 
countObs ++ ; 
if ( hasStations ) processStations ( parent , sdata ) ; 
if ( hasDate ) { 
extract . extract ( sdata ) ; 
CalendarDate date = extract . makeCalendarDate ( ) ; 
if ( Math . abs ( date . getDifferenceInMsecs ( today ) ) > 1000L * 3600 * 24 * 100 ) { 
extract . makeCalendarDate ( ) ; 
long msecs = date . getMillis ( ) ; 
if ( this . start > msecs ) { 
this . start = msecs ; 
if ( this . end < msecs ) { 
this . end = msecs ; 
if ( m . getDataType ( ) == DataType . SEQUENCE ) { 
FieldConverter fld = parent . getChild ( count ) ; 
int n = data . getStructureDataCount ( ) ; 
fld . trackSeqCounts ( n ) ; 
processSeq ( data . getStructureDataIterator ( ) , fld , false ) ; 
private void processStations ( FieldConverter parent , StructureData sdata ) { 
BufrStation station = new BufrStation ( ) ; 
station . read ( parent , sdata ) ; 
if ( station . getName ( ) == null ) { 
BufrStation check = map . get ( station . getName ( ) ) ; 
if ( check == null ) 
map . put ( station . getName ( ) , station ) ; 
check . count ++ ; 
if ( ! station . equals ( check ) ) 
public class BufrStation extends StationImpl { 
public int count = 1 ; 
void read ( FieldConverter parent , StructureData sdata ) { 
setName ( extract . getStationId ( ) ) ; 
setLatitude ( extract . getFieldValueD ( BufrCdmIndexProto . FldType . lat ) ) ; 
setLongitude ( extract . getFieldValueD ( BufrCdmIndexProto . FldType . lon ) ) ; 
if ( extract . hasField ( BufrCdmIndexProto . FldType . stationDesc ) ) 
setDescription ( extract . getFieldValueS ( BufrCdmIndexProto . FldType . stationDesc ) ) ; 
if ( extract . hasField ( BufrCdmIndexProto . FldType . wmoId ) ) 
setWmoId ( extract . getFieldValueS ( BufrCdmIndexProto . FldType . wmoId ) ) ; 
if ( extract . hasField ( BufrCdmIndexProto . FldType . heightOfStation ) ) 
setAltitude ( extract . getFieldValueD ( BufrCdmIndexProto . FldType . heightOfStation ) ) ; 
BufrStation that = ( BufrStation ) o ; 
if ( Double . compare ( that . alt , alt ) != 0 ) return false ; 
if ( Double . compare ( that . lat , lat ) != 0 ) return false ; 
if ( Double . compare ( that . lon , lon ) != 0 ) return false ; 
if ( desc != null ? ! desc . equals ( that . desc ) : that . desc != null ) return false ; 
if ( ! name . equals ( that . name ) ) return false ; 
if ( wmoId != null ? ! wmoId . equals ( that . wmoId ) : that . wmoId != null ) return false ; 
int result ; 
long temp ; 
temp = Double . doubleToLongBits ( lat ) ; 
result = ( int ) ( temp ^ ( temp > > > 32 ) ) ; 
temp = Double . doubleToLongBits ( lon ) ; 
result = 31 * result + ( int ) ( temp ^ ( temp > > > 32 ) ) ; 
temp = Double . doubleToLongBits ( alt ) ; 
result = 31 * result + name . hashCode ( ) ; 
result = 31 * result + ( desc != null ? desc . hashCode ( ) : 0 ) ; 
result = 31 * result + ( wmoId != null ? wmoId . hashCode ( ) : 0 ) ; 
public class FieldConverter implements BufrField { 
DataDescriptor dds ; 
List < FieldConverter > flds ; 
BufrCdmIndexProto . FldType type ; 
BufrCdmIndexProto . FldAction action ; 
int min = Integer . MAX_VALUE ; 
int max = 0 ; 
boolean isSeq ; 
private FieldConverter ( int center , DataDescriptor dds ) { 
this . dds = dds ; 
this . type = StandardFields . findField ( center , dds . getFxyName ( ) ) ; 
if ( dds . getSubKeys ( ) != null ) { 
this . flds = new ArrayList < > ( dds . getSubKeys ( ) . size ( ) ) ; 
for ( DataDescriptor subdds : dds . getSubKeys ( ) ) { 
FieldConverter subfld = new FieldConverter ( center , subdds ) ; 
flds . add ( subfld ) ; 
public String getName ( ) { 
return dds . getName ( ) ; 
public String getDesc ( ) { 
return dds . getDesc ( ) ; 
public String getUnits ( ) { 
return dds . getUnits ( ) ; 
public short getFxy ( ) { 
return dds . getFxy ( ) ; 
public String getFxyName ( ) { 
return dds . getFxyName ( ) ; 
public BufrCdmIndexProto . FldAction getAction ( ) { 
public BufrCdmIndexProto . FldType getType ( ) { 
public List < FieldConverter > getChildren ( ) { 
return flds ; 
public boolean isSeq ( ) { 
return isSeq ; 
public int getMin ( ) { 
return min ; 
public int getMax ( ) { 
return max ; 
public int getScale ( ) { 
return dds . getScale ( ) ; 
public int getReference ( ) { 
return dds . getRefVal ( ) ; 
public int getBitWidth ( ) { 
return dds . getBitWidth ( ) ; 
public void setAction ( String action ) { 
BufrCdmIndexProto . FldAction act = BufrCdmIndexProto . FldAction . valueOf ( action ) ; 
if ( act != null ) 
this . action = act ; 
public void setAction ( BufrCdmIndexProto . FldAction action ) { 
this . action = action ; 
FieldConverter findChild ( String want ) { 
for ( FieldConverter child : flds ) { 
String name = child . dds . getName ( ) ; 
if ( name != null && name . equals ( want ) ) 
FieldConverter findChildByFxyName ( String fxyName ) { 
String name = child . dds . getFxyName ( ) ; 
if ( name != null && name . equals ( fxyName ) ) 
public FieldConverter getChild ( int i ) { 
return flds . get ( i ) ; 
void trackSeqCounts ( int n ) { 
isSeq = true ; 
if ( n > max ) max = n ; 
if ( n < min ) min = n ; 
void showRange ( Formatter f ) { 
if ( ! isSeq ) return ; 
BufrCdmIndexProto . FldAction makeAction ( ) { 
if ( ! isSeq ) return null ; 
if ( max == 0 ) return BufrCdmIndexProto . FldAction . remove ; 
if ( max < 2 ) return BufrCdmIndexProto . FldAction . asMissing ; 
else return BufrCdmIndexProto . FldAction . asArray ; 
void show ( Formatter f , Indent indent , int index ) { 
boolean hasContent = false ; 
if ( isSeq ) 
dds . getFxyName ( ) , dds . getName ( ) , dds . getDesc ( ) , dds . getUnits ( ) , dds . getBitWidth ( ) ) ; 
showRange ( f ) ; 
if ( flds != null ) { 
f . format ( ">%n" ) ; 
int subidx = 0 ; 
for ( FieldConverter cc : flds ) { 
cc . show ( f , indent , subidx ++ ) ; 
hasContent = true ; 
if ( hasContent ) 
f . format ( "%s</fld>%n" , indent ) ; 
public void show ( Formatter out ) { 
if ( standardFields != null ) 
for ( FieldConverter fld : rootConverter . flds ) { 
fld . show ( out , indent , index ++ ) ; 
out . format ( "</bufr2nc>%n" ) ; 
public static void main ( String [ ] args ) throws IOException { 
String filename = "G:/work/manross/split/872d794d.bufr" ; 
BufrConfig config = BufrConfig . scanEntireFile ( raf ) ; 
Formatter out = new Formatter ( ) ; 
config . show ( out ) ; 
System . out . printf ( "%s%n" , out ) ; 
ConfigCatalogExtProto . DataRoot . Builder builder = ConfigCatalogExtProto . DataRoot . newBuilder ( ) ; 
builder . setUrlPath ( path ) ; 
builder . setDirLocation ( dirLocation ) ; 
builder . setType ( convertDataRootType ( type ) ) ; 
if ( type != DataRoot . Type . datasetRoot ) { 
builder . setCatLocation ( catLocation ) ; 
if ( restrict != null ) 
builder . setRestrict ( restrict ) ; 
ConfigCatalogExtProto . DataRoot index = builder . build ( ) ; 
} static public DataRoot . Type convertDataRootType ( ConfigCatalogExtProto . DataRootType type ) { 
case datasetRoot : 
return DataRoot . Type . datasetRoot ; 
case datasetScan : 
return DataRoot . Type . datasetScan ; 
case catalogScan : 
return DataRoot . Type . catalogScan ; 
case featureCollection : 
return DataRoot . Type . featureCollection ; 
double xrowi ; 
double xcoli ; 
double xqlon ; 
double xspace ; 
double yspace ; 
double xt1 ; 
double xt2 ; 
double xh ; 
double xfac ; 
double xblat ; 
double glamx ; 
double glomx ; 
double glamn ; 
double glomn ; 
double ginct ; 
double gincn ; 
GRIDnav nav = new GRIDnav ( vals ) ; 
int gridType = vals [ 33 ] ; 
int navType = gridType % 10 ; 
addParam ( "Proj" , String . valueOf ( navType ) ) ; 
boolean wierd = gridType / 10 == 1 ; 
int ny = vals [ 1 ] ; 
int nx = vals [ 2 ] ; 
addParam ( PROJ , getProjName ( navType ) ) ; 
addParam ( NX , String . valueOf ( nx ) ) ; 
addParam ( NY , String . valueOf ( ny ) ) ; 
double [ ] [ ] input ; 
if ( nav . isFlippedRowCoordinates ( ) ) { 
input = new double [ ] [ ] { { 1 , nx } , { 1 , ny } } ; 
input = new double [ ] [ ] { { 1 , nx } , { ny , 1 } } ; 
double [ ] [ ] llur = nav . toLatLon ( input ) ; 
addParam ( LA1 , String . valueOf ( llur [ 0 ] [ 0 ] ) ) ; 
addParam ( LO1 , String . valueOf ( llur [ 1 ] [ 0 ] ) ) ; 
addParam ( LA2 , String . valueOf ( llur [ 0 ] [ 1 ] ) ) ; 
addParam ( LO2 , String . valueOf ( llur [ 1 ] [ 1 ] ) ) ; 
switch ( navType ) { 
case PSEUDO_MERCATOR : 
case PSEUDO_MERCATOR_GENERAL : 
glamx = vals [ 34 ] / 10000. ; 
glomx = - vals [ 35 ] / 10000. ; 
glamn = vals [ 34 ] / 10000. ; 
glomn = - vals [ 35 ] / 10000. ; 
ginct = vals [ 38 ] / 10000. ; 
gincn = ( navType == PSEUDO_MERCATOR_GENERAL ) 
? vals [ 39 ] / 10000. 
: ginct ; 
addParam ( "Latin" , String . valueOf ( 20 ) ) ; 
case PS_OR_LAMBERT_CONIC : 
xrowi = vals [ 34 ] / 10000. ; 
xcoli = vals [ 35 ] / 10000. ; 
xspace = vals [ 36 ] ; 
xqlon = - vals [ 37 ] / 10000. ; 
xt1 = vals [ 38 ] / 10000. ; 
xt2 = vals [ 39 ] / 10000. ; 
addParam ( LATIN1 , String . valueOf ( xt1 ) ) ; 
addParam ( LOV , String . valueOf ( xqlon ) ) ; 
addParam ( LATIN2 , String . valueOf ( xt2 ) ) ; 
